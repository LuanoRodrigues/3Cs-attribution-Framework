{
   "pyr_l1_html": {
    "prompt": "You are drafting a section entitled \"{research_question}\" within the subsection \"{overarching_theme}\", focusing specifically on evidence type \"{evidence_type}\".\n\nCONTEXT\nYou will be given a JSON array of payload items. Each item contains: \"direct_quote\", \"paraphrase\", \"researcher_comment\", a thematic label \"theme\" (the item's potential theme), an \"item_key\", and a unique \"direct_quote_id\".\n\nOBJECTIVE\nProduce a section draft at academic-journal quality. For each thematic paragraph: start with a clear topic sentence answering part of the research question, then develop supporting reasoning grounded in the evidence. Integrate short quoted fragments directly in the anchors so the evidence is visible at point of claim.\n\nCOVERAGE RULES (exhaustive)\n• Every payload item must be analyzed at least once. No exceptions. Cite each item when used.\n• Prioritise grouping by shared \"theme\"; when useful, show convergence or disagreement across multiple sources in the same paragraph.\n• If any items remain hard to place, add one final paragraph titled \"Residual coverage\" that cites them and briefly explains why they do not fit thematically.\n\nCITATION HYGIENE (mandatory)\n• At least one anchor per paragraph; anchor every non-obvious claim immediately after the supporting sentence.\n• Use exactly this anchor shape and include a short evidence snippet (≤30 words) as inner text:\n  <a href=\"KEY\" data-key=\"item_key\" title=\"direct_quote_id\">SHORT_QUOTE_OR_NEUTRAL_LABEL</a>\n• When multiple sources support the same sentence, include multiple anchors in the same parenthetical set separated by semicolons.\n• Do not invent keys. Do not duplicate the same (item_key, direct_quote_id) within a single sentence.\n\nDIVERSITY & ECONOMY\n• Aim for ≥2 DISTINCT item_keys per thematic paragraph when available.\n• Avoid citing the same item_key in consecutive sentences unless necessary; prefer mixing sources when evidence permits.\n\nOUTPUT (strictly raw HTML — no Markdown, no lists)\n• Begin with a section title:\n  <h3 id=\"section-title\">{research_question} — {overarching_theme} — {evidence_type}</h3>\n• Then write N thematic paragraphs. Each paragraph MUST be exactly one <p> element and include:\n  – a clear topic sentence;\n  – at least one correctly formed anchor with inner quoted text;\n  – a data-tags attribute with 1–3 concise tags (semicolon-separated) that classify the paragraph.\n  Example shape:\n  <p id=\"p1\" data-tags=\"methods;scope\">Topic sentence. Evidence-led exposition … (<a href=\"KEY\" data-key=\"item_key\" title=\"direct_quote_id\">short quote</a>; <a href=\"KEY2\" data-key=\"item_key_2\" title=\"direct_quote_id_2\">short quote</a>)</p>\n• After thematic paragraphs, add a conclusive paragraph (2–3 sentences) with EXACT id:\n  <p id=\"conslusion\">Synthesis across paragraphs; state the strongest regularities, salient disagreements, and implications.</p>\n• If any items were not integrated thematically, append a residuals paragraph with EXACT id (note the space at the end):\n  <p id=\"Residual \">Residual coverage: brief reason these items do not fit; still cite them with anchors.</p>\n• Finally, append a coverage ledger comment:\n  <!-- coverage used=[comma-separated item_keys used] unused=[comma-separated item_keys not used] -->\n\nQUALITY CHECK (fix before returning)\n• Every paragraph has ≥1 anchor with inner quoted text (≤30 words).\n• Each <p> has data-tags with 1–3 tags; tags are concise and informative.\n• No invented keys; anchors match payload items; no duplicate (item_key, direct_quote_id) within a sentence.\n• Include exactly one <h3 id=\"section-title\">, one <p id=\"conslusion\">, and optional <p id=\"Residual \"> when needed.\n• Coverage ledger matches the actual anchors: unused = payload_keys − used.\n",
    "default_model": { "openai": "gpt-5-mini" },
    "max_tokens": 10000,
    "effort": "high",
    "response_format": { "type": "text" }
  },
   "pyr_l2_html": {
    "prompt": "",
    "default_model": { "openai": "gpt-5-mini" },
    "max_tokens": 12000,
    "effort": "high",
    "response_format": { "type": "text" }
  },

  "code_pdf_page": {
    "prompt": "You are an expert research assistant coding a PDF page for a literature review against one or more Research Questions (RQs). Use a skeptical, high-rigour, PhD-level lens (social science / international politics / international law aware). Extract ONLY content that is genuinely responsive to ANY RQ.\n\nList of Research Questions (0-based Index: Question):\n{research_questions_formatted}\n\nSource Document Info: Item Key {parent_item_key}, Author/Year {author_year_info}\n\nText Chunk from PDF:\n--- BEGIN CHUNK ---\n{context}\n--- END CHUNK ---\n\nTask:\nIdentify specific sentences or short passages that DIRECTLY address ANY aspect of ANY RQ. For EACH distinct relevant piece of information, output ONE evidence object with the keys: quote, paraphrase, researcher_comment, potential_themes, relevance_score, relevant_rqs, evidence_type, argument_type, claim_direction, open_codes.\n\nItem-level expectations (strict):\n- quote: VERBATIM raw extract from the chunk (must be a substring). Use the minimal span needed to carry ONE atomic claim. Limit to 1–3 sentences; 8–35 words is typical, shorter is fine if precise. Do NOT tidy wording, fix grammar, or merge text across non-adjacent lines.\n- paraphrase: One affirmative sentence that restates the quoted claim in your own words, explicitly tied to the relevant RQ(s). Preserve any important qualifiers (e.g., \"may\", \"in this case\", \"under Article X\") as qualifiers, not as speculation.\n- researcher_comment: Up to 3 short sentences. Provide a pointed note on how/why this quote matters for the RQ(s), including caveats, scope conditions, assumptions, thresholds, alternative readings, methodological limits, legal status/authority (if relevant), and fit for synthesis.\n- potential_themes: Choose 1–3 mid-level, clusterable labels that best match the quote (e.g., \"attribution_challenges\", \"evidentiary_standards\", \"state_responsibility_thresholds\"). Use canonical project labels or their CURIE aliases if you know them. Do not invent new labels; if no existing label clearly fits, SKIP this evidence item.\n- relevance_score: Integer 1–5 where 5 = directly answers an RQ OR provides a usable definition/finding/legal rule/operationalization; 3 = partial/indirect support; 1 = tangential mention.\n- relevant_rqs: Provide a list of objects with the RQ indices only, e.g., [{\"index\": 0}, {\"index\": 2}]. Select every RQ that the evidence substantively addresses.\n\nControlled vocab selections (choose the most specific fit):\n- evidence_type: Select ONE from {definition_conceptual, theory_model, framework, taxonomy_typology, legal_source_primary, jurisprudence_case_law, state_practice_custom, policy_position, empirical_finding_quantitative, empirical_finding_qualitative, empirical_finding_mixed_methods, case_study_example, dataset_resource, method_design, method_operationalization, assumption, scope_condition, limitation, threat_to_validity, recommendation}.\n  Guidance:\n  - Use legal_source_primary for verbatim or paraphrased binding texts (treaty provisions, UN Charter articles, statutes, formal rules).\n  - Use jurisprudence_case_law for court/tribunal holdings or judicial reasoning.\n  - Use state_practice_custom for evidence/claims about state practice, opinio juris, customary international law formation.\n  - Use empirical_finding_* for reported results; use method_* for how evidence is generated (design, identification strategy, operationalization, measurement).\n  - Use limitation / threat_to_validity only when the text explicitly states a limitation or validity threat (internal/external/construct, selection bias, confounding, measurement error).\n\n- argument_type: Select ONE from {definitional, descriptive, causal, correlational, comparative, normative, legal_interpretive, methodological, procedural, predictive, unspecified}.\n  Guidance:\n  - legal_interpretive = interpretation/qualification of a legal rule, standard, threshold, obligation, or doctrine.\n  - methodological = claim about design validity, measurement, identification, inference, or evaluation logic.\n\n- claim_direction: Select ONE from {supports, contradicts, mixed, qualifies, neutral, unspecified}.\n  Guidance:\n  - supports/contradicts/qualifies should be used only when the quote clearly takes a stance relative to a proposition relevant to an RQ (including author’s own earlier claim within the quote). If no stance is expressed, use neutral or unspecified.\n\n- open_codes: Return 1–5 concise inductive codes (snake_case preferred) grounded in the quote (e.g., \"attribution_standard_of_proof\", \"customary_law_evidence\", \"selection_bias_risk\").\n\nNoise filters and guardrails:\n- Prefer: definitions, theories/mechanisms, empirical findings, operationalizations, methodological claims, legal doctrines/thresholds, policy positions, explicit limitations/threats.\n- Ignore: pure narrative framing, generic background, section headers, reference lists, boilerplate, and figure/table captions unless they contain a substantive claim relevant to an RQ.\n- Do NOT infer beyond the chunk. No page numbers, no external citations, no cross-chunk stitching.\n- If a passage mentions multiple claims, split into multiple evidence objects.\n\nOutput format:\nReturn ONLY a JSON object with a single key \"evidence\" whose value is a list of 0–20 evidence objects as specified. If nothing qualifies, return {\"evidence\": []}. No prose, no markdown, no backticks—JSON only.",
    "default_model": { "openai": "gpt-5-mini" },
    "max_tokens": 1500,
    "effort": "medium",
    "property": {
      "name": "code_pdf_page",
      "description": "Return an object with an 'evidence' array of extracted evidence items relevant to the provided RQs.",
      "schema": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "evidence": {
            "type": "array",
            "description": "List of evidence objects extracted from the provided text chunk.",
            "minItems": 0,
            "maxItems": 20,
            "items": {
              "type": "object",
              "additionalProperties": false,
              "properties": {
                "quote": {
                  "type": "string",
                  "minLength": 6,
                  "maxLength": 600,
                  "description": "Exact sentence(s) copied VERBATIM from the chunk (must be a substring of the chunk). Keep as short as possible while conveying ONE atomic claim."
                },
                "paraphrase": {
                  "type": "string",
                  "minLength": 1,
                  "maxLength": 300,
                  "description": "One-sentence neutral summary aligned to the relevant RQ(s). Preserve key qualifiers as qualifiers."
                },
                "researcher_comment": {
                  "type": "string",
                  "minLength": 1,
                  "maxLength": 600,
                  "description": "Concise, pointed critical analysis in ≤3 sentences (note assumptions/scope/limits/legal authority where relevant and how this might be used)."
                },
                "potential_themes": {
                  "type": "array",
                  "minItems": 1,
                  "maxItems": 3,
                  "items": { "type": "string", "minLength": 3, "maxLength": 80 },
                  "description": "Select 1–3 labels from the controlled vocabulary (ISO 25964-style governance). Use canonical labels (e.g., \"attribution_challenges\") or CURIEs (e.g., \"zkatheme:attribution_challenges\"). Do not mint new labels."
                },
                "relevance_score": {
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 5,
                  "description": "1–5 rating of relevance to the RQs."
                },
                "relevant_rqs": {
                  "type": "array",
                  "minItems": 0,
                  "items": {
                    "type": "object",
                    "additionalProperties": false,
                    "properties": {
                      "index": { "type": "integer", "minimum": 0 }
                    },
                    "required": ["index"]
                  },
                  "description": "List of {index} objects identifying the RQs addressed (use an empty array if none)."
                },
                "evidence_type": {
                  "type": "string",
                  "enum": [
                    "definition_conceptual",
                    "theory_model",
                    "framework",
                    "taxonomy_typology",
                    "legal_source_primary",
                    "jurisprudence_case_law",
                    "state_practice_custom",
                    "policy_position",
                    "empirical_finding_quantitative",
                    "empirical_finding_qualitative",
                    "empirical_finding_mixed_methods",
                    "case_study_example",
                    "dataset_resource",
                    "method_design",
                    "method_operationalization",
                    "assumption",
                    "scope_condition",
                    "limitation",
                    "threat_to_validity",
                    "recommendation"
                  ],
                  "description": "Evidence modality/content class represented by the quote (social science / international law aware)."
                },
                "argument_type": {
                  "type": "string",
                  "enum": [
                    "definitional",
                    "descriptive",
                    "causal",
                    "correlational",
                    "comparative",
                    "normative",
                    "legal_interpretive",
                    "methodological",
                    "procedural",
                    "predictive",
                    "unspecified"
                  ],
                  "description": "Argumentation form of the extracted claim."
                },
                "claim_direction": {
                  "type": "string",
                  "enum": [
                    "supports",
                    "contradicts",
                    "mixed",
                    "qualifies",
                    "neutral",
                    "unspecified"
                  ],
                  "description": "Directional stance of the claim relative to a proposition relevant to the RQ framing; use neutral/unspecified if no clear stance is expressed."
                },
                "open_codes": {
                  "type": "array",
                  "minItems": 1,
                  "maxItems": 5,
                  "items": { "type": "string", "minLength": 2, "maxLength": 80 },
                  "description": "1–5 concise inductive codes grounded in the quote (snake_case preferred)."
                }
              },
              "required": [
                "quote",
                "paraphrase",
                "researcher_comment",
                "potential_themes",
                "relevance_score",
                "relevant_rqs",
                "evidence_type",
                "argument_type",
                "claim_direction",
                "open_codes"
              ]
            }
          }
        },
        "required": ["evidence"]
      }
    }
  }
,
   "code_intro_conclusion_extract_core_claims": {
    "prompt": "You are an expert research assistant extracting high-value, claim-level evidence from the INTRODUCTION and CONCLUSION (and optionally DISCUSSION/LIMITATIONS) of an academic paper for a literature review in social science / international politics / international law. Use a skeptical, high-rigour, PhD-level lens.\n\nYou will receive:\n- Source Document Info: item_key {parent_item_key}, author/year {author_year_info}\n- Research Questions (0-based index):\n{research_questions_formatted}\n- Existing codes/themes available for this project (controlled vocabulary):\n{controlled_codes_formatted}\n- Text from the paper (Introduction + Conclusion; may include adjacent sections):\n--- BEGIN CHUNK ---\n{context}\n--- END CHUNK ---\n\nObjective (strict):\nExtract ONLY the following types of content when they are explicit in the chunk:\n1) Definitions (conceptual or legal)\n2) Main findings / main claims of contribution (as stated by the authors)\n3) Method claims (design, identification strategy, operationalization, measurement, case selection, data sources)\n4) Stated limitations / threats to validity / scope conditions (explicit caveats)\n5) Recommendations / future work (explicit proposals, normative implications)\n\nFor EACH distinct relevant piece of information, output ONE evidence object with keys: dqid, quote, extraction_type, paraphrase, relevance_score, relevant_rqs, mapped_codes.\n\nExtraction rules:\n- dqid: A deterministic ID that MUST be exactly \"{parent_item_key}#DQ\" followed by a 3-digit sequence starting at 001 in the order the evidence appears in the chunk (e.g., \"doi:10.1234/abcd#DQ001\").\n- quote: VERBATIM raw extract from the chunk (must be a substring). Use the minimal span needed to carry ONE atomic claim. Limit to 1–3 sentences; 8–45 words is typical. Do NOT merge non-adjacent text.\n- extraction_type: Select ONE from {definition, main_finding, method_claim, limitation, recommendation}.\n- paraphrase: One affirmative sentence restating the quoted claim in your own words. Preserve qualifiers (e.g., \"may\", \"under Article X\", \"in this case\") as qualifiers.\n- relevance_score: Integer 1–5 where 5 = directly answers an RQ OR gives a usable definition/finding/method/limitation/recommendation; 3 = partial/indirect; 1 = tangential.\n- relevant_rqs: List of objects with indices only, e.g., [{\"index\":0},{\"index\":2}]. Include every RQ substantively addressed; empty array allowed.\n- mapped_codes: Choose 0–5 codes from the provided controlled vocabulary ONLY (exact string match). If none clearly fit, return an empty array.\n\nDiscipline-specific guidance:\n- Definitions may be conceptual (the authors’ definition of a construct) or legal (a standard, threshold, obligation, doctrine). If legal, treat treaty text / doctrine statements as definitions only when used to define a term/standard.\n- Main findings in intro/conclusion are often framed as contributions (\"we show\", \"we find\", \"this paper demonstrates\"). Extract those only if they contain a substantive claim (not marketing).\n- Method claims include scope (case selection logic, dataset choice, operationalization) and epistemic stance (interpretivist/process-tracing; quantitative identification strategy; legal doctrinal method).\n- Limitations must be explicitly stated (\"we cannot\", \"limited to\", \"does not\", \"future work should address\").\n- Recommendations/future work must be explicit proposals or implications (policy/legal/political) and not generic concluding fluff.\n\nNoise filters:\n- Ignore: generic motivation, background history, broad statements of importance without a claim, and citations/reference lists.\n- Do NOT infer beyond the chunk. No cross-chunk stitching.\n- If a passage contains multiple claims, split into multiple evidence objects.\n\nOutput format:\nReturn ONLY a JSON object with a single key \"evidence\" whose value is a list of 0–25 evidence objects as specified. If nothing qualifies, return {\"evidence\": []}. No prose, no markdown, no backticks—JSON only.",
    "default_model": { "openai": "gpt-5-mini" },
    "max_tokens": 1600,
    "effort": "medium",
    "property": {
      "name": "code_intro_conclusion_extract_core_claims",
      "description": "Extract definitions, main findings, method claims, stated limitations, and recommendations from intro/conclusion text, with deterministic dqid and verbatim quotes.",
      "schema": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "evidence": {
            "type": "array",
            "minItems": 0,
            "maxItems": 25,
            "items": {
              "type": "object",
              "additionalProperties": false,
              "properties": {
                "dqid": {
                  "type": "string",
                  "minLength": 8,
                  "maxLength": 200,
                  "description": "Deterministic ID: {parent_item_key}#DQ### (001+)."
                },
                "quote": {
                  "type": "string",
                  "minLength": 6,
                  "maxLength": 800,
                  "description": "Verbatim excerpt from the provided chunk (must be a substring). Minimal span for ONE claim."
                },
                "extraction_type": {
                  "type": "string",
                  "enum": ["definition", "main_finding", "method_claim", "limitation", "recommendation"],
                  "description": "Category of extracted content."
                },
                "paraphrase": {
                  "type": "string",
                  "minLength": 1,
                  "maxLength": 320,
                  "description": "One-sentence restatement aligned to RQ(s); preserve qualifiers."
                },
                "relevance_score": {
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 5,
                  "description": "1–5 rating of relevance to the RQs."
                },
                "relevant_rqs": {
                  "type": "array",
                  "minItems": 0,
                  "items": {
                    "type": "object",
                    "additionalProperties": false,
                    "properties": {
                      "index": { "type": "integer", "minimum": 0 }
                    },
                    "required": ["index"]
                  },
                  "description": "List of {index} objects identifying the RQs addressed (use an empty array if none)."
                },
                "mapped_codes": {
                  "type": "array",
                  "minItems": 0,
                  "maxItems": 5,
                  "items": { "type": "string", "minLength": 2, "maxLength": 120 },
                  "description": "0–5 codes selected ONLY from the provided controlled vocabulary (exact match)."
                }
              },
              "required": [
                "dqid",
                "quote",
                "extraction_type",
                "paraphrase",
                "relevance_score",
                "relevant_rqs",
                "mapped_codes"
              ]
            }
          }
        },
        "required": ["evidence"]
      }
    }
  },



  "extract_NA": {
    "json_schema": {
      "name": "extract_NA",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "keyword_analysis": {
            "type": "object",
            "properties": {
            },
            "required": [],
            "additionalProperties": false
          }
        },
        "required": [
          "results"
        ],
        "additionalProperties": false
      }
    },
    "theoretical_orientation": {
      "prompt": "Set `value` to one of [Realism, Liberalism, Constructivism, Critical, Doctrinal, Normative, Policy-analytic, None] or Other:{value}. Then: 1) write a discussion paragraph (60–140 words) linking this concept to the paper’s research question/problem, findings, limitations, contribution, gap, and/or future direction; 2) provide support — one exact sentence from `paper_text` (allowed normalisation only: fix hyphenated line-breaks, collapse whitespace); 3) add a critique paragraph (60–140 words) using a clear evaluative stance; 4) if no clean single sentence exists, set support to \"NA\". Hard rules: Support is one literal sentence; Discussion/Critique are 60–140 words each; do not alter quotation markers; output only the JSON object with canonical keys: value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Realism",
                  "Liberalism",
                  "Constructivism",
                  "Critical",
                  "Doctrinal",
                  "Normative",
                  "Policy-analytic",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "ontology": {
      "prompt": "Set `value` to one of [Individual, Group/Non-state, Firm/Platform, Organisational, Dyadic, State, Transnational/Regime, Systemic, None] or Other:{value}. Then: discussion (60–140 words) connecting level of analysis to the paper’s question/problem, findings, limits, contribution, and/or future work; support — one literal sentence from `paper_text` (only fix hyphenation and whitespace); critique (60–140 words). If no single clean sentence exists, set support to \"NA\". Hard rules as above; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Individual",
                  "Group/Non-state",
                  "Firm/Platform",
                  "Organisational",
                  "Dyadic",
                  "State",
                  "Transnational/Regime",
                  "Systemic",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "epistemology": {
      "prompt": "Set `value` to one of [Positivist, Constructivist, Critical, Doctrinal/Analytic, Normative, Pragmatist, None] or Other:{value}. Then produce: discussion (60–140 words) linking epistemic stance to the paper’s question/problem, method, and findings; support — one exact sentence from `paper_text` (only allowed normalisation); critique (60–140 words). If no clean sentence exists, support = \"NA\". Follow the hard rules and output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Positivist",
                  "Constructivist",
                  "Critical",
                  "Doctrinal/Analytic",
                  "Normative",
                  "Pragmatist",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "argumentation_logic": {
      "prompt": "Set `value` to one of [Deductive, Inductive, Abductive, Normative, None] or Other:{value}. Then write: discussion (60–140 words) explaining how this logic structures inference from evidence to claims in the paper; support — one exact sentence from `paper_text` (allowed normalisation only); critique (60–140 words). If no single sentence fits, support = \"NA\". Apply the hard rules; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Deductive",
                  "Inductive",
                  "Abductive",
                  "Normative",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "evidence_source_base": {
      "prompt": "Set `value` to the dominant evidence type used, chosen from [Interviews, Archival Documents, Public Statements, Surveys, Simulation Output, Legal Texts, Court Filings/Case Law, Diplomatic Notes, Sanctions Notices, UN GGE/OEWG Reports, National Strategies/Doctrines, Policy Documents, Technical data/Logs, Forensic Artifacts, Malware Reports, Threat Intelligence Reports] or Other:{value}. Then: discussion (60–140 words) linking evidence base to claims, limits, and findings; support — one exact sentence from `paper_text` that names or exemplifies the evidence; critique (60–140 words). If no clean sentence exists, support = \"NA\". Hard rules apply; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Interviews",
                  "Archival Documents",
                  "Public Statements",
                  "Surveys",
                  "Simulation Output",
                  "Legal Texts",
                  "Court Filings/Case Law",
                  "Diplomatic Notes",
                  "Sanctions Notices",
                  "UN GGE/OEWG Reports",
                  "National Strategies/Doctrines",
                  "Policy Documents",
                  "Technical data/Logs",
                  "Forensic Artifacts",
                  "Malware Reports",
                  "Threat Intelligence Reports",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "methods": {
      "prompt": "Set `value` to the dominant method from [Content Analysis, Regression Analysis, Network Analysis, Case Study, Comparative Case Study, Game-theoretic Modeling, Agent-Based Simulation, Scenario Exercises/Simulation, Doctrinal Analysis, Comparative Legal Analysis, Case-law Analysis, Interviews, Surveys, Discourse Analysis] or Other:{value}. Then: discussion (60–140 words) explaining how this method is applied and tied to the findings; support — one exact sentence from `paper_text`; critique (60–140 words). If no clean sentence exists, support = \"NA\". Hard rules apply; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Content Analysis",
                  "Regression Analysis",
                  "Network Analysis",
                  "Case Study",
                  "Comparative Case Study",
                  "Game-theoretic Modeling",
                  "Agent-Based Simulation",
                  "Scenario Exercises/Simulation",
                  "Doctrinal Analysis",
                  "Comparative Legal Analysis",
                  "Case-law Analysis",
                  "Interviews",
                  "Surveys",
                  "Discourse Analysis",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "method_type": {
      "prompt": "Set `value` to one of [Qualitative, Quantitative, Mixed, Doctrinal, None] or Other:{value}. Then: discussion (60–140 words) linking approach to data/evidence and inference; support — one exact sentence from `paper_text`; critique (60–140 words). If no clean sentence exists, support = \"NA\". Follow the hard rules; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Qualitative",
                  "Quantitative",
                  "Mixed",
                  "Doctrinal",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "framework_model": {
      "prompt": "Set `value` to one named framework/doctrine explicitly relied upon: [Deterrence Theory, Decision-Making Attribution Framework, State Responsibility, Threshold Model, Due Diligence, Effective Control, Overall Control, Virtual Control, Countermeasures, Sliding scale approaches, Proportionality, Use of Force, Armed Attack, UN GGE Norms, UN OEWG Norms, Tallinn Manual, Sanctions/Export Controls, MITRE ATT&CK, Diamond Model, Cyber Kill Chain, None] or Other:{value}. Then: discussion (60–140 words) linking the framework to the paper’s reasoning and findings; support — one exact sentence from `paper_text`; critique (60–140 words). If no clean sentence exists, support = \"NA\". Apply hard rules; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Deterrence Theory",
                  "Decision-Making Attribution Framework",
                  "State Responsibility",
                  "Threshold Model",
                  "Due Diligence",
                  "Effective Control",
                  "Overall Control",
                  "Virtual Control",
                  "Countermeasures",
                  "Sliding scale approaches",
                  "Proportionality",
                  "Use of Force",
                  "Armed Attack",
                  "UN GGE Norms",
                  "UN OEWG Norms",
                  "Tallinn Manual",
                  "Sanctions/Export Controls",
                  "MITRE ATT&CK",
                  "Diamond Model",
                  "Cyber Kill Chain",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "contribution_type": {
      "prompt": "Set `value` to one of [Theoretical, Empirical, Methodological, Conceptual, Practical, Survey/Review, Dataset, Policy Proposal/Guidance, Case Note/Commentary, Framework Proposal, None] or Other:{value}. Then: discussion (60–140 words) explaining the paper’s contribution and how it is substantiated; support — one exact sentence from `paper_text`; critique (60–140 words). If no clean sentence exists, support = \"NA\". Follow hard rules; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Theoretical",
                  "Empirical",
                  "Methodological",
                  "Conceptual",
                  "Practical",
                  "Survey/Review",
                  "Dataset",
                  "Policy Proposal/Guidance",
                  "Case Note/Commentary",
                  "Framework Proposal",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "attribution_lens_focus": {
      "prompt": "Set `value` to one of [Strategic/Political, Legal/Doctrinal, Technical/Forensic, Intelligence/Tradecraft, Economic/Regulatory, Multi-dimensional, None] or Other:{value}. Then: discussion (60–140 words) connecting lens to question, methods, and findings; support — one exact sentence from `paper_text`; critique (60–140 words). If no clean sentence exists, support = \"NA\". Apply the hard rules; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Strategic/Political",
                  "Legal/Doctrinal",
                  "Technical/Forensic",
                  "Intelligence/Tradecraft",
                  "Economic/Regulatory",
                  "Multi-dimensional",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }
    },
    "research_question_purpose": {
      "prompt": "Set `value` to one of [Exploratory, Descriptive, Explanatory, Normative, None] or Other:{value}. Then: discussion (60–140 words) linking purpose to design, evidence, and findings; support — one exact sentence from `paper_text`; critique (60–140 words). If no clean sentence exists, support = \"NA\". Follow the hard rules; output only value, discussion, support, critique.",
      "property": {
        "type": "object",
        "properties": {
          "value": {
            "type": "string",
            "anyOf": [
              {
                "enum": [
                  "Exploratory",
                  "Descriptive",
                  "Explanatory",
                  "Normative",
                  "None"
                ]
              },
              {
                "pattern": "^Other:.+"
              }
            ]
          },
          "discussion": {
            "type": "string"
          },
          "support": {
            "type": "string"
          },
          "critique": {
            "type": "string"
          }
        },
        "required": [
          "value",
          "discussion",
          "support",
          "critique"
        ],
        "additionalProperties": false
      }

  },
    "affiliations": {
  "prompt": "System: Extract ONLY (a) author affiliations as they appear in the paper. Affiliation: produce one object per author affiliation as it appears. If the paper has multiple affiliations, emit one object per affiliation. If author names are present but not needed for this task, ignore them. - get the institution(s) producing the paper normally the institutions the authors are affiliated to. it can be universities, companies, goverment agencies among others. - department, retrieve the exact department of the institution if existant - city : retrieve the city of the affiliation if existant • Country: set the country exactly as written if explicit; otherwise set it to \"\" (empty string) or use a best-effort country if unambiguous from the institution name; when uncertain, set it to \"\". if city is present, infer the country by the city. - region/continent: retrieve the continent/region inferred through the city/country",
  "property": {
    "type": "array",
    "items": {
      "type": "object",
      "properties": {
        "institution": { "type": "string" },
        "department": { "type": ["string", "null"] },
        "city": { "type": ["string", "null"] },
        "country": { "type": "string" },
        "continent": { "type": "string" }
      },
      "required": ["institution", "department", "city", "country", "continent"],
      "additionalProperties": false
    }
  }
},


  "controlled_vocabulary_terms": {
    "prompt": "From the given academic paper only (title, abstract, and main text if present), extract controlled vocabulary terms that faithfully reflect its central themes, methods, frameworks, evidence base, findings, and contribution. Do not use or mirror any pipeline metadata, screening outcomes, boilerplate sections (acknowledgements, disclaimers), or reference lists. Return 3–12 terms (or [] if none apply). Each term must be a noun phrase of 1–4 words in British English, singular lemma, with capitalisation only for proper names and standard acronyms. Prefer labels explicitly supported by the text; where multiple near-synonyms appear, choose one preferred form. Apply ISO 25964/SKOS practices: normalise, deduplicate, and map synonyms to a single preferred label. When the text supports it, aim for a faceted mix (problem/domain; doctrine/framework; methodology; evidence type; attribution lens; actors/regions; temporal orientation). Exclude vague catch-alls and idiosyncratic titles. Order terms by salience to the paper’s argument and main findings.",
    "property": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "List of controlled vocabulary terms (empty array if not included)."
    }
  },
  "abstract": {
    "prompt": "Produce one synthetic abstract of ~500 words (±10 %). If screening_status = Include, write a single coherent paragraph that follows this exact order: (a) state the author(s) by name; 1) problem statement; 2) research question; 3) research objective; 4) methodology/epistemology/framework — specify approach (qualitative/quantitative/mixed), concrete methods (e.g., content analysis, interviews, case study), and any named frameworks/epistemic stance; 5) findings — link back to the problem, explain the argumentative logic (deductive/inductive/abductive), and identify the evidence types used (e.g., legal texts, public statements) and how they support the findings; 6) recommendations/future research only if explicitly indicated. No headings or bullet points; no invented citations.",
    "property": {
      "type": "string",
      "description": "A synthesized ~500-word paragraph if screening_status = Include; otherwise \"N/A\"."
    }
  }
}
,
 "paper_affiliation_and_entities": {
  "content": "System: Extract ONLY (a) author affiliations and (b) named entities, preserving literal wording.\n• Affiliation: produce one object per author affiliation as it appears. If an author has multiple affiliations, emit one object per affiliation. If author names are present but not needed for this task, ignore them.\n• Country: set the country exactly as written if explicit; otherwise set it to \"\" (empty string) or use a best-effort country if unambiguous from the institution name; when uncertain, set it to \"\".\n• Entities: list distinct named entities as they appear (literal). For each entity, return just its literal text and a type from the fixed list below. No other metadata fields.\n• Valid entity types: Person, Organisation, Institution, GovernmentBody, Country, City/Region, Treaty/Convention, Doctrine/Framework, LegalInstrument, Programme/Operation, Dataset/Tool, Court/Tribunal, Event, Other, or Other:{custom}.\n• Deduplication: dedupe case-insensitively; keep the first literal form seen.\n• Do not invent data. If none found: affiliations=[], entities_mentioned=[].\n{payload_placeholder}",
  "prompt": "Return exactly one JSON block:\n\n```json\n{\n  \"affiliation_and_entities\": {\n    \"affiliation\": [...],\n    \"entities_mentioned\": [...]\n  }\n}\n```\n\nNo extra keys or commentary.",
  "json_schema": {
    "name": "affiliation_entities_schema",
    "strict": true,
    "schema": {
      "type": "object",
      "properties": {
        "affiliation_and_entities": {
          "type": "object",
          "properties": {
            "affiliation": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "department": { "type": ["string", "null"] },
                  "institution": { "type": "string" },
                  "country": { "type": "string" }
                },
                "required": ["department", "institution", "country"],
                "additionalProperties": false
              }
            },
            "entities_mentioned": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "text": { "type": "string" },
                  "type": {
                    "type": "string",
                    "anyOf": [
                      { "enum": [
                        "Person",
                        "Organisation",
                        "Institution",
                        "GovernmentBody",
                        "Country",
                        "City/Region",
                        "Treaty/Convention",
                        "Doctrine/Framework",
                        "LegalInstrument",
                        "Programme/Operation",
                        "Dataset/Tool",
                        "Court/Tribunal",
                        "Event",
                        "Other"
                      ]},
                      { "pattern": "^Other:.+" }
                    ]
                  }
                },
                "required": ["text", "type"],
                "additionalProperties": false
              }
            }
          },
          "required": ["affiliation", "entities_mentioned"],
          "additionalProperties": false
        }
      },
      "required": ["affiliation_and_entities"],
      "additionalProperties": false
    }
  }
}
,

"paper_coding1": {
    "default_model": {
      "openai": "o4-mini-2025-04-16",
      "mistral": "mistral-7b-instruct"
    },
    "def_temperature": 0.1,
  "content": "System: You are a methodological coding assistant. **Return exactly one JSON object that conforms to the schema below – nothing more, nothing less.**\n\n### Input\n• `paper_text` – raw article text (intro, methods, findings, discussion). May contain line breaks, hyphenation, and citation markers like `${ }^{#}`.\n\n---\n### Inference & normalisation rules\n1. Ignore external codes. **Infer** values **directly from `paper_text`** for the canonical keys: `ontology, epistemology, argumentation_logic, evidence_source_base, methods, method_type`.\n2. Choose the label(s) from the schema’s allowed taxonomy that are **best supported by the text**; normalise hyphens/spaces and match case-insensitively. If nothing fits, set `value` to `Other:<literal phrase>` taken from the paper.\n3. Set `original_value` to the closest **literal phrase** in the paper that supports your chosen label (stringified if a list in the text). If you mapped a near-synonym to an allowed label, set `was_corrected` = `true`; otherwise `false`.\n4. Do not rely on references/footnotes lists; prioritise the body text. Prefer explicit statements over inference.\n\n---\n### `code_evidence` (the only section you must produce)\nFor **each** canonical key listed above:\n1. Provide `value` in the allowed type (string or array as per schema).\n2. Write a **`discussion`** paragraph (60–140 words) linking the concept to the paper’s question/problem, findings, limits, contribution, gap, and/or future direction.\n3. Provide **`support`** – one exact sentence from `paper_text`. **Allowed normalisation only:** fix hyphenated line-breaks and collapse whitespace; otherwise quote verbatim including citation markers.\n4. Add a **`critique`** paragraph (60–140 words) using a clear evaluative stance.\n5. If no clean sentence exists, set `support` = \"NA\" but still provide `value`, `discussion`, and `critique`.\n\n---\n### Hard rules\n• **Support** = one exact sentence (only the allowed normalisation).  \n• **Discussion** & **critique** = 60–140 words each.  \n• Do **not** invent or alter quotation markers.  \n• Do **not** add or remove code keys beyond the canonical list.  \n• Use the **canonical keys** exactly as property names in `code_evidence`.  \n• Output only the JSON object—no prose or Markdown.\n\nViolation of any rule invalidates the output.\n{payload_placeholder}",
  "text": "Paper text:\n\n{paper_text}\n\nReturn exactly one JSON object.",
    "json_schema": {
      "name": "coding_schema_v4a",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "code_evidence": {
            "type": "object",
            "additionalProperties": false,
            "required": [
              "ontology",
              "epistemology",
              "argumentation_logic",
              "evidence_source_base",
              "methods",
              "method_type"
            ],
            "properties": {
              "ontology": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "string",
                    "anyOf": [
                      { "enum": ["Individual","Group/Non-state","Firm/Platform","Organisational","Dyadic","State","Transnational/Regime","Systemic","None"] },
                      { "pattern": "^Other:.+" }
                    ]
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "epistemology": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "string",
                    "anyOf": [
                      { "enum": ["Positivist","Constructivist","Critical","Doctrinal/Analytic","Normative","Pragmatist","None"] },
                      { "pattern": "^Other:.+" }
                    ]
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "argumentation_logic": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "string",
                    "anyOf": [
                      { "enum": ["Deductive","Inductive","Abductive","Normative","None"] },
                      { "pattern": "^Other:.+" }
                    ]
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "evidence_source_base": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "anyOf": [
                        { "enum": [
                          "Interviews",
                          "Archival Documents",
                          "Public Statements",
                          "Surveys",
                          "Simulation Output",
                          "Legal Texts",
                          "Court Filings/Case Law",
                          "Diplomatic Notes",
                          "Sanctions Notices",
                          "UN GGE/OEWG Reports",
                          "National Strategies/Doctrines",
                          "Policy Documents",
                          "Technical data/Logs",
                          "Forensic Artifacts",
                          "Malware Reports",
                          "Threat Intelligence Reports"
                        ] },
                        { "pattern": "^Other:.+" }
                      ]
                    },
                    "maxItems": 5
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "methods": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "anyOf": [
                        { "enum": [
                          "Content Analysis",
                          "Regression Analysis",
                          "Network Analysis",
                          "Case Study",
                          "Comparative Case Study",
                          "Game-theoretic Modeling",
                          "Agent-Based Simulation",
                          "Scenario Exercises/Simulation",
                          "Doctrinal Analysis",
                          "Comparative Legal Analysis",
                          "Case-law Analysis",
                          "Interviews",
                          "Surveys",
                          "Discourse Analysis"
                        ] },
                        { "pattern": "^Other:.+" }
                      ]
                    },
                    "maxItems": 3
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "method_type": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "string",
                    "anyOf": [
                      { "enum": ["Qualitative","Quantitative","Mixed","Doctrinal","None"] },
                      { "pattern": "^Other:.+" }
                    ]
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              }
            }
          }
        },
        "required": ["code_evidence"],
        "additionalProperties": false
      }
    }
  }
,
   "paper_coding2": {
    "default_model": {
      "openai": "o4-mini-2025-04-16",
      "mistral": "mistral-7b-instruct"
    },
    "def_temperature": 0.1,
     "content": "System: You are a methodological coding assistant. **Return exactly one JSON object that conforms to the schema below – nothing more, nothing less.**\n\n### Input\n• `paper_text` – raw article text (intro, methods, findings, discussion). May contain line breaks, hyphenation, and citation markers like `${ }^{#}`.\n\n---\n### Inference & normalisation rules\n1. Ignore external codes. **Infer** values **directly from `paper_text`** for the canonical keys: `framework_model, contribution_type, attribution_lens_focus, research_question_purpose`.\n2. Choose labels from the schema’s allowed taxonomy that are **best supported by the text**; normalise hyphens/spaces and match case-insensitively. If nothing fits, set `value` to `Other:<literal phrase>` taken from the paper.\n3. Set `original_value` to the closest **literal phrase** in the paper that supports your chosen label (stringified if a list in the text). If you mapped a near-synonym to an allowed label, set `was_corrected` = `true`; otherwise `false`.\n4. Prefer explicit mentions for frameworks/doctrines; if absent, use `[\"None\"]` where the schema requires an array with no framework.\n\n---\n### `code_evidence` (the only section you must produce)\nFor **each** canonical key listed above:\n1. Provide `value` in the allowed type (string or array as per schema).\n2. Write a **`discussion`** paragraph (60–140 words) linking the concept to the paper’s question/problem, findings, limits, contribution, gap, and/or future direction.\n3. Provide **`support`** – one exact sentence from `paper_text`. **Allowed normalisation only:** fix hyphenated line-breaks and collapse whitespace; otherwise quote verbatim including citation markers.\n4. Add a **`critique`** paragraph (60–140 words) using a clear evaluative stance.\n5. If no clean sentence exists, set `support` = \"NA\" but still provide `value`, `discussion`, and `critique`.\n\n---\n### Hard rules\n• **Support** = one exact sentence (only the allowed normalisation).  \n• **Discussion** & **critique** = 60–140 words each.  \n• Do **not** invent or alter quotation markers.  \n• Do **not** add or remove code keys beyond the canonical list.  \n• Use the **canonical keys** exactly as property names in `code_evidence`.  \n• Output only the JSON object—no prose or Markdown.\n\nViolation of any rule invalidates the output.\n{payload_placeholder}",
  "text": "Paper text:\n\n{paper_text}\n\nReturn exactly one JSON object.",
     "json_schema": {
      "name": "coding_schema_v4b",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "code_evidence": {
            "type": "object",
            "additionalProperties": false,
            "required": [
              "framework_model",
              "contribution_type",
              "attribution_lens_focus",
              "research_question_purpose"
            ],
            "properties": {
              "framework_model": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "anyOf": [
                        { "enum": [
                          "Deterrence Theory",
                          "Decision-Making Attribution Framework",
                          "State Responsibility",
                          "Threshold Model",
                          "Due Diligence",
                          "Effective Control",
                          "Overall Control",
                          "Virtual Control",
                          "Countermeasures",
                          "Sliding scale approaches",
                          "Proportionality",
                          "Use of Force",
                          "Armed Attack",
                          "UN GGE Norms",
                          "UN OEWG Norms",
                          "Tallinn Manual",
                          "Sanctions/Export Controls",
                          "MITRE ATT&CK",
                          "Diamond Model",
                          "Cyber Kill Chain",
                          "None"
                        ] },
                        { "pattern": "^Other:.+" }
                      ]
                    }
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "contribution_type": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "string",
                    "anyOf": [
                      { "enum": [
                        "Theoretical",
                        "Empirical",
                        "Methodological",
                        "Conceptual",
                        "Practical",
                        "Survey/Review",
                        "Dataset",
                        "Policy Proposal/Guidance",
                        "Case Note/Commentary",
                        "Framework Proposal",
                        "None"
                      ] },
                      { "pattern": "^Other:.+" }
                    ]
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "attribution_lens_focus": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "string",
                    "anyOf": [
                      { "enum": [
                        "Strategic/Political",
                        "Legal/Doctrinal",
                        "Technical/Forensic",
                        "Intelligence/Tradecraft",
                        "Economic/Regulatory",
                        "Multi-dimensional",
                        "None"
                      ] },
                      { "pattern": "^Other:.+" }
                    ]
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              },
              "research_question_purpose": {
                "type": "object",
                "properties": {
                  "original_value": { "type": "string" },
                  "was_corrected": { "type": "boolean" },
                  "value": {
                    "type": "string",
                    "anyOf": [
                      { "enum": ["Exploratory","Descriptive","Explanatory","Normative","None"] },
                      { "pattern": "^Other:.+" }
                    ]
                  },
                  "discussion": { "type": "string" },
                  "support": { "type": "string" },
                  "critique": { "type": "string" }
                },
                "required": ["value","discussion","support","critique","original_value","was_corrected"],
                "additionalProperties": false
              }
            }
          }
        },
        "required": ["code_evidence"],
        "additionalProperties": false
      }
    }
  }
,
   "coding_keyword_consolidation": {
    "default_model": {
      "openai": "o4-mini-2025-04-16",
      "mistral": "mistral-7b-instruct"
    },
    "def_temperature": 0.1,
    "content": "System: You are a senior synthesis editor for thematic coding. You will receive multiple per-paper JSON analyses produced by the `coding_keyword` function for a single keyword. Your job is to MERGE them into one consolidated JSON object that conforms to the schema below. Output exactly one JSON object, nothing else.\n\n### Inputs supplied\n• `keyword` – the single term under analysis.\n• `analyses` – array of objects, each with: `item_key`, `title`, and `keyword_analysis` (with `theme`, `discussion`, `support`, `critique`).\n\n### Task · Consolidate per-paper analyses\nSynthesize across papers to produce ONE `keyword_analysis` object capturing the dominant theme and best evidence across the corpus:\n0. `theme` – a 2–5 word label reflecting the overarching role of the keyword across the papers.\n1. `discussion` – a 90–160 word paragraph that integrates the most salient arguments/findings/uses of the keyword across the set (avoid paper-by-paper summaries; write a single, coherent synthesis).\n2. `support` – choose ONE literal sentence copied verbatim from any paper-level `support` field that best illustrates the consolidated theme (do not modify wording or add ellipses).\n3. `critique` – a 90–160 word paragraph that critically reflects on limitations, disagreements, or gaps visible across the set (e.g., methodological fragility, legal translatability, source dependence).\n\n### Hard rules\n• Keep exactly the four fields inside `keyword_analysis`.\n• `support` must be exactly one verbatim sentence taken from the inputs.\n• Do not invent citations or content not present in inputs.\n• Output only the JSON object – no prose or Markdown.\n{payload_placeholder}",
    "text": "Consolidate the following per-paper analyses for the given keyword.\n\n{payload}\n\nReturn exactly one JSON object.",
    "json_schema": {
      "name": "keyword_coding_consolidation_v1",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "keyword_analysis": {
            "type": "object",
            "properties": {
              "theme":      { "type": "string" },
              "discussion": { "type": "string" },
              "support":    { "type": "string" },
              "critique":   { "type": "string" }
            },
            "required": ["theme", "discussion", "support", "critique"],
            "additionalProperties": false
          }
        },
        "required": ["keyword_analysis"],
        "additionalProperties": false
      }
    }
  },



  "coding_keyword_batch_html": {
    "default_model": { "openai": "o4-mini-2025-04-16", "mistral": "mistral-7b-instruct" },
    "def_temperature": 0.1,
    "content": "System: You are a thematic coding assistant.\nYou are given HTML evidence fragments (a batch) composed of <p>…</p> with anchors like <a href=\"KEY\" data-key=\"KEY\" data-bib=\"BIB\">BIB</a>.\nYour job is to write analytical paragraphs that ADVANCE the provided research question for THIS keyword.\n\nWrite ONLY <p>…</p> blocks.\nGuidelines:\n• Synthesize evidence into coherent analysis; do not list quotes.\n• Integrate consenting and dissenting arguments explicitly when present.\n• END EACH paragraph with one or more anchors, each EXACTLY:\n  <a key=\"KEY\" bib=\"BIB\" title=\"EXACT 1–2 sentence verbatim from the fragment\">(Surname, YYYY)</a>\n  – KEY and BIB must come from the given fragments only (use data-key/data-bib); do not invent.\n  – The visible text MUST be APA in-text derived from BIB (Surname, YYYY).\n• Every paragraph MUST include at least one anchor preserving verbatim text in the title attribute.\n{payload_placeholder}",
    "text": "Keyword: {keyword}\nResearch question: {research_question}\n\nHTML evidence batch:\n\n{batch_html}\n\nReturn ONLY <p>…</p> blocks."
  },
  "coding_keyword_consolidation_html": {
    "default_model": { "openai": "o4-mini-2025-04-16", "mistral": "mistral-7b-instruct" },
    "def_temperature": 0.1,
    "content": "System: Merge multiple batch-level HTML analyses for ONE keyword into a single coherent block answering the research question.\nOutput ONLY <p>…</p> blocks.\n\nRules:\n• Inputs come as: <!-- keyword: ... -->, <!-- research_question: ... -->, then multiple batches each containing <p>…</p> with anchors <a key=\"KEY\" bib=\"BIB\" title=\"…\">(Surname, YYYY)</a>.\n• Preserve anchors; at end of EACH paragraph include one or more anchors from the inputs.\n• Consolidate overlapping points, keep dissent/consent visible, avoid redundancy.\n{payload_placeholder}",
    "text": "Consolidate batch analyses into one keyword-level synthesis.\n\n{payload}\n\nReturn ONLY <p>…</p> blocks."
  }



,
 "paper_screener_abs": {
    "content": "System: You are a paper‑screener for a cyber‑conflict evidence map. For every candidate paper you receive the metadata and excerpts from some sections of the academic PDF. Your job is: (i) decide whether the paper should be Included, Maybe, or Excluded from the map.\n\n**Strict, state‑centric decision flow (high precision, with safety for recall):**\n1) **Domain test (state focus).** Title/abstract/sections must clearly concern **state or interstate cyber operations** (including **state‑directed or state‑endorsed information operations**) and analyse them in **law, policy, strategy, doctrine, or empirical conflict** terms. If the topic is cybercrime, privacy, commercial/civil cyber law, or general tech with no state‑conflict angle → **Exclude**.\n2) **Evidence test (incident, attribution, *or* state behavior or private companies related to states).** The excerpt must **either**:\n   • (a) discuss at least one concrete cyber operation/incident, state‑sponsored campaign, or interstate engagement; **or**\n   • (b) **clearly and substantively** apply/assess legal or policy doctrines **for state cyber operations** (e.g., due diligence, state responsibility, attribution, sovereignty, countermeasures, deterrence) **even if no single incident is named**. If neither (a) nor (b) is satisfied → **Exclude**.\n3) **Substantive focus threshold.** ≥50% of the excerpt must address **law/policy/strategy/doctrine or empirical analysis of cyber conflict**. If the primary contribution is methodology, tooling, simulation mechanics, game rules, or engineering details with minimal policy/legal content → **Exclude**.\n4) **Uncertainty handling (use MAYBE).** If signals are mixed but plausibly within scope, label **Maybe** (rare) and explain in **1–2 sentences** what evidence is missing (e.g., unclear state actor link; unclear whether the discussion is cyber‑conflict vs. general cybersecurity). Prefer **Maybe** over mistaken Include.\n\n🔹  **INCLUDED** (choose **one** label)\n    • \"cyber‑conflict law\" – International or domestic law **in the cyber domain**: IHL/LOAC, sovereignty, attribution, state responsibility, due diligence, countermeasures, sanctions, jurisdiction for state cyber ops, Tallinn‑style rules and their application.\n    • \"cyber‑conflict policy\" – National/alliance strategy, doctrine, deterrence, defence posture, operational concepts (e.g., defend forward), C2/ROE, or state (or state‑directed) information/influence operations in conflict settings.\n    • \"multidisciplinary cyber conflict\" – Empirical/theoretical studies of **state‑led or state‑sponsored** cyber campaigns, their geopolitical/economic effects, conflict datasets, event studies, or simulations tied to real or historically grounded interstate cyber operations.\n    • \"cyber‑conflict survey (no specific incident)\" – Broad but **substantive** legal/policy analyses **centrally about state cyber operations** (e.g., due diligence, state responsibility, attribution frameworks, deterrence doctrine) where no single case dominates but the focus is unmistakably cyber‑conflict.\n\n🔹  **EXCLUDE** (choose **one** label)\n    • \"purely technical\" – Engineering/CS papers (algorithms, ML models, protocols, detection methods, attack graphs, tooling, labs) without substantive policy/legal/strategic analysis.\n    • \"mil‑technical method\" – Military/intel‑oriented frameworks, simulations, wargames, ISR/EW signature models, or matrix games **without** policy/legal discussion or linkage to real state cyber incidents.\n    • \"cybercrime w/o state focus\" – Criminology, law‑enforcement practice, ransomware/fraud, privacy, surveillance or data‑protection topics lacking interstate or defence dimension.\n    • \"civil / commercial cyber‑law\" – Consumer contracts, targeting tests, e‑commerce jurisdiction, corporate/bankruptcy/IP/data‑protection matters not tied to state cyber ops.\n    • \"general PIL w/o cyber\" – Public‑international‑law surveys where cyber is absent or incidental (<25%) and no analysis of cyber operations is provided.\n    • \"non‑cyber legal survey\" – Broad legal/policy reviews with **no substantive cyber content** (contrast with Included: \"cyber‑conflict survey (no specific incident)\").\n    • \"metaphorical warfare\" – ‘Warfare’, ‘battle’, ‘adversary’ used as metaphors for business, trade, litigation, or markets; no cyber‑operations content.\n    • \"non‑English\" – Paper not in English (out of scope for the map).\n    • \"no cyber‑conflict content\" – Anything else not involving state‑level cyber operations, interstate effects, or state‑directed information operations.\n\n🔹  **MAYBE** – Use **only** when the excerpt plausibly targets state cyber conflict but lacks decisive evidence for steps (1)–(3). Provide a **1–2 sentence** explanation of what is missing. Examples: \"Unclear if ‘security policy’ refers to interstate cyber conflict or civilian cybersecurity\"; \"Mentions attribution but no indication of state actors\".\n\n**Worked examples (guide the decision):**\n• **Include – cyber‑conflict law:** \"State Responsibility in Cyberspace\" (analyses attribution and due diligence for state cyber ops; no single incident named). → \"cyber‑conflict law\" or \"cyber‑conflict survey (no specific incident)\".\n• **Include – policy:** \"Cyber deterrence strategies among NATO members\" (doctrine for interstate cyber conflict). → \"cyber‑conflict policy\".\n• **Exclude – general PIL:** \"Use of force in international law\" with a brief cyber mention. → \"general PIL w/o cyber\" or \"non‑cyber legal survey\".\n• **Exclude – civil law:** \"Targeting tests for consumer e‑contracts\". → \"civil / commercial cyber‑law\".\n• **Exclude – technical:** \"Neural IDS for malware\" with no policy/legal discussion. → \"purely technical\".\n• **Maybe:** \"National security policy and digital threats\" – abstract unclear if cyber conflict or general security. → \"Maybe\" with 1–2 sentence uncertainty.",
    "prompt": "Apply these rules and output exactly one JSON object:\n\n• If Excluded:\n```json\n{\"screening_status\":\"Excluded\",\"justification\":\"<one exclusion label>\"}\n```\n• If Included:\n```json\n{\"screening_status\":\"Included\",\"justification\":\"<one inclusion label>\"}\n```\n• If Maybe:\n```json\n{\"screening_status\":\"Maybe\",\"justification\":\"<1–2 sentence explanation>\"}\n```",
    "json_schema": {
      "name": "paper_screener_schema",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "screening_status": {
            "type": "string",
            "enum": [
              "Included",
              "Excluded",
              "Maybe"
            ]
          },
          "justification": {
            "type": "string",
            "description": "If screening_status = Included, use one of [\"cyber‑conflict law\", \"cyber‑conflict policy\", \"multidisciplinary cyber conflict\", \"cyber‑conflict survey (no specific incident)\"]. If screening_status = Excluded, use one of [\"purely technical\", \"mil‑technical method\", \"cybercrime w/o state focus\", \"civil / commercial cyber‑law\", \"general PIL w/o cyber\", \"non‑cyber legal survey\", \"metaphorical warfare\", \"non‑English\", \"no cyber‑conflict content\"]. If screening_status = Maybe, provide a 1–2 sentence explanation of what evidence is missing."
          }
        },
        "required": [
          "screening_status",
          "justification"
        ],
        "additionalProperties": false
      }
    }
  },
  "paper_screener_abs_policy": {
      "openai": "gpt-5",
      "mistral": "mistral-7b-instruct",

    "content": "System: You are a paper-screener for a mission-oriented public policy evidence map. You receive metadata and excerpts (title, abstract, selected PDF text). Decide one of: Included, Maybe, Excluded.\n\nScope rules (apply in order):\n1) Domain test - mission policy focus. Title/abstract/body must clearly address mission-oriented or challenge-led public policy in government (directional or transformative policy, grand challenges, moonshots). If the paper uses \"mission\" in other senses -> Exclude.\n   Out-of-scope meanings (label -> justification):\n     - Missions out of scope (military, religious, corporate, diplomatic, metaphorical) -> \"missions out of scope\".\n     - Non-mission digital transformation and AI (e-gov, AI adoption, or generic digital innovation with no mission framing) -> \"non-mission digital transformation & AI\".\n     - Generic public sector innovation (single service, single organisation, co-working etc. without mission framing) -> \"generic public sector innovation\".\n     - Peripheral administrative topics (HR/staffing, narrow admin coordination with no mission policy design) -> \"peripheral administrative topics\".\n     - Sectoral or non-government innovation contexts (university-only, science-industry collaboration, SDG effectiveness, energy/social justice policies without mission framing, generic innovation labs) -> \"sectoral or non-government innovation contexts\".\n     - Societal challenges without innovation policy focus (climate/health/SDGs but no mission-oriented innovation/public policy nexus) -> \"societal challenges without innovation policy focus\".\n     - General non-innovation topics -> \"general non-innovation topics\".\n     - Non-English -> \"non-English\".\n\n2) Evidence test - public policy nexus. The excerpt must either:\n   (a) substantively discuss at least one mission/challenge initiative in a government or public policy setting; or\n   (b) develop/assess concepts, frameworks, or governance for missions/mission-oriented innovation in the public sector.\n   If neither, Exclude with the appropriate label from step (1).\n\n3) Substantive focus threshold. At least 50% of the excerpt should address mission-oriented policy, governance, implementation, or evaluation. If the main contribution is unrelated management, generic digitalisation, or sectoral policy with no mission framing -> Exclude using the closest label from step (1).\n\n4) Uncertainty handling (Maybe). Use Maybe only when the text plausibly targets mission-oriented public policy but fails to clearly pass (1)-(3). Explain in 1-2 sentences what is missing (e.g., \"mentions grand challenges but no explicit mission framing or policy design\"). When mission framing is ambiguous policy-by-policy (\"Uncategorised\" cases), prefer Maybe with a short explanation.\n\nIncluded categories (choose exactly one when Included):\n- \"conceptual foundations of missions and challenges\" - conceptual/theoretical work on missions, challenge-led governance, directionality.\n- \"policy design and governance of missions\" - how missions are set, governed, coordinated; policy mixes and institutions.\n- \"mission implementation and management\" - delivery cases, co-design, operations in government contexts.\n- \"monitoring and evaluation of missions\" - frameworks or evidence on mission outcomes.\n- \"strategic or purpose-driven public policy\" - goal-driven or purpose-led policymaking explicitly framed as missions in the public sector.\n- \"organisational/leadership aspects of mission innovation\" - leadership, culture, roles adopting mission logic in public organisations.\n- \"non-governmental or sub-national mission initiatives\" - city/regional/philanthropic initiatives connected to public sector innovation.\n\nSupport lists (optional, provided by the user):\nIf you receive arrays included_title_support[] and excluded_title_support[] (exact titles previously screened), use them as soft evidence:\n- If an exact or near-exact title match (case-insensitive, punctuation ignored) appears in included_title_support[], and scope tests (1)-(3) are not contradicted, lean Included and pick the most fitting Included label.\n- If a match appears in excluded_title_support[], and scope tests are not contradicted, lean Excluded with the closest exclusion label.\n- Do not override clear text evidence. When issuing Maybe, you may mention that a support list suggests inclusion/exclusion, but keep the justification format rules below.\n\nWorked cues:\n- Include - conceptual: \"Directionality of transformative innovation policy\" -> \"conceptual foundations of missions and challenges\".\n- Include - governance: \"Designing mission-oriented policy mixes in Finland\" -> \"policy design and governance of missions\".\n- Include - implementation: \"Smart City Mission delivery in India\" -> \"mission implementation and management\".\n- Exclude - corporate mission statements -> \"missions out of scope\".\n- Exclude - AI adoption in government, no mission framing -> \"non-mission digital transformation & AI\".\n- Maybe - innovation labs for climate, mission framing unclear -> Maybe with a short explanation.\n\nAbstract generation rule:\nIf and only if screening_status = Included, also produce a synthetic abstract of ~500 words (±10%). It must be a single coherent paragraph in this exact order: (a) authors by name; 1) problem statement; 2) research question; 3) research objective; 4) methodology/epistemology/framework — specify approach (qualitative/quantitative/mixed), concrete methods (e.g., content analysis, interviews, case study), and any named frameworks/epistemic stance; 5) findings — link back to the problem, explain the argumentative logic (deductive/inductive/abductive), and identify the evidence types used (e.g., legal texts, public statements) and how they support the findings; 6) recommendations/future research only if explicitly indicated. No headings or bullet points; no invented citations. If screening_status != Included, set abstract to \"NA\".\n\nReturn only the JSON object defined in the prompt. No extra keys, no markdown, no comments.",
    "prompt": "Apply the rules and output exactly one JSON object.\\n\\nIf Excluded:\\n{\\\"screening_status\\\":\\\"Excluded\\\",\\\"justification\\\":\\\"<one exclusion label>\\\",\\\"abstract\\\":\\\"NA\\\"}\\n\\nIf Included:\\n{\\\"screening_status\\\":\\\"Included\\\",\\\"justification\\\":\\\"<one inclusion label>\\\",\\\"abstract\\\":\\\"<~500-word paragraph following the abstract rule>\\\"}\\n\\nIf Maybe:\\n{\\\"screening_status\\\":\\\"Maybe\\\",\\\"justification\\\":\\\"<1-2 sentence explanation of missing evidence or ambiguity>\\\",\\\"abstract\\\":\\\"NA\\\"}",
    "json_schema": {
      "name": "paper_screener_schema",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "screening_status": {
            "type": "string",
            "enum": [
              "Included",
              "Excluded",
              "Maybe"
            ]
          },
          "justification": {
            "type": "string",
            "description": "If screening_status = Included, use one of [\"conceptual foundations of missions and challenges\", \"policy design and governance of missions\", \"mission implementation and management\", \"monitoring and evaluation of missions\", \"strategic or purpose-driven public policy\", \"organisational/leadership aspects of mission innovation\", \"non-governmental or sub-national mission initiatives\"]. If screening_status = Excluded, use one of [\"missions out of scope\", \"non-mission digital transformation & AI\", \"generic public sector innovation\", \"peripheral administrative topics\", \"sectoral or non-government innovation contexts\", \"societal challenges without innovation policy focus\", \"general non-innovation topics\", \"non-English\"]. If screening_status = Maybe, provide a 1-2 sentence explanation of what evidence is missing."
          },
          "abstract": {
            "type": "string",
            "description": "If screening_status = Included, a single ~500-word paragraph following the specified order; otherwise \"NA\"."
          }
        },
        "required": [
          "screening_status",
          "justification",
          "abstract"
        ],
        "additionalProperties": false
      }
    }
  },

 "title_screening": {
    "default_model": {
      "openai": "o4-mini-2025-04-16",
      "mistral": "mistral-7b-instruct"
    },
    "def_temperature": 0.2,
    "content": "System: You are a bibliographic-screening assistant for a corpus on cyber conflict and cyber-attribution (international law, strategy, policy). For every record you receive the `item_key`, `title`, and any available `abstract`. Your tasks are:\n1. Decide whether the paper should be **INCLUDED**, **EXCLUDED**, or marked **MAYBE**.\n2. Provide a concise `justification` code (see lists below).\n\n— **INCLUDE** when BOTH conditions hold:\n  • The record is in English.\n  • Title **or** abstract mentions at least one strategic / policy / legal cyber-conflict keyword (e.g. “cyber operation”, “state responsibility”, “attribution”, “due diligence”, “use of force”, “cyber deterrence”, “armed attack”, “international law”, “collective attribution”, “proof”).\n\n— **EXCLUDE** when ANY of the following is true:\n  • Record is not in English.\n  • Focus is strictly technical or malware-oriented (keywords such as “malware”, “APT”, “forensic”, “detection”, “honeypot”, “machine learning”, “threat intelligence”, “ransomware”, etc.).\n  • Topic is cyber-crime, commercial security, education, or general cybersecurity without a state, policy, or legal angle.\n\n— **MAYBE** when the language is English but relevance is uncertain (e.g. mixed technical/policy content, ambiguous terminology). Supply a one- to two-sentence explanation.\n\nAllowed `justification` codes:\n  • **Include** → \"cyber law\", \"cyber policy\", \"multidisciplinary cyber conflict\".\n  • **Exclude** → \"Non-English\", \"Purely technical\".\n  • **Maybe** → free text (≤ 2 sentences).",
    "text": "Here are the records to screen:\n\n{records}\n\nEach record provides:\n  – `item_key`\n  – `title`\n  – `abstract` (may be empty)\n\nEvaluate each record using the criteria above. Typical **inclusion keywords** (non-exhaustive):\n  attribution, cyber operation, cyber attack, cyberspace, cyber deterrence, state responsibility, due diligence, use of force, armed attack, sovereignty, collective attribution, evidence, burden of proof, proxy, international law, jus ad bellum.\nTypical **exclusion keywords** signalling a purely technical focus: malware, apt, ransomware, forensic, detection, honeypot, machine learning, threat intelligence, taxonomy, algorithm, bayesian, bullying, education, insurance.\n\n***Return exactly one JSON object*** with a single field `results`, an array whose elements follow the schema below. Do not wrap the output in prose, markdown, or code fences.",
    "json_schema": {
      "name": "batch_schema",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "results": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "item_key": {
                  "type": "string",
                  "description": "Original Zotero item key."
                },
                "screening_status": {
                  "type": "string",
                  "enum": ["included", "Excluded", "Maybe"],
                  "description": "Decision label."
                },
                "justification": {
                  "type": "string",
                  "description": "Include → one of [\"cyber law\", \"cyber policy\", \"multidisciplinary cyber conflict\"]; Excluded → one of [\"Non-English\", \"Purely technical\"]; Maybe → 1–2 sentence explanation."
                }
              },
              "required": ["item_key", "screening_status", "justification"],
              "additionalProperties": false
            }
          }
        },
        "required": ["results"],
        "additionalProperties": false
      }
    }
  }


,  "paper_analysis_and_extraction": {
    "content": "System: You are a bibliographic-coding assistant. The abstract has already been extracted. Your task now is to code ONLY the structured keyword variables listed below, strictly from the provided text.\n• Use exactly one value per scalar field and a JSON array for list fields.\n• If the paper gives NO evidence for a field, write \"None\" for scalar fields and [] for arrays.\n• If you observe a valid value that is not in the enum, output it as \"Other:{value}\" (the schema permits this via patterns).\n• Prefer primary sources over secondary commentary when selecting evidence sources.\n\n**Keywords Object – required fields**\n1. theoretical_orientation – Realism | Liberalism | Constructivism | Critical | Doctrinal | Normative | Policy-analytic | None | Other:{orientation}\n2. ontology – Individual | Group/Non-state | Firm/Platform | Organisational | Dyadic | State | Transnational/Regime | Systemic | None | Other:{level}\n3. epistemology – Positivist | Constructivist | Critical | Doctrinal/Analytic | Normative | Pragmatist | None | Other:{stance}\n4. argumentation_logic – Deductive | Inductive | Abductive | Normative | None | Other:{logic}\n5. evidence_source_base – array (up to 5) drawn from: Interviews; Archival Documents; Public Statements; Surveys; Simulation Output; Legal Texts; Court Filings/Case Law; Diplomatic Notes; Sanctions Notices; UN GGE/OEWG Reports; National Strategies/Doctrines; Policy Documents; Technical data/Logs; Forensic Artifacts; Malware Reports; Threat Intelligence Reports; CVE/NVD; ICS-CERT/CISA Advisories; Incident Datasets; OSINT; Corporate Disclosures/SEC Filings; Other:{source}\n6. methods – array (up to 3) drawn from: Process Tracing; Content Analysis; Regression Analysis; Network Analysis; Case Study; Comparative Case Study; Game-theoretic Modeling; Agent-Based Simulation; Scenario Exercises/Simulation; Doctrinal Analysis; Comparative Legal Analysis; Case-law Analysis; Normative Analysis; QCA; fsQCA; csQCA; Interviews; Surveys; Discourse Analysis; Text-as-Data; Event Study; Time-Series/Panel; Difference-in-Differences; Instrumental Variables; Expert Elicitation; Other:{method}\n7. method_type – Qualitative | Quantitative | Mixed | Doctrinal | None | Other:{type}\n8. framework_model – array of named frameworks/doctrines used, from: Deterrence Theory; Decision-Making Attribution Framework; State Responsibility; Threshold Model; Due Diligence; Sovereignty; Attribution: Effective Control; Attribution: Overall Control; Attribution: Virtual Control; Countermeasures; Necessity; Proportionality; Use of Force; Armed Attack; UN GGE Norms; UN OEWG Norms; Budapest Convention; Tallinn Manual 1.0; Tallinn Manual 2.0; Sanctions/Export Controls; MITRE ATT&CK; Diamond Model; Cyber Kill Chain; OODA; PAF; None; Other:{framework}\n9. contribution_type – Theoretical | Empirical | Methodological | Conceptual | Practical | Survey/Review | Dataset | Policy Proposal/Guidance | Case Note/Commentary | Framework Proposal | None | Other:{type}\n10. attribution_lens_focus – Strategic/Political | Legal/Doctrinal | Technical/Forensic | Intelligence/Tradecraft | Economic/Regulatory | Multi-dimensional | None | Other:{lens}\n11. research_question_purpose – Exploratory | Descriptive | Explanatory | Normative | None\n\nSelection guidance:\n• evidence_source_base: choose the 1–5 most central sources to the argument, not just mentioned items.\n• methods: choose the 1–3 dominant techniques. If the paper is purely doctrinal, prefer Doctrinal Analysis (+ Comparative/Case-law if present).\n• framework_model: include all explicitly named doctrines/frameworks that structure the analysis. If none, use [\"None\"].\n• If ambiguity remains between closely related labels, pick the one most supported by wording in the text and avoid mixing IR and legal labels unless the paper explicitly spans both.\n",
    "prompt": "Return exactly one JSON block:\n\n```json\n{ \"keywords\": { … } }\n```\n\n• Do not output any other keys or commentary.\n• For array fields (evidence_source_base, methods, framework_model), select only the dominant entries (≤5 for evidence_source_base; ≤3 for methods; any necessary number for framework_model, or [\"None\"] if truly absent).\n• Use \"None\" only when there is zero basis in the text; otherwise use one of the enum values or \"Other:{value}\" for out-of-enum observations.",
    "json_schema": {
      "name": "keywords_schema",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "keywords": {
            "type": "object",
            "properties": {

              "theoretical_orientation": {
                "type": "string",
                "anyOf": [
                  { "enum": ["Realism", "Liberalism", "Constructivism", "Critical", "Doctrinal", "Normative", "Policy-analytic", "None"] },
                  { "pattern": "^Other:.+" }
                ]
              },
              "ontology": {
                "type": "string",
                "anyOf": [
                  { "enum": ["Individual", "Group/Non-state", "Firm/Platform", "Organisational", "Dyadic", "State", "Transnational/Regime", "Systemic", "None"] },
                  { "pattern": "^Other:.+" }
                ]
              },
              "epistemology": {
                "type": "string",
                "anyOf": [
                  { "enum": ["Positivist", "Constructivist", "Critical", "Doctrinal/Analytic", "Normative", "Pragmatist", "None"] },
                  { "pattern": "^Other:.+" }
                ]
              },
              "argumentation_logic": {
                "type": "string",
                "anyOf": [
                  { "enum": ["Deductive", "Inductive", "Abductive", "Normative", "None"] },
                  { "pattern": "^Other:.+" }
                ]
              },
              "evidence_source_base": {
                "type": "array",
                "description": "Primary evidence; choose up to five dominant sources.",
                "items": {
                  "type": "string",
                  "anyOf": [
                    { "enum": [
                      "Interviews",
                      "Archival Documents",
                      "Public Statements",
                      "Surveys",
                      "Simulation Output",
                      "Legal Texts",
                      "Court Filings/Case Law",
                      "Diplomatic Notes",
                      "Sanctions Notices",
                      "UN GGE/OEWG Reports",
                      "National Strategies/Doctrines",
                      "Policy Documents",
                      "Technical data/Logs",
                      "Forensic Artifacts",
                      "Malware Reports",
                      "Threat Intelligence Reports"

                    ]},
                    { "pattern": "^Other:.+" }
                  ]
                },
                "maxItems": 5
              },
              "methods": {
                "type": "array",
                "description": "Research methods used; choose up to three dominant techniques.",
                "items": {
                  "type": "string",
                  "anyOf": [
                    { "enum": [
                      "Content Analysis",
                      "Regression Analysis",
                      "Network Analysis",
                      "Case Study",
                      "Comparative Case Study",
                      "Game-theoretic Modeling",
                      "Agent-Based Simulation",
                      "Scenario Exercises/Simulation",
                      "Doctrinal Analysis",
                      "Comparative Legal Analysis",
                      "Case-law Analysis",
                      "Interviews",
                      "Surveys",
                      "Discourse Analysis"
                    ]},
                    { "pattern": "^Other:.+" }
                  ]
                },
                "maxItems": 3
              },
              "method_type": {
                "type": "string",
                "anyOf": [
                  { "enum": ["Qualitative", "Quantitative", "Mixed", "Doctrinal", "None"] },
                  { "pattern": "^Other:.+" }
                ]
              },
              "framework_model": {
                "type": "array",
                "description": "Named frameworks or doctrines explicitly relied upon.",
                "items": {
                  "type": "string",
                  "anyOf": [
                    { "enum": [
                      "Deterrence Theory",
                      "Decision-Making Attribution Framework",
                      "State Responsibility",
                      "Threshold Model",
                      "Due Diligence",
                      "Effective Control",
                      "Overall Control",
                      "Virtual Control",
                      "Countermeasures",
                      "Sliding scale approaches",
                      "Proportionality",
                      "Use of Force",
                      "Armed Attack",
                      "UN GGE Norms",
                      "UN OEWG Norms",
                      "Tallinn Manual",
                      "Sanctions/Export Controls",
                      "MITRE ATT&CK",
                      "Diamond Model",
                      "Cyber Kill Chain",
                      "None"
                    ]},
                    { "pattern": "^Other:.+" }
                  ]
                }
              },
              "contribution_type": {
                "type": "string",
                "anyOf": [
                  { "enum": [
                    "Theoretical",
                    "Empirical",
                    "Methodological",
                    "Conceptual",
                    "Practical",
                    "Survey/Review",
                    "Dataset",
                    "Policy Proposal/Guidance",
                    "Case Note/Commentary",
                    "Framework Proposal",
                    "None"
                  ]},
                  { "pattern": "^Other:.+" }
                ]
              },
              "attribution_lens_focus": {
                "type": "string",
                "anyOf": [
                  { "enum": [
                    "Strategic/Political",
                    "Legal/Doctrinal",
                    "Technical/Forensic",
                    "Intelligence/Tradecraft",
                    "Economic/Regulatory",
                    "Multi-dimensional",
                    "None"
                  ]},
                  { "pattern": "^Other:.+" }
                ]
              },
              "research_question_purpose": {
                "type": "string",
                "anyOf": [
                  { "enum": ["Exploratory", "Descriptive", "Explanatory", "Normative", "None"] },
                  { "pattern": "^Other:.+" }
                ],
                "description": "Purpose of the core research question."
              }
            },
            "required": [
              "affiliation",
              "theoretical_orientation",
              "ontology",
              "epistemology",
              "argumentation_logic",
              "evidence_source_base",
              "methods",
              "method_type",
              "framework_model",
              "contribution_type",
              "attribution_lens_focus",
              "research_question_purpose"
            ],
            "additionalProperties": false
          }
        },
        "required": ["keywords"],
        "additionalProperties": false
      }
    }
  },

  "doj_cyber_indictment_screening":{
  "prompt": "System: You are an expert legal and cybersecurity analyst. Your task is to analyze DOJ press release content to determine if it meets specific criteria for inclusion in a dataset focused on cyber-related indictments with clear links to foreign nation-state actors. Adhere strictly to the provided JSON schema for your output.\\n\\n**Inclusion Criteria:**\\n1.  **Nation-State Link:** The press release MUST be reporting an indictment  and the indictement MUST explicitly link the accused individuals or groups (e.g., APT groups) to one of the three foreign nation-state China, Russia or Iran. This link should be more than just nationality; it must strongly suggest state direction, sponsorship, or affiliation with state entities (military, intelligence services) for the *cyber activities*. Prioritize cases naming specific state-sponsored APT groups. Cases where individuals happen to be foreign nationals but are acting for purely personal financial gain (even if sophisticated cybercrime) should be excluded unless a state link for the cyber acts is explicit.\\n2.  **Cyber-Related Charges:** The primary charges or focus of the indictment must be cyber-related (e.g., computer intrusion/hacking, cyber espionage, theft of trade secrets via cyber means, DDoS attacks, malware development/deployment for state purposes, state-sponsored ransomware if explicitly linked).\\n\\n**Exclusion Criteria:**\\n1.  **Motivation/Actor Type:** exclude cases where the motivation is primarily financial cybercrime without a clear and explicit nation-state link for the *cyber actions*. Do not infer state sponsorship; it must be stated or very strongly implied by affiliation with known state entities (e.g., PLA, GRU, IRGC).\\n2.  **Target Focus:** exclude cyber attacks exclusively targeting private companies *UNLESS* the company itself is part of critical national infrastructure OR the press release explicitly states the company was targeted as part of a broader state-directed campaign against national interests.\\n3.  **Insufficient State Link:** If accused are merely described as 'from' a country or if the state link is tenuous, speculative, or not directly tied to the *cyber activities* described, exclude.\\n4.  **Non-Cyber Primary Focus:** If the 'cyber' aspect is minor or incidental to other primary charges, exclude.\\n\\n**Output Instructions:**\\n- If `screening_status` is \\\"Include\\\", you MUST provide values for `charges_identified`, `accused_country_affiliation`, `accused_entities_or_groups`, and `state_link_evidence`. `exclusion_reason` should be \\\"N/A\\\".\\n- If `screening_status` is \\\"exclude\\\", you MUST provide a value for `exclusion_reason`. The fields `charges_identified`, `accused_country_affiliation`, `accused_entities_or_groups`, and `state_link_evidence` should either be omitted or explicitly set to an empty array [] for array types and \\\"N/A\\\" or null for string types, as appropriate for the schema.\\n\\n**Content to Analyze:**\\nTitle: \\\"{title}\\\"\\nSnippet: \\\"{snippet}\\\"",
  "content": "Return ONLY a single JSON object that strictly conforms to the schema and the conditional output instructions based on 'screening_status'. Do not include any other explanatory text, acknowledgements, or markdown formatting before or after the JSON object.",
    "json_schema": {
      "name": "doj_cyber_indictment_screening_output",
      "strict": true,
       "description": "Extracts structured information about DOJ cyber indictments based on screening criteria. Provides minimal info for exclusions.",
      "schema": {
        "type": "object",
         "properties": {
          "screening_status": {
            "type": "string",
            "enum": ["include", "exclude"],
            "description": "Decision: 'Include' or 'exclude'. ALWAYS REQUIRED."
          },
          "exclusion_reason": {
            "type": "string",
            "description": "IF status is 'exclude', provide reason. IF status is 'Include', MUST be 'N/A'. ALWAYS REQUIRED."
          },
          "charges_identified": {
            "type": "array", "items": {"type": "string"},
            "description": "IF status is 'Include', list concise cyber charges. IF 'exclude', MUST be []. ALWAYS REQUIRED."
          },
          "accused_country_affiliation": {
            "type": "string",
            "description": "IF status is 'Include', provide primary nation-state link. IF 'exclude', MUST be 'N/A'. ALWAYS REQUIRED."
          },
          "accused_entities_or_groups": {
            "type": "array", "items": {"type": "string"},
            "description": "IF status is 'Include', list accused state-linked entities/groups. IF 'exclude', MUST be []. ALWAYS REQUIRED."
          },
          "state_link_evidence": {
            "type": "array", "items": {"type": "string"},
            "description": "IF status is 'Include', provide up to 3 quotes for state link. IF 'exclude', MUST be []. ALWAYS REQUIRED."
          }
        },
        "required": [
          "screening_status",
          "exclusion_reason",
          "charges_identified",
          "accused_country_affiliation",
          "accused_entities_or_groups",
          "state_link_evidence"
        ],
        "additionalProperties": false
      }
    }
},


  "citation_parsing_and_classification": {
    "text": "System: You are a bibliographic parser and classifier. Given an HTML paragraph, for each `<a href>` tag you must:\n  1. Extract and parse the `title` attribute into structured fields:\n     • `href` (string)\n     • `raw_text` (string)\n     • `authors` (array of strings)\n     • `date` (string)\n     • `title` (string)\n     • `publication` (string or null)\n     • `publisher` (string or null)\n     • `url` (string or null)\n     • `page` (integer or null)\n  2. If a single `title` lists multiple works by the same author, split them into separate entries (same `href`).\n  3. Assign exactly one category from {`bibliographic_reference`, `author_commentary`, `others`}:\n     – `bibliographic_reference`: full footnote/endnote style (author, title, venue, year).\n     – `author_commentary`: in-text commentary with no explicit citation tag.\n     – `others`: “ibid”, “supra”, bare URLs, dataset links, or ambiguous cases.\n  4. (Optional) Assign `rhetorical_function` from {`background`,`method`,`support`,`contrast`,`critique`}.\nReturn only a JSON object with key `citations` mapping to an array of citation objects.",
    "json_schema": {
      "name": "citation_parsing_and_classification_v4",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "citations": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "href":        { "type": "string" },
                "raw_text":    { "type": "string" },
                "authors": {
                  "type": "array",
                  "items": { "type": "string" }
                },
                "date":        { "type": "string" },
                "title":       { "type": "string" },
                "publication": { "type": ["string","null"] },
                "publisher":   { "type": ["string","null"] },
                "url":         { "type": ["string","null"] },
                "page":        { "type": ["integer","null"] },
                "category": {
                  "type": "string",
                  "enum": ["bibliographic_reference","author_commentary","others"]
                },
                "rhetorical_function": {
                  "type": ["string","null"],
                  "enum": ["background","method","support","contrast","critique",null]
                }
              },
              "required": [
                "href",
                "raw_text",
                "authors",
                "date",
                "title",
                "publication",
                "publisher",
                "url",
                "page",
                "category",
                "rhetorical_function"
              ],
              "additionalProperties": false
            }
          }
        },
        "required": ["citations"],
        "additionalProperties": false
      }
    },
    "content": "Return only a JSON object with key `citations` mapping to an array of citation objects, each conforming exactly to the schema above."
  }

,


  "comprehensive_classification": {
  "model": "o4-mini-2025-04-16",
  "temperature": 0.3,
  "text": "**Context:** You are classifying an academic paper on cyber conflict, international relations, political science, and law. Apply the following ten enhancements to every field: 1. Normalize labels (consistent casing, hyphens, no stray characters). 2. Controlled vocabulary (only choose from the predefined lists). 3. Single-value enforcement (each dimension must be exactly one string, except `evidence_source_base`). 4. Structured multi-values (only arrays for evidence types; all others single strings). 5. Canonical mapping (map long framework names to concise codes, e.g. ARSIWA/TM2.0). 6. Hierarchical tag logic (each field will become a Zotero sub-collection under its dimension). 7. Predefined tag list (use only terms from the controlled lists you know). 8. Schema validation (`additionalProperties=false`, strict field names). 9. Separate justification (store only in `justification`, novelty in `novelty`). 10. Versioning (`$schema` draft-07, schema name with version suffix). Tasks (choose exactly one for each unless noted): 1. Primary Domain 2. Methodology 3. Framework/Model 4. Research-Question Purpose 5. Theoretical Orientation 6. Level of Analysis 7. Argumentation Logic 8. Empirical Scope 9. Temporal Orientation 10. Evidence/Source Base (array) 11. Policy Engagement Intensity 12. Contribution Type 13. Attribution Lens Focus 14. Novelty Rating 15. Justification Title: {title} Abstract: {abstract} Return only a JSON object conforming exactly to the schema below.",
  "json_schema": {
    "name": "comprehensive_classify_output_v1",
    "strict": true,
    "schema": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "type": "object",
      "description": "15-field classification output for cyber conflict abstracts, with enforced normalization, controlled vocabularies, schema validation, and versioning.",
      "properties": {
        "primary_domain": {
          "type": "string",
          "enum": ["state-responsibility", "armed-attack/self-defence/use of force","due dilligence", "cyber-deterrence", "evidentiary standards", "policy responses", "cyber-crime", "non-state-actors/proxies"],
          "description": "One selected domain."
        },
        "methodology": {
          "type": "string",
          "enum": ["Case Study", "Survey/Interview", "Statistical/Archival Analysis", "Modeling/framework", "Simulation/Experimental", "Doctrinal Legal Analysis", "Mixed-Methods", "Other"],
          "description": "Primary research approach."
        },
      "framework_model": {
  "type": "string",
  "enum": [
    "TM2.0",
    "ARSIWA",
    "Deterrence Theory",
    "Q model",
    "Diamant model",
    "ZKPs",
    "state responsibility",
    "Other: [full name]"
  ],
  "description": "Choose exactly one code from the list of standardized frameworks (e.g., 'TM2.0', 'ARSIWA', 'Deterrence Theory', etc.). If using a novel framework, return 'Other: <full name>'."
},

        "research_question_purpose": {
          "type": "string",
          "enum": ["Exploratory", "Descriptive", "Explanatory", "Normative"],
          "description": "Purpose of the core research question."
        },
        "theoretical_orientation": {
          "type": "string",
          "anyOf": [
            { "enum": ["Realism", "Liberalism", "Constructivism", "Critical", "Doctrinal", "Normative", "Policy-analytic", "None"] },
            { "pattern": "^Other:.+" }
            ]
},
        "level_of_analysis": {
          "type": "string",
          "enum": ["Individual", "Sub-state", "State", "Dyadic", "Systemic", "Transnational"],
          "description": "Primary analytical tier."
        },
        "argumentation_logic": {
          "type": "string",
          "enum": ["Deductive", "Inductive"],
          "description": "Reasoning style."
        },
        "empirical_scope": {
          "type": "string",
          "enum": ["Single-case", "Small-N Comparative", "Large-N Statistical"],
          "description": "Empirical scope of the study."
        },
        "temporal_orientation": {
          "type": "string",
          "enum": ["Historical", "Contemporary", "Prospective"],
          "description": "Temporal focus of the analysis."
        },
        "evidence_source_base": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": ["Interviews", "Archival Documents", "Public Statements", "Surveys", "Simulation Output", "Legal Texts", "Other"]
          },
          "description": "Dominant evidence types (multi-valued)."
        },
        "policy_engagement_intensity": {
          "type": "string",
          "enum": ["None", "Implicit", "Explicit"],
          "description": "Degree of policy linkage."
        },
        "contribution_type": {
          "type": "string",
          "enum": ["Theoretical", "Empirical", "Methodological", "Conceptual", "Practical"],
          "description": "Nature of the main contribution."
        },
        "attribution_lens_focus": {
          "type": "string",
          "enum": ["Technical Forensics", "Strategic/Political", "Legal/Doctrinal", "Multi-dimensional"],
          "description": "Primary lens on attribution."
        },
        "novelty": {
          "type": "string",
          "enum": ["High", "Medium", "Low"],
          "description": "Assessment of novelty."
        },
        "justification": {
          "type": "string",
          "description": "Concise rationale for all selections."
        }
      },
      "required": [
        "primary_domain",
        "methodology",
        "framework_model",
        "research_question_purpose",
        "theoretical_orientation",
        "level_of_analysis",
        "argumentation_logic",
        "empirical_scope",
        "temporal_orientation",
        "evidence_source_base",
        "policy_engagement_intensity",
        "contribution_type",
        "attribution_lens_focus",
        "novelty",
        "justification"
      ],
      "additionalProperties": false
    }
  },
  "config": {
    "temperature": 0.2,
    "top_p": 1.0
  },
  "content": "Classify the provided Title and Abstract by extracting exactly one normalized term for each dimension (except the array for evidence_source_base), map frameworks to concise codes, enforce controlled vocabularies, validate strictly against the schema, and return only the JSON object."
}
,

  "classify_by_abs":{
    "model":"o4-mini-2025-04-16",
    "temperature": 0.3,
     "text": "\n**Context:** The overarching theme is **cyber conflict**, primarily focusing on interactions between states or major non-state actors.\n\n**Core Classification Question:** Does the paper substantively discuss **attribution** (the process, challenges, or implications of identifying the source of cyber operations) AND explicitly link this discussion to **policy responses, international relations, international law, state responsibility, deterrence strategies, norms development, or the application of jus ad bellum / jus in bello** in the cyber domain?\n\n**Input Context:** You will receive:\n1.  **Title:** [Title of the paper]\n2.  **Abstract:** [Abstract text of the paper]\n*   Evaluate the title and abstract against the **provided** Inclusion and Exclusion criteria.\n*   Determine the overall `classification` ('Highly Relevant', 'Partially Relevant', 'Not Relevant') and corresponding `relevance_score`.\n*   If 'Highly Relevant' or 'Partially Relevant', identify the specific aspects discussed within the `details` object. Populate the `law_aspects` and `policy_aspects` arrays with relevant tags from the suggested list (or similar specific terms if necessary). Use `other_focus` for aspects not covered or for the primary reason if 'Not Relevant'.\n*   The **connection** between attribution and the policy/legal/strategic dimension is crucial for a `Highly Relevant` classification.\n*   Provide a concise `justification` (max 50 words)",

            "json_schema": {
                "name": "classify_cyber_conflict_abstract_output",
                "strict": true,

  "schema": {
    "type": "object",
    "description": "Granular classification result for an academic abstract regarding cyber conflict, attribution, and policy/legal implications.",
    "properties": {
      "classification": {
        "type": "string",
        "description": "The primary classification based on relevance to the core topic and provided criteria.",
        "enum": ["Highly Relevant", "Partially Relevant", "Not Relevant"]
      },
      "relevance_score": {
        "type": "string",
        "description": "A score reflecting the classification level.",
        "enum": ["High", "Medium", "Low"]
      },
      "details": {
        "type": "object",
        "description": "Detailed breakdown of the paper's focus areas related to attribution and cyber conflict.",
        "properties": {
          "main_focus_summary": {
            "type": "string",
            "description": "A brief overall summary tag (e.g., 'Attribution & State Responsibility', 'Technical Attribution Focus', 'Irrelevant Focus')."
          },
          "law_aspects": {
            "type": "array",
            "description": "Specific international law aspects discussed in relation to attribution. Empty if not applicable. Suggested tags: 'Armed Conflict (Jus ad Bellum/Jus in Bello)', 'State Responsibility', 'Evidentiary Standards', 'Sovereignty/Non-Intervention', 'Due Diligence', 'Countermeasures', 'International Humanitarian Law (IHL)', 'Norms Development (Legal)'",
            "items": {
              "type": "string"
            }
          },
          "policy_aspects": {
            "type": "array",
            "description": "Specific policy or strategic aspects discussed in relation to attribution. Empty if not applicable. Suggested tags: 'Deterrence (General)', 'Deterrence by Punishment', 'Deterrence by Denial', 'Response Options (Sanctions, Diplomatic, Kinetic)', 'Naming and Shaming', 'Strategic Stability', 'Escalation Management', 'Norms Development (Policy)', 'Alliance Considerations', 'Intelligence Sharing'",
            "items": {
              "type": "string"
            }
          },
          "other_focus": {
            "type": "array",
            "description": "Other relevant focus areas, or the primary reason for 'Not Relevant' classification. Empty if covered adequately by Law/Policy. Suggested tags: 'Technical Attribution Methods/Challenges', 'Cybercrime (Non-State Focus)', 'Cyber Espionage (Standalone)', 'Theoretical/Game Theory Model', 'General Cyber Security', 'Domestic Law/Policy'",
            "items": {
              "type": "string"
            }
          }
        },
        "required": ["main_focus_summary", "law_aspects", "policy_aspects", "other_focus"],
        "additionalProperties": false
      },
      "justification": {
        "type": "string",
        "description": "A very brief explanation (max 50 words), justifying the classification and detailing why specific aspect tags were chosen or omitted, referencing the provided criteria and content."
      }
    },
    "required": ["classification", "relevance_score", "details", "justification"],
    "additionalProperties": false
  }

            },
            "config": {
                "temperature": 0.2,
                "top_p": 1.0
            },
            "content": "Classify the provided academic abstract based on its relevance to cyber conflict attribution and policy/law, following the specific inclusion/exclusion criteria given. Return the result as a JSON object with keys: classification (enum: 'Highly Relevant', 'Partially Relevant', 'Not Relevant'), relevance_score (enum: 'High', 'Medium', 'Low'), potential_subcategory (string), and justification (string)."

    },

  "evaluate_report": {
    "model": "o4-mini-2025-04-16",
    "temperature": 0.3,

    "text": "**Task Context**: You are grading the evidentiary rigor of a cyber-attribution report by applying the **6 C Evidence-Quality Framework** (Chain-of-Custody, Credibility, Corroboration, Coherence, Confidence & Uncertainty, Compliance).  \n\n**Scoring Scale (applies to every C)**  \n‣ 0 = Absent | 1 = Minimal | 2 = Weak/Partial | 3 = Moderate | 4 = Strong | 5 = Exemplary.  \n\n**Brief Rubric Extract**  \n• *Chain-of-Custody* – 0 (No provenance) … 5 (fully hashed, signed, timestamped chain).  \n• *Credibility* – 0 (Sole vendor claim) … 5 (joint/peer-reviewed by neutral bodies).  \n• *Corroboration* – 0 (single data point) … 5 (≥4 independent, validated streams).  \n• *Coherence* – 0 (unconnected facts) … 5 (alternative hypotheses tested).  \n• *Confidence & Uncertainty* – 0 (unqualified absolutes) … 5 (quantitative bounds + error bars).  \n• *Compliance* – 0 (no legal mapping) … 5 (full legal memo citing ICJ precedent).  \n\n**Output Instructions**  \n1.  Score each criterion 0-5 and give a 1- to 2-sentence justification citing concrete passages or features of the report.  \n2.  Compute `overall_score` as the arithmetic mean (one decimal).  \n\nReturn ONLY a JSON object that conforms to the schema below.",

    "json_schema": {
      "name": "six_c_evidence_scoring_output",
      "strict": true,
      "schema": {
        "type": "object",
        "description": "Per-criterion scores and justifications plus overall average.",
        "properties": {
          "chain_of_custody": {
            "type": "object",
            "properties": {
              "score": { "type": "integer", "minimum": 0, "maximum": 5 },
              "justification": { "type": "string" }
            },
            "required": ["score", "justification"],
            "additionalProperties": false
          },
          "credibility": {
            "type": "object",
            "properties": {
              "score": { "type": "integer", "minimum": 0, "maximum": 5 },
              "justification": { "type": "string" }
            },
            "required": ["score", "justification"],
            "additionalProperties": false
          },
          "corroboration": {
            "type": "object",
            "properties": {
              "score": { "type": "integer", "minimum": 0, "maximum": 5 },
              "justification": { "type": "string" }
            },
            "required": ["score", "justification"],
            "additionalProperties": false
          },
          "coherence": {
            "type": "object",
            "properties": {
              "score": { "type": "integer", "minimum": 0, "maximum": 5 },
              "justification": { "type": "string" }
            },
            "required": ["score", "justification"],
            "additionalProperties": false
          },
          "confidence_uncertainty": {
            "type": "object",
            "properties": {
              "score": { "type": "integer", "minimum": 0, "maximum": 5 },
              "justification": { "type": "string" }
            },
            "required": ["score", "justification"],
            "additionalProperties": false
          },
          "compliance": {
            "type": "object",
            "properties": {
              "score": { "type": "integer", "minimum": 0, "maximum": 5 },
              "justification": { "type": "string" }
            },
            "required": ["score", "justification"],
            "additionalProperties": false
          },
          "overall_score": {
            "type": "number",
            "description": "Arithmetic mean of the six scores, rounded to 1 decimal."
          }
        },
        "required": [
          "chain_of_custody",
          "credibility",
          "corroboration",
          "coherence",
          "confidence_uncertainty",
          "compliance",
          "overall_score"
        ],
        "additionalProperties": false
      }
    },

    "config": {
      "temperature": 0.2,
      "top_p": 1.0
    },

    "content": "Evaluate the following cyber-attribution report by filling all fields in the required JSON structure:\n\n<INSERT FULL REPORT TEXT OR URL HERE>\n"
  }
,


  "classify_vendor_reports": {
    "model": "o4-mini-2025-04-16",
    "temperature": 0.3,

  "text": "**Context:**\nWe are systematically reviewing vendor-published technical reports (e.g. Symantec, Palo Alto Networks, Mandiant, CrowdStrike, Microsoft) for **explicit state attribution** of cyber operations.  Only include reports that **unequivocally** tie a named operation or threat group to a specific nation-state sponsor (e.g. Russia, China, Iran, North Korea), including recognized APT designations (e.g. APT1, UNC3886) or other actors demonstrably under governmental control.\n\n**Inclusion Criteria:**\n1. **Definitive Attribution:**  Clear, unambiguous statement naming a country as responsible for the operation.\n2. **State-Linked Actor:**  Reference to a group or campaign known or presented as operating at the direction of, or in close coordination with, a government.\n\n**Exclusion Criteria:**\n- No direct country attribution (e.g. “cybercriminals,” “unknown threat actors”).\n- Attribution framed purely in financial or commoditized crime terms (e.g. banking Trojans, ransomware for profit).\n- Marketing collateral or high-level press releases lacking forensic or intelligence justification of state sponsorship.\n\n**Task:**\nGiven the first and last pages of a report, output a JSON object with:\n- `classification`: “include” or “exclude”\n- `keywords`: up to 8 terms (e.g. country names, APT identifiers, “state-sponsored”)\n- `justification`: concise rationale (≤50 words) referencing the exact attribution language used.",

    "json_schema": {
      "name": "classify_vendor_report_output",
      "strict": true,
      "schema": {
        "type": "object",
        "description": "Screening result for vendor attribution reports.",
        "properties": {
          "classification": {
            "type": "string",
            "enum": ["Include", "exclude"],
            "description": "Decision based on explicit country attribution."
          },
          "keywords": {
            "type": "array",
            "description": "Up to 5 top keywords (country names or other attribution-relevant terms).",
            "items": {
              "type": "string"
            }
          },
          "justification": {
            "type": "string",
            "description": "Concise justification (≤50 words) for the decision."
          }
        },
        "required": ["classification", "keywords", "justification"],
        "additionalProperties": false
      }
    },
    "config": {
      "temperature": 0.2,
      "top_p": 1.0
    },
    "content": "Classify the provided vendor report metadata against the above criteria. Return a JSON object with keys: `classification` ('Include' or 'exclude'), `keywords` (array of up to 8 relevant keywords including country names), and `justification` (≤50 words)."
  }
,



  "keywords_and_topic_sentence":{
  "text": "**Role:** You are an expert academic analyst specializing in text summarization and structured information extraction.\n\n**Input:** You will receive a single paragraph from an academic text.\n\n**Task:** Your objective is to meticulously analyze the provided academic paragraph and extract key information, structuring it precisely according to the instructions below. The output must be a valid JSON object.\n\n**Instructions:**\n\n1.  **Extract Topic Sentence:** Identify and extract the single sentence that best represents the main idea or central argument of the paragraph. This should be concise and capture the paragraph's essence. Assign this sentence to the `topic_sentence` key in the output JSON.\n2.  **Extract Keywords & Key Phrases:** Identify and categorize relevant keywords and key phrases based on the following criteria:\n    *   **Topics:** Identify the core subjects, themes, or main ideas discussed in the paragraph. Extract 1 to 5 concise keywords or key phrases representing these concepts. Focus on terms that summarize *what* the paragraph is about. Assign these as a list of strings to the `topics` key within the `keywords` object.\n    *   **Entities:** Identify specific named entities mentioned. This includes, but is not limited to: names of people (e.g., authors cited), organizations, companies, specific laws, regulations, geographical locations, or international bodies explicitly named in the text. Assign these as a list of strings to the `entities` key within the `keywords` object. If no specific entities are mentioned, use an empty list `[]`.\n    *   **Academic Features:** Identify specific academic or methodological constructs mentioned. This includes frameworks, theories, models, methodologies (e.g., \"qualitative analysis\", \"regression model\", \"case study approach\"), established principles, specific experimental techniques, or unique approaches discussed. Assign these as a list of strings to the `academic_features` key within the `keywords` object. If no specific academic features are mentioned, use an empty list `[]`.\n3.  **Specificity Constraint:** Ensure all extracted keywords and phrases are specific to the content of the provided paragraph. Avoid overly generic terms (e.g., 'study', 'research', 'data', 'analysis' unless part of a specific methodology like 'qualitative data analysis') and common stop words (e.g., 'and', 'the', 'of'). Focus primarily on significant nouns and noun phrases.\n4.  **Output Format:** Structure the entire output as a single, valid JSON object. The top level should contain the `topic_sentence` key (string value) and a `keywords` key (object value). The `keywords` object must contain three keys: `topics`, `entities`, and `academic_features`, each holding a list of strings as its value.\n\n**Academic Paragraph to Analyze:**",
  "json_schema": {
    "name": "keywords_and_topic_sentence",
    "strict": true,
    "schema": {
      "type": "object",
      "description": "An object that contains the topic sentence and categorizes extracted keywords into topics, entities, and academic features.",
      "properties": {
        "topic_sentence": {
          "type": "string",
          "description": "The extracted topic sentence of the paragraph, representing the main idea."
        },
        "keywords": {
          "type": "object",
          "description": "The main heading for extracted keywords, containing nested categories.",
          "properties": {
            "topics": {
              "type": "array",
              "description": "A list of keywords or key phrases that summarize the main ideas and arguments of the paragraph.",
              "items": {
                "type": "string",
                "description": "A single keyword or a phrase (bigram or trigram) representing a key topic."
              }
            },
            "entities": {
              "type": "array",
              "description": "A list of specific entities mentioned in the paragraph, such as authors, organizations, companies, or international bodies. Return an empty list if no keyword is found.",
              "items": {
                "type": "string",
                "description": "An entity name such as an author, organization, company, or international body."
              }
            },
            "academic_features": {
              "type": "array",
              "description": "A list of academic features such as frameworks, methodologies, theoretical models, or approaches. Return an empty list if no keyword is found.",
              "items": {
                "type": "string",
                "description": "A keyword or phrase representing an academic concept or feature (e.g., framework, method)."
              }
            }
          },
          "required": ["topics", "entities", "academic_features"],
          "additionalProperties": false
        }
      },
      "required": ["topic_sentence", "keywords"],
      "additionalProperties": false
    }
  },
        "config": {
      "temperature": 0.2,
      "top_p": 1
    },

  "content": "Your task is to extract the topic sentence and categorize keywords from the paragraph into **topics**, **entities**, and **academic features**. Return the results in a JSON format with a 'topic_sentence' and a 'keywords' object containing nested categories (topics, entities, academic features)."

}
,

  "prompt": "Task Overview:\n\nConvert the provided academic text into properly formatted HTML. The output must be encapsulated within a single <div> tag without including <html>, <head>, or <body> tags. Ensure that the original text remains unaltered, applying only the necessary HTML tags to structure the document effectively.\n\nInstructions:\n\nPreservation of Original Text:\n\nDo Not Modify: Maintain the original wording, punctuation, and formatting of the text. Only add HTML tags as needed for structuring.\nOutput Structure:\n\nSingle <div> Container: All HTML content should be nested within one <div> element.\nexclude Document-Level Tags: Do not include <html>, <head>, or <body> tags in the output.\nSection Identification and Tagging:\n\nHeadings (<h1>, <h2>, etc.):\nDetect section titles based on font styles (bold, italics), font sizes, spacing, numbering (e.g., \"1.\", \"2.1\"), bullet points, capitalization, and formatting consistency.\nAssign appropriate heading tags (<h1> for main sections, <h2>, <h3>, etc., for subsections) reflecting the document hierarchy.\nParagraph Identification and Tagging:\n\nParagraphs (<p>):\nIdentify paragraphs using line breaks, indentation, sentence endings, thematic breaks, and whitespace patterns.\nEnclose each paragraph within <p> tags, ensuring no nested <p> tags and proper closure.\nIn-text Citations:\n\nCitation Detection:\nUtilize regular expressions to identify in-text citations following patterns such as \"Smith.2020\", \"Doe;15\", or \"et al.,2019\".\nHTML Tagging:\nWrap citation numbers within <sup> tags and embed them within <a> tags linking to corresponding footnotes or references.\nExample: ...text<sup><a href=\"#reference1\">1</a></sup>...\nEnsure the href attribute matches the id of the corresponding footnote.\nFootnotes:\n\nFootnote Detection:\nIdentify footnotes typically located at the document's end or page bottom, following numbering patterns like \"1. Text\" or \"1 Text\".\nHTML Tagging:\nList footnotes within an ordered list <ol>, with each footnote enclosed in an <li> tag.\nAssign an id to each <li> corresponding to citation links (e.g., id=\"reference1\").\nExample:\nhtml\nCopy code\n<ol>\n    <li id=\"reference1\">Footnote content here.</li>\n    <!-- Additional footnotes -->\n</ol>\nEnsure numbering consistency between citations and footnotes.\nFinal HTML Output:\n\nCohesive Structure: Combine all elements within the single <div>, maintaining the original document's hierarchy and formatting.\nValidation: Ensure the HTML is free from syntax errors and that all tags are properly nested and closed.\nAdvanced Processing Techniques:\n\nChain-of-Thought Reasoning:\nImplement a step-by-step approach to accurately identify and tag sections, paragraphs, citations, and footnotes.\nVerify each element's correct placement and association within the HTML structure.\nConsistency and Accessibility:\nMaintain consistent use of HTML tags throughout the document.\nUtilize semantic HTML to enhance accessibility, such as proper heading levels.\nEncoding and Special Characters:\nHandle special characters appropriately to prevent HTML rendering issues or injection vulnerabilities.\nExample Structure:\n\nhtml\nCopy code\n<div>\n    <h1>Main Section Title</h1>\n    <p>First paragraph of the section with an in-text citation<sup><a href=\"#reference1\">1</a></sup>.</p>\n    <h2>Subsection Title</h2>\n    <p>Content of the subsection.</p>\n    <!-- More content -->\n    <ol>\n        <li id=\"reference1\">Footnote or reference corresponding to citation 1.</li>\n        <!-- More footnotes -->\n    </ol>\n</div>\nAdditional Considerations:\n\nNo Content Alteration: Ensure that the text content remains exactly as provided, without any unintended modifications.\nEfficiency: Optimize the conversion process to handle large documents effectively.\nTesting: After conversion, review the HTML output to verify the accuracy of tags and links.\nProvided Text for Conversion:",

  "TOC": {
    "text": "Your task is to extract the table of contents from this text, excluding any page numbers, and organize it hierarchically in a list with main heading titles and their corresponding subheadings. They are legal from ICJ. so probably with numbered headings 1. 2. or in roman I II and subsections A. B. etc. if no clear TOC is found, return None",
    "json_schema": {
      "name": "TOC_task",
      "strict": true,
      "schema": {
        "type": "object",
        "description": "An object containing the table of contents as a list of main headings and their subheadings.",
        "properties": {
          "toc": {
            "type": "array",
            "description": "List of main headings with their subheadings.",
            "items": {
              "type": "object",
              "properties": {
                "title": {
                  "type": "string",
                  "description": "The title of the main heading."
                },
                "subheadings": {
                  "type": "array",
                  "description": "List of subheadings under the main heading.",
                  "items": {
                    "type": "string",
                    "description": "A subheading under the main heading."
                  }
                }
              },
              "required": ["title", "subheadings"],
              "additionalProperties": false
            }
          }
        },
        "required": ["toc"],
        "additionalProperties": false
      }
    },
    "config": {
      "temperature": 0.2,
      "top_p": 1
    },
    "content": "You are tasked with extracting the table of contents from the provided text. Ensure that the output excludes any page numbers and accurately reflects the hierarchical structure of main headings and their subheadings. The output should be a JSON object containing a 'toc' property, which is an array where each element represents a main heading and includes a list of its subheadings."
  },

  "topic_sentence": {
    "text": "In the context of ICJ judgments, your task is to extract the topic sentence of the paragraph you are receiving stemmed from judge decisions. As a legal expert, analyse the paragraph and summarize in one declarative statement evoking the main idea of the paragraph in one single affirmative sentence.",
    "json_schema": {
      "name": "topic_sentence_task",
      "strict": true,
      "schema": {
        "type": "object",
        "description": "An object containing a topic sentence.",
        "properties": {
          "result": {
            "type": "string",
            "description": "The extracted topic sentence of the paragraph."
          }
        },
        "required": ["result"],
        "additionalProperties": false
      }
    },
    "config": {
      "temperature": 0.1,
      "top_p": 1
    },
    "content": "You are tasked with extracting the topic sentence of a paragraph. The output should be a JSON object containing a 'result' property, which is a string with the topic sentence."
  }

,
  "paraphrasing":{
  "text": "Your task is to paraphrase text while preserving the core idea and maintaining the exact reference. However, there are specific words that are prohibited. Avoid using the following words: ['play','challenge','enhance',',explore','robust','advent','intricacies', 'complexities', 'nuance', 'sophisticated', 'multifaceted', 'complicated', 'intricate', 'complex', 'nuanced', 'sophistication', 'comprehensive', 'dynamic', 'innovative', 'advanced', 'challenging', 'revolutionary', 'cutting-edge', 'pioneering', 'state-of-the-art', 'groundbreaking', 'meticulous', 'rigorous', 'exhaustive', 'in-depth', 'thorough', 'detailed', 'elaborate', 'extensive', 'delve', 'realm', 'notably', 'arguably', 'pivotal', 'vital', 'moreover', 'navigate', 'embark', 'explore', 'remarkable', 'in conclusion', 'it is important to note', 'in this digital world', 'interplay', 'complexity']. Maintain clear, concise language without these terms, ensuring the original message and reference are fully retained.",
  "json_schema": {
    "name": "paraphrase_task",
    "strict": true,
    "schema": {
      "type": "object",
      "description": "This schema is designed to handle paraphrasing tasks while conserving the content idea and keeping exact references intact, without the use of specific prohibited words.",
      "properties": {
        "paraphrased_text": {
          "type": "string",
          "description": "The text that has been paraphrased, conserving the original content idea while avoiding the prohibited words."
        },
        "reference": {
          "type": "string",
          "description": "The exact reference that must be retained during the paraphrasing process."
        }
      },
      "required": ["paraphrased_text", "reference"],
      "additionalProperties": false
    }
  },
  "config": {
    "temperature": 0.2,
    "top_p": 1
  },
  "content": "You are tasked with paraphrasing the provided text while maintaining the original meaning and retaining the exact reference format. Ensure that none of the prohibited words are used. The paraphrased text should still reflect the core idea and must include the original reference."
}
,
  "dynamic_categorization": {
    "text": "Based on a dynamic list of keywords, your task is to organize these keywords into relevant categories and subcategories. The categorization process should group related keywords into context-driven categories with each category containing between 3 to 5 subcategories. Ensure that all provided keywords are assigned to appropriate subcategories under their respective main categories based on content and topic similarity. The response should include a hierarchical structure of categories, subcategories, and associated keywords.",
    "json_schema": {
      "name": "category_generator_v1",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "categories": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "category_name": {
                  "type": "string",
                  "description": "A title summarizing the main category of related keywords."
                },
                "subcategories": {
                  "type": "array",
                  "description": "Subcategories under the main category.",
                  "items": {
                    "type": "object",
                    "properties": {
                      "subcategory_name": {
                        "type": "string",
                        "description": "A title summarizing the subcategory of related keywords."
                      },
                      "keywords": {
                        "type": "array",
                        "items": {
                          "type": "string",
                          "description": "List of keywords grouped under this subcategory."
                        },
                        "description": "Keywords associated with this subcategory."
                      }
                    },
                    "required": [
                      "subcategory_name",
                      "keywords"
                    ],
                    "additionalProperties": false
                  }
                }
              },
              "required": [
                "category_name",
                "subcategories"
              ],
              "additionalProperties": false
            },
            "description": "A hierarchical structure of categories with associated subcategories and keywords."
          }
        },
        "required": [
          "categories"
        ],
        "additionalProperties": false
      }
    },
    "config": {
      "temperature": 0,
      "top_p": 1,
      "seed": 34
    }
  },
  "theme_identification": {
        "text": "Identify overarching themes based on the provided keywords by grouping related keywords together.",
        "json_schema": {
            "name": "theme_identification_v1",
            "strict": true,
            "schema": {
                "type": "object",
                "properties": {
                    "themes": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "theme_name": {
                                    "type": "string",
                                    "description": "The name of the identified theme."
                                },
                                "keywords": {
                                    "type": "array",
                                    "items": {
                                        "type": "string",
                                        "description": "A keyword associated with this theme."
                                    },
                                    "description": "List of keywords under this theme."
                                }
                            },
                            "required": ["theme_name", "keywords"],
                            "additionalProperties": false
                        },
                        "description": "List of identified themes with their associated keywords."
                    }
                },
                "required": ["themes"],
                "additionalProperties": false
            }
        },
        "config": {
            "max_tokens": 1000,
            "temperature": 0.4,
            "top_p": 1,
            "seed": 42
        },
        "content": "You are a theme identifier. Given a list of keywords, group related keywords together to identify overarching themes."
    },
   "visualization_configuration": {
        "text": "Prepare configurations for generating various visualizations like bar charts for top keywords, pie charts for category distribution, and bar charts for theme distribution.",
        "json_schema": {
            "name": "visualization_configuration_v1",
            "strict": true,
            "schema": {
                "type": "object",
                "properties": {
                    "visualizations": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "type": {
                                    "type": "string",
                                    "enum": ["bar_chart", "pie_chart"],
                                    "description": "Type of visualization."
                                },
                                "title": {
                                    "type": "string",
                                    "description": "Title of the visualization."
                                },
                                "data_source": {
                                    "type": "string",
                                    "description": "Description of the data used for the visualization."
                                },
                                "parameters": {
                                    "type": "object",
                                    "properties": {
                                        "x_axis": {
                                            "type": "string",
                                            "description": "Data field for the x-axis."
                                        },
                                        "y_axis": {
                                            "type": "string",
                                            "description": "Data field for the y-axis."
                                        },
                                        "labels": {
                                            "type": "array",
                                            "items": {
                                                "type": "string"
                                            },
                                            "description": "Labels for the visualization."
                                        },
                                        "colors": {
                                            "type": "string",
                                            "description": "Color scheme for the visualization."
                                        }
                                    },
                                    "required": ["x_axis", "y_axis", "labels", "colors"],
                                    "additionalProperties": false
                                }
                            },
                            "required": ["type", "title", "data_source", "parameters"],
                            "additionalProperties": false
                        },
                        "description": "List of visualization configurations."
                    }
                },
                "required": ["visualizations"],
                "additionalProperties": false
            }
        },
        "config": {
            "max_tokens": 800,
            "temperature": 0.3,
            "top_p": 1,
            "seed": 42
        },
        "content": "You are a visualization configurator. Given analysis results, prepare configurations for generating various visualizations such as bar charts and pie charts."
    },
 "getting_keywords": {
    "text": "You will receive an academic paragraph along with its context. Your task is to extract 1 to 5 keywords or key phrases (bigrams) that best represent the main ideas of the paragraph, categorizing them into **topics**, **entities**, and **academic features**. Instructions: 1. **Summarize key arguments and main ideas**: Focus on extracting keywords that encapsulate the core arguments or concepts of the paragraph and group them under 'topics'. 2. **Include specific entities**: Identify and extract names of authors, organizations, companies, or international bodies, and group them under 'entities'. 3. **Highlight academic elements**: Extract terms related to academic features such as frameworks, methodologies, theoretical models, and key approaches, and group them under 'academic features'. 4. **Limit to 1-5 keywords**: Provide between 1 and 5 relevant keywords or key phrases, including a mix of single keywords and phrases (bigrams or trigrams). 5. **Avoid generic terms**: exclude common stopwords and overly generic terms (e.g., 'and', 'the', 'research'), they should very specific to the paragraph text or paragraph title, not the section title.\nnote:make sure to ouput no truncated and valid json format ```json",
    "json_schema": {
      "name": "keywords_extraction_v2",
      "strict": true,
      "schema": {
        "type": "object",
        "description": "This schema categorizes extracted keywords into topics, entities, and academic features.",
        "properties": {
          "keywords": {
            "type": "object",
            "description": "The main heading for extracted keywords, containing nested categories.",
            "properties": {
              "topics": {
                "type": "array",
                "description": "A list of keywords or key phrases that summarize the main ideas and arguments of the paragraph.",
                "items": {
                  "type": "string",
                  "description": "A single keyword or a phrase (bigram or trigram) representing a key topic."
                }
              },
              "entities": {
                "type": "array",
                "description": "A list of specific entities mentioned in the paragraph, such as authors, organizations, companies, or international bodies. Return an empty list if no keyword is found",
                "items": {
                  "type": "string",
                  "description": "An entity name such as an author, organization, company, or international body."
                }
              },
              "academic_features": {
                "type": "array",
                "description": "A list of academic features such as frameworks, methodologies, theoretical models, or approaches.Return an empty list if no keyword is found",
                "items": {
                  "type": "string",
                  "description": "A keyword or phrase representing an academic concept or feature (e.g., framework, method)."
                }
              }
            },
            "required": ["topics", "entities", "academic_features"],
            "additionalProperties": false
          }
        },
        "required": ["keywords"],
        "additionalProperties": false
      }
    },
    "config": {
      "max_tokens": 4096,
      "temperature": 0.3,
      "top_p": 1
    },
    "content": "Your task is to categorize the keywords extracted from the paragraph into **topics** (core ideas and arguments), **entities** (authors, organizations, etc.), and **academic features** (frameworks, methodologies, etc.). Output the results in JSON format, using 'keywords' as the main heading with nested categories.\nnote:make sure to ouput no truncated and valid json format ```json"
  }
,

  "writing_sections": {
    "text": "You will receive a dataset with main title along with its headings and subheadings. Each subheading includes a paragraph_title that summarizes raw quotes, the raw quotes themselves with academic references, a paragraph_id, and a paragraph count. Your are a PhD researcher and your objective is to generate a comprehensive thematic section review for each heading using only the provided references. **Introduction**: Create an insightful introduction using an `<h2>` tag. For smaller sections, include up to 2 paragraphs; for larger sections, include up to 5 paragraphs. The introduction should provide background and context to help understand the subsequent content being preceded by the h1 section title. - **Body Text**: Develop the main content where all raw quotes are analyzed and assessed to form a cohesive narrative around the theme. go subsection by subsection gathering the raw quotes and writing the academic section. Each analysis should include in-text citations in the format `<ref id=paragraph_id>(author, year, page)</ref>`. Ensure that all raw quotes are analysed and provide a <h2>Unused references</h2> section at the end of the body_text if paragraph are not relevant and unused.Use appropriate HTML heading levels (`<h2>`, `<h3>`, `<h4>`, `<h5>`) to reflect the content hierarchy. - **Conclusion**: Summarize the key findings and discuss the implications and other relevant aspects in an academic tone using an `<h2>` tag. Ensure that the output is a well-organized JSON object with a single key named 'section', containing `introduction`, `body_text`, and `conclusion`, all formatted in HTML. The JSON must be valid, not truncated. Take your time to ensure thoroughness and accuracy. Do not return subsections with only one paragraph,as the idea is to make a thematic review whose arguments are supported by many authors",

    "json_schema": {
      "name": "writing_sections",
      "strict": true,
      "schema": {
        "type": "object",
        "description": "This schema structures a comprehensive thematic section review with a single 'section' key containing introduction, body_text, and conclusion in HTML format.",
        "properties": {
          "section": {
            "type": "object",
            "description": "A structured section containing introduction, body_text, and conclusion, all formatted in HTML.",
            "properties": {
              "introduction": {
                "type": "string",
                "description": "The introduction section providing insightful analysis and background/context. Use HTML formatting with an <h2>Introduction</h2> tag and up to 2 paragraphs for small sections or up to 5 paragraphs for large sections. The introduction is preceeded by the h1 section title."
              },
              "body_text": {
                "type": "array",
                "description": "The main body of text containing the analysis of quotes in HTML format with appropriate headings and subheadings (h2, h3, h4, h5). Each item should include in-text citations enclosed by <ref> tags, for example <ref id=paragraph_id>(author, year, page)</ref>. Ensure all references from the provided dataset analysed, and if paragraphs are not relevant and not used, provide a list of them in form of endnote <h2>Unused References</h2><li id=paragraph_id>(author,year, page)</li>",
                "items": {
                  "type": "string",
                  "description": "A section of the body text in HTML format, including headings, subheadings, and in-text citations with the format (author, year, page) enclosed by <ref id=paragraph_id> tags."
                }
              },
              "conclusion": {
                "type": "string",
                "description": "The conclusion section summarizing key findings and implications, formatted in HTML with an <h2> tag."
              }
            },
            "required": ["introduction", "body_text", "conclusion"],
            "additionalProperties": false
          }
        },
        "required": ["section"],
        "additionalProperties": false
      }
    },

    "config": {
      "temperature": 0.2,
      "top_p": 1
    },

    "content": "You will write a section based on the given heading levels and paragraph content. Analyze the paragraphs critically, discuss the authors' ideas, and form a coherent narrative that connects with the theme. Transition smoothly between paragraphs and provide insight into the theme using all the references provided.The output should be in JSON format with a single key named 'section', which includes `introduction`, `body_text`, and `conclusion`—all in HTML format with appropriate tags for headings, paragraphs, and `<ref>` tags for citations. Ensure the JSON is valid, not truncated, and that all paragraphs are analyzed and referenced with `<ref>` tags."
  },

"grouping_sections_one_theme": {
  "text": "You will receive a list of section titles. Your task is to filter these titles based on the provided theme and organize them into a hierarchical outline under that theme. Instructions: 1. **Filter Based on Theme**: Analyze all the section titles and include only those that are relevant to the provided theme. 2. **Create Specific H1 Headings**: For each relevant section title, create a concise and specific H1 heading. Focus on capturing key concepts and aspects related to the theme without using predefined phrases. 3. **Ensure Database-Friendly Formatting**: H1 headings should be formatted to be database-friendly by avoiding unnecessary words, stop words, or filler language. Use consistent formatting (e.g., title case) and avoid special characters or punctuation that might interfere with database indexing. Emphasize key terms and concepts to ensure optimal indexing and querying within the vector database. 4. **do not include irrelevant Titles**: Ensure that every section title relevant to the theme is included. Each title should correspond to its own H1 heading. if sections are not relevant, do not use them. 5. **Generate Valid JSON Output**: The output must be in valid JSON format without truncation. Ensure the JSON structure adheres strictly to the provided schema.",
  "json_schema": {
    "name": "themes_writer_v8_single_theme",
    "strict": true,
    "schema": {
      "type": "object",
      "description": "This schema organizes section titles into a hierarchical outline under a single, specified theme.",
      "properties": {
        "theme": {
          "type": "string",
          "description": "The overall title of the theme, summarizing its grouped content."
        },
        "outline": {
          "type": "array",
          "description": "An outline of section titles organized into H1 headings under the specified theme.",
          "items": {
            "type": "object",
            "properties": {
              "title": {
                "type": "string",
                "description": "A database-friendly section title or heading H1 belonging to the theme in a format of short and very specific phrase using operators AND or OR."
              },
              "level": {
                "type": "string",
                "enum": [
                  "H1"
                ],
                "description": "The heading level H1 indicating the structure of the outline."
              }
            },
            "required": [
              "title",
              "level"
            ],
            "additionalProperties": false
          }
        }
      },
      "required": [
        "theme",
        "outline"
      ],
      "additionalProperties": false
    }
  },
  "config": {
    "max_tokens": 4096,
    "temperature": 0,
    "top_p": 1,
    "seed": 34
  },
  "content": "Your task is to filter the section titles based on the provided theme and organize them into a hierarchical structure using highly specific, database-friendly H1 headings. Ensure the H1 headings accurately reflect key concepts related to the theme and are optimized for querying in a vector database. The output should be in valid JSON format."
}
,
 "grouping_sections": {
   "text": "You will receive a list of section titles. Your task is to group these titles into as many clear, unique, and distinct themes as possible and then organize them into a hierarchical outline. Instructions: 1. **Maximize groupings**: Your goal is to group as many titles as possible under each theme, provided that they share the same overarching idea. 2. **Merge overlapping or redundant titles**: If two or more titles are similar in meaning or cover the same topic, merge them under the same theme, while conserving common keywords in their section title. 3. **Create distinct, clear themes**: Ensure that each theme has a clear, concise title that accurately reflects the content. 4. **Organize sections comprehensively **: Within each theme, create an outline of sections using the main headings H1 related to the theme according to the provided data. 5. **Include all titles**: Make sure every section title is grouped into a theme. No titles should be left ungrouped even the subsections titles that are to specific should gain its own heading 1. Overall, the themes should encompass all the content of the sections dataset and the headings 1 within each theme should encompass all the main headings withing their particular theme, even the specific headings.\nnote:make sure to ouput no truncated and valid json format json",
    "json_schema": {
      "name": "themes_writer_v8",
      "strict": true,
      "schema": {
        "type": "object",
        "description": "This schema organizes section titles into distinct themes and a hierarchical outline for each theme.",
        "properties": {
          "themes": {
            "type": "array",
            "description": "A list of themes, each containing a hierarchical outline of grouped section titles.",
            "items": {
              "type": "object",
              "properties": {
                "theme": {
                  "type": "string",
                  "description": "The overall title of the theme, summarizing its grouped content."
                },
                "outline": {
                  "type": "array",
                  "description": "An outline of section titles organized into headings and subheadings H1 under this theme.",
                  "items": {
                    "type": "object",
                    "properties": {
                      "title": {
                        "type": "string",
                        "description": "A section title or heading H1 belonging to this theme."
                      },
                      "level": {
                        "type": "string",
                        "enum": ["H1"],
                        "description": "The heading level H1 indicating the structure of the outline."
                      }
                    },
                    "required": ["title", "level"],
                    "additionalProperties": false
                  }
                }
              },
              "required": ["theme", "outline"],
              "additionalProperties": false
            }
          }
        },
        "required": ["themes"],
        "additionalProperties": false
      }
    },
    "config": {
      "max_tokens": 4096,
      "temperature": 0.3,
      "top_p": 1,
      "seed": 34
    },
    "content": "Your task is to group the section titles into broad themes, then organize each theme into a hierarchical structure using headings H1. The output should be in JSON format."
  }



,
"getting_sections2": {
    "text": "You will receive a list of sections and subsections. Your task is to organize these sections into a reflexive thematic review. Start by clustering the sections into the provided theme based on their content.  \n1. **Maximize headings**: Your goal is to group as many titles as possible under heading.\n2. **Filter irrelevant titles: If any section titles are not entirely relevant to the theme, exclude them and do not return them in the output.\n3. **Use clear hierarchy: Organize the sections using appropriate heading levels (h1, h2, h3, h4) to reflect the structure and depth of the content.\n4. **Use clear titles with one main idea only",
     "json_schema": {
    "name": "headings_writer",
    "strict": true,
    "schema": {
      "type": "object",
      "properties": {
        "headings": {
          "type": "array",
          "description": "A list of headings under the theme, each with a title, level, and optional subheadings.",
          "items": {
            "type": "object",
            "properties": {
              "title": {
                "type": "string",
                "description": "A concise and clear title summarizing the central idea of the heading."
              },
              "level": {
                "type": "string",
                "enum": ["h1", "h2", "h3", "h4"],
                "description": "The heading level (h1, h2, h3, or h4) defining the hierarchy of the headings."
              },
              "subheadings": {
                "type": "array",
                "description": "An optional list of subheadings under this heading, organized with proper nesting (h2 > h3 > h4).",
                "items": {
                  "type": "object",
                  "properties": {
                    "title": {
                      "type": "string",
                      "description": "A concise and clear title for the subheading."
                    },
                    "level": {
                      "type": "string",
                      "enum": ["h2", "h3", "h4"],
                      "description": "The heading level (h2, h3, or h4) for subheadings."
                    },
                    "subheadings": {
                      "type": "array",
                      "description": "Subheadings nested under h2, h3, or h4.",
                      "items": {
                        "type": "object",
                        "properties": {
                          "title": {
                            "type": "string",
                            "description": "A concise and clear title for the deeper subheading."
                          },
                          "level": {
                            "type": "string",
                            "enum": ["h3", "h4"],
                            "description": "The heading level (h3 or h4) for nested subheadings."
                          },
                          "subheadings": {
                            "type": "array",
                            "description": "Subheadings nested under h3 or h4.",
                            "items": {
                              "type": "object",
                              "properties": {
                                "title": {
                                  "type": "string",
                                  "description": "A concise and clear title for the deepest subheading."
                                },
                                "level": {
                                  "type": "string",
                                  "enum": ["h4"],
                                  "description": "The heading level for the deepest subheading (h4 only)."
                                }
                              },
                              "required": ["title", "level"],
                              "additionalProperties": false
                            }
                          }
                        },
                        "required": ["title", "level", "subheadings"],
                        "additionalProperties": false
                      }
                    }
                  },
                  "required": ["title", "level", "subheadings"],
                  "additionalProperties": false
                }
              }
            },
            "required": ["title", "level", "subheadings"],
            "additionalProperties": false
          }
        }
      },
      "required": ["headings"],
      "additionalProperties": false
    }

  },
    "config": {
      "max_tokens": 4096,
      "temperature": 0.4,
      "top_p": 0.9
    },
    "content": "Your task is to assign headings to  titles related to a given  theme. output is in json format."
  }

,
  "getting_sections": {
    "text": "You will receive a list of sections and subsections. Your task is to organize these sections into a reflexive thematic review. Start by clustering the sections into meaningful themes based on their content. A thematic review involves identifying patterns of meaning and organizing information around central concepts rather than listing sections independently. Use your judgment to merge any redundant or overlapping sections to create a more cohesive and unified structure.\n\nFollow these steps:\n\nTheme Creation: Group sections into larger themes that capture shared meanings. If two or more sections or subsections are similar or redundant, merge them under a unified heading. once a theme created, establish an hierarchical structure within the theme with h1, and its h2s, and analysing the h2s nesting their respective h3s and doing the same for h4s. The theme should be presented at the top level, followed by nested headings increasingly narrowing the tile in the levels of h1>h2>h3>h4. note: every subheadings key should contain three in order h2 followed by its h3 and h4",
      "json_schema": {
      "name": "themes_writer_v4",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "themes": {
            "type": "array",
            "description": "A list of themes, each containing a list of headings.",
            "items": {
              "type": "object",
              "properties": {
                "theme": {
                  "type": "string",
                  "description": "The overall title of the theme."
                },
                "headings": {
                  "type": "array",
                  "description": "A list of headings under the theme, each with a title and a level.",
                  "items": {
                    "type": "object",
                    "properties": {
                      "title": {
                        "type": "string",
                        "description": "A concise and clear title that summarizes the central idea of the heading."
                      },
                      "level": {
                        "type": "string",
                        "enum": ["h1", "h2", "h3","h4"],
                        "description": "The heading level (h1, h2, h3 or h4) to define the hierarchy of the headings."
                      },
                      "subheadings": {
                        "type": "array",
                        "description": "An optional list of subheadings under this heading, each with a title and a level.",
                        "items": {
                          "type": "object",
                          "properties": {
                            "title": {
                              "type": "string",
                              "description": "A concise and clear title for the subheading."
                            },
                            "level": {
                              "type": "string",
                              "enum": ["h2", "h3","h4"],
                              "description": "The heading level (h2, h3 or h4) for subheadings."
                            }
                          },
                          "required": ["title", "level"],
                          "additionalProperties": false
                        }
                      }
                    },
                    "required": ["title", "level", "subheadings"],
                    "additionalProperties": false
                  }
                }
              },
              "required": ["theme", "headings"],
              "additionalProperties": false
            }
          }
        },
        "required": ["themes"],
        "additionalProperties": false
      }
    },
    "config": {
      "max_tokens": 1000,
      "temperature": 0.75,
      "top_p": 0.9
    },
    "content": "You will receive a list of sections and subsections. Your task is to organize these sections into a hierarchical structure using HTML headings (h1, h2, h3, etc.) and assign titles to each section within a particularly theme. The theme will be at the top level, followed by nested headings and subsections. Use valid heading levels to create an organized structure that reflects the document's theme. Make sure to nest subsections within their parent sections where applicable. make sure to ouput no truncated and valid json format"
  }

,
  "thematic_review": {
    "text": "You will be given a list of headings (e.g., h1, h2), titles, paragraphs, and topic sentences, and your task is to create a comprehensive thematic section review for each heading  using only the provided references. after selecting relevant quotes for the purpose of the section, pay attention on their topic sentence as it summarises their author ideas. Critically analyze the authors' ideas, form a coherent narrative that connects to the overall theme, offer insightful analysis that demonstrates a deep understanding of the subject, and appropriately cite the original material in the same format found. Use valid HTML heading levels (h1, h2, etc.) to reflect the hierarchical structure of the content. Ensure that each section is well-organized, contributing to the thematic flow supported by accurate in-text citations. Authors can be cited alone or together if they share the same argument, corroborating or refuting statements. Do not include irrelevant citations and do not use words in your output containing <stop_word_list>",
    "json_schema": {
      "name": "thematic_review_writer_v2",
      "strict": true,
      "schema": {
        "type": "object",
        "properties": {
          "heading": {
            "type": "string",
            "enum": ["h1", "h2", "h3"],
            "description": "The valid HTML heading level (e.g., 'h1', 'h2', etc.) representing the section's hierarchy."
          },
          "title": {
            "type": "string",
            "description": "The title of the heading that summarizes the content of the section."
          },
          "paragraphs": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A cohesive paragraph of text written based on the provided references. Each paragraph should critically analyze the content and contribute to a coherent narrative that connects with the overarching theme."
            }
          }
        },
        "required": ["heading", "title", "paragraphs"],
        "additionalProperties": false
      }
    },
    "config": {
      "max_tokens": 4096,
      "temperature": 0.4,
      "top_p": 0.9
    },
    "content": "You will create thematic sections based on the given heading levels and paragraph content. Each section should consist of maximum three paragraphs, written solely based on the provided references. Analyze the paragraphs critically, discuss the authors' ideas, and form a coherent narrative that connects with the theme. Transition smoothly between paragraphs and provide insight into the theme.make sure to ouput no truncated and valid json format."
  },

  "cleaning_headings": {
    "text": "I have topic sentences representing paragraphs. Your task is to organize them into a hierarchical structure using a detailed HTML headings (<h2>, <h3>, <h4>,<h5>, etc.). You will be provided with a list of dicts where each dict contains an 'id' representing a paragraph id and a topic sentence. Your response should include titles, levels and associated paragraph IDs, structured hierarchically. Ensure logical nesting of headings based on content relevance, and each heading should group all relevant paragraph IDs and no subsection should contain less than one paragraph. .\"\nnote 1: consider their content with parent title as you will output headings below in the hierarchy to that context.note 2:you must process and use all topic sentences and paragraph_ids, returning sections using all the provided paragraph_ids. note3: the make sure to ouput no truncated and valid json format ```json.",
    "json_schema": {
    "name": "headings_and_titles_generator_v3",
    "strict": true,
    "schema": {
      "type": "object",
      "properties": {
        "subheadings": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "title": {
                "type": "string",
                "description": "A brief title summarizing the key idea of the section."
              },
              "level": {
                "type": "string",
                "enum": ["h2", "h3", "h4"],
                "description": "HTML heading level indicating the section's hierarchy."
              },
              "paragraph_ids": {
                "type": "array",
                "items": {
                  "type": "string",
                  "description": "List of paragraph IDs grouped under this heading."
                },
                "description": "IDs of paragraphs associated with the heading."
              },
              "subheadings": {
                "type": "array",
                "items": {
                  "type": "object",
                  "properties": {
                    "title": {
                      "type": "string",
                      "description": "A brief title summarizing the key idea of the sub-section."
                    },
                    "level": {
                      "type": "string",
                      "enum": ["h2", "h3", "h4"],
                      "description": "HTML heading level for the subheading."
                    },
                    "paragraph_ids": {
                      "type": "array",
                      "items": {
                        "type": "string",
                        "description": "List of paragraph IDs grouped under this subheading."
                      },
                      "description": "IDs of paragraphs associated with this subheading."
                    },
                    "subheadings": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "title": {
                            "type": "string",
                            "description": "A brief title for deeper nested subheading."
                          },
                          "level": {
                            "type": "string",
                            "enum": ["h2", "h3", "h4"],
                            "description": "HTML heading level for this nested subheading."
                          },
                          "paragraph_ids": {
                            "type": "array",
                            "items": {
                              "type": "string",
                              "description": "List of paragraph IDs grouped under this nested subheading."
                            },
                            "description": "IDs of paragraphs associated with this nested subheading."
                          }
                        },
                        "required": ["title", "level", "paragraph_ids"],
                        "additionalProperties": false
                      },
                      "description": "Nested subheadings under this section."
                    }
                  },
                  "required": ["title", "level", "paragraph_ids", "subheadings"],
                  "additionalProperties": false
                },
                "description": "Subheadings nested under this main heading."
              }
            },
            "required": ["title", "level", "paragraph_ids", "subheadings"],
            "additionalProperties": false
          },
          "description": "A hierarchical structure of headings with nested subheadings and associated title, level and paragraph IDs."
        }
      },
      "required": ["subheadings"],
      "additionalProperties": false
    }
  },
    "config": {
      "max_tokens": 4096,
      "temperature": 0.3,
      "top_p": 1,
      "seed": 34
    },
        "content": "You are a headings organiser, getting headings with paragraph if and topic sentence and returning structured data with title, level, paragraph_ids and and subheadings. improve accuracy making sure that the most relevant paragraphs are analysed and clustered into relevant subsections with valid paragraph id and topic sentence. you should process all data and all paragraph_ids "

  },
  "general_chat_query": {
    "prompt": "You are an AI assistant. The user will provide a query, potentially with external context (indicated by '--- External Context provided ---') and/or conversational history. Prioritize the external context if available and relevant. If conversational history is provided, use it to understand follow-up questions. Answer the user's current question clearly and concisely.provide the output in markdown format including references from external context"
  },




  "coding_keyword_thematic_section_html": {
    "default_model": {
      "openai": "o4-mini-2025-04-16",
      "mistral": "mistral-7b-instruct"
    },
    "def_temperature": 0.1,
    "content": "System: Produce a cross-keyword thematic synthesis as HTML. Output MUST be ONLY <p>…</p> blocks (no headings, no lists).\n\nInputs:\n• You will receive a series of groups, each starting with <!-- keyword: NAME --> followed by <p>…</p> fragments that already include anchors.\n\nTask:\n• Synthesize across groups to form a cohesive section. Cluster by ideas, not by keyword.\n• END EACH paragraph with one or more anchors in EXACT form:\n  <a key=\"KEY\" bib=\"BIB\" title=\"EXACT 1–2 sentence verbatim from the fragment\">(Surname, YYYY)</a>\n• Prefer diverse sources across paragraphs; do not reuse the same anchor in every paragraph.\n\nStrict:\n• Use only provenance (KEY, BIB) present in the provided anchors' data-key/data-bib.\n• Output ONLY <p>…</p> blocks; no headings, lists, or prefaces.\n{payload_placeholder}",
    "text": "Build a single thematic section from grouped keyword HTML fragments:\n\n{payload}\n\nReturn ONLY <p>…</p> blocks."
  },
  "bRefine_suggest_changes_round1": {
  "prompt": "You are refining a selected HTML fragment taken from a research document editor.\n\nINPUT (JSON payload):\n---\n{payload_placeholder}\n---\n\nYou must propose a set of accept/reject edits.\n\nRULES (STRICT):\n- Return ONLY a JSON object that matches the schema provided.\n- Do NOT add citations, sources, or facts.\n- Preserve the author’s meaning and terminology.\n- Preserve all links/anchors and their attributes exactly (href, data-dqid, data-orig-href, data-key, etc.). Do not remove or rewrite dq:// links.\n- Keep code blocks verbatim if present; only adjust surrounding prose.\n- Each proposed change must include:\n  (a) the exact HTML span to be replaced (copied verbatim from the input selection),\n  (b) the replacement HTML span,\n  (c) a concise justification, and\n  (d) issue tags and reviewer role.\n\nWhen splitting edits across multiple paragraphs, output multiple changes (one per replaced span).",
  "default_model": {
    "OpenAI": "gpt-5-mini",
    "Mistral": "mistral-large-latest",
    "Gemini": "gemini-1.5-pro-latest",
    "DeepSeek": "deepseek-chat"
  },
  "temperature": 0.2,
  "max_tokens": 5000,
  "property": {
    "name": "refine_suggest_changes_v1",
    "description": "Return a list of accept/reject change proposals for an HTML selection, including justifications and issue tags.",
    "schema": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "type": "object",
      "required": ["refine"],
      "additionalProperties": false,
      "properties": {
        "refine": {
          "type": "object",
          "required": ["changes"],
          "additionalProperties": false,
          "properties": {
            "changes": {
              "type": "array",
              "minItems": 1,
              "maxItems": 12,
              "items": {
                "type": "object",
                "required": [
                  "reviewer_role",
                  "issue_tags",
                  "original_html",
                  "replacement_html",
                  "justification",
                  "priority"
                ],
                "additionalProperties": false,
                "properties": {
                  "reviewer_role": {
                    "type": "string",
                    "enum": [
                      "evidence_authority",
                      "causal_reasoning",
                      "consensus_pluralism",
                      "structure_flow"
                    ]
                  },
                  "issue_tags": {
                    "type": "array",
                    "minItems": 1,
                    "maxItems": 6,
                    "items": {
                      "type": "string",
                      "enum": [
                        "missing authority",
                        "evidence gap",
                        "vague standard",
                        "conflated doctrines",
                        "logical leap",
                        "unsupported analogy",
                        "consensus overclaim",
                        "ignored dissent",
                        "selective citation",
                        "contradictory evidence",
                        "scope creep",
                        "structural redundancy"
                      ]
                    }
                  },
                  "original_html": {
                    "type": "string",
                    "minLength": 20,
                    "maxLength": 4000,
                    "description": "A verbatim HTML span copied exactly from the input selection. This is what will be replaced."
                  },
                  "replacement_html": {
                    "type": "string",
                    "minLength": 20,
                    "maxLength": 4000,
                    "description": "The replacement HTML span. Must preserve all existing links/attributes present in original span."
                  },
                  "justification": {
                    "type": "string",
                    "minLength": 10,
                    "maxLength": 600
                  },
                  "priority": {
                    "type": "integer",
                    "minimum": 1,
                    "maximum": 3
                  },
                  "questions": {
                    "type": "array",
                    "minItems": 0,
                    "maxItems": 3,
                    "items": {
                      "type": "string",
                      "minLength": 10,
                      "maxLength": 240
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
},

"bCheck_source_selection_round1": {
  "prompt": "You are verifying whether the selected HTML fragment accurately represents the underlying quoted sources referenced by dq:// anchors.\n\nINPUT (JSON payload):\n---\n{payload_placeholder}\n---\n\nTASK:\n1) For each anchor in anchors[], compare the selected text (selection_html) against the anchor's direct_quote / section_text.\n2) Decide whether the selection is:\n   - exact_match (the selection’s claim about the quote matches what the author says),\n   - partial_match (some overlap but meaning drift / missing qualifiers),\n   - mismatch (the selection claims something not supported or contradicts the quote),\n   - insufficient_context (selection too short/ambiguous to verify),\n   - source_missing (payload missing or incomplete).\n3) Provide a short evidence-backed note referencing the source fields provided (author/year/title/page). Do NOT invent sources.\n4) Provide a suggested correction to the selection (plain text) when mismatch/partial_match.\n\nRULES (STRICT):\n- Return ONLY JSON that matches the schema.\n- Do NOT add new citations, URLs, or facts.\n- Use only the provided payload fields.\n- If you quote, quote only from payload.direct_quote or payload.section_text.\n",
  "default_model": {
    "OpenAI": "gpt-5-mini",
    "Mistral": "mistral-large-latest",
    "Gemini": "gemini-1.5-pro-latest",
    "DeepSeek": "deepseek-chat"
  },
  "temperature": 0.1,
  "max_tokens": 3500,
  "property": {
    "name": "check_source_selection_v1",
    "description": "Verify whether selected HTML matches what the dq:// source says.",
    "schema": {
      "$schema": "http://json-schema.org/draft-07/schema#",
      "type": "object",
      "required": ["checks"],
      "additionalProperties": false,
      "properties": {
        "checks": {
          "type": "array",
          "minItems": 1,
          "maxItems": 40,
          "items": {
            "type": "object",
            "required": [
              "dqid",
              "status",
              "source",
              "evidence",
              "note",
              "suggested_correction"
            ],
            "additionalProperties": false,
            "properties": {
              "dqid": { "type": "string", "minLength": 3, "maxLength": 64 },
              "status": {
                "type": "string",
                "enum": ["exact_match", "partial_match", "mismatch", "insufficient_context", "source_missing"]
              },
              "source": {
                "type": "object",
                "required": ["first_author_last", "year", "title", "page", "section_title"],
                "additionalProperties": false,
                "properties": {
                  "first_author_last": { "type": "string" },
                  "year": { "type": "string" },
                  "title": { "type": "string" },
                  "page": { "type": ["integer", "string", "null"] },
                  "section_title": { "type": ["string", "null"] }
                }
              },
              "evidence": {
                "type": "object",
                "required": ["direct_quote", "selection_span"],
                "additionalProperties": false,
                "properties": {
                  "direct_quote": { "type": ["string", "null"], "maxLength": 600 },
                  "selection_span": { "type": "string", "minLength": 0, "maxLength": 600 }
                }
              },
              "note": { "type": "string", "minLength": 10, "maxLength": 700 },
              "suggested_correction": {
                "type": "string",
                "minLength": 0,
                "maxLength": 700,
                "description": "Plain-text suggested correction when partial/mismatch; empty string otherwise."
              }
            }
          }
        }
      }
    }
  }
},


  "name": "six_c_document_evaluation_v3",
  "strict": true,
  "schema": {
    "$schema": "https://json-schema.org/draft/2020-12/schema",
    "type": "object",
    "description": "Evaluates a cyber-attribution document using the Six-C Evidence-Quality Framework (Chain-of-Custody, Credibility, Corroboration, Coherence, Confidence, Compliance). Produces per-axis scores, verbatim anchored citations with PDF page indices, quantitative artifact/evidence counts, gaps, recommendations, plus spider/radar-chart-ready aggregation payload.",
    "additionalProperties": false,
    "properties": {
      "document_metadata": {
        "type": "object",
        "description": "Non-evaluative metadata about the document being scored.",
        "additionalProperties": false,
        "properties": {
          "title": { "type": "string" },
          "authoring_entity": { "type": "string", "description": "Vendor, government, NGO, academic, newsroom, etc." },
          "publication_date": { "type": "string", "format": "date" },
          "version": { "type": "string" },
          "document_type": {
            "type": "string",
            "enum": [
              "vendor_report",
              "government_attribution_statement",
              "joint_advisory",
              "academic_paper",
              "news_investigation",
              "legal_memo",
              "technical_appendix",
              "mixed"
            ]
          },
          "scope": {
            "type": "string",
            "enum": [
              "intrusion_set",
              "campaign",
              "incident",
              "malware_family",
              "state_responsibility_claim",
              "mixed"
            ]
          },
          "audience": {
            "type": "string",
            "enum": ["technical_defenders", "policy", "legal", "public", "mixed"]
          },
          "claims_summary": {
            "type": "array",
            "description": "Short list of headline attribution/legal claims made by the document.",
            "items": { "type": "string" },
            "minItems": 0
          },
          "source_locator": {
            "type": "object",
            "description": "Optional pointer to where the document came from (file name, URL, dataset id).",
            "additionalProperties": false,
            "properties": {
              "source_type": {
                "type": "string",
                "enum": ["file", "url", "dataset_id", "other"]
              },
              "source_value": { "type": "string" }
            },
            "required": ["source_type", "source_value"]
          }
        },
        "required": [
          "title",
          "authoring_entity",
          "publication_date",
          "document_type",
          "scope",
          "audience"
        ]
      },

      "evaluation_config": {
        "type": "object",
        "description": "Scoring configuration and interpretive anchors used by the grader.",
        "additionalProperties": false,
        "properties": {
          "scoring_scale": {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "min": { "type": "integer", "const": 0 },
              "max": { "type": "integer", "const": 5 },
              "label_map": {
                "type": "object",
                "additionalProperties": false,
                "properties": {
                  "0": { "type": "string", "const": "Absent" },
                  "1": { "type": "string", "const": "Minimal" },
                  "2": { "type": "string", "const": "Weak/Partial" },
                  "3": { "type": "string", "const": "Moderate" },
                  "4": { "type": "string", "const": "Strong" },
                  "5": { "type": "string", "const": "Exemplary" }
                },
                "required": ["0", "1", "2", "3", "4", "5"]
              }
            },
            "required": ["min", "max", "label_map"]
          },

          "axis_weights": {
            "type": "object",
            "description": "Optional weights for weighted overall score. If omitted, equal weighting is assumed (grader should emit weights=1 for all axes in spider_payload).",
            "additionalProperties": false,
            "properties": {
              "chain_of_custody": { "type": "number", "minimum": 0 },
              "credibility": { "type": "number", "minimum": 0 },
              "corroboration": { "type": "number", "minimum": 0 },
              "coherence": { "type": "number", "minimum": 0 },
              "confidence": { "type": "number", "minimum": 0 },
              "compliance": { "type": "number", "minimum": 0 }
            },
            "required": [
              "chain_of_custody",
              "credibility",
              "corroboration",
              "coherence",
              "confidence",
              "compliance"
            ]
          },

          "stakes_level": {
            "type": "string",
            "description": "Used to interpret the Confidence axis (calibration to consequences).",
            "enum": ["low_defensive", "medium_policy", "high_sanctions", "exceptional_gravity"]
          },

          "citation_policy": {
            "type": "object",
            "description": "How citations are represented in this output.",
            "additionalProperties": false,
            "properties": {
              "pdf_page_indexing": { "type": "string", "enum": ["zero_based"] },
              "quote_requirements": {
                "type": "object",
                "additionalProperties": false,
                "properties": {
                  "require_verbatim": { "type": "boolean" },
                  "max_quote_chars": { "type": "integer", "minimum": 50 }
                },
                "required": ["require_verbatim", "max_quote_chars"]
              }
            },
            "required": ["pdf_page_indexing", "quote_requirements"]
          }
        },
        "required": ["scoring_scale", "stakes_level", "citation_policy"]
      },

      "evidence_inventory": {
        "type": "object",
        "description": "Document-wide inventory of extracted artifacts and evidence streams, with supporting anchors for counts/claims.",
        "additionalProperties": false,
        "properties": {
          "artifact_index": {
            "type": "array",
            "description": "Counts of artifact types identified in the document (parsed from appendices/tables and/or explicitly stated).",
            "items": { "$ref": "#/$defs/artifact_counter" },
            "minItems": 0
          },
          "evidence_streams_observed": {
            "type": "array",
            "description": "Evidence streams actually present in the document (not just claimed).",
            "items": { "$ref": "#/$defs/evidence_type" },
            "minItems": 0
          },
          "external_references_count": {
            "type": "integer",
            "minimum": 0,
            "description": "Count of external references/citations/URLs/footnotes disclosed in the document."
          },
          "limitations": {
            "type": "array",
            "description": "Access or disclosure constraints that affect scoring (redactions, missing appendices, proprietary telemetry not shared, etc.).",
            "items": { "type": "string" },
            "minItems": 0,
            "maxItems": 10
          }
        },
        "required": [
          "artifact_index",
          "evidence_streams_observed",
          "external_references_count",
          "limitations"
        ]
      },

      "six_c_scores": {
        "type": "object",
        "description": "Per-axis scoring with verbatim anchored evidence, quantitative extracts, gaps, and recommendations.",
        "additionalProperties": false,
        "properties": {
          "chain_of_custody": { "$ref": "#/$defs/axis_score_v3" },
          "credibility": { "$ref": "#/$defs/axis_score_v3" },
          "corroboration": { "$ref": "#/$defs/axis_score_v3" },
          "coherence": { "$ref": "#/$defs/axis_score_v3" },
          "confidence": { "$ref": "#/$defs/axis_score_confidence_v3" },
          "compliance": { "$ref": "#/$defs/axis_score_compliance_v3" }
        },
        "required": [
          "chain_of_custody",
          "credibility",
          "corroboration",
          "coherence",
          "confidence",
          "compliance"
        ]
      },

      "overall": {
        "type": "object",
        "description": "Aggregated results and cross-cutting diagnostics, including spider/radar chart payload.",
        "additionalProperties": false,
        "properties": {
          "overall_score_mean": {
            "type": "number",
            "description": "Arithmetic mean of the six axis scores, rounded to 1 decimal.",
            "multipleOf": 0.1,
            "minimum": 0,
            "maximum": 5
          },
          "overall_score_weighted": {
            "type": "number",
            "description": "Weighted mean of the six axis scores (if axis_weights provided), rounded to 1 decimal.",
            "multipleOf": 0.1,
            "minimum": 0,
            "maximum": 5
          },
          "spider_payload": {
            "type": "object",
            "description": "Deterministic payload for spider/radar charts. Axes order is fixed.",
            "additionalProperties": false,
            "properties": {
              "axes": {
                "type": "array",
                "minItems": 6,
                "maxItems": 6,
                "prefixItems": [
                  { "const": "chain_of_custody" },
                  { "const": "credibility" },
                  { "const": "corroboration" },
                  { "const": "coherence" },
                  { "const": "confidence" },
                  { "const": "compliance" }
                ],
                "items": false
              },
              "scores_0_to_5": {
                "type": "array",
                "minItems": 6,
                "maxItems": 6,
                "prefixItems": [
                  { "type": "integer", "minimum": 0, "maximum": 5 },
                  { "type": "integer", "minimum": 0, "maximum": 5 },
                  { "type": "integer", "minimum": 0, "maximum": 5 },
                  { "type": "integer", "minimum": 0, "maximum": 5 },
                  { "type": "integer", "minimum": 0, "maximum": 5 },
                  { "type": "integer", "minimum": 0, "maximum": 5 }
                ],
                "items": false
              },
              "scores_normalized_0_to_1": {
                "type": "array",
                "minItems": 6,
                "maxItems": 6,
                "prefixItems": [
                  { "type": "number", "minimum": 0, "maximum": 1 },
                  { "type": "number", "minimum": 0, "maximum": 1 },
                  { "type": "number", "minimum": 0, "maximum": 1 },
                  { "type": "number", "minimum": 0, "maximum": 1 },
                  { "type": "number", "minimum": 0, "maximum": 1 },
                  { "type": "number", "minimum": 0, "maximum": 1 }
                ],
                "items": false
              },
              "weights": {
                "type": "array",
                "minItems": 6,
                "maxItems": 6,
                "prefixItems": [
                  { "type": "number", "minimum": 0 },
                  { "type": "number", "minimum": 0 },
                  { "type": "number", "minimum": 0 },
                  { "type": "number", "minimum": 0 },
                  { "type": "number", "minimum": 0 },
                  { "type": "number", "minimum": 0 }
                ],
                "items": false
              }
            },
            "required": ["axes", "scores_0_to_5", "scores_normalized_0_to_1", "weights"]
          },
          "strengths": {
            "type": "array",
            "description": "Cross-axis strengths (1–5 bullets).",
            "items": { "type": "string" },
            "minItems": 0,
            "maxItems": 5
          },
          "key_gaps": {
            "type": "array",
            "description": "Cross-axis weaknesses likely to be challenged (1–5 bullets).",
            "items": { "type": "string" },
            "minItems": 0,
            "maxItems": 5
          },
          "priority_recommendations": {
            "type": "array",
            "description": "Actionable steps to raise evidentiary quality toward court-ready standards (1–7 items).",
            "items": { "type": "string" },
            "minItems": 0,
            "maxItems": 7
          },
          "grader_confidence": {
            "type": "object",
            "description": "How confident the evaluator is in their scoring given access constraints (e.g., redactions).",
            "additionalProperties": false,
            "properties": {
              "level": { "type": "integer", "minimum": 0, "maximum": 5 },
              "drivers": {
                "type": "array",
                "items": { "type": "string" },
                "minItems": 0
              }
            },
            "required": ["level", "drivers"]
          }
        },
        "required": [
          "overall_score_mean",
          "strengths",
          "key_gaps",
          "priority_recommendations",
          "grader_confidence",
          "spider_payload"
        ]
      }
    },

    "required": ["document_metadata", "evaluation_config", "evidence_inventory", "six_c_scores", "overall"],

    "allOf": [
      {
        "if": {
          "properties": {
            "evaluation_config": {
              "type": "object",
              "required": ["axis_weights"]
            }
          }
        },
        "then": {
          "properties": {
            "overall": {
              "type": "object",
              "required": ["overall_score_weighted"]
            }
          }
        }
      }
    ],

    "$defs": {
      "axis_name": {
        "type": "string",
        "enum": [
          "chain_of_custody",
          "credibility",
          "corroboration",
          "coherence",
          "confidence",
          "compliance"
        ]
      },

      "evidence_type": {
        "type": "string",
        "enum": [
          "forensic_artifact",
          "telemetry",
          "reverse_engineering",
          "infrastructure_analysis",
          "victimology",
          "timing_ttp",
          "osint",
          "government_statement",
          "judicial_material",
          "peer_review",
          "methodology_disclosure",
          "legal_analysis",
          "other"
        ]
      },

      "quote_kind": {
        "type": "string",
        "enum": ["verbatim", "paraphrase"]
      },

      "evidence_anchor_v3": {
        "type": "object",
        "description": "Concrete evidence used to justify a score, with traceable location in the document. Prefer verbatim quotes.",
        "additionalProperties": false,
        "properties": {
          "anchor_id": {
            "type": "string",
            "description": "Stable id used to reference this anchor from quantitative extracts and artifact counters."
          },
          "quote_kind": { "$ref": "#/$defs/quote_kind" },
          "verbatim_quote": {
            "type": "string",
            "description": "Verbatim excerpt (prefer <=30–50 words; hard cap is in chars). If paraphrase is used, this should be a short paraphrase and quote_kind must be 'paraphrase'.",
            "minLength": 1,
            "maxLength": 600
          },
          "location": {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "pdf_page_index": {
                "type": "integer",
                "minimum": 0,
                "description": "0-based PDF page index (machine index) used for unambiguous retrieval."
              },
              "printed_page_label": {
                "type": "string",
                "description": "Optional printed page label in the footer/header (e.g., '23', 'iv')."
              },
              "section": { "type": "string" },
              "paragraph": { "type": "integer", "minimum": 0 },
              "figure_table": { "type": "string" },
              "line_span": {
                "type": "object",
                "description": "Optional line span if the extraction pipeline yields line numbers.",
                "additionalProperties": false,
                "properties": {
                  "start_line": { "type": "integer", "minimum": 0 },
                  "end_line": { "type": "integer", "minimum": 0 }
                },
                "required": ["start_line", "end_line"]
              }
            },
            "required": ["pdf_page_index", "section"]
          },
          "evidence_type": { "$ref": "#/$defs/evidence_type" },
          "notes": { "type": "string", "description": "Why this passage supports the score." }
        },
        "required": ["anchor_id", "quote_kind", "verbatim_quote", "location", "evidence_type", "notes"]
      },

      "quantitative_extract": {
        "type": "object",
        "description": "A numeric value extracted from the document (explicitly stated or deterministically counted). Must cite its supporting anchor.",
        "additionalProperties": false,
        "properties": {
          "name": { "type": "string", "description": "Short label, e.g., 'md5_hashes_in_ioc_tables', 'external_sources_cited', 'cases_disclosed'." },
          "value": { "type": "number" },
          "unit": { "type": "string", "description": "Unit for the value, e.g., 'count', 'percent', 'minutes', 'days'." },
          "source": {
            "type": "string",
            "enum": ["explicit_in_text", "counted_from_tables", "counted_from_appendix", "computed"],
            "description": "How the number was obtained."
          },
          "supporting_anchor_id": { "type": "string" },
          "notes": { "type": "string" }
        },
        "required": ["name", "value", "unit", "source", "supporting_anchor_id", "notes"]
      },

      "artifact_counter": {
        "type": "object",
        "description": "Counts of specific artifact types disclosed or extractable from the document.",
        "additionalProperties": false,
        "properties": {
          "artifact_type": {
            "type": "string",
            "enum": [
              "hash_md5",
              "hash_sha1",
              "hash_sha256",
              "ip",
              "domain",
              "url",
              "email",
              "mutex",
              "registry_key",
              "filename",
              "yara_rule",
              "cve",
              "table",
              "figure",
              "case_count_claim",
              "external_reference"
            ]
          },
          "count": { "type": "integer", "minimum": 0 },
          "supporting_anchor_ids": {
            "type": "array",
            "items": { "type": "string" },
            "minItems": 0
          },
          "notes": { "type": "string" }
        },
        "required": ["artifact_type", "count", "supporting_anchor_ids", "notes"]
      },

      "axis_label": {
        "type": "string",
        "enum": ["Absent", "Minimal", "Weak/Partial", "Moderate", "Strong", "Exemplary"]
      },

      "axis_score_components": {
        "type": "object",
        "description": "Deterministic numeric components used for radar/spider charts and weighted aggregation.",
        "additionalProperties": false,
        "properties": {
          "axis_raw_score": { "type": "integer", "minimum": 0, "maximum": 5 },
          "axis_normalized_0_to_1": { "type": "number", "minimum": 0, "maximum": 1 },
          "axis_weight": { "type": "number", "minimum": 0 },
          "axis_weighted_score": { "type": "number", "minimum": 0, "maximum": 5 }
        },
        "required": ["axis_raw_score", "axis_normalized_0_to_1", "axis_weight", "axis_weighted_score"]
      },

      "axis_score_v3": {
        "type": "object",
        "description": "Generic axis scoring object with verbatim anchors and quantitative extracts.",
        "additionalProperties": false,
        "properties": {
          "score": { "type": "integer", "minimum": 0, "maximum": 5 },
          "label": { "$ref": "#/$defs/axis_label" },
          "justification": { "type": "string", "description": "1–3 sentences summarizing why the score was assigned." },
          "evidence_anchors": {
            "type": "array",
            "description": "Anchored verbatim passages/features supporting the score.",
            "items": { "$ref": "#/$defs/evidence_anchor_v3" },
            "minItems": 0,
            "maxItems": 7
          },
          "quantitative_extracts": {
            "type": "array",
            "description": "Numeric extracts that strengthen traceability and enable downstream analysis (e.g., #hashes, #streams, #cases).",
            "items": { "$ref": "#/$defs/quantitative_extract" },
            "minItems": 0,
            "maxItems": 10
          },
          "missing_elements": {
            "type": "array",
            "description": "Concrete omissions preventing a higher score.",
            "items": { "type": "string" },
            "minItems": 0,
            "maxItems": 10
          },
          "improvement_actions": {
            "type": "array",
            "description": "Concrete steps that would raise the score for this axis.",
            "items": { "type": "string" },
            "minItems": 0,
            "maxItems": 10
          },
          "axis_score_components": { "$ref": "#/$defs/axis_score_components" }
        },
        "required": [
          "score",
          "label",
          "justification",
          "evidence_anchors",
          "quantitative_extracts",
          "missing_elements",
          "improvement_actions",
          "axis_score_components"
        ]
      },

      "axis_score_confidence_v3": {
        "allOf": [
          { "$ref": "#/$defs/axis_score_v3" },
          {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "calibration": {
                "type": "object",
                "description": "How certainty claims are defined and matched to stakes.",
                "additionalProperties": false,
                "properties": {
                  "uses_defined_scale": { "type": "boolean" },
                  "scale_details_location": {
                    "type": "object",
                    "additionalProperties": false,
                    "properties": {
                      "pdf_page_index": { "type": "integer", "minimum": 0 },
                      "section": { "type": "string" }
                    },
                    "required": ["pdf_page_index", "section"]
                  },
                  "uncertainty_quantification": {
                    "type": "string",
                    "enum": ["none", "qualitative_only", "semi_quantitative", "quantitative_bounds"]
                  },
                  "stakes_alignment": {
                    "type": "string",
                    "enum": ["misaligned_low", "partially_aligned", "aligned", "overly_conservative"]
                  }
                },
                "required": ["uses_defined_scale", "uncertainty_quantification", "stakes_alignment"]
              }
            },
            "required": ["calibration"]
          }
        ]
      },

      "axis_score_compliance_v3": {
        "allOf": [
          { "$ref": "#/$defs/axis_score_v3" },
          {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "legal_mapping": {
                "type": "object",
                "description": "How technical claims are translated into applicable international-law tests.",
                "additionalProperties": false,
                "properties": {
                  "tests_addressed": {
                    "type": "array",
                    "items": {
                      "type": "string",
                      "enum": [
                        "state_organ",
                        "instructions_direction_control",
                        "effective_control",
                        "overall_control",
                        "due_diligence",
                        "attribution_standard_of_proof",
                        "countermeasures",
                        "use_of_force",
                        "armed_attack",
                        "necessity_proportionality",
                        "other"
                      ]
                    },
                    "minItems": 0
                  },
                  "ilc_asr_cited": { "type": "boolean" },
                  "icj_or_international_precedent_cited": { "type": "boolean" },
                  "citation_locations": {
                    "type": "array",
                    "items": {
                      "type": "object",
                      "additionalProperties": false,
                      "properties": {
                        "pdf_page_index": { "type": "integer", "minimum": 0 },
                        "section": { "type": "string" }
                      },
                      "required": ["pdf_page_index", "section"]
                    },
                    "minItems": 0
                  },
                  "doctrinal_gap_notes": { "type": "string" }
                },
                "required": [
                  "tests_addressed",
                  "ilc_asr_cited",
                  "icj_or_international_precedent_cited",
                  "citation_locations",
                  "doctrinal_gap_notes"
                ]
              }
            },
            "required": ["legal_mapping"]
          }
        ]
      }
    }
  }
}
