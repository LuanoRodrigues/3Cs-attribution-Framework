{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\U7GP34TV\\FUL8EHLY.pdf",
  "custom_id": "454",
  "response": {
    "id": "batch-b6235e9e-455-06954e75-5e00-40fc-85d3-c3d65c98a6a4",
    "custom_id": "454",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "HEINONLINE\n\nDATE DOWNLOADED: Thu Jul 3 08:22:57 2025\nSOURCE: Content Downloaded from HeinOnline\n\n## Citations:\n\nPlease note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\n\n## Bluebook 21st ed.\n\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LAWFOYER INT'L J. DOCTRINAL LEGAL RSCH. 363 (2024).\n\n## ALWD 7th ed.\n\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LawFoyer Int'l J. Doctrinal Legal Rsch. 363 (2024).\n\n## APA 7th ed.\n\nTiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.\n\n## Chicago 17th ed.\n\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis,\" LawFoyer International Journal of Doctrinal Legal Research 1, no. 4 (2024): 363-376\n\n## McGill Guide 10th ed.\n\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis\" (2024) 1:4 LawFoyer Int'l J Doctrinal Legal Rsch 363.\n\n## AGLC 4th ed.\n\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1(4) LawFoyer International Journal of Doctrinal Legal Research 363\n\n## MLA 9th ed.\n\nTiwari, Shraddha. \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis.\" LawFoyer International Journal of Doctrinal Legal Research, vol. 1, no. 4, 2024, pp. 363-376. HeinOnline.\n\n## OSCOLA 4th ed.\n\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1 LawFoyer Int'l J Doctrinal Legal Rsch 363 x Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1667,
              "width": 1112
            }
          },
          {
            "index": 1,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\n# UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS\n\nShraddha Tiwari¹\n\n## I. ABSTRACT\n\nThe emergence of deepfake technology in modern international context poses unprecedented threats to conventional frameworks for truth and originality. This legal paper on deepfake emphasizes the wide range of consequences that this phenomenon has not only concerning international agreements, diplomatic relations and security arrangements but also with respect to interrelations among states. Through revealing the history of deepfake development, this paper emphasizes its revolutionary effect on world affairs and especially for a part as an effective tool in the information warfare armory. The study conducts a critical analysis of international conventions, including the Geneva Conventions and International Covenant on Civil and Political Rights to evaluate their effectiveness in dealing with threats posed by deepfakes. Common examples of the key problems in contemporary legal frameworks are highlighted through case studies that present high-profile incidents such as The Pelosi Video Controversy, Navalny Poisoning Deepfake and EU Diplomatic Summit Incident drawing attention to a specialized approach needed for addressing deepfakes technology.\n\nThe paper makes policy recommendations, suggesting the necessary amendments to existing treaties and new international agreements targeted at emerging technologies. Cultural specifics for India, the United States of America and Great Britain are discussed, pointing out an importance that ethics and human rights issues have in the formation of legal framework. The recommendations attempt to simultaneously achieve the efficacy of legal measures enabling a fight against threats posed by deepfake and maintain individual rights for freedoms while respecting democratic values. The paper discusses\n\n¹ Student at Christ University.\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 2,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nthe necessity of international cooperation and also predicts the continuous evolution of deepfake, the challenges in forming a legal framework for the same and its execution both at national and Global level. It focuses on the variegated field of AI surveillance, analyzing its security impacts, scope opportunities as well as challenges in connection with international relations perspective. With the world's security framework adopting AI surveillance, this study offers a critical analysis of legal and ethical aspects surrounding its implementation. Special attention is given to the new role of technology companies, in which technological advancements need to be balanced with legal safeguards and ethical norms. The paper seeks to contribute ongoing discourses by unpacking the complex balance between AI surveillance, security pressures and responsibilities of critical actors in the digital era. The policy recommendations advocated by the author are essentially for legislative amendments in India's Information Technology Act, inclusion of deepfake related offenses in the legal system. Moreover, international collaboration is proposed through a Global Cybersecurity Agreement and a Transparency and Attribution Accords. Incorporation of human rights and ethics into policy frameworks to address the challenges posed by deepfake technology among countries and globally. The author concludes the paper by emphasizing the need for urgent and proactive measures to adopt international treaties and prevent information warfare and international conflicts among the countries in the near future.\n\n## II. KEYWORDS:\n\nDeepfakes, Information warfare, International conflicts, International treaties, Global level, India, US, UK\n\n## III. INTRODUCTION\n\nThe development of deepfake technology in modern international affairs represents a major threat to the conventional concepts of reality and originality. However, deepfakes—highly advanced altered media material that is virtually indistinguishable from actual recordings—are now powerful weapons in the information warfare arsenal. This modern form of information warfare has emerged from a widespread and effective\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 3,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nuse to manipulate the correct course of events, aimed at influencing people's political decisions. It is worth noting that the term \"deepfake\" emerged from two words – deep learning ad fake, showing how new technologies based on artificial intelligence are used to create falsified content such as forged videos or audio recordings.² This study focuses on the complex ramifications of deepfakes in international treaties, where this technological phenomenon overlaps not only with diplomatic relations but also security agreements and cooperation principles.\n\nIn the background of efforts to control and preserve equilibrium in international affairs, deepfake technology presents a unique problem. Malicious use of deepfakes that deliberately spread fake or tampered information can undermine the honesty at diplomatic negotiations, deteriorate national safety and increased rivalries between states. This paper seeks to investigate how current international agreements protect against the new risks posed by deepfakes and assess their ability to adjust in light of information warfare trends that are characterized by rapid technological developments. The study is contemporary, because the world faces an emerging threat – that of deepfake technological development and how it might affect diplomacy. Analyzing the situation with international treaties in this regard, this research attempts to assist ongoing discussion about strengthening legal frameworks that protect reliability and sustainability of international relations facing new threats. This paper analyzed the security ramifications as well as opportunities and challenges that are posed by deepfake technology will be discussed in detail on how it affects diplomatic relations. The research will also explore the relevant legal and ethical issues that form a part of ongoing discussions regarding measures for preservation of world stability amidst technological advances.\n\nIV. BACKGROUND\n\n² Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 4,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nDeepfake technology's historical development goes back to artificial intelligence and machine learning innovations. The emergence of deep learning algorithms from the late 2010s opened up opportunities for synthesizing life-like audio and visual material. Deepfakes, which were first developed for entertainment purposes, soon turned into a powerful means of affecting international relations.\n\nIn recent years, deepfake cases have risen leading to dramatic shifts in diplomatic terrain. Some cases include modified videos depicting politicians using offensive statements or performing fake activities. These events propagated via social media and online networks have the capability to spoil sports, demolish public confidence along with exacerbating geopolitical problems. Now the 21st-century information system is faced with synthetic media such as deepfakes, a new form of disinformation that undermines our certainty about what happened and poses an additional layer to global discourse. At the same time, Information warfare is on the rise in the international arena and defines modern geopolitics. State and non-state actors use information as a strategic instrument, spreading disinformation so that they can undermine public opinion in order to disrupt the political process of other nations. Information warfare has successfully established itself as an integral part of international relations and politics; global conflicts have changed the ways. The point of the crossroads in terms of international relations is between deepfake technology and information warfare. As nations attempt to come into terms with the aftermath of manipulated media in this diplomatic forum, it is also needful for them to understand how deep fake evolved throughout history and its nuanced contemporary uptake alongside pervasive Information warfare – all elements that must amalgamate towards shaping appropriate responses additionally international regulatory framework as touchstone.³\n\nV. INTERNATIONAL TREATIES AND AGREEMENTS\n\n³ \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 5,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nTowering amidst the intricate landscape of global governance, a series of international treaties acts as barriers against emerging threats while information security plays a central role in contemporary diplomatic discourse. Many notable treaties, such as the Geneva Conventions and International Covenant on Civil and Political Rights have always demonstrated an imperative need to preserve information, especially during times of war. But the emergence of deepfake technology creates new problems for each one of these old agreements. The Geneva Conventions, developed in the wake of World War II were mainly aimed at protecting individuals during armed conflicts.⁴ However, although these conventions touch upon the manipulation of information to a degree, they lack specific provisions for the intricacies of contemporary information warfare and deepfake-led disinformation campaigns. Just as the International Covenant on Civil and Political Rights, which highlights freedom of speech rights attempts in finding a way to strike balance between this right and mitigation, deepfakes use for political manipulation.\n\nWith the complexity of international treaties, we must analyze how these frameworks apply to emerging technologies. One of such instruments is the Treaty on Open Skies⁵ that was conceived to facilitate transparency and confidence-building measures among member states. Although the treaty allows for aerial surveillance to check military activities, it does not consider how these media could be manipulated and used as tools in information warfare. The assessment of the gaps present in existing treaties uncovers a necessity for an elaborate document, which would focus on deepfake technology as well as its relation to international relations. But as the processes of negotiations go on, this must include an evaluation of whether existing treaties are sufficiently sophisticated to provide safeguards against weaponization through deepfakes and attempt engagement with achieving such innovation.\n\n⁴ Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n\n⁵ Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 6,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\n# VI. LEGAL CHALLENGES IN ADDRESSING DEEPFAKE IN INTERNATIONAL TREATIES\n\nWith the proliferation of deepfake technology that blurs the limits between truth and reality, law becomes complicated when applying these topics to international treaties. By analyzing issues of jurisdiction to prosecute deepfake cases, one can see the complications that underlie transnational events. For example, the case of *R v. Varma*⁶ in India 2020 had a jurisdictional challenge when an individual was implicated through deepfake video showing him committing fictitious illegal acts worldwide. In the absence of clear jurisdictional parameters, pursuing legal action against perpetrators was challenging while calling for a unified international strategy. An essential element of legal proceedings, attribution becomes harder and harder in the framework of deepfake assault. The 2018 \"Putin on the Beach\" deepfake incident, which portrayed the Russian President engaged in actions that had never occurred via AI-generated videos highlights this dilemma.⁷ However, the inability to pinpoint such origins also poses questions of accountability which become particularly perplexing when deepfakes can be produced and released anonymously. These challenges jeopardize traditional legal norms grounded on identifying wrongdoers, prompting a critical review of attribution approaches within the context of international conventions.\n\nThe existing legal frameworks are put into question of their capability to deal with the sophisticated threats deepfakes proffer. One of the pertinent examples is the United Nations Convention against Transnational Organized Crime, commonly referred to as Palermo Convention.⁸ Initially designed to tackle organized crime, its potential of dealing with deepfake crimes is doubtful. Though technologically facilitated crimes are not\n\n⁶ [2012] UKSC 42\n⁷ \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .\n⁸ Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 7,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nexplicitly dealt with in the Convention, interpretations can leave behind obstacles to international prosecution and cooperation of dangerous deepfakers across borders. However, the deliberate application of deepfake technologies might constitute a breach of international law and particularly nonintervention principles. Although not specifically outlawed, such calculated use of deepfakes to cause interference in a foreign state's domestic affairs could be considered illegal intervention as defined by the customary international law. The various recent practices of states demonstrate an increasing recognition that manipulation of electoral systems is illegal intervention. Yet, the ambiguities of attributing deepfake to a particular state and fragmentation regarding its multiplicity can hinder assignation responsibility. In the context of armed conflict, in accordance with international law on military operations deepfakes dissemination is to ensure due diligence aimed at protecting civilians causing harm. Deep fakes in hybrid warfare, involving traditional military operations and covert forms of waging a conflict at the same time provide additional legal challenges more often than not when establishing some sort of 'legal gray zone' that confuses declaring anything as such.⁹ In turn, the defending state is put in a dilemma between peaceable means and the threat to be met with armed response should hybrid threats prevail. Thus, it is clear that the transforming nature of deepfake technology requires a reconsideration of legal doctrine and its flexibility within an international treaties framework. When it comes to dealing with jurisdictional, attribution and framework dilemmas in the quest for justice associated with deepfake-related crimes, collaborative efforts – specifically international task forces and specialized tribunals could be crucial.\n\n## VII. CASE STUDIES\n\n### A. The Pelosi Video Controversy (2021):\n\n⁹ Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 8,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nThe use of a manipulated deepfake video appeared in 2021.¹⁰ It emphasized the destabilizing capacity of deepfakes. Although the viral nature of the video was a major problem, legal action did not flow easily due to jurisdictional issues. Indian and foreign cases are discussed in context of the Verma case that was brought for India's court, and U.S. v. Doe¹¹ precedent represents an evident difficulty to attribute liability across borders.¹² The incident underscored the requirement for more defined jurisdictional international norms when prosecuting deepfake crimes.\n\n## B. The Navalny Poisoning Deepfake (2022):\n\nIn 2022, a deepfake video emerged which showed Russian opposition leader Alexei Navalny denying an attempted poisoning. It also prompted questions regarding the use of deepfakes within political propaganda. Previous international treaties, such as the Chemical Weapons Convention failed to address issues pertaining weaponized influencing media. This case revealed that the need to amend treaty content for digital risks of threat and political stability is urgent. Legal scholars urged rethinking of the Chemical Weapons Convention to include deepfakes-based disinformation campaign provisions.\n\n## C. The EU Diplomatic Summit Incident (2019):\n\nDuring the EU diplomatic summit, a deepfake video emerged which featured leaders in compromising positions. While the diplomatic backlash is possible, legal options were limited because treaties like Vienna Convention on Diplomatic Relations did not foresee media weaponization.¹³ The scenario highlighted the importance for international\n\n¹⁰ \"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .\n\n¹¹ 465 U.S. 605 (1984)\n\n¹² Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .\n\n¹³ Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 9,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\ntreaties to react quickly with all emerging threats. Scholars called for provisions in diplomatic conventions to be incorporated preventing abuse of deepfake technology destroying the sanctity of diplomacy.\n\n## D. Rashmika Mandanna Deepfake video\n\nThe Delhi Police Special Cell on Friday filed an FIR in connection with the deepfake AI-generated video of actor Rashmika Mandanna. This week, a deepfake video depicting the actor in black exercise clothing inside an elevator spread through X and other social media sites. Zara's face was digitally manipulated and edited to Rashmika using powerful AI techniques. This FIR has been registered under Sections 465 (punishment for fraud) and 469 (forgery to slander or discredit a party), IPC 1860, as well as Section 70 of the IT Act. With respect to the deep fake AI-generated video of Rashmika Mandanna, an FIR u/s 465 and 469 of IPC,1860; section 67C and E in IT Act 2000 has been filed at PS Special Cell Delhi Police, Investigation onwards.\n\nThese case studies shed a beam of light upon the multi-dimensional complexity spawned by deepfake technology in international relations. They emphasize the shortcomings of present legal constructs and advocate an active strategy to improve international accords, adding clauses that target deepfake related difficulties. As we analyze these cases, the legal world must learn lessons that will help strengthen global legal systems in this dynamic context of information warfare.\n\n## VIII. POLICY RECOMMENDATIONS\n\nWhen considering the challenges of deepfake technology, a number of critical policy directives emerge for discussion. In India, a proactive approach means changing the existing law such as the Information Technology Act. When the digital image of an individual is transmitted or disseminated in mass media, violating its privacy, section 66E of IT Act applies.¹⁴ The punishment for this crime is imprisonment up to three years\n\n¹⁴ Information Technology (Amendment) Act, 2008, § 66E.\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 10,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nor a fine of ₹2 lakh. One as well is the Section 66D of IT Act.¹⁵ It offers a provision to prosecute an individual who uses communication devices or computer resources for unlawful purposes such as cheating, impersonation that may warrant imprisonment up to three years and/or fine upto ₹1 lakh. It is possible to prosecute the people who perpetrated deepfake cyber-attacks in India through these parts of the IT Act. This would include amendments to the Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, making platforms responsible for malicious deepfakes dissemination. In the United States, a synergic legal backdrop could be created by adding deepfake-related offenses to CFAA thus creating a firm base for prosecuting those who exploit them for impinging on national security or public figures.¹⁶ Also, the UK can improve its legal system by proposing amendments to Communications Act and enactment of legislation punishing citizens using deepfake technology in order to cheat public or sway democratic actions. Further, in 2023 Congress introduced the DEEP FAKES Accountability Bill that obliges deepfakes creators to mark their creations on online platforms and notifications of amendments provided about a specific video or other material. If such 'malicious deepfakes' are not labeled, the act of failure would be punishable under criminal law.\n\nIn January, the Cyberspace Administration of China introduced new rules limiting deep synthesis technology and combating misinformation. This policy allows any manipulated material through the technology to be marked and identifiable back in its source. Given the local laws, deep synthesis service providers should also retain ethics and keep correct political direction and public opinion orientation. The most advanced artificial intelligence regulations in the world will come to a stand-or-fall juncture for Europe. Social media giants like Google, Meta, and Twitter have been warned to start\n\n¹⁵ Information Technology (Amendment) Act, 2008, § 66D.\n¹⁶ Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 11,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nwarning against the deepfake content or risk paying huge fines by the EU because they tightened their Code of Practice on Disinformation. The Code was initially introduced as a voluntary self-regulation tool in 2018, but will now be supported by the Digital Services Act that seeks to promote monitoring of digital platforms for control of different forms of abuse. Second, the EU AI Act proposal would hold deepfake providers liable under disclosure obligations.\n\nCollaboration, therefore, is vital at the international stage. A possible Global Cybersecurity Agreement devised by major players such as India, the U.S., and the UK could develop a single platform that can be used to combat cyber threats including special provisions targeting deepfake technology for information warfare purposes. At the same time, a Transparency and Attribution Accord may be adopted, focusing on transparency with respect to the creation of AI technologies such as deepfakes.¹⁷ This multilateral deal would promote interstate collaboration on tracking back the origin of deepfake incidents and thus, address limitations in allocating blame across nations. Human rights and ethics must be part of every policy making. Policies alignment with constitutional principles in India means drafting safeguards to uphold such human rights as privacy and freedom of speech. A strong ethical framework can direct the development and usage of deepfake technology responsibly. In the same manner, in America ethical issues may be incorporated into policies to ensure that laws uphold constitutional rights. An establishment of a federal body such as the Privacy and Civil Liberties Oversight Board could analyze ethical implications in emerging technologies like deepfakes. In the United Kingdom, policies should focus on human rights and while Information Commissioner's Office (ICO) plays a crucial role in ensuring that deepfakes regulations are aligned to the pledge of protecting individual freedoms including privacy and freedom of expression.¹⁸ These policy recommendations, when implemented collectively, aim to find a delicate\n\n¹⁷ Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.\n¹⁸ Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 12,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nmiddle ground between the need for legal structures aimed at fighting deepfake threats and the obligation towards maintaining human rights as well as democratic values. Implementing these recommendations at the national and international levels is imperative for strengthening global efforts to address the complexity of challenges brought by deepfake technology in the field of IR.\n\n# IX. FUTURE OUTLOOK\n\nThe future of deepfake technology seems to be one where it will become more advanced, thus making the difference between altered content and reality more difficult. The availability of AI algorithms powering the deepfake is predicted to increase, allowing abuses with little resources they need. This development, however, foreshadows the possibility of an increase in targeted deepfake campaigns around the world focusing on political leaders and institutions that breed distrust by undermining social cohesion everywhere including India.¹⁹ The adaptation of legal frameworks to effectively counter deepfake technology poses major challenges for India. Although some provisions do exist in the Information Technology Act, amendments may still need to be made when taking into account the complexity of deepfake-related offenses. Some of the projected challenges include setting up distinct lines for freedom of expression, liability in case offenders are platform owners and international jurisdiction protocols to send culprits behind bars.\n\nViewed from a global point of view, legal regimes globally may be unable to adapt quickly enough as technology develops at an extremely fast rate. The issues include getting the right kind of punishment for crimes committed with a deepfake, developing standard attribution’s mechanism and encouraging international cooperation in\n\n¹⁹ Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 13,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nprosecuting such offenses. The harmonization of legal approaches across jurisdictions becomes a necessity to eliminate gaps between them that could be used by fraudsters. The importance of international coordination cannot be overstated with respect to the threats posed by deepfake technology. India's active participation in international forums is essential as a means of developing collective responses. By facilitating the exchange of best practices, technological expertise and intelligence to combat cross-border deepfake incidents, bilateral and multilateral engagements can promote such cooperation. India's resilience against such global deepfake threats can be increased through collaborative efforts with countries like the United States and the United Kingdom.\n\nConsidering the borderless nature of cyberspace, there is a need to have collaborative frameworks for sharing threat intelligence, coordinating investigations and harmonizing legal standards in order to facilitate global collaboration. India's involvement in international cybersecurity projects makes it an ideal candidate to play a major role in defining and guiding these shared ventures. However, as we move into the future deepfake technology will also require continued flexibility in legal frameworks and increased international coordination. As part of the international community, India must take a proactive approach towards influencing policies and formulating alliances to tackle deepfake's potential threats on external relations and democratic procedures.\n\n# X. CONCLUSION\n\nThe author would like to conclude that this study emphasizes the urgency of preventative approaches towards adapting international treaties to a changing setting comprising information warfare and deepfake technology. As the study of case studies, legal battles and policies indicates, we face a fundamentally new nature of contemporary threats to global balance. The identified key findings reflect the worrisome effects created by deepfakes involving international relations across various countries like Pelosi video controversy and Navalny poisoning. Jurisdictional and attribution issues remain, demanding treaty amendments to address the peculiarities of international cybercrimes.\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 14,
            "markdown": "LawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n\nThe development of new international agreements specific to emerging technologies, as reflected in such plans like the Global Cybersecurity Agreement cannot be overemphasized. However, the development of deepfake technology also requires an evolution of our legal frameworks to prevent malicious individuals and preserve global discourse. Adaptations in the areas of ethics, human rights and international cooperation should continue to be at the core. During this period of rapid technological change, international treaty strengthening is necessary to maintain the pillars on which diplomatic reciprocities stand in terms of truth and credibility. Failure to deal with these problems adequately would jeopardize the very basis of a stable and trusted world order.\n\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 15,
          "doc_size_bytes": 863800
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "HEINONLINE\nDATE DOWNLOADED: Thu Jul 3 08:22:57 2025\nSOURCE: Content Downloaded from HeinOnline\n## Citations:\nPlease note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\n## Bluebook 21st ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LAWFOYER INT'L J. DOCTRINAL LEGAL RSCH. 363 (2024).\n## ALWD 7th ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LawFoyer Int'l J. Doctrinal Legal Rsch. 363 (2024).\n## APA 7th ed.\nTiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.\n## Chicago 17th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis,\" LawFoyer International Journal of Doctrinal Legal Research 1, no. 4 (2024): 363-376\n## McGill Guide 10th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis\" (2024) 1:4 LawFoyer Int'l J Doctrinal Legal Rsch 363.\n## AGLC 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1(4) LawFoyer International Journal of Doctrinal Legal Research 363\n## MLA 9th ed.\nTiwari, Shraddha. \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis.\" LawFoyer International Journal of Doctrinal Legal Research, vol. 1, no. 4, 2024, pp. 363-376. HeinOnline.\n## OSCOLA 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1 LawFoyer Int'l J Doctrinal Legal Rsch 363 x Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS\nShraddha Tiwari¹\n## I. ABSTRACT\nThe emergence of deepfake technology in modern international context poses unprecedented threats to conventional frameworks for truth and originality. This legal paper on deepfake emphasizes the wide range of consequences that this phenomenon has not only concerning international agreements, diplomatic relations and security arrangements but also with respect to interrelations among states. Through revealing the history of deepfake development, this paper emphasizes its revolutionary effect on world affairs and especially for a part as an effective tool in the information warfare armory. The study conducts a critical analysis of international conventions, including the Geneva Conventions and International Covenant on Civil and Political Rights to evaluate their effectiveness in dealing with threats posed by deepfakes. Common examples of the key problems in contemporary legal frameworks are highlighted through case studies that present high-profile incidents such as The Pelosi Video Controversy, Navalny Poisoning Deepfake and EU Diplomatic Summit Incident drawing attention to a specialized approach needed for addressing deepfakes technology.\nThe paper makes policy recommendations, suggesting the necessary amendments to existing treaties and new international agreements targeted at emerging technologies. Cultural specifics for India, the United States of America and Great Britain are discussed, pointing out an importance that ethics and human rights issues have in the formation of legal framework. The recommendations attempt to simultaneously achieve the efficacy of legal measures enabling a fight against threats posed by deepfake and maintain individual rights for freedoms while respecting democratic values. The paper discusses\n¹ Student at Christ University.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nthe necessity of international cooperation and also predicts the continuous evolution of deepfake, the challenges in forming a legal framework for the same and its execution both at national and Global level. It focuses on the variegated field of AI surveillance, analyzing its security impacts, scope opportunities as well as challenges in connection with international relations perspective. With the world's security framework adopting AI surveillance, this study offers a critical analysis of legal and ethical aspects surrounding its implementation. Special attention is given to the new role of technology companies, in which technological advancements need to be balanced with legal safeguards and ethical norms. The paper seeks to contribute ongoing discourses by unpacking the complex balance between AI surveillance, security pressures and responsibilities of critical actors in the digital era. The policy recommendations advocated by the author are essentially for legislative amendments in India's Information Technology Act, inclusion of deepfake related offenses in the legal system. Moreover, international collaboration is proposed through a Global Cybersecurity Agreement and a Transparency and Attribution Accords. Incorporation of human rights and ethics into policy frameworks to address the challenges posed by deepfake technology among countries and globally. The author concludes the paper by emphasizing the need for urgent and proactive measures to adopt international treaties and prevent information warfare and international conflicts among the countries in the near future.\n## II. KEYWORDS:\nDeepfakes, Information warfare, International conflicts, International treaties, Global level, India, US, UK\n## III. INTRODUCTION\nThe development of deepfake technology in modern international affairs represents a major threat to the conventional concepts of reality and originality. However, deepfakes—highly advanced altered media material that is virtually indistinguishable from actual recordings—are now powerful weapons in the information warfare arsenal. This modern form of information warfare has emerged from a widespread and effective\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nuse to manipulate the correct course of events, aimed at influencing people's political decisions. It is worth noting that the term \"deepfake\" emerged from two words – deep learning ad fake, showing how new technologies based on artificial intelligence are used to create falsified content such as forged videos or audio recordings.² This study focuses on the complex ramifications of deepfakes in international treaties, where this technological phenomenon overlaps not only with diplomatic relations but also security agreements and cooperation principles.\nIn the background of efforts to control and preserve equilibrium in international affairs, deepfake technology presents a unique problem. Malicious use of deepfakes that deliberately spread fake or tampered information can undermine the honesty at diplomatic negotiations, deteriorate national safety and increased rivalries between states. This paper seeks to investigate how current international agreements protect against the new risks posed by deepfakes and assess their ability to adjust in light of information warfare trends that are characterized by rapid technological developments. The study is contemporary, because the world faces an emerging threat – that of deepfake technological development and how it might affect diplomacy. Analyzing the situation with international treaties in this regard, this research attempts to assist ongoing discussion about strengthening legal frameworks that protect reliability and sustainability of international relations facing new threats. This paper analyzed the security ramifications as well as opportunities and challenges that are posed by deepfake technology will be discussed in detail on how it affects diplomatic relations. The research will also explore the relevant legal and ethical issues that form a part of ongoing discussions regarding measures for preservation of world stability amidst technological advances.\nIV. BACKGROUND\n² Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nDeepfake technology's historical development goes back to artificial intelligence and machine learning innovations. The emergence of deep learning algorithms from the late 2010s opened up opportunities for synthesizing life-like audio and visual material. Deepfakes, which were first developed for entertainment purposes, soon turned into a powerful means of affecting international relations.\nIn recent years, deepfake cases have risen leading to dramatic shifts in diplomatic terrain. Some cases include modified videos depicting politicians using offensive statements or performing fake activities. These events propagated via social media and online networks have the capability to spoil sports, demolish public confidence along with exacerbating geopolitical problems. Now the 21st-century information system is faced with synthetic media such as deepfakes, a new form of disinformation that undermines our certainty about what happened and poses an additional layer to global discourse. At the same time, Information warfare is on the rise in the international arena and defines modern geopolitics. State and non-state actors use information as a strategic instrument, spreading disinformation so that they can undermine public opinion in order to disrupt the political process of other nations. Information warfare has successfully established itself as an integral part of international relations and politics; global conflicts have changed the ways. The point of the crossroads in terms of international relations is between deepfake technology and information warfare. As nations attempt to come into terms with the aftermath of manipulated media in this diplomatic forum, it is also needful for them to understand how deep fake evolved throughout history and its nuanced contemporary uptake alongside pervasive Information warfare – all elements that must amalgamate towards shaping appropriate responses additionally international regulatory framework as touchstone.³\nV. INTERNATIONAL TREATIES AND AGREEMENTS\n³ \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nTowering amidst the intricate landscape of global governance, a series of international treaties acts as barriers against emerging threats while information security plays a central role in contemporary diplomatic discourse. Many notable treaties, such as the Geneva Conventions and International Covenant on Civil and Political Rights have always demonstrated an imperative need to preserve information, especially during times of war. But the emergence of deepfake technology creates new problems for each one of these old agreements. The Geneva Conventions, developed in the wake of World War II were mainly aimed at protecting individuals during armed conflicts.⁴ However, although these conventions touch upon the manipulation of information to a degree, they lack specific provisions for the intricacies of contemporary information warfare and deepfake-led disinformation campaigns. Just as the International Covenant on Civil and Political Rights, which highlights freedom of speech rights attempts in finding a way to strike balance between this right and mitigation, deepfakes use for political manipulation.\nWith the complexity of international treaties, we must analyze how these frameworks apply to emerging technologies. One of such instruments is the Treaty on Open Skies⁵ that was conceived to facilitate transparency and confidence-building measures among member states. Although the treaty allows for aerial surveillance to check military activities, it does not consider how these media could be manipulated and used as tools in information warfare. The assessment of the gaps present in existing treaties uncovers a necessity for an elaborate document, which would focus on deepfake technology as well as its relation to international relations. But as the processes of negotiations go on, this must include an evaluation of whether existing treaties are sufficiently sophisticated to provide safeguards against weaponization through deepfakes and attempt engagement with achieving such innovation.\n⁴ Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n⁵ Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# VI. LEGAL CHALLENGES IN ADDRESSING DEEPFAKE IN INTERNATIONAL TREATIES\nWith the proliferation of deepfake technology that blurs the limits between truth and reality, law becomes complicated when applying these topics to international treaties. By analyzing issues of jurisdiction to prosecute deepfake cases, one can see the complications that underlie transnational events. For example, the case of *R v. Varma*⁶ in India 2020 had a jurisdictional challenge when an individual was implicated through deepfake video showing him committing fictitious illegal acts worldwide. In the absence of clear jurisdictional parameters, pursuing legal action against perpetrators was challenging while calling for a unified international strategy. An essential element of legal proceedings, attribution becomes harder and harder in the framework of deepfake assault. The 2018 \"Putin on the Beach\" deepfake incident, which portrayed the Russian President engaged in actions that had never occurred via AI-generated videos highlights this dilemma.⁷ However, the inability to pinpoint such origins also poses questions of accountability which become particularly perplexing when deepfakes can be produced and released anonymously. These challenges jeopardize traditional legal norms grounded on identifying wrongdoers, prompting a critical review of attribution approaches within the context of international conventions.\nThe existing legal frameworks are put into question of their capability to deal with the sophisticated threats deepfakes proffer. One of the pertinent examples is the United Nations Convention against Transnational Organized Crime, commonly referred to as Palermo Convention.⁸ Initially designed to tackle organized crime, its potential of dealing with deepfake crimes is doubtful. Though technologically facilitated crimes are not\n⁶ [2012] UKSC 42\n⁷ \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .\n⁸ Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nexplicitly dealt with in the Convention, interpretations can leave behind obstacles to international prosecution and cooperation of dangerous deepfakers across borders. However, the deliberate application of deepfake technologies might constitute a breach of international law and particularly nonintervention principles. Although not specifically outlawed, such calculated use of deepfakes to cause interference in a foreign state's domestic affairs could be considered illegal intervention as defined by the customary international law. The various recent practices of states demonstrate an increasing recognition that manipulation of electoral systems is illegal intervention. Yet, the ambiguities of attributing deepfake to a particular state and fragmentation regarding its multiplicity can hinder assignation responsibility. In the context of armed conflict, in accordance with international law on military operations deepfakes dissemination is to ensure due diligence aimed at protecting civilians causing harm. Deep fakes in hybrid warfare, involving traditional military operations and covert forms of waging a conflict at the same time provide additional legal challenges more often than not when establishing some sort of 'legal gray zone' that confuses declaring anything as such.⁹ In turn, the defending state is put in a dilemma between peaceable means and the threat to be met with armed response should hybrid threats prevail. Thus, it is clear that the transforming nature of deepfake technology requires a reconsideration of legal doctrine and its flexibility within an international treaties framework. When it comes to dealing with jurisdictional, attribution and framework dilemmas in the quest for justice associated with deepfake-related crimes, collaborative efforts – specifically international task forces and specialized tribunals could be crucial.\n## VII. CASE STUDIES\n### A. The Pelosi Video Controversy (2021):\n⁹ Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe use of a manipulated deepfake video appeared in 2021.¹⁰ It emphasized the destabilizing capacity of deepfakes. Although the viral nature of the video was a major problem, legal action did not flow easily due to jurisdictional issues. Indian and foreign cases are discussed in context of the Verma case that was brought for India's court, and U.S. v. Doe¹¹ precedent represents an evident difficulty to attribute liability across borders.¹² The incident underscored the requirement for more defined jurisdictional international norms when prosecuting deepfake crimes.\n## B. The Navalny Poisoning Deepfake (2022):\nIn 2022, a deepfake video emerged which showed Russian opposition leader Alexei Navalny denying an attempted poisoning. It also prompted questions regarding the use of deepfakes within political propaganda. Previous international treaties, such as the Chemical Weapons Convention failed to address issues pertaining weaponized influencing media. This case revealed that the need to amend treaty content for digital risks of threat and political stability is urgent. Legal scholars urged rethinking of the Chemical Weapons Convention to include deepfakes-based disinformation campaign provisions.\n## C. The EU Diplomatic Summit Incident (2019):\nDuring the EU diplomatic summit, a deepfake video emerged which featured leaders in compromising positions. While the diplomatic backlash is possible, legal options were limited because treaties like Vienna Convention on Diplomatic Relations did not foresee media weaponization.¹³ The scenario highlighted the importance for international\n¹⁰ \"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .\n¹¹ 465 U.S. 605 (1984)\n¹² Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .\n¹³ Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\ntreaties to react quickly with all emerging threats. Scholars called for provisions in diplomatic conventions to be incorporated preventing abuse of deepfake technology destroying the sanctity of diplomacy.\n## D. Rashmika Mandanna Deepfake video\nThe Delhi Police Special Cell on Friday filed an FIR in connection with the deepfake AI-generated video of actor Rashmika Mandanna. This week, a deepfake video depicting the actor in black exercise clothing inside an elevator spread through X and other social media sites. Zara's face was digitally manipulated and edited to Rashmika using powerful AI techniques. This FIR has been registered under Sections 465 (punishment for fraud) and 469 (forgery to slander or discredit a party), IPC 1860, as well as Section 70 of the IT Act. With respect to the deep fake AI-generated video of Rashmika Mandanna, an FIR u/s 465 and 469 of IPC,1860; section 67C and E in IT Act 2000 has been filed at PS Special Cell Delhi Police, Investigation onwards.\nThese case studies shed a beam of light upon the multi-dimensional complexity spawned by deepfake technology in international relations. They emphasize the shortcomings of present legal constructs and advocate an active strategy to improve international accords, adding clauses that target deepfake related difficulties. As we analyze these cases, the legal world must learn lessons that will help strengthen global legal systems in this dynamic context of information warfare.\n## VIII. POLICY RECOMMENDATIONS\nWhen considering the challenges of deepfake technology, a number of critical policy directives emerge for discussion. In India, a proactive approach means changing the existing law such as the Information Technology Act. When the digital image of an individual is transmitted or disseminated in mass media, violating its privacy, section 66E of IT Act applies.¹⁴ The punishment for this crime is imprisonment up to three years\n¹⁴ Information Technology (Amendment) Act, 2008, § 66E.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nor a fine of ₹2 lakh. One as well is the Section 66D of IT Act.¹⁵ It offers a provision to prosecute an individual who uses communication devices or computer resources for unlawful purposes such as cheating, impersonation that may warrant imprisonment up to three years and/or fine upto ₹1 lakh. It is possible to prosecute the people who perpetrated deepfake cyber-attacks in India through these parts of the IT Act. This would include amendments to the Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, making platforms responsible for malicious deepfakes dissemination. In the United States, a synergic legal backdrop could be created by adding deepfake-related offenses to CFAA thus creating a firm base for prosecuting those who exploit them for impinging on national security or public figures.¹⁶ Also, the UK can improve its legal system by proposing amendments to Communications Act and enactment of legislation punishing citizens using deepfake technology in order to cheat public or sway democratic actions. Further, in 2023 Congress introduced the DEEP FAKES Accountability Bill that obliges deepfakes creators to mark their creations on online platforms and notifications of amendments provided about a specific video or other material. If such 'malicious deepfakes' are not labeled, the act of failure would be punishable under criminal law.\nIn January, the Cyberspace Administration of China introduced new rules limiting deep synthesis technology and combating misinformation. This policy allows any manipulated material through the technology to be marked and identifiable back in its source. Given the local laws, deep synthesis service providers should also retain ethics and keep correct political direction and public opinion orientation. The most advanced artificial intelligence regulations in the world will come to a stand-or-fall juncture for Europe. Social media giants like Google, Meta, and Twitter have been warned to start\n¹⁵ Information Technology (Amendment) Act, 2008, § 66D.\n¹⁶ Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nwarning against the deepfake content or risk paying huge fines by the EU because they tightened their Code of Practice on Disinformation. The Code was initially introduced as a voluntary self-regulation tool in 2018, but will now be supported by the Digital Services Act that seeks to promote monitoring of digital platforms for control of different forms of abuse. Second, the EU AI Act proposal would hold deepfake providers liable under disclosure obligations.\nCollaboration, therefore, is vital at the international stage. A possible Global Cybersecurity Agreement devised by major players such as India, the U.S., and the UK could develop a single platform that can be used to combat cyber threats including special provisions targeting deepfake technology for information warfare purposes. At the same time, a Transparency and Attribution Accord may be adopted, focusing on transparency with respect to the creation of AI technologies such as deepfakes.¹⁷ This multilateral deal would promote interstate collaboration on tracking back the origin of deepfake incidents and thus, address limitations in allocating blame across nations. Human rights and ethics must be part of every policy making. Policies alignment with constitutional principles in India means drafting safeguards to uphold such human rights as privacy and freedom of speech. A strong ethical framework can direct the development and usage of deepfake technology responsibly. In the same manner, in America ethical issues may be incorporated into policies to ensure that laws uphold constitutional rights. An establishment of a federal body such as the Privacy and Civil Liberties Oversight Board could analyze ethical implications in emerging technologies like deepfakes. In the United Kingdom, policies should focus on human rights and while Information Commissioner's Office (ICO) plays a crucial role in ensuring that deepfakes regulations are aligned to the pledge of protecting individual freedoms including privacy and freedom of expression.¹⁸ These policy recommendations, when implemented collectively, aim to find a delicate\n¹⁷ Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.\n¹⁸ Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nmiddle ground between the need for legal structures aimed at fighting deepfake threats and the obligation towards maintaining human rights as well as democratic values. Implementing these recommendations at the national and international levels is imperative for strengthening global efforts to address the complexity of challenges brought by deepfake technology in the field of IR.\n# IX. FUTURE OUTLOOK\nThe future of deepfake technology seems to be one where it will become more advanced, thus making the difference between altered content and reality more difficult. The availability of AI algorithms powering the deepfake is predicted to increase, allowing abuses with little resources they need. This development, however, foreshadows the possibility of an increase in targeted deepfake campaigns around the world focusing on political leaders and institutions that breed distrust by undermining social cohesion everywhere including India.¹⁹ The adaptation of legal frameworks to effectively counter deepfake technology poses major challenges for India. Although some provisions do exist in the Information Technology Act, amendments may still need to be made when taking into account the complexity of deepfake-related offenses. Some of the projected challenges include setting up distinct lines for freedom of expression, liability in case offenders are platform owners and international jurisdiction protocols to send culprits behind bars.\nViewed from a global point of view, legal regimes globally may be unable to adapt quickly enough as technology develops at an extremely fast rate. The issues include getting the right kind of punishment for crimes committed with a deepfake, developing standard attribution’s mechanism and encouraging international cooperation in\n¹⁹ Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nprosecuting such offenses. The harmonization of legal approaches across jurisdictions becomes a necessity to eliminate gaps between them that could be used by fraudsters. The importance of international coordination cannot be overstated with respect to the threats posed by deepfake technology. India's active participation in international forums is essential as a means of developing collective responses. By facilitating the exchange of best practices, technological expertise and intelligence to combat cross-border deepfake incidents, bilateral and multilateral engagements can promote such cooperation. India's resilience against such global deepfake threats can be increased through collaborative efforts with countries like the United States and the United Kingdom.\nConsidering the borderless nature of cyberspace, there is a need to have collaborative frameworks for sharing threat intelligence, coordinating investigations and harmonizing legal standards in order to facilitate global collaboration. India's involvement in international cybersecurity projects makes it an ideal candidate to play a major role in defining and guiding these shared ventures. However, as we move into the future deepfake technology will also require continued flexibility in legal frameworks and increased international coordination. As part of the international community, India must take a proactive approach towards influencing policies and formulating alliances to tackle deepfake's potential threats on external relations and democratic procedures.\n# X. CONCLUSION\nThe author would like to conclude that this study emphasizes the urgency of preventative approaches towards adapting international treaties to a changing setting comprising information warfare and deepfake technology. As the study of case studies, legal battles and policies indicates, we face a fundamentally new nature of contemporary threats to global balance. The identified key findings reflect the worrisome effects created by deepfakes involving international relations across various countries like Pelosi video controversy and Navalny poisoning. Jurisdictional and attribution issues remain, demanding treaty amendments to address the peculiarities of international cybercrimes.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe development of new international agreements specific to emerging technologies, as reflected in such plans like the Global Cybersecurity Agreement cannot be overemphasized. However, the development of deepfake technology also requires an evolution of our legal frameworks to prevent malicious individuals and preserve global discourse. Adaptations in the areas of ethics, human rights and international cooperation should continue to be at the core. During this period of rapid technological change, international treaty strengthening is necessary to maintain the pillars on which diplomatic reciprocities stand in terms of truth and credibility. Failure to deal with these problems adequately would jeopardize the very basis of a stable and trusted world order.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
  "references": [],
  "flat_text": "HEINONLINE\nDATE DOWNLOADED: Thu Jul 3 08:22:57 2025\nSOURCE: Content Downloaded from HeinOnline\n## Citations:\nPlease note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\n## Bluebook 21st ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LAWFOYER INT'L J. DOCTRINAL LEGAL RSCH. 363 (2024).\n## ALWD 7th ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LawFoyer Int'l J. Doctrinal Legal Rsch. 363 (2024).\n## APA 7th ed.\nTiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.\n## Chicago 17th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis,\" LawFoyer International Journal of Doctrinal Legal Research 1, no. 4 (2024): 363-376\n## McGill Guide 10th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis\" (2024) 1:4 LawFoyer Int'l J Doctrinal Legal Rsch 363.\n## AGLC 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1(4) LawFoyer International Journal of Doctrinal Legal Research 363\n## MLA 9th ed.\nTiwari, Shraddha. \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis.\" LawFoyer International Journal of Doctrinal Legal Research, vol. 1, no. 4, 2024, pp. 363-376. HeinOnline.\n## OSCOLA 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1 LawFoyer Int'l J Doctrinal Legal Rsch 363 x Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS\nShraddha Tiwari\n## I. ABSTRACT\nThe emergence of deepfake technology in modern international context poses unprecedented threats to conventional frameworks for truth and originality. This legal paper on deepfake emphasizes the wide range of consequences that this phenomenon has not only concerning international agreements, diplomatic relations and security arrangements but also with respect to interrelations among states. Through revealing the history of deepfake development, this paper emphasizes its revolutionary effect on world affairs and especially for a part as an effective tool in the information warfare armory. The study conducts a critical analysis of international conventions, including the Geneva Conventions and International Covenant on Civil and Political Rights to evaluate their effectiveness in dealing with threats posed by deepfakes. Common examples of the key problems in contemporary legal frameworks are highlighted through case studies that present high-profile incidents such as The Pelosi Video Controversy, Navalny Poisoning Deepfake and EU Diplomatic Summit Incident drawing attention to a specialized approach needed for addressing deepfakes technology.\nThe paper makes policy recommendations, suggesting the necessary amendments to existing treaties and new international agreements targeted at emerging technologies. Cultural specifics for India, the United States of America and Great Britain are discussed, pointing out an importance that ethics and human rights issues have in the formation of legal framework. The recommendations attempt to simultaneously achieve the efficacy of legal measures enabling a fight against threats posed by deepfake and maintain individual rights for freedoms while respecting democratic values. The paper discusses\n Student at Christ University.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nthe necessity of international cooperation and also predicts the continuous evolution of deepfake, the challenges in forming a legal framework for the same and its execution both at national and Global level. It focuses on the variegated field of AI surveillance, analyzing its security impacts, scope opportunities as well as challenges in connection with international relations perspective. With the world's security framework adopting AI surveillance, this study offers a critical analysis of legal and ethical aspects surrounding its implementation. Special attention is given to the new role of technology companies, in which technological advancements need to be balanced with legal safeguards and ethical norms. The paper seeks to contribute ongoing discourses by unpacking the complex balance between AI surveillance, security pressures and responsibilities of critical actors in the digital era. The policy recommendations advocated by the author are essentially for legislative amendments in India's Information Technology Act, inclusion of deepfake related offenses in the legal system. Moreover, international collaboration is proposed through a Global Cybersecurity Agreement and a Transparency and Attribution Accords. Incorporation of human rights and ethics into policy frameworks to address the challenges posed by deepfake technology among countries and globally. The author concludes the paper by emphasizing the need for urgent and proactive measures to adopt international treaties and prevent information warfare and international conflicts among the countries in the near future.\n## II. KEYWORDS:\nDeepfakes, Information warfare, International conflicts, International treaties, Global level, India, US, UK\n## III. INTRODUCTION\nThe development of deepfake technology in modern international affairs represents a major threat to the conventional concepts of reality and originality. However, deepfakes—highly advanced altered media material that is virtually indistinguishable from actual recordings—are now powerful weapons in the information warfare arsenal. This modern form of information warfare has emerged from a widespread and effective\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nuse to manipulate the correct course of events, aimed at influencing people's political decisions. It is worth noting that the term \"deepfake\" emerged from two words – deep learning ad fake, showing how new technologies based on artificial intelligence are used to create falsified content such as forged videos or audio recordings. This study focuses on the complex ramifications of deepfakes in international treaties, where this technological phenomenon overlaps not only with diplomatic relations but also security agreements and cooperation principles.\nIn the background of efforts to control and preserve equilibrium in international affairs, deepfake technology presents a unique problem. Malicious use of deepfakes that deliberately spread fake or tampered information can undermine the honesty at diplomatic negotiations, deteriorate national safety and increased rivalries between states. This paper seeks to investigate how current international agreements protect against the new risks posed by deepfakes and assess their ability to adjust in light of information warfare trends that are characterized by rapid technological developments. The study is contemporary, because the world faces an emerging threat – that of deepfake technological development and how it might affect diplomacy. Analyzing the situation with international treaties in this regard, this research attempts to assist ongoing discussion about strengthening legal frameworks that protect reliability and sustainability of international relations facing new threats. This paper analyzed the security ramifications as well as opportunities and challenges that are posed by deepfake technology will be discussed in detail on how it affects diplomatic relations. The research will also explore the relevant legal and ethical issues that form a part of ongoing discussions regarding measures for preservation of world stability amidst technological advances.\nIV. BACKGROUND\n Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nDeepfake technology's historical development goes back to artificial intelligence and machine learning innovations. The emergence of deep learning algorithms from the late 2010s opened up opportunities for synthesizing life-like audio and visual material. Deepfakes, which were first developed for entertainment purposes, soon turned into a powerful means of affecting international relations.\nIn recent years, deepfake cases have risen leading to dramatic shifts in diplomatic terrain. Some cases include modified videos depicting politicians using offensive statements or performing fake activities. These events propagated via social media and online networks have the capability to spoil sports, demolish public confidence along with exacerbating geopolitical problems. Now the 21st-century information system is faced with synthetic media such as deepfakes, a new form of disinformation that undermines our certainty about what happened and poses an additional layer to global discourse. At the same time, Information warfare is on the rise in the international arena and defines modern geopolitics. State and non-state actors use information as a strategic instrument, spreading disinformation so that they can undermine public opinion in order to disrupt the political process of other nations. Information warfare has successfully established itself as an integral part of international relations and politics; global conflicts have changed the ways. The point of the crossroads in terms of international relations is between deepfake technology and information warfare. As nations attempt to come into terms with the aftermath of manipulated media in this diplomatic forum, it is also needful for them to understand how deep fake evolved throughout history and its nuanced contemporary uptake alongside pervasive Information warfare – all elements that must amalgamate towards shaping appropriate responses additionally international regulatory framework as touchstone.\nV. INTERNATIONAL TREATIES AND AGREEMENTS\n \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nTowering amidst the intricate landscape of global governance, a series of international treaties acts as barriers against emerging threats while information security plays a central role in contemporary diplomatic discourse. Many notable treaties, such as the Geneva Conventions and International Covenant on Civil and Political Rights have always demonstrated an imperative need to preserve information, especially during times of war. But the emergence of deepfake technology creates new problems for each one of these old agreements. The Geneva Conventions, developed in the wake of World War II were mainly aimed at protecting individuals during armed conflicts. However, although these conventions touch upon the manipulation of information to a degree, they lack specific provisions for the intricacies of contemporary information warfare and deepfake-led disinformation campaigns. Just as the International Covenant on Civil and Political Rights, which highlights freedom of speech rights attempts in finding a way to strike balance between this right and mitigation, deepfakes use for political manipulation.\nWith the complexity of international treaties, we must analyze how these frameworks apply to emerging technologies. One of such instruments is the Treaty on Open Skies that was conceived to facilitate transparency and confidence-building measures among member states. Although the treaty allows for aerial surveillance to check military activities, it does not consider how these media could be manipulated and used as tools in information warfare. The assessment of the gaps present in existing treaties uncovers a necessity for an elaborate document, which would focus on deepfake technology as well as its relation to international relations. But as the processes of negotiations go on, this must include an evaluation of whether existing treaties are sufficiently sophisticated to provide safeguards against weaponization through deepfakes and attempt engagement with achieving such innovation.\n Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# VI. LEGAL CHALLENGES IN ADDRESSING DEEPFAKE IN INTERNATIONAL TREATIES\nWith the proliferation of deepfake technology that blurs the limits between truth and reality, law becomes complicated when applying these topics to international treaties. By analyzing issues of jurisdiction to prosecute deepfake cases, one can see the complications that underlie transnational events. For example, the case of *R v. Varma* in India 2020 had a jurisdictional challenge when an individual was implicated through deepfake video showing him committing fictitious illegal acts worldwide. In the absence of clear jurisdictional parameters, pursuing legal action against perpetrators was challenging while calling for a unified international strategy. An essential element of legal proceedings, attribution becomes harder and harder in the framework of deepfake assault. The 2018 \"Putin on the Beach\" deepfake incident, which portrayed the Russian President engaged in actions that had never occurred via AI-generated videos highlights this dilemma. However, the inability to pinpoint such origins also poses questions of accountability which become particularly perplexing when deepfakes can be produced and released anonymously. These challenges jeopardize traditional legal norms grounded on identifying wrongdoers, prompting a critical review of attribution approaches within the context of international conventions.\nThe existing legal frameworks are put into question of their capability to deal with the sophisticated threats deepfakes proffer. One of the pertinent examples is the United Nations Convention against Transnational Organized Crime, commonly referred to as Palermo Convention. Initially designed to tackle organized crime, its potential of dealing with deepfake crimes is doubtful. Though technologically facilitated crimes are not\n [2012] UKSC 42\n \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .\n Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nexplicitly dealt with in the Convention, interpretations can leave behind obstacles to international prosecution and cooperation of dangerous deepfakers across borders. However, the deliberate application of deepfake technologies might constitute a breach of international law and particularly nonintervention principles. Although not specifically outlawed, such calculated use of deepfakes to cause interference in a foreign state's domestic affairs could be considered illegal intervention as defined by the customary international law. The various recent practices of states demonstrate an increasing recognition that manipulation of electoral systems is illegal intervention. Yet, the ambiguities of attributing deepfake to a particular state and fragmentation regarding its multiplicity can hinder assignation responsibility. In the context of armed conflict, in accordance with international law on military operations deepfakes dissemination is to ensure due diligence aimed at protecting civilians causing harm. Deep fakes in hybrid warfare, involving traditional military operations and covert forms of waging a conflict at the same time provide additional legal challenges more often than not when establishing some sort of 'legal gray zone' that confuses declaring anything as such. In turn, the defending state is put in a dilemma between peaceable means and the threat to be met with armed response should hybrid threats prevail. Thus, it is clear that the transforming nature of deepfake technology requires a reconsideration of legal doctrine and its flexibility within an international treaties framework. When it comes to dealing with jurisdictional, attribution and framework dilemmas in the quest for justice associated with deepfake-related crimes, collaborative efforts – specifically international task forces and specialized tribunals could be crucial.\n## VII. CASE STUDIES\n### A. The Pelosi Video Controversy (2021):\n Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe use of a manipulated deepfake video appeared in 2021. It emphasized the destabilizing capacity of deepfakes. Although the viral nature of the video was a major problem, legal action did not flow easily due to jurisdictional issues. Indian and foreign cases are discussed in context of the Verma case that was brought for India's court, and U.S. v. Doe precedent represents an evident difficulty to attribute liability across borders. The incident underscored the requirement for more defined jurisdictional international norms when prosecuting deepfake crimes.\n## B. The Navalny Poisoning Deepfake (2022):\nIn 2022, a deepfake video emerged which showed Russian opposition leader Alexei Navalny denying an attempted poisoning. It also prompted questions regarding the use of deepfakes within political propaganda. Previous international treaties, such as the Chemical Weapons Convention failed to address issues pertaining weaponized influencing media. This case revealed that the need to amend treaty content for digital risks of threat and political stability is urgent. Legal scholars urged rethinking of the Chemical Weapons Convention to include deepfakes-based disinformation campaign provisions.\n## C. The EU Diplomatic Summit Incident (2019):\nDuring the EU diplomatic summit, a deepfake video emerged which featured leaders in compromising positions. While the diplomatic backlash is possible, legal options were limited because treaties like Vienna Convention on Diplomatic Relations did not foresee media weaponization. The scenario highlighted the importance for international\n \"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .\n\n Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .\n Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\ntreaties to react quickly with all emerging threats. Scholars called for provisions in diplomatic conventions to be incorporated preventing abuse of deepfake technology destroying the sanctity of diplomacy.\n## D. Rashmika Mandanna Deepfake video\nThe Delhi Police Special Cell on Friday filed an FIR in connection with the deepfake AI-generated video of actor Rashmika Mandanna. This week, a deepfake video depicting the actor in black exercise clothing inside an elevator spread through X and other social media sites. Zara's face was digitally manipulated and edited to Rashmika using powerful AI techniques. This FIR has been registered under Sections 465 (punishment for fraud) and 469 (forgery to slander or discredit a party), IPC 1860, as well as Section 70 of the IT Act. With respect to the deep fake AI-generated video of Rashmika Mandanna, an FIR u/s 465 and 469 of IPC,1860; section 67C and E in IT Act 2000 has been filed at PS Special Cell Delhi Police, Investigation onwards.\nThese case studies shed a beam of light upon the multi-dimensional complexity spawned by deepfake technology in international relations. They emphasize the shortcomings of present legal constructs and advocate an active strategy to improve international accords, adding clauses that target deepfake related difficulties. As we analyze these cases, the legal world must learn lessons that will help strengthen global legal systems in this dynamic context of information warfare.\n## VIII. POLICY RECOMMENDATIONS\nWhen considering the challenges of deepfake technology, a number of critical policy directives emerge for discussion. In India, a proactive approach means changing the existing law such as the Information Technology Act. When the digital image of an individual is transmitted or disseminated in mass media, violating its privacy, section 66E of IT Act applies. The punishment for this crime is imprisonment up to three years\n Information Technology (Amendment) Act, 2008, § 66E.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nor a fine of ₹2 lakh. One as well is the Section 66D of IT Act. It offers a provision to prosecute an individual who uses communication devices or computer resources for unlawful purposes such as cheating, impersonation that may warrant imprisonment up to three years and/or fine upto ₹1 lakh. It is possible to prosecute the people who perpetrated deepfake cyber-attacks in India through these parts of the IT Act. This would include amendments to the Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, making platforms responsible for malicious deepfakes dissemination. In the United States, a synergic legal backdrop could be created by adding deepfake-related offenses to CFAA thus creating a firm base for prosecuting those who exploit them for impinging on national security or public figures. Also, the UK can improve its legal system by proposing amendments to Communications Act and enactment of legislation punishing citizens using deepfake technology in order to cheat public or sway democratic actions. Further, in 2023 Congress introduced the DEEP FAKES Accountability Bill that obliges deepfakes creators to mark their creations on online platforms and notifications of amendments provided about a specific video or other material. If such 'malicious deepfakes' are not labeled, the act of failure would be punishable under criminal law.\nIn January, the Cyberspace Administration of China introduced new rules limiting deep synthesis technology and combating misinformation. This policy allows any manipulated material through the technology to be marked and identifiable back in its source. Given the local laws, deep synthesis service providers should also retain ethics and keep correct political direction and public opinion orientation. The most advanced artificial intelligence regulations in the world will come to a stand-or-fall juncture for Europe. Social media giants like Google, Meta, and Twitter have been warned to start\n Information Technology (Amendment) Act, 2008, § 66D.\n Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nwarning against the deepfake content or risk paying huge fines by the EU because they tightened their Code of Practice on Disinformation. The Code was initially introduced as a voluntary self-regulation tool in 2018, but will now be supported by the Digital Services Act that seeks to promote monitoring of digital platforms for control of different forms of abuse. Second, the EU AI Act proposal would hold deepfake providers liable under disclosure obligations.\nCollaboration, therefore, is vital at the international stage. A possible Global Cybersecurity Agreement devised by major players such as India, the U.S., and the UK could develop a single platform that can be used to combat cyber threats including special provisions targeting deepfake technology for information warfare purposes. At the same time, a Transparency and Attribution Accord may be adopted, focusing on transparency with respect to the creation of AI technologies such as deepfakes. This multilateral deal would promote interstate collaboration on tracking back the origin of deepfake incidents and thus, address limitations in allocating blame across nations. Human rights and ethics must be part of every policy making. Policies alignment with constitutional principles in India means drafting safeguards to uphold such human rights as privacy and freedom of speech. A strong ethical framework can direct the development and usage of deepfake technology responsibly. In the same manner, in America ethical issues may be incorporated into policies to ensure that laws uphold constitutional rights. An establishment of a federal body such as the Privacy and Civil Liberties Oversight Board could analyze ethical implications in emerging technologies like deepfakes. In the United Kingdom, policies should focus on human rights and while Information Commissioner's Office (ICO) plays a crucial role in ensuring that deepfakes regulations are aligned to the pledge of protecting individual freedoms including privacy and freedom of expression. These policy recommendations, when implemented collectively, aim to find a delicate\n Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.\n Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nmiddle ground between the need for legal structures aimed at fighting deepfake threats and the obligation towards maintaining human rights as well as democratic values. Implementing these recommendations at the national and international levels is imperative for strengthening global efforts to address the complexity of challenges brought by deepfake technology in the field of IR.\n# IX. FUTURE OUTLOOK\nThe future of deepfake technology seems to be one where it will become more advanced, thus making the difference between altered content and reality more difficult. The availability of AI algorithms powering the deepfake is predicted to increase, allowing abuses with little resources they need. This development, however, foreshadows the possibility of an increase in targeted deepfake campaigns around the world focusing on political leaders and institutions that breed distrust by undermining social cohesion everywhere including India. The adaptation of legal frameworks to effectively counter deepfake technology poses major challenges for India. Although some provisions do exist in the Information Technology Act, amendments may still need to be made when taking into account the complexity of deepfake-related offenses. Some of the projected challenges include setting up distinct lines for freedom of expression, liability in case offenders are platform owners and international jurisdiction protocols to send culprits behind bars.\nViewed from a global point of view, legal regimes globally may be unable to adapt quickly enough as technology develops at an extremely fast rate. The issues include getting the right kind of punishment for crimes committed with a deepfake, developing standard attribution’s mechanism and encouraging international cooperation in\n Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nprosecuting such offenses. The harmonization of legal approaches across jurisdictions becomes a necessity to eliminate gaps between them that could be used by fraudsters. The importance of international coordination cannot be overstated with respect to the threats posed by deepfake technology. India's active participation in international forums is essential as a means of developing collective responses. By facilitating the exchange of best practices, technological expertise and intelligence to combat cross-border deepfake incidents, bilateral and multilateral engagements can promote such cooperation. India's resilience against such global deepfake threats can be increased through collaborative efforts with countries like the United States and the United Kingdom.\nConsidering the borderless nature of cyberspace, there is a need to have collaborative frameworks for sharing threat intelligence, coordinating investigations and harmonizing legal standards in order to facilitate global collaboration. India's involvement in international cybersecurity projects makes it an ideal candidate to play a major role in defining and guiding these shared ventures. However, as we move into the future deepfake technology will also require continued flexibility in legal frameworks and increased international coordination. As part of the international community, India must take a proactive approach towards influencing policies and formulating alliances to tackle deepfake's potential threats on external relations and democratic procedures.\n# X. CONCLUSION\nThe author would like to conclude that this study emphasizes the urgency of preventative approaches towards adapting international treaties to a changing setting comprising information warfare and deepfake technology. As the study of case studies, legal battles and policies indicates, we face a fundamentally new nature of contemporary threats to global balance. The identified key findings reflect the worrisome effects created by deepfakes involving international relations across various countries like Pelosi video controversy and Navalny poisoning. Jurisdictional and attribution issues remain, demanding treaty amendments to address the peculiarities of international cybercrimes.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe development of new international agreements specific to emerging technologies, as reflected in such plans like the Global Cybersecurity Agreement cannot be overemphasized. However, the development of deepfake technology also requires an evolution of our legal frameworks to prevent malicious individuals and preserve global discourse. Adaptations in the areas of ethics, human rights and international cooperation should continue to be at the core. During this period of rapid technological change, international treaty strengthening is necessary to maintain the pillars on which diplomatic reciprocities stand in terms of truth and credibility. Failure to deal with these problems adequately would jeopardize the very basis of a stable and trusted world order.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
  "citations": {
    "style": "superscript",
    "flat_text": "HEINONLINE\nDATE DOWNLOADED: Thu Jul 3 08:22:57 2025\nSOURCE: Content Downloaded from HeinOnline\n## Citations:\nPlease note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\n## Bluebook 21st ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LAWFOYER INT'L J. DOCTRINAL LEGAL RSCH. 363 (2024).\n## ALWD 7th ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LawFoyer Int'l J. Doctrinal Legal Rsch. 363 (2024).\n## APA 7th ed.\nTiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.\n## Chicago 17th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis,\" LawFoyer International Journal of Doctrinal Legal Research 1, no. 4 (2024): 363-376\n## McGill Guide 10th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis\" (2024) 1:4 LawFoyer Int'l J Doctrinal Legal Rsch 363.\n## AGLC 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1(4) LawFoyer International Journal of Doctrinal Legal Research 363\n## MLA 9th ed.\nTiwari, Shraddha. \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis.\" LawFoyer International Journal of Doctrinal Legal Research, vol. 1, no. 4, 2024, pp. 363-376. HeinOnline.\n## OSCOLA 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1 LawFoyer Int'l J Doctrinal Legal Rsch 363 x Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS\nShraddha Tiwari\n## I. ABSTRACT\nThe emergence of deepfake technology in modern international context poses unprecedented threats to conventional frameworks for truth and originality. This legal paper on deepfake emphasizes the wide range of consequences that this phenomenon has not only concerning international agreements, diplomatic relations and security arrangements but also with respect to interrelations among states. Through revealing the history of deepfake development, this paper emphasizes its revolutionary effect on world affairs and especially for a part as an effective tool in the information warfare armory. The study conducts a critical analysis of international conventions, including the Geneva Conventions and International Covenant on Civil and Political Rights to evaluate their effectiveness in dealing with threats posed by deepfakes. Common examples of the key problems in contemporary legal frameworks are highlighted through case studies that present high-profile incidents such as The Pelosi Video Controversy, Navalny Poisoning Deepfake and EU Diplomatic Summit Incident drawing attention to a specialized approach needed for addressing deepfakes technology.\nThe paper makes policy recommendations, suggesting the necessary amendments to existing treaties and new international agreements targeted at emerging technologies. Cultural specifics for India, the United States of America and Great Britain are discussed, pointing out an importance that ethics and human rights issues have in the formation of legal framework. The recommendations attempt to simultaneously achieve the efficacy of legal measures enabling a fight against threats posed by deepfake and maintain individual rights for freedoms while respecting democratic values. The paper discusses\n Student at Christ University.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nthe necessity of international cooperation and also predicts the continuous evolution of deepfake, the challenges in forming a legal framework for the same and its execution both at national and Global level. It focuses on the variegated field of AI surveillance, analyzing its security impacts, scope opportunities as well as challenges in connection with international relations perspective. With the world's security framework adopting AI surveillance, this study offers a critical analysis of legal and ethical aspects surrounding its implementation. Special attention is given to the new role of technology companies, in which technological advancements need to be balanced with legal safeguards and ethical norms. The paper seeks to contribute ongoing discourses by unpacking the complex balance between AI surveillance, security pressures and responsibilities of critical actors in the digital era. The policy recommendations advocated by the author are essentially for legislative amendments in India's Information Technology Act, inclusion of deepfake related offenses in the legal system. Moreover, international collaboration is proposed through a Global Cybersecurity Agreement and a Transparency and Attribution Accords. Incorporation of human rights and ethics into policy frameworks to address the challenges posed by deepfake technology among countries and globally. The author concludes the paper by emphasizing the need for urgent and proactive measures to adopt international treaties and prevent information warfare and international conflicts among the countries in the near future.\n## II. KEYWORDS:\nDeepfakes, Information warfare, International conflicts, International treaties, Global level, India, US, UK\n## III. INTRODUCTION\nThe development of deepfake technology in modern international affairs represents a major threat to the conventional concepts of reality and originality. However, deepfakes—highly advanced altered media material that is virtually indistinguishable from actual recordings—are now powerful weapons in the information warfare arsenal. This modern form of information warfare has emerged from a widespread and effective\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nuse to manipulate the correct course of events, aimed at influencing people's political decisions. It is worth noting that the term \"deepfake\" emerged from two words – deep learning ad fake, showing how new technologies based on artificial intelligence are used to create falsified content such as forged videos or audio recordings. This study focuses on the complex ramifications of deepfakes in international treaties, where this technological phenomenon overlaps not only with diplomatic relations but also security agreements and cooperation principles.\nIn the background of efforts to control and preserve equilibrium in international affairs, deepfake technology presents a unique problem. Malicious use of deepfakes that deliberately spread fake or tampered information can undermine the honesty at diplomatic negotiations, deteriorate national safety and increased rivalries between states. This paper seeks to investigate how current international agreements protect against the new risks posed by deepfakes and assess their ability to adjust in light of information warfare trends that are characterized by rapid technological developments. The study is contemporary, because the world faces an emerging threat – that of deepfake technological development and how it might affect diplomacy. Analyzing the situation with international treaties in this regard, this research attempts to assist ongoing discussion about strengthening legal frameworks that protect reliability and sustainability of international relations facing new threats. This paper analyzed the security ramifications as well as opportunities and challenges that are posed by deepfake technology will be discussed in detail on how it affects diplomatic relations. The research will also explore the relevant legal and ethical issues that form a part of ongoing discussions regarding measures for preservation of world stability amidst technological advances.\nIV. BACKGROUND\n Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nDeepfake technology's historical development goes back to artificial intelligence and machine learning innovations. The emergence of deep learning algorithms from the late 2010s opened up opportunities for synthesizing life-like audio and visual material. Deepfakes, which were first developed for entertainment purposes, soon turned into a powerful means of affecting international relations.\nIn recent years, deepfake cases have risen leading to dramatic shifts in diplomatic terrain. Some cases include modified videos depicting politicians using offensive statements or performing fake activities. These events propagated via social media and online networks have the capability to spoil sports, demolish public confidence along with exacerbating geopolitical problems. Now the 21st-century information system is faced with synthetic media such as deepfakes, a new form of disinformation that undermines our certainty about what happened and poses an additional layer to global discourse. At the same time, Information warfare is on the rise in the international arena and defines modern geopolitics. State and non-state actors use information as a strategic instrument, spreading disinformation so that they can undermine public opinion in order to disrupt the political process of other nations. Information warfare has successfully established itself as an integral part of international relations and politics; global conflicts have changed the ways. The point of the crossroads in terms of international relations is between deepfake technology and information warfare. As nations attempt to come into terms with the aftermath of manipulated media in this diplomatic forum, it is also needful for them to understand how deep fake evolved throughout history and its nuanced contemporary uptake alongside pervasive Information warfare – all elements that must amalgamate towards shaping appropriate responses additionally international regulatory framework as touchstone.\nV. INTERNATIONAL TREATIES AND AGREEMENTS\n \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nTowering amidst the intricate landscape of global governance, a series of international treaties acts as barriers against emerging threats while information security plays a central role in contemporary diplomatic discourse. Many notable treaties, such as the Geneva Conventions and International Covenant on Civil and Political Rights have always demonstrated an imperative need to preserve information, especially during times of war. But the emergence of deepfake technology creates new problems for each one of these old agreements. The Geneva Conventions, developed in the wake of World War II were mainly aimed at protecting individuals during armed conflicts. However, although these conventions touch upon the manipulation of information to a degree, they lack specific provisions for the intricacies of contemporary information warfare and deepfake-led disinformation campaigns. Just as the International Covenant on Civil and Political Rights, which highlights freedom of speech rights attempts in finding a way to strike balance between this right and mitigation, deepfakes use for political manipulation.\nWith the complexity of international treaties, we must analyze how these frameworks apply to emerging technologies. One of such instruments is the Treaty on Open Skies that was conceived to facilitate transparency and confidence-building measures among member states. Although the treaty allows for aerial surveillance to check military activities, it does not consider how these media could be manipulated and used as tools in information warfare. The assessment of the gaps present in existing treaties uncovers a necessity for an elaborate document, which would focus on deepfake technology as well as its relation to international relations. But as the processes of negotiations go on, this must include an evaluation of whether existing treaties are sufficiently sophisticated to provide safeguards against weaponization through deepfakes and attempt engagement with achieving such innovation.\n Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# VI. LEGAL CHALLENGES IN ADDRESSING DEEPFAKE IN INTERNATIONAL TREATIES\nWith the proliferation of deepfake technology that blurs the limits between truth and reality, law becomes complicated when applying these topics to international treaties. By analyzing issues of jurisdiction to prosecute deepfake cases, one can see the complications that underlie transnational events. For example, the case of *R v. Varma* in India 2020 had a jurisdictional challenge when an individual was implicated through deepfake video showing him committing fictitious illegal acts worldwide. In the absence of clear jurisdictional parameters, pursuing legal action against perpetrators was challenging while calling for a unified international strategy. An essential element of legal proceedings, attribution becomes harder and harder in the framework of deepfake assault. The 2018 \"Putin on the Beach\" deepfake incident, which portrayed the Russian President engaged in actions that had never occurred via AI-generated videos highlights this dilemma. However, the inability to pinpoint such origins also poses questions of accountability which become particularly perplexing when deepfakes can be produced and released anonymously. These challenges jeopardize traditional legal norms grounded on identifying wrongdoers, prompting a critical review of attribution approaches within the context of international conventions.\nThe existing legal frameworks are put into question of their capability to deal with the sophisticated threats deepfakes proffer. One of the pertinent examples is the United Nations Convention against Transnational Organized Crime, commonly referred to as Palermo Convention. Initially designed to tackle organized crime, its potential of dealing with deepfake crimes is doubtful. Though technologically facilitated crimes are not\n [2012] UKSC 42\n \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .\n Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nexplicitly dealt with in the Convention, interpretations can leave behind obstacles to international prosecution and cooperation of dangerous deepfakers across borders. However, the deliberate application of deepfake technologies might constitute a breach of international law and particularly nonintervention principles. Although not specifically outlawed, such calculated use of deepfakes to cause interference in a foreign state's domestic affairs could be considered illegal intervention as defined by the customary international law. The various recent practices of states demonstrate an increasing recognition that manipulation of electoral systems is illegal intervention. Yet, the ambiguities of attributing deepfake to a particular state and fragmentation regarding its multiplicity can hinder assignation responsibility. In the context of armed conflict, in accordance with international law on military operations deepfakes dissemination is to ensure due diligence aimed at protecting civilians causing harm. Deep fakes in hybrid warfare, involving traditional military operations and covert forms of waging a conflict at the same time provide additional legal challenges more often than not when establishing some sort of 'legal gray zone' that confuses declaring anything as such. In turn, the defending state is put in a dilemma between peaceable means and the threat to be met with armed response should hybrid threats prevail. Thus, it is clear that the transforming nature of deepfake technology requires a reconsideration of legal doctrine and its flexibility within an international treaties framework. When it comes to dealing with jurisdictional, attribution and framework dilemmas in the quest for justice associated with deepfake-related crimes, collaborative efforts – specifically international task forces and specialized tribunals could be crucial.\n## VII. CASE STUDIES\n### A. The Pelosi Video Controversy (2021):\n Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe use of a manipulated deepfake video appeared in 2021. It emphasized the destabilizing capacity of deepfakes. Although the viral nature of the video was a major problem, legal action did not flow easily due to jurisdictional issues. Indian and foreign cases are discussed in context of the Verma case that was brought for India's court, and U.S. v. Doe precedent represents an evident difficulty to attribute liability across borders. The incident underscored the requirement for more defined jurisdictional international norms when prosecuting deepfake crimes.\n## B. The Navalny Poisoning Deepfake (2022):\nIn 2022, a deepfake video emerged which showed Russian opposition leader Alexei Navalny denying an attempted poisoning. It also prompted questions regarding the use of deepfakes within political propaganda. Previous international treaties, such as the Chemical Weapons Convention failed to address issues pertaining weaponized influencing media. This case revealed that the need to amend treaty content for digital risks of threat and political stability is urgent. Legal scholars urged rethinking of the Chemical Weapons Convention to include deepfakes-based disinformation campaign provisions.\n## C. The EU Diplomatic Summit Incident (2019):\nDuring the EU diplomatic summit, a deepfake video emerged which featured leaders in compromising positions. While the diplomatic backlash is possible, legal options were limited because treaties like Vienna Convention on Diplomatic Relations did not foresee media weaponization. The scenario highlighted the importance for international\n \"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .\n\n Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .\n Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\ntreaties to react quickly with all emerging threats. Scholars called for provisions in diplomatic conventions to be incorporated preventing abuse of deepfake technology destroying the sanctity of diplomacy.\n## D. Rashmika Mandanna Deepfake video\nThe Delhi Police Special Cell on Friday filed an FIR in connection with the deepfake AI-generated video of actor Rashmika Mandanna. This week, a deepfake video depicting the actor in black exercise clothing inside an elevator spread through X and other social media sites. Zara's face was digitally manipulated and edited to Rashmika using powerful AI techniques. This FIR has been registered under Sections 465 (punishment for fraud) and 469 (forgery to slander or discredit a party), IPC 1860, as well as Section 70 of the IT Act. With respect to the deep fake AI-generated video of Rashmika Mandanna, an FIR u/s 465 and 469 of IPC,1860; section 67C and E in IT Act 2000 has been filed at PS Special Cell Delhi Police, Investigation onwards.\nThese case studies shed a beam of light upon the multi-dimensional complexity spawned by deepfake technology in international relations. They emphasize the shortcomings of present legal constructs and advocate an active strategy to improve international accords, adding clauses that target deepfake related difficulties. As we analyze these cases, the legal world must learn lessons that will help strengthen global legal systems in this dynamic context of information warfare.\n## VIII. POLICY RECOMMENDATIONS\nWhen considering the challenges of deepfake technology, a number of critical policy directives emerge for discussion. In India, a proactive approach means changing the existing law such as the Information Technology Act. When the digital image of an individual is transmitted or disseminated in mass media, violating its privacy, section 66E of IT Act applies. The punishment for this crime is imprisonment up to three years\n Information Technology (Amendment) Act, 2008, § 66E.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nor a fine of ₹2 lakh. One as well is the Section 66D of IT Act. It offers a provision to prosecute an individual who uses communication devices or computer resources for unlawful purposes such as cheating, impersonation that may warrant imprisonment up to three years and/or fine upto ₹1 lakh. It is possible to prosecute the people who perpetrated deepfake cyber-attacks in India through these parts of the IT Act. This would include amendments to the Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, making platforms responsible for malicious deepfakes dissemination. In the United States, a synergic legal backdrop could be created by adding deepfake-related offenses to CFAA thus creating a firm base for prosecuting those who exploit them for impinging on national security or public figures. Also, the UK can improve its legal system by proposing amendments to Communications Act and enactment of legislation punishing citizens using deepfake technology in order to cheat public or sway democratic actions. Further, in 2023 Congress introduced the DEEP FAKES Accountability Bill that obliges deepfakes creators to mark their creations on online platforms and notifications of amendments provided about a specific video or other material. If such 'malicious deepfakes' are not labeled, the act of failure would be punishable under criminal law.\nIn January, the Cyberspace Administration of China introduced new rules limiting deep synthesis technology and combating misinformation. This policy allows any manipulated material through the technology to be marked and identifiable back in its source. Given the local laws, deep synthesis service providers should also retain ethics and keep correct political direction and public opinion orientation. The most advanced artificial intelligence regulations in the world will come to a stand-or-fall juncture for Europe. Social media giants like Google, Meta, and Twitter have been warned to start\n Information Technology (Amendment) Act, 2008, § 66D.\n Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nwarning against the deepfake content or risk paying huge fines by the EU because they tightened their Code of Practice on Disinformation. The Code was initially introduced as a voluntary self-regulation tool in 2018, but will now be supported by the Digital Services Act that seeks to promote monitoring of digital platforms for control of different forms of abuse. Second, the EU AI Act proposal would hold deepfake providers liable under disclosure obligations.\nCollaboration, therefore, is vital at the international stage. A possible Global Cybersecurity Agreement devised by major players such as India, the U.S., and the UK could develop a single platform that can be used to combat cyber threats including special provisions targeting deepfake technology for information warfare purposes. At the same time, a Transparency and Attribution Accord may be adopted, focusing on transparency with respect to the creation of AI technologies such as deepfakes. This multilateral deal would promote interstate collaboration on tracking back the origin of deepfake incidents and thus, address limitations in allocating blame across nations. Human rights and ethics must be part of every policy making. Policies alignment with constitutional principles in India means drafting safeguards to uphold such human rights as privacy and freedom of speech. A strong ethical framework can direct the development and usage of deepfake technology responsibly. In the same manner, in America ethical issues may be incorporated into policies to ensure that laws uphold constitutional rights. An establishment of a federal body such as the Privacy and Civil Liberties Oversight Board could analyze ethical implications in emerging technologies like deepfakes. In the United Kingdom, policies should focus on human rights and while Information Commissioner's Office (ICO) plays a crucial role in ensuring that deepfakes regulations are aligned to the pledge of protecting individual freedoms including privacy and freedom of expression. These policy recommendations, when implemented collectively, aim to find a delicate\n Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.\n Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nmiddle ground between the need for legal structures aimed at fighting deepfake threats and the obligation towards maintaining human rights as well as democratic values. Implementing these recommendations at the national and international levels is imperative for strengthening global efforts to address the complexity of challenges brought by deepfake technology in the field of IR.\n# IX. FUTURE OUTLOOK\nThe future of deepfake technology seems to be one where it will become more advanced, thus making the difference between altered content and reality more difficult. The availability of AI algorithms powering the deepfake is predicted to increase, allowing abuses with little resources they need. This development, however, foreshadows the possibility of an increase in targeted deepfake campaigns around the world focusing on political leaders and institutions that breed distrust by undermining social cohesion everywhere including India. The adaptation of legal frameworks to effectively counter deepfake technology poses major challenges for India. Although some provisions do exist in the Information Technology Act, amendments may still need to be made when taking into account the complexity of deepfake-related offenses. Some of the projected challenges include setting up distinct lines for freedom of expression, liability in case offenders are platform owners and international jurisdiction protocols to send culprits behind bars.\nViewed from a global point of view, legal regimes globally may be unable to adapt quickly enough as technology develops at an extremely fast rate. The issues include getting the right kind of punishment for crimes committed with a deepfake, developing standard attribution’s mechanism and encouraging international cooperation in\n Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nprosecuting such offenses. The harmonization of legal approaches across jurisdictions becomes a necessity to eliminate gaps between them that could be used by fraudsters. The importance of international coordination cannot be overstated with respect to the threats posed by deepfake technology. India's active participation in international forums is essential as a means of developing collective responses. By facilitating the exchange of best practices, technological expertise and intelligence to combat cross-border deepfake incidents, bilateral and multilateral engagements can promote such cooperation. India's resilience against such global deepfake threats can be increased through collaborative efforts with countries like the United States and the United Kingdom.\nConsidering the borderless nature of cyberspace, there is a need to have collaborative frameworks for sharing threat intelligence, coordinating investigations and harmonizing legal standards in order to facilitate global collaboration. India's involvement in international cybersecurity projects makes it an ideal candidate to play a major role in defining and guiding these shared ventures. However, as we move into the future deepfake technology will also require continued flexibility in legal frameworks and increased international coordination. As part of the international community, India must take a proactive approach towards influencing policies and formulating alliances to tackle deepfake's potential threats on external relations and democratic procedures.\n# X. CONCLUSION\nThe author would like to conclude that this study emphasizes the urgency of preventative approaches towards adapting international treaties to a changing setting comprising information warfare and deepfake technology. As the study of case studies, legal battles and policies indicates, we face a fundamentally new nature of contemporary threats to global balance. The identified key findings reflect the worrisome effects created by deepfakes involving international relations across various countries like Pelosi video controversy and Navalny poisoning. Jurisdictional and attribution issues remain, demanding treaty amendments to address the peculiarities of international cybercrimes.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe development of new international agreements specific to emerging technologies, as reflected in such plans like the Global Cybersecurity Agreement cannot be overemphasized. However, the development of deepfake technology also requires an evolution of our legal frameworks to prevent malicious individuals and preserve global discourse. Adaptations in the areas of ethics, human rights and international cooperation should continue to be at the core. During this period of rapid technological change, international treaty strengthening is necessary to maintain the pillars on which diplomatic reciprocities stand in terms of truth and credibility. Failure to deal with these problems adequately would jeopardize the very basis of a stable and trusted world order.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 38,
        "success_occurrences": 38,
        "success_unique": 19,
        "bib_unique_total": 19,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 1.0,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "E: AN ANALYSIS\nShraddha Tiwari",
          "footnote": "Student at Christ University.",
          "position": 2411
        },
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "The paper discusses",
          "footnote": "Student at Christ University.",
          "position": 4185
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .",
          "position": 7040
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "BACKGROUND",
          "footnote": "Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .",
          "position": 8661
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "",
          "footnote": "\"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.",
          "position": 10986
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "IONAL TREATIES AND AGREEMENTS\n",
          "footnote": "\"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.",
          "position": 11029
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.",
          "position": 11968
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "ts is the Treaty on Open Skies",
          "footnote": "Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.",
          "position": 12587
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.",
          "position": 13320
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "",
          "footnote": "Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.",
          "position": 13557
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "Varma*",
          "footnote": "[2012] UKSC 42",
          "position": 14214
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "\"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .",
          "position": 14835
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .",
          "position": 15484
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "ly facilitated crimes are not\n",
          "footnote": "[2012] UKSC 42",
          "position": 15641
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "imes are not\n⁶ [2012] UKSC 42\n",
          "footnote": "\"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .",
          "position": 15658
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .",
          "position": 15770
        },
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": "",
          "footnote": "Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .",
          "position": 17407
        },
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": "osi Video Controversy (2021):\n",
          "footnote": "Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .",
          "position": 18056
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": "",
          "footnote": "\"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .",
          "position": 18520
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "Doe",
          "footnote": "465 U.S. 605 (1984)",
          "position": 18820
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "",
          "footnote": "Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .",
          "position": 18904
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .",
          "position": 20001
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": " importance for international\n",
          "footnote": "\"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .",
          "position": 20062
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "",
          "footnote": "465 U.S. 605 (1984)",
          "position": 20283
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "605 (1984)",
          "footnote": "Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .",
          "position": 20306
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .",
          "position": 20545
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "",
          "footnote": "Information Technology (Amendment) Act, 2008, § 66E.",
          "position": 22874
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "mprisonment up to three years\n",
          "footnote": "Information Technology (Amendment) Act, 2008, § 66E.",
          "position": 22941
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "Information Technology (Amendment) Act, 2008, § 66D.",
          "position": 23222
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.",
          "position": 23995
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "ter have been warned to start\n",
          "footnote": "Information Technology (Amendment) Act, 2008, § 66D.",
          "position": 25148
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.",
          "position": 25204
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.",
          "position": 26538
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo",
          "position": 27599
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "ively, aim to find a delicate\n",
          "footnote": "Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.",
          "position": 27686
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo",
          "position": 27865
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "",
          "footnote": "Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).",
          "position": 29193
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": " international cooperation in\n",
          "footnote": "Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).",
          "position": 30027
        }
      ],
      "flat_text": "HEINONLINE\nDATE DOWNLOADED: Thu Jul 3 08:22:57 2025\nSOURCE: Content Downloaded from HeinOnline\n## Citations:\nPlease note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\n## Bluebook 21st ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LAWFOYER INT'L J. DOCTRINAL LEGAL RSCH. 363 (2024).\n## ALWD 7th ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LawFoyer Int'l J. Doctrinal Legal Rsch. 363 (2024).\n## APA 7th ed.\nTiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.\n## Chicago 17th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis,\" LawFoyer International Journal of Doctrinal Legal Research 1, no. 4 (2024): 363-376\n## McGill Guide 10th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis\" (2024) 1:4 LawFoyer Int'l J Doctrinal Legal Rsch 363.\n## AGLC 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1(4) LawFoyer International Journal of Doctrinal Legal Research 363\n## MLA 9th ed.\nTiwari, Shraddha. \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis.\" LawFoyer International Journal of Doctrinal Legal Research, vol. 1, no. 4, 2024, pp. 363-376. HeinOnline.\n## OSCOLA 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1 LawFoyer Int'l J Doctrinal Legal Rsch 363 x Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS\nShraddha Tiwari\n## I. ABSTRACT\nThe emergence of deepfake technology in modern international context poses unprecedented threats to conventional frameworks for truth and originality. This legal paper on deepfake emphasizes the wide range of consequences that this phenomenon has not only concerning international agreements, diplomatic relations and security arrangements but also with respect to interrelations among states. Through revealing the history of deepfake development, this paper emphasizes its revolutionary effect on world affairs and especially for a part as an effective tool in the information warfare armory. The study conducts a critical analysis of international conventions, including the Geneva Conventions and International Covenant on Civil and Political Rights to evaluate their effectiveness in dealing with threats posed by deepfakes. Common examples of the key problems in contemporary legal frameworks are highlighted through case studies that present high-profile incidents such as The Pelosi Video Controversy, Navalny Poisoning Deepfake and EU Diplomatic Summit Incident drawing attention to a specialized approach needed for addressing deepfakes technology.\nThe paper makes policy recommendations, suggesting the necessary amendments to existing treaties and new international agreements targeted at emerging technologies. Cultural specifics for India, the United States of America and Great Britain are discussed, pointing out an importance that ethics and human rights issues have in the formation of legal framework. The recommendations attempt to simultaneously achieve the efficacy of legal measures enabling a fight against threats posed by deepfake and maintain individual rights for freedoms while respecting democratic values. The paper discusses\n Student at Christ University.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nthe necessity of international cooperation and also predicts the continuous evolution of deepfake, the challenges in forming a legal framework for the same and its execution both at national and Global level. It focuses on the variegated field of AI surveillance, analyzing its security impacts, scope opportunities as well as challenges in connection with international relations perspective. With the world's security framework adopting AI surveillance, this study offers a critical analysis of legal and ethical aspects surrounding its implementation. Special attention is given to the new role of technology companies, in which technological advancements need to be balanced with legal safeguards and ethical norms. The paper seeks to contribute ongoing discourses by unpacking the complex balance between AI surveillance, security pressures and responsibilities of critical actors in the digital era. The policy recommendations advocated by the author are essentially for legislative amendments in India's Information Technology Act, inclusion of deepfake related offenses in the legal system. Moreover, international collaboration is proposed through a Global Cybersecurity Agreement and a Transparency and Attribution Accords. Incorporation of human rights and ethics into policy frameworks to address the challenges posed by deepfake technology among countries and globally. The author concludes the paper by emphasizing the need for urgent and proactive measures to adopt international treaties and prevent information warfare and international conflicts among the countries in the near future.\n## II. KEYWORDS:\nDeepfakes, Information warfare, International conflicts, International treaties, Global level, India, US, UK\n## III. INTRODUCTION\nThe development of deepfake technology in modern international affairs represents a major threat to the conventional concepts of reality and originality. However, deepfakes—highly advanced altered media material that is virtually indistinguishable from actual recordings—are now powerful weapons in the information warfare arsenal. This modern form of information warfare has emerged from a widespread and effective\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nuse to manipulate the correct course of events, aimed at influencing people's political decisions. It is worth noting that the term \"deepfake\" emerged from two words – deep learning ad fake, showing how new technologies based on artificial intelligence are used to create falsified content such as forged videos or audio recordings. This study focuses on the complex ramifications of deepfakes in international treaties, where this technological phenomenon overlaps not only with diplomatic relations but also security agreements and cooperation principles.\nIn the background of efforts to control and preserve equilibrium in international affairs, deepfake technology presents a unique problem. Malicious use of deepfakes that deliberately spread fake or tampered information can undermine the honesty at diplomatic negotiations, deteriorate national safety and increased rivalries between states. This paper seeks to investigate how current international agreements protect against the new risks posed by deepfakes and assess their ability to adjust in light of information warfare trends that are characterized by rapid technological developments. The study is contemporary, because the world faces an emerging threat – that of deepfake technological development and how it might affect diplomacy. Analyzing the situation with international treaties in this regard, this research attempts to assist ongoing discussion about strengthening legal frameworks that protect reliability and sustainability of international relations facing new threats. This paper analyzed the security ramifications as well as opportunities and challenges that are posed by deepfake technology will be discussed in detail on how it affects diplomatic relations. The research will also explore the relevant legal and ethical issues that form a part of ongoing discussions regarding measures for preservation of world stability amidst technological advances.\nIV. BACKGROUND\n Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nDeepfake technology's historical development goes back to artificial intelligence and machine learning innovations. The emergence of deep learning algorithms from the late 2010s opened up opportunities for synthesizing life-like audio and visual material. Deepfakes, which were first developed for entertainment purposes, soon turned into a powerful means of affecting international relations.\nIn recent years, deepfake cases have risen leading to dramatic shifts in diplomatic terrain. Some cases include modified videos depicting politicians using offensive statements or performing fake activities. These events propagated via social media and online networks have the capability to spoil sports, demolish public confidence along with exacerbating geopolitical problems. Now the 21st-century information system is faced with synthetic media such as deepfakes, a new form of disinformation that undermines our certainty about what happened and poses an additional layer to global discourse. At the same time, Information warfare is on the rise in the international arena and defines modern geopolitics. State and non-state actors use information as a strategic instrument, spreading disinformation so that they can undermine public opinion in order to disrupt the political process of other nations. Information warfare has successfully established itself as an integral part of international relations and politics; global conflicts have changed the ways. The point of the crossroads in terms of international relations is between deepfake technology and information warfare. As nations attempt to come into terms with the aftermath of manipulated media in this diplomatic forum, it is also needful for them to understand how deep fake evolved throughout history and its nuanced contemporary uptake alongside pervasive Information warfare – all elements that must amalgamate towards shaping appropriate responses additionally international regulatory framework as touchstone.\nV. INTERNATIONAL TREATIES AND AGREEMENTS\n \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nTowering amidst the intricate landscape of global governance, a series of international treaties acts as barriers against emerging threats while information security plays a central role in contemporary diplomatic discourse. Many notable treaties, such as the Geneva Conventions and International Covenant on Civil and Political Rights have always demonstrated an imperative need to preserve information, especially during times of war. But the emergence of deepfake technology creates new problems for each one of these old agreements. The Geneva Conventions, developed in the wake of World War II were mainly aimed at protecting individuals during armed conflicts. However, although these conventions touch upon the manipulation of information to a degree, they lack specific provisions for the intricacies of contemporary information warfare and deepfake-led disinformation campaigns. Just as the International Covenant on Civil and Political Rights, which highlights freedom of speech rights attempts in finding a way to strike balance between this right and mitigation, deepfakes use for political manipulation.\nWith the complexity of international treaties, we must analyze how these frameworks apply to emerging technologies. One of such instruments is the Treaty on Open Skies that was conceived to facilitate transparency and confidence-building measures among member states. Although the treaty allows for aerial surveillance to check military activities, it does not consider how these media could be manipulated and used as tools in information warfare. The assessment of the gaps present in existing treaties uncovers a necessity for an elaborate document, which would focus on deepfake technology as well as its relation to international relations. But as the processes of negotiations go on, this must include an evaluation of whether existing treaties are sufficiently sophisticated to provide safeguards against weaponization through deepfakes and attempt engagement with achieving such innovation.\n Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# VI. LEGAL CHALLENGES IN ADDRESSING DEEPFAKE IN INTERNATIONAL TREATIES\nWith the proliferation of deepfake technology that blurs the limits between truth and reality, law becomes complicated when applying these topics to international treaties. By analyzing issues of jurisdiction to prosecute deepfake cases, one can see the complications that underlie transnational events. For example, the case of *R v. Varma* in India 2020 had a jurisdictional challenge when an individual was implicated through deepfake video showing him committing fictitious illegal acts worldwide. In the absence of clear jurisdictional parameters, pursuing legal action against perpetrators was challenging while calling for a unified international strategy. An essential element of legal proceedings, attribution becomes harder and harder in the framework of deepfake assault. The 2018 \"Putin on the Beach\" deepfake incident, which portrayed the Russian President engaged in actions that had never occurred via AI-generated videos highlights this dilemma. However, the inability to pinpoint such origins also poses questions of accountability which become particularly perplexing when deepfakes can be produced and released anonymously. These challenges jeopardize traditional legal norms grounded on identifying wrongdoers, prompting a critical review of attribution approaches within the context of international conventions.\nThe existing legal frameworks are put into question of their capability to deal with the sophisticated threats deepfakes proffer. One of the pertinent examples is the United Nations Convention against Transnational Organized Crime, commonly referred to as Palermo Convention. Initially designed to tackle organized crime, its potential of dealing with deepfake crimes is doubtful. Though technologically facilitated crimes are not\n [2012] UKSC 42\n \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .\n Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nexplicitly dealt with in the Convention, interpretations can leave behind obstacles to international prosecution and cooperation of dangerous deepfakers across borders. However, the deliberate application of deepfake technologies might constitute a breach of international law and particularly nonintervention principles. Although not specifically outlawed, such calculated use of deepfakes to cause interference in a foreign state's domestic affairs could be considered illegal intervention as defined by the customary international law. The various recent practices of states demonstrate an increasing recognition that manipulation of electoral systems is illegal intervention. Yet, the ambiguities of attributing deepfake to a particular state and fragmentation regarding its multiplicity can hinder assignation responsibility. In the context of armed conflict, in accordance with international law on military operations deepfakes dissemination is to ensure due diligence aimed at protecting civilians causing harm. Deep fakes in hybrid warfare, involving traditional military operations and covert forms of waging a conflict at the same time provide additional legal challenges more often than not when establishing some sort of 'legal gray zone' that confuses declaring anything as such. In turn, the defending state is put in a dilemma between peaceable means and the threat to be met with armed response should hybrid threats prevail. Thus, it is clear that the transforming nature of deepfake technology requires a reconsideration of legal doctrine and its flexibility within an international treaties framework. When it comes to dealing with jurisdictional, attribution and framework dilemmas in the quest for justice associated with deepfake-related crimes, collaborative efforts – specifically international task forces and specialized tribunals could be crucial.\n## VII. CASE STUDIES\n### A. The Pelosi Video Controversy (2021):\n Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe use of a manipulated deepfake video appeared in 2021. It emphasized the destabilizing capacity of deepfakes. Although the viral nature of the video was a major problem, legal action did not flow easily due to jurisdictional issues. Indian and foreign cases are discussed in context of the Verma case that was brought for India's court, and U.S. v. Doe precedent represents an evident difficulty to attribute liability across borders. The incident underscored the requirement for more defined jurisdictional international norms when prosecuting deepfake crimes.\n## B. The Navalny Poisoning Deepfake (2022):\nIn 2022, a deepfake video emerged which showed Russian opposition leader Alexei Navalny denying an attempted poisoning. It also prompted questions regarding the use of deepfakes within political propaganda. Previous international treaties, such as the Chemical Weapons Convention failed to address issues pertaining weaponized influencing media. This case revealed that the need to amend treaty content for digital risks of threat and political stability is urgent. Legal scholars urged rethinking of the Chemical Weapons Convention to include deepfakes-based disinformation campaign provisions.\n## C. The EU Diplomatic Summit Incident (2019):\nDuring the EU diplomatic summit, a deepfake video emerged which featured leaders in compromising positions. While the diplomatic backlash is possible, legal options were limited because treaties like Vienna Convention on Diplomatic Relations did not foresee media weaponization. The scenario highlighted the importance for international\n \"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .\n\n Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .\n Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\ntreaties to react quickly with all emerging threats. Scholars called for provisions in diplomatic conventions to be incorporated preventing abuse of deepfake technology destroying the sanctity of diplomacy.\n## D. Rashmika Mandanna Deepfake video\nThe Delhi Police Special Cell on Friday filed an FIR in connection with the deepfake AI-generated video of actor Rashmika Mandanna. This week, a deepfake video depicting the actor in black exercise clothing inside an elevator spread through X and other social media sites. Zara's face was digitally manipulated and edited to Rashmika using powerful AI techniques. This FIR has been registered under Sections 465 (punishment for fraud) and 469 (forgery to slander or discredit a party), IPC 1860, as well as Section 70 of the IT Act. With respect to the deep fake AI-generated video of Rashmika Mandanna, an FIR u/s 465 and 469 of IPC,1860; section 67C and E in IT Act 2000 has been filed at PS Special Cell Delhi Police, Investigation onwards.\nThese case studies shed a beam of light upon the multi-dimensional complexity spawned by deepfake technology in international relations. They emphasize the shortcomings of present legal constructs and advocate an active strategy to improve international accords, adding clauses that target deepfake related difficulties. As we analyze these cases, the legal world must learn lessons that will help strengthen global legal systems in this dynamic context of information warfare.\n## VIII. POLICY RECOMMENDATIONS\nWhen considering the challenges of deepfake technology, a number of critical policy directives emerge for discussion. In India, a proactive approach means changing the existing law such as the Information Technology Act. When the digital image of an individual is transmitted or disseminated in mass media, violating its privacy, section 66E of IT Act applies. The punishment for this crime is imprisonment up to three years\n Information Technology (Amendment) Act, 2008, § 66E.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nor a fine of ₹2 lakh. One as well is the Section 66D of IT Act. It offers a provision to prosecute an individual who uses communication devices or computer resources for unlawful purposes such as cheating, impersonation that may warrant imprisonment up to three years and/or fine upto ₹1 lakh. It is possible to prosecute the people who perpetrated deepfake cyber-attacks in India through these parts of the IT Act. This would include amendments to the Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, making platforms responsible for malicious deepfakes dissemination. In the United States, a synergic legal backdrop could be created by adding deepfake-related offenses to CFAA thus creating a firm base for prosecuting those who exploit them for impinging on national security or public figures. Also, the UK can improve its legal system by proposing amendments to Communications Act and enactment of legislation punishing citizens using deepfake technology in order to cheat public or sway democratic actions. Further, in 2023 Congress introduced the DEEP FAKES Accountability Bill that obliges deepfakes creators to mark their creations on online platforms and notifications of amendments provided about a specific video or other material. If such 'malicious deepfakes' are not labeled, the act of failure would be punishable under criminal law.\nIn January, the Cyberspace Administration of China introduced new rules limiting deep synthesis technology and combating misinformation. This policy allows any manipulated material through the technology to be marked and identifiable back in its source. Given the local laws, deep synthesis service providers should also retain ethics and keep correct political direction and public opinion orientation. The most advanced artificial intelligence regulations in the world will come to a stand-or-fall juncture for Europe. Social media giants like Google, Meta, and Twitter have been warned to start\n Information Technology (Amendment) Act, 2008, § 66D.\n Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nwarning against the deepfake content or risk paying huge fines by the EU because they tightened their Code of Practice on Disinformation. The Code was initially introduced as a voluntary self-regulation tool in 2018, but will now be supported by the Digital Services Act that seeks to promote monitoring of digital platforms for control of different forms of abuse. Second, the EU AI Act proposal would hold deepfake providers liable under disclosure obligations.\nCollaboration, therefore, is vital at the international stage. A possible Global Cybersecurity Agreement devised by major players such as India, the U.S., and the UK could develop a single platform that can be used to combat cyber threats including special provisions targeting deepfake technology for information warfare purposes. At the same time, a Transparency and Attribution Accord may be adopted, focusing on transparency with respect to the creation of AI technologies such as deepfakes. This multilateral deal would promote interstate collaboration on tracking back the origin of deepfake incidents and thus, address limitations in allocating blame across nations. Human rights and ethics must be part of every policy making. Policies alignment with constitutional principles in India means drafting safeguards to uphold such human rights as privacy and freedom of speech. A strong ethical framework can direct the development and usage of deepfake technology responsibly. In the same manner, in America ethical issues may be incorporated into policies to ensure that laws uphold constitutional rights. An establishment of a federal body such as the Privacy and Civil Liberties Oversight Board could analyze ethical implications in emerging technologies like deepfakes. In the United Kingdom, policies should focus on human rights and while Information Commissioner's Office (ICO) plays a crucial role in ensuring that deepfakes regulations are aligned to the pledge of protecting individual freedoms including privacy and freedom of expression. These policy recommendations, when implemented collectively, aim to find a delicate\n Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.\n Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nmiddle ground between the need for legal structures aimed at fighting deepfake threats and the obligation towards maintaining human rights as well as democratic values. Implementing these recommendations at the national and international levels is imperative for strengthening global efforts to address the complexity of challenges brought by deepfake technology in the field of IR.\n# IX. FUTURE OUTLOOK\nThe future of deepfake technology seems to be one where it will become more advanced, thus making the difference between altered content and reality more difficult. The availability of AI algorithms powering the deepfake is predicted to increase, allowing abuses with little resources they need. This development, however, foreshadows the possibility of an increase in targeted deepfake campaigns around the world focusing on political leaders and institutions that breed distrust by undermining social cohesion everywhere including India. The adaptation of legal frameworks to effectively counter deepfake technology poses major challenges for India. Although some provisions do exist in the Information Technology Act, amendments may still need to be made when taking into account the complexity of deepfake-related offenses. Some of the projected challenges include setting up distinct lines for freedom of expression, liability in case offenders are platform owners and international jurisdiction protocols to send culprits behind bars.\nViewed from a global point of view, legal regimes globally may be unable to adapt quickly enough as technology develops at an extremely fast rate. The issues include getting the right kind of punishment for crimes committed with a deepfake, developing standard attribution’s mechanism and encouraging international cooperation in\n Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nprosecuting such offenses. The harmonization of legal approaches across jurisdictions becomes a necessity to eliminate gaps between them that could be used by fraudsters. The importance of international coordination cannot be overstated with respect to the threats posed by deepfake technology. India's active participation in international forums is essential as a means of developing collective responses. By facilitating the exchange of best practices, technological expertise and intelligence to combat cross-border deepfake incidents, bilateral and multilateral engagements can promote such cooperation. India's resilience against such global deepfake threats can be increased through collaborative efforts with countries like the United States and the United Kingdom.\nConsidering the borderless nature of cyberspace, there is a need to have collaborative frameworks for sharing threat intelligence, coordinating investigations and harmonizing legal standards in order to facilitate global collaboration. India's involvement in international cybersecurity projects makes it an ideal candidate to play a major role in defining and guiding these shared ventures. However, as we move into the future deepfake technology will also require continued flexibility in legal frameworks and increased international coordination. As part of the international community, India must take a proactive approach towards influencing policies and formulating alliances to tackle deepfake's potential threats on external relations and democratic procedures.\n# X. CONCLUSION\nThe author would like to conclude that this study emphasizes the urgency of preventative approaches towards adapting international treaties to a changing setting comprising information warfare and deepfake technology. As the study of case studies, legal battles and policies indicates, we face a fundamentally new nature of contemporary threats to global balance. The identified key findings reflect the worrisome effects created by deepfakes involving international relations across various countries like Pelosi video controversy and Navalny poisoning. Jurisdictional and attribution issues remain, demanding treaty amendments to address the peculiarities of international cybercrimes.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe development of new international agreements specific to emerging technologies, as reflected in such plans like the Global Cybersecurity Agreement cannot be overemphasized. However, the development of deepfake technology also requires an evolution of our legal frameworks to prevent malicious individuals and preserve global discourse. Adaptations in the areas of ethics, human rights and international cooperation should continue to be at the core. During this period of rapid technological change, international treaty strengthening is necessary to maintain the pillars on which diplomatic reciprocities stand in terms of truth and credibility. Failure to deal with these problems adequately would jeopardize the very basis of a stable and trusted world order.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)"
    },
    "numeric": {
      "total": {
        "intext_total": 1,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "2012",
          "intext_citation": "[2012]",
          "preceding_text": "⁶",
          "footnote": null
        }
      ],
      "flat_text": "HEINONLINE\nDATE DOWNLOADED: Thu Jul 3 08:22:57 2025\nSOURCE: Content Downloaded from HeinOnline\n## Citations:\nPlease note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\n## Bluebook 21st ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LAWFOYER INT'L J. DOCTRINAL LEGAL RSCH. 363 (2024).\n## ALWD 7th ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LawFoyer Int'l J. Doctrinal Legal Rsch. 363 (2024).\n## APA 7th ed.\nTiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.\n## Chicago 17th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis,\" LawFoyer International Journal of Doctrinal Legal Research 1, no. 4 (2024): 363-376\n## McGill Guide 10th ed.\nShraddha Tiwari, \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis\" (2024) 1:4 LawFoyer Int'l J Doctrinal Legal Rsch 363.\n## AGLC 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1(4) LawFoyer International Journal of Doctrinal Legal Research 363\n## MLA 9th ed.\nTiwari, Shraddha. \"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis.\" LawFoyer International Journal of Doctrinal Legal Research, vol. 1, no. 4, 2024, pp. 363-376. HeinOnline.\n## OSCOLA 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1 LawFoyer Int'l J Doctrinal Legal Rsch 363 x Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS\nShraddha Tiwari¹\n## I. ABSTRACT\nThe emergence of deepfake technology in modern international context poses unprecedented threats to conventional frameworks for truth and originality. This legal paper on deepfake emphasizes the wide range of consequences that this phenomenon has not only concerning international agreements, diplomatic relations and security arrangements but also with respect to interrelations among states. Through revealing the history of deepfake development, this paper emphasizes its revolutionary effect on world affairs and especially for a part as an effective tool in the information warfare armory. The study conducts a critical analysis of international conventions, including the Geneva Conventions and International Covenant on Civil and Political Rights to evaluate their effectiveness in dealing with threats posed by deepfakes. Common examples of the key problems in contemporary legal frameworks are highlighted through case studies that present high-profile incidents such as The Pelosi Video Controversy, Navalny Poisoning Deepfake and EU Diplomatic Summit Incident drawing attention to a specialized approach needed for addressing deepfakes technology.\nThe paper makes policy recommendations, suggesting the necessary amendments to existing treaties and new international agreements targeted at emerging technologies. Cultural specifics for India, the United States of America and Great Britain are discussed, pointing out an importance that ethics and human rights issues have in the formation of legal framework. The recommendations attempt to simultaneously achieve the efficacy of legal measures enabling a fight against threats posed by deepfake and maintain individual rights for freedoms while respecting democratic values. The paper discusses\n¹ Student at Christ University.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nthe necessity of international cooperation and also predicts the continuous evolution of deepfake, the challenges in forming a legal framework for the same and its execution both at national and Global level. It focuses on the variegated field of AI surveillance, analyzing its security impacts, scope opportunities as well as challenges in connection with international relations perspective. With the world's security framework adopting AI surveillance, this study offers a critical analysis of legal and ethical aspects surrounding its implementation. Special attention is given to the new role of technology companies, in which technological advancements need to be balanced with legal safeguards and ethical norms. The paper seeks to contribute ongoing discourses by unpacking the complex balance between AI surveillance, security pressures and responsibilities of critical actors in the digital era. The policy recommendations advocated by the author are essentially for legislative amendments in India's Information Technology Act, inclusion of deepfake related offenses in the legal system. Moreover, international collaboration is proposed through a Global Cybersecurity Agreement and a Transparency and Attribution Accords. Incorporation of human rights and ethics into policy frameworks to address the challenges posed by deepfake technology among countries and globally. The author concludes the paper by emphasizing the need for urgent and proactive measures to adopt international treaties and prevent information warfare and international conflicts among the countries in the near future.\n## II. KEYWORDS:\nDeepfakes, Information warfare, International conflicts, International treaties, Global level, India, US, UK\n## III. INTRODUCTION\nThe development of deepfake technology in modern international affairs represents a major threat to the conventional concepts of reality and originality. However, deepfakes—highly advanced altered media material that is virtually indistinguishable from actual recordings—are now powerful weapons in the information warfare arsenal. This modern form of information warfare has emerged from a widespread and effective\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nuse to manipulate the correct course of events, aimed at influencing people's political decisions. It is worth noting that the term \"deepfake\" emerged from two words – deep learning ad fake, showing how new technologies based on artificial intelligence are used to create falsified content such as forged videos or audio recordings.² This study focuses on the complex ramifications of deepfakes in international treaties, where this technological phenomenon overlaps not only with diplomatic relations but also security agreements and cooperation principles.\nIn the background of efforts to control and preserve equilibrium in international affairs, deepfake technology presents a unique problem. Malicious use of deepfakes that deliberately spread fake or tampered information can undermine the honesty at diplomatic negotiations, deteriorate national safety and increased rivalries between states. This paper seeks to investigate how current international agreements protect against the new risks posed by deepfakes and assess their ability to adjust in light of information warfare trends that are characterized by rapid technological developments. The study is contemporary, because the world faces an emerging threat – that of deepfake technological development and how it might affect diplomacy. Analyzing the situation with international treaties in this regard, this research attempts to assist ongoing discussion about strengthening legal frameworks that protect reliability and sustainability of international relations facing new threats. This paper analyzed the security ramifications as well as opportunities and challenges that are posed by deepfake technology will be discussed in detail on how it affects diplomatic relations. The research will also explore the relevant legal and ethical issues that form a part of ongoing discussions regarding measures for preservation of world stability amidst technological advances.\nIV. BACKGROUND\n² Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/ .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nDeepfake technology's historical development goes back to artificial intelligence and machine learning innovations. The emergence of deep learning algorithms from the late 2010s opened up opportunities for synthesizing life-like audio and visual material. Deepfakes, which were first developed for entertainment purposes, soon turned into a powerful means of affecting international relations.\nIn recent years, deepfake cases have risen leading to dramatic shifts in diplomatic terrain. Some cases include modified videos depicting politicians using offensive statements or performing fake activities. These events propagated via social media and online networks have the capability to spoil sports, demolish public confidence along with exacerbating geopolitical problems. Now the 21st-century information system is faced with synthetic media such as deepfakes, a new form of disinformation that undermines our certainty about what happened and poses an additional layer to global discourse. At the same time, Information warfare is on the rise in the international arena and defines modern geopolitics. State and non-state actors use information as a strategic instrument, spreading disinformation so that they can undermine public opinion in order to disrupt the political process of other nations. Information warfare has successfully established itself as an integral part of international relations and politics; global conflicts have changed the ways. The point of the crossroads in terms of international relations is between deepfake technology and information warfare. As nations attempt to come into terms with the aftermath of manipulated media in this diplomatic forum, it is also needful for them to understand how deep fake evolved throughout history and its nuanced contemporary uptake alongside pervasive Information warfare – all elements that must amalgamate towards shaping appropriate responses additionally international regulatory framework as touchstone.³\nV. INTERNATIONAL TREATIES AND AGREEMENTS\n³ \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nTowering amidst the intricate landscape of global governance, a series of international treaties acts as barriers against emerging threats while information security plays a central role in contemporary diplomatic discourse. Many notable treaties, such as the Geneva Conventions and International Covenant on Civil and Political Rights have always demonstrated an imperative need to preserve information, especially during times of war. But the emergence of deepfake technology creates new problems for each one of these old agreements. The Geneva Conventions, developed in the wake of World War II were mainly aimed at protecting individuals during armed conflicts.⁴ However, although these conventions touch upon the manipulation of information to a degree, they lack specific provisions for the intricacies of contemporary information warfare and deepfake-led disinformation campaigns. Just as the International Covenant on Civil and Political Rights, which highlights freedom of speech rights attempts in finding a way to strike balance between this right and mitigation, deepfakes use for political manipulation.\nWith the complexity of international treaties, we must analyze how these frameworks apply to emerging technologies. One of such instruments is the Treaty on Open Skies⁵ that was conceived to facilitate transparency and confidence-building measures among member states. Although the treaty allows for aerial surveillance to check military activities, it does not consider how these media could be manipulated and used as tools in information warfare. The assessment of the gaps present in existing treaties uncovers a necessity for an elaborate document, which would focus on deepfake technology as well as its relation to international relations. But as the processes of negotiations go on, this must include an evaluation of whether existing treaties are sufficiently sophisticated to provide safeguards against weaponization through deepfakes and attempt engagement with achieving such innovation.\n⁴ Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n⁵ Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\n# VI. LEGAL CHALLENGES IN ADDRESSING DEEPFAKE IN INTERNATIONAL TREATIES\nWith the proliferation of deepfake technology that blurs the limits between truth and reality, law becomes complicated when applying these topics to international treaties. By analyzing issues of jurisdiction to prosecute deepfake cases, one can see the complications that underlie transnational events. For example, the case of *R v. Varma*⁶ in India 2020 had a jurisdictional challenge when an individual was implicated through deepfake video showing him committing fictitious illegal acts worldwide. In the absence of clear jurisdictional parameters, pursuing legal action against perpetrators was challenging while calling for a unified international strategy. An essential element of legal proceedings, attribution becomes harder and harder in the framework of deepfake assault. The 2018 \"Putin on the Beach\" deepfake incident, which portrayed the Russian President engaged in actions that had never occurred via AI-generated videos highlights this dilemma.⁷ However, the inability to pinpoint such origins also poses questions of accountability which become particularly perplexing when deepfakes can be produced and released anonymously. These challenges jeopardize traditional legal norms grounded on identifying wrongdoers, prompting a critical review of attribution approaches within the context of international conventions.\nThe existing legal frameworks are put into question of their capability to deal with the sophisticated threats deepfakes proffer. One of the pertinent examples is the United Nations Convention against Transnational Organized Crime, commonly referred to as Palermo Convention.⁸ Initially designed to tackle organized crime, its potential of dealing with deepfake crimes is doubtful. Though technologically facilitated crimes are not\n⁶  UKSC 42\n⁷ \"A brief history of fake news,\" BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q .\n⁸ Izabella Kaminska, \"A lesson in fake news from the info-wars of ancient Rome,\" Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nexplicitly dealt with in the Convention, interpretations can leave behind obstacles to international prosecution and cooperation of dangerous deepfakers across borders. However, the deliberate application of deepfake technologies might constitute a breach of international law and particularly nonintervention principles. Although not specifically outlawed, such calculated use of deepfakes to cause interference in a foreign state's domestic affairs could be considered illegal intervention as defined by the customary international law. The various recent practices of states demonstrate an increasing recognition that manipulation of electoral systems is illegal intervention. Yet, the ambiguities of attributing deepfake to a particular state and fragmentation regarding its multiplicity can hinder assignation responsibility. In the context of armed conflict, in accordance with international law on military operations deepfakes dissemination is to ensure due diligence aimed at protecting civilians causing harm. Deep fakes in hybrid warfare, involving traditional military operations and covert forms of waging a conflict at the same time provide additional legal challenges more often than not when establishing some sort of 'legal gray zone' that confuses declaring anything as such.⁹ In turn, the defending state is put in a dilemma between peaceable means and the threat to be met with armed response should hybrid threats prevail. Thus, it is clear that the transforming nature of deepfake technology requires a reconsideration of legal doctrine and its flexibility within an international treaties framework. When it comes to dealing with jurisdictional, attribution and framework dilemmas in the quest for justice associated with deepfake-related crimes, collaborative efforts – specifically international task forces and specialized tribunals could be crucial.\n## VII. CASE STUDIES\n### A. The Pelosi Video Controversy (2021):\n⁹ Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe use of a manipulated deepfake video appeared in 2021.¹⁰ It emphasized the destabilizing capacity of deepfakes. Although the viral nature of the video was a major problem, legal action did not flow easily due to jurisdictional issues. Indian and foreign cases are discussed in context of the Verma case that was brought for India's court, and U.S. v. Doe¹¹ precedent represents an evident difficulty to attribute liability across borders.¹² The incident underscored the requirement for more defined jurisdictional international norms when prosecuting deepfake crimes.\n## B. The Navalny Poisoning Deepfake (2022):\nIn 2022, a deepfake video emerged which showed Russian opposition leader Alexei Navalny denying an attempted poisoning. It also prompted questions regarding the use of deepfakes within political propaganda. Previous international treaties, such as the Chemical Weapons Convention failed to address issues pertaining weaponized influencing media. This case revealed that the need to amend treaty content for digital risks of threat and political stability is urgent. Legal scholars urged rethinking of the Chemical Weapons Convention to include deepfakes-based disinformation campaign provisions.\n## C. The EU Diplomatic Summit Incident (2019):\nDuring the EU diplomatic summit, a deepfake video emerged which featured leaders in compromising positions. While the diplomatic backlash is possible, legal options were limited because treaties like Vienna Convention on Diplomatic Relations did not foresee media weaponization.¹³ The scenario highlighted the importance for international\n¹⁰ \"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\" Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI .\n¹¹ 465 U.S. 605 (1984)\n¹² Robert Chesney and Danielle Citron, \"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\" Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy .\n¹³ Robert Chesney and Danielle Citron, \"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\" Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118 .\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\ntreaties to react quickly with all emerging threats. Scholars called for provisions in diplomatic conventions to be incorporated preventing abuse of deepfake technology destroying the sanctity of diplomacy.\n## D. Rashmika Mandanna Deepfake video\nThe Delhi Police Special Cell on Friday filed an FIR in connection with the deepfake AI-generated video of actor Rashmika Mandanna. This week, a deepfake video depicting the actor in black exercise clothing inside an elevator spread through X and other social media sites. Zara's face was digitally manipulated and edited to Rashmika using powerful AI techniques. This FIR has been registered under Sections 465 (punishment for fraud) and 469 (forgery to slander or discredit a party), IPC 1860, as well as Section 70 of the IT Act. With respect to the deep fake AI-generated video of Rashmika Mandanna, an FIR u/s 465 and 469 of IPC,1860; section 67C and E in IT Act 2000 has been filed at PS Special Cell Delhi Police, Investigation onwards.\nThese case studies shed a beam of light upon the multi-dimensional complexity spawned by deepfake technology in international relations. They emphasize the shortcomings of present legal constructs and advocate an active strategy to improve international accords, adding clauses that target deepfake related difficulties. As we analyze these cases, the legal world must learn lessons that will help strengthen global legal systems in this dynamic context of information warfare.\n## VIII. POLICY RECOMMENDATIONS\nWhen considering the challenges of deepfake technology, a number of critical policy directives emerge for discussion. In India, a proactive approach means changing the existing law such as the Information Technology Act. When the digital image of an individual is transmitted or disseminated in mass media, violating its privacy, section 66E of IT Act applies.¹⁴ The punishment for this crime is imprisonment up to three years\n¹⁴ Information Technology (Amendment) Act, 2008, § 66E.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nor a fine of ₹2 lakh. One as well is the Section 66D of IT Act.¹⁵ It offers a provision to prosecute an individual who uses communication devices or computer resources for unlawful purposes such as cheating, impersonation that may warrant imprisonment up to three years and/or fine upto ₹1 lakh. It is possible to prosecute the people who perpetrated deepfake cyber-attacks in India through these parts of the IT Act. This would include amendments to the Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, making platforms responsible for malicious deepfakes dissemination. In the United States, a synergic legal backdrop could be created by adding deepfake-related offenses to CFAA thus creating a firm base for prosecuting those who exploit them for impinging on national security or public figures.¹⁶ Also, the UK can improve its legal system by proposing amendments to Communications Act and enactment of legislation punishing citizens using deepfake technology in order to cheat public or sway democratic actions. Further, in 2023 Congress introduced the DEEP FAKES Accountability Bill that obliges deepfakes creators to mark their creations on online platforms and notifications of amendments provided about a specific video or other material. If such 'malicious deepfakes' are not labeled, the act of failure would be punishable under criminal law.\nIn January, the Cyberspace Administration of China introduced new rules limiting deep synthesis technology and combating misinformation. This policy allows any manipulated material through the technology to be marked and identifiable back in its source. Given the local laws, deep synthesis service providers should also retain ethics and keep correct political direction and public opinion orientation. The most advanced artificial intelligence regulations in the world will come to a stand-or-fall juncture for Europe. Social media giants like Google, Meta, and Twitter have been warned to start\n¹⁵ Information Technology (Amendment) Act, 2008, § 66D.\n¹⁶ Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nwarning against the deepfake content or risk paying huge fines by the EU because they tightened their Code of Practice on Disinformation. The Code was initially introduced as a voluntary self-regulation tool in 2018, but will now be supported by the Digital Services Act that seeks to promote monitoring of digital platforms for control of different forms of abuse. Second, the EU AI Act proposal would hold deepfake providers liable under disclosure obligations.\nCollaboration, therefore, is vital at the international stage. A possible Global Cybersecurity Agreement devised by major players such as India, the U.S., and the UK could develop a single platform that can be used to combat cyber threats including special provisions targeting deepfake technology for information warfare purposes. At the same time, a Transparency and Attribution Accord may be adopted, focusing on transparency with respect to the creation of AI technologies such as deepfakes.¹⁷ This multilateral deal would promote interstate collaboration on tracking back the origin of deepfake incidents and thus, address limitations in allocating blame across nations. Human rights and ethics must be part of every policy making. Policies alignment with constitutional principles in India means drafting safeguards to uphold such human rights as privacy and freedom of speech. A strong ethical framework can direct the development and usage of deepfake technology responsibly. In the same manner, in America ethical issues may be incorporated into policies to ensure that laws uphold constitutional rights. An establishment of a federal body such as the Privacy and Civil Liberties Oversight Board could analyze ethical implications in emerging technologies like deepfakes. In the United Kingdom, policies should focus on human rights and while Information Commissioner's Office (ICO) plays a crucial role in ensuring that deepfakes regulations are aligned to the pledge of protecting individual freedoms including privacy and freedom of expression.¹⁸ These policy recommendations, when implemented collectively, aim to find a delicate\n¹⁷ Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.\n¹⁸ Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nmiddle ground between the need for legal structures aimed at fighting deepfake threats and the obligation towards maintaining human rights as well as democratic values. Implementing these recommendations at the national and international levels is imperative for strengthening global efforts to address the complexity of challenges brought by deepfake technology in the field of IR.\n# IX. FUTURE OUTLOOK\nThe future of deepfake technology seems to be one where it will become more advanced, thus making the difference between altered content and reality more difficult. The availability of AI algorithms powering the deepfake is predicted to increase, allowing abuses with little resources they need. This development, however, foreshadows the possibility of an increase in targeted deepfake campaigns around the world focusing on political leaders and institutions that breed distrust by undermining social cohesion everywhere including India.¹⁹ The adaptation of legal frameworks to effectively counter deepfake technology poses major challenges for India. Although some provisions do exist in the Information Technology Act, amendments may still need to be made when taking into account the complexity of deepfake-related offenses. Some of the projected challenges include setting up distinct lines for freedom of expression, liability in case offenders are platform owners and international jurisdiction protocols to send culprits behind bars.\nViewed from a global point of view, legal regimes globally may be unable to adapt quickly enough as technology develops at an extremely fast rate. The issues include getting the right kind of punishment for crimes committed with a deepfake, developing standard attribution’s mechanism and encouraging international cooperation in\n¹⁹ Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nprosecuting such offenses. The harmonization of legal approaches across jurisdictions becomes a necessity to eliminate gaps between them that could be used by fraudsters. The importance of international coordination cannot be overstated with respect to the threats posed by deepfake technology. India's active participation in international forums is essential as a means of developing collective responses. By facilitating the exchange of best practices, technological expertise and intelligence to combat cross-border deepfake incidents, bilateral and multilateral engagements can promote such cooperation. India's resilience against such global deepfake threats can be increased through collaborative efforts with countries like the United States and the United Kingdom.\nConsidering the borderless nature of cyberspace, there is a need to have collaborative frameworks for sharing threat intelligence, coordinating investigations and harmonizing legal standards in order to facilitate global collaboration. India's involvement in international cybersecurity projects makes it an ideal candidate to play a major role in defining and guiding these shared ventures. However, as we move into the future deepfake technology will also require continued flexibility in legal frameworks and increased international coordination. As part of the international community, India must take a proactive approach towards influencing policies and formulating alliances to tackle deepfake's potential threats on external relations and democratic procedures.\n# X. CONCLUSION\nThe author would like to conclude that this study emphasizes the urgency of preventative approaches towards adapting international treaties to a changing setting comprising information warfare and deepfake technology. As the study of case studies, legal battles and policies indicates, we face a fundamentally new nature of contemporary threats to global balance. The identified key findings reflect the worrisome effects created by deepfakes involving international relations across various countries like Pelosi video controversy and Navalny poisoning. Jurisdictional and attribution issues remain, demanding treaty amendments to address the peculiarities of international cybercrimes.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)\nLawFoyer International Journal of Doctrinal Legal Research\n[Vol. I Issue IV]\nThe development of new international agreements specific to emerging technologies, as reflected in such plans like the Global Cybersecurity Agreement cannot be overemphasized. However, the development of deepfake technology also requires an evolution of our legal frameworks to prevent malicious individuals and preserve global discourse. Adaptations in the areas of ethics, human rights and international cooperation should continue to be at the core. During this period of rapid technological change, international treaty strengthening is necessary to maintain the pillars on which diplomatic reciprocities stand in terms of truth and credibility. Failure to deal with these problems adequately would jeopardize the very basis of a stable and trusted world order.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research\n(ISSN: 2583-7753)"
    },
    "author_year": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [],
      "flat_text": "HEINONLINE DATE DOWNLOADED: Thu Jul 3 08:22:57 2025 SOURCE: Content Downloaded from HeinOnline ## Citations: Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\n## Bluebook 21st ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LAWFOYER INT'L J. DOCTRINAL LEGAL RSCH. 363 (2024).\n## ALWD 7th ed.\nShraddha Tiwari, Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis, 1 LawFoyer Int'l J. Doctrinal Legal Rsch. 363 (2024).\n## APA 7th ed.\nTiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.\n## Chicago 17th ed.\nShraddha Tiwari,\"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis,\"LawFoyer International Journal of Doctrinal Legal Research 1, no. 4 (2024): 363-376 ## McGill Guide 10th ed.\nShraddha Tiwari,\"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis\"(2024) 1:4 LawFoyer Int'l J Doctrinal Legal Rsch 363.\n## AGLC 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1(4) LawFoyer International Journal of Doctrinal Legal Research 363 ## MLA 9th ed.\nTiwari, Shraddha.\"Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis.\"LawFoyer International Journal of Doctrinal Legal Research, vol. 1, no. 4, 2024, pp. 363-376. HeinOnline.\n## OSCOLA 4th ed.\nShraddha Tiwari, 'Unraveling the Impact of Deepfakes on International Conflict through the Lens of Information Warfare: An Analysis' (2024) 1 LawFoyer Int'l J Doctrinal Legal Rsch 363 x Please note: citations are provided as a general guideline. Users should consult their preferred citation format's style manual for proper citation formatting.\nLawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] # UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS Shraddha Tiwari¹ ## I. ABSTRACT The emergence of deepfake technology in modern international context poses unprecedented threats to conventional frameworks for truth and originality. This legal paper on deepfake emphasizes the wide range of consequences that this phenomenon has not only concerning international agreements, diplomatic relations and security arrangements but also with respect to interrelations among states. Through revealing the history of deepfake development, this paper emphasizes its revolutionary effect on world affairs and especially for a part as an effective tool in the information warfare armory. The study conducts a critical analysis of international conventions, including the Geneva Conventions and International Covenant on Civil and Political Rights to evaluate their effectiveness in dealing with threats posed by deepfakes. Common examples of the key problems in contemporary legal frameworks are highlighted through case studies that present high-profile incidents such as The Pelosi Video Controversy, Navalny Poisoning Deepfake and EU Diplomatic Summit Incident drawing attention to a specialized approach needed for addressing deepfakes technology.\nThe paper makes policy recommendations, suggesting the necessary amendments to existing treaties and new international agreements targeted at emerging technologies. Cultural specifics for India, the United States of America and Great Britain are discussed, pointing out an importance that ethics and human rights issues have in the formation of legal framework. The recommendations attempt to simultaneously achieve the efficacy of legal measures enabling a fight against threats posed by deepfake and maintain individual rights for freedoms while respecting democratic values. The paper discusses ¹ Student at Christ University.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] the necessity of international cooperation and also predicts the continuous evolution of deepfake, the challenges in forming a legal framework for the same and its execution both at national and Global level. It focuses on the variegated field of AI surveillance, analyzing its security impacts, scope opportunities as well as challenges in connection with international relations perspective. With the world's security framework adopting AI surveillance, this study offers a critical analysis of legal and ethical aspects surrounding its implementation. Special attention is given to the new role of technology companies, in which technological advancements need to be balanced with legal safeguards and ethical norms. The paper seeks to contribute ongoing discourses by unpacking the complex balance between AI surveillance, security pressures and responsibilities of critical actors in the digital era. The policy recommendations advocated by the author are essentially for legislative amendments in India's Information Technology Act, inclusion of deepfake related offenses in the legal system. Moreover, international collaboration is proposed through a Global Cybersecurity Agreement and a Transparency and Attribution Accords. Incorporation of human rights and ethics into policy frameworks to address the challenges posed by deepfake technology among countries and globally. The author concludes the paper by emphasizing the need for urgent and proactive measures to adopt international treaties and prevent information warfare and international conflicts among the countries in the near future.\n## II. KEYWORDS: Deepfakes, Information warfare, International conflicts, International treaties, Global level, India, US, UK ## III. INTRODUCTION The development of deepfake technology in modern international affairs represents a major threat to the conventional concepts of reality and originality. However, deepfakes—highly advanced altered media material that is virtually indistinguishable from actual recordings—are now powerful weapons in the information warfare arsenal. This modern form of information warfare has emerged from a widespread and effective © 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] use to manipulate the correct course of events, aimed at influencing people's political decisions. It is worth noting that the term\"deepfake\"emerged from two words – deep learning ad fake, showing how new technologies based on artificial intelligence are used to create falsified content such as forged videos or audio recordings.² This study focuses on the complex ramifications of deepfakes in international treaties, where this technological phenomenon overlaps not only with diplomatic relations but also security agreements and cooperation principles.\nIn the background of efforts to control and preserve equilibrium in international affairs, deepfake technology presents a unique problem. Malicious use of deepfakes that deliberately spread fake or tampered information can undermine the honesty at diplomatic negotiations, deteriorate national safety and increased rivalries between states. This paper seeks to investigate how current international agreements protect against the new risks posed by deepfakes and assess their ability to adjust in light of information warfare trends that are characterized by rapid technological developments. The study is contemporary, because the world faces an emerging threat – that of deepfake technological development and how it might affect diplomacy. Analyzing the situation with international treaties in this regard, this research attempts to assist ongoing discussion about strengthening legal frameworks that protect reliability and sustainability of international relations facing new threats. This paper analyzed the security ramifications as well as opportunities and challenges that are posed by deepfake technology will be discussed in detail on how it affects diplomatic relations. The research will also explore the relevant legal and ethical issues that form a part of ongoing discussions regarding measures for preservation of world stability amidst technological advances.\nIV. BACKGROUND ² Tom Simonite, “A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be,” WIRED, March 17, 2022, https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook/.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] Deepfake technology's historical development goes back to artificial intelligence and machine learning innovations. The emergence of deep learning algorithms from the late 2010s opened up opportunities for synthesizing life-like audio and visual material. Deepfakes, which were first developed for entertainment purposes, soon turned into a powerful means of affecting international relations.\nIn recent years, deepfake cases have risen leading to dramatic shifts in diplomatic terrain. Some cases include modified videos depicting politicians using offensive statements or performing fake activities. These events propagated via social media and online networks have the capability to spoil sports, demolish public confidence along with exacerbating geopolitical problems. Now the 21st-century information system is faced with synthetic media such as deepfakes, a new form of disinformation that undermines our certainty about what happened and poses an additional layer to global discourse. At the same time, Information warfare is on the rise in the international arena and defines modern geopolitics. State and non-state actors use information as a strategic instrument, spreading disinformation so that they can undermine public opinion in order to disrupt the political process of other nations. Information warfare has successfully established itself as an integral part of international relations and politics; global conflicts have changed the ways. The point of the crossroads in terms of international relations is between deepfake technology and information warfare. As nations attempt to come into terms with the aftermath of manipulated media in this diplomatic forum, it is also needful for them to understand how deep fake evolved throughout history and its nuanced contemporary uptake alongside pervasive Information warfare – all elements that must amalgamate towards shaping appropriate responses additionally international regulatory framework as touchstone.³ V. INTERNATIONAL TREATIES AND AGREEMENTS ³\"A brief history of fake news,\"BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] Towering amidst the intricate landscape of global governance, a series of international treaties acts as barriers against emerging threats while information security plays a central role in contemporary diplomatic discourse. Many notable treaties, such as the Geneva Conventions and International Covenant on Civil and Political Rights have always demonstrated an imperative need to preserve information, especially during times of war. But the emergence of deepfake technology creates new problems for each one of these old agreements. The Geneva Conventions, developed in the wake of World War II were mainly aimed at protecting individuals during armed conflicts.⁴ However, although these conventions touch upon the manipulation of information to a degree, they lack specific provisions for the intricacies of contemporary information warfare and deepfake-led disinformation campaigns. Just as the International Covenant on Civil and Political Rights, which highlights freedom of speech rights attempts in finding a way to strike balance between this right and mitigation, deepfakes use for political manipulation.\nWith the complexity of international treaties, we must analyze how these frameworks apply to emerging technologies. One of such instruments is the Treaty on Open Skies⁵ that was conceived to facilitate transparency and confidence-building measures among member states. Although the treaty allows for aerial surveillance to check military activities, it does not consider how these media could be manipulated and used as tools in information warfare. The assessment of the gaps present in existing treaties uncovers a necessity for an elaborate document, which would focus on deepfake technology as well as its relation to international relations. But as the processes of negotiations go on, this must include an evaluation of whether existing treaties are sufficiently sophisticated to provide safeguards against weaponization through deepfakes and attempt engagement with achieving such innovation.\n⁴ Robert Chesney and Danielle Citron, “Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,” Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n⁵ Open Skies Treaty, March 24, 1992, 1843 U.N.T.S. 338, Unites States of America.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] # VI. LEGAL CHALLENGES IN ADDRESSING DEEPFAKE IN INTERNATIONAL TREATIES With the proliferation of deepfake technology that blurs the limits between truth and reality, law becomes complicated when applying these topics to international treaties. By analyzing issues of jurisdiction to prosecute deepfake cases, one can see the complications that underlie transnational events. For example, the case of *R v. Varma*⁶ in India 2020 had a jurisdictional challenge when an individual was implicated through deepfake video showing him committing fictitious illegal acts worldwide. In the absence of clear jurisdictional parameters, pursuing legal action against perpetrators was challenging while calling for a unified international strategy. An essential element of legal proceedings, attribution becomes harder and harder in the framework of deepfake assault. The 2018\"Putin on the Beach\"deepfake incident, which portrayed the Russian President engaged in actions that had never occurred via AI-generated videos highlights this dilemma.⁷ However, the inability to pinpoint such origins also poses questions of accountability which become particularly perplexing when deepfakes can be produced and released anonymously. These challenges jeopardize traditional legal norms grounded on identifying wrongdoers, prompting a critical review of attribution approaches within the context of international conventions.\nThe existing legal frameworks are put into question of their capability to deal with the sophisticated threats deepfakes proffer. One of the pertinent examples is the United Nations Convention against Transnational Organized Crime, commonly referred to as Palermo Convention.⁸ Initially designed to tackle organized crime, its potential of dealing with deepfake crimes is doubtful. Though technologically facilitated crimes are not ⁶ [2012] UKSC 42 ⁷\"A brief history of fake news,\"BBC News, December 4, 2020, https://www.bbc.co.uk/bitesize/articles/zwcgn9q.\n⁸ Izabella Kaminska,\"A lesson in fake news from the info-wars of ancient Rome,\"Financial Times, January 17, 2017, https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] explicitly dealt with in the Convention, interpretations can leave behind obstacles to international prosecution and cooperation of dangerous deepfakers across borders. However, the deliberate application of deepfake technologies might constitute a breach of international law and particularly nonintervention principles. Although not specifically outlawed, such calculated use of deepfakes to cause interference in a foreign state's domestic affairs could be considered illegal intervention as defined by the customary international law. The various recent practices of states demonstrate an increasing recognition that manipulation of electoral systems is illegal intervention. Yet, the ambiguities of attributing deepfake to a particular state and fragmentation regarding its multiplicity can hinder assignation responsibility. In the context of armed conflict, in accordance with international law on military operations deepfakes dissemination is to ensure due diligence aimed at protecting civilians causing harm. Deep fakes in hybrid warfare, involving traditional military operations and covert forms of waging a conflict at the same time provide additional legal challenges more often than not when establishing some sort of 'legal gray zone' that confuses declaring anything as such.⁹ In turn, the defending state is put in a dilemma between peaceable means and the threat to be met with armed response should hybrid threats prevail. Thus, it is clear that the transforming nature of deepfake technology requires a reconsideration of legal doctrine and its flexibility within an international treaties framework. When it comes to dealing with jurisdictional, attribution and framework dilemmas in the quest for justice associated with deepfake-related crimes, collaborative efforts – specifically international task forces and specialized tribunals could be crucial.\n## VII. CASE STUDIES ### A. The Pelosi Video Controversy (2021): ⁹ Greg Allen and Taniel Chan, “Artificial Intelligence and National Security,” (Cambridge: Belfer Center for Science and International Affairs, July 2017), https://www.belfercenter.org/publication/artificial-intelligence-and-national-security.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] The use of a manipulated deepfake video appeared in 2021.¹⁰ It emphasized the destabilizing capacity of deepfakes. Although the viral nature of the video was a major problem, legal action did not flow easily due to jurisdictional issues. Indian and foreign cases are discussed in context of the Verma case that was brought for India's court, and U.S. v. Doe¹¹ precedent represents an evident difficulty to attribute liability across borders.¹² The incident underscored the requirement for more defined jurisdictional international norms when prosecuting deepfake crimes.\n## B. The Navalny Poisoning Deepfake (2022): In 2022, a deepfake video emerged which showed Russian opposition leader Alexei Navalny denying an attempted poisoning. It also prompted questions regarding the use of deepfakes within political propaganda. Previous international treaties, such as the Chemical Weapons Convention failed to address issues pertaining weaponized influencing media. This case revealed that the need to amend treaty content for digital risks of threat and political stability is urgent. Legal scholars urged rethinking of the Chemical Weapons Convention to include deepfakes-based disinformation campaign provisions.\n## C. The EU Diplomatic Summit Incident (2019): During the EU diplomatic summit, a deepfake video emerged which featured leaders in compromising positions. While the diplomatic backlash is possible, legal options were limited because treaties like Vienna Convention on Diplomatic Relations did not foresee media weaponization.¹³ The scenario highlighted the importance for international ¹⁰\"Fact check: 'Drunk' Nancy Pelosi video is manipulated,\"Reuters, August 3, 2020, https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI.\n¹¹ 465 U.S. 605 (1984) ¹² Robert Chesney and Danielle Citron,\"Deepfakes: A Looming Crisis for National Security, Democracy and Privacy?,\"Lawfare, February 21, 2018, https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy.\n¹³ Robert Chesney and Danielle Citron,\"Deepfakes and the New Disinformation War: The Coming Age of Post-Truth Geopolitics,\"Foreign Affairs, January/ February 2019, https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] treaties to react quickly with all emerging threats. Scholars called for provisions in diplomatic conventions to be incorporated preventing abuse of deepfake technology destroying the sanctity of diplomacy.\n## D. Rashmika Mandanna Deepfake video The Delhi Police Special Cell on Friday filed an FIR in connection with the deepfake AI-generated video of actor Rashmika Mandanna. This week, a deepfake video depicting the actor in black exercise clothing inside an elevator spread through X and other social media sites. Zara's face was digitally manipulated and edited to Rashmika using powerful AI techniques. This FIR has been registered under Sections 465 (punishment for fraud) and 469 (forgery to slander or discredit a party), IPC 1860, as well as Section 70 of the IT Act. With respect to the deep fake AI-generated video of Rashmika Mandanna, an FIR u/s 465 and 469 of IPC,1860; section 67C and E in IT Act 2000 has been filed at PS Special Cell Delhi Police, Investigation onwards.\nThese case studies shed a beam of light upon the multi-dimensional complexity spawned by deepfake technology in international relations. They emphasize the shortcomings of present legal constructs and advocate an active strategy to improve international accords, adding clauses that target deepfake related difficulties. As we analyze these cases, the legal world must learn lessons that will help strengthen global legal systems in this dynamic context of information warfare.\n## VIII. POLICY RECOMMENDATIONS When considering the challenges of deepfake technology, a number of critical policy directives emerge for discussion. In India, a proactive approach means changing the existing law such as the Information Technology Act. When the digital image of an individual is transmitted or disseminated in mass media, violating its privacy, section 66E of IT Act applies.¹⁴ The punishment for this crime is imprisonment up to three years ¹⁴ Information Technology (Amendment) Act, 2008, § 66E.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] or a fine of ₹2 lakh. One as well is the Section 66D of IT Act.¹⁵ It offers a provision to prosecute an individual who uses communication devices or computer resources for unlawful purposes such as cheating, impersonation that may warrant imprisonment up to three years and/or fine upto ₹1 lakh. It is possible to prosecute the people who perpetrated deepfake cyber-attacks in India through these parts of the IT Act. This would include amendments to the Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, making platforms responsible for malicious deepfakes dissemination. In the United States, a synergic legal backdrop could be created by adding deepfake-related offenses to CFAA thus creating a firm base for prosecuting those who exploit them for impinging on national security or public figures.¹⁶ Also, the UK can improve its legal system by proposing amendments to Communications Act and enactment of legislation punishing citizens using deepfake technology in order to cheat public or sway democratic actions. Further, in 2023 Congress introduced the DEEP FAKES Accountability Bill that obliges deepfakes creators to mark their creations on online platforms and notifications of amendments provided about a specific video or other material. If such 'malicious deepfakes' are not labeled, the act of failure would be punishable under criminal law.\nIn January, the Cyberspace Administration of China introduced new rules limiting deep synthesis technology and combating misinformation. This policy allows any manipulated material through the technology to be marked and identifiable back in its source. Given the local laws, deep synthesis service providers should also retain ethics and keep correct political direction and public opinion orientation. The most advanced artificial intelligence regulations in the world will come to a stand-or-fall juncture for Europe. Social media giants like Google, Meta, and Twitter have been warned to start ¹⁵ Information Technology (Amendment) Act, 2008, § 66D.\n¹⁶ Henry Farrell, Abraham Newman, and Jeremy Wallace, “Spirals of Delusion,” Foreign Affairs, September/October 2022, https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] warning against the deepfake content or risk paying huge fines by the EU because they tightened their Code of Practice on Disinformation. The Code was initially introduced as a voluntary self-regulation tool in 2018, but will now be supported by the Digital Services Act that seeks to promote monitoring of digital platforms for control of different forms of abuse. Second, the EU AI Act proposal would hold deepfake providers liable under disclosure obligations.\nCollaboration, therefore, is vital at the international stage. A possible Global Cybersecurity Agreement devised by major players such as India, the U.S., and the UK could develop a single platform that can be used to combat cyber threats including special provisions targeting deepfake technology for information warfare purposes. At the same time, a Transparency and Attribution Accord may be adopted, focusing on transparency with respect to the creation of AI technologies such as deepfakes.¹⁷ This multilateral deal would promote interstate collaboration on tracking back the origin of deepfake incidents and thus, address limitations in allocating blame across nations. Human rights and ethics must be part of every policy making. Policies alignment with constitutional principles in India means drafting safeguards to uphold such human rights as privacy and freedom of speech. A strong ethical framework can direct the development and usage of deepfake technology responsibly. In the same manner, in America ethical issues may be incorporated into policies to ensure that laws uphold constitutional rights. An establishment of a federal body such as the Privacy and Civil Liberties Oversight Board could analyze ethical implications in emerging technologies like deepfakes. In the United Kingdom, policies should focus on human rights and while Information Commissioner's Office (ICO) plays a crucial role in ensuring that deepfakes regulations are aligned to the pledge of protecting individual freedoms including privacy and freedom of expression.¹⁸ These policy recommendations, when implemented collectively, aim to find a delicate ¹⁷ Lourdes Vasquez, “Recommendations for the Regulation of Deepfakes in the U.S.: Deepfake Laws Should Protect Everyone Not Only Public Figures” (unpublished manuscript, 2021),7.\n¹⁸ Ali Breland, “The Bizarre and Terrifying Case of the ‘Deepfake’ Video that Helped Bring an African Nation to the Brink,” Mother Jones, March 15, 2019, https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo © 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] middle ground between the need for legal structures aimed at fighting deepfake threats and the obligation towards maintaining human rights as well as democratic values. Implementing these recommendations at the national and international levels is imperative for strengthening global efforts to address the complexity of challenges brought by deepfake technology in the field of IR.\n# IX. FUTURE OUTLOOK The future of deepfake technology seems to be one where it will become more advanced, thus making the difference between altered content and reality more difficult. The availability of AI algorithms powering the deepfake is predicted to increase, allowing abuses with little resources they need. This development, however, foreshadows the possibility of an increase in targeted deepfake campaigns around the world focusing on political leaders and institutions that breed distrust by undermining social cohesion everywhere including India.¹⁹ The adaptation of legal frameworks to effectively counter deepfake technology poses major challenges for India. Although some provisions do exist in the Information Technology Act, amendments may still need to be made when taking into account the complexity of deepfake-related offenses. Some of the projected challenges include setting up distinct lines for freedom of expression, liability in case offenders are platform owners and international jurisdiction protocols to send culprits behind bars.\nViewed from a global point of view, legal regimes globally may be unable to adapt quickly enough as technology develops at an extremely fast rate. The issues include getting the right kind of punishment for crimes committed with a deepfake, developing standard attribution’s mechanism and encouraging international cooperation in ¹⁹ Jason Lyall, Divided Armies: Inequality and Battlefield Performance in Modern War (Princeton University Press, 2020).\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] prosecuting such offenses. The harmonization of legal approaches across jurisdictions becomes a necessity to eliminate gaps between them that could be used by fraudsters. The importance of international coordination cannot be overstated with respect to the threats posed by deepfake technology. India's active participation in international forums is essential as a means of developing collective responses. By facilitating the exchange of best practices, technological expertise and intelligence to combat cross-border deepfake incidents, bilateral and multilateral engagements can promote such cooperation. India's resilience against such global deepfake threats can be increased through collaborative efforts with countries like the United States and the United Kingdom.\nConsidering the borderless nature of cyberspace, there is a need to have collaborative frameworks for sharing threat intelligence, coordinating investigations and harmonizing legal standards in order to facilitate global collaboration. India's involvement in international cybersecurity projects makes it an ideal candidate to play a major role in defining and guiding these shared ventures. However, as we move into the future deepfake technology will also require continued flexibility in legal frameworks and increased international coordination. As part of the international community, India must take a proactive approach towards influencing policies and formulating alliances to tackle deepfake's potential threats on external relations and democratic procedures.\n# X. CONCLUSION The author would like to conclude that this study emphasizes the urgency of preventative approaches towards adapting international treaties to a changing setting comprising information warfare and deepfake technology. As the study of case studies, legal battles and policies indicates, we face a fundamentally new nature of contemporary threats to global balance. The identified key findings reflect the worrisome effects created by deepfakes involving international relations across various countries like Pelosi video controversy and Navalny poisoning. Jurisdictional and attribution issues remain, demanding treaty amendments to address the peculiarities of international cybercrimes.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753) LawFoyer International Journal of Doctrinal Legal Research [Vol. I Issue IV] The development of new international agreements specific to emerging technologies, as reflected in such plans like the Global Cybersecurity Agreement cannot be overemphasized. However, the development of deepfake technology also requires an evolution of our legal frameworks to prevent malicious individuals and preserve global discourse. Adaptations in the areas of ethics, human rights and international cooperation should continue to be at the core. During this period of rapid technological change, international treaty strengthening is necessary to maintain the pillars on which diplomatic reciprocities stand in terms of truth and credibility. Failure to deal with these problems adequately would jeopardize the very basis of a stable and trusted world order.\n© 2024. LawFoyer International Journal of Doctrinal Legal Research (ISSN: 2583-7753)"
    }
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 38.0,
      "success_occurrences": 38.0,
      "success_unique": 19.0,
      "bib_unique_total": 19.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 1.0,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 38.0,
        "success_occurrences": 38.0,
        "success_unique": 19.0,
        "bib_unique_total": 19.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 1.0,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 1.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "UNRAVELING THE IMPACT OF DEEPFAKES ON INTERNATIONAL CONFLICT THROUGH THE LENS OF INFORMATION WARFARE: AN ANALYSIS",
    "subtitle": "",
    "document_type": "journal_article",
    "venue": "Tiwari, Shraddha. (2024). Unraveling the impact of deepfakes on international conflict through the lens of information warfare: an analysis. LawFoyer International Journal of Doctrinal Legal Research, 1(4), 363-376.",
    "publication_year": 2024,
    "authors": [
      "Shraddha Tiwari"
    ],
    "affiliations": [],
    "emails": [],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [],
    "publication_dates": {},
    "identifiers": {
      "doi": [],
      "issn": [
        "ISSN: 2583-7753"
      ],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "https://www.wired.com/story/zelensky-deepfake-facebook-twitter-playbook",
        "https://www.bbc.co.uk/bitesize/articles/zwcgn9q",
        "https://www.lawfareblog.com/deepfakes-looming-crisis-national-security-democracy-and-privacy",
        "https://www.ft.com/content/aaf2bb08-dca2-11e6-86ac-f253db7791c6",
        "https://www.belfercenter.org/publication/artificial-intelligence-and-national-security",
        "https://www.reuters.com/article/uk-factcheck-nancypelosi-manipulated/fact-check-drunk-nancy-pelosi-video-is-manipulated-idUSKCN24Z2BI",
        "https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war?cid=otr-authors-january_february_2019-121118",
        "https://www.foreignaffairs.com/world/spirals-delusion-artificial-intelligence-decision-making",
        "https://www.motherjones.com/politics/2019/03/deepfakegabon-ali-bongo"
      ]
    },
    "references_block_count": 0,
    "references_entries_estimated": 0,
    "heading_count": 22,
    "max_heading_level": 3,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "title_looks_like_mid_paragraph_sentence",
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 38,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.42105263157894735,
      "footnote_coverage": 1.0,
      "unique_index_count": 19
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 38,
        "superscript_definition_lines": 19,
        "numeric_bracket_hits": 1,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 19.0,
      "dominant_bib_coverage_rate": 1.0,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 22,
      "max_heading_level": 3,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": false,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": false,
        "emails": false,
        "orcids": false,
        "abstract": false,
        "keywords": false,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 1,
        "affiliations": 0,
        "emails": 0,
        "orcids": 0,
        "keywords": 0,
        "doi": 0,
        "issn": 1,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 9
      },
      "coverage": {
        "core_coverage": 0.6666666666666666,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "title_looks_like_mid_paragraph_sentence",
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_abstract_and_keywords"
      ]
    },
    "flags": [
      "missing_preceding_text",
      "missing_reference_heading",
      "meta_missing_abstract_and_keywords"
    ]
  },
  "updated_at_utc": "2026-02-14T08:29:05.771914+00:00"
}