{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\4R2DQ4FK\\Hedgecock - 2021 - Strategic Attribution Target State Communications in Response to Cyber Operations.pdf",
  "custom_id": "52",
  "response": {
    "id": "batch-b6235e9e-53-54d19f8c-12d5-4d41-a496-46c1c430d24c",
    "custom_id": "52",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "# Strategic Attribution: Target State Communication in Response to Cyber Operations\n\nKathryn Hedgecock\n\nFebruary 24, 2023\n\n## Abstract\n\nThis paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 1,
            "markdown": "\"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau¹\n\n# Introduction\n\nIn December 2014, three weeks after the Sony Picture hack, the first two questions of the White House Press Briefing asked: “Does the White House believe that North Korea is behind the hack at Sony Pictures?” and “What is the United States going to do about it?”. Reporters were asking the standard questions associated with the disclosure of a hack, namely, who is responsible and how the state will respond. The press was seeking public attribution, i.e. the public assignment of blame, which is typically a prerequisite for retaliatory action. To these questions Press Secretary John Earnest subsequently responded, “this is a matter that is still under investigation...[I] am not going to get ahead of that investigation” and “before we start publicly speculating about a response, it’s appropriate that we allow the investigation to move forward”.² Press Secretary Earnest was implicitly appealing to the attribution problem –difficulty in achieving technical attribution– for why North Korea had yet to be named and no response yet taken.\n\nThe attribution problem is a central theme in the cyber literature.³ The covert and\n\n¹ Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).\n\n² Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n\n³ Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 2,
            "markdown": "technical nature of cyber operations make identifying the sponsor very difficult or, at a minimum, time and resource intensive. As a result, the literature focuses on the negative consequences associated with the attribution problem, primarily an erosion of the credibility and feasibility of deterrence by punishment.⁴ However, in this paper, I argue that a narrow focus on attribution as a problem overlooks the strategic agency that deniable attribution provides targets of cyber operations. Uncertainty in the ability and timeliness of attribution, coupled with the clandestine and covert nature of cyber operations, provide the target state three strategies of communication: collusion, disclosure, or public attribution; all of which should be viewed as intentional actions with strategic implications.\n\nThis paper contributes to the literature on covert action, cyber deterrence, and public attribution as a distinct concept. First, I advance the literature by challenging the emphasis of attribution as a “problem” in the cyber domain. Instead, I argue the attribution problem can also be a strategic asset of the target state by providing additional agency in how they respond to and communicate about cyber operations. While this strategic logic exists in covert action broadly, there are unique features of the cyber domain that heighten the target’s agency. The covert nature of most cyber operations and complexity of attribution provide plausible deniability, not only for the perpetrator, but also for the target state’s technical attribution. A target’s discretion in choosing to what extent they want to acknowledge or respond to an operation prioritizes escalation management at the expense of deterrence by punishment. Second, I extend and adapt the logic of Carson’s *Secret Wars* and Poznansky\n\nMIT Press, *International Security* 38, no. 2 (2013): 7–40; Martin C. Libicki, *Cyberdeterrence and cyberwar*, in collab. with Project Air Force (U.S.), OCLC: ocn428819545 (Santa Monica, CA: RAND, 2009); Jon R. Lindsay, “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack,” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67; Joseph S. Nye, “Deterrence and Dissuasion in Cyberspace,” *International Security* 41, no. 3 (January 2017): 44–71.\n\n⁴ Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 3,
            "markdown": "and Perkoski's Rethinking Secrecy in Cyberspace, in arguing that the targeted state has two distinct decisions when experiencing a covert cyber attack: the decision to reveal the occurrence of an operation to the public and the decision to blame their attacker publicly.⁵ The decisions whether to reveal and blame lead to three primary communication strategies: collusion, disclosure, or public attribution. Rather than viewing attribution in the cyber domain as merely a problem to be overcome, attribution should be viewed as a multi-level, multi-player strategic decision in which the target state can choose to what extent it wants to activate domestic and international audiences and its desire to respond.\n\nThe objective of this paper is theory building and a descriptive effort to advance and define the study of cyber attribution. Given the challenges associated with capturing the universe of cases, empirical examples throughout will provide plausibility probes rather than a definitive test of my theory. This paper will proceed in seven parts. First, I will explore the existing literature on cyber attribution. Second, I discuss two interrelated features of cyber operations that underpin my theory: the covert and clandestine nature and the attribution problem. Third, I argue against the notion that the attribution problem is solely \"problematic\", instead arguing that these features provide a target state increased agency in their response to cyber operations. This has implications for the efficacy of deterrence by punishment, but in a different way than previously theorized. Fourth, I disaggregate attribution into two distinct actions: revealing and blaming. Fifth, I then develop the three strategies available to the target state of a cyber operation: collusion, disclosure, and public attribution. Sixth, I discuss the role of third party actors in the strategic dynamic between target and initiator. Seventh, I demonstrate how temporal considerations are magnified by the clandestine nature of cyber operations and the attribution problem. Finally, I conclude with thoughts about how the nature of cyber operations affects Type I and Type II error in\n\n⁵ Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 4,
            "markdown": "attribution.\n\n# Scope\n\nThe scope of this theory is the strategic considerations of nation-states that are targets of covert, state-sponsored cyber operations (hereby referred to as the target state).⁶ State-sponsored cyber operations include actions taken by the state military and intelligence forces, as well as those that are conducted by state proxies. Even if the specific identity of the attacker is not known, it is often evident when an attack is plausibly associated with a state actor. Typically, the sophistication of the operation, including the resource and intelligence requirements, provide initial indications that a state sponsor may be responsible.⁷\n\nNon-state actors, from lone wolves to cybercriminal syndicates, are active initiators in cyberspace, but they are outside the scope of the theory. Because of their asymmetry of power with the state, the target state requires different strategic calculations to publicly attribute non-state actors. Additionally, overt cyber operations fall outside of the scope of this theory. Overt operations are those where the perpetrator makes no effort to conceal their identity; thereby removing the target's agency to reveal or attribute. Non-state actors are more likely to initiate overt cyber operations. Currently, the empirical record shows no instances of a state officially credit-claiming a cyberattack on another nation-state.⁸\n\n⁶ Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.\n\n⁷ Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).\n\n⁸ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 5,
            "markdown": "# 1 Cyber Attribution Literature\n\nAttribution is among the most highly studied concepts in cyber; however, it does not carry a singular meaning across the literature.⁹ Some scholars discuss attribution as an act of simply identifying the actor or party responsible, while other scholars use attribution to mean the public act of assigning blame. While this may seem like a minor contrast, these two types of attribution have unique implications and should be understood as distinct.\n\nThe foundational definition of attribution is the act of identifying the sponsor of an operation (i.e. who is to blame);¹⁰ this will be hereby known as technical attribution. In order for a state to achieve technical attribution, human capital, technical expertise, and intelligence assets are required. There are significant sunk costs in building the capacity to conduct technical attribution for cyber operations.¹¹ Technical attribution also contains a measure of uncertainty because digital forensics do not always clearly map onto a single individual or responsible party. As Lin (2016) points out, there are often different evidentiary standards depending on what ends are sought.¹² Technical attribution typically includes a confidence indicator that captures the uncertainty associated with the assessment of ‘whodunit’. The “attribution problem” discussed within the cyber literature refers to the challenges associated with achieving timely and accurate technical attribution.\n\nHowever, the use of the word ‘attribution’ among policy makers, news media, and some scholars more frequently refers to a second type of attribution—the political act of publicly assigning blame; henceforth, I will refer to this as public attribution. Thomas Rid and Ben\n\n⁹. Clark and Landau, “Untangling Attribution Essay”; Herbert Lin, *Attribution of Malicious Cyber Incidents: From Soup to Nuts*, SSRN Scholarly Paper ID 2835719 (Rochester, NY: Social Science Research Network, September 2, 2016); Benjamin Edwards et al., “Strategic aspects of cyberattack, attribution, and blame,” *Proceedings of the National Academy of Sciences* 114, no. 11 (March 14, 2017): 2825–2830.\n\n¹⁰. Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Susan W. Brenner, “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare,” *The Journal of Criminal Law and Criminology* (1973-) 97, no. 2 (2007): 379–475; Florian J Egloff, “Public attribution of cyber intrusions,” *Journal of Cybersecurity* 6 (tyaa012 2020).\n\n¹¹. Lindsay, “Tipping the scales.”\n\n¹². Lin, *Attribution of Malicious Cyber Incidents*.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 6,
            "markdown": "Buchanan (2015) famously wrote “attribution is what states make of it” (p.7). Their work, *Attributing Cyber Attacks*, was among the first to develop a more nuanced understanding of cyber attribution by assessing attribution on three levels: technical, operational, and strategic. They challenged entrenched assumptions that attribution is binary and that attribution is merely a problem of evidence gathering. Specifically, Rid and Buchanan argued that attribution on a strategic level is a function of political stakes, and it is important to understand how attribution is communicated to the public.\n\nTo date, there has been little effort in the literature to understand public attribution as a distinct theoretical concept. One exception is Florian Egloff who develops a theoretical baseline of public attribution in his work, *Public Attribution of Cyber Intrusions*.¹³ Egloff divides attribution into two conceptual processes which he terms ‘sense-making’ and ‘meaning-making’ processes. Sense-making refers to a technical form of attribution—discovering the perpetrator’s identity—which lies at the root of the attribution problem. Meaning-making is a political strategy that considers attribution within a broader strategic consequence. Egloff has laid a foundation for exploration of attribution as an intentional act by theoretically conceptualizing how public attribution serves a states’ political ends. In subsequent work, Egloff and Smeets (2021) prescribe considerations for when a state should publicly attribute.¹⁴\n\n## 2 Two Defining Attributes of Cyber Operations\n\nThere are two defining, interrelated features of cyber operations that are central to all aspects of my theory 1) the clandestine and covert nature of cyber operations and 2) the persistence of the ‘attribution problem’. Together, these characteristics have implications for the target’s\n\n¹³ Egloff, “Public attribution of cyber intrusions.”\n\n¹⁴ Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 7,
            "markdown": "ability to communicate technical attribution, and how they respond to cyber operations.\n\n## 2.1 Covert and Clandestine Nature\n\nFirst, as previously discussed in the scope conditions, this theory only pertains to covert operations in which the sponsor has not claimed credit for an attack. Poznansky and Perkoski carefully outline this phenomenon in their work, *Rethinking Secrecy in Cyberspace*.¹⁵ The authors disaggregate secrecy into two types of operations: clandestine and covert. Clandestine operations are those that are hidden from view. Covert operations are those that are designed to conceal the identity of the perpetrator or create plausible deniability, rather than conceal the action itself. Most cyber operations are clandestine by nature given they travel over the digital network. As a result, these operations are not observable. Even cyber operations that are not clandestine, such as ransomware and defacement, are typically covert and the initiating actor strives to conceal their identity.\n\nThe covert and clandestine nature of cyber operations has implications for both the initiating and target states. Initiating actors are limited in their coercive power since it is difficult to bargain when identity remains concealed.¹⁶ The interaction between the initiator and target may be prone to miscommunication due to difficulty of signaling in cyberspace. Additionally, if the target state wants to understand the nature of the exploit or retaliate, they must invest significant time and resources into the discovery of and the assignment of blame.\n\n¹⁵ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n\n¹⁶ Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 8,
            "markdown": "## 2.2 Attribution Problem\n\nSecond, in order for this theory to hold, the attribution problem—the difficulty associated with achieving technical attribution—must persist or be broadly perceived to exist. The attribution problem directly follows from the covert and clandestine nature of cyber operations. When the attribution problem was first introduced in the cyber literature, there was a belief that technical attribution of some cyber operations could be impossible to achieve. Today, a more sophisticated technical community would reject the notion that attribution is impossible.¹⁷ However, the fact remains that technical attribution of cyber operations requires time and resources.¹⁸ States lacking this capacity may continue to find themselves unable to make technical attribution, while all states, regardless of capacity, continue to deal with the implications for timely response.\n\n## 2.3 The Attribution Problem and Deterrence\n\nIn the current literature, the primary theoretical consequence of the attribution problem is its erosion of deterrence by punishment; this makes the ‘attribution problem’ even more problematic.¹⁹ Traditional conceptions of deterrence require a credible threat *ex-ante* that changes the cost-benefit analysis of the initiator. Deterrence by punishment is undermined by the difficulty of achieving swift technical attribution (i.e. the attribution problem) because it reduces the target’s ability to credibly threaten costs.\n\n¹⁷ Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).\n\n¹⁸ Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,\n\n¹⁹ Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 9,
            "markdown": "According to existing literature, the difficulty of technical attribution is a problem for deterrence by punishment due to temporal reasons. Traditionally, there is a sense that punishment for an action should be reasonably close in time to the action for which the retaliation is being leveled. Brantly 2018, in his discussion of cyber deterrence, points out that even if a state promises to punish in the future, upon technical attribution, “the risk of punishment for an attack is possible but so temporally distant as to be discounted to the point of irrelevance” (p.45).²⁰ In other words, the initiating state does not have incentive to change their behavior because, ex-ante, the threat of punishment is so far in the future and uncertain as to be ineffective. While the idea of temporal appropriateness of punishment has not been explored extensively in the international relations literature, it is reinforced by discourses of administering punishment in psychology and legal fields. U.S. Supreme Court Justice Stephen Breyer referenced the long time between punishment and the crime while questioning the constitutionality of the death penalty in his dissenting opinion for *Glossip v. Gross*.²¹\n\n## 3 Expanding the Consequences of the Attribution Problem\n\nThe consequences of the attribution problem are more nuanced than currently portrayed. The existing explanation for how the attribution problem erodes deterrence by punishment contains an underlying assumption that, should technical attribution be obtained, punishment would be leveled in response to a cyber operation. However, I question the validity of this assumption in the cyber domain. For deterrence by punishment to serve a legitimate deterrent capability, the initiator must find the threat of punishment credible\n\n²⁰ Brantly, “The cyber deterrence problem.”\n\n²¹ Glossip v. Gross, No. 14-7955 (June 29, 2015).\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 10,
            "markdown": "ex-ante. Selective application of punishment erodes the credibility of the threat; therefore, deterrence by punishment only succeeds when punishment is leveled in response to all cyber incidents, or, at a minimum, a clearly designated threshold which empirically does not currently exist.²²\n\nIn traditional escalation literature, one of the most effective ways to credibly threaten punishment is through the tying of hands.²³ Yet, difficulties in attribution and the covert and clandestine nature of cyber operations not only provide plausible deniability to the perpetrator, they also provide plausible deniability for the target that they have achieved technical attribution. This, in effect, permits the target leeway to strategically withhold or release information about their attribution or lack thereof. It is precisely this discretion that allows the target to untie their hands and selectively respond to cyber operations. In this way, the attribution problem permits target states to sacrifice deterrence by punishment in favor of agency over how they respond to cyber operations.\n\nThe argument presented in this paper— that difficulties in technical attribution provide the target additional strategic agency in responding to cyber operations— is predicated on several assumptions.\n\n## 3.1 Assumptions\n\nFirst and most centrally, this argument rests on the assumption that **target states do not want to respond to every cyber operation**. There are several reasons why this assumption is plausible. To begin, there is perceived to be an offensive advantage in cyberspace and the technology is widely accessible below the threshold of the state.²⁴ These\n\n²². Lindsay, “Tipping the scales” findings that deterrence works for large scale attacks suggest there may be a tacit understanding of this threshold, but it is not publicly stated.\n\n²³. Thomas C. Schelling, *Arms and Influence*, 2008th ed., Google-Books-ID: TX_yAAAAQBAJ (Yale University Press, 1966).\n\n²⁴. Kello, “The Meaning of the Cyber Revolution”; Lindsay, “Tipping the scales”; Nye, “Deterrence and Dissuasion in Cyberspace”; Edwards et al., “Strategic aspects of cyberattack, attribution, and blame.”\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 11,
            "markdown": "characteristics contribute to a high volume of intrusions, exploits, and attacks, therefore making it impossible to level punishment for every action. Second, choosing how to best respond to a cyber operation is not clear-cut.²⁵ Often, there is not a tidy reciprocal cyber action that a target can take against the initiator. There are four alternative approaches to cyber exploitation by a state actor: 1) take no public action; 2) utilize diplomatic levers such as sanctions or naming and shaming; 3) treat cyber exploits as provocations that require militarization; 4) treat cyber exploits as offenses that require criminalization. This is further complicated by a lack of consensus around what ‘force’ is in the cyber domain.²⁶ For example, some scholars argue that SolarWinds is an espionage operation and, therefore, merely an act of statecraft.²⁷ While others point to the egregious scale and potential for future sabotage and power shifts due to the exploit.²⁸\n\nThe decision how to respond to a cyber operation is not a simple one. Lindsay states “retaliation can be costly for the one administering the punishment as well as the punished, a victim may decide not to do anything even after attribution if the costs and risks of punishing are too great” (p. 57).²⁹ Here, Lindsay identifies that responding to a cyber operation requires a cost-benefit calculation on behalf of the target state. The target state must have the resolve and political will to respond with punishment once correctly identifying their attacker. There will be instances in which leveling a response is more costly than doing nothing at all. One of the great risks of responding to a cyber operation is the risk of escalation.³⁰ Schneider\n\n²⁵. Erica Borghard and Shawn Lonergan, “Cyber Operations as Imperfect Tools of Escalation,” *Strategic Studies Quarterly* 63, no. 2 (2019): 122–145; Jason Healey and Robert Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability,” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n\n²⁶. David Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations,” *Daedalus* 145 (September 1, 2016): 37–49; Russell Buchan, “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?,” Publisher: Oxford University Press, *Journal of Conflict and Security Law* 17, no. 2 (2012): 211–227.\n\n²⁷. Erica Borghard and Jacquelyn Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy,” *Wired*, December 17, 2020,\n\n²⁸. Yevgeny Vindman, “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.,” Lawfare, January 26, 2021, accessed March 12, 2021, https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n\n²⁹. Lindsay, “Tipping the scales.”\n\n³⁰. Martin C. Libicki, *Crisis and Escalation in Cyberspace*, Google-Books-ID: D9YzsTx1mnMC (Rand\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 12,
            "markdown": "finds that participants in wargame simulations self-restrain in response to cyber operations out of the perception that cyber is highly escalatory.³¹ Once again, this provides plausible evidence that targets of cyber operations do not want to respond to every cyber operation, including, perhaps, some of the most egregious due to a fear of escalation. The challenges of choosing which incidents to respond to, and what response is ‘appropriate’ further erode deterrence by punishment beyond the attribution problem.\n\nThe second assumption is that states feel pressure to “do something” when they fall victim to hostile actions from another nation-state. This pressure can come from domestic constituents, international audiences, or an internal desire to deter future actions or appear resolved against an adversary.³² The assertion that domestic public support retaliatory response is plausibly supported by survey research which shows high levels of support for retaliation. For example, survey work has found that nearly two-thirds of respondents support a military response when the United States is attacked, regardless if the means of attack are cyber or kinetic.³³ The high-level of support for retaliation is even more notable because the survey experiment tests relatively low-level exploits including financial and information theft. Only 7 percent of survey respondents selected ‘do not acknowledge the attack’ as their most preferred response, meaning 93 percent of respondents preferred the government take some sort of action.\n\nThe third assumption is that the attribution problem endemic in cyber domain operations (specifically the difficulty of achieving technical attribution) is widely\n\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\nCorporation, 2012); Herbert Lin, “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25; Monica Kaminska, “Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks,” Journal of Cybersecurity 7 (tyab008 2021); Brandon G. Valeriano and Ben Jenson, The Myth of the Cyber Offense: The Case for Cyber Restraint, SSRN Scholarly Paper ID 3382340 (Rochester, NY: Social Science Research Network, January 15, 2019); Healey and Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability.”\n\n³¹. Dr Jacquelyn Schneider, “Cyber and Crisis Escalation: Insights from Wargaming” (March 2017), 43.\n\n³². Robert D. Putnam, “Diplomacy and domestic politics: the logic of two-level games,” 00000, International Organization 42, no. 3 (1988): 427–460.\n\n³³. hedgecock’sukin2023.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 13,
            "markdown": "accepted and the public is desensitized to it. In other words, there must be an enduring belief that technical attribution of cyber operations is difficult to achieve and that there is variation on the amount of time and feasibility required. In the kinetic domain, there is an assumption that swift technical attribution can and will be achieved. This creates expectations among domestic and international audiences that the target state will make a public attribution when they are the victim of a conventional attack or exploitation. Even in the case of terrorism, where the identity of the perpetrator may be especially hard to distill, politicians promise to identify and punish their attackers. Less than one minute into President Clinton’s statement following the USS Cole bombing he said: “We will find out who is responsible and hold them accountable.” While elected leaders may face a credibility problem or domestic political costs if they revealed a kinetic operation and said that they did not know who did it or may never know,³⁴ this is not the case for the cyber domain. In fact, the attribution problem is so endemic that several scholars have explored the challenges of convincing the public of an attribution claim in the cyber domain.³⁵ The prevalence of the public rhetoric around the attribution problem has changed expectations of attribution for cyber incidents.\n\nThe attribution problem is widely referenced in public discourse which helps perpetuate this belief among the public. Take, for example, the United States Office of the Director of National Intelligence’s Guide to Cyber Attribution. In discussing technical attribution, they write: “This painstaking work in many cases requires several weeks or months of analyzing intelligence and forensics. In some instances in which analysts can determine responsibility\n\n³⁴. James D. Fearon, “Domestic Political Audiences and the Escalation of International Disputes,” *American Political Science Review* 88, no. 3 (September 1994): 577–592; Kenneth A. Schultz, *Democracy and Coercive Diplomacy* (Cambridge University Press, July 26, 2001).\n\n³⁵. Marcus Schulzke, “The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty,” Num Pages: 954–968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, *Perspectives on Politics* 16, no. 4 (December 2018): 954–968; Florian J. Egloff, “Contested public attributions of cyber incidents and the role of academia,” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, *Contemporary Security Policy* 41, no. 1 (January 2, 2020): 55–81.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 14,
            "markdown": "for a cyber attack within hours of an incident the accuracy and level of confidence is likely to vary depending on the available data”.36 Separately, during a Biden administration press conference discussing the SolarWinds hack, Deputy National Security Advisor for Cyber and Emerging Technologies, Anne Neuberger, was pressed by a reporter asking “how long this investigation [into SolarWinds] will take?”. Neuberger responded that it would take “several months” without any resistance or skepticism.37 The difficulty of attribution was also part of mainstream dialogue in the 2016 Presidential debates where President Trump made his now infamous statement about the Democratic National Committee hack saying, “[Clinton is] saying Russia, Russia, Russia. Maybe it was. It could also be China. It could be someone sitting on their bed that weighs 400 pounds”.38 Statements such as these continue to reinforce public expectations that cyber attribution is difficult and emphasize a temporal dimension.\n\nTaken together, these three assumptions provide the foundation for my argument that difficulties in attribution provide target states strategic agency in their response to cyber operations. If states feel pressure to respond when they reveal they are the victim of a cyber operation, but also struggle with the appropriate response to a cyber operation, they may not want to publicly attribute the cyber operation at all or delay their attribution until they have constructed an adequate response. Therefore, the perception of attribution difficulty and the clandestine and covert nature of cyber operations provide target states the ability to manipulate revelation and public attribution to meet their strategic needs. In addition to the commonly understood erosion of deterrence by punishment by undermining the timely delivery of punishment, I\n\n36. A Guide to Cyber Attribution (Office of the Director of National Intelligence, September 14, 2018).\n\n37. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021,” The White House, January 20, 2021, accessed April 8, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\n\n38. Cory Bennett, “Cyber history made at the first debate,” POLITICO, September 27, 2016, accessed March 6, 2021, https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 15,
            "markdown": "propose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence.\n\n# 4 Disaggregating Attribution\n\nTo this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency.\n\nAs aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.³⁹\n\nThe relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical\n\n³⁹. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 16,
            "markdown": "attribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story.\n\nFirst, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public.\n\nThe second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.⁴⁰\n\n# 5 Target State Strategies\n\nIn arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy.⁴¹ To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international\n\n⁴⁰. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n⁴¹. Lindsay, “Tipping the scales.”\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 17,
            "markdown": "and domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs.\n\nDisaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine.[42] Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker.[43] In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy.\n\n![img-0.jpeg](img-0.jpeg)\nFigure 1: Strategies of Communication for Target States\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [
              {
                "id": "img-0.jpeg",
                "top_left_x": 557,
                "top_left_y": 1236,
                "bottom_right_x": 1115,
                "bottom_right_y": 1522,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 18,
            "markdown": "# 5.1 Collusion\n\nCollusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains.⁴⁴ In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation.\n\nWhile Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding.\n\nIn the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and\n\n⁴⁴ Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 19,
            "markdown": "the incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling.\n\nCarson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity.\n\n## 5.2 Disclosure\n\nThroughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take.⁴⁵ This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without\n\n⁴⁵. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 20,
            "markdown": "assigning blame.⁴⁶ Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation.\n\nDisclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist.\n\nLooking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected.\n\n## 5.2.1 Forms of Disclosure\n\nDisclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing\n\n⁴⁶. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 21,
            "markdown": "and explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways.\n\nIt is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal.\n\n## Ambiguous Disclosure\n\nFirst, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill.⁴⁷ After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response.\n\nAmbiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised\n\n⁴⁷ Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 22,
            "markdown": "and whether blame is being intentionally withheld or not.\n\nAmbiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first.\n\n## Unattributed Disclosure\n\nSecond, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame.\n\nOne purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel.[48] In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 23,
            "markdown": "finalize the attribution process.\n\n## Withheld Disclosure\n\nFinally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case.\n\nOne example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 24,
            "markdown": "practical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50\n\nIn this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52\n\nThis example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution.\n\nThe target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 25,
            "markdown": "outside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate.\n\nThe target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution.\n\nSecond, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution.\n\n### 5.3 Public Attribution\n\nFinally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 26,
            "markdown": "range of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value.\n\nA target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved.\n\nFor one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55\n\nThe risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds\n\n54. As is the case with all cyber operations, a retaliatory cyber operation is not overt unless the target public claims credit for launching a retaliatory operation or the effects are visible and publicized.\n\n55. Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021.”\n\n56. Schultz, Democracy and Coercive Diplomacy.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 27,
            "markdown": "that the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected.\n\nAlthough public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58\n\n## 6 The Role of Third-Party Actors\n\nThus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations.\n\nIn the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized\n\n57. Carson, Secret Wars.\n58. Lin, \"Escalation Dynamics and Conflict Termination in Cyberspace\"; Libicki, Crisis and Escalation in Cyberspace.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 28,
            "markdown": "cybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media.\n\nIn assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim.\n\nThird-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\".[59] Finally,\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 29,
            "markdown": "third parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research.\n\nHowever, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia.⁶⁰ Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation.\n\nOnly months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium.⁶¹ In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack.⁶² Interestingly, while Microsoft very\n\n⁶⁰. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia.\n\n⁶¹. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n\n⁶². “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 30,
            "markdown": "clearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government.\n\nIn both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude.\n\n# 7 Temporal Considerations\n\nGiven that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications.\n\nThere are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 31,
            "markdown": "# 7.1 Discovery-Disclosure\n\nFirst, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is.\n\nA short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures.\n\nAlternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty.\n\nAn intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 32,
            "markdown": "as an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63\n\n## 7.2 Disclosure-Public Attribution\n\nThe second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution.\n\nThe SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 33,
            "markdown": "disclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle.\n\nIn contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage.⁶⁴ While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months.⁶⁵ The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.⁶⁶\n\nThe belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the\n\n⁶⁴. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n\n⁶⁵. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018,\n\n⁶⁶. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 34,
            "markdown": "impact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment\n\nOne suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).[67]\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 35,
            "markdown": "![img-1.jpeg](img-1.jpeg)\nFigure 2: NotPetya Worldwide Search Results from Google Trends\n\n![img-2.jpeg](img-2.jpeg)\nFigure 3: WannaCry Virus Worldwide Search Results from Google Trends\n\nWhile retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [
              {
                "id": "img-1.jpeg",
                "top_left_x": 408,
                "top_left_y": 200,
                "bottom_right_x": 1283,
                "bottom_right_y": 803,
                "image_base64": null,
                "image_annotation": null
              },
              {
                "id": "img-2.jpeg",
                "top_left_x": 408,
                "top_left_y": 976,
                "bottom_right_x": 1283,
                "bottom_right_y": 1579,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 36,
            "markdown": "responding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response.\n\nWith the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a\n\n68. Barack Obama, “Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment,” whitehouse.gov, December 29, 2016, accessed April 8, 2021, https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\n\n69. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021,” The White House, February 17, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n\n70. Rose McDermott et al., “Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence,” Texas National Security Review 1, no. 1 (November 24, 2017).\n\n71. Nicole Gauvette, “White House says it will hold those responsible for SolarWinds hack accountable within weeks,” CNN, February 19, 2021, accessed February 21, 2021, https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 37,
            "markdown": "specific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action.\n\nThe uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent.\n\n## 8 Type I and Type II Attribution Error\n\nFinally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how.\n\nAs previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party.\n\nThe common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions\n\n72. A Guide to Cyber Attribution.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 38,
            "markdown": "that are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt.\n\nTo date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.\n\n73. Catalin Cimpanu, “EU sanctions China, Russia, and North Korea for past hacks,” ZDNet, July 30, 2020, accessed April 8, 2021, https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\n\n74. Borghard and Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.”\n\n75. Buchan, “Cyber Attacks”; Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion.”\n\n76. Brandon Valeriano and Ryan C Maness, “The dynamics of cyber conflict between rival antagonists, 2001–11,” Journal of Peace Research 51, no. 3 (May 2014): 347–360.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 39,
            "markdown": "Despite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo.\n\nA need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan, \"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events \"may outpace the speed of the attribution process\" (p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 40,
            "markdown": "# 9 Conclusion\n\nTo date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand.\n\nAdditionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution.\n\nThe argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 41,
            "markdown": "key to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 42,
            "markdown": "# References\n\nA Guide to Cyber Attribution. Office of the Director of National Intelligence, September 14, 2018.\n\n“Australia cyber attacks: PM Morrison warns of ‘sophisticated’ state hack.” BBC News, June 19, 2020.\n\nBennett, Cory. “Cyber history made at the first debate.” POLITICO, September 27, 2016. Accessed March 6, 2021. https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\n\nBiddle, Tami. “Coercion Theory: A Basic Introduction for Practitioners.” Texas National Security Review, February 20, 2020. Accessed March 4, 2021. https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/.\n\nBorghard, Erica, and Shawn Lonergan. “Cyber Operations as Imperfect Tools of Escalation.” Strategic Studies Quarterly 63, no. 2 (2019): 122–145.\n\nBorghard, Erica, and Jacquelyn Schneider. “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.” Wired, December 17, 2020.\n\nBorghard, Erica D., and Shawn W. Lonergan. “The Logic of Coercion in Cyberspace.” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, Security Studies 26, no. 3 (July 3, 2017): 452–481.\n\nBossert, Thomas P. “It’s Official: North Korea Is Behind WannaCry.” Wall Street Journal, December 19, 2017.\n\nBradshaw, Abigail. “General Session Panel Allies Counter Common Cyber Adversaries.” Director, Australian Cyber Security Centre, 11th Annual Billington Cybersecurity Summit 2020, September 8, 2020.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 43,
            "markdown": "Electronic copy available at: https://ssrn.com/abstract=4353069\n\nBrantly, A. F. “The cyber deterrence problem.” In 2018 10th International Conference on Cyber Conflict (CyCon), 31–54. ISSN: 2325-5374. May 2018.\n\nBrenner, Susan W. “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare.” The Journal of Criminal Law and Criminology (1973-) 97, no. 2 (2007): 379–475.\n\nBuchan, Russell. “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?” Publisher: Oxford University Press, Journal of Conflict and Security Law 17, no. 2 (2012): 211–227.\n\nBurt, Tom. “New nation-state cyberattacks.” Microsoft On the Issues, March 2, 2021. Accessed April 5, 2021. https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n\nCanfil, Justin. “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay.” Journal of Cybersecurity, 2022.\n\nCarson, Austin. Secret Wars: Covert Conflict in International Politics. Princeton University Press, September 25, 2018.\n\nCarson, Austin, and Allison Carnegie. “The Disclosure Dilemma: Nuclear Intelligence and International Organizations.” *American Journal of Political Science* 13, no. 3 (2019): 269–285.\n\nCimpanu, Catalin. “EU sanctions China, Russia, and North Korea for past hacks.” ZDNET, July 30, 2020. Accessed April 8, 2021. https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\n\nClark, David D., and Susan Landau. “Untangling Attribution Essay.” Harvard National Security Journal 2, no. 2 (2011): 323–352.\n\n44",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 44,
            "markdown": "Earnest, Josh. “Press Briefing by the Press Secretary Josh Earnest, 12/18/14.” Whitehouse.gov, December 18, 2014. Accessed April 7, 2021. https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n\nEdwards, Benjamin, Alexander Furnas, Stephanie Forrest, and Robert Axelrod. “Strategic aspects of cyberattack, attribution, and blame.” Proceedings of the National Academy of Sciences 114, no. 11 (March 14, 2017): 2825–2830.\n\nEgloff, Florian J. “Public attribution of cyber intrusions.” Journal of Cybersecurity 6 (tyaa012 2020).\n\n———. “Contested public attributions of cyber incidents and the role of academia.” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, Contemporary Security Policy 41, no. 1 (January 2, 2020): 55–81.\n\nEgloff, Florian J., and Max Smeets. “Publicly attributing cyber attacks: a framework.” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, Journal of Strategic Studies, March 10, 2021, 1–32.\n\nFearon, James D. “Domestic Political Audiences and the Escalation of International Disputes.” *American Political Science Review* 88, no. 3 (September 1994): 577–592.\n\nFidler, David. “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations.” *Daedalus* 145 (September 1, 2016): 37–49.\n\nFischerkeller, Michael P., and Richard J. Harknett. “Deterrence is Not a Credible Strategy for Cyberspace.” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\n\nGartzke, Erik. “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.” Publisher: The MIT Press, International Security 38, no. 2 (2013): 41–73.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 45,
            "markdown": "Gartzke, Erik, and Jon R. Lindsay. “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.” *Security Studies* 24, no. 2 (April 3, 2015): 316–348.\n\nGauvette, Nicole. “White House says it will hold those responsible for SolarWinds hack accountable within weeks.” CNN, February 19, 2021. Accessed February 21, 2021. https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\n\nGlaser, Charles L. *Deterrence of Cyber Attacks and U.S. National Security*. Report GW-CSPRI-2011-5. Cyber Security Policy and Research Institute, June 1, 2011.\n\nGreenberg, Andy. “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’.” *Wired*, February 15, 2018.\n\nHampton, Andrew. “General Session Panel Allies Counter Common Cyber Adversaries.” New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summit 2020, September 8, 2020.\n\nHarknett, Richard J., and Joseph S. Nye. “Is Deterrence Possible in Cyberspace?” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199.\n\nHealey, Jason, and Robert Jervis. “The Escalation Inversion and Other Oddities of Situational Cyber Stability.” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n\nHedgecock, Kathryn, and Lauren Sukin. “Responding to Uncertainty: The Importance of Covertness in Support for Retaliation to Kinetic and Cyber Attacks.” *Journal of Conflict Resolution*, 2023.\n\nInformation Security, Federal Office for. *Bericht zur Lage der IT-Sicherheit in Deutschland 2014*. 2014.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 46,
            "markdown": "\"Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA.\" Accessed February 1, 2021. https://www.cisa.gov/news/2021/01/05/joint-statement-federal-bureau-investigation-fbi-cybersecurity-and-infrastructure.\n\nJoyce, Rob. \"Improving and Making the Vulnerability Equities Process Transparent is the Right Thing to Do – The White House,\" November 15, 2017. Accessed February 9, 2021. https://trumpwhitehouse.archives.gov/articles/improving-making-vulnerability-equities-process-transparent-right-thing/.\n\nKaminska, Monica. \"Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks.\" Journal of Cybersecurity 7 (tyab008 2021).\n\nKello, Lucas. \"The Meaning of the Cyber Revolution: Perils to Theory and Statecraft.\" Publisher: The MIT Press, International Security 38, no. 2 (2013): 7-40.\n\nKeown, Arthur J., and John M. Pinkerton. \"Merger Announcements and Insider Trading Activity: An Empirical Investigation.\" Publisher: [American Finance Association, Wiley], The Journal of Finance 36, no. 4 (1981): 855-869.\n\nKushner, David. \"The Real Story of Stuxnet - IEEE Spectrum.\" IEEE Spectrum: Technology, Engineering, and Science News, February 26, 2013. Accessed April 8, 2021. https://spectrum.ieee.org/telecom/security/the-real-story-of-stuxnet.\n\nLibicki, Martin C. Crisis and Escalation in Cyberspace. Google-Books-ID: D9YzsTx1mnMC. Rand Corporation, 2012.\n\n——. Cyberdeterrence and cyberwar. In collaboration with Project Air Force (U.S.) OCLC: ocn428819545. Santa Monica, CA: RAND, 2009.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 47,
            "markdown": "Lin, Herbert. *Attribution of Malicious Cyber Incidents: From Soup to Nuts*. SSRN Scholarly Paper ID 2835719. Rochester, NY: Social Science Research Network, September 2, 2016.\n\n———. “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25.\n\nLindsay, Jon R. “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack.” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67.\n\nMaurer, Tim. *Cyber Mercenaries*. Google-Books-ID: rKpCDwAAQBAJ. Cambridge University Press, January 18, 2018.\n\nMcDermott, Rose, Anthony C Lopez, and Peter K Hatemi. “‘Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence.” *Texas National Security Review* 1, no. 1 (November 24, 2017).\n\nMilton Mueller, Brenden Kuerbis, Karl Grindal, and Farzaneh Badiei. “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?” *The Cyber Defense Review* 4 (1 2019).\n\nMorrison, Scott. “Statement on malicious cyber activity against Australian networks — Prime Minister of Australia,” June 19, 2020. Accessed April 8, 2021. https://www.pm.gov.au/media/statement-malicious-cyber-activity-against-australian-networks.\n\nNewman, Lily Hay. “Hacker Lexicon: What Is the Attribution Problem?” *Wired*, December 24, 2016.\n\nNye, Joseph S. “Deterrence and Dissuasion in Cyberspace.” *International Security* 41, no. 3 (January 2017): 44–71.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 48,
            "markdown": "Obama, Barack. \"Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment.\" Whitehouse.gov, December 29, 2016. Accessed April 8, 2021. https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\n\nOtto, Jacob, and William Spaniel. \"Doubling Down: The Danger of Disclosing Secret Action.\" International Studies Quarterly 65, no. 2 (2021): 500–511.\n\nPoznansky, Michael, and Evan Perkoski. \"Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution.\" Journal of Global Security Studies 3, no. 4 (October 1, 2018): 402–416.\n\nPsaki, Jen. \"Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021.\" The White House, February 17, 2021. https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n\n———. \"Press Briefing by Press Secretary Jen Psaki, January 20, 2021.\" The White House, January 20, 2021. Accessed April 8, 2021. https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\n\nPutnam, Robert D. \"Diplomacy and domestic politics: the logic of two-level games.\" 00000, International Organization 42, no. 3 (1988): 427–460.\n\nRid, Thomas, and Ben Buchanan. \"Attributing Cyber Attacks.\" Journal of Strategic Studies 38, no. 1 (January 2, 2015): 4–37.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 49,
            "markdown": "Sanders, Sarah. \"Statement from the Press Secretary.\" The White House, February 15, 2018. Accessed December 6, 2019. https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n\n\"All eyes on China as it's revealed Australia was targeted in a 'sophisticated' cyber attack.\" SBS News, June 19, 2020.\n\nSchelling, Thomas C. Arms and Influence. 2008th ed. Google-Books-ID: TX_yAAAAQBAJ. Yale University Press, 1966.\n\nSchneider, Dr Jacquelyn. \"Cyber and Crisis Escalation: Insights from Wargaming,\" 43. March 2017.\n\nSchultz, Kenneth A. Democracy and Coercive Diplomacy. Cambridge University Press, July 26, 2001.\n\nSchulzke, Marcus. \"The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty.\" Num Pages: 954-968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, Perspectives on Politics 16, no. 4 (December 2018): 954-968.\n\n\"Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace.\" The United States Department of Justice, October 19, 2020. Accessed April 8, 2021. https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\n\nStilgherrian. \"Blaming Russia for NotPetya was coordinated diplomatic action.\" ZDNET, April 12, 2018. Accessed April 6, 2021. https://www.zdnet.com/article/blaming-russia-for-notpetya-was-coordinated-diplomatic-action/.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 50,
            "markdown": "Valeriano, Brandon, and Ryan C Maness. “The dynamics of cyber conflict between rival antagonists, 2001–11.” *Journal of Peace Research* 51, no. 3 (May 2014): 347–360.\n\nValeriano, Brandon G., and Ben Jenson. *The Myth of the Cyber Offense: The Case for Cyber Restraint*. SSRN Scholarly Paper ID 3382340. Rochester, NY: Social Science Research Network, January 15, 2019.\n\nVindman, Yevgeny. “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.” Lawfare, January 26, 2021. Accessed March 12, 2021. https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 51,
          "doc_size_bytes": 1243043
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "# Strategic Attribution: Target State Communication in Response to Cyber Operations\nKathryn Hedgecock\nFebruary 24, 2023\n## Abstract\nThis paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau¹\n# Introduction\nIn December 2014, three weeks after the Sony Picture hack, the first two questions of the White House Press Briefing asked: “Does the White House believe that North Korea is behind the hack at Sony Pictures?” and “What is the United States going to do about it?”. Reporters were asking the standard questions associated with the disclosure of a hack, namely, who is responsible and how the state will respond. The press was seeking public attribution, i.e. the public assignment of blame, which is typically a prerequisite for retaliatory action. To these questions Press Secretary John Earnest subsequently responded, “this is a matter that is still under investigation...[I] am not going to get ahead of that investigation” and “before we start publicly speculating about a response, it’s appropriate that we allow the investigation to move forward”.² Press Secretary Earnest was implicitly appealing to the attribution problem –difficulty in achieving technical attribution– for why North Korea had yet to be named and no response yet taken.\nThe attribution problem is a central theme in the cyber literature.³ The covert and\n¹ Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).\n² Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n³ Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The\nElectronic copy available at: https://ssrn.com/abstract=4353069\ntechnical nature of cyber operations make identifying the sponsor very difficult or, at a minimum, time and resource intensive. As a result, the literature focuses on the negative consequences associated with the attribution problem, primarily an erosion of the credibility and feasibility of deterrence by punishment.⁴ However, in this paper, I argue that a narrow focus on attribution as a problem overlooks the strategic agency that deniable attribution provides targets of cyber operations. Uncertainty in the ability and timeliness of attribution, coupled with the clandestine and covert nature of cyber operations, provide the target state three strategies of communication: collusion, disclosure, or public attribution; all of which should be viewed as intentional actions with strategic implications.\nThis paper contributes to the literature on covert action, cyber deterrence, and public attribution as a distinct concept. First, I advance the literature by challenging the emphasis of attribution as a “problem” in the cyber domain. Instead, I argue the attribution problem can also be a strategic asset of the target state by providing additional agency in how they respond to and communicate about cyber operations. While this strategic logic exists in covert action broadly, there are unique features of the cyber domain that heighten the target’s agency. The covert nature of most cyber operations and complexity of attribution provide plausible deniability, not only for the perpetrator, but also for the target state’s technical attribution. A target’s discretion in choosing to what extent they want to acknowledge or respond to an operation prioritizes escalation management at the expense of deterrence by punishment. Second, I extend and adapt the logic of Carson’s *Secret Wars* and Poznansky\nMIT Press, *International Security* 38, no. 2 (2013): 7–40; Martin C. Libicki, *Cyberdeterrence and cyberwar*, in collab. with Project Air Force (U.S.), OCLC: ocn428819545 (Santa Monica, CA: RAND, 2009); Jon R. Lindsay, “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack,” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67; Joseph S. Nye, “Deterrence and Dissuasion in Cyberspace,” *International Security* 41, no. 3 (January 2017): 44–71.\n⁴ Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand Perkoski's Rethinking Secrecy in Cyberspace, in arguing that the targeted state has two distinct decisions when experiencing a covert cyber attack: the decision to reveal the occurrence of an operation to the public and the decision to blame their attacker publicly.⁵ The decisions whether to reveal and blame lead to three primary communication strategies: collusion, disclosure, or public attribution. Rather than viewing attribution in the cyber domain as merely a problem to be overcome, attribution should be viewed as a multi-level, multi-player strategic decision in which the target state can choose to what extent it wants to activate domestic and international audiences and its desire to respond.\nThe objective of this paper is theory building and a descriptive effort to advance and define the study of cyber attribution. Given the challenges associated with capturing the universe of cases, empirical examples throughout will provide plausibility probes rather than a definitive test of my theory. This paper will proceed in seven parts. First, I will explore the existing literature on cyber attribution. Second, I discuss two interrelated features of cyber operations that underpin my theory: the covert and clandestine nature and the attribution problem. Third, I argue against the notion that the attribution problem is solely \"problematic\", instead arguing that these features provide a target state increased agency in their response to cyber operations. This has implications for the efficacy of deterrence by punishment, but in a different way than previously theorized. Fourth, I disaggregate attribution into two distinct actions: revealing and blaming. Fifth, I then develop the three strategies available to the target state of a cyber operation: collusion, disclosure, and public attribution. Sixth, I discuss the role of third party actors in the strategic dynamic between target and initiator. Seventh, I demonstrate how temporal considerations are magnified by the clandestine nature of cyber operations and the attribution problem. Finally, I conclude with thoughts about how the nature of cyber operations affects Type I and Type II error in\n⁵ Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution.\n# Scope\nThe scope of this theory is the strategic considerations of nation-states that are targets of covert, state-sponsored cyber operations (hereby referred to as the target state).⁶ State-sponsored cyber operations include actions taken by the state military and intelligence forces, as well as those that are conducted by state proxies. Even if the specific identity of the attacker is not known, it is often evident when an attack is plausibly associated with a state actor. Typically, the sophistication of the operation, including the resource and intelligence requirements, provide initial indications that a state sponsor may be responsible.⁷\nNon-state actors, from lone wolves to cybercriminal syndicates, are active initiators in cyberspace, but they are outside the scope of the theory. Because of their asymmetry of power with the state, the target state requires different strategic calculations to publicly attribute non-state actors. Additionally, overt cyber operations fall outside of the scope of this theory. Overt operations are those where the perpetrator makes no effort to conceal their identity; thereby removing the target's agency to reveal or attribute. Non-state actors are more likely to initiate overt cyber operations. Currently, the empirical record shows no instances of a state officially credit-claiming a cyberattack on another nation-state.⁸\n⁶ Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.\n⁷ Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).\n⁸ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 1 Cyber Attribution Literature\nAttribution is among the most highly studied concepts in cyber; however, it does not carry a singular meaning across the literature.⁹ Some scholars discuss attribution as an act of simply identifying the actor or party responsible, while other scholars use attribution to mean the public act of assigning blame. While this may seem like a minor contrast, these two types of attribution have unique implications and should be understood as distinct.\nThe foundational definition of attribution is the act of identifying the sponsor of an operation (i.e. who is to blame);¹⁰ this will be hereby known as technical attribution. In order for a state to achieve technical attribution, human capital, technical expertise, and intelligence assets are required. There are significant sunk costs in building the capacity to conduct technical attribution for cyber operations.¹¹ Technical attribution also contains a measure of uncertainty because digital forensics do not always clearly map onto a single individual or responsible party. As Lin (2016) points out, there are often different evidentiary standards depending on what ends are sought.¹² Technical attribution typically includes a confidence indicator that captures the uncertainty associated with the assessment of ‘whodunit’. The “attribution problem” discussed within the cyber literature refers to the challenges associated with achieving timely and accurate technical attribution.\nHowever, the use of the word ‘attribution’ among policy makers, news media, and some scholars more frequently refers to a second type of attribution—the political act of publicly assigning blame; henceforth, I will refer to this as public attribution. Thomas Rid and Ben\n⁹. Clark and Landau, “Untangling Attribution Essay”; Herbert Lin, *Attribution of Malicious Cyber Incidents: From Soup to Nuts*, SSRN Scholarly Paper ID 2835719 (Rochester, NY: Social Science Research Network, September 2, 2016); Benjamin Edwards et al., “Strategic aspects of cyberattack, attribution, and blame,” *Proceedings of the National Academy of Sciences* 114, no. 11 (March 14, 2017): 2825–2830.\n¹⁰. Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Susan W. Brenner, “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare,” *The Journal of Criminal Law and Criminology* (1973-) 97, no. 2 (2007): 379–475; Florian J Egloff, “Public attribution of cyber intrusions,” *Journal of Cybersecurity* 6 (tyaa012 2020).\n¹¹. Lindsay, “Tipping the scales.”\n¹². Lin, *Attribution of Malicious Cyber Incidents*.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nBuchanan (2015) famously wrote “attribution is what states make of it” (p.7). Their work, *Attributing Cyber Attacks*, was among the first to develop a more nuanced understanding of cyber attribution by assessing attribution on three levels: technical, operational, and strategic. They challenged entrenched assumptions that attribution is binary and that attribution is merely a problem of evidence gathering. Specifically, Rid and Buchanan argued that attribution on a strategic level is a function of political stakes, and it is important to understand how attribution is communicated to the public.\nTo date, there has been little effort in the literature to understand public attribution as a distinct theoretical concept. One exception is Florian Egloff who develops a theoretical baseline of public attribution in his work, *Public Attribution of Cyber Intrusions*.¹³ Egloff divides attribution into two conceptual processes which he terms ‘sense-making’ and ‘meaning-making’ processes. Sense-making refers to a technical form of attribution—discovering the perpetrator’s identity—which lies at the root of the attribution problem. Meaning-making is a political strategy that considers attribution within a broader strategic consequence. Egloff has laid a foundation for exploration of attribution as an intentional act by theoretically conceptualizing how public attribution serves a states’ political ends. In subsequent work, Egloff and Smeets (2021) prescribe considerations for when a state should publicly attribute.¹⁴\n## 2 Two Defining Attributes of Cyber Operations\nThere are two defining, interrelated features of cyber operations that are central to all aspects of my theory 1) the clandestine and covert nature of cyber operations and 2) the persistence of the ‘attribution problem’. Together, these characteristics have implications for the target’s\n¹³ Egloff, “Public attribution of cyber intrusions.”\n¹⁴ Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nability to communicate technical attribution, and how they respond to cyber operations.\n## 2.1 Covert and Clandestine Nature\nFirst, as previously discussed in the scope conditions, this theory only pertains to covert operations in which the sponsor has not claimed credit for an attack. Poznansky and Perkoski carefully outline this phenomenon in their work, *Rethinking Secrecy in Cyberspace*.¹⁵ The authors disaggregate secrecy into two types of operations: clandestine and covert. Clandestine operations are those that are hidden from view. Covert operations are those that are designed to conceal the identity of the perpetrator or create plausible deniability, rather than conceal the action itself. Most cyber operations are clandestine by nature given they travel over the digital network. As a result, these operations are not observable. Even cyber operations that are not clandestine, such as ransomware and defacement, are typically covert and the initiating actor strives to conceal their identity.\nThe covert and clandestine nature of cyber operations has implications for both the initiating and target states. Initiating actors are limited in their coercive power since it is difficult to bargain when identity remains concealed.¹⁶ The interaction between the initiator and target may be prone to miscommunication due to difficulty of signaling in cyberspace. Additionally, if the target state wants to understand the nature of the exploit or retaliate, they must invest significant time and resources into the discovery of and the assignment of blame.\n¹⁵ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n¹⁶ Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n## 2.2 Attribution Problem\nSecond, in order for this theory to hold, the attribution problem—the difficulty associated with achieving technical attribution—must persist or be broadly perceived to exist. The attribution problem directly follows from the covert and clandestine nature of cyber operations. When the attribution problem was first introduced in the cyber literature, there was a belief that technical attribution of some cyber operations could be impossible to achieve. Today, a more sophisticated technical community would reject the notion that attribution is impossible.¹⁷ However, the fact remains that technical attribution of cyber operations requires time and resources.¹⁸ States lacking this capacity may continue to find themselves unable to make technical attribution, while all states, regardless of capacity, continue to deal with the implications for timely response.\n## 2.3 The Attribution Problem and Deterrence\nIn the current literature, the primary theoretical consequence of the attribution problem is its erosion of deterrence by punishment; this makes the ‘attribution problem’ even more problematic.¹⁹ Traditional conceptions of deterrence require a credible threat *ex-ante* that changes the cost-benefit analysis of the initiator. Deterrence by punishment is undermined by the difficulty of achieving swift technical attribution (i.e. the attribution problem) because it reduces the target’s ability to credibly threaten costs.\n¹⁷ Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).\n¹⁸ Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,\n¹⁹ Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nAccording to existing literature, the difficulty of technical attribution is a problem for deterrence by punishment due to temporal reasons. Traditionally, there is a sense that punishment for an action should be reasonably close in time to the action for which the retaliation is being leveled. Brantly 2018, in his discussion of cyber deterrence, points out that even if a state promises to punish in the future, upon technical attribution, “the risk of punishment for an attack is possible but so temporally distant as to be discounted to the point of irrelevance” (p.45).²⁰ In other words, the initiating state does not have incentive to change their behavior because, ex-ante, the threat of punishment is so far in the future and uncertain as to be ineffective. While the idea of temporal appropriateness of punishment has not been explored extensively in the international relations literature, it is reinforced by discourses of administering punishment in psychology and legal fields. U.S. Supreme Court Justice Stephen Breyer referenced the long time between punishment and the crime while questioning the constitutionality of the death penalty in his dissenting opinion for *Glossip v. Gross*.²¹\n## 3 Expanding the Consequences of the Attribution Problem\nThe consequences of the attribution problem are more nuanced than currently portrayed. The existing explanation for how the attribution problem erodes deterrence by punishment contains an underlying assumption that, should technical attribution be obtained, punishment would be leveled in response to a cyber operation. However, I question the validity of this assumption in the cyber domain. For deterrence by punishment to serve a legitimate deterrent capability, the initiator must find the threat of punishment credible\n²⁰ Brantly, “The cyber deterrence problem.”\n²¹ Glossip v. Gross, No. 14-7955 (June 29, 2015).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nex-ante. Selective application of punishment erodes the credibility of the threat; therefore, deterrence by punishment only succeeds when punishment is leveled in response to all cyber incidents, or, at a minimum, a clearly designated threshold which empirically does not currently exist.²²\nIn traditional escalation literature, one of the most effective ways to credibly threaten punishment is through the tying of hands.²³ Yet, difficulties in attribution and the covert and clandestine nature of cyber operations not only provide plausible deniability to the perpetrator, they also provide plausible deniability for the target that they have achieved technical attribution. This, in effect, permits the target leeway to strategically withhold or release information about their attribution or lack thereof. It is precisely this discretion that allows the target to untie their hands and selectively respond to cyber operations. In this way, the attribution problem permits target states to sacrifice deterrence by punishment in favor of agency over how they respond to cyber operations.\nThe argument presented in this paper— that difficulties in technical attribution provide the target additional strategic agency in responding to cyber operations— is predicated on several assumptions.\n## 3.1 Assumptions\nFirst and most centrally, this argument rests on the assumption that **target states do not want to respond to every cyber operation**. There are several reasons why this assumption is plausible. To begin, there is perceived to be an offensive advantage in cyberspace and the technology is widely accessible below the threshold of the state.²⁴ These\n²². Lindsay, “Tipping the scales” findings that deterrence works for large scale attacks suggest there may be a tacit understanding of this threshold, but it is not publicly stated.\n²³. Thomas C. Schelling, *Arms and Influence*, 2008th ed., Google-Books-ID: TX_yAAAAQBAJ (Yale University Press, 1966).\n²⁴. Kello, “The Meaning of the Cyber Revolution”; Lindsay, “Tipping the scales”; Nye, “Deterrence and Dissuasion in Cyberspace”; Edwards et al., “Strategic aspects of cyberattack, attribution, and blame.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncharacteristics contribute to a high volume of intrusions, exploits, and attacks, therefore making it impossible to level punishment for every action. Second, choosing how to best respond to a cyber operation is not clear-cut.²⁵ Often, there is not a tidy reciprocal cyber action that a target can take against the initiator. There are four alternative approaches to cyber exploitation by a state actor: 1) take no public action; 2) utilize diplomatic levers such as sanctions or naming and shaming; 3) treat cyber exploits as provocations that require militarization; 4) treat cyber exploits as offenses that require criminalization. This is further complicated by a lack of consensus around what ‘force’ is in the cyber domain.²⁶ For example, some scholars argue that SolarWinds is an espionage operation and, therefore, merely an act of statecraft.²⁷ While others point to the egregious scale and potential for future sabotage and power shifts due to the exploit.²⁸\nThe decision how to respond to a cyber operation is not a simple one. Lindsay states “retaliation can be costly for the one administering the punishment as well as the punished, a victim may decide not to do anything even after attribution if the costs and risks of punishing are too great” (p. 57).²⁹ Here, Lindsay identifies that responding to a cyber operation requires a cost-benefit calculation on behalf of the target state. The target state must have the resolve and political will to respond with punishment once correctly identifying their attacker. There will be instances in which leveling a response is more costly than doing nothing at all. One of the great risks of responding to a cyber operation is the risk of escalation.³⁰ Schneider\n²⁵. Erica Borghard and Shawn Lonergan, “Cyber Operations as Imperfect Tools of Escalation,” *Strategic Studies Quarterly* 63, no. 2 (2019): 122–145; Jason Healey and Robert Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability,” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n²⁶. David Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations,” *Daedalus* 145 (September 1, 2016): 37–49; Russell Buchan, “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?,” Publisher: Oxford University Press, *Journal of Conflict and Security Law* 17, no. 2 (2012): 211–227.\n²⁷. Erica Borghard and Jacquelyn Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy,” *Wired*, December 17, 2020,\n²⁸. Yevgeny Vindman, “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.,” Lawfare, January 26, 2021, accessed March 12, 2021, https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n²⁹. Lindsay, “Tipping the scales.”\n³⁰. Martin C. Libicki, *Crisis and Escalation in Cyberspace*, Google-Books-ID: D9YzsTx1mnMC (Rand\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinds that participants in wargame simulations self-restrain in response to cyber operations out of the perception that cyber is highly escalatory.³¹ Once again, this provides plausible evidence that targets of cyber operations do not want to respond to every cyber operation, including, perhaps, some of the most egregious due to a fear of escalation. The challenges of choosing which incidents to respond to, and what response is ‘appropriate’ further erode deterrence by punishment beyond the attribution problem.\nThe second assumption is that states feel pressure to “do something” when they fall victim to hostile actions from another nation-state. This pressure can come from domestic constituents, international audiences, or an internal desire to deter future actions or appear resolved against an adversary.³² The assertion that domestic public support retaliatory response is plausibly supported by survey research which shows high levels of support for retaliation. For example, survey work has found that nearly two-thirds of respondents support a military response when the United States is attacked, regardless if the means of attack are cyber or kinetic.³³ The high-level of support for retaliation is even more notable because the survey experiment tests relatively low-level exploits including financial and information theft. Only 7 percent of survey respondents selected ‘do not acknowledge the attack’ as their most preferred response, meaning 93 percent of respondents preferred the government take some sort of action.\nThe third assumption is that the attribution problem endemic in cyber domain operations (specifically the difficulty of achieving technical attribution) is widely\nElectronic copy available at: https://ssrn.com/abstract=4353069\nCorporation, 2012); Herbert Lin, “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25; Monica Kaminska, “Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks,” Journal of Cybersecurity 7 (tyab008 2021); Brandon G. Valeriano and Ben Jenson, The Myth of the Cyber Offense: The Case for Cyber Restraint, SSRN Scholarly Paper ID 3382340 (Rochester, NY: Social Science Research Network, January 15, 2019); Healey and Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability.”\n³¹. Dr Jacquelyn Schneider, “Cyber and Crisis Escalation: Insights from Wargaming” (March 2017), 43.\n³². Robert D. Putnam, “Diplomacy and domestic politics: the logic of two-level games,” 00000, International Organization 42, no. 3 (1988): 427–460.\n³³. hedgecock’sukin2023.\naccepted and the public is desensitized to it. In other words, there must be an enduring belief that technical attribution of cyber operations is difficult to achieve and that there is variation on the amount of time and feasibility required. In the kinetic domain, there is an assumption that swift technical attribution can and will be achieved. This creates expectations among domestic and international audiences that the target state will make a public attribution when they are the victim of a conventional attack or exploitation. Even in the case of terrorism, where the identity of the perpetrator may be especially hard to distill, politicians promise to identify and punish their attackers. Less than one minute into President Clinton’s statement following the USS Cole bombing he said: “We will find out who is responsible and hold them accountable.” While elected leaders may face a credibility problem or domestic political costs if they revealed a kinetic operation and said that they did not know who did it or may never know,³⁴ this is not the case for the cyber domain. In fact, the attribution problem is so endemic that several scholars have explored the challenges of convincing the public of an attribution claim in the cyber domain.³⁵ The prevalence of the public rhetoric around the attribution problem has changed expectations of attribution for cyber incidents.\nThe attribution problem is widely referenced in public discourse which helps perpetuate this belief among the public. Take, for example, the United States Office of the Director of National Intelligence’s Guide to Cyber Attribution. In discussing technical attribution, they write: “This painstaking work in many cases requires several weeks or months of analyzing intelligence and forensics. In some instances in which analysts can determine responsibility\n³⁴. James D. Fearon, “Domestic Political Audiences and the Escalation of International Disputes,” *American Political Science Review* 88, no. 3 (September 1994): 577–592; Kenneth A. Schultz, *Democracy and Coercive Diplomacy* (Cambridge University Press, July 26, 2001).\n³⁵. Marcus Schulzke, “The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty,” Num Pages: 954–968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, *Perspectives on Politics* 16, no. 4 (December 2018): 954–968; Florian J. Egloff, “Contested public attributions of cyber incidents and the role of academia,” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, *Contemporary Security Policy* 41, no. 1 (January 2, 2020): 55–81.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfor a cyber attack within hours of an incident the accuracy and level of confidence is likely to vary depending on the available data”.36 Separately, during a Biden administration press conference discussing the SolarWinds hack, Deputy National Security Advisor for Cyber and Emerging Technologies, Anne Neuberger, was pressed by a reporter asking “how long this investigation [into SolarWinds] will take?”. Neuberger responded that it would take “several months” without any resistance or skepticism.37 The difficulty of attribution was also part of mainstream dialogue in the 2016 Presidential debates where President Trump made his now infamous statement about the Democratic National Committee hack saying, “[Clinton is] saying Russia, Russia, Russia. Maybe it was. It could also be China. It could be someone sitting on their bed that weighs 400 pounds”.38 Statements such as these continue to reinforce public expectations that cyber attribution is difficult and emphasize a temporal dimension.\nTaken together, these three assumptions provide the foundation for my argument that difficulties in attribution provide target states strategic agency in their response to cyber operations. If states feel pressure to respond when they reveal they are the victim of a cyber operation, but also struggle with the appropriate response to a cyber operation, they may not want to publicly attribute the cyber operation at all or delay their attribution until they have constructed an adequate response. Therefore, the perception of attribution difficulty and the clandestine and covert nature of cyber operations provide target states the ability to manipulate revelation and public attribution to meet their strategic needs. In addition to the commonly understood erosion of deterrence by punishment by undermining the timely delivery of punishment, I\n36. A Guide to Cyber Attribution (Office of the Director of National Intelligence, September 14, 2018).\n37. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021,” The White House, January 20, 2021, accessed April 8, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\n38. Cory Bennett, “Cyber history made at the first debate,” POLITICO, September 27, 2016, accessed March 6, 2021, https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\nElectronic copy available at: https://ssrn.com/abstract=4353069\npropose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence.\n# 4 Disaggregating Attribution\nTo this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency.\nAs aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.³⁹\nThe relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical\n³⁹. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story.\nFirst, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public.\nThe second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.⁴⁰\n# 5 Target State Strategies\nIn arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy.⁴¹ To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international\n⁴⁰. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n⁴¹. Lindsay, “Tipping the scales.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs.\nDisaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine.[42] Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker.[43] In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy.\nFigure 1: Strategies of Communication for Target States\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 5.1 Collusion\nCollusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains.⁴⁴ In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation.\nWhile Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding.\nIn the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and\n⁴⁴ Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthe incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling.\nCarson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity.\n## 5.2 Disclosure\nThroughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take.⁴⁵ This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without\n⁴⁵. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nassigning blame.⁴⁶ Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation.\nDisclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist.\nLooking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected.\n## 5.2.1 Forms of Disclosure\nDisclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing\n⁴⁶. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways.\nIt is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal.\n## Ambiguous Disclosure\nFirst, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill.⁴⁷ After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response.\nAmbiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised\n⁴⁷ Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand whether blame is being intentionally withheld or not.\nAmbiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first.\n## Unattributed Disclosure\nSecond, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame.\nOne purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel.[48] In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinalize the attribution process.\n## Withheld Disclosure\nFinally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case.\nOne example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of\nElectronic copy available at: https://ssrn.com/abstract=4353069\npractical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50\nIn this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52\nThis example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution.\nThe target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists\nElectronic copy available at: https://ssrn.com/abstract=4353069\noutside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate.\nThe target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution.\nSecond, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution.\n### 5.3 Public Attribution\nFinally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide\nrange of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value.\nA target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved.\nFor one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55\nThe risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds\n54. As is the case with all cyber operations, a retaliatory cyber operation is not overt unless the target public claims credit for launching a retaliatory operation or the effects are visible and publicized.\n55. Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021.”\n56. Schultz, Democracy and Coercive Diplomacy.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected.\nAlthough public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58\n## 6 The Role of Third-Party Actors\nThus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations.\nIn the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized\n57. Carson, Secret Wars.\n58. Lin, \"Escalation Dynamics and Conflict Termination in Cyberspace\"; Libicki, Crisis and Escalation in Cyberspace.\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media.\nIn assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim.\nThird-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\".[59] Finally,\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthird parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research.\nHowever, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia.⁶⁰ Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation.\nOnly months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium.⁶¹ In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack.⁶² Interestingly, while Microsoft very\n⁶⁰. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia.\n⁶¹. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n⁶². “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nclearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government.\nIn both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude.\n# 7 Temporal Considerations\nGiven that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications.\nThere are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 7.1 Discovery-Disclosure\nFirst, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is.\nA short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures.\nAlternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty.\nAn intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves\nElectronic copy available at: https://ssrn.com/abstract=4353069\nas an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63\n## 7.2 Disclosure-Public Attribution\nThe second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution.\nThe SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and\nElectronic copy available at: https://ssrn.com/abstract=4353069\ndisclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle.\nIn contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage.⁶⁴ While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months.⁶⁵ The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.⁶⁶\nThe belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the\n⁶⁴. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n⁶⁵. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018,\n⁶⁶. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nimpact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment\nOne suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).[67]\nElectronic copy available at: https://ssrn.com/abstract=4353069\nFigure 2: NotPetya Worldwide Search Results from Google Trends\nFigure 3: WannaCry Virus Worldwide Search Results from Google Trends\nWhile retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions\nElectronic copy available at: https://ssrn.com/abstract=4353069\nresponding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response.\nWith the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a\n68. Barack Obama, “Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment,” whitehouse.gov, December 29, 2016, accessed April 8, 2021, https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\n69. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021,” The White House, February 17, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n70. Rose McDermott et al., “Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence,” Texas National Security Review 1, no. 1 (November 24, 2017).\n71. Nicole Gauvette, “White House says it will hold those responsible for SolarWinds hack accountable within weeks,” CNN, February 19, 2021, accessed February 21, 2021, https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nspecific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action.\nThe uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent.\n## 8 Type I and Type II Attribution Error\nFinally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how.\nAs previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party.\nThe common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions\n72. A Guide to Cyber Attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt.\nTo date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.\n73. Catalin Cimpanu, “EU sanctions China, Russia, and North Korea for past hacks,” ZDNet, July 30, 2020, accessed April 8, 2021, https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\n74. Borghard and Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.”\n75. Buchan, “Cyber Attacks”; Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion.”\n76. Brandon Valeriano and Ryan C Maness, “The dynamics of cyber conflict between rival antagonists, 2001–11,” Journal of Peace Research 51, no. 3 (May 2014): 347–360.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nDespite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo.\nA need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan, \"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events \"may outpace the speed of the attribution process\" (p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 9 Conclusion\nTo date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand.\nAdditionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution.\nThe argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is\nElectronic copy available at: https://ssrn.com/abstract=4353069\nkey to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications.\nElectronic copy available at: https://ssrn.com/abstract=4353069",
  "references": [
    "# References\nA Guide to Cyber Attribution. Office of the Director of National Intelligence, September 14, 2018.\n“Australia cyber attacks: PM Morrison warns of ‘sophisticated’ state hack.” BBC News, June 19, 2020.\nBennett, Cory. “Cyber history made at the first debate.” POLITICO, September 27, 2016. Accessed March 6, 2021. https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\nBiddle, Tami. “Coercion Theory: A Basic Introduction for Practitioners.” Texas National Security Review, February 20, 2020. Accessed March 4, 2021. https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/.\nBorghard, Erica, and Shawn Lonergan. “Cyber Operations as Imperfect Tools of Escalation.” Strategic Studies Quarterly 63, no. 2 (2019): 122–145.\nBorghard, Erica, and Jacquelyn Schneider. “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.” Wired, December 17, 2020.\nBorghard, Erica D., and Shawn W. Lonergan. “The Logic of Coercion in Cyberspace.” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, Security Studies 26, no. 3 (July 3, 2017): 452–481.\nBossert, Thomas P. “It’s Official: North Korea Is Behind WannaCry.” Wall Street Journal, December 19, 2017.\nBradshaw, Abigail. “General Session Panel Allies Counter Common Cyber Adversaries.” Director, Australian Cyber Security Centre, 11th Annual Billington Cybersecurity Summit 2020, September 8, 2020.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nElectronic copy available at: https://ssrn.com/abstract=4353069\nBrantly, A. F. “The cyber deterrence problem.” In 2018 10th International Conference on Cyber Conflict (CyCon), 31–54. ISSN: 2325-5374. May 2018.\nBrenner, Susan W. “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare.” The Journal of Criminal Law and Criminology (1973-) 97, no. 2 (2007): 379–475.\nBuchan, Russell. “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?” Publisher: Oxford University Press, Journal of Conflict and Security Law 17, no. 2 (2012): 211–227.\nBurt, Tom. “New nation-state cyberattacks.” Microsoft On the Issues, March 2, 2021. Accessed April 5, 2021. https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\nCanfil, Justin. “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay.” Journal of Cybersecurity, 2022.\nCarson, Austin. Secret Wars: Covert Conflict in International Politics. Princeton University Press, September 25, 2018.\nCarson, Austin, and Allison Carnegie. “The Disclosure Dilemma: Nuclear Intelligence and International Organizations.” *American Journal of Political Science* 13, no. 3 (2019): 269–285.\nCimpanu, Catalin. “EU sanctions China, Russia, and North Korea for past hacks.” ZDNET, July 30, 2020. Accessed April 8, 2021. https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\nClark, David D., and Susan Landau. “Untangling Attribution Essay.” Harvard National Security Journal 2, no. 2 (2011): 323–352.\n44\nEarnest, Josh. “Press Briefing by the Press Secretary Josh Earnest, 12/18/14.” Whitehouse.gov, December 18, 2014. Accessed April 7, 2021. https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\nEdwards, Benjamin, Alexander Furnas, Stephanie Forrest, and Robert Axelrod. “Strategic aspects of cyberattack, attribution, and blame.” Proceedings of the National Academy of Sciences 114, no. 11 (March 14, 2017): 2825–2830.\nEgloff, Florian J. “Public attribution of cyber intrusions.” Journal of Cybersecurity 6 (tyaa012 2020).\n———. “Contested public attributions of cyber incidents and the role of academia.” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, Contemporary Security Policy 41, no. 1 (January 2, 2020): 55–81.\nEgloff, Florian J., and Max Smeets. “Publicly attributing cyber attacks: a framework.” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, Journal of Strategic Studies, March 10, 2021, 1–32.\nFearon, James D. “Domestic Political Audiences and the Escalation of International Disputes.” *American Political Science Review* 88, no. 3 (September 1994): 577–592.\nFidler, David. “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations.” *Daedalus* 145 (September 1, 2016): 37–49.\nFischerkeller, Michael P., and Richard J. Harknett. “Deterrence is Not a Credible Strategy for Cyberspace.” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\nGartzke, Erik. “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.” Publisher: The MIT Press, International Security 38, no. 2 (2013): 41–73.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nGartzke, Erik, and Jon R. Lindsay. “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.” *Security Studies* 24, no. 2 (April 3, 2015): 316–348.\nGauvette, Nicole. “White House says it will hold those responsible for SolarWinds hack accountable within weeks.” CNN, February 19, 2021. Accessed February 21, 2021. https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\nGlaser, Charles L. *Deterrence of Cyber Attacks and U.S. National Security*. Report GW-CSPRI-2011-5. Cyber Security Policy and Research Institute, June 1, 2011.\nGreenberg, Andy. “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’.” *Wired*, February 15, 2018.\nHampton, Andrew. “General Session Panel Allies Counter Common Cyber Adversaries.” New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summit 2020, September 8, 2020.\nHarknett, Richard J., and Joseph S. Nye. “Is Deterrence Possible in Cyberspace?” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199.\nHealey, Jason, and Robert Jervis. “The Escalation Inversion and Other Oddities of Situational Cyber Stability.” *Texas National Security Review* 3, no. 4 (2020): 30–53.\nHedgecock, Kathryn, and Lauren Sukin. “Responding to Uncertainty: The Importance of Covertness in Support for Retaliation to Kinetic and Cyber Attacks.” *Journal of Conflict Resolution*, 2023.\nInformation Security, Federal Office for. *Bericht zur Lage der IT-Sicherheit in Deutschland 2014*. 2014.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\"Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA.\" Accessed February 1, 2021. https://www.cisa.gov/news/2021/01/05/joint-statement-federal-bureau-investigation-fbi-cybersecurity-and-infrastructure.\nJoyce, Rob. \"Improving and Making the Vulnerability Equities Process Transparent is the Right Thing to Do – The White House,\" November 15, 2017. Accessed February 9, 2021. https://trumpwhitehouse.archives.gov/articles/improving-making-vulnerability-equities-process-transparent-right-thing/.\nKaminska, Monica. \"Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks.\" Journal of Cybersecurity 7 (tyab008 2021).\nKello, Lucas. \"The Meaning of the Cyber Revolution: Perils to Theory and Statecraft.\" Publisher: The MIT Press, International Security 38, no. 2 (2013): 7-40.\nKeown, Arthur J., and John M. Pinkerton. \"Merger Announcements and Insider Trading Activity: An Empirical Investigation.\" Publisher: [American Finance Association, Wiley], The Journal of Finance 36, no. 4 (1981): 855-869.\nKushner, David. \"The Real Story of Stuxnet - IEEE Spectrum.\" IEEE Spectrum: Technology, Engineering, and Science News, February 26, 2013. Accessed April 8, 2021. https://spectrum.ieee.org/telecom/security/the-real-story-of-stuxnet.\nLibicki, Martin C. Crisis and Escalation in Cyberspace. Google-Books-ID: D9YzsTx1mnMC. Rand Corporation, 2012.\n——. Cyberdeterrence and cyberwar. In collaboration with Project Air Force (U.S.) OCLC: ocn428819545. Santa Monica, CA: RAND, 2009.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nLin, Herbert. *Attribution of Malicious Cyber Incidents: From Soup to Nuts*. SSRN Scholarly Paper ID 2835719. Rochester, NY: Social Science Research Network, September 2, 2016.\n———. “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25.\nLindsay, Jon R. “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack.” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67.\nMaurer, Tim. *Cyber Mercenaries*. Google-Books-ID: rKpCDwAAQBAJ. Cambridge University Press, January 18, 2018.\nMcDermott, Rose, Anthony C Lopez, and Peter K Hatemi. “‘Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence.” *Texas National Security Review* 1, no. 1 (November 24, 2017).\nMilton Mueller, Brenden Kuerbis, Karl Grindal, and Farzaneh Badiei. “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?” *The Cyber Defense Review* 4 (1 2019).\nMorrison, Scott. “Statement on malicious cyber activity against Australian networks — Prime Minister of Australia,” June 19, 2020. Accessed April 8, 2021. https://www.pm.gov.au/media/statement-malicious-cyber-activity-against-australian-networks.\nNewman, Lily Hay. “Hacker Lexicon: What Is the Attribution Problem?” *Wired*, December 24, 2016.\nNye, Joseph S. “Deterrence and Dissuasion in Cyberspace.” *International Security* 41, no. 3 (January 2017): 44–71.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nObama, Barack. \"Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment.\" Whitehouse.gov, December 29, 2016. Accessed April 8, 2021. https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\nOtto, Jacob, and William Spaniel. \"Doubling Down: The Danger of Disclosing Secret Action.\" International Studies Quarterly 65, no. 2 (2021): 500–511.\nPoznansky, Michael, and Evan Perkoski. \"Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution.\" Journal of Global Security Studies 3, no. 4 (October 1, 2018): 402–416.\nPsaki, Jen. \"Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021.\" The White House, February 17, 2021. https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n———. \"Press Briefing by Press Secretary Jen Psaki, January 20, 2021.\" The White House, January 20, 2021. Accessed April 8, 2021. https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\nPutnam, Robert D. \"Diplomacy and domestic politics: the logic of two-level games.\" 00000, International Organization 42, no. 3 (1988): 427–460.\nRid, Thomas, and Ben Buchanan. \"Attributing Cyber Attacks.\" Journal of Strategic Studies 38, no. 1 (January 2, 2015): 4–37.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nSanders, Sarah. \"Statement from the Press Secretary.\" The White House, February 15, 2018. Accessed December 6, 2019. https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n\"All eyes on China as it's revealed Australia was targeted in a 'sophisticated' cyber attack.\" SBS News, June 19, 2020.\nSchelling, Thomas C. Arms and Influence. 2008th ed. Google-Books-ID: TX_yAAAAQBAJ. Yale University Press, 1966.\nSchneider, Dr Jacquelyn. \"Cyber and Crisis Escalation: Insights from Wargaming,\" 43. March 2017.\nSchultz, Kenneth A. Democracy and Coercive Diplomacy. Cambridge University Press, July 26, 2001.\nSchulzke, Marcus. \"The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty.\" Num Pages: 954-968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, Perspectives on Politics 16, no. 4 (December 2018): 954-968.\n\"Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace.\" The United States Department of Justice, October 19, 2020. Accessed April 8, 2021. https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\nStilgherrian. \"Blaming Russia for NotPetya was coordinated diplomatic action.\" ZDNET, April 12, 2018. Accessed April 6, 2021. https://www.zdnet.com/article/blaming-russia-for-notpetya-was-coordinated-diplomatic-action/.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nValeriano, Brandon, and Ryan C Maness. “The dynamics of cyber conflict between rival antagonists, 2001–11.” *Journal of Peace Research* 51, no. 3 (May 2014): 347–360.\nValeriano, Brandon G., and Ben Jenson. *The Myth of the Cyber Offense: The Case for Cyber Restraint*. SSRN Scholarly Paper ID 3382340. Rochester, NY: Social Science Research Network, January 15, 2019.\nVindman, Yevgeny. “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.” Lawfare, January 26, 2021. Accessed March 12, 2021. https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\nElectronic copy available at: https://ssrn.com/abstract=4353069"
  ],
  "flat_text": "# Strategic Attribution: Target State Communication in Response to Cyber Operations\nKathryn Hedgecock\nFebruary 24, 2023\n## Abstract\nThis paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau\n# Introduction\nIn December 2014, three weeks after the Sony Picture hack, the first two questions of the White House Press Briefing asked: “Does the White House believe that North Korea is behind the hack at Sony Pictures?” and “What is the United States going to do about it?”. Reporters were asking the standard questions associated with the disclosure of a hack, namely, who is responsible and how the state will respond. The press was seeking public attribution, i.e. the public assignment of blame, which is typically a prerequisite for retaliatory action. To these questions Press Secretary John Earnest subsequently responded, “this is a matter that is still under investigation...[I] am not going to get ahead of that investigation” and “before we start publicly speculating about a response, it’s appropriate that we allow the investigation to move forward”. Press Secretary Earnest was implicitly appealing to the attribution problem –difficulty in achieving technical attribution– for why North Korea had yet to be named and no response yet taken.\nThe attribution problem is a central theme in the cyber literature. The covert and\n Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).\n Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The\nElectronic copy available at: https://ssrn.com/abstract=4353069\ntechnical nature of cyber operations make identifying the sponsor very difficult or, at a minimum, time and resource intensive. As a result, the literature focuses on the negative consequences associated with the attribution problem, primarily an erosion of the credibility and feasibility of deterrence by punishment. However, in this paper, I argue that a narrow focus on attribution as a problem overlooks the strategic agency that deniable attribution provides targets of cyber operations. Uncertainty in the ability and timeliness of attribution, coupled with the clandestine and covert nature of cyber operations, provide the target state three strategies of communication: collusion, disclosure, or public attribution; all of which should be viewed as intentional actions with strategic implications.\nThis paper contributes to the literature on covert action, cyber deterrence, and public attribution as a distinct concept. First, I advance the literature by challenging the emphasis of attribution as a “problem” in the cyber domain. Instead, I argue the attribution problem can also be a strategic asset of the target state by providing additional agency in how they respond to and communicate about cyber operations. While this strategic logic exists in covert action broadly, there are unique features of the cyber domain that heighten the target’s agency. The covert nature of most cyber operations and complexity of attribution provide plausible deniability, not only for the perpetrator, but also for the target state’s technical attribution. A target’s discretion in choosing to what extent they want to acknowledge or respond to an operation prioritizes escalation management at the expense of deterrence by punishment. Second, I extend and adapt the logic of Carson’s *Secret Wars* and Poznansky\nMIT Press, *International Security* 38, no. 2 (2013): 7–40; Martin C. Libicki, *Cyberdeterrence and cyberwar*, in collab. with Project Air Force (U.S.), OCLC: ocn428819545 (Santa Monica, CA: RAND, 2009); Jon R. Lindsay, “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack,” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67; Joseph S. Nye, “Deterrence and Dissuasion in Cyberspace,” *International Security* 41, no. 3 (January 2017): 44–71.\n Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand Perkoski's Rethinking Secrecy in Cyberspace, in arguing that the targeted state has two distinct decisions when experiencing a covert cyber attack: the decision to reveal the occurrence of an operation to the public and the decision to blame their attacker publicly. The decisions whether to reveal and blame lead to three primary communication strategies: collusion, disclosure, or public attribution. Rather than viewing attribution in the cyber domain as merely a problem to be overcome, attribution should be viewed as a multi-level, multi-player strategic decision in which the target state can choose to what extent it wants to activate domestic and international audiences and its desire to respond.\nThe objective of this paper is theory building and a descriptive effort to advance and define the study of cyber attribution. Given the challenges associated with capturing the universe of cases, empirical examples throughout will provide plausibility probes rather than a definitive test of my theory. This paper will proceed in seven parts. First, I will explore the existing literature on cyber attribution. Second, I discuss two interrelated features of cyber operations that underpin my theory: the covert and clandestine nature and the attribution problem. Third, I argue against the notion that the attribution problem is solely \"problematic\", instead arguing that these features provide a target state increased agency in their response to cyber operations. This has implications for the efficacy of deterrence by punishment, but in a different way than previously theorized. Fourth, I disaggregate attribution into two distinct actions: revealing and blaming. Fifth, I then develop the three strategies available to the target state of a cyber operation: collusion, disclosure, and public attribution. Sixth, I discuss the role of third party actors in the strategic dynamic between target and initiator. Seventh, I demonstrate how temporal considerations are magnified by the clandestine nature of cyber operations and the attribution problem. Finally, I conclude with thoughts about how the nature of cyber operations affects Type I and Type II error in\n Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution.\n# Scope\nThe scope of this theory is the strategic considerations of nation-states that are targets of covert, state-sponsored cyber operations (hereby referred to as the target state). State-sponsored cyber operations include actions taken by the state military and intelligence forces, as well as those that are conducted by state proxies. Even if the specific identity of the attacker is not known, it is often evident when an attack is plausibly associated with a state actor. Typically, the sophistication of the operation, including the resource and intelligence requirements, provide initial indications that a state sponsor may be responsible.\nNon-state actors, from lone wolves to cybercriminal syndicates, are active initiators in cyberspace, but they are outside the scope of the theory. Because of their asymmetry of power with the state, the target state requires different strategic calculations to publicly attribute non-state actors. Additionally, overt cyber operations fall outside of the scope of this theory. Overt operations are those where the perpetrator makes no effort to conceal their identity; thereby removing the target's agency to reveal or attribute. Non-state actors are more likely to initiate overt cyber operations. Currently, the empirical record shows no instances of a state officially credit-claiming a cyberattack on another nation-state.\n Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.\n Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).\n Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 1 Cyber Attribution Literature\nAttribution is among the most highly studied concepts in cyber; however, it does not carry a singular meaning across the literature. Some scholars discuss attribution as an act of simply identifying the actor or party responsible, while other scholars use attribution to mean the public act of assigning blame. While this may seem like a minor contrast, these two types of attribution have unique implications and should be understood as distinct.\nThe foundational definition of attribution is the act of identifying the sponsor of an operation (i.e. who is to blame); this will be hereby known as technical attribution. In order for a state to achieve technical attribution, human capital, technical expertise, and intelligence assets are required. There are significant sunk costs in building the capacity to conduct technical attribution for cyber operations. Technical attribution also contains a measure of uncertainty because digital forensics do not always clearly map onto a single individual or responsible party. As Lin (2016) points out, there are often different evidentiary standards depending on what ends are sought. Technical attribution typically includes a confidence indicator that captures the uncertainty associated with the assessment of ‘whodunit’. The “attribution problem” discussed within the cyber literature refers to the challenges associated with achieving timely and accurate technical attribution.\nHowever, the use of the word ‘attribution’ among policy makers, news media, and some scholars more frequently refers to a second type of attribution—the political act of publicly assigning blame; henceforth, I will refer to this as public attribution. Thomas Rid and Ben\n. Clark and Landau, “Untangling Attribution Essay”; Herbert Lin, *Attribution of Malicious Cyber Incidents: From Soup to Nuts*, SSRN Scholarly Paper ID 2835719 (Rochester, NY: Social Science Research Network, September 2, 2016); Benjamin Edwards et al., “Strategic aspects of cyberattack, attribution, and blame,” *Proceedings of the National Academy of Sciences* 114, no. 11 (March 14, 2017): 2825–2830.\n. Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Susan W. Brenner, “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare,” *The Journal of Criminal Law and Criminology* (1973-) 97, no. 2 (2007): 379–475; Florian J Egloff, “Public attribution of cyber intrusions,” *Journal of Cybersecurity* 6 (tyaa012 2020).\n. Lindsay, “Tipping the scales.”\n. Lin, *Attribution of Malicious Cyber Incidents*.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nBuchanan (2015) famously wrote “attribution is what states make of it” (p.7). Their work, *Attributing Cyber Attacks*, was among the first to develop a more nuanced understanding of cyber attribution by assessing attribution on three levels: technical, operational, and strategic. They challenged entrenched assumptions that attribution is binary and that attribution is merely a problem of evidence gathering. Specifically, Rid and Buchanan argued that attribution on a strategic level is a function of political stakes, and it is important to understand how attribution is communicated to the public.\nTo date, there has been little effort in the literature to understand public attribution as a distinct theoretical concept. One exception is Florian Egloff who develops a theoretical baseline of public attribution in his work, *Public Attribution of Cyber Intrusions*. Egloff divides attribution into two conceptual processes which he terms ‘sense-making’ and ‘meaning-making’ processes. Sense-making refers to a technical form of attribution—discovering the perpetrator’s identity—which lies at the root of the attribution problem. Meaning-making is a political strategy that considers attribution within a broader strategic consequence. Egloff has laid a foundation for exploration of attribution as an intentional act by theoretically conceptualizing how public attribution serves a states’ political ends. In subsequent work, Egloff and Smeets (2021) prescribe considerations for when a state should publicly attribute.\n## 2 Two Defining Attributes of Cyber Operations\nThere are two defining, interrelated features of cyber operations that are central to all aspects of my theory 1) the clandestine and covert nature of cyber operations and 2) the persistence of the ‘attribution problem’. Together, these characteristics have implications for the target’s\n Egloff, “Public attribution of cyber intrusions.”\n Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nability to communicate technical attribution, and how they respond to cyber operations.\n## 2.1 Covert and Clandestine Nature\nFirst, as previously discussed in the scope conditions, this theory only pertains to covert operations in which the sponsor has not claimed credit for an attack. Poznansky and Perkoski carefully outline this phenomenon in their work, *Rethinking Secrecy in Cyberspace*. The authors disaggregate secrecy into two types of operations: clandestine and covert. Clandestine operations are those that are hidden from view. Covert operations are those that are designed to conceal the identity of the perpetrator or create plausible deniability, rather than conceal the action itself. Most cyber operations are clandestine by nature given they travel over the digital network. As a result, these operations are not observable. Even cyber operations that are not clandestine, such as ransomware and defacement, are typically covert and the initiating actor strives to conceal their identity.\nThe covert and clandestine nature of cyber operations has implications for both the initiating and target states. Initiating actors are limited in their coercive power since it is difficult to bargain when identity remains concealed. The interaction between the initiator and target may be prone to miscommunication due to difficulty of signaling in cyberspace. Additionally, if the target state wants to understand the nature of the exploit or retaliate, they must invest significant time and resources into the discovery of and the assignment of blame.\n Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n## 2.2 Attribution Problem\nSecond, in order for this theory to hold, the attribution problem—the difficulty associated with achieving technical attribution—must persist or be broadly perceived to exist. The attribution problem directly follows from the covert and clandestine nature of cyber operations. When the attribution problem was first introduced in the cyber literature, there was a belief that technical attribution of some cyber operations could be impossible to achieve. Today, a more sophisticated technical community would reject the notion that attribution is impossible. However, the fact remains that technical attribution of cyber operations requires time and resources. States lacking this capacity may continue to find themselves unable to make technical attribution, while all states, regardless of capacity, continue to deal with the implications for timely response.\n## 2.3 The Attribution Problem and Deterrence\nIn the current literature, the primary theoretical consequence of the attribution problem is its erosion of deterrence by punishment; this makes the ‘attribution problem’ even more problematic. Traditional conceptions of deterrence require a credible threat *ex-ante* that changes the cost-benefit analysis of the initiator. Deterrence by punishment is undermined by the difficulty of achieving swift technical attribution (i.e. the attribution problem) because it reduces the target’s ability to credibly threaten costs.\n Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).\n Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,\n Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nAccording to existing literature, the difficulty of technical attribution is a problem for deterrence by punishment due to temporal reasons. Traditionally, there is a sense that punishment for an action should be reasonably close in time to the action for which the retaliation is being leveled. Brantly 2018, in his discussion of cyber deterrence, points out that even if a state promises to punish in the future, upon technical attribution, “the risk of punishment for an attack is possible but so temporally distant as to be discounted to the point of irrelevance” (p.45). In other words, the initiating state does not have incentive to change their behavior because, ex-ante, the threat of punishment is so far in the future and uncertain as to be ineffective. While the idea of temporal appropriateness of punishment has not been explored extensively in the international relations literature, it is reinforced by discourses of administering punishment in psychology and legal fields. U.S. Supreme Court Justice Stephen Breyer referenced the long time between punishment and the crime while questioning the constitutionality of the death penalty in his dissenting opinion for *Glossip v. Gross*.\n## 3 Expanding the Consequences of the Attribution Problem\nThe consequences of the attribution problem are more nuanced than currently portrayed. The existing explanation for how the attribution problem erodes deterrence by punishment contains an underlying assumption that, should technical attribution be obtained, punishment would be leveled in response to a cyber operation. However, I question the validity of this assumption in the cyber domain. For deterrence by punishment to serve a legitimate deterrent capability, the initiator must find the threat of punishment credible\n Brantly, “The cyber deterrence problem.”\n Glossip v. Gross, No. 14-7955 (June 29, 2015).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nex-ante. Selective application of punishment erodes the credibility of the threat; therefore, deterrence by punishment only succeeds when punishment is leveled in response to all cyber incidents, or, at a minimum, a clearly designated threshold which empirically does not currently exist.\nIn traditional escalation literature, one of the most effective ways to credibly threaten punishment is through the tying of hands. Yet, difficulties in attribution and the covert and clandestine nature of cyber operations not only provide plausible deniability to the perpetrator, they also provide plausible deniability for the target that they have achieved technical attribution. This, in effect, permits the target leeway to strategically withhold or release information about their attribution or lack thereof. It is precisely this discretion that allows the target to untie their hands and selectively respond to cyber operations. In this way, the attribution problem permits target states to sacrifice deterrence by punishment in favor of agency over how they respond to cyber operations.\nThe argument presented in this paper— that difficulties in technical attribution provide the target additional strategic agency in responding to cyber operations— is predicated on several assumptions.\n## 3.1 Assumptions\nFirst and most centrally, this argument rests on the assumption that **target states do not want to respond to every cyber operation**. There are several reasons why this assumption is plausible. To begin, there is perceived to be an offensive advantage in cyberspace and the technology is widely accessible below the threshold of the state. These\n. Lindsay, “Tipping the scales” findings that deterrence works for large scale attacks suggest there may be a tacit understanding of this threshold, but it is not publicly stated.\n. Thomas C. Schelling, *Arms and Influence*, 2008th ed., Google-Books-ID: TX_yAAAAQBAJ (Yale University Press, 1966).\n. Kello, “The Meaning of the Cyber Revolution”; Lindsay, “Tipping the scales”; Nye, “Deterrence and Dissuasion in Cyberspace”; Edwards et al., “Strategic aspects of cyberattack, attribution, and blame.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncharacteristics contribute to a high volume of intrusions, exploits, and attacks, therefore making it impossible to level punishment for every action. Second, choosing how to best respond to a cyber operation is not clear-cut. Often, there is not a tidy reciprocal cyber action that a target can take against the initiator. There are four alternative approaches to cyber exploitation by a state actor: 1) take no public action; 2) utilize diplomatic levers such as sanctions or naming and shaming; 3) treat cyber exploits as provocations that require militarization; 4) treat cyber exploits as offenses that require criminalization. This is further complicated by a lack of consensus around what ‘force’ is in the cyber domain. For example, some scholars argue that SolarWinds is an espionage operation and, therefore, merely an act of statecraft. While others point to the egregious scale and potential for future sabotage and power shifts due to the exploit.\nThe decision how to respond to a cyber operation is not a simple one. Lindsay states “retaliation can be costly for the one administering the punishment as well as the punished, a victim may decide not to do anything even after attribution if the costs and risks of punishing are too great” (p. 57). Here, Lindsay identifies that responding to a cyber operation requires a cost-benefit calculation on behalf of the target state. The target state must have the resolve and political will to respond with punishment once correctly identifying their attacker. There will be instances in which leveling a response is more costly than doing nothing at all. One of the great risks of responding to a cyber operation is the risk of escalation. Schneider\n. Erica Borghard and Shawn Lonergan, “Cyber Operations as Imperfect Tools of Escalation,” *Strategic Studies Quarterly* 63, no. 2 (2019): 122–145; Jason Healey and Robert Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability,” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n. David Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations,” *Daedalus* 145 (September 1, 2016): 37–49; Russell Buchan, “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?,” Publisher: Oxford University Press, *Journal of Conflict and Security Law* 17, no. 2 (2012): 211–227.\n. Erica Borghard and Jacquelyn Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy,” *Wired*, December 17, 2020,\n. Yevgeny Vindman, “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.,” Lawfare, January 26, 2021, accessed March 12, 2021, https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n. Lindsay, “Tipping the scales.”\n. Martin C. Libicki, *Crisis and Escalation in Cyberspace*, Google-Books-ID: D9YzsTx1mnMC (Rand\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinds that participants in wargame simulations self-restrain in response to cyber operations out of the perception that cyber is highly escalatory. Once again, this provides plausible evidence that targets of cyber operations do not want to respond to every cyber operation, including, perhaps, some of the most egregious due to a fear of escalation. The challenges of choosing which incidents to respond to, and what response is ‘appropriate’ further erode deterrence by punishment beyond the attribution problem.\nThe second assumption is that states feel pressure to “do something” when they fall victim to hostile actions from another nation-state. This pressure can come from domestic constituents, international audiences, or an internal desire to deter future actions or appear resolved against an adversary. The assertion that domestic public support retaliatory response is plausibly supported by survey research which shows high levels of support for retaliation. For example, survey work has found that nearly two-thirds of respondents support a military response when the United States is attacked, regardless if the means of attack are cyber or kinetic. The high-level of support for retaliation is even more notable because the survey experiment tests relatively low-level exploits including financial and information theft. Only 7 percent of survey respondents selected ‘do not acknowledge the attack’ as their most preferred response, meaning 93 percent of respondents preferred the government take some sort of action.\nThe third assumption is that the attribution problem endemic in cyber domain operations (specifically the difficulty of achieving technical attribution) is widely\nElectronic copy available at: https://ssrn.com/abstract=4353069\nCorporation, 2012); Herbert Lin, “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25; Monica Kaminska, “Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks,” Journal of Cybersecurity 7 (tyab008 2021); Brandon G. Valeriano and Ben Jenson, The Myth of the Cyber Offense: The Case for Cyber Restraint, SSRN Scholarly Paper ID 3382340 (Rochester, NY: Social Science Research Network, January 15, 2019); Healey and Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability.”\n. Dr Jacquelyn Schneider, “Cyber and Crisis Escalation: Insights from Wargaming” (March 2017), 43.\n. Robert D. Putnam, “Diplomacy and domestic politics: the logic of two-level games,” 00000, International Organization 42, no. 3 (1988): 427–460.\n. hedgecock’sukin2023.\naccepted and the public is desensitized to it. In other words, there must be an enduring belief that technical attribution of cyber operations is difficult to achieve and that there is variation on the amount of time and feasibility required. In the kinetic domain, there is an assumption that swift technical attribution can and will be achieved. This creates expectations among domestic and international audiences that the target state will make a public attribution when they are the victim of a conventional attack or exploitation. Even in the case of terrorism, where the identity of the perpetrator may be especially hard to distill, politicians promise to identify and punish their attackers. Less than one minute into President Clinton’s statement following the USS Cole bombing he said: “We will find out who is responsible and hold them accountable.” While elected leaders may face a credibility problem or domestic political costs if they revealed a kinetic operation and said that they did not know who did it or may never know, this is not the case for the cyber domain. In fact, the attribution problem is so endemic that several scholars have explored the challenges of convincing the public of an attribution claim in the cyber domain. The prevalence of the public rhetoric around the attribution problem has changed expectations of attribution for cyber incidents.\nThe attribution problem is widely referenced in public discourse which helps perpetuate this belief among the public. Take, for example, the United States Office of the Director of National Intelligence’s Guide to Cyber Attribution. In discussing technical attribution, they write: “This painstaking work in many cases requires several weeks or months of analyzing intelligence and forensics. In some instances in which analysts can determine responsibility\n. James D. Fearon, “Domestic Political Audiences and the Escalation of International Disputes,” *American Political Science Review* 88, no. 3 (September 1994): 577–592; Kenneth A. Schultz, *Democracy and Coercive Diplomacy* (Cambridge University Press, July 26, 2001).\n. Marcus Schulzke, “The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty,” Num Pages: 954–968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, *Perspectives on Politics* 16, no. 4 (December 2018): 954–968; Florian J. Egloff, “Contested public attributions of cyber incidents and the role of academia,” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, *Contemporary Security Policy* 41, no. 1 (January 2, 2020): 55–81.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfor a cyber attack within hours of an incident the accuracy and level of confidence is likely to vary depending on the available data”.36 Separately, during a Biden administration press conference discussing the SolarWinds hack, Deputy National Security Advisor for Cyber and Emerging Technologies, Anne Neuberger, was pressed by a reporter asking “how long this investigation [into SolarWinds] will take?”. Neuberger responded that it would take “several months” without any resistance or skepticism.37 The difficulty of attribution was also part of mainstream dialogue in the 2016 Presidential debates where President Trump made his now infamous statement about the Democratic National Committee hack saying, “[Clinton is] saying Russia, Russia, Russia. Maybe it was. It could also be China. It could be someone sitting on their bed that weighs 400 pounds”.38 Statements such as these continue to reinforce public expectations that cyber attribution is difficult and emphasize a temporal dimension.\nTaken together, these three assumptions provide the foundation for my argument that difficulties in attribution provide target states strategic agency in their response to cyber operations. If states feel pressure to respond when they reveal they are the victim of a cyber operation, but also struggle with the appropriate response to a cyber operation, they may not want to publicly attribute the cyber operation at all or delay their attribution until they have constructed an adequate response. Therefore, the perception of attribution difficulty and the clandestine and covert nature of cyber operations provide target states the ability to manipulate revelation and public attribution to meet their strategic needs. In addition to the commonly understood erosion of deterrence by punishment by undermining the timely delivery of punishment, I\n36. A Guide to Cyber Attribution (Office of the Director of National Intelligence, September 14, 2018).\n37. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021,” The White House, January 20, 2021, accessed April 8, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\n38. Cory Bennett, “Cyber history made at the first debate,” POLITICO, September 27, 2016, accessed March 6, 2021, https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\nElectronic copy available at: https://ssrn.com/abstract=4353069\npropose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence.\n# 4 Disaggregating Attribution\nTo this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency.\nAs aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.\nThe relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical\n. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story.\nFirst, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public.\nThe second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.\n# 5 Target State Strategies\nIn arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy. To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international\n. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n. Lindsay, “Tipping the scales.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs.\nDisaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine.[42] Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker.[43] In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy.\nFigure 1: Strategies of Communication for Target States\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 5.1 Collusion\nCollusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains. In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation.\nWhile Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding.\nIn the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and\n Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthe incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling.\nCarson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity.\n## 5.2 Disclosure\nThroughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take. This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without\n. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nassigning blame. Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation.\nDisclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist.\nLooking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected.\n## 5.2.1 Forms of Disclosure\nDisclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing\n. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways.\nIt is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal.\n## Ambiguous Disclosure\nFirst, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill. After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response.\nAmbiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised\n Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand whether blame is being intentionally withheld or not.\nAmbiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first.\n## Unattributed Disclosure\nSecond, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame.\nOne purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel.[48] In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinalize the attribution process.\n## Withheld Disclosure\nFinally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case.\nOne example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of\nElectronic copy available at: https://ssrn.com/abstract=4353069\npractical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50\nIn this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52\nThis example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution.\nThe target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists\nElectronic copy available at: https://ssrn.com/abstract=4353069\noutside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate.\nThe target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution.\nSecond, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution.\n### 5.3 Public Attribution\nFinally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide\nrange of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value.\nA target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved.\nFor one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55\nThe risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds\n54. As is the case with all cyber operations, a retaliatory cyber operation is not overt unless the target public claims credit for launching a retaliatory operation or the effects are visible and publicized.\n55. Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021.”\n56. Schultz, Democracy and Coercive Diplomacy.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected.\nAlthough public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58\n## 6 The Role of Third-Party Actors\nThus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations.\nIn the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized\n57. Carson, Secret Wars.\n58. Lin, \"Escalation Dynamics and Conflict Termination in Cyberspace\"; Libicki, Crisis and Escalation in Cyberspace.\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media.\nIn assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim.\nThird-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\".[59] Finally,\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthird parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research.\nHowever, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia. Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation.\nOnly months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium. In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack. Interestingly, while Microsoft very\n. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia.\n. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n. “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nclearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government.\nIn both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude.\n# 7 Temporal Considerations\nGiven that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications.\nThere are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 7.1 Discovery-Disclosure\nFirst, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is.\nA short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures.\nAlternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty.\nAn intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves\nElectronic copy available at: https://ssrn.com/abstract=4353069\nas an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63\n## 7.2 Disclosure-Public Attribution\nThe second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution.\nThe SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and\nElectronic copy available at: https://ssrn.com/abstract=4353069\ndisclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle.\nIn contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage. While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months. The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.\nThe belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the\n. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018,\n. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nimpact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment\nOne suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).[67]\nElectronic copy available at: https://ssrn.com/abstract=4353069\nFigure 2: NotPetya Worldwide Search Results from Google Trends\nFigure 3: WannaCry Virus Worldwide Search Results from Google Trends\nWhile retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions\nElectronic copy available at: https://ssrn.com/abstract=4353069\nresponding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response.\nWith the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a\n68. Barack Obama, “Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment,” whitehouse.gov, December 29, 2016, accessed April 8, 2021, https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\n69. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021,” The White House, February 17, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n70. Rose McDermott et al., “Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence,” Texas National Security Review 1, no. 1 (November 24, 2017).\n71. Nicole Gauvette, “White House says it will hold those responsible for SolarWinds hack accountable within weeks,” CNN, February 19, 2021, accessed February 21, 2021, https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nspecific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action.\nThe uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent.\n## 8 Type I and Type II Attribution Error\nFinally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how.\nAs previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party.\nThe common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions\n72. A Guide to Cyber Attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt.\nTo date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.\n73. Catalin Cimpanu, “EU sanctions China, Russia, and North Korea for past hacks,” ZDNet, July 30, 2020, accessed April 8, 2021, https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\n74. Borghard and Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.”\n75. Buchan, “Cyber Attacks”; Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion.”\n76. Brandon Valeriano and Ryan C Maness, “The dynamics of cyber conflict between rival antagonists, 2001–11,” Journal of Peace Research 51, no. 3 (May 2014): 347–360.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nDespite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo.\nA need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan, \"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events \"may outpace the speed of the attribution process\" (p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 9 Conclusion\nTo date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand.\nAdditionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution.\nThe argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is\nElectronic copy available at: https://ssrn.com/abstract=4353069\nkey to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications.\nElectronic copy available at: https://ssrn.com/abstract=4353069",
  "citations": {
    "style": "superscript",
    "flat_text": "# Strategic Attribution: Target State Communication in Response to Cyber Operations\nKathryn Hedgecock\nFebruary 24, 2023\n## Abstract\nThis paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau\n# Introduction\nIn December 2014, three weeks after the Sony Picture hack, the first two questions of the White House Press Briefing asked: “Does the White House believe that North Korea is behind the hack at Sony Pictures?” and “What is the United States going to do about it?”. Reporters were asking the standard questions associated with the disclosure of a hack, namely, who is responsible and how the state will respond. The press was seeking public attribution, i.e. the public assignment of blame, which is typically a prerequisite for retaliatory action. To these questions Press Secretary John Earnest subsequently responded, “this is a matter that is still under investigation...[I] am not going to get ahead of that investigation” and “before we start publicly speculating about a response, it’s appropriate that we allow the investigation to move forward”. Press Secretary Earnest was implicitly appealing to the attribution problem –difficulty in achieving technical attribution– for why North Korea had yet to be named and no response yet taken.\nThe attribution problem is a central theme in the cyber literature. The covert and\n Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).\n Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The\nElectronic copy available at: https://ssrn.com/abstract=4353069\ntechnical nature of cyber operations make identifying the sponsor very difficult or, at a minimum, time and resource intensive. As a result, the literature focuses on the negative consequences associated with the attribution problem, primarily an erosion of the credibility and feasibility of deterrence by punishment. However, in this paper, I argue that a narrow focus on attribution as a problem overlooks the strategic agency that deniable attribution provides targets of cyber operations. Uncertainty in the ability and timeliness of attribution, coupled with the clandestine and covert nature of cyber operations, provide the target state three strategies of communication: collusion, disclosure, or public attribution; all of which should be viewed as intentional actions with strategic implications.\nThis paper contributes to the literature on covert action, cyber deterrence, and public attribution as a distinct concept. First, I advance the literature by challenging the emphasis of attribution as a “problem” in the cyber domain. Instead, I argue the attribution problem can also be a strategic asset of the target state by providing additional agency in how they respond to and communicate about cyber operations. While this strategic logic exists in covert action broadly, there are unique features of the cyber domain that heighten the target’s agency. The covert nature of most cyber operations and complexity of attribution provide plausible deniability, not only for the perpetrator, but also for the target state’s technical attribution. A target’s discretion in choosing to what extent they want to acknowledge or respond to an operation prioritizes escalation management at the expense of deterrence by punishment. Second, I extend and adapt the logic of Carson’s *Secret Wars* and Poznansky\nMIT Press, *International Security* 38, no. 2 (2013): 7–40; Martin C. Libicki, *Cyberdeterrence and cyberwar*, in collab. with Project Air Force (U.S.), OCLC: ocn428819545 (Santa Monica, CA: RAND, 2009); Jon R. Lindsay, “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack,” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67; Joseph S. Nye, “Deterrence and Dissuasion in Cyberspace,” *International Security* 41, no. 3 (January 2017): 44–71.\n Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand Perkoski's Rethinking Secrecy in Cyberspace, in arguing that the targeted state has two distinct decisions when experiencing a covert cyber attack: the decision to reveal the occurrence of an operation to the public and the decision to blame their attacker publicly. The decisions whether to reveal and blame lead to three primary communication strategies: collusion, disclosure, or public attribution. Rather than viewing attribution in the cyber domain as merely a problem to be overcome, attribution should be viewed as a multi-level, multi-player strategic decision in which the target state can choose to what extent it wants to activate domestic and international audiences and its desire to respond.\nThe objective of this paper is theory building and a descriptive effort to advance and define the study of cyber attribution. Given the challenges associated with capturing the universe of cases, empirical examples throughout will provide plausibility probes rather than a definitive test of my theory. This paper will proceed in seven parts. First, I will explore the existing literature on cyber attribution. Second, I discuss two interrelated features of cyber operations that underpin my theory: the covert and clandestine nature and the attribution problem. Third, I argue against the notion that the attribution problem is solely \"problematic\", instead arguing that these features provide a target state increased agency in their response to cyber operations. This has implications for the efficacy of deterrence by punishment, but in a different way than previously theorized. Fourth, I disaggregate attribution into two distinct actions: revealing and blaming. Fifth, I then develop the three strategies available to the target state of a cyber operation: collusion, disclosure, and public attribution. Sixth, I discuss the role of third party actors in the strategic dynamic between target and initiator. Seventh, I demonstrate how temporal considerations are magnified by the clandestine nature of cyber operations and the attribution problem. Finally, I conclude with thoughts about how the nature of cyber operations affects Type I and Type II error in\n Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution.\n# Scope\nThe scope of this theory is the strategic considerations of nation-states that are targets of covert, state-sponsored cyber operations (hereby referred to as the target state). State-sponsored cyber operations include actions taken by the state military and intelligence forces, as well as those that are conducted by state proxies. Even if the specific identity of the attacker is not known, it is often evident when an attack is plausibly associated with a state actor. Typically, the sophistication of the operation, including the resource and intelligence requirements, provide initial indications that a state sponsor may be responsible.\nNon-state actors, from lone wolves to cybercriminal syndicates, are active initiators in cyberspace, but they are outside the scope of the theory. Because of their asymmetry of power with the state, the target state requires different strategic calculations to publicly attribute non-state actors. Additionally, overt cyber operations fall outside of the scope of this theory. Overt operations are those where the perpetrator makes no effort to conceal their identity; thereby removing the target's agency to reveal or attribute. Non-state actors are more likely to initiate overt cyber operations. Currently, the empirical record shows no instances of a state officially credit-claiming a cyberattack on another nation-state.\n Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.\n Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).\n Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 1 Cyber Attribution Literature\nAttribution is among the most highly studied concepts in cyber; however, it does not carry a singular meaning across the literature. Some scholars discuss attribution as an act of simply identifying the actor or party responsible, while other scholars use attribution to mean the public act of assigning blame. While this may seem like a minor contrast, these two types of attribution have unique implications and should be understood as distinct.\nThe foundational definition of attribution is the act of identifying the sponsor of an operation (i.e. who is to blame); this will be hereby known as technical attribution. In order for a state to achieve technical attribution, human capital, technical expertise, and intelligence assets are required. There are significant sunk costs in building the capacity to conduct technical attribution for cyber operations. Technical attribution also contains a measure of uncertainty because digital forensics do not always clearly map onto a single individual or responsible party. As Lin (2016) points out, there are often different evidentiary standards depending on what ends are sought. Technical attribution typically includes a confidence indicator that captures the uncertainty associated with the assessment of ‘whodunit’. The “attribution problem” discussed within the cyber literature refers to the challenges associated with achieving timely and accurate technical attribution.\nHowever, the use of the word ‘attribution’ among policy makers, news media, and some scholars more frequently refers to a second type of attribution—the political act of publicly assigning blame; henceforth, I will refer to this as public attribution. Thomas Rid and Ben\n. Clark and Landau, “Untangling Attribution Essay”; Herbert Lin, *Attribution of Malicious Cyber Incidents: From Soup to Nuts*, SSRN Scholarly Paper ID 2835719 (Rochester, NY: Social Science Research Network, September 2, 2016); Benjamin Edwards et al., “Strategic aspects of cyberattack, attribution, and blame,” *Proceedings of the National Academy of Sciences* 114, no. 11 (March 14, 2017): 2825–2830.\n. Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Susan W. Brenner, “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare,” *The Journal of Criminal Law and Criminology* (1973-) 97, no. 2 (2007): 379–475; Florian J Egloff, “Public attribution of cyber intrusions,” *Journal of Cybersecurity* 6 (tyaa012 2020).\n. Lindsay, “Tipping the scales.”\n. Lin, *Attribution of Malicious Cyber Incidents*.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nBuchanan (2015) famously wrote “attribution is what states make of it” (p.7). Their work, *Attributing Cyber Attacks*, was among the first to develop a more nuanced understanding of cyber attribution by assessing attribution on three levels: technical, operational, and strategic. They challenged entrenched assumptions that attribution is binary and that attribution is merely a problem of evidence gathering. Specifically, Rid and Buchanan argued that attribution on a strategic level is a function of political stakes, and it is important to understand how attribution is communicated to the public.\nTo date, there has been little effort in the literature to understand public attribution as a distinct theoretical concept. One exception is Florian Egloff who develops a theoretical baseline of public attribution in his work, *Public Attribution of Cyber Intrusions*. Egloff divides attribution into two conceptual processes which he terms ‘sense-making’ and ‘meaning-making’ processes. Sense-making refers to a technical form of attribution—discovering the perpetrator’s identity—which lies at the root of the attribution problem. Meaning-making is a political strategy that considers attribution within a broader strategic consequence. Egloff has laid a foundation for exploration of attribution as an intentional act by theoretically conceptualizing how public attribution serves a states’ political ends. In subsequent work, Egloff and Smeets (2021) prescribe considerations for when a state should publicly attribute.\n## 2 Two Defining Attributes of Cyber Operations\nThere are two defining, interrelated features of cyber operations that are central to all aspects of my theory 1) the clandestine and covert nature of cyber operations and 2) the persistence of the ‘attribution problem’. Together, these characteristics have implications for the target’s\n Egloff, “Public attribution of cyber intrusions.”\n Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nability to communicate technical attribution, and how they respond to cyber operations.\n## 2.1 Covert and Clandestine Nature\nFirst, as previously discussed in the scope conditions, this theory only pertains to covert operations in which the sponsor has not claimed credit for an attack. Poznansky and Perkoski carefully outline this phenomenon in their work, *Rethinking Secrecy in Cyberspace*. The authors disaggregate secrecy into two types of operations: clandestine and covert. Clandestine operations are those that are hidden from view. Covert operations are those that are designed to conceal the identity of the perpetrator or create plausible deniability, rather than conceal the action itself. Most cyber operations are clandestine by nature given they travel over the digital network. As a result, these operations are not observable. Even cyber operations that are not clandestine, such as ransomware and defacement, are typically covert and the initiating actor strives to conceal their identity.\nThe covert and clandestine nature of cyber operations has implications for both the initiating and target states. Initiating actors are limited in their coercive power since it is difficult to bargain when identity remains concealed. The interaction between the initiator and target may be prone to miscommunication due to difficulty of signaling in cyberspace. Additionally, if the target state wants to understand the nature of the exploit or retaliate, they must invest significant time and resources into the discovery of and the assignment of blame.\n Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n## 2.2 Attribution Problem\nSecond, in order for this theory to hold, the attribution problem—the difficulty associated with achieving technical attribution—must persist or be broadly perceived to exist. The attribution problem directly follows from the covert and clandestine nature of cyber operations. When the attribution problem was first introduced in the cyber literature, there was a belief that technical attribution of some cyber operations could be impossible to achieve. Today, a more sophisticated technical community would reject the notion that attribution is impossible. However, the fact remains that technical attribution of cyber operations requires time and resources. States lacking this capacity may continue to find themselves unable to make technical attribution, while all states, regardless of capacity, continue to deal with the implications for timely response.\n## 2.3 The Attribution Problem and Deterrence\nIn the current literature, the primary theoretical consequence of the attribution problem is its erosion of deterrence by punishment; this makes the ‘attribution problem’ even more problematic. Traditional conceptions of deterrence require a credible threat *ex-ante* that changes the cost-benefit analysis of the initiator. Deterrence by punishment is undermined by the difficulty of achieving swift technical attribution (i.e. the attribution problem) because it reduces the target’s ability to credibly threaten costs.\n Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).\n Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,\n Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nAccording to existing literature, the difficulty of technical attribution is a problem for deterrence by punishment due to temporal reasons. Traditionally, there is a sense that punishment for an action should be reasonably close in time to the action for which the retaliation is being leveled. Brantly 2018, in his discussion of cyber deterrence, points out that even if a state promises to punish in the future, upon technical attribution, “the risk of punishment for an attack is possible but so temporally distant as to be discounted to the point of irrelevance” (p.45). In other words, the initiating state does not have incentive to change their behavior because, ex-ante, the threat of punishment is so far in the future and uncertain as to be ineffective. While the idea of temporal appropriateness of punishment has not been explored extensively in the international relations literature, it is reinforced by discourses of administering punishment in psychology and legal fields. U.S. Supreme Court Justice Stephen Breyer referenced the long time between punishment and the crime while questioning the constitutionality of the death penalty in his dissenting opinion for *Glossip v. Gross*.\n## 3 Expanding the Consequences of the Attribution Problem\nThe consequences of the attribution problem are more nuanced than currently portrayed. The existing explanation for how the attribution problem erodes deterrence by punishment contains an underlying assumption that, should technical attribution be obtained, punishment would be leveled in response to a cyber operation. However, I question the validity of this assumption in the cyber domain. For deterrence by punishment to serve a legitimate deterrent capability, the initiator must find the threat of punishment credible\n Brantly, “The cyber deterrence problem.”\n Glossip v. Gross, No. 14-7955 (June 29, 2015).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nex-ante. Selective application of punishment erodes the credibility of the threat; therefore, deterrence by punishment only succeeds when punishment is leveled in response to all cyber incidents, or, at a minimum, a clearly designated threshold which empirically does not currently exist.\nIn traditional escalation literature, one of the most effective ways to credibly threaten punishment is through the tying of hands. Yet, difficulties in attribution and the covert and clandestine nature of cyber operations not only provide plausible deniability to the perpetrator, they also provide plausible deniability for the target that they have achieved technical attribution. This, in effect, permits the target leeway to strategically withhold or release information about their attribution or lack thereof. It is precisely this discretion that allows the target to untie their hands and selectively respond to cyber operations. In this way, the attribution problem permits target states to sacrifice deterrence by punishment in favor of agency over how they respond to cyber operations.\nThe argument presented in this paper— that difficulties in technical attribution provide the target additional strategic agency in responding to cyber operations— is predicated on several assumptions.\n## 3.1 Assumptions\nFirst and most centrally, this argument rests on the assumption that **target states do not want to respond to every cyber operation**. There are several reasons why this assumption is plausible. To begin, there is perceived to be an offensive advantage in cyberspace and the technology is widely accessible below the threshold of the state. These\n. Lindsay, “Tipping the scales” findings that deterrence works for large scale attacks suggest there may be a tacit understanding of this threshold, but it is not publicly stated.\n. Thomas C. Schelling, *Arms and Influence*, 2008th ed., Google-Books-ID: TX_yAAAAQBAJ (Yale University Press, 1966).\n. Kello, “The Meaning of the Cyber Revolution”; Lindsay, “Tipping the scales”; Nye, “Deterrence and Dissuasion in Cyberspace”; Edwards et al., “Strategic aspects of cyberattack, attribution, and blame.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncharacteristics contribute to a high volume of intrusions, exploits, and attacks, therefore making it impossible to level punishment for every action. Second, choosing how to best respond to a cyber operation is not clear-cut. Often, there is not a tidy reciprocal cyber action that a target can take against the initiator. There are four alternative approaches to cyber exploitation by a state actor: 1) take no public action; 2) utilize diplomatic levers such as sanctions or naming and shaming; 3) treat cyber exploits as provocations that require militarization; 4) treat cyber exploits as offenses that require criminalization. This is further complicated by a lack of consensus around what ‘force’ is in the cyber domain. For example, some scholars argue that SolarWinds is an espionage operation and, therefore, merely an act of statecraft. While others point to the egregious scale and potential for future sabotage and power shifts due to the exploit.\nThe decision how to respond to a cyber operation is not a simple one. Lindsay states “retaliation can be costly for the one administering the punishment as well as the punished, a victim may decide not to do anything even after attribution if the costs and risks of punishing are too great” (p. 57). Here, Lindsay identifies that responding to a cyber operation requires a cost-benefit calculation on behalf of the target state. The target state must have the resolve and political will to respond with punishment once correctly identifying their attacker. There will be instances in which leveling a response is more costly than doing nothing at all. One of the great risks of responding to a cyber operation is the risk of escalation. Schneider\n. Erica Borghard and Shawn Lonergan, “Cyber Operations as Imperfect Tools of Escalation,” *Strategic Studies Quarterly* 63, no. 2 (2019): 122–145; Jason Healey and Robert Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability,” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n. David Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations,” *Daedalus* 145 (September 1, 2016): 37–49; Russell Buchan, “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?,” Publisher: Oxford University Press, *Journal of Conflict and Security Law* 17, no. 2 (2012): 211–227.\n. Erica Borghard and Jacquelyn Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy,” *Wired*, December 17, 2020,\n. Yevgeny Vindman, “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.,” Lawfare, January 26, 2021, accessed March 12, 2021, https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n. Lindsay, “Tipping the scales.”\n. Martin C. Libicki, *Crisis and Escalation in Cyberspace*, Google-Books-ID: D9YzsTx1mnMC (Rand\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinds that participants in wargame simulations self-restrain in response to cyber operations out of the perception that cyber is highly escalatory. Once again, this provides plausible evidence that targets of cyber operations do not want to respond to every cyber operation, including, perhaps, some of the most egregious due to a fear of escalation. The challenges of choosing which incidents to respond to, and what response is ‘appropriate’ further erode deterrence by punishment beyond the attribution problem.\nThe second assumption is that states feel pressure to “do something” when they fall victim to hostile actions from another nation-state. This pressure can come from domestic constituents, international audiences, or an internal desire to deter future actions or appear resolved against an adversary. The assertion that domestic public support retaliatory response is plausibly supported by survey research which shows high levels of support for retaliation. For example, survey work has found that nearly two-thirds of respondents support a military response when the United States is attacked, regardless if the means of attack are cyber or kinetic. The high-level of support for retaliation is even more notable because the survey experiment tests relatively low-level exploits including financial and information theft. Only 7 percent of survey respondents selected ‘do not acknowledge the attack’ as their most preferred response, meaning 93 percent of respondents preferred the government take some sort of action.\nThe third assumption is that the attribution problem endemic in cyber domain operations (specifically the difficulty of achieving technical attribution) is widely\nElectronic copy available at: https://ssrn.com/abstract=4353069\nCorporation, 2012); Herbert Lin, “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25; Monica Kaminska, “Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks,” Journal of Cybersecurity 7 (tyab008 2021); Brandon G. Valeriano and Ben Jenson, The Myth of the Cyber Offense: The Case for Cyber Restraint, SSRN Scholarly Paper ID 3382340 (Rochester, NY: Social Science Research Network, January 15, 2019); Healey and Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability.”\n. Dr Jacquelyn Schneider, “Cyber and Crisis Escalation: Insights from Wargaming” (March 2017), 43.\n. Robert D. Putnam, “Diplomacy and domestic politics: the logic of two-level games,” 00000, International Organization 42, no. 3 (1988): 427–460.\n. hedgecock’sukin2023.\naccepted and the public is desensitized to it. In other words, there must be an enduring belief that technical attribution of cyber operations is difficult to achieve and that there is variation on the amount of time and feasibility required. In the kinetic domain, there is an assumption that swift technical attribution can and will be achieved. This creates expectations among domestic and international audiences that the target state will make a public attribution when they are the victim of a conventional attack or exploitation. Even in the case of terrorism, where the identity of the perpetrator may be especially hard to distill, politicians promise to identify and punish their attackers. Less than one minute into President Clinton’s statement following the USS Cole bombing he said: “We will find out who is responsible and hold them accountable.” While elected leaders may face a credibility problem or domestic political costs if they revealed a kinetic operation and said that they did not know who did it or may never know, this is not the case for the cyber domain. In fact, the attribution problem is so endemic that several scholars have explored the challenges of convincing the public of an attribution claim in the cyber domain. The prevalence of the public rhetoric around the attribution problem has changed expectations of attribution for cyber incidents.\nThe attribution problem is widely referenced in public discourse which helps perpetuate this belief among the public. Take, for example, the United States Office of the Director of National Intelligence’s Guide to Cyber Attribution. In discussing technical attribution, they write: “This painstaking work in many cases requires several weeks or months of analyzing intelligence and forensics. In some instances in which analysts can determine responsibility\n. James D. Fearon, “Domestic Political Audiences and the Escalation of International Disputes,” *American Political Science Review* 88, no. 3 (September 1994): 577–592; Kenneth A. Schultz, *Democracy and Coercive Diplomacy* (Cambridge University Press, July 26, 2001).\n. Marcus Schulzke, “The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty,” Num Pages: 954–968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, *Perspectives on Politics* 16, no. 4 (December 2018): 954–968; Florian J. Egloff, “Contested public attributions of cyber incidents and the role of academia,” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, *Contemporary Security Policy* 41, no. 1 (January 2, 2020): 55–81.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfor a cyber attack within hours of an incident the accuracy and level of confidence is likely to vary depending on the available data”.36 Separately, during a Biden administration press conference discussing the SolarWinds hack, Deputy National Security Advisor for Cyber and Emerging Technologies, Anne Neuberger, was pressed by a reporter asking “how long this investigation [into SolarWinds] will take?”. Neuberger responded that it would take “several months” without any resistance or skepticism.37 The difficulty of attribution was also part of mainstream dialogue in the 2016 Presidential debates where President Trump made his now infamous statement about the Democratic National Committee hack saying, “[Clinton is] saying Russia, Russia, Russia. Maybe it was. It could also be China. It could be someone sitting on their bed that weighs 400 pounds”.38 Statements such as these continue to reinforce public expectations that cyber attribution is difficult and emphasize a temporal dimension.\nTaken together, these three assumptions provide the foundation for my argument that difficulties in attribution provide target states strategic agency in their response to cyber operations. If states feel pressure to respond when they reveal they are the victim of a cyber operation, but also struggle with the appropriate response to a cyber operation, they may not want to publicly attribute the cyber operation at all or delay their attribution until they have constructed an adequate response. Therefore, the perception of attribution difficulty and the clandestine and covert nature of cyber operations provide target states the ability to manipulate revelation and public attribution to meet their strategic needs. In addition to the commonly understood erosion of deterrence by punishment by undermining the timely delivery of punishment, I\n36. A Guide to Cyber Attribution (Office of the Director of National Intelligence, September 14, 2018).\n37. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021,” The White House, January 20, 2021, accessed April 8, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\n38. Cory Bennett, “Cyber history made at the first debate,” POLITICO, September 27, 2016, accessed March 6, 2021, https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\nElectronic copy available at: https://ssrn.com/abstract=4353069\npropose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence.\n# 4 Disaggregating Attribution\nTo this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency.\nAs aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.\nThe relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical\n. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story.\nFirst, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public.\nThe second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.\n# 5 Target State Strategies\nIn arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy. To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international\n. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n. Lindsay, “Tipping the scales.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs.\nDisaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine.[42] Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker.[43] In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy.\nFigure 1: Strategies of Communication for Target States\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 5.1 Collusion\nCollusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains. In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation.\nWhile Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding.\nIn the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and\n Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthe incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling.\nCarson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity.\n## 5.2 Disclosure\nThroughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take. This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without\n. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nassigning blame. Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation.\nDisclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist.\nLooking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected.\n## 5.2.1 Forms of Disclosure\nDisclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing\n. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways.\nIt is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal.\n## Ambiguous Disclosure\nFirst, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill. After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response.\nAmbiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised\n Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand whether blame is being intentionally withheld or not.\nAmbiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first.\n## Unattributed Disclosure\nSecond, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame.\nOne purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel.[48] In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinalize the attribution process.\n## Withheld Disclosure\nFinally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case.\nOne example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of\nElectronic copy available at: https://ssrn.com/abstract=4353069\npractical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50\nIn this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52\nThis example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution.\nThe target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists\nElectronic copy available at: https://ssrn.com/abstract=4353069\noutside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate.\nThe target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution.\nSecond, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution.\n### 5.3 Public Attribution\nFinally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide\nrange of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value.\nA target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved.\nFor one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55\nThe risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds\n54. As is the case with all cyber operations, a retaliatory cyber operation is not overt unless the target public claims credit for launching a retaliatory operation or the effects are visible and publicized.\n55. Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021.”\n56. Schultz, Democracy and Coercive Diplomacy.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected.\nAlthough public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58\n## 6 The Role of Third-Party Actors\nThus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations.\nIn the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized\n57. Carson, Secret Wars.\n58. Lin, \"Escalation Dynamics and Conflict Termination in Cyberspace\"; Libicki, Crisis and Escalation in Cyberspace.\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media.\nIn assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim.\nThird-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\".[59] Finally,\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthird parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research.\nHowever, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia. Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation.\nOnly months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium. In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack. Interestingly, while Microsoft very\n. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia.\n. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n. “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nclearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government.\nIn both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude.\n# 7 Temporal Considerations\nGiven that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications.\nThere are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 7.1 Discovery-Disclosure\nFirst, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is.\nA short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures.\nAlternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty.\nAn intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves\nElectronic copy available at: https://ssrn.com/abstract=4353069\nas an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63\n## 7.2 Disclosure-Public Attribution\nThe second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution.\nThe SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and\nElectronic copy available at: https://ssrn.com/abstract=4353069\ndisclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle.\nIn contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage. While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months. The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.\nThe belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the\n. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018,\n. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nimpact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment\nOne suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).[67]\nElectronic copy available at: https://ssrn.com/abstract=4353069\nFigure 2: NotPetya Worldwide Search Results from Google Trends\nFigure 3: WannaCry Virus Worldwide Search Results from Google Trends\nWhile retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions\nElectronic copy available at: https://ssrn.com/abstract=4353069\nresponding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response.\nWith the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a\n68. Barack Obama, “Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment,” whitehouse.gov, December 29, 2016, accessed April 8, 2021, https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\n69. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021,” The White House, February 17, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n70. Rose McDermott et al., “Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence,” Texas National Security Review 1, no. 1 (November 24, 2017).\n71. Nicole Gauvette, “White House says it will hold those responsible for SolarWinds hack accountable within weeks,” CNN, February 19, 2021, accessed February 21, 2021, https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nspecific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action.\nThe uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent.\n## 8 Type I and Type II Attribution Error\nFinally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how.\nAs previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party.\nThe common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions\n72. A Guide to Cyber Attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt.\nTo date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.\n73. Catalin Cimpanu, “EU sanctions China, Russia, and North Korea for past hacks,” ZDNet, July 30, 2020, accessed April 8, 2021, https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\n74. Borghard and Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.”\n75. Buchan, “Cyber Attacks”; Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion.”\n76. Brandon Valeriano and Ryan C Maness, “The dynamics of cyber conflict between rival antagonists, 2001–11,” Journal of Peace Research 51, no. 3 (May 2014): 347–360.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nDespite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo.\nA need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan, \"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events \"may outpace the speed of the attribution process\" (p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 9 Conclusion\nTo date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand.\nAdditionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution.\nThe argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is\nElectronic copy available at: https://ssrn.com/abstract=4353069\nkey to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications.\nElectronic copy available at: https://ssrn.com/abstract=4353069",
    "footnotes": {
      "items": {
        "36": "A Guide to Cyber Attribution (Office of the Director of National Intelligence, September 14, 2018).",
        "37": "Jen Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021,” The White House, January 20, 2021, accessed April 8, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.",
        "38": "Cory Bennett, “Cyber history made at the first debate,” POLITICO, September 27, 2016, accessed March 6, 2021, https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544. Electronic copy available at: https://ssrn.com/abstract=4353069 propose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence. # 4 Disaggregating Attribution To this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency. As aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.³⁹ The relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical ³⁹. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’. Electronic copy available at: https://ssrn.com/abstract=4353069 attribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story. First, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public. The second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.⁴⁰ # 5 Target State Strategies In arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy.⁴¹ To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international ⁴⁰. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.” ⁴¹. Lindsay, “Tipping the scales.” Electronic copy available at: https://ssrn.com/abstract=4353069 and domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs. Disaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine.[42] Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker.[43] In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy. Figure 1: Strategies of Communication for Target States Electronic copy available at: https://ssrn.com/abstract=4353069 # 5.1 Collusion Collusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains.⁴⁴ In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation. While Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding. In the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and ⁴⁴ Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.” Electronic copy available at: https://ssrn.com/abstract=4353069 the incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling. Carson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity. ## 5.2 Disclosure Throughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take.⁴⁵ This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without ⁴⁵. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives. Electronic copy available at: https://ssrn.com/abstract=4353069 assigning blame.⁴⁶ Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation. Disclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist. Looking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected. ## 5.2.1 Forms of Disclosure Disclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing ⁴⁶. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511 Electronic copy available at: https://ssrn.com/abstract=4353069 and explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways. It is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal. ## Ambiguous Disclosure First, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill.⁴⁷ After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response. Ambiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised ⁴⁷ Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014). Electronic copy available at: https://ssrn.com/abstract=4353069 and whether blame is being intentionally withheld or not. Ambiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first. ## Unattributed Disclosure Second, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame. One purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel.[48] In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to Electronic copy available at: https://ssrn.com/abstract=4353069 finalize the attribution process. ## Withheld Disclosure Finally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case. One example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of Electronic copy available at: https://ssrn.com/abstract=4353069 practical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50 In this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52 This example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution. The target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists Electronic copy available at: https://ssrn.com/abstract=4353069 outside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate. The target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution. Second, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution. ### 5.3 Public Attribution Finally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide range of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value. A target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved. For one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55 The risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds",
        "54": "As is the case with all cyber operations, a retaliatory cyber operation is not overt unless the target public claims credit for launching a retaliatory operation or the effects are visible and publicized.",
        "55": "Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021.”",
        "56": "Schultz, Democracy and Coercive Diplomacy. Electronic copy available at: https://ssrn.com/abstract=4353069 that the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected. Although public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58 ## 6 The Role of Third-Party Actors Thus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations. In the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized",
        "57": "Carson, Secret Wars.",
        "58": "Lin, \"Escalation Dynamics and Conflict Termination in Cyberspace\"; Libicki, Crisis and Escalation in Cyberspace. Electronic copy available at: https://ssrn.com/abstract=4353069 cybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media. In assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim. Third-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\".[59] Finally, Electronic copy available at: https://ssrn.com/abstract=4353069 third parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research. However, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia.⁶⁰ Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation. Only months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium.⁶¹ In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack.⁶² Interestingly, while Microsoft very ⁶⁰. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia. ⁶¹. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/. ⁶². “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/. Electronic copy available at: https://ssrn.com/abstract=4353069 clearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government. In both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude. # 7 Temporal Considerations Given that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications. There are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function. Electronic copy available at: https://ssrn.com/abstract=4353069 # 7.1 Discovery-Disclosure First, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is. A short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures. Alternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty. An intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves Electronic copy available at: https://ssrn.com/abstract=4353069 as an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63 ## 7.2 Disclosure-Public Attribution The second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution. The SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and Electronic copy available at: https://ssrn.com/abstract=4353069 disclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle. In contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage.⁶⁴ While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months.⁶⁵ The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.⁶⁶ The belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the ⁶⁴. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/. ⁶⁵. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018, ⁶⁶. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and. Electronic copy available at: https://ssrn.com/abstract=4353069 impact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment One suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).[67] Electronic copy available at: https://ssrn.com/abstract=4353069 Figure 2: NotPetya Worldwide Search Results from Google Trends Figure 3: WannaCry Virus Worldwide Search Results from Google Trends While retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions Electronic copy available at: https://ssrn.com/abstract=4353069 responding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response. With the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a",
        "68": "Barack Obama, “Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment,” whitehouse.gov, December 29, 2016, accessed April 8, 2021, https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.",
        "69": "Jen Psaki, “Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021,” The White House, February 17, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.",
        "70": "Rose McDermott et al., “Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence,” Texas National Security Review 1, no. 1 (November 24, 2017).",
        "71": "Nicole Gauvette, “White House says it will hold those responsible for SolarWinds hack accountable within weeks,” CNN, February 19, 2021, accessed February 21, 2021, https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html. Electronic copy available at: https://ssrn.com/abstract=4353069 specific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action. The uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent. ## 8 Type I and Type II Attribution Error Finally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how. As previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party. The common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions",
        "72": "A Guide to Cyber Attribution. Electronic copy available at: https://ssrn.com/abstract=4353069 that are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt. To date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.",
        "73": "Catalin Cimpanu, “EU sanctions China, Russia, and North Korea for past hacks,” ZDNet, July 30, 2020, accessed April 8, 2021, https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.",
        "74": "Borghard and Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.”",
        "75": "Buchan, “Cyber Attacks”; Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion.”",
        "76": "Brandon Valeriano and Ryan C Maness, “The dynamics of cyber conflict between rival antagonists, 2001–11,” Journal of Peace Research 51, no. 3 (May 2014): 347–360. Electronic copy available at: https://ssrn.com/abstract=4353069 Despite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo. A need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan, \"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events \"may outpace the speed of the attribution process\" (p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error. Electronic copy available at: https://ssrn.com/abstract=4353069 # 9 Conclusion To date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand. Additionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution. The argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is Electronic copy available at: https://ssrn.com/abstract=4353069 key to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications. Electronic copy available at: https://ssrn.com/abstract=4353069"
      },
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 17,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 17,
        "uncited_footnote_indices": [
          36,
          37,
          38,
          54,
          55,
          56,
          57,
          58,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76
        ],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 38,
        "success_occurrences": 38,
        "success_unique": 19,
        "bib_unique_total": 19,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 1.0,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "Communications Security Bureau",
          "footnote": "Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).",
          "position": 1219
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.",
          "position": 2088
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "",
          "footnote": "Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The",
          "position": 2348
        },
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "³ The covert and",
          "footnote": "Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).",
          "position": 2365
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.",
          "position": 2736
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "",
          "footnote": "Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The",
          "position": 2992
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.",
          "position": 3476
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.",
          "position": 5501
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "",
          "footnote": "Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.",
          "position": 6325
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "s Type I and Type II error in\n",
          "footnote": "Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.",
          "position": 8232
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "",
          "footnote": "Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.",
          "position": 8803
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).",
          "position": 9270
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”",
          "position": 9998
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "⁸",
          "footnote": "Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.",
          "position": 10000
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).",
          "position": 10553
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”",
          "position": 10666
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "Egloff, “Public attribution of cyber intrusions.”",
          "position": 14338
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "",
          "footnote": "Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.",
          "position": 14995
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "implications for the target’s\n",
          "footnote": "Egloff, “Public attribution of cyber intrusions.”",
          "position": 15335
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "”",
          "footnote": "Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.",
          "position": 15388
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”",
          "position": 16065
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.",
          "position": 16915
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”",
          "position": 17239
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "”",
          "footnote": "Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.",
          "position": 17302
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).",
          "position": 18866
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,",
          "position": 18970
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "",
          "footnote": "Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”",
          "position": 19413
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).",
          "position": 19744
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,",
          "position": 20058
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "” *Wired*, December 24, 2016,\n",
          "footnote": "Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”",
          "position": 20158
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "",
          "footnote": "Brantly, “The cyber deterrence problem.”",
          "position": 21323
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "Glossip v. Gross, No. 14-7955 (June 29, 2015).",
          "position": 21950
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "threat of punishment credible\n",
          "footnote": "Brantly, “The cyber deterrence problem.”",
          "position": 22536
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "”",
          "footnote": "Glossip v. Gross, No. 14-7955 (June 29, 2015).",
          "position": 22580
        },
        {
          "index": 44,
          "intext_citation": "⁴⁴",
          "preceding_text": "",
          "footnote": "Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”",
          "position": 41546
        },
        {
          "index": 44,
          "intext_citation": "⁴⁴",
          "preceding_text": "ithholding their identity and\n",
          "footnote": "Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”",
          "position": 43322
        },
        {
          "index": 47,
          "intext_citation": "⁴⁷",
          "preceding_text": "",
          "footnote": "Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).",
          "position": 49444
        },
        {
          "index": 47,
          "intext_citation": "⁴⁷",
          "preceding_text": "identity has been compromised\n",
          "footnote": "Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).",
          "position": 50285
        }
      ],
      "flat_text": "# Strategic Attribution: Target State Communication in Response to Cyber Operations\nKathryn Hedgecock\nFebruary 24, 2023\n## Abstract\nThis paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau\n# Introduction\nIn December 2014, three weeks after the Sony Picture hack, the first two questions of the White House Press Briefing asked: “Does the White House believe that North Korea is behind the hack at Sony Pictures?” and “What is the United States going to do about it?”. Reporters were asking the standard questions associated with the disclosure of a hack, namely, who is responsible and how the state will respond. The press was seeking public attribution, i.e. the public assignment of blame, which is typically a prerequisite for retaliatory action. To these questions Press Secretary John Earnest subsequently responded, “this is a matter that is still under investigation...[I] am not going to get ahead of that investigation” and “before we start publicly speculating about a response, it’s appropriate that we allow the investigation to move forward”. Press Secretary Earnest was implicitly appealing to the attribution problem –difficulty in achieving technical attribution– for why North Korea had yet to be named and no response yet taken.\nThe attribution problem is a central theme in the cyber literature. The covert and\n Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).\n Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The\nElectronic copy available at: https://ssrn.com/abstract=4353069\ntechnical nature of cyber operations make identifying the sponsor very difficult or, at a minimum, time and resource intensive. As a result, the literature focuses on the negative consequences associated with the attribution problem, primarily an erosion of the credibility and feasibility of deterrence by punishment. However, in this paper, I argue that a narrow focus on attribution as a problem overlooks the strategic agency that deniable attribution provides targets of cyber operations. Uncertainty in the ability and timeliness of attribution, coupled with the clandestine and covert nature of cyber operations, provide the target state three strategies of communication: collusion, disclosure, or public attribution; all of which should be viewed as intentional actions with strategic implications.\nThis paper contributes to the literature on covert action, cyber deterrence, and public attribution as a distinct concept. First, I advance the literature by challenging the emphasis of attribution as a “problem” in the cyber domain. Instead, I argue the attribution problem can also be a strategic asset of the target state by providing additional agency in how they respond to and communicate about cyber operations. While this strategic logic exists in covert action broadly, there are unique features of the cyber domain that heighten the target’s agency. The covert nature of most cyber operations and complexity of attribution provide plausible deniability, not only for the perpetrator, but also for the target state’s technical attribution. A target’s discretion in choosing to what extent they want to acknowledge or respond to an operation prioritizes escalation management at the expense of deterrence by punishment. Second, I extend and adapt the logic of Carson’s *Secret Wars* and Poznansky\nMIT Press, *International Security* 38, no. 2 (2013): 7–40; Martin C. Libicki, *Cyberdeterrence and cyberwar*, in collab. with Project Air Force (U.S.), OCLC: ocn428819545 (Santa Monica, CA: RAND, 2009); Jon R. Lindsay, “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack,” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67; Joseph S. Nye, “Deterrence and Dissuasion in Cyberspace,” *International Security* 41, no. 3 (January 2017): 44–71.\n Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand Perkoski's Rethinking Secrecy in Cyberspace, in arguing that the targeted state has two distinct decisions when experiencing a covert cyber attack: the decision to reveal the occurrence of an operation to the public and the decision to blame their attacker publicly. The decisions whether to reveal and blame lead to three primary communication strategies: collusion, disclosure, or public attribution. Rather than viewing attribution in the cyber domain as merely a problem to be overcome, attribution should be viewed as a multi-level, multi-player strategic decision in which the target state can choose to what extent it wants to activate domestic and international audiences and its desire to respond.\nThe objective of this paper is theory building and a descriptive effort to advance and define the study of cyber attribution. Given the challenges associated with capturing the universe of cases, empirical examples throughout will provide plausibility probes rather than a definitive test of my theory. This paper will proceed in seven parts. First, I will explore the existing literature on cyber attribution. Second, I discuss two interrelated features of cyber operations that underpin my theory: the covert and clandestine nature and the attribution problem. Third, I argue against the notion that the attribution problem is solely \"problematic\", instead arguing that these features provide a target state increased agency in their response to cyber operations. This has implications for the efficacy of deterrence by punishment, but in a different way than previously theorized. Fourth, I disaggregate attribution into two distinct actions: revealing and blaming. Fifth, I then develop the three strategies available to the target state of a cyber operation: collusion, disclosure, and public attribution. Sixth, I discuss the role of third party actors in the strategic dynamic between target and initiator. Seventh, I demonstrate how temporal considerations are magnified by the clandestine nature of cyber operations and the attribution problem. Finally, I conclude with thoughts about how the nature of cyber operations affects Type I and Type II error in\n Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution.\n# Scope\nThe scope of this theory is the strategic considerations of nation-states that are targets of covert, state-sponsored cyber operations (hereby referred to as the target state). State-sponsored cyber operations include actions taken by the state military and intelligence forces, as well as those that are conducted by state proxies. Even if the specific identity of the attacker is not known, it is often evident when an attack is plausibly associated with a state actor. Typically, the sophistication of the operation, including the resource and intelligence requirements, provide initial indications that a state sponsor may be responsible.\nNon-state actors, from lone wolves to cybercriminal syndicates, are active initiators in cyberspace, but they are outside the scope of the theory. Because of their asymmetry of power with the state, the target state requires different strategic calculations to publicly attribute non-state actors. Additionally, overt cyber operations fall outside of the scope of this theory. Overt operations are those where the perpetrator makes no effort to conceal their identity; thereby removing the target's agency to reveal or attribute. Non-state actors are more likely to initiate overt cyber operations. Currently, the empirical record shows no instances of a state officially credit-claiming a cyberattack on another nation-state.\n Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.\n Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).\n Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 1 Cyber Attribution Literature\nAttribution is among the most highly studied concepts in cyber; however, it does not carry a singular meaning across the literature. Some scholars discuss attribution as an act of simply identifying the actor or party responsible, while other scholars use attribution to mean the public act of assigning blame. While this may seem like a minor contrast, these two types of attribution have unique implications and should be understood as distinct.\nThe foundational definition of attribution is the act of identifying the sponsor of an operation (i.e. who is to blame); this will be hereby known as technical attribution. In order for a state to achieve technical attribution, human capital, technical expertise, and intelligence assets are required. There are significant sunk costs in building the capacity to conduct technical attribution for cyber operations. Technical attribution also contains a measure of uncertainty because digital forensics do not always clearly map onto a single individual or responsible party. As Lin (2016) points out, there are often different evidentiary standards depending on what ends are sought. Technical attribution typically includes a confidence indicator that captures the uncertainty associated with the assessment of ‘whodunit’. The “attribution problem” discussed within the cyber literature refers to the challenges associated with achieving timely and accurate technical attribution.\nHowever, the use of the word ‘attribution’ among policy makers, news media, and some scholars more frequently refers to a second type of attribution—the political act of publicly assigning blame; henceforth, I will refer to this as public attribution. Thomas Rid and Ben\n. Clark and Landau, “Untangling Attribution Essay”; Herbert Lin, *Attribution of Malicious Cyber Incidents: From Soup to Nuts*, SSRN Scholarly Paper ID 2835719 (Rochester, NY: Social Science Research Network, September 2, 2016); Benjamin Edwards et al., “Strategic aspects of cyberattack, attribution, and blame,” *Proceedings of the National Academy of Sciences* 114, no. 11 (March 14, 2017): 2825–2830.\n. Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Susan W. Brenner, “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare,” *The Journal of Criminal Law and Criminology* (1973-) 97, no. 2 (2007): 379–475; Florian J Egloff, “Public attribution of cyber intrusions,” *Journal of Cybersecurity* 6 (tyaa012 2020).\n. Lindsay, “Tipping the scales.”\n. Lin, *Attribution of Malicious Cyber Incidents*.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nBuchanan (2015) famously wrote “attribution is what states make of it” (p.7). Their work, *Attributing Cyber Attacks*, was among the first to develop a more nuanced understanding of cyber attribution by assessing attribution on three levels: technical, operational, and strategic. They challenged entrenched assumptions that attribution is binary and that attribution is merely a problem of evidence gathering. Specifically, Rid and Buchanan argued that attribution on a strategic level is a function of political stakes, and it is important to understand how attribution is communicated to the public.\nTo date, there has been little effort in the literature to understand public attribution as a distinct theoretical concept. One exception is Florian Egloff who develops a theoretical baseline of public attribution in his work, *Public Attribution of Cyber Intrusions*. Egloff divides attribution into two conceptual processes which he terms ‘sense-making’ and ‘meaning-making’ processes. Sense-making refers to a technical form of attribution—discovering the perpetrator’s identity—which lies at the root of the attribution problem. Meaning-making is a political strategy that considers attribution within a broader strategic consequence. Egloff has laid a foundation for exploration of attribution as an intentional act by theoretically conceptualizing how public attribution serves a states’ political ends. In subsequent work, Egloff and Smeets (2021) prescribe considerations for when a state should publicly attribute.\n## 2 Two Defining Attributes of Cyber Operations\nThere are two defining, interrelated features of cyber operations that are central to all aspects of my theory 1) the clandestine and covert nature of cyber operations and 2) the persistence of the ‘attribution problem’. Together, these characteristics have implications for the target’s\n Egloff, “Public attribution of cyber intrusions.”\n Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nability to communicate technical attribution, and how they respond to cyber operations.\n## 2.1 Covert and Clandestine Nature\nFirst, as previously discussed in the scope conditions, this theory only pertains to covert operations in which the sponsor has not claimed credit for an attack. Poznansky and Perkoski carefully outline this phenomenon in their work, *Rethinking Secrecy in Cyberspace*. The authors disaggregate secrecy into two types of operations: clandestine and covert. Clandestine operations are those that are hidden from view. Covert operations are those that are designed to conceal the identity of the perpetrator or create plausible deniability, rather than conceal the action itself. Most cyber operations are clandestine by nature given they travel over the digital network. As a result, these operations are not observable. Even cyber operations that are not clandestine, such as ransomware and defacement, are typically covert and the initiating actor strives to conceal their identity.\nThe covert and clandestine nature of cyber operations has implications for both the initiating and target states. Initiating actors are limited in their coercive power since it is difficult to bargain when identity remains concealed. The interaction between the initiator and target may be prone to miscommunication due to difficulty of signaling in cyberspace. Additionally, if the target state wants to understand the nature of the exploit or retaliate, they must invest significant time and resources into the discovery of and the assignment of blame.\n Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n## 2.2 Attribution Problem\nSecond, in order for this theory to hold, the attribution problem—the difficulty associated with achieving technical attribution—must persist or be broadly perceived to exist. The attribution problem directly follows from the covert and clandestine nature of cyber operations. When the attribution problem was first introduced in the cyber literature, there was a belief that technical attribution of some cyber operations could be impossible to achieve. Today, a more sophisticated technical community would reject the notion that attribution is impossible. However, the fact remains that technical attribution of cyber operations requires time and resources. States lacking this capacity may continue to find themselves unable to make technical attribution, while all states, regardless of capacity, continue to deal with the implications for timely response.\n## 2.3 The Attribution Problem and Deterrence\nIn the current literature, the primary theoretical consequence of the attribution problem is its erosion of deterrence by punishment; this makes the ‘attribution problem’ even more problematic. Traditional conceptions of deterrence require a credible threat *ex-ante* that changes the cost-benefit analysis of the initiator. Deterrence by punishment is undermined by the difficulty of achieving swift technical attribution (i.e. the attribution problem) because it reduces the target’s ability to credibly threaten costs.\n Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).\n Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,\n Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nAccording to existing literature, the difficulty of technical attribution is a problem for deterrence by punishment due to temporal reasons. Traditionally, there is a sense that punishment for an action should be reasonably close in time to the action for which the retaliation is being leveled. Brantly 2018, in his discussion of cyber deterrence, points out that even if a state promises to punish in the future, upon technical attribution, “the risk of punishment for an attack is possible but so temporally distant as to be discounted to the point of irrelevance” (p.45). In other words, the initiating state does not have incentive to change their behavior because, ex-ante, the threat of punishment is so far in the future and uncertain as to be ineffective. While the idea of temporal appropriateness of punishment has not been explored extensively in the international relations literature, it is reinforced by discourses of administering punishment in psychology and legal fields. U.S. Supreme Court Justice Stephen Breyer referenced the long time between punishment and the crime while questioning the constitutionality of the death penalty in his dissenting opinion for *Glossip v. Gross*.\n## 3 Expanding the Consequences of the Attribution Problem\nThe consequences of the attribution problem are more nuanced than currently portrayed. The existing explanation for how the attribution problem erodes deterrence by punishment contains an underlying assumption that, should technical attribution be obtained, punishment would be leveled in response to a cyber operation. However, I question the validity of this assumption in the cyber domain. For deterrence by punishment to serve a legitimate deterrent capability, the initiator must find the threat of punishment credible\n Brantly, “The cyber deterrence problem.”\n Glossip v. Gross, No. 14-7955 (June 29, 2015).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nex-ante. Selective application of punishment erodes the credibility of the threat; therefore, deterrence by punishment only succeeds when punishment is leveled in response to all cyber incidents, or, at a minimum, a clearly designated threshold which empirically does not currently exist.\nIn traditional escalation literature, one of the most effective ways to credibly threaten punishment is through the tying of hands. Yet, difficulties in attribution and the covert and clandestine nature of cyber operations not only provide plausible deniability to the perpetrator, they also provide plausible deniability for the target that they have achieved technical attribution. This, in effect, permits the target leeway to strategically withhold or release information about their attribution or lack thereof. It is precisely this discretion that allows the target to untie their hands and selectively respond to cyber operations. In this way, the attribution problem permits target states to sacrifice deterrence by punishment in favor of agency over how they respond to cyber operations.\nThe argument presented in this paper— that difficulties in technical attribution provide the target additional strategic agency in responding to cyber operations— is predicated on several assumptions.\n## 3.1 Assumptions\nFirst and most centrally, this argument rests on the assumption that **target states do not want to respond to every cyber operation**. There are several reasons why this assumption is plausible. To begin, there is perceived to be an offensive advantage in cyberspace and the technology is widely accessible below the threshold of the state. These\n. Lindsay, “Tipping the scales” findings that deterrence works for large scale attacks suggest there may be a tacit understanding of this threshold, but it is not publicly stated.\n. Thomas C. Schelling, *Arms and Influence*, 2008th ed., Google-Books-ID: TX_yAAAAQBAJ (Yale University Press, 1966).\n. Kello, “The Meaning of the Cyber Revolution”; Lindsay, “Tipping the scales”; Nye, “Deterrence and Dissuasion in Cyberspace”; Edwards et al., “Strategic aspects of cyberattack, attribution, and blame.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncharacteristics contribute to a high volume of intrusions, exploits, and attacks, therefore making it impossible to level punishment for every action. Second, choosing how to best respond to a cyber operation is not clear-cut. Often, there is not a tidy reciprocal cyber action that a target can take against the initiator. There are four alternative approaches to cyber exploitation by a state actor: 1) take no public action; 2) utilize diplomatic levers such as sanctions or naming and shaming; 3) treat cyber exploits as provocations that require militarization; 4) treat cyber exploits as offenses that require criminalization. This is further complicated by a lack of consensus around what ‘force’ is in the cyber domain. For example, some scholars argue that SolarWinds is an espionage operation and, therefore, merely an act of statecraft. While others point to the egregious scale and potential for future sabotage and power shifts due to the exploit.\nThe decision how to respond to a cyber operation is not a simple one. Lindsay states “retaliation can be costly for the one administering the punishment as well as the punished, a victim may decide not to do anything even after attribution if the costs and risks of punishing are too great” (p. 57). Here, Lindsay identifies that responding to a cyber operation requires a cost-benefit calculation on behalf of the target state. The target state must have the resolve and political will to respond with punishment once correctly identifying their attacker. There will be instances in which leveling a response is more costly than doing nothing at all. One of the great risks of responding to a cyber operation is the risk of escalation. Schneider\n. Erica Borghard and Shawn Lonergan, “Cyber Operations as Imperfect Tools of Escalation,” *Strategic Studies Quarterly* 63, no. 2 (2019): 122–145; Jason Healey and Robert Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability,” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n. David Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations,” *Daedalus* 145 (September 1, 2016): 37–49; Russell Buchan, “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?,” Publisher: Oxford University Press, *Journal of Conflict and Security Law* 17, no. 2 (2012): 211–227.\n. Erica Borghard and Jacquelyn Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy,” *Wired*, December 17, 2020,\n. Yevgeny Vindman, “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.,” Lawfare, January 26, 2021, accessed March 12, 2021, https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n. Lindsay, “Tipping the scales.”\n. Martin C. Libicki, *Crisis and Escalation in Cyberspace*, Google-Books-ID: D9YzsTx1mnMC (Rand\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinds that participants in wargame simulations self-restrain in response to cyber operations out of the perception that cyber is highly escalatory. Once again, this provides plausible evidence that targets of cyber operations do not want to respond to every cyber operation, including, perhaps, some of the most egregious due to a fear of escalation. The challenges of choosing which incidents to respond to, and what response is ‘appropriate’ further erode deterrence by punishment beyond the attribution problem.\nThe second assumption is that states feel pressure to “do something” when they fall victim to hostile actions from another nation-state. This pressure can come from domestic constituents, international audiences, or an internal desire to deter future actions or appear resolved against an adversary. The assertion that domestic public support retaliatory response is plausibly supported by survey research which shows high levels of support for retaliation. For example, survey work has found that nearly two-thirds of respondents support a military response when the United States is attacked, regardless if the means of attack are cyber or kinetic. The high-level of support for retaliation is even more notable because the survey experiment tests relatively low-level exploits including financial and information theft. Only 7 percent of survey respondents selected ‘do not acknowledge the attack’ as their most preferred response, meaning 93 percent of respondents preferred the government take some sort of action.\nThe third assumption is that the attribution problem endemic in cyber domain operations (specifically the difficulty of achieving technical attribution) is widely\nElectronic copy available at: https://ssrn.com/abstract=4353069\nCorporation, 2012); Herbert Lin, “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25; Monica Kaminska, “Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks,” Journal of Cybersecurity 7 (tyab008 2021); Brandon G. Valeriano and Ben Jenson, The Myth of the Cyber Offense: The Case for Cyber Restraint, SSRN Scholarly Paper ID 3382340 (Rochester, NY: Social Science Research Network, January 15, 2019); Healey and Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability.”\n. Dr Jacquelyn Schneider, “Cyber and Crisis Escalation: Insights from Wargaming” (March 2017), 43.\n. Robert D. Putnam, “Diplomacy and domestic politics: the logic of two-level games,” 00000, International Organization 42, no. 3 (1988): 427–460.\n. hedgecock’sukin2023.\naccepted and the public is desensitized to it. In other words, there must be an enduring belief that technical attribution of cyber operations is difficult to achieve and that there is variation on the amount of time and feasibility required. In the kinetic domain, there is an assumption that swift technical attribution can and will be achieved. This creates expectations among domestic and international audiences that the target state will make a public attribution when they are the victim of a conventional attack or exploitation. Even in the case of terrorism, where the identity of the perpetrator may be especially hard to distill, politicians promise to identify and punish their attackers. Less than one minute into President Clinton’s statement following the USS Cole bombing he said: “We will find out who is responsible and hold them accountable.” While elected leaders may face a credibility problem or domestic political costs if they revealed a kinetic operation and said that they did not know who did it or may never know, this is not the case for the cyber domain. In fact, the attribution problem is so endemic that several scholars have explored the challenges of convincing the public of an attribution claim in the cyber domain. The prevalence of the public rhetoric around the attribution problem has changed expectations of attribution for cyber incidents.\nThe attribution problem is widely referenced in public discourse which helps perpetuate this belief among the public. Take, for example, the United States Office of the Director of National Intelligence’s Guide to Cyber Attribution. In discussing technical attribution, they write: “This painstaking work in many cases requires several weeks or months of analyzing intelligence and forensics. In some instances in which analysts can determine responsibility\n. James D. Fearon, “Domestic Political Audiences and the Escalation of International Disputes,” *American Political Science Review* 88, no. 3 (September 1994): 577–592; Kenneth A. Schultz, *Democracy and Coercive Diplomacy* (Cambridge University Press, July 26, 2001).\n. Marcus Schulzke, “The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty,” Num Pages: 954–968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, *Perspectives on Politics* 16, no. 4 (December 2018): 954–968; Florian J. Egloff, “Contested public attributions of cyber incidents and the role of academia,” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, *Contemporary Security Policy* 41, no. 1 (January 2, 2020): 55–81.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfor a cyber attack within hours of an incident the accuracy and level of confidence is likely to vary depending on the available data”.36 Separately, during a Biden administration press conference discussing the SolarWinds hack, Deputy National Security Advisor for Cyber and Emerging Technologies, Anne Neuberger, was pressed by a reporter asking “how long this investigation [into SolarWinds] will take?”. Neuberger responded that it would take “several months” without any resistance or skepticism.37 The difficulty of attribution was also part of mainstream dialogue in the 2016 Presidential debates where President Trump made his now infamous statement about the Democratic National Committee hack saying, “[Clinton is] saying Russia, Russia, Russia. Maybe it was. It could also be China. It could be someone sitting on their bed that weighs 400 pounds”.38 Statements such as these continue to reinforce public expectations that cyber attribution is difficult and emphasize a temporal dimension.\nTaken together, these three assumptions provide the foundation for my argument that difficulties in attribution provide target states strategic agency in their response to cyber operations. If states feel pressure to respond when they reveal they are the victim of a cyber operation, but also struggle with the appropriate response to a cyber operation, they may not want to publicly attribute the cyber operation at all or delay their attribution until they have constructed an adequate response. Therefore, the perception of attribution difficulty and the clandestine and covert nature of cyber operations provide target states the ability to manipulate revelation and public attribution to meet their strategic needs. In addition to the commonly understood erosion of deterrence by punishment by undermining the timely delivery of punishment, I\n36. A Guide to Cyber Attribution (Office of the Director of National Intelligence, September 14, 2018).\n37. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021,” The White House, January 20, 2021, accessed April 8, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\n38. Cory Bennett, “Cyber history made at the first debate,” POLITICO, September 27, 2016, accessed March 6, 2021, https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\nElectronic copy available at: https://ssrn.com/abstract=4353069\npropose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence.\n# 4 Disaggregating Attribution\nTo this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency.\nAs aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.\nThe relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical\n. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story.\nFirst, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public.\nThe second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.\n# 5 Target State Strategies\nIn arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy. To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international\n. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n. Lindsay, “Tipping the scales.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs.\nDisaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine.[42] Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker.[43] In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy.\nFigure 1: Strategies of Communication for Target States\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 5.1 Collusion\nCollusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains. In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation.\nWhile Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding.\nIn the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and\n Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthe incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling.\nCarson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity.\n## 5.2 Disclosure\nThroughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take. This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without\n. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nassigning blame. Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation.\nDisclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist.\nLooking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected.\n## 5.2.1 Forms of Disclosure\nDisclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing\n. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways.\nIt is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal.\n## Ambiguous Disclosure\nFirst, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill. After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response.\nAmbiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised\n Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand whether blame is being intentionally withheld or not.\nAmbiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first.\n## Unattributed Disclosure\nSecond, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame.\nOne purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel.[48] In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinalize the attribution process.\n## Withheld Disclosure\nFinally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case.\nOne example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of\nElectronic copy available at: https://ssrn.com/abstract=4353069\npractical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50\nIn this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52\nThis example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution.\nThe target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists\nElectronic copy available at: https://ssrn.com/abstract=4353069\noutside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate.\nThe target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution.\nSecond, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution.\n### 5.3 Public Attribution\nFinally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide\nrange of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value.\nA target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved.\nFor one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55\nThe risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds\n54. As is the case with all cyber operations, a retaliatory cyber operation is not overt unless the target public claims credit for launching a retaliatory operation or the effects are visible and publicized.\n55. Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021.”\n56. Schultz, Democracy and Coercive Diplomacy.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected.\nAlthough public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58\n## 6 The Role of Third-Party Actors\nThus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations.\nIn the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized\n57. Carson, Secret Wars.\n58. Lin, \"Escalation Dynamics and Conflict Termination in Cyberspace\"; Libicki, Crisis and Escalation in Cyberspace.\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media.\nIn assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim.\nThird-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\".[59] Finally,\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthird parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research.\nHowever, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia. Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation.\nOnly months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium. In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack. Interestingly, while Microsoft very\n. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia.\n. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n. “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nclearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government.\nIn both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude.\n# 7 Temporal Considerations\nGiven that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications.\nThere are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 7.1 Discovery-Disclosure\nFirst, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is.\nA short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures.\nAlternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty.\nAn intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves\nElectronic copy available at: https://ssrn.com/abstract=4353069\nas an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63\n## 7.2 Disclosure-Public Attribution\nThe second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution.\nThe SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and\nElectronic copy available at: https://ssrn.com/abstract=4353069\ndisclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle.\nIn contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage. While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months. The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.\nThe belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the\n. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018,\n. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nimpact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment\nOne suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).[67]\nElectronic copy available at: https://ssrn.com/abstract=4353069\nFigure 2: NotPetya Worldwide Search Results from Google Trends\nFigure 3: WannaCry Virus Worldwide Search Results from Google Trends\nWhile retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions\nElectronic copy available at: https://ssrn.com/abstract=4353069\nresponding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response.\nWith the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a\n68. Barack Obama, “Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment,” whitehouse.gov, December 29, 2016, accessed April 8, 2021, https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\n69. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021,” The White House, February 17, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n70. Rose McDermott et al., “Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence,” Texas National Security Review 1, no. 1 (November 24, 2017).\n71. Nicole Gauvette, “White House says it will hold those responsible for SolarWinds hack accountable within weeks,” CNN, February 19, 2021, accessed February 21, 2021, https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nspecific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action.\nThe uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent.\n## 8 Type I and Type II Attribution Error\nFinally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how.\nAs previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party.\nThe common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions\n72. A Guide to Cyber Attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt.\nTo date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.\n73. Catalin Cimpanu, “EU sanctions China, Russia, and North Korea for past hacks,” ZDNet, July 30, 2020, accessed April 8, 2021, https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\n74. Borghard and Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.”\n75. Buchan, “Cyber Attacks”; Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion.”\n76. Brandon Valeriano and Ryan C Maness, “The dynamics of cyber conflict between rival antagonists, 2001–11,” Journal of Peace Research 51, no. 3 (May 2014): 347–360.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nDespite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo.\nA need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan, \"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events \"may outpace the speed of the attribution process\" (p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 9 Conclusion\nTo date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand.\nAdditionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution.\nThe argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is\nElectronic copy available at: https://ssrn.com/abstract=4353069\nkey to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications.\nElectronic copy available at: https://ssrn.com/abstract=4353069"
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 17,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "# Strategic Attribution: Target State Communication in Response to Cyber Operations\nKathryn Hedgecock\nFebruary 24, 2023\n## Abstract\nThis paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau¹\n# Introduction\nIn December 2014, three weeks after the Sony Picture hack, the first two questions of the White House Press Briefing asked: “Does the White House believe that North Korea is behind the hack at Sony Pictures?” and “What is the United States going to do about it?”. Reporters were asking the standard questions associated with the disclosure of a hack, namely, who is responsible and how the state will respond. The press was seeking public attribution, i.e. the public assignment of blame, which is typically a prerequisite for retaliatory action. To these questions Press Secretary John Earnest subsequently responded, “this is a matter that is still under investigation...[I] am not going to get ahead of that investigation” and “before we start publicly speculating about a response, it’s appropriate that we allow the investigation to move forward”.² Press Secretary Earnest was implicitly appealing to the attribution problem –difficulty in achieving technical attribution– for why North Korea had yet to be named and no response yet taken.\nThe attribution problem is a central theme in the cyber literature.³ The covert and\n¹ Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).\n² Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n³ Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The\nElectronic copy available at: https://ssrn.com/abstract=4353069\ntechnical nature of cyber operations make identifying the sponsor very difficult or, at a minimum, time and resource intensive. As a result, the literature focuses on the negative consequences associated with the attribution problem, primarily an erosion of the credibility and feasibility of deterrence by punishment.⁴ However, in this paper, I argue that a narrow focus on attribution as a problem overlooks the strategic agency that deniable attribution provides targets of cyber operations. Uncertainty in the ability and timeliness of attribution, coupled with the clandestine and covert nature of cyber operations, provide the target state three strategies of communication: collusion, disclosure, or public attribution; all of which should be viewed as intentional actions with strategic implications.\nThis paper contributes to the literature on covert action, cyber deterrence, and public attribution as a distinct concept. First, I advance the literature by challenging the emphasis of attribution as a “problem” in the cyber domain. Instead, I argue the attribution problem can also be a strategic asset of the target state by providing additional agency in how they respond to and communicate about cyber operations. While this strategic logic exists in covert action broadly, there are unique features of the cyber domain that heighten the target’s agency. The covert nature of most cyber operations and complexity of attribution provide plausible deniability, not only for the perpetrator, but also for the target state’s technical attribution. A target’s discretion in choosing to what extent they want to acknowledge or respond to an operation prioritizes escalation management at the expense of deterrence by punishment. Second, I extend and adapt the logic of Carson’s *Secret Wars* and Poznansky\nMIT Press, *International Security* 38, no. 2 (2013): 7–40; Martin C. Libicki, *Cyberdeterrence and cyberwar*, in collab. with Project Air Force (U.S.), OCLC: ocn428819545 (Santa Monica, CA: RAND, 2009); Jon R. Lindsay, “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack,” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67; Joseph S. Nye, “Deterrence and Dissuasion in Cyberspace,” *International Security* 41, no. 3 (January 2017): 44–71.\n⁴ Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 (May 2018), 31–54.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand Perkoski's Rethinking Secrecy in Cyberspace, in arguing that the targeted state has two distinct decisions when experiencing a covert cyber attack: the decision to reveal the occurrence of an operation to the public and the decision to blame their attacker publicly.⁵ The decisions whether to reveal and blame lead to three primary communication strategies: collusion, disclosure, or public attribution. Rather than viewing attribution in the cyber domain as merely a problem to be overcome, attribution should be viewed as a multi-level, multi-player strategic decision in which the target state can choose to what extent it wants to activate domestic and international audiences and its desire to respond.\nThe objective of this paper is theory building and a descriptive effort to advance and define the study of cyber attribution. Given the challenges associated with capturing the universe of cases, empirical examples throughout will provide plausibility probes rather than a definitive test of my theory. This paper will proceed in seven parts. First, I will explore the existing literature on cyber attribution. Second, I discuss two interrelated features of cyber operations that underpin my theory: the covert and clandestine nature and the attribution problem. Third, I argue against the notion that the attribution problem is solely \"problematic\", instead arguing that these features provide a target state increased agency in their response to cyber operations. This has implications for the efficacy of deterrence by punishment, but in a different way than previously theorized. Fourth, I disaggregate attribution into two distinct actions: revealing and blaming. Fifth, I then develop the three strategies available to the target state of a cyber operation: collusion, disclosure, and public attribution. Sixth, I discuss the role of third party actors in the strategic dynamic between target and initiator. Seventh, I demonstrate how temporal considerations are magnified by the clandestine nature of cyber operations and the attribution problem. Finally, I conclude with thoughts about how the nature of cyber operations affects Type I and Type II error in\n⁵ Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution.\n# Scope\nThe scope of this theory is the strategic considerations of nation-states that are targets of covert, state-sponsored cyber operations (hereby referred to as the target state).⁶ State-sponsored cyber operations include actions taken by the state military and intelligence forces, as well as those that are conducted by state proxies. Even if the specific identity of the attacker is not known, it is often evident when an attack is plausibly associated with a state actor. Typically, the sophistication of the operation, including the resource and intelligence requirements, provide initial indications that a state sponsor may be responsible.⁷\nNon-state actors, from lone wolves to cybercriminal syndicates, are active initiators in cyberspace, but they are outside the scope of the theory. Because of their asymmetry of power with the state, the target state requires different strategic calculations to publicly attribute non-state actors. Additionally, overt cyber operations fall outside of the scope of this theory. Overt operations are those where the perpetrator makes no effort to conceal their identity; thereby removing the target's agency to reveal or attribute. Non-state actors are more likely to initiate overt cyber operations. Currently, the empirical record shows no instances of a state officially credit-claiming a cyberattack on another nation-state.⁸\n⁶ Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.\n⁷ Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).\n⁸ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 1 Cyber Attribution Literature\nAttribution is among the most highly studied concepts in cyber; however, it does not carry a singular meaning across the literature.⁹ Some scholars discuss attribution as an act of simply identifying the actor or party responsible, while other scholars use attribution to mean the public act of assigning blame. While this may seem like a minor contrast, these two types of attribution have unique implications and should be understood as distinct.\nThe foundational definition of attribution is the act of identifying the sponsor of an operation (i.e. who is to blame);¹⁰ this will be hereby known as technical attribution. In order for a state to achieve technical attribution, human capital, technical expertise, and intelligence assets are required. There are significant sunk costs in building the capacity to conduct technical attribution for cyber operations.¹¹ Technical attribution also contains a measure of uncertainty because digital forensics do not always clearly map onto a single individual or responsible party. As Lin (2016) points out, there are often different evidentiary standards depending on what ends are sought.¹² Technical attribution typically includes a confidence indicator that captures the uncertainty associated with the assessment of ‘whodunit’. The “attribution problem” discussed within the cyber literature refers to the challenges associated with achieving timely and accurate technical attribution.\nHowever, the use of the word ‘attribution’ among policy makers, news media, and some scholars more frequently refers to a second type of attribution—the political act of publicly assigning blame; henceforth, I will refer to this as public attribution. Thomas Rid and Ben\n⁹. Clark and Landau, “Untangling Attribution Essay”; Herbert Lin, *Attribution of Malicious Cyber Incidents: From Soup to Nuts*, SSRN Scholarly Paper ID 2835719 (Rochester, NY: Social Science Research Network, September 2, 2016); Benjamin Edwards et al., “Strategic aspects of cyberattack, attribution, and blame,” *Proceedings of the National Academy of Sciences* 114, no. 11 (March 14, 2017): 2825–2830.\n¹⁰. Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Susan W. Brenner, “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare,” *The Journal of Criminal Law and Criminology* (1973-) 97, no. 2 (2007): 379–475; Florian J Egloff, “Public attribution of cyber intrusions,” *Journal of Cybersecurity* 6 (tyaa012 2020).\n¹¹. Lindsay, “Tipping the scales.”\n¹². Lin, *Attribution of Malicious Cyber Incidents*.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nBuchanan (2015) famously wrote “attribution is what states make of it” (p.7). Their work, *Attributing Cyber Attacks*, was among the first to develop a more nuanced understanding of cyber attribution by assessing attribution on three levels: technical, operational, and strategic. They challenged entrenched assumptions that attribution is binary and that attribution is merely a problem of evidence gathering. Specifically, Rid and Buchanan argued that attribution on a strategic level is a function of political stakes, and it is important to understand how attribution is communicated to the public.\nTo date, there has been little effort in the literature to understand public attribution as a distinct theoretical concept. One exception is Florian Egloff who develops a theoretical baseline of public attribution in his work, *Public Attribution of Cyber Intrusions*.¹³ Egloff divides attribution into two conceptual processes which he terms ‘sense-making’ and ‘meaning-making’ processes. Sense-making refers to a technical form of attribution—discovering the perpetrator’s identity—which lies at the root of the attribution problem. Meaning-making is a political strategy that considers attribution within a broader strategic consequence. Egloff has laid a foundation for exploration of attribution as an intentional act by theoretically conceptualizing how public attribution serves a states’ political ends. In subsequent work, Egloff and Smeets (2021) prescribe considerations for when a state should publicly attribute.¹⁴\n## 2 Two Defining Attributes of Cyber Operations\nThere are two defining, interrelated features of cyber operations that are central to all aspects of my theory 1) the clandestine and covert nature of cyber operations and 2) the persistence of the ‘attribution problem’. Together, these characteristics have implications for the target’s\n¹³ Egloff, “Public attribution of cyber intrusions.”\n¹⁴ Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nability to communicate technical attribution, and how they respond to cyber operations.\n## 2.1 Covert and Clandestine Nature\nFirst, as previously discussed in the scope conditions, this theory only pertains to covert operations in which the sponsor has not claimed credit for an attack. Poznansky and Perkoski carefully outline this phenomenon in their work, *Rethinking Secrecy in Cyberspace*.¹⁵ The authors disaggregate secrecy into two types of operations: clandestine and covert. Clandestine operations are those that are hidden from view. Covert operations are those that are designed to conceal the identity of the perpetrator or create plausible deniability, rather than conceal the action itself. Most cyber operations are clandestine by nature given they travel over the digital network. As a result, these operations are not observable. Even cyber operations that are not clandestine, such as ransomware and defacement, are typically covert and the initiating actor strives to conceal their identity.\nThe covert and clandestine nature of cyber operations has implications for both the initiating and target states. Initiating actors are limited in their coercive power since it is difficult to bargain when identity remains concealed.¹⁶ The interaction between the initiator and target may be prone to miscommunication due to difficulty of signaling in cyberspace. Additionally, if the target state wants to understand the nature of the exploit or retaliate, they must invest significant time and resources into the discovery of and the assignment of blame.\n¹⁵ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n¹⁶ Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n## 2.2 Attribution Problem\nSecond, in order for this theory to hold, the attribution problem—the difficulty associated with achieving technical attribution—must persist or be broadly perceived to exist. The attribution problem directly follows from the covert and clandestine nature of cyber operations. When the attribution problem was first introduced in the cyber literature, there was a belief that technical attribution of some cyber operations could be impossible to achieve. Today, a more sophisticated technical community would reject the notion that attribution is impossible.¹⁷ However, the fact remains that technical attribution of cyber operations requires time and resources.¹⁸ States lacking this capacity may continue to find themselves unable to make technical attribution, while all states, regardless of capacity, continue to deal with the implications for timely response.\n## 2.3 The Attribution Problem and Deterrence\nIn the current literature, the primary theoretical consequence of the attribution problem is its erosion of deterrence by punishment; this makes the ‘attribution problem’ even more problematic.¹⁹ Traditional conceptions of deterrence require a credible threat *ex-ante* that changes the cost-benefit analysis of the initiator. Deterrence by punishment is undermined by the difficulty of achieving swift technical attribution (i.e. the attribution problem) because it reduces the target’s ability to credibly threaten costs.\n¹⁷ Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).\n¹⁸ Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,\n¹⁹ Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nAccording to existing literature, the difficulty of technical attribution is a problem for deterrence by punishment due to temporal reasons. Traditionally, there is a sense that punishment for an action should be reasonably close in time to the action for which the retaliation is being leveled. Brantly 2018, in his discussion of cyber deterrence, points out that even if a state promises to punish in the future, upon technical attribution, “the risk of punishment for an attack is possible but so temporally distant as to be discounted to the point of irrelevance” (p.45).²⁰ In other words, the initiating state does not have incentive to change their behavior because, ex-ante, the threat of punishment is so far in the future and uncertain as to be ineffective. While the idea of temporal appropriateness of punishment has not been explored extensively in the international relations literature, it is reinforced by discourses of administering punishment in psychology and legal fields. U.S. Supreme Court Justice Stephen Breyer referenced the long time between punishment and the crime while questioning the constitutionality of the death penalty in his dissenting opinion for *Glossip v. Gross*.²¹\n## 3 Expanding the Consequences of the Attribution Problem\nThe consequences of the attribution problem are more nuanced than currently portrayed. The existing explanation for how the attribution problem erodes deterrence by punishment contains an underlying assumption that, should technical attribution be obtained, punishment would be leveled in response to a cyber operation. However, I question the validity of this assumption in the cyber domain. For deterrence by punishment to serve a legitimate deterrent capability, the initiator must find the threat of punishment credible\n²⁰ Brantly, “The cyber deterrence problem.”\n²¹ Glossip v. Gross, No. 14-7955 (June 29, 2015).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nex-ante. Selective application of punishment erodes the credibility of the threat; therefore, deterrence by punishment only succeeds when punishment is leveled in response to all cyber incidents, or, at a minimum, a clearly designated threshold which empirically does not currently exist.²²\nIn traditional escalation literature, one of the most effective ways to credibly threaten punishment is through the tying of hands.²³ Yet, difficulties in attribution and the covert and clandestine nature of cyber operations not only provide plausible deniability to the perpetrator, they also provide plausible deniability for the target that they have achieved technical attribution. This, in effect, permits the target leeway to strategically withhold or release information about their attribution or lack thereof. It is precisely this discretion that allows the target to untie their hands and selectively respond to cyber operations. In this way, the attribution problem permits target states to sacrifice deterrence by punishment in favor of agency over how they respond to cyber operations.\nThe argument presented in this paper— that difficulties in technical attribution provide the target additional strategic agency in responding to cyber operations— is predicated on several assumptions.\n## 3.1 Assumptions\nFirst and most centrally, this argument rests on the assumption that **target states do not want to respond to every cyber operation**. There are several reasons why this assumption is plausible. To begin, there is perceived to be an offensive advantage in cyberspace and the technology is widely accessible below the threshold of the state.²⁴ These\n²². Lindsay, “Tipping the scales” findings that deterrence works for large scale attacks suggest there may be a tacit understanding of this threshold, but it is not publicly stated.\n²³. Thomas C. Schelling, *Arms and Influence*, 2008th ed., Google-Books-ID: TX_yAAAAQBAJ (Yale University Press, 1966).\n²⁴. Kello, “The Meaning of the Cyber Revolution”; Lindsay, “Tipping the scales”; Nye, “Deterrence and Dissuasion in Cyberspace”; Edwards et al., “Strategic aspects of cyberattack, attribution, and blame.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncharacteristics contribute to a high volume of intrusions, exploits, and attacks, therefore making it impossible to level punishment for every action. Second, choosing how to best respond to a cyber operation is not clear-cut.²⁵ Often, there is not a tidy reciprocal cyber action that a target can take against the initiator. There are four alternative approaches to cyber exploitation by a state actor: 1) take no public action; 2) utilize diplomatic levers such as sanctions or naming and shaming; 3) treat cyber exploits as provocations that require militarization; 4) treat cyber exploits as offenses that require criminalization. This is further complicated by a lack of consensus around what ‘force’ is in the cyber domain.²⁶ For example, some scholars argue that SolarWinds is an espionage operation and, therefore, merely an act of statecraft.²⁷ While others point to the egregious scale and potential for future sabotage and power shifts due to the exploit.²⁸\nThe decision how to respond to a cyber operation is not a simple one. Lindsay states “retaliation can be costly for the one administering the punishment as well as the punished, a victim may decide not to do anything even after attribution if the costs and risks of punishing are too great” (p. 57).²⁹ Here, Lindsay identifies that responding to a cyber operation requires a cost-benefit calculation on behalf of the target state. The target state must have the resolve and political will to respond with punishment once correctly identifying their attacker. There will be instances in which leveling a response is more costly than doing nothing at all. One of the great risks of responding to a cyber operation is the risk of escalation.³⁰ Schneider\n²⁵. Erica Borghard and Shawn Lonergan, “Cyber Operations as Imperfect Tools of Escalation,” *Strategic Studies Quarterly* 63, no. 2 (2019): 122–145; Jason Healey and Robert Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability,” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n²⁶. David Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations,” *Daedalus* 145 (September 1, 2016): 37–49; Russell Buchan, “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?,” Publisher: Oxford University Press, *Journal of Conflict and Security Law* 17, no. 2 (2012): 211–227.\n²⁷. Erica Borghard and Jacquelyn Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy,” *Wired*, December 17, 2020,\n²⁸. Yevgeny Vindman, “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.,” Lawfare, January 26, 2021, accessed March 12, 2021, https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n²⁹. Lindsay, “Tipping the scales.”\n³⁰. Martin C. Libicki, *Crisis and Escalation in Cyberspace*, Google-Books-ID: D9YzsTx1mnMC (Rand\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinds that participants in wargame simulations self-restrain in response to cyber operations out of the perception that cyber is highly escalatory.³¹ Once again, this provides plausible evidence that targets of cyber operations do not want to respond to every cyber operation, including, perhaps, some of the most egregious due to a fear of escalation. The challenges of choosing which incidents to respond to, and what response is ‘appropriate’ further erode deterrence by punishment beyond the attribution problem.\nThe second assumption is that states feel pressure to “do something” when they fall victim to hostile actions from another nation-state. This pressure can come from domestic constituents, international audiences, or an internal desire to deter future actions or appear resolved against an adversary.³² The assertion that domestic public support retaliatory response is plausibly supported by survey research which shows high levels of support for retaliation. For example, survey work has found that nearly two-thirds of respondents support a military response when the United States is attacked, regardless if the means of attack are cyber or kinetic.³³ The high-level of support for retaliation is even more notable because the survey experiment tests relatively low-level exploits including financial and information theft. Only 7 percent of survey respondents selected ‘do not acknowledge the attack’ as their most preferred response, meaning 93 percent of respondents preferred the government take some sort of action.\nThe third assumption is that the attribution problem endemic in cyber domain operations (specifically the difficulty of achieving technical attribution) is widely\nElectronic copy available at: https://ssrn.com/abstract=4353069\nCorporation, 2012); Herbert Lin, “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25; Monica Kaminska, “Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks,” Journal of Cybersecurity 7 (tyab008 2021); Brandon G. Valeriano and Ben Jenson, The Myth of the Cyber Offense: The Case for Cyber Restraint, SSRN Scholarly Paper ID 3382340 (Rochester, NY: Social Science Research Network, January 15, 2019); Healey and Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability.”\n³¹. Dr Jacquelyn Schneider, “Cyber and Crisis Escalation: Insights from Wargaming” (March 2017), 43.\n³². Robert D. Putnam, “Diplomacy and domestic politics: the logic of two-level games,” 00000, International Organization 42, no. 3 (1988): 427–460.\n³³. hedgecock’sukin2023.\naccepted and the public is desensitized to it. In other words, there must be an enduring belief that technical attribution of cyber operations is difficult to achieve and that there is variation on the amount of time and feasibility required. In the kinetic domain, there is an assumption that swift technical attribution can and will be achieved. This creates expectations among domestic and international audiences that the target state will make a public attribution when they are the victim of a conventional attack or exploitation. Even in the case of terrorism, where the identity of the perpetrator may be especially hard to distill, politicians promise to identify and punish their attackers. Less than one minute into President Clinton’s statement following the USS Cole bombing he said: “We will find out who is responsible and hold them accountable.” While elected leaders may face a credibility problem or domestic political costs if they revealed a kinetic operation and said that they did not know who did it or may never know,³⁴ this is not the case for the cyber domain. In fact, the attribution problem is so endemic that several scholars have explored the challenges of convincing the public of an attribution claim in the cyber domain.³⁵ The prevalence of the public rhetoric around the attribution problem has changed expectations of attribution for cyber incidents.\nThe attribution problem is widely referenced in public discourse which helps perpetuate this belief among the public. Take, for example, the United States Office of the Director of National Intelligence’s Guide to Cyber Attribution. In discussing technical attribution, they write: “This painstaking work in many cases requires several weeks or months of analyzing intelligence and forensics. In some instances in which analysts can determine responsibility\n³⁴. James D. Fearon, “Domestic Political Audiences and the Escalation of International Disputes,” *American Political Science Review* 88, no. 3 (September 1994): 577–592; Kenneth A. Schultz, *Democracy and Coercive Diplomacy* (Cambridge University Press, July 26, 2001).\n³⁵. Marcus Schulzke, “The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty,” Num Pages: 954–968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, *Perspectives on Politics* 16, no. 4 (December 2018): 954–968; Florian J. Egloff, “Contested public attributions of cyber incidents and the role of academia,” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, *Contemporary Security Policy* 41, no. 1 (January 2, 2020): 55–81.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfor a cyber attack within hours of an incident the accuracy and level of confidence is likely to vary depending on the available data”.36 Separately, during a Biden administration press conference discussing the SolarWinds hack, Deputy National Security Advisor for Cyber and Emerging Technologies, Anne Neuberger, was pressed by a reporter asking “how long this investigation [into SolarWinds] will take?”. Neuberger responded that it would take “several months” without any resistance or skepticism.37 The difficulty of attribution was also part of mainstream dialogue in the 2016 Presidential debates where President Trump made his now infamous statement about the Democratic National Committee hack saying, “[Clinton is] saying Russia, Russia, Russia. Maybe it was. It could also be China. It could be someone sitting on their bed that weighs 400 pounds”.38 Statements such as these continue to reinforce public expectations that cyber attribution is difficult and emphasize a temporal dimension.\nTaken together, these three assumptions provide the foundation for my argument that difficulties in attribution provide target states strategic agency in their response to cyber operations. If states feel pressure to respond when they reveal they are the victim of a cyber operation, but also struggle with the appropriate response to a cyber operation, they may not want to publicly attribute the cyber operation at all or delay their attribution until they have constructed an adequate response. Therefore, the perception of attribution difficulty and the clandestine and covert nature of cyber operations provide target states the ability to manipulate revelation and public attribution to meet their strategic needs. In addition to the commonly understood erosion of deterrence by punishment by undermining the timely delivery of punishment, I\n36. A Guide to Cyber Attribution (Office of the Director of National Intelligence, September 14, 2018).\n37. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021,” The White House, January 20, 2021, accessed April 8, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/01/20/press-briefing-by-press-secretary-jen-psaki-january-20-2021/.\n38. Cory Bennett, “Cyber history made at the first debate,” POLITICO, September 27, 2016, accessed March 6, 2021, https://www.politico.com/tipsheets/morning-cybersecurity/2016/09/cyber-history-made-at-the-first-debate-216544.\nElectronic copy available at: https://ssrn.com/abstract=4353069\npropose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence.\n# 4 Disaggregating Attribution\nTo this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency.\nAs aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.³⁹\nThe relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical\n³⁹. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story.\nFirst, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public.\nThe second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.⁴⁰\n# 5 Target State Strategies\nIn arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy.⁴¹ To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international\n⁴⁰. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n⁴¹. Lindsay, “Tipping the scales.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs.\nDisaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine. Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker. In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy.\nFigure 1: Strategies of Communication for Target States\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 5.1 Collusion\nCollusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains.⁴⁴ In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation.\nWhile Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding.\nIn the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and\n⁴⁴ Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthe incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling.\nCarson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity.\n## 5.2 Disclosure\nThroughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take.⁴⁵ This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without\n⁴⁵. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nassigning blame.⁴⁶ Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation.\nDisclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist.\nLooking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected.\n## 5.2.1 Forms of Disclosure\nDisclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing\n⁴⁶. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways.\nIt is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal.\n## Ambiguous Disclosure\nFirst, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill.⁴⁷ After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response.\nAmbiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised\n⁴⁷ Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand whether blame is being intentionally withheld or not.\nAmbiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first.\n## Unattributed Disclosure\nSecond, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame.\nOne purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel. In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinalize the attribution process.\n## Withheld Disclosure\nFinally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case.\nOne example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of\nElectronic copy available at: https://ssrn.com/abstract=4353069\npractical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50\nIn this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52\nThis example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution.\nThe target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists\nElectronic copy available at: https://ssrn.com/abstract=4353069\noutside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate.\nThe target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution.\nSecond, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution.\n### 5.3 Public Attribution\nFinally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide\nrange of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value.\nA target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved.\nFor one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55\nThe risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds\n54. As is the case with all cyber operations, a retaliatory cyber operation is not overt unless the target public claims credit for launching a retaliatory operation or the effects are visible and publicized.\n55. Psaki, “Press Briefing by Press Secretary Jen Psaki, January 20, 2021.”\n56. Schultz, Democracy and Coercive Diplomacy.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected.\nAlthough public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58\n## 6 The Role of Third-Party Actors\nThus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations.\nIn the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized\n57. Carson, Secret Wars.\n58. Lin, \"Escalation Dynamics and Conflict Termination in Cyberspace\"; Libicki, Crisis and Escalation in Cyberspace.\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media.\nIn assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim.\nThird-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\". Finally,\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthird parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research.\nHowever, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia.⁶⁰ Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation.\nOnly months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium.⁶¹ In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack.⁶² Interestingly, while Microsoft very\n⁶⁰. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia.\n⁶¹. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n⁶². “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nclearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government.\nIn both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude.\n# 7 Temporal Considerations\nGiven that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications.\nThere are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 7.1 Discovery-Disclosure\nFirst, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is.\nA short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures.\nAlternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty.\nAn intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves\nElectronic copy available at: https://ssrn.com/abstract=4353069\nas an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63\n## 7.2 Disclosure-Public Attribution\nThe second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution.\nThe SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and\nElectronic copy available at: https://ssrn.com/abstract=4353069\ndisclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle.\nIn contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage.⁶⁴ While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months.⁶⁵ The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.⁶⁶\nThe belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the\n⁶⁴. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n⁶⁵. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018,\n⁶⁶. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nimpact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment\nOne suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nFigure 2: NotPetya Worldwide Search Results from Google Trends\nFigure 3: WannaCry Virus Worldwide Search Results from Google Trends\nWhile retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions\nElectronic copy available at: https://ssrn.com/abstract=4353069\nresponding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response.\nWith the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a\n68. Barack Obama, “Statement by the President on Actions in Response to Russian Malicious Cyber Activity and Harassment,” whitehouse.gov, December 29, 2016, accessed April 8, 2021, https://obamawhitehouse.archives.gov/the-press-office/2016/12/29/statement-president-actions-response-russian-malicious-cyber-activity.\n69. Jen Psaki, “Press Briefing by Press Secretary Jen Psaki and Deputy National Security Advisor for Cyber and Emerging Technology Anne Neuberger, February 17, 2021,” The White House, February 17, 2021, https://www.whitehouse.gov/briefing-room/press-briefings/2021/02/17/press-briefing-by-press-secretary-jen-psaki-and-deputy-national-security-advisor-for-cyber-and-emerging-technology-anne-neuberger-february-17-2021/.\n70. Rose McDermott et al., “Blunt Not the Heart, Enrage It’: The Psychology of Revenge and Deterrence,” Texas National Security Review 1, no. 1 (November 24, 2017).\n71. Nicole Gauvette, “White House says it will hold those responsible for SolarWinds hack accountable within weeks,” CNN, February 19, 2021, accessed February 21, 2021, https://www.cnn.com/2021/02/19/politics/sullivan-solarwinds-khashoggi/index.html.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nspecific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action.\nThe uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent.\n## 8 Type I and Type II Attribution Error\nFinally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how.\nAs previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party.\nThe common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions\n72. A Guide to Cyber Attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthat are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt.\nTo date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.\n73. Catalin Cimpanu, “EU sanctions China, Russia, and North Korea for past hacks,” ZDNet, July 30, 2020, accessed April 8, 2021, https://www.zdnet.com/article/eu-sanctions-china-russia-and-north-korea-for-past-hacks/.\n74. Borghard and Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy.”\n75. Buchan, “Cyber Attacks”; Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion.”\n76. Brandon Valeriano and Ryan C Maness, “The dynamics of cyber conflict between rival antagonists, 2001–11,” Journal of Peace Research 51, no. 3 (May 2014): 347–360.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nDespite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo.\nA need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan, \"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events \"may outpace the speed of the attribution process\" (p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 9 Conclusion\nTo date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand.\nAdditionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution.\nThe argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is\nElectronic copy available at: https://ssrn.com/abstract=4353069\nkey to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications.\nElectronic copy available at: https://ssrn.com/abstract=4353069"
    },
    "author_year": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 182,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [],
      "flat_text": "# Strategic Attribution: Target State Communication in Response to Cyber Operations\nKathryn Hedgecock\nFebruary 24, 2023\n## Abstract\nThis paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n\"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau¹\n# Introduction\nIn December 2014, three weeks after the Sony Picture hack, the first two questions of the White House Press Briefing asked: “Does the White House believe that North Korea is behind the hack at Sony Pictures?” and “What is the United States going to do about it?”. Reporters were asking the standard questions associated with the disclosure of a hack, namely, who is responsible and how the state will respond. The press was seeking public attribution, i.e. the public assignment of blame, which is typically a prerequisite for retaliatory action. To these questions Press Secretary John Earnest subsequently responded, “this is a matter that is still under investigation...[I] am not going to get ahead of that investigation” and “before we start publicly speculating about a response, it’s appropriate that we allow the investigation to move forward”.² Press Secretary Earnest was implicitly appealing to the attribution problem –difficulty in achieving technical attribution– for why North Korea had yet to be named and no response yet taken.\nThe attribution problem is a central theme in the cyber literature.³ The covert and\n¹ Statement by Andrew Hampton, Director-General of New Zealand Government Communications Security Bureau to the Billington Cybersecurity Summit Andrew Hampton, “General Session Panel Allies Counter Common Cyber Adversaries” (New Zealand Director-General of Government Communications Security Bureau, 11th Annual Billington Cybersecurity Summitt 2020, September 8, 2020).\n² Josh Earnest, “Press Briefing by the Press Secretary Josh Earnest, 12/18/14,” whitehouse.gov, December 18, 2014, accessed April 7, 2021, https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814.\n³ Lucas Kello, “The Meaning of the Cyber Revolution: Perils to Theory and Statecraft,” Publisher: The\nElectronic copy available at: https://ssrn.com/abstract=4353069\ntechnical nature of cyber operations make identifying the sponsor very difficult or, at a minimum, time and resource intensive. As a result, the literature focuses on the negative consequences associated with the attribution problem, primarily an erosion of the credibility and feasibility of deterrence by punishment.⁴ However, in this paper, I argue that a narrow focus on attribution as a problem overlooks the strategic agency that deniable attribution provides targets of cyber operations. Uncertainty in the ability and timeliness of attribution, coupled with the clandestine and covert nature of cyber operations, provide the target state three strategies of communication: collusion, disclosure, or public attribution; all of which should be viewed as intentional actions with strategic implications.\nThis paper contributes to the literature on covert action, cyber deterrence, and public attribution as a distinct concept. First, I advance the literature by challenging the emphasis of attribution as a “problem” in the cyber domain. Instead, I argue the attribution problem can also be a strategic asset of the target state by providing additional agency in how they respond to and communicate about cyber operations. While this strategic logic exists in covert action broadly, there are unique features of the cyber domain that heighten the target’s agency. The covert nature of most cyber operations and complexity of attribution provide plausible deniability, not only for the perpetrator, but also for the target state’s technical attribution. A target’s discretion in choosing to what extent they want to acknowledge or respond to an operation prioritizes escalation management at the expense of deterrence by punishment. Second, I extend and adapt the logic of Carson’s *Secret Wars* and Poznansky\nMIT Press, *International Security* 38, no. 2 (2013): 7–40; Martin C. Libicki, *Cyberdeterrence and cyberwar*, in collab. with Project Air Force (U.S.), OCLC: ocn428819545 (Santa Monica, CA: RAND, 2009); Jon R. Lindsay, “Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack,” Publisher: Oxford Academic, *Journal of Cybersecurity* 1, no. 1 (September 1, 2015): 53–67; Joseph S. Nye, “Deterrence and Dissuasion in Cyberspace,” *International Security* 41, no. 3 : 44–71.\n⁴ Charles L Glaser, *Deterrence of Cyber Attacks and U.S. National Security*, Report GW-CSPRI-2011-5 (Cyber Security Policy and Research Institute, June 1, 2011), 8; David D. Clark and Susan Landau, “Untangling Attribution Essay,” *Harvard National Security Journal* 2, no. 2 (2011): 323–352; Nye, “Deterrence and Dissuasion in Cyberspace”; A. F. Brantly, “The cyber deterrence problem,” in *2018 10th International Conference on Cyber Conflict (CyCon)*, ISSN: 2325-5374 , 31–54.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand Perkoski's Rethinking Secrecy in Cyberspace, in arguing that the targeted state has two distinct decisions when experiencing a covert cyber attack: the decision to reveal the occurrence of an operation to the public and the decision to blame their attacker publicly.⁵ The decisions whether to reveal and blame lead to three primary communication strategies: collusion, disclosure, or public attribution. Rather than viewing attribution in the cyber domain as merely a problem to be overcome, attribution should be viewed as a multi-level, multi-player strategic decision in which the target state can choose to what extent it wants to activate domestic and international audiences and its desire to respond.\nThe objective of this paper is theory building and a descriptive effort to advance and define the study of cyber attribution. Given the challenges associated with capturing the universe of cases, empirical examples throughout will provide plausibility probes rather than a definitive test of my theory. This paper will proceed in seven parts. First, I will explore the existing literature on cyber attribution. Second, I discuss two interrelated features of cyber operations that underpin my theory: the covert and clandestine nature and the attribution problem. Third, I argue against the notion that the attribution problem is solely \"problematic\", instead arguing that these features provide a target state increased agency in their response to cyber operations. This has implications for the efficacy of deterrence by punishment, but in a different way than previously theorized. Fourth, I disaggregate attribution into two distinct actions: revealing and blaming. Fifth, I then develop the three strategies available to the target state of a cyber operation: collusion, disclosure, and public attribution. Sixth, I discuss the role of third party actors in the strategic dynamic between target and initiator. Seventh, I demonstrate how temporal considerations are magnified by the clandestine nature of cyber operations and the attribution problem. Finally, I conclude with thoughts about how the nature of cyber operations affects Type I and Type II error in\n⁵ Austin Carson, *Secret Wars: Covert Conflict in International Politics* (Princeton University Press, September 25, 2018); Michael Poznansky and Evan Perkoski, “Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution,” *Journal of Global Security Studies* 3, no. 4 (October 1, 2018): 402–416.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution.\n# Scope\nThe scope of this theory is the strategic considerations of nation-states that are targets of covert, state-sponsored cyber operations (hereby referred to as the target state).⁶ State-sponsored cyber operations include actions taken by the state military and intelligence forces, as well as those that are conducted by state proxies. Even if the specific identity of the attacker is not known, it is often evident when an attack is plausibly associated with a state actor. Typically, the sophistication of the operation, including the resource and intelligence requirements, provide initial indications that a state sponsor may be responsible.⁷\nNon-state actors, from lone wolves to cybercriminal syndicates, are active initiators in cyberspace, but they are outside the scope of the theory. Because of their asymmetry of power with the state, the target state requires different strategic calculations to publicly attribute non-state actors. Additionally, overt cyber operations fall outside of the scope of this theory. Overt operations are those where the perpetrator makes no effort to conceal their identity; thereby removing the target's agency to reveal or attribute. Non-state actors are more likely to initiate overt cyber operations. Currently, the empirical record shows no instances of a state officially credit-claiming a cyberattack on another nation-state.⁸\n⁶ Often, private entities, such as businesses and hospitals, are the victim of cyber operations; however, private industry lacks both the legal right to self-defense in cyberspace, as well as, in many instances, the technical capacity to neutralize sophisticated attacks. As a result, the nation-state in which the private entity resides remains the primary strategic actor faced with a political decision whether or not to acknowledge, attribute and respond to an attack on their private industry. These operations are within the scope of this theory.\n⁷ Tim Maurer, *Cyber Mercenaries*, Google-Books-ID: rKpCDwAAQBAJ (Cambridge University Press, January 18, 2018).\n⁸ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 1 Cyber Attribution Literature\nAttribution is among the most highly studied concepts in cyber; however, it does not carry a singular meaning across the literature.⁹ Some scholars discuss attribution as an act of simply identifying the actor or party responsible, while other scholars use attribution to mean the public act of assigning blame. While this may seem like a minor contrast, these two types of attribution have unique implications and should be understood as distinct.\nThe foundational definition of attribution is the act of identifying the sponsor of an operation (i.e. who is to blame);¹⁰ this will be hereby known as technical attribution. In order for a state to achieve technical attribution, human capital, technical expertise, and intelligence assets are required. There are significant sunk costs in building the capacity to conduct technical attribution for cyber operations.¹¹ Technical attribution also contains a measure of uncertainty because digital forensics do not always clearly map onto a single individual or responsible party. As Lin (2016) points out, there are often different evidentiary standards depending on what ends are sought.¹² Technical attribution typically includes a confidence indicator that captures the uncertainty associated with the assessment of ‘whodunit’. The “attribution problem” discussed within the cyber literature refers to the challenges associated with achieving timely and accurate technical attribution.\nHowever, the use of the word ‘attribution’ among policy makers, news media, and some scholars more frequently refers to a second type of attribution—the political act of publicly assigning blame; henceforth, I will refer to this as public attribution. Thomas Rid and Ben\n⁹. Clark and Landau, “Untangling Attribution Essay”; Herbert Lin, *Attribution of Malicious Cyber Incidents: From Soup to Nuts*, SSRN Scholarly Paper ID 2835719 (Rochester, NY: Social Science Research Network, September 2, 2016); Benjamin Edwards et al., “Strategic aspects of cyberattack, attribution, and blame,” *Proceedings of the National Academy of Sciences* 114, no. 11 (March 14, 2017): 2825–2830.\n¹⁰. Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Susan W. Brenner, “At Light Speed”: Attribution and Response to Cybercrime/Terrorism/Warfare,” *The Journal of Criminal Law and Criminology* (1973-) 97, no. 2 (2007): 379–475; Florian J Egloff, “Public attribution of cyber intrusions,” *Journal of Cybersecurity* 6 (tyaa012 2020).\n¹¹. Lindsay, “Tipping the scales.”\n¹². Lin, *Attribution of Malicious Cyber Incidents*.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nBuchanan (2015) famously wrote “attribution is what states make of it” (p.7). Their work, *Attributing Cyber Attacks*, was among the first to develop a more nuanced understanding of cyber attribution by assessing attribution on three levels: technical, operational, and strategic. They challenged entrenched assumptions that attribution is binary and that attribution is merely a problem of evidence gathering. Specifically, Rid and Buchanan argued that attribution on a strategic level is a function of political stakes, and it is important to understand how attribution is communicated to the public.\nTo date, there has been little effort in the literature to understand public attribution as a distinct theoretical concept. One exception is Florian Egloff who develops a theoretical baseline of public attribution in his work, *Public Attribution of Cyber Intrusions*.¹³ Egloff divides attribution into two conceptual processes which he terms ‘sense-making’ and ‘meaning-making’ processes. Sense-making refers to a technical form of attribution—discovering the perpetrator’s identity—which lies at the root of the attribution problem. Meaning-making is a political strategy that considers attribution within a broader strategic consequence. Egloff has laid a foundation for exploration of attribution as an intentional act by theoretically conceptualizing how public attribution serves a states’ political ends. In subsequent work, Egloff and Smeets (2021) prescribe considerations for when a state should publicly attribute.¹⁴\n## 2 Two Defining Attributes of Cyber Operations\nThere are two defining, interrelated features of cyber operations that are central to all aspects of my theory 1) the clandestine and covert nature of cyber operations and 2) the persistence of the ‘attribution problem’. Together, these characteristics have implications for the target’s\n¹³ Egloff, “Public attribution of cyber intrusions.”\n¹⁴ Florian J. Egloff and Max Smeets, “Publicly attributing cyber attacks: a framework,” Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, *Journal of Strategic Studies*, March 10, 2021, 1–32.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nability to communicate technical attribution, and how they respond to cyber operations.\n## 2.1 Covert and Clandestine Nature\nFirst, as previously discussed in the scope conditions, this theory only pertains to covert operations in which the sponsor has not claimed credit for an attack. Poznansky and Perkoski carefully outline this phenomenon in their work, *Rethinking Secrecy in Cyberspace*.¹⁵ The authors disaggregate secrecy into two types of operations: clandestine and covert. Clandestine operations are those that are hidden from view. Covert operations are those that are designed to conceal the identity of the perpetrator or create plausible deniability, rather than conceal the action itself. Most cyber operations are clandestine by nature given they travel over the digital network. As a result, these operations are not observable. Even cyber operations that are not clandestine, such as ransomware and defacement, are typically covert and the initiating actor strives to conceal their identity.\nThe covert and clandestine nature of cyber operations has implications for both the initiating and target states. Initiating actors are limited in their coercive power since it is difficult to bargain when identity remains concealed.¹⁶ The interaction between the initiator and target may be prone to miscommunication due to difficulty of signaling in cyberspace. Additionally, if the target state wants to understand the nature of the exploit or retaliate, they must invest significant time and resources into the discovery of and the assignment of blame.\n¹⁵ Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n¹⁶ Erik Gartzke, “The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth,” Publisher: The MIT Press, *International Security* 38, no. 2 (2013): 41–73; Erica D. Borghard and Shawn W. Lonergan, “The Logic of Coercion in Cyberspace,” Publisher: Routledge _eprint: https://doi.org/10.1080/09636412.2017.1306396, *Security Studies* 26, no. 3 (July 3, 2017): 452–481; Erik Gartzke and Jon R. Lindsay, “Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace,” *Security Studies* 24, no. 2 (April 3, 2015): 316–348; Tami Biddle, “Coercion Theory: A Basic Introduction for Practitioners,” Texas National Security Review, February 20, 2020, accessed March 4, 2021, https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners/; Michael P. Fischerkeller and Richard J. Harknett, “Deterrence is Not a Credible Strategy for Cyberspace,” *Orbis* 61, no. 3 (January 1, 2017): 381–393.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n## 2.2 Attribution Problem\nSecond, in order for this theory to hold, the attribution problem—the difficulty associated with achieving technical attribution—must persist or be broadly perceived to exist. The attribution problem directly follows from the covert and clandestine nature of cyber operations. When the attribution problem was first introduced in the cyber literature, there was a belief that technical attribution of some cyber operations could be impossible to achieve. Today, a more sophisticated technical community would reject the notion that attribution is impossible.¹⁷ However, the fact remains that technical attribution of cyber operations requires time and resources.¹⁸ States lacking this capacity may continue to find themselves unable to make technical attribution, while all states, regardless of capacity, continue to deal with the implications for timely response.\n## 2.3 The Attribution Problem and Deterrence\nIn the current literature, the primary theoretical consequence of the attribution problem is its erosion of deterrence by punishment; this makes the ‘attribution problem’ even more problematic.¹⁹ Traditional conceptions of deterrence require a credible threat *ex-ante* that changes the cost-benefit analysis of the initiator. Deterrence by punishment is undermined by the difficulty of achieving swift technical attribution (i.e. the attribution problem) because it reduces the target’s ability to credibly threaten costs.\n¹⁷ Justin Canfil, “Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay,” *Journal of Cybersecurity*, 2022, Brenden Kuerbis Milton Mueller Karl Grindal and Farzaneh Badiei, “Cyber Attribution: Can a New Institution Achieve Transnational Credibility?,” *The Cyber Defense Review* 4 (1 2019).\n¹⁸ Lily Hay Newman, “Hacker Lexicon: What Is the Attribution Problem?,” *Wired*, December 24, 2016,\n¹⁹ Clark and Landau, “Untangling Attribution Essay”; Libicki, *Cyberdeterrence and cyberwar*; Glaser, *Deterrence of Cyber Attacks and U.S. National Security*; Nye, “Deterrence and Dissuasion in Cyberspace”; Richard J. Harknett and Joseph S. Nye, “Is Deterrence Possible in Cyberspace?,” Publisher: MIT Press, *International Security* 42, no. 2 (November 1, 2017): 196–199; Brantly, “The cyber deterrence problem”; Biddle, “Coercion Theory”; Fischerkeller and Harknett, “Deterrence is Not a Credible Strategy for Cyberspace.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nAccording to existing literature, the difficulty of technical attribution is a problem for deterrence by punishment due to temporal reasons. Traditionally, there is a sense that punishment for an action should be reasonably close in time to the action for which the retaliation is being leveled. Brantly 2018, in his discussion of cyber deterrence, points out that even if a state promises to punish in the future, upon technical attribution, “the risk of punishment for an attack is possible but so temporally distant as to be discounted to the point of irrelevance” (p.45).²⁰ In other words, the initiating state does not have incentive to change their behavior because, ex-ante, the threat of punishment is so far in the future and uncertain as to be ineffective. While the idea of temporal appropriateness of punishment has not been explored extensively in the international relations literature, it is reinforced by discourses of administering punishment in psychology and legal fields. U.S. Supreme Court Justice Stephen Breyer referenced the long time between punishment and the crime while questioning the constitutionality of the death penalty in his dissenting opinion for *Glossip v. Gross*.²¹\n## 3 Expanding the Consequences of the Attribution Problem\nThe consequences of the attribution problem are more nuanced than currently portrayed. The existing explanation for how the attribution problem erodes deterrence by punishment contains an underlying assumption that, should technical attribution be obtained, punishment would be leveled in response to a cyber operation. However, I question the validity of this assumption in the cyber domain. For deterrence by punishment to serve a legitimate deterrent capability, the initiator must find the threat of punishment credible\n²⁰ Brantly, “The cyber deterrence problem.”\n²¹ Glossip v. Gross, No. 14-7955 (June 29, 2015).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nex-ante. Selective application of punishment erodes the credibility of the threat; therefore, deterrence by punishment only succeeds when punishment is leveled in response to all cyber incidents, or, at a minimum, a clearly designated threshold which empirically does not currently exist.²²\nIn traditional escalation literature, one of the most effective ways to credibly threaten punishment is through the tying of hands.²³ Yet, difficulties in attribution and the covert and clandestine nature of cyber operations not only provide plausible deniability to the perpetrator, they also provide plausible deniability for the target that they have achieved technical attribution. This, in effect, permits the target leeway to strategically withhold or release information about their attribution or lack thereof. It is precisely this discretion that allows the target to untie their hands and selectively respond to cyber operations. In this way, the attribution problem permits target states to sacrifice deterrence by punishment in favor of agency over how they respond to cyber operations.\nThe argument presented in this paper— that difficulties in technical attribution provide the target additional strategic agency in responding to cyber operations— is predicated on several assumptions.\n## 3.1 Assumptions\nFirst and most centrally, this argument rests on the assumption that **target states do not want to respond to every cyber operation**. There are several reasons why this assumption is plausible. To begin, there is perceived to be an offensive advantage in cyberspace and the technology is widely accessible below the threshold of the state.²⁴ These\n²². Lindsay, “Tipping the scales” findings that deterrence works for large scale attacks suggest there may be a tacit understanding of this threshold, but it is not publicly stated.\n²³. Thomas C. Schelling, *Arms and Influence*, 2008th ed., Google-Books-ID: TX_yAAAAQBAJ (Yale University Press, 1966).\n²⁴. Kello, “The Meaning of the Cyber Revolution”; Lindsay, “Tipping the scales”; Nye, “Deterrence and Dissuasion in Cyberspace”; Edwards et al., “Strategic aspects of cyberattack, attribution, and blame.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncharacteristics contribute to a high volume of intrusions, exploits, and attacks, therefore making it impossible to level punishment for every action. Second, choosing how to best respond to a cyber operation is not clear-cut.²⁵ Often, there is not a tidy reciprocal cyber action that a target can take against the initiator. There are four alternative approaches to cyber exploitation by a state actor: 1) take no public action; 2) utilize diplomatic levers such as sanctions or naming and shaming; 3) treat cyber exploits as provocations that require militarization; 4) treat cyber exploits as offenses that require criminalization. This is further complicated by a lack of consensus around what ‘force’ is in the cyber domain.²⁶ For example, some scholars argue that SolarWinds is an espionage operation and, therefore, merely an act of statecraft.²⁷ While others point to the egregious scale and potential for future sabotage and power shifts due to the exploit.²⁸\nThe decision how to respond to a cyber operation is not a simple one. Lindsay states “retaliation can be costly for the one administering the punishment as well as the punished, a victim may decide not to do anything even after attribution if the costs and risks of punishing are too great” (p. 57).²⁹ Here, Lindsay identifies that responding to a cyber operation requires a cost-benefit calculation on behalf of the target state. The target state must have the resolve and political will to respond with punishment once correctly identifying their attacker. There will be instances in which leveling a response is more costly than doing nothing at all. One of the great risks of responding to a cyber operation is the risk of escalation.³⁰ Schneider\n²⁵. Erica Borghard and Shawn Lonergan, “Cyber Operations as Imperfect Tools of Escalation,” *Strategic Studies Quarterly* 63, no. 2 (2019): 122–145; Jason Healey and Robert Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability,” *Texas National Security Review* 3, no. 4 (2020): 30–53.\n²⁶. David Fidler, “Just &amp; Unjust War, Uses of Force &amp; Coercion: An Ethical Inquiry with Cyber Illustrations,” *Daedalus* 145 (September 1, 2016): 37–49; Russell Buchan, “Cyber Attacks: Unlawful Uses of Force or Prohibited Interventions?,” Publisher: Oxford University Press, *Journal of Conflict and Security Law* 17, no. 2 (2012): 211–227.\n²⁷. Erica Borghard and Jacquelyn Schneider, “Russia’s Hack Wasn’t Cyberwar. That Complicates US Strategy,” *Wired*, December 17, 2020,\n²⁸. Yevgeny Vindman, “Is the SolarWinds Cyberattack an Act of War? It Is, If the United States Says It Is.,” Lawfare, January 26, 2021, accessed March 12, 2021, https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it.\n²⁹. Lindsay, “Tipping the scales.”\n³⁰. Martin C. Libicki, *Crisis and Escalation in Cyberspace*, Google-Books-ID: D9YzsTx1mnMC (Rand\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinds that participants in wargame simulations self-restrain in response to cyber operations out of the perception that cyber is highly escalatory.³¹ Once again, this provides plausible evidence that targets of cyber operations do not want to respond to every cyber operation, including, perhaps, some of the most egregious due to a fear of escalation. The challenges of choosing which incidents to respond to, and what response is ‘appropriate’ further erode deterrence by punishment beyond the attribution problem.\nThe second assumption is that states feel pressure to “do something” when they fall victim to hostile actions from another nation-state. This pressure can come from domestic constituents, international audiences, or an internal desire to deter future actions or appear resolved against an adversary.³² The assertion that domestic public support retaliatory response is plausibly supported by survey research which shows high levels of support for retaliation. For example, survey work has found that nearly two-thirds of respondents support a military response when the United States is attacked, regardless if the means of attack are cyber or kinetic.³³ The high-level of support for retaliation is even more notable because the survey experiment tests relatively low-level exploits including financial and information theft. Only 7 percent of survey respondents selected ‘do not acknowledge the attack’ as their most preferred response, meaning 93 percent of respondents preferred the government take some sort of action.\nThe third assumption is that the attribution problem endemic in cyber domain operations (specifically the difficulty of achieving technical attribution) is widely\nElectronic copy available at: https://ssrn.com/abstract=4353069\nCorporation, 2012); Herbert Lin, “Escalation Dynamics and Conflict Termination in Cyberspace,” 2012, 25; Monica Kaminska, “Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks,” Journal of Cybersecurity 7 (tyab008 2021); Brandon G. Valeriano and Ben Jenson, The Myth of the Cyber Offense: The Case for Cyber Restraint, SSRN Scholarly Paper ID 3382340 (Rochester, NY: Social Science Research Network, January 15, 2019); Healey and Jervis, “The Escalation Inversion and Other Oddities of Situational Cyber Stability.”\n³¹. Dr Jacquelyn Schneider, “Cyber and Crisis Escalation: Insights from Wargaming” , 43.\n³². Robert D. Putnam, “Diplomacy and domestic politics: the logic of two-level games,” 00000, International Organization 42, no. 3 (1988): 427–460.\n³³. hedgecock’sukin2023.\naccepted and the public is desensitized to it. In other words, there must be an enduring belief that technical attribution of cyber operations is difficult to achieve and that there is variation on the amount of time and feasibility required. In the kinetic domain, there is an assumption that swift technical attribution can and will be achieved. This creates expectations among domestic and international audiences that the target state will make a public attribution when they are the victim of a conventional attack or exploitation. Even in the case of terrorism, where the identity of the perpetrator may be especially hard to distill, politicians promise to identify and punish their attackers. Less than one minute into President Clinton’s statement following the USS Cole bombing he said: “We will find out who is responsible and hold them accountable.” While elected leaders may face a credibility problem or domestic political costs if they revealed a kinetic operation and said that they did not know who did it or may never know,³⁴ this is not the case for the cyber domain. In fact, the attribution problem is so endemic that several scholars have explored the challenges of convincing the public of an attribution claim in the cyber domain.³⁵ The prevalence of the public rhetoric around the attribution problem has changed expectations of attribution for cyber incidents.\nThe attribution problem is widely referenced in public discourse which helps perpetuate this belief among the public. Take, for example, the United States Office of the Director of National Intelligence’s Guide to Cyber Attribution. In discussing technical attribution, they write: “This painstaking work in many cases requires several weeks or months of analyzing intelligence and forensics. In some instances in which analysts can determine responsibility\n³⁴. James D. Fearon, “Domestic Political Audiences and the Escalation of International Disputes,” *American Political Science Review* 88, no. 3 : 577–592; Kenneth A. Schultz, *Democracy and Coercive Diplomacy* (Cambridge University Press, July 26, 2001).\n³⁵. Marcus Schulzke, “The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty,” Num Pages: 954–968 Place: Cambridge, United Kingdom Publisher: Cambridge University Press Section: Special Section Article, *Perspectives on Politics* 16, no. 4 : 954–968; Florian J. Egloff, “Contested public attributions of cyber incidents and the role of academia,” Publisher: Routledge _eprint: https://doi.org/10.1080/13523260.2019.1677324, *Contemporary Security Policy* 41, no. 1 (January 2, 2020): 55–81.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfor a cyber attack within hours of an incident the accuracy and level of confidence is likely to vary depending on the available data”.36 Separately, during a Biden administration press conference discussing the SolarWinds hack, Deputy National Security Advisor for Cyber and Emerging Technologies, Anne Neuberger, was pressed by a reporter asking “how long this investigation [into SolarWinds] will take?”. Neuberger responded that it would take “several months” without any resistance or skepticism.37 The difficulty of attribution was also part of mainstream dialogue in the 2016 Presidential debates where President Trump made his now infamous statement about the Democratic National Committee hack saying, “[Clinton is] saying Russia, Russia, Russia. Maybe it was. It could also be China. It could be someone sitting on their bed that weighs 400 pounds”.38 Statements such as these continue to reinforce public expectations that cyber attribution is difficult and emphasize a temporal dimension.\nTaken together, these three assumptions provide the foundation for my argument that difficulties in attribution provide target states strategic agency in their response to cyber operations. If states feel pressure to respond when they reveal they are the victim of a cyber operation, but also struggle with the appropriate response to a cyber operation, they may not want to publicly attribute the cyber operation at all or delay their attribution until they have constructed an adequate response. Therefore, the perception of attribution difficulty and the clandestine and covert nature of cyber operations provide target states the ability to manipulate revelation and public attribution to meet their strategic needs. In addition to the commonly understood erosion of deterrence by punishment by undermining the timely delivery of punishment, I\n\nElectronic copy available at: https://ssrn.com/abstract=4353069\npropose a second mechanism by which the attribution problem erodes deterrence by punishment: by providing plausible deniability to the target which permits them to use discretion in which incidents to respond to and when. This can be a target state advantage to control escalation management, but may also degrade deterrence by punishment by eroding the perception of resolve – the political dimension of deterrence.\n# 4 Disaggregating Attribution\nTo this point, I have established how the covert and clandestine nature of cyber operations and the persistence of the attribution problem provide a buffer for target states choosing to respond to cyber operations. The second half of this paper seeks to describe the strategies available to a target state when communicating and attributing a cyber operation, while also considering the effect of third parties on the target's strategic agency.\nAs aforementioned, discussions of attribution in the literature often implicitly connote that blame is being made public. Attribution is cast as the only alternative to maintaining secrecy. However, I believe it is important to distinguish public attribution as a political act that is the culmination of two distinct decisions 1) to reveal a cyber operation has taken place; 2) to publicly assign blame for the cyber operation. Disaggregating public attribution into these decisions provides a more complete understanding of the target's strategic logic in communicating cyber operations and helps illuminate the information dynamics between the initiating and target state.³⁹\nThe relationship between an initiating state and a target state during a cyber operation is one of asymmetric information. Upon initiation of a clandestine and covert cyber operation, the initiating state retains all information about their actions. Upon discovery and technical\n³⁹. The subsection header is inspired by a subtitle in Poznansky and Perkoski (2018) which considers an initiating actor’s decision to keep an operation clandestine or covert which they call ‘Disaggregating Secrecy’.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nattribution of a cyber operation, the target state shifts the information asymmetry in their favor. Any action the target state takes once discovering the intrusion contributes to the broader information story.\nFirst, the target state can make the decision to reveal an attack to the public. This occurs when a clandestine action is made known. Take, for example, a cyberattack on a city's electric grid causing widespread power outages. To the average resident, this incident would initially appear to be a technical malfunction. In order for citizens to know that a cyberattack was the source of the outage, officials with private knowledge about the clandestine attack would have to discover it in the network and reveal it to the public.\nThe second action is a decision whether or not to publicly assign blame; choosing to assign blame constitutes public attribution. This action makes the covert action, overt. An actor can reveal the existence of an exploit without publicly attributing it, but public attribution cannot exist without revealing that an exploit has taken place. Publicly naming the attacker is a decision with political consequences because it evokes both domestic and international audiences. The initiator could remove the agency from the target state should they choose to credit-claim. However, it is empirically unfounded for states to officially claim credit for cyberattacks.⁴⁰\n# 5 Target State Strategies\nIn arguing that the target's response to a cyber operation, or lack thereof, is strategically undertaken, I am also assuming that target states are making a rational cost-benefits calculation when choosing a strategy.⁴¹ To properly understand the decision of the target state, it is worth considering the target state's utility function when deciding how to communicate attribution. I propose that a target state takes into account both international\n⁴⁰. Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace.”\n⁴¹. Lindsay, “Tipping the scales.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand domestic audiences while maximizing national security. Therefore, the target's utility function in choosing the proper response is to maximize deterrent effect, minimize risk of escalation, and minimize the domestic political costs. If the effectiveness of deterrence by punishment is uncertain, then a target state may reasonably aim to optimize on escalation risk and domestic political costs.\nDisaggregating attribution into two distinct decisions (whether to reveal and whether to blame) leads to three primary strategies for the target state. First, a target state may choose collusion by keeping the action and the perpetrator clandestine.[42] Second, a target state may opt for disclosure by exclusively choosing to reveal a cyber operation without assigning blame. The third, and final, strategy is public attribution which occurs when a state both reveals a cyber operation to the public and chooses to assign blame by naming its attacker.[43] In the existing literature, collusion and public attribution are often discussed as the only alternatives available to the target state (see Egloff 2020); however, this theory permits intentionality in revealing without assigning blame under the categorization of disclosure. The following sections will develop the logics within each strategy.\nFigure 1: Strategies of Communication for Target States\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 5.1 Collusion\nCollusion results when the target state chooses to withhold revelation of an attack, as well as the sponsor's identity. This is a well-developed phenomena in the covert action literature both in kinetic and cyber domains.⁴⁴ In his book *Secret Wars*, Carson (2018) theorizes that states participate in either tacit or explicit collusion to manage escalation dynamics. Collusion exists when the target state reinforces a position of non-involvement by refusing to confirm allegations and withholding private information about the role. Because cyber operations are clandestine and covert, the purest form of collusion occurs when the entire operation and the identity of its attacker remain secret or unacknowledged (i.e. the universe of cyber operations that remain classified). The primary mechanism incentivizing collusion in Carson's work is domestic political costs that would require response if the information became public. Egloff (2020) updates Carson's definition of tacit collusion in the cyber domain by arguing collusion in the cyber domain serves three distinct purposes: to communicate legitimacy of the actions such as in espionage activities, to avoid endangering existing rules and regimes, and to prevent cross-domain escalation.\nWhile Egloff's theoretically derived purposes of collusion are a welcome advancement for the cyber domain, it is not clear that tacit collusion provides any distinction among these strategies from the initiator's point of view. The communication being tacit in nature, i.e. not explicitly stated, leaves room for misinterpretation and uncertainty of what is being communicated, particularly in the cyber domain. True collusion requires both the initiator and the target to know that the target could expose their actions and identity but is intentionally withholding.\nIn the cyber domain, the appearance of collusion only tells a partial information story because it is not clear to the initiator *why* the target is withholding their identity and\n⁴⁴ Carson, *Secret Wars*; Poznansky and Perkoski, “Rethinking Secrecy in Cyberspace”; Egloff, “Public attribution of cyber intrusions.”\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthe incident. Without private communication, it is possible that the target is merely feigning collusion for strategic advantage or, alternatively, is inadvertently ‘colluding’ due to difficulties in technical attribution. The important note feature is that both inadvertent and feigned ‘collusion’ may mistakenly appear to be sincere to the initiator and could lead to further misinterpretation. The only true collusion for clandestine and covert actions in cyberspace requires clear, private communication or signaling.\nCarson’s exploration of collusion also accounts for possible exposure by third party actors. He argues that exposure of a covert action by a third party actor makes the operation an “open secret” (p. 48). The visibility of the collusion is particularly important in the cyber domain due to the large number of private cybersecurity firms who have visibility over clandestine actions, as well as the number of victims and the global nature of the transit across publicly accessible servers. The cyber domain provides an extensive range of collusion cases that are “open secrets,” i.e. cyber operations that have been revealed to the public by third-party actors, and have not been acknowledged by the target or initiating state. However, in the cyber domain, it is important to distinguish whether the third party merely has visibility over the occurrence of an operation, or if they also can expose the perpetrator’s identity.\n## 5.2 Disclosure\nThroughout the cyber literature, attribution and collusion are often presented as the only discrete actions a state can take.⁴⁵ This neglects a third, frequently used option, I term disclosure. Disclosure is the act of revealing the existence of a cyber operation without\n⁴⁵. In Carson, *Secret Wars*, the alternative to collusion is exposure, which he argues has variations among the level of detail or witnesses. This distinction manifests in “covert-but-visible to other major powers or covert-but-visible to all publics and states” (p. 39). Because of the clandestine nature of cyber operations and the lack of visible evidence to available to alternative audiences, exposure is insufficient to capture non-collusive behavior in the cyber domain. Exposure implies attribution and bundles the two stages I have disaggregated in this theory. Egloff (2020) in his development of public attribution likewise pairs collusion and public attribution as alternatives.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nassigning blame.⁴⁶ Technical attribution is not necessary for disclosure to take place. Even if the target state does not know their hacker, the target state can still reveal the discovery of a cyber operation.\nDisclosure is largely unexplored in the literature because there is an implicit assumption that states only choose this outcome when they do not know the identity of their attacker (i.e. the attribution problem). However, this neglects a secondary, more strategically interesting type of disclosure where a target may opt to reveal they were the victim of a cyber operation and intentionally withhold the identity of their attacker. Disclosure is a strategy that is more politically viable in response to operations in the cyber than the kinetic domain so long as the attribution problem is believed to exist.\nLooking at the target states' utility function, disclosure eliminates the likelihood of escalation because there is no named responsible party to retaliate against. There is a mild deterrent effect by notifying the initiating actor that their operation is compromised and communicating normative expectations of appropriate cyber behavior. The greatest unknown for ambiguous disclosure is the domestic political costs. Depending on how the disclosure is delivered, the domestic public may demand more information, the public may be sympathetic to the challenges of attribution, or the public may show apathy to the costs of the attack with no further action expected.\n## 5.2.1 Forms of Disclosure\nDisclosure can take three forms: 1) **ambiguous disclosure**- revealing the existence of a cyber operation with no indication of blame; 2) **unattributed disclosure**- revealing\n⁴⁶. The disclosure I propose is different than how disclosure is currently discussed in the literature which implies attribution while making private information public; therefore, it is more akin to exposure. See Austin Carson and Allison Carnegie, “The Disclosure Dilemma: Nuclear Intelligence and International Organizations,” *American Journal of Political Science* 13, no. 3 (2019): 269–285; Jacob Otto and William Spaniel, “Doubling Down: The Danger of Disclosing Secret Action,” *International Studies Quarterly* 65, no. 2 (2021): 500–511\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand explicitly declaring that technical attribution has not been achieved 3) withheld disclosure- revealing and explicitly stating that technical attribution is achieved, but public blame is being intentionally withheld. Each of these disclosure strategies affects the information symmetry between target and initiator, while also activating audiences in different ways.\nIt is important to note that when a state qualifies their disclosure with whether or not they have achieved technical attribution, audiences are being asked to take them on their word. There is no proof that validates the absence or achievement of technical attribution. Therefore, disclosure of all types still fosters uncertainty and lacks credibility as a signal.\n## Ambiguous Disclosure\nFirst, the target state may choose ambiguous disclosure by revealing a cyber operation with no indication of blame. One example of this is the 2014 hack of a German steel mill. In December 2014, the German Federal Office for Information Security published their annual report, revealing that a cyberattack resulted in physical damage at an unnamed steel mill.⁴⁷ After Stuxnet, this incident was only the second-known cyberattack to result in physical destruction; yet, little attention was paid to this event. Germany never publicly revealed the perpetrator, nor did they issue any public response to the incident- a quiet admission of cyberattack, nestled in an otherwise standard annual report, was the entirety of the public-facing response.\nAmbiguous disclosure is useful if the target state wants to induce uncertainty in the attack sponsor. At the point of disclosure, barring any private communication, the sponsor of the cyber operation still does not know whether the target has identified them as the initiator. As a result, the information asymmetry shifts in favor of the target. The initiating state must interpret from this disclosure whether or not their identity has been compromised\n⁴⁷ Federal Office for Information Security, Bericht zur Lage der IT-Sicherheit in Deutschland 2014 (2014).\nElectronic copy available at: https://ssrn.com/abstract=4353069\nand whether blame is being intentionally withheld or not.\nAmbiguous disclosure is a primary strategy when the target state is legally obligated to reveal a cyber operation, but does not want to take further action. A target may also be incentivized to choose ambiguous disclosure when there is a potential that a third party may reveal the cyber operation and the state wants to maintain the initiative and competency by disclosing the operation first.\n## Unattributed Disclosure\nSecond, the target state may disclose a cyber operation and publicly acknowledge that they have not achieved technical attribution and therefore cannot assign blame, which I term unattributed disclosure. This is frequently the chosen strategy when technical attribution requires more time, but the target state is compelled to reveal. Therefore, this may be a preliminary strategy to bide time on public attribution. However, it is not always a precursor to public attribution. The target state may not want to invest the resources into achieving technical attribution, or, alternatively, may not be able to achieve enough confidence in their technical attribution that they are willing to publicly assign blame.\nOne purpose of unattributed disclosure is an appeal for assistance. Unattributed disclosure of a cyber operation generates a response from the broader cybersecurity community, such as the case of Stuxnet. Following the Iranian discovery of the malware in their computer systems, the United Nations' International Telecommunication Union (ITU) asked Kaspersky Lab to study the malware. Private security researchers determined the code had similarities to Flame malware and ultimately attributed the malware to the United States and Israel.[48] In this case, revealing the cyber exploit and admitting the absence of technical attribution permitted sophisticated third-party cybersecurity researchers to\nElectronic copy available at: https://ssrn.com/abstract=4353069\nfinalize the attribution process.\n## Withheld Disclosure\nFinally, a state may choose withheld disclosure by acknowledging or implying that technical attribution has been achieved, but blame will not be publicly assigned. Withheld disclosure is an information story that communicates several things. First, to the sponsoring state, private attribution serves as a warning shot that they have been discovered. Second, to international and domestic audiences it communicates the target states' technical competence in attribution. Third, it implies that the target has no desire to take public action against the perpetrator. Fourth, it suggests that the target perceives its domestic constituents to be apathetic to a response. If there are no domestic costs for choosing this approach, this may be an optimal strategy for a target state when they assess the costs of a retaliatory response are too high. It may also be the case that attribution is being withheld out of a desire to bundle public attributions in a more powerful case.\nOne example of withheld disclosure is the June 19, 2020 disclosure of a major cyber campaign by Australian Prime Minister Scott Morrison. Prime Minister Morrison made a first-of-its-kind televised address to the nation notifying Australians that the government and private entities were experiencing widespread cyber attacks from a “sophisticated state-based cyber actor”.49 During the statement, Prime Minister Morrison appealed to the public to improve their cyber hygiene. Abigail Bradshaw, Head of Australian Cybersecurity Centre, told Billington Cybersecurity Summit that “The benefit of that national statement that the prime minister made was the very purpose we have been discussing, to generate a national awareness for two purposes: firstly, defense is always the best offense, always. And secondly, cybersecurity is a team sport. So, I’m going to use the 19th of June statement by way of\nElectronic copy available at: https://ssrn.com/abstract=4353069\npractical example. As I said, the purpose of that statement by the Prime Minister was to lift Australian awareness from individuals through the big critical infrastructure providers through to all levels of government about the level of targeting that is apparent\".50\nIn this instance, Prime Minister Morrison intentionally left the sophisticated state-based actor nameless, but technical attribution was implied. When asked in a press conference about the identity of the responsible party, Morrison responded “There are not a large number of state-based actors that can engage in this type of activity.” Further pressed, he stated he would not make “any public attribution”.51 After a rash of news reports began speculating that the actor was China, Morrison remained coy stating, “We have not gone any further than that. I can’t control what speculation others might engage in”.52\nThis example illustrates a key purpose of withheld disclosure, which is permitting third-party speculation on the attribution. A third-party may correctly identify the sponsor of the attack (perhaps even due to ‘anonymous government officials’), however, until the target state chooses to acknowledge the public attribution they are forgoing the responsibility to respond. This was well captured in the ZDNet headline “Scott Morrison cries ‘Cyber Wolf!’ to deniably blame China”.53 I categorize this as distinct from state-actor collusion because the state consciously chooses to reveal the existence of the operation and may even encourage third party attribution.\nThe target state must know that disclosure of any type activates a broader audience. The domestic public becomes aware of a cyber operation and their potential individual vulnerability. If a target state elects to disclose a cyber operation and the exploit exists\nElectronic copy available at: https://ssrn.com/abstract=4353069\noutside the government’s classified network, third-parties may make public attribution without their consent. Once a consequential cyber operation is revealed to the public, the marketplace of cybersecurity firms has reputational and financial reasons to seek attribution. However, allowing a third party to make an attribution and remaining silent is a legitimate strategy if the target state does not want to publicly retaliate.\nThe target state can lose agency over the decision to reveal in a few circumstances. First, if the initiator chooses to conduct a non-clandestine cyberattack then the cyber operation is revealed by the nature of the exploit, i.e. ransomware or defacement. For example, in the 2014 Sony hack, employees logged onto their computers to find a threatening message warning them data would be released if they did not comply with the hackers’ demands. In these instances, the sponsor state has willingly revealed and has forced the target state down the decision tree to decide whether or not they will publicly attribute the attack once they have achieved technical attribution.\nSecond, the target state can lose agency over the disclosure when public shareholders or legal liability requires a private entity to disclose a hack. This is frequently the case with data breaches in which domestic laws require disclosure to the individuals’ whose data has been exposed. In each of these instances, the target state cannot contain the public nature of the disclosure; however, they can select whether or not they would like to qualify the disclosure with an indication of technical attribution.\n### 5.3 Public Attribution\nFinally, the states that take the action to both reveal and assign blame to a cyber operation are choosing public attribution. Public attribution is the only strategy that requires technical attribution (although to what certainty depends on the state’s prioritization of Type I and Type II error, which I briefly explore later in this paper). A target state that wants to impose non-clandestine, overt consequences must publicly attribute. Overt punishments span a wide\nrange of escalatory potential from diplomatic solutions, such as naming-and-shaming and economic sanctions, to retaliatory cyber or physical attacks.54 Egloff (2020) argues that public attribution serves three primary purposes: to shape the operational space, to develop norms, and to provide limited deterrence value.\nA target states’ decision to publicly attribute makes the attribution common knowledge; the sponsor state knows that the target knows they initiated the operation. However, the information story is more complicated than a binary knowledge of whodunit. Public attribution begets detailed, public information disclosure, especially in democracies. The target state runs a risk in choosing how much information to share and the level of detail involved.\nFor one of the best illustrations of the information dynamics, I return again to the example of SolarWinds. The United States chose a strategy of public attribution for SolarWinds. As previously mentioned, within five days of FireEye disclosing their hack, the United States government formally acknowledged that numerous state agencies had fallen victim to the exploit and that they believed Russia was responsible. The government began a highly public tally of businesses and agencies involved. In one press conference, Deputy National Security Advisor Anne Neuberger noted that “nine federal agencies and about 100 private sector companies were compromised”.55\nThe risk associated with public attribution is that, particularly in democracies, there is an expectation of transparency.56 Excessive transparency accompanying public attribution provides the initiator an information advantage. In the case of SolarWinds, the United States government was publicly acknowledging each U.S. agency that had been compromised as it was discovered. It was not until nearly two months after the initial revelation of SolarWinds\n\nElectronic copy available at: https://ssrn.com/abstract=4353069 that the U.S. government announced that NASA and the FAA were also victims of the hack. Russian intelligence could feasibly use open-source reporting to assess which intrusions had been compromised and which remained undetected.\nAlthough public attribution is necessary to impose overt punishment, a target state can engage in a clandestine response to a cyber operations at any stage: collusion, disclosure, or public attribution. A target state could directly threaten to impose costs for future action in the 'backstage' while still colluding to maintain secrecy from the public.57 While covert retaliation should be explored in more detail in future research, it is important to note that a clandestine response prevents the target state from engaging international or domestic audiences (a prerequisite for naming-and-shaming). Therefore, it may be the case that covert retaliation is more escalatory than overt diplomatic options, but less escalatory than overt counter-operations in either the cyber or kinetic domain. However, covert retaliation faces the same issues of covert initiation in that clear intent or signaling to the initiating actor may not be possible without accompanying communication. Therefore, inadvertent escalation could be even more acute in response to covert retaliation.58 ## 6 The Role of Third-Party Actors Thus far, I have discussed three strategies available to the state to communicate cyber operations. In all examples of state strategy presented, there has been a common theme—the presence of third party actors. Empirically, third-parties have an unconventionally large role in the disclosure and public attribution of cyber operations.\nIn the kinetic domain, public attribution is primarily the responsibility of the state. This is not the case in the cyber domain, where a robust secondary market of privatized\n\nElectronic copy available at: https://ssrn.com/abstract=4353069\ncybersecurity professionals often make public attributions before or in lieu of the state. Third-parties include, but are not limited to, private cybersecurity firms, technology companies, private corporations, international organizations, and independent news media.\nIn assessing the role of a third-party in attribution, it is essential to understand the third-parties' relationship to the cyber operation. Third-parties can be an injured party, or merely a bystander. The incentive structure for making a public attribution is different for third-party actors compared to the target state. As bystanders, third-party actors have both financial and reputational stakes which may incentivize public attribution of incidents. Separately, legal requirements and stakeholder pressure drive disclosure when they are the victim.\nThird-party actors can either be complementary or disruptive to the target state's agency. Third parties serve as a complement to target state attribution in three ways: 1) assisting with attribution and discovery when the target state lacks visibility or resources; 2) by bolstering the credibility of an attribution; 3) disclosing or attributing on behalf of the state, permitting the state to retain their plausible deniability. Evidence of the assistance with attribution (technical and public) is illustrated in the previous example of Stuxnet, involving both the UN's International Telecommunication Agency and Kaspersky cybersecurity firm. Third parties can also bolster attribution credibility, signaling legitimacy for an technical attribution that otherwise is difficult to demonstrate to the public. One example is a Wall Street Journal Op-ed in which Homeland Security Adviser Thomas Bossert publicly attributed the 2017 WannaCry attacks, writing: \"We do not make this allegation lightly. It is based on evidence. We are not alone with our findings, either. Other governments and private companies agree. The United Kingdom attributes the attack to North Korea, and Microsoft traced the attack to cyber affiliates of the North Korean government\".[59] Finally,\nElectronic copy available at: https://ssrn.com/abstract=4353069\nthird parties may make a public attribution or disclosure in lieu of the government. This is most common with independent news media reporting on the condition of anonymous sources, as indicated in the previous example of the Australian intrusion. The existence of this outcome suggests a third form of collusion between the target and third party actors which is an area ripe for further research.\nHowever, third-parties can also be disruptive in the attribution space by forcing the target state's hand on attribution and disclosure decisions. To illustrate this, I offer a closer look at the U.S. government's handling of two major cyber operations within months of each other: SolarWinds (Sunburst) and the Microsoft Exchange Hack. In the case of SolarWinds, FireEye, a private cybersecurity firm, took the lead in disclosing the attack. However, they conducted an ambiguous disclosure, offering no indication whether or not they knew the identity of their attacker. The U.S. government not only acknowledged the hack, but also provided swift public attribution that the hack was conducted by Russia.⁶⁰ Additionally, the Biden administration made clear that they were crafting a retaliatory response for the operation.\nOnly months later, in March 2021, Microsoft released a blog notifying the public of an ongoing nation-state attack affecting the Microsoft Exchange server with corresponding patches to protect against the exploit. Microsoft explicitly attributed the exchange hack to Chinese APT group, Hafnium.⁶¹ In the subsequent day's press briefing, the White House acknowledged the existence of the hack, warning the public about the far-reaching effects of this exploit. Likewise, the Cybersecurity and Infrastructure Security Agency (CISA) released emergency directives warning the public of the hack.⁶² Interestingly, while Microsoft very\n⁶⁰. The U.S. government under a Trump Administration and President-Elect Biden both publicly attributed the operation to Russia.\n⁶¹. Tom Burt, “New nation-state cyberattacks,” Microsoft On the Issues, March 2, 2021, accessed April 5, 2021, https://blogs.microsoft.com/on-the-issues/2021/03/02/new-nation-state-cyberattacks/.\n⁶². “Joint Statement by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), the Office of the Director of National Intelligence (ODNI), and the National Security Agency (NSA) — CISA,” accessed February 1, 2021, https://www.cisa.gov/news/2021/01/05/joint-statement-by-the-federal-bureau-of-investigation-cisa/.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nclearly attributed the attack to Hafnium, the White House and CISA stopped at ambiguous disclosure – neither engaged in public attribution. It was not until July of 2021 that the Biden Administration announced it was prepared to publicly attribute Hafnium to the Chinese government.\nIn both cases, third party actors had a role in shaping the strategic response of the United States. FireEye, in the case of SolarWinds, removed the target state’s agency for private collusion, i.e. keeping the exploit classified. This forced the government further down the decision tree to decide whether or not to publicly attribute. Separately, Microsoft’s public attribution of China forced the United States to decide whether to acknowledge the attribution or to openly collude.\n# 7 Temporal Considerations\nGiven that third-party actors have a prominent role in the dynamics of public attribution, one may reasonably conclude that the target state only has limited agency over the political implications of attribution. However, target states can retain some strategic agency by manipulating the timing of their communications.\nThere are two strategically significant timelines at play in this interaction: 1) Discovery-Disclosure: The timing of when a target discovers an operation relative to when the attack is disclosed to the public; 2) Disclosure-Public Attribution: The timing of disclosure of a cyber operation relative to when blame is publicly attributed. Both these temporal windows can serve an important political function.\nElectronic copy available at: https://ssrn.com/abstract=4353069\n# 7.1 Discovery-Disclosure\nFirst, there is timing between when the operation is discovered and when it is revealed to the public. A well-concealed operation may take months or years to detect. This delay is particularly likely for instances of cyber espionage where the initiating state has an incentive to remain undetected for as long as possible, such as the 2020 SolarWinds hack. The discovery of a cyber exploit by the target (whether espionage or sabotage) is not a political action; however, what the target state does with the knowledge of a cyber operation is.\nA short discovery to disclosure timeline may serve an important defensive function to mobilize the public to patch servers or alternative cyber hygiene measures. This is especially important with zero-day vulnerabilities on public software. An example of this is the previously discussed Microsoft Exchange hack. The White House and CISA amplified the disclosure with an emergency directive to encourage defensive measures.\nAlternatively, the target may have incentive to delay revealing a newly discovered cyber operation. For enduring cyber operations such as espionage or dormant sabotage operations, the target may want to observe their hacker at work and learn more about their identity, tactics, and techniques. Returning to the concept of common knowledge, an attack sponsor does not know their operation has been compromised until the target reveals the discovery. A delay between discovery and disclosure also allows the target to prepare a response or seek outside expertise to increase certainty.\nAn intentional delay in the discovery-disclosure timeline is plausibly supported by the existence of the Vulnerability Equities Process (VEP) in the United States. The VEP is an interagency process designed to deliberately assess when to disclose newly discovered software vulnerabilities to companies for patching. Delayed disclosure allows the government to exploit the vulnerabilities for intelligence gathering. The VEP gets its name because each actor has different ‘equities’ in the process which must be balanced for the sake of national security. These equities are discussed in an Equities Review Board, which serves\nElectronic copy available at: https://ssrn.com/abstract=4353069\nas an interagency discussion to assess disclosure. Rob Joyce, Trump Administration White House Cybersecurity Coordinator explains, “At its most basic level, the VEP is charged with balancing whether to disclose vulnerability information to the vendor with expectation that they will patch the vulnerability, or temporarily restrict knowledge of the vulnerability so that it can be used for national security or law enforcement purposes. I believe that conducting this risk/benefit analysis is a vital responsibility of the Federal Government”.63\n## 7.2 Disclosure-Public Attribution\nThe second important temporal consideration is the time between the disclosure of a hack and the public attribution. Empirically, temporal spacing between these two events is a very common phenomenon. While it is possible that the disclosure and public attribution are spaced out of necessity (the absence of technical attribution), the timing could also be intentional. Keeping the disclosure and public attribution simultaneous or in swift succession increases the urgency to act. The disclosure of the attack generates headlines and may provoke perceptions of vulnerability and fear. Alternatively, significant passage of time between the revelation of a hack and publicly attributing the perpetrator may provide a critical source of escalation reduction. As time passes, so too does the news cycle and issues that were once emotional become less salient. The implication of this theory is that leaders who want to generate public support for retaliation are incentivized to closely space the disclosure and attribution.\nThe SolarWinds exploit entered the U.S. government systems via supply chain hack, establishing a backdoor through a trusted software. The exploit lived in the U.S. government networks since March 2020, yet, the attack was not discovered until December 2020 by the cybersecurity firm, FireEye. In the case of SolarWinds, both the discovery-disclosure and\nElectronic copy available at: https://ssrn.com/abstract=4353069\ndisclosure-public attribution timelines were very short; the exploit was revealed and publicly attributed to Russia within a matter of days from when it was discovered in the network. It is no surprise that simultaneous calls for retaliation sounded from both sides of the aisle.\nIn contrast, one example of a prolonged discovery-public attribution timeline is NotPetya. NotPetya was the “most destructive and costly and devastating cyber-attack in history” paralyzing global industry and costing billions of dollars in damage.⁶⁴ While the primary political target of the operation was Ukraine, the indiscriminate effects victimized nations around the world. Despite the scale of the operation, governments did not publicly attribute Russia to the operation for eight months.⁶⁵ The response to NotPetya was a coordinated diplomatic response (naming-and-shaming) of seven nations, with a subsequent U.S. Department of Justice indictment for the actors involved- a relatively tepid response for such a costly operation.⁶⁶\nThe belief that public salience of a cyber operation is reduced when the disclosure-public attribution timeline is prolonged is plausibly supported by a phenomenon from economics literature known as the Efficient Market Hypothesis (EMH). The EMH suggests that share prices reflect all available information. In studying the market’s reaction to company mergers, Keown and Pinkerton (1981) find that the market reacts when the information is released, not when the actual merger takes place. This provides some plausibility for how to understand the reception of information during the revelation and public attribution of cyber operations. Revealing the occurrence of a cyber attack is the announcement of new information that generates a news headline. If attribution of that event happens after time has passed, the\n⁶⁴. Sarah Sanders, “Statement from the Press Secretary,” The White House, February 15, 2018, accessed December 6, 2019, https://www.whitehouse.gov/briefings-statements/statement-press-secretary-25/.\n⁶⁵. Andy Greenberg, “White House Blames Russia for NotPetya, the ‘Most Costly Cyberattack In History’,” Wired, February 15, 2018,\n⁶⁶. Stilgherrian, “Blaming Russia for NotPetya was coordinated diplomatic action”; “Six Russian GRU Officers Charged in Connection with Worldwide Deployment of Destructive Malware and Other Disruptive Actions in Cyberspace,” The United States Department of Justice, October 19, 2020, accessed April 8, 2021, https://www.justice.gov/opa/pr/six-russian-gru-officers-charged-connection-worldwide-deployment-destructive-malware-and.\nElectronic copy available at: https://ssrn.com/abstract=4353069\nimpact is less salient to the general public. This phenomena is supported in Hedgecock and Sukin (2023) where they find respondents were four percent less likely to support retaliation if they received a vignette treatment stating the attack happened 'more than a year ago' compared to those who received the treatment of 'recently'. findings that respondents who received a treatment\nOne suggestive test of this phenomena in the cyber domain is also the Google Trends data associated with NotPetya and WannaCry. I selected these two cyber operations for several reasons. First, they were highly consequential operations that generated large amounts of news coverage; because the public is aware of the costly nature of the operations, these incidents serve as a stringent test of the theory. Second, these cyber operations affected western nations whose publics were more likely to use the Google browser. Third, the public attribution by the target state was months after the cyber incident was disclosed to the public. Finally, they were attributed to two different actors, Russia and North Korea respectively, so any inherent bias associated with a specific perpetrator may manifest in different public engagement. Figure 2 and 3 both illustrate a very similar story of declining public salience. The y-axis runs from 0 to 100, where 100 represents the maximum number of searches for the term within the specified time range. The incident date is represented by the dashed red line and the public attribution is represented by the dashed black line. In both instances, there is a dramatic decline in google searches for both the incident's name, as well as a corresponding general search term, (i.e. cyberattack or virus respectively).[67]\nElectronic copy available at: https://ssrn.com/abstract=4353069\nFigure 2: NotPetya Worldwide Search Results from Google Trends\nFigure 3: WannaCry Virus Worldwide Search Results from Google Trends\nWhile retaliation should theoretically be delivered within a short temporal window, the rhetoric of the U.S. administrations has attempted to leave open a broader window of retaliation for cyber operations. In December 2016, while announcing a series of sanctions\nElectronic copy available at: https://ssrn.com/abstract=4353069\nresponding to the Russian cyber and information operations surrounding the election, President Obama said “These actions are not the sum total of our response to Russia’s aggressive activities. We will continue to take a variety of actions at a time and place of our choosing, some of which will not be publicized”.68 Likewise, during the first press conference of the Biden Administration, just one month after the revelation of the SolarWinds hack, Press Secretary Jen Psaki, said “we reserve the right to respond at a time and in a manner of our choosing to any cyberattack”.69 The insistence that the United States can respond at a time of its choosing runs counter to previously existing belief that retaliation is best served warm.70 In fact, this reduces the salience of the attribution problem on deterrence by punishment by eliminating a need for swift technical attribution in order to level a retaliatory response.\nWith the passing of time, the certainty of technical attribution may also increase. United States National Security Director Jake Sullivan said in an interview, “Right after President Biden took office, he tasked the intelligence community with an assessment of the scope and scale of [SolarWinds], and he also asked the intelligence community to provide him with an updated capacity to attribute exactly who conducted it. What the previous administration said was, quote, ‘that it was likely of Russian origin.’ We believe we can go further than that”.71 The idea that the administration can go further in attribution, to perhaps offer a\n\nElectronic copy available at: https://ssrn.com/abstract=4353069 specific individual or APT (advanced persistent threat) actor demonstrates another temporal dimension. In this case, the United States is suggesting that technical attribution of higher precision is possible which could in turn justify delaying retaliatory action.\nThe uncertainty about the ability and timeliness of attribution is a necessary feature for this strategic logic to work. If attribution was thought to be easy and quick, it would undermine the target state’s ability to temporally space the disclosure and public attribution without appearing incompetent.\n## 8 Type I and Type II Attribution Error Finally, the covert nature of cyber operations and the challenges of technical attribution also have implications for Type I and Type II public attribution error in cyberspace. Public attribution activates international and domestic audiences through a formal accusation of wrongdoing, thereby, drawing attention to the target’s next move. This action raises the stakes for all parties involved as they consider whether to respond and how.\nAs previously mentioned, technical attribution often reflects some measure of uncertainty. The United States Director of National Intelligence classifies attributions with an indicator of high, moderate or low confidence.72 The target state must determine what degree of certainty they require to publicly attribute. This is not a fixed quantity and may vary depending on the political context or the identity of the responsible party.\nThe common perception that cyber attribution requires time and expertise has moderated expectations among domestic and international audiences, reducing the expectation of swift, or even feasible, attribution. Low expectations for attribution among the public provide a natural buffer against the political costs of inaction, allowing for target states to prioritize accurate attribution and minimize Type I error; in other words, to only make attributions Electronic copy available at: https://ssrn.com/abstract=4353069 that are correct, even if it means allowing some perpetrators with lower levels of certainty go unchecked. The ability to bias in favor of reducing Type I error suggests that claims of attribution in cyberspace should be made with a high level of certainty. The United States' reliance on Department of Justice indictments for cyber operations is an excellent example of highly detailed public attributions that bias in favor of Type I attribution. The choice to use a legal venue and criminalize the action requires that the accusation can stand up in a court of law and be proven beyond a reasonable doubt.\nTo date, the overt consequences of being blamed for a cyber operation are relatively low. The primary public facing response for a cyber operation are diplomatic actions such as naming and shaming. Russia, China, and North Korea have all been sanctioned for select actions in cyberspace.73 The United States has also attempted to create costs for individuals through indictments and sanctions of specific actors. One reason the costs remain low is that there is a disagreement whether cyber espionage, which makes up a preponderance of offensive cyber operations, is statecraft or an attack.74 There is no normative consensus on acceptable behavior in cyberspace, and existing international law which explicitly requires a use of force has ambiguous applications to cyber effects.75 These limitations make punishing sponsors of cyber operations difficult. Because the punishments rendered after being accused of a cyber operation have been relatively low, Type I error -falsely accusing a state for a cyber operation they did not sponsor- carries relatively low risk of escalation. To date, there is little reciprocity for cyber operations and escalation has proven to be restrained.76 Even once attribution is made with certainty, there is a high likelihood that the attack sponsor denies the event.\n\nElectronic copy available at: https://ssrn.com/abstract=4353069 Despite the fact that the costs of Type I error would remain low, it is still more costly for the target state than making no attribution at all and allowing the perpetrator to go unchecked (Type II error). The costs for a target state that makes an incorrect public attribution are not just the risk of inadvertent escalation. Incorrect public attribution can damage a target state's reputation and credibility. Additionally, an incorrect public attribution provides information to the true operation sponsor that they have not been correctly identified and may embolden them. The sponsor once again has an informational advantage of knowing their identity has remained covert. Thanks to the prevailing attribution problem and the clandestine nature of cyber, the residual category of no public attribution is a legitimate, low cost option for a target. Type I error is considerably more costly than the status quo.\nA need for swift decision making could increase the amount of Type I error in cyberspace. Rid and Buchanan (Rid and Buchanan,\"Attributing Cyber Attacks\") briefly allude to this when they say, it is possible that political events\"may outpace the speed of the attribution process\"(p. 32). While this is true in theory, it is difficult to conceive of the cyber context in which this is the case. Unlike in the kinetic domain where quick reciprocity may prevent further loss of life or destruction, a majority of cyber events, particularly espionage, do not require an immediate volley of return fire. The most likely case of cyber incidents that would necessitate a rapid response are sabotage operations that create physical destruction. Sabotage attacks are difficult to create en masse, as a zero-day attack is highly tailored to exploit a specific vulnerability.77 Separately, when cyber operations serve as a compliment rather than a substitute for force in cross-domain conflict, there are many contextual and physical indicators that would increase the speed and confidence of attribution, reducing the likelihood of Type I error.\nElectronic copy available at: https://ssrn.com/abstract=4353069 # 9 Conclusion To date, the preponderance of work on cyber attribution focuses on the difficulty of credibly deterring and punishing when attribution is slow or impossible. However, this emphasis among scholars neglects the agency that attribution difficulties provide to the target state. Challenges of attribution buffer from expectations of rapid response and allow the target greater discretion over the strategic interaction with the initiator. In turn, the attribution problem *does* erode deterrence by punishment, but in a different, more self-inflicted way than previously theorized: plausible deniability permits the target state flexibility over how and when to respond to cyber operations, thereby untying their hands and making punishment less credible. While this may be detrimental for deterrence by punishment, the target state retains an advantage by controlling escalation and domestic political costs. The implication of this theory is that initiating actors who want to elicit a response from their target, perhaps to draw them into costly action or to divert resources and attention, should conduct overt operations or at least operations visible to the public to force the target’s hand.\nAdditionally, in the second half of the paper I adapt the logic of *Carson (2018)* and *Poznansky and Perkoski (2018)* by outlining the strategic considerations of states who fall victim to state-sponsored cyber operations. I argue that the covert and clandestine nature of cyber operations, and the resulting difficulties associated with attribution, create two decision points for the target state: whether to reveal an operation and whether to publicly assign blame. These decisions provide three possible communication strategies: collusion, disclosure, or public attribution.\nThe argument presented here today suggests that a lack of escalation in the cyber domain is not merely because retaliation is hard to deliver in a timely manner; rather, the attribution problem permits target states discretion to choose a slow, tailored approach to public attribution and response. Public understanding of the attribution problem is Electronic copy available at: https://ssrn.com/abstract=4353069 key to moderate domestic political costs associated with drawn out response times or the absence of attribution all together. Ultimately, this paper opens a broader dialogue about the intentionality with which attribution is communicated to the public and its implications.\nElectronic copy available at: https://ssrn.com/abstract=4353069"
    }
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 38.0,
      "success_occurrences": 38.0,
      "success_unique": 19.0,
      "bib_unique_total": 19.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 1.0,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 17.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 17.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 38.0,
        "success_occurrences": 38.0,
        "success_unique": 19.0,
        "bib_unique_total": 19.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 1.0,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 17.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 182.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "Strategic Attribution: Target State Communication in Response to Cyber Operations",
    "subtitle": "February 24, 2023",
    "document_type": "report",
    "venue": "",
    "publication_year": 2023,
    "authors": [
      "Kathryn Hedgecock"
    ],
    "affiliations": [],
    "emails": [],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "This paper explores the strategic nature of public attribution in cyberspace. Previous research has focused narrowly on the difficulty of attribution as a problem; however, I argue this overlooks the strategic agency that uncertainty in attribution provides the target state. Deterrence in the cyber domain is not merely eroded by difficulty in attribution, but also intentionally through a prioritization of escalation management. Further, this article seeks to establish a common lexicon that distinguishes between three communication strategies available to the target state: collusion, disclosure, or public attribution. Electronic copy available at: https://ssrn.com/abstract=4353069 \"We estimate that over a third of the incidents we manage in a year can be attributed directly back to a state-sponsor or state actor of some sort. There have been instances where we have joined with our Five Eyes partners and have publicly called out some of these actors, but obviously not in every case.\" -Andrew Hampton, New Zealand Director-General of Government Communications Security Bureau¹",
    "keywords": [],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1080/01402390.2021.1895117",
        "10.1080/09636412.2017.1306396",
        "10.1080/13523260.2019.1677324"
      ],
      "issn": [
        "ISSN: 2325-5374"
      ],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "https://ssrn.com/abstract=4353069",
        "https://obamawhitehouse.archives.gov/the-press-office/2014/12/18/press-briefing-press-secretary-josh-earnest-121814",
        "https://doi.org/10.1080/01402390.2021.1895117",
        "https://doi.org/10.1080/09636412.2017.1306396",
        "https://tnsr.org/2020/02/coercion-theory-a-basic-introduction-for-practitioners",
        "https://www.lawfareblog.com/solarwinds-cyberattack-act-war-it-if-united-states-says-it"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 59,
    "heading_count": 27,
    "max_heading_level": 3,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 38,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.3157894736842105,
      "footnote_coverage": 1.0,
      "unique_index_count": 19
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 17
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 96,
        "superscript_definition_lines": 19,
        "numeric_bracket_hits": 5,
        "numeric_endnote_lines": 17,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 19.0,
      "dominant_bib_coverage_rate": 1.0,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 27,
      "max_heading_level": 3,
      "level_jump_violations": 0,
      "numbering_parent_violations": 10,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": false,
        "emails": false,
        "orcids": false,
        "abstract": true,
        "keywords": false,
        "venue": false,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 1,
        "affiliations": 0,
        "emails": 0,
        "orcids": 0,
        "keywords": 0,
        "doi": 3,
        "issn": 1,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 6
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [],
        "toc_dot_lines": 0
      },
      "flags": []
    },
    "flags": [
      "missing_preceding_text",
      "heading_numbering_parent_violation"
    ]
  },
  "updated_at_utc": "2026-02-14T08:27:12.429774+00:00"
}