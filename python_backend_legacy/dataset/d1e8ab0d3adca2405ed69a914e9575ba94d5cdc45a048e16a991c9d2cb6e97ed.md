{
  "full_text": "Special Section Article\n# The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty\nMarcus Schulzke\nAttribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as \"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including\nMarcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as \"circumstantial\" and \"flimsy.\"³\nThese exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out, \"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense\nPerspectives on Politics\ndoi:10.1017/S153759271800110X\n© American Political Science Association 2018\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press\nof the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n## The Attribution Problem following Cyberattacks\nIt is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also\nhave fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\nCyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.”^{13} Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.”^{14} This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.^{15}\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.”^{16} It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it.^{17} The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating.^{18} Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.”^{19} This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.”^{20} Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?”^{21} Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.\n## The Politics of Attribution\nThe attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.”^{22} Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.”^{23} Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations.^{24} With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.\nThis existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27\nHow members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms . . . or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event\nand when the damage of misattribution may have already been done.\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.\n## Opportunities for Elite Framing\nThe first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial.^{35} In most cases, alternative frames tend to come from disagreement among elites or independent blameframes.^{36} However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.\nWhen information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed.^{37} With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events.^{38} The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information.^{39} Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe.^{40} When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators.^{41} When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information.^{42} The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom.^{43} The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months.^{44} These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them\ncontrol over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.\n## Blame Feedback Loops\nThe well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\nKinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to\nbecome the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault.^{53} The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.”^{54} Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq.^{55} It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement.^{56} Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet.^{57} Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.^{58}\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.^{59}\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea.^{60} Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an\nexisting enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.\n## Cultivating Conspiracies\nWhen cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.\nThe long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.\nPredispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.”^{67} Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.”^{68} Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.”^{69} And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed.^{70} Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence.^{71} With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories,^{72} and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.”^{73} With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.”^{74} In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries.^{75} Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.”^{76} One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction.^{77} Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.^{78}\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack.^{79} Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats.^{80} From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks.^{81} The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine.^{82} However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial\nthinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.\n## The Threat to Democratic Accountability\nThus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84\nDrawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92\nUnfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is\nSpecial Section Article | The Politics of Attributing Blame for Cyberattacks\nworthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.\n## Conclusion\nThe literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.\nThe attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that\n“an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem.",
  "flat_text": "Special Section Article # The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty Marcus Schulzke Attribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as\"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including Marcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as\"circumstantial\"and\"flimsy.\"³ These exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out,\"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense Perspectives on Politics doi:10.1017/S153759271800110X © American Political Science Association 2018 https://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press of the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n## The Attribution Problem following Cyberattacks It is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also have fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\nCyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.” Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.” This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.” It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it. The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating. Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.” This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.” Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?” Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.\n## The Politics of Attribution The attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.” Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.” Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations. With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.\nThis existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27 How members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms... or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event and when the damage of misattribution may have already been done.\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.\n## Opportunities for Elite Framing The first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial. In most cases, alternative frames tend to come from disagreement among elites or independent blameframes. However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.\nWhen information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed. With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events. The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information. Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe. When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators. When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information. The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom. The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months. These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them control over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.\n## Blame Feedback Loops The well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\nKinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to become the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault. The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.” Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq. It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement. Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet. Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea. Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an existing enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.\n## Cultivating Conspiracies When cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.\nThe long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.\nPredispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.” Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.” Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.” And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed. Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence. With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories, and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.” With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.” In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries. Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.” One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction. Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack. Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats. From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks. The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine. However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial thinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.\n## The Threat to Democratic Accountability Thus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84 Drawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92 Unfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is Special Section Article | The Politics of Attributing Blame for Cyberattacks worthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.\n## Conclusion The literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.\nThe attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that “an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem.",
  "toc": [
    [
      1,
      "__preamble__"
    ],
    [
      1,
      "## The Attribution Problem following Cyberattacks It is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also have fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it."
    ],
    [
      1,
      "## The Politics of Attribution The attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.” Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.” Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations. With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected."
    ],
    [
      1,
      "## Opportunities for Elite Framing The first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial. In most cases, alternative frames tend to come from disagreement among elites or independent blameframes. However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints."
    ],
    [
      1,
      "## Blame Feedback Loops The well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception."
    ],
    [
      1,
      "## Cultivating Conspiracies When cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive."
    ],
    [
      1,
      "## The Threat to Democratic Accountability Thus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84 Drawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation."
    ],
    [
      1,
      "## Conclusion The literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process."
    ]
  ],
  "sections": {
    "__preamble__": "Special Section Article # The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty Marcus Schulzke Attribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as\"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including Marcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as\"circumstantial\"and\"flimsy.\"³ These exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out,\"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense Perspectives on Politics doi:10.1017/S153759271800110X © American Political Science Association 2018 https://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press of the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.",
    "## The Attribution Problem following Cyberattacks It is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also have fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.": "Cyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.” Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.” This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.” It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it. The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating. Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.” This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.” Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?” Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.",
    "## The Politics of Attribution The attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.” Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.” Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations. With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.": "This existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27 How members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms... or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event and when the damage of misattribution may have already been done.\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.",
    "## Opportunities for Elite Framing The first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial. In most cases, alternative frames tend to come from disagreement among elites or independent blameframes. However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.": "When information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed. With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events. The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information. Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe. When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators. When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information. The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom. The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months. These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them control over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.",
    "## Blame Feedback Loops The well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.": "Kinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to become the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault. The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.” Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq. It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement. Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet. Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea. Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an existing enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.",
    "## Cultivating Conspiracies When cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.": "The long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.\nPredispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.” Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.” Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.” And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed. Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence. With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories, and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.” With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.” In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries. Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.” One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction. Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack. Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats. From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks. The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine. However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial thinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.",
    "## The Threat to Democratic Accountability Thus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84 Drawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.": "Politicians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92 Unfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is Special Section Article | The Politics of Attributing Blame for Cyberattacks worthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.",
    "## Conclusion The literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.": "The attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that “an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem."
  },
  "process_log": {
    "scheme": "markdown",
    "numeric_check": {
      "first_num": null,
      "raw_count": 0,
      "raw_examples": [],
      "filtered_count": 0,
      "filtered_examples": [],
      "seq_score": 0.0
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0
    },
    "toc_count": 7,
    "section_count": 8
  },
  "word_count": 9594,
  "references": [
    "## Notes\n1. Sanger 2013.\n2. Strohm, Dorning, and Riley 2016.\n3. Associated Press 2014; Zetter 2014.\n4. Rid 2013, 142.\n5. Maestas et al. 2008, 609–610.\n6. Stone 1989, 299.\n7. Forsyth 1980.\n8. Carlin 2014.\n9. Peffley 1984; Rudolph 2003; Gomez and Wilson 2003; Arceneaux 2003; Brown 2012.\n10. Atkeson and Maestas 2012.\n11. Economist 2011; Starr 2016.\n12. Uscinski and Parent 2014. [AU: Not in your References.]\n13. Eun and Aßmann 2014, 13.\n14. Brenner 2011, 32.\n15. Zetter 2011.\n16. Sheldon 2014, 289–9.\nPerspectives on Politics\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press\n17 Zetter 2011.\n18 Brenner 2014, 82.\n19 Rid and Buchanan 2015, 5.\n20 Ibid.\n21 Farwell and Rohozinski 2011, 27.\n22 Eun and Aßmann 2014, 13.\n23 Rid 2013, 139.\n24 Lindsay 2015.\n25 Iyengar 1989, 879.\n26 Atkesan and Maestas 2012, 9.\n27 Gomez and Wilson 2003.\n28 Kühne, Weber, and Sommer 2015, 264.\n29 Marcus, Russell, and MacKuen 2003.\n30 Walker 2006.\n31 Ibid., 32.\n32 Henley and Traynor 2015.\n33 Berinsky 2009; Holsti 2011.\n34 Maestas and Atkinson 2012.\n35 Stone 1989, 299.\n36 Baum and Groeling 2010.\n37 Bennett, Lawrence, and Livingston 2007.\n38 Ibid. 2007; Graber 2005.\n39 Entman 2004.\n40 Druckman 2004, 675.\n41 Kaufmann 2004; Berinsky 2009.\n42 Haider-Markel and Joslyn 2001.\n43 Wong 2017.\n44 Newman 2017.\n45 Zetter 2011.\n46 Poulsen 2008.\n47 Ibid.\n48 Kershner 2013.\n49 Zetter 2011.\n50 Green 2015; Kaplan 2016.\n51 Sheldon 2014.\n52 Brader 2006, Atkeson and Maestas 2012; Marcus, Neuman, and MacKuen 2003.\n53 Traynor 2007.\n54 Arkin 1999.\n55 Zetter 2011, 209.\n56 Poulsen 2009.\n57 Zetter 2011, 54\n58 Fox-Brewster 2015.\n59 Corera 2016.\n60 Bartholomew and Guerrero-Saade 2016.\n61 Eun and Aßmann 2014, 13.\n62 Zetter 2011.\n63 Peffley 1984; Rudolph 2003; Gomez and Wilson 2003; Arceneaux 2003; Brown 2010.\n64 Nyhan, Reifler, and Ubel 2013.\n65 Oliver and Wood 2014, 953.\n66 Oliver and Wood 2014; Uscinski and Parent 2014.\n67 Zaller 1992, 6.\n68 Garrett 2011, 256.\n69 Miller, Saunders, and Farhart 2015, 2.\n70 Konkes and Lester 2017.\n71 Swami et al. 2014.\n72 Oliver and Wood 2014.\n73 Swami and Furnham 2014, 220.\n74 Uscinski, Klofstad, and Atkinson 2016, 58.\n75 Zetter 2011.\n76 Libicki 2009, 45.\n77 Russell 2004.\n78 Rid 2013, 5–7.\n79 Serjoie 2016.\n80 Zetter 2011.\n81 Rid 2013.\n82 Zetter 2016.\n83 Malhotra and Kuo 2008, 121.\n84 Iyengar 1998, 1990; Peffley 1984; Rudolph 2003.\n85 Hood 2010.\n86 Rudolph 2003; Peffley 1984; Brown 2010; Gomez and Wilson 2003; Nawara 2015.\n87 Carlin, Love, and Martínez-Gallardo 2014, 443.\n88 Rudolph 2003; Brown 2010; Bartels 2002; Stone 1989; Haider-Markel and Joslyn 2001; Arceneaux 2003; Carlin, Love, and Martínez-Gallardo 2014; Nawara 2015.\n89 Lichtblau and Myers 2016.\n90 YouGov 2016.\n91 Dyer 2016.\n92 Lui 2016.\n93 Gartzke and Lindsay 2015, 328.\n94 Ibid.\n95 Mazzetti 2013; Niva 2013.\n96 Rudolph 2003, 701.\n## References\nAssociated Press. 2014. \"Evidence in Sony Hack Is Largely Circumstantial, Sources Say. Denver Post, December 18. Available at http://www.denverpost.com/2014/2012/2018/evidence-in-sony-hack-is-largely-circumstantial-sources-say/.\nArceneaux, Kevin. 2003. \"The Conditional Impact of Blame Attribution on the Relationship Between Economic Adversity and Turnout.\" Political Research Quarterly 56(1): 67–75.\nArkin, William M. 1999. \"Sunrise, Sunset.\" Washington Post, March 29. Available at https://www.washingtonpost.com/wp-srv/national/dotmil/arkin032999.htm.\nAtkeson, Lonna Rae and Cherie D. Maestas. 2012. Catastrophic Politics: How Extraordinary Events Redefine Perceptions of Government. Cambridge: Cambridge University Press.\nBartels, Larry M. 2002. \"Beyond the Running Tally: Partisan Bias in Political Perceptions.\" Political Behavior 24(2): 117–50.\nBartholomew, Brian and Juan Andres Guerrero-Saade. 2016. \"Wave Your False Flags!\". Presented at the Virus Bulletin Conference, Denver, CO, October 5–7.\nDecember 2018 | Vol. 16/No. 4 965\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press\nSpecial Section Article | The Politics of Attributing Blame for Cyberattacks\nBaum, Matthew A. and Tim Groeling. 2010. \"Reality Asserts Itself: Public Opinion on Iraq and the Elasticity of Reality.\" International Organization 64: 443–79.\nBennett, W. Lance, Regina G. Lawrence and Steven Livingston. 2007. When the Press Fails: Political Power and the News Media from Iraq to Katrina. Chicago: University of Chicago Press.\nBerinsky, Adam J. 2009. In Time of War: Understanding American Public Opinion from World War II to Iraq. Chicago: University of Chicago Press.\nBrader, Ted. 2006. Campaigning for Hearts and Minds: How Emotional Appeals in Political Ads Work. Chicago: University of Chicago Press.\nBrenner, Joel. 2011. America the Vulnerable: Inside the New Threat Matrix of Digital Espionage, Crime, and Warfare. New York: Penguin\nBrenner, Susan. 2014. Cyberthreats and the Decline of the Nation-State. London: Routledge.\nBrown, Adam R. 2010. \"Are Governors Responsible for the State Economy? Partisanship, Blame, and Divided Federalism.\" Journal of Politics 72(3): 605–15.\nCarlin, Ryan E. Gregory J. Love, and Cecilia Martínez-Gallardo. 2014. \"Security, Clarity of Responsibility, and Presidential Approval.\" Comparative Political Studies 48(4): 438–63.\nCorera, Gordon. 2016. \"How France's TV5 Was Almost Destroyed by 'Russian Hackers'.\" BBC News, October 10. Available at http://www.bbc.co.uk/news/technology-37590375.\nDruckman, James N. 2004. \"Political Preference Formation: Competition, Deliberation, And The (Ir) Relevance Of Framing effects.\" American Political Science Review 98(4): 671–86.\nDyer, Geoff. 2016. \"Hackers Attack Arizona and Illinois Election Computer Systems\" Financial Times, August 29. Available at https://www.ft.com/content/1ea03bf4-6e2e-11e6-9ac1-1055824ca907.\nEconomist. 2011. \"Who Is to Blame?\" December 24. Available at http://www.economist.com/blogs/newsbook/2011/2012/attacks-syria.\nEntman, Robert M. 2004. Projections of Power: Framing News, Public Opinion, and U.S. Foreign Policy. Chicago: University of Chicago Press.\nEun, Yong-Soo and Judith Sita Aßmann. 2016. \"Cyberwar: Taking Stock of Security and Warfare in the Digital Age.\" International Studies Perspectives 17(3): 343–60.\nFarwell, James P. and Rafal Rohozinski. 2011. \"Stuxnet and the Future of Cyber War.\" Survival: Global Politics and Strategy 53(1): 23–40.\nForsyth, Donelson R. 1980. \"The Functions of Attributions.\" Social Psychology Quarterly 43(2): 184–98.\nFox-Brewster, Thomas. 2015. \"Gaza Resident Linked to Cyber Attacks on Israel: Security Company Has Put My Life in Danger.\" Forbes, February 24.\nAvailable at https://www.forbes.com/sites/thomasbrewster/2015/02/24/trend-micro-worrying-attribution-of-gaza-strip-businessman/#1dd668392e9e.\nGarrett, R. Kelly. 2011. \"Troubling Consequences of Online Political Rumoring.\" Human Communication Research 37: 255–74.\nGartzke, Erik and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" Security Studies 24(2): 316–48.\nGomez, Brad T. and J. Matthew Wilson. 2003. \"Causal Attribution and Economic Voting in American Congressional Elections.\" Political Research Quarterly 56(3): 271–82.\nGraber, Doris A. 2005. Mass Media and American Politics. Washington, DC: CQ Press.\nGreen, James A., ed. 2015. Cyber Warfare: A Multidisciplinary Analysis. New York: Routledge.\nHaider-Markel, Donald P. and Mark R. Joslyn. 2001. \"Gun Policy, Opinion, Tragedy, and Blame Attribution: The Conditional Influence of Issue-Frames.\" Journal of Politics 63(2): 520–43.\nHenley, Jon and Ian Traynor. 2015. \"Fight against Isis Heats Up as UN Backs Action after Paris Attacks.\" The Guardian, November 22. Available at https://www.theguardian.com/world/2015/nov/21/fight-against-isis-heats-up-as-un-backs-action-after-paris-attacks.\nHolsti, Ole Rudolf. 2011. American Public Opinion on the Iraq War. Ann Arbor: University of Michigan Press.\nHood, Christopher. 2010. The Blame Game: Spin, Bureaucracy, and Self-Preservation in Government. Princeton, NJ: Princeton University Press.\nIyengar, Shanto. 1989. \"How Citizens Think about National Issues: A Matter of Responsibility.\" American Journal of Political Science 33(4): 878–900.\n——. 1990. \"Framing Responsibility for Political Issues: The Case of Poverty.\" Political Behavior 12(1): 19–40.\nKaplan, Fred. 2016. Dark Territory: The Secret History of Cyber War. New York: Simon &amp; Schuster.\nKaufmann, Chaim. 2004. \"Threat Inflation and the Failure of the Marketplace of Ideas: The Selling of the Iraq War.\" International Security 29(1): 5–48.\nKershner, Isabel. 2013. \"Israel Says It Repelled Most Attacks on Its Web Sites by Pro-Palestinian Hackers.\" New York Times, April 7. Available at http://www.nytimes.com/2013/04/08/world/middleeast/pro-palestinian-hackers-attack-israeli-sites.html?_r=0.\nKonkes, Claire and Libby Lester. 2017. \"Incomplete Knowledge, Rumour and Truth Seeking.\" Journalism Studies 18(7): 826–44.\nKühne, Rinaldo, Patrick Weber, and Katharina Sommer. 2015. \"Beyond Cognitive Framing Processes: Anger Mediates the Effects of Responsibility Framing on the Preference for Punitive Measures.\" Journal of Communication 65: 259–79.\nPerspectives on Politics\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press\nLibickim Martin, C. 2009 Cyberdeterrence and Cyberwar. Santa Monica, CA: RAND Corporation.\nLichtblau, Eric and Steven Lee Myers. 2016. \"Investigating Donald Trump, F.B.I. Sees No Clear Link to Russia.\" New York Times, October 31. Available at http://www.nytimes.com/2016/11/01/us/politics/fbi-russia-election-donald-trump.html?_r=0.\nLindsay, Jon R. 2015. \"Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence against Cyberattack.\" Journal of Cybersecurity 1(1): 53-67.\nLui, Kevin. 2016. \"Russian Hackers Could Fake Evidence of Electoral Fraud, Warn U.S. Officials.\" Time, October 20. Available at http://time.com/4539904/fake-voter-fraud-russia-us-election-hack-warning/.\nMaestas, Cherie D., Lonna Rae Atkeson, Thomas Croom, and Lisa A. Bryant. 2008. \"Shifting the Blame: Federalism, Media, and Public Assignment of Blame Following Hurricane Katrina.\" *Publius: The Journal of Federalism* 38(4): 609-32.\nMalhotra, Neil and Alexander G. Kuo. 2008. \"Attributing Blame: The Public's Response to Hurricane Katrina.\" Journal of Politics 70(1): 120-35.\nMarcus, George E., W. Russell Neuman, and Michael MacKuen. 2003. Affective Intelligence and Political Judgment. Chicago University of Chicago Press.\nMazzetti, Mark. 2013. Way of The Knife: The CIA, A Secret Army, and a War at the Ends of the Earth. New York: Penguin.\nMiller, Joanne M., Kyle L. Saunders, and Christina E. Farhart. 2015. \"Conspiracy Endorsement as Motivated Reasoning: The Moderating Roles of Political Knowledge and Trust.\" American Journal of Political Science 60(4): 824-44.\nNawara, P. Steven. 2015. \"Who Is Responsible, the Incumbent or the Former President? Motivated Reasoning in Responsibility Attributions.\" *Presidential Studies Quarterly* 45(1): 110-31.\nNewman, Lily Hay. 2017. \"The Equifax Breach Exposes America's Identity Crisis.\" Wired, September 8. Available at https://www.wired.com/story/the-equifax-breach-exposes-americas-identity-crisis/.\nNiva, Steve. 2013. \"Disappearing Violence: JSOC and the Pentagon's New Cartography of Networked Warfare.\" Security Dialogue 44(3): 185-202.\nNyhan, Brendan, Jason Reifler, and Peter A. Ubel. 2013. \"The Hazards of Correcting Myths about Health Care Reform.\" Medical Care 51(2): 127-32.\nOliver, J. Eric and Thomas J. Wood. 2014. \"Conspiracy Theories and the Paranoid Style(s) of Mass Opinion.\" American Journal of Political Science 58(4): 952-66.\nPeffley, Mark 1984. \"The Voter as Juror: Attributing Responsibility for Economic Conditions.\" Political Behavior 6(3): 275-94.\nPoulsen, Kevin. 2008. \"Did Hackers Cause the 2003 Northeast Blackout? Umm, No.\" Wired, May 29.\nAvailable at https://www.wired.com/2008/05/did-hackers-cau/.\n_____. 2009. \"Report: Cyber Attacks Caused Power Outages in Brazil.\" Wired, November 7. Available at https://www.wired.com/2009/11/brazil/.\nRid, Thomas. 2013. Cyber War Will Not Take Place. New York: Oxford University Press.\nRid, Thomas and Ben Buchanan. 2015. \"Attributing Cyber Attacks.\" Journal of Strategic Studies 38(1-2): 4-37.\nRudolph, Thomas J. 2003. \"Who's Responsible for the Economy? The Formation and Consequences of Responsibility Attributions.\" American Journal of Political Science 47(4): 698-713.\nRussell, Alec. 2004. \"CIA Plot Led to a HUGE BLAST in Siberian Gas Pipeline. The Telegraph, February 28. Available at http://www.telegraph.co.uk/news/worldnews/northamerica/usa/1455559/CIA-plot-led-to-huge-blast-in-Siberian-gas-pipeline.html.\nSanger, David. 2013. \"U.S. Blames China's Military Directly for Cyberattacks.\" New York Times, May 6. Available at http://www.nytimes.com/2013/2005/2007/world/asia/us-accuses-chinas-military-in-cyberattacks.html?_r=2010.\nSerjoie, Kay Armin. 2016. \"Iran Investigates If Series of Oil Industry Accidents Were Caused by Cyber Attack.\" Time, August 12. Available at http://time.com/4450433/iran-investigates-if-series-of-oil-industry-accidents-were-caused-by-cyber-attack/.\nSheldon, John. 2014. \"Geopolitics and Cyber Power: Why Geography Still Matters.\" American Foreign Policy Interests 36(5): 286-93.\nStarr, Barbara 2016. \"US blames Russia for Syria Convoy Attack; Moscow Points to Terrorists.\" CNN, September 21. Available at http://edition.cnn.com/2016/2009/2020/politics/syria-convoy-strike-us-conclusion-russia/.\nStone, Deborah. 1989. \"Causal Stories and the Formation of Policy Agendas.\" Political Science Quarterly 104(2): 281-300.\nStrohm, Chris, Mike Dorning, and Michael Riley. 2016. \"FBI Investigating DNC Hack Some Democrats Blame on Russia.\" Bloomberg, July 25. Available at http://www.bloomberg.com/politics/articles/2016-2007-2025/fbi-investigating-dnc-cyber-hack-some-democrats-blame-on-russia.\nSwami, Viren, Martin Voracek, Stefan Stieger, Ulrich S. Tran, and Adrian Furnham. 2014. \"Analytic Thinking Reduces Belief in Conspiracy Theories.\" Cognition 133(3): 572-85.\nSwami, Viren and A. Furnham. 2014. \"Political Paranoia and Conspiracy Theories.\" In Power Politics, and Paranoia: Why People Are Suspicious of Their Leaders, ed. J. P. Prooijen and P. A. M. van Lange. Cambridge: Cambridge University Press.\nDecember 2018 | Vol. 16/No. 4\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press\nSpecial Section Article | The Politics of Attributing Blame for Cyberattacks\nTraynor, Ian. 2007. \"Russia Accused of Unleashing Cyberwar to Disable Estonia.\" *The Guardian*. Available at https://www.theguardian.com/world/2007/may/2017/topstories2003.russia.\nUscinski, Joseph E., Casey Klofstad, and Matthew D. Atkinson. 2016. \"What Drives Conspiratorial Beliefs? The Role of Informational Cues and Predispositions.\" *Political Research Quarterly* 69(1): 57–71.\nUscinski, Joseph E. and Joseph M. Parent. 2014. *American Conspiracy Theories*. Oxford: Oxford University Press.\nWalker, Margaret Urban. 2006. *Moral Repair: Reconstructing Moral Relations after Wrongdoing*. Cambridge: Cambridge University Press.\nWong, Julia Carrie. 2017. \"Uber Concealed Massive Hack that Exposed Data of 57m Users and Drivers.\" *The Guardian*, November 22. Available at https://www.theguardian.com/technology/2017/nov/21/uber-data-hack-cyber-attack.\nYouGov. 2016. \"Belief in Conspiracies Largely Depends on Political Identity.\" Available at https://today.yougov.com/news/2016/12/27/belief-conspiracies-largely-depends-political-iden/\nZaller, John. 1992. *The Nature and Origins of Mass Opinion*. Cambridge: Cambridge University Press.\nZetter, Kim. 2011. *Countdown to Zero Day: Stuxnet and the Launch of the World's First Digital Weapon*. New York: Crown.\n——. 2014. \"The Evidence that North Korea Hacked Sony Is Flimsy.\" *Wired*, December 17. Available at https://www.wired.com/2014/2012/evidence-of-north-korea-hack-is-thin/.\n——. 2016. \"Inside the Cunning, Unprecedented Hack of Ukraine's Power Grid.\" *Wired*, March 3. Available at https://www.wired.com/2016/03/inside-cunning-unprecedented-hack-ukraines-power-grid/.\nPerspectives on Politics\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press"
  ],
  "citations": {
    "style": "author_year",
    "flat_text": "Special Section Article # The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty Marcus Schulzke Attribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as\"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including Marcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as\"circumstantial\"and\"flimsy.\"³ These exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out,\"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense Perspectives on Politics doi:10.1017/S153759271800110X © American Political Science Association 2018 https://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press of the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n## The Attribution Problem following Cyberattacks It is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also have fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\nCyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.” Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.” This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.” It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it. The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating. Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.” This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.” Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?” Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.\n## The Politics of Attribution The attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.” Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.” Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations. With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.\nThis existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27 How members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms... or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event and when the damage of misattribution may have already been done.\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.\n## Opportunities for Elite Framing The first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial. In most cases, alternative frames tend to come from disagreement among elites or independent blameframes. However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.\nWhen information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed. With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events. The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information. Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe. When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators. When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information. The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom. The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months. These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them control over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.\n## Blame Feedback Loops The well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\nKinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to become the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault. The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.” Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq. It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement. Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet. Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea. Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an existing enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.\n## Cultivating Conspiracies When cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.\nThe long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.\nPredispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.” Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.” Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.” And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed. Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence. With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories, and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.” With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.” In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries. Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.” One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction. Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack. Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats. From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks. The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine. However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial thinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.\n## The Threat to Democratic Accountability Thus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84 Drawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92 Unfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is Special Section Article | The Politics of Attributing Blame for Cyberattacks worthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.\n## Conclusion The literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.\nThe attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that “an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem.",
    "footnotes": {
      "items": {},
      "intext": [
        {
          "index": "43",
          "intext_citation": "^{43}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "44",
          "intext_citation": "^{44}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "53",
          "intext_citation": "^{53}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "54",
          "intext_citation": "^{54}",
          "preceding_text": "”",
          "footnote": null
        },
        {
          "index": "55",
          "intext_citation": "^{55}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "56",
          "intext_citation": "^{56}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "57",
          "intext_citation": "^{57}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "58",
          "intext_citation": "^{58}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "59",
          "intext_citation": "^{59}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "60",
          "intext_citation": "^{60}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "67",
          "intext_citation": "^{67}",
          "preceding_text": "”",
          "footnote": null
        },
        {
          "index": "68",
          "intext_citation": "^{68}",
          "preceding_text": "”",
          "footnote": null
        },
        {
          "index": "69",
          "intext_citation": "^{69}",
          "preceding_text": "”",
          "footnote": null
        },
        {
          "index": "70",
          "intext_citation": "^{70}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "71",
          "intext_citation": "^{71}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "72",
          "intext_citation": "^{72}",
          "preceding_text": "One of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories,",
          "footnote": null
        },
        {
          "index": "73",
          "intext_citation": "^{73}",
          "preceding_text": "”",
          "footnote": null
        },
        {
          "index": "74",
          "intext_citation": "^{74}",
          "preceding_text": "”",
          "footnote": null
        },
        {
          "index": "75",
          "intext_citation": "^{75}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "76",
          "intext_citation": "^{76}",
          "preceding_text": "”",
          "footnote": null
        },
        {
          "index": "77",
          "intext_citation": "^{77}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "78",
          "intext_citation": "^{78}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "79",
          "intext_citation": "^{79}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "80",
          "intext_citation": "^{80}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "81",
          "intext_citation": "^{81}",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "82",
          "intext_citation": "^{82}",
          "preceding_text": "",
          "footnote": null
        }
      ],
      "stats": {
        "intext_total": 26,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 56,
        "missing_intext_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          61,
          62,
          63,
          64,
          65,
          66
        ],
        "highest_intext_index": 82,
        "missing_footnotes_for_seen_total": 26,
        "missing_footnotes_for_seen_intext": [
          43,
          44,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82
        ],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Special Section Article\n# The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty\nMarcus Schulzke\nAttribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as \"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including\nMarcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as \"circumstantial\" and \"flimsy.\"³\nThese exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out, \"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense\nPerspectives on Politics\ndoi:10.1017/S153759271800110X\n© American Political Science Association 2018\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press\nof the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n## The Attribution Problem following Cyberattacks\nIt is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also\nhave fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\nCyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.”^{13} Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.”^{14} This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.^{15}\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.”^{16} It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it.^{17} The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating.^{18} Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.”^{19} This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.”^{20} Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?”^{21} Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.\n## The Politics of Attribution\nThe attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.”^{22} Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.”^{23} Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations.^{24} With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.\nThis existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27\nHow members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms . . . or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event\nand when the damage of misattribution may have already been done.\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.\n## Opportunities for Elite Framing\nThe first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial.^{35} In most cases, alternative frames tend to come from disagreement among elites or independent blameframes.^{36} However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.\nWhen information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed.^{37} With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events.^{38} The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information.^{39} Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe.^{40} When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators.^{41} When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information.^{42} The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom.^{43} The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months.^{44} These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them\ncontrol over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.\n## Blame Feedback Loops\nThe well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\nKinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to\nbecome the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault.^{53} The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.”^{54} Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq.^{55} It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement.^{56} Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet.^{57} Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.^{58}\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.^{59}\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea.^{60} Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an\nexisting enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.\n## Cultivating Conspiracies\nWhen cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.\nThe long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.\nPredispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.”^{67} Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.”^{68} Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.”^{69} And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed.^{70} Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence.^{71} With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories,^{72} and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.”^{73} With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.”^{74} In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries.^{75} Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.”^{76} One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction.^{77} Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.^{78}\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack.^{79} Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats.^{80} From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks.^{81} The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine.^{82} However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial\nthinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.\n## The Threat to Democratic Accountability\nThus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84\nDrawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92\nUnfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is\nSpecial Section Article | The Politics of Attributing Blame for Cyberattacks\nworthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.\n## Conclusion\nThe literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.\nThe attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that\n“an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem."
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Special Section Article\n# The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty\nMarcus Schulzke\nAttribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as \"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including\nMarcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as \"circumstantial\" and \"flimsy.\"³\nThese exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out, \"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense\nPerspectives on Politics\ndoi:10.1017/S153759271800110X\n© American Political Science Association 2018\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press\nof the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n## The Attribution Problem following Cyberattacks\nIt is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also\nhave fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\nCyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.”^{13} Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.”^{14} This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.^{15}\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.”^{16} It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it.^{17} The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating.^{18} Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.”^{19} This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.”^{20} Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?”^{21} Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.\n## The Politics of Attribution\nThe attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.”^{22} Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.”^{23} Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations.^{24} With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.\nThis existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27\nHow members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms . . . or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event\nand when the damage of misattribution may have already been done.\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.\n## Opportunities for Elite Framing\nThe first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial.^{35} In most cases, alternative frames tend to come from disagreement among elites or independent blameframes.^{36} However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.\nWhen information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed.^{37} With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events.^{38} The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information.^{39} Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe.^{40} When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators.^{41} When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information.^{42} The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom.^{43} The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months.^{44} These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them\ncontrol over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.\n## Blame Feedback Loops\nThe well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\nKinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to\nbecome the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault.^{53} The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.”^{54} Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq.^{55} It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement.^{56} Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet.^{57} Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.^{58}\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.^{59}\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea.^{60} Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an\nexisting enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.\n## Cultivating Conspiracies\nWhen cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.\nThe long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.\nPredispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.”^{67} Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.”^{68} Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.”^{69} And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed.^{70} Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence.^{71} With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories,^{72} and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.”^{73} With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.”^{74} In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries.^{75} Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.”^{76} One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction.^{77} Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.^{78}\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack.^{79} Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats.^{80} From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks.^{81} The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine.^{82} However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial\nthinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.\n## The Threat to Democratic Accountability\nThus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84\nDrawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92\nUnfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is\nSpecial Section Article | The Politics of Attributing Blame for Cyberattacks\nworthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.\n## Conclusion\nThe literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.\nThe attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that\n“an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem."
    },
    "author_year": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 119,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [],
      "flat_text": "Special Section Article # The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty Marcus Schulzke Attribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as\"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including Marcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as\"circumstantial\"and\"flimsy.\"³ These exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out,\"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense Perspectives on Politics doi:10.1017/S153759271800110X © American Political Science Association 2018 https://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press of the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n## The Attribution Problem following Cyberattacks It is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also have fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\nCyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.” Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.” This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.” It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it. The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating. Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.” This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.” Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?” Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.\n## The Politics of Attribution The attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.” Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.” Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations. With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.\nThis existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27 How members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms... or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event and when the damage of misattribution may have already been done.\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.\n## Opportunities for Elite Framing The first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial. In most cases, alternative frames tend to come from disagreement among elites or independent blameframes. However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.\nWhen information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed. With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events. The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information. Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe. When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators. When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information. The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom. The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months. These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them control over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.\n## Blame Feedback Loops The well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\nKinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to become the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault. The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.” Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq. It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement. Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet. Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea. Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an existing enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.\n## Cultivating Conspiracies When cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.\nThe long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.\nPredispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.” Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.” Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.” And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed. Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence. With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories, and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.” With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.” In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries. Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.” One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction. Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack. Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats. From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks. The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine. However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial thinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.\n## The Threat to Democratic Accountability Thus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84 Drawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92 Unfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is Special Section Article | The Politics of Attributing Blame for Cyberattacks worthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.\n## Conclusion The literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.\nThe attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that “an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem."
    }
  },
  "summary": {
    "full_text": {
      "words": 9640,
      "tokens": 11388
    },
    "flat_text": {
      "words": 9594,
      "tokens": 11214
    }
  },
  "payload": "## __preamble__\n\nSpecial Section Article # The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty Marcus Schulzke Attribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as\"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including Marcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as\"circumstantial\"and\"flimsy.\"³ These exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out,\"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense Perspectives on Politics doi:10.1017/S153759271800110X © American Political Science Association 2018 https://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press of the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n\n---\n\n## ## The Threat to Democratic Accountability Thus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84 Drawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\n\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92 Unfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is Special Section Article | The Politics of Attributing Blame for Cyberattacks worthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:SUCCESS\nsections_raw:8\nsections_clean:8\nintro:FOUND\nconclusion:FOUND\npredefined_sections:None\nextra_sections:## Blame Feedback Loops The well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\npayload_tokens_before:6058\npayload_tokens_after:4923\ndropped_section:## The Attribution Problem following Cyberattacks It is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also have fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\nadded_section:None\n---LOG_SUMMARY_END---",
  "pages_text": [
    "Special Section Article\n\n# The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty\n\nMarcus Schulzke\n\nAttribution is one of the most serious challenges associated with cyberattacks. It is often difficult to determine who launched an attack and why, which hinders efforts to formulate appropriate responses. Although the attribution problem has been discussed extensively in research on cybersecurity, it is generally approached as a technical challenge for security professionals and politicians. I contend that it is vital to take the attribution problem beyond this elite focus by considering how attributional challenges can interfere with the public's efforts to understand security challenges and evaluate government actions. Faced with uncertainty and the confusion of attempting to understand novel cyber threats, citizens frequently lack the information they need to reliably identify the culprits behind attacks—or sometimes even to know whether an attack has taken place. I show that attributional uncertainty immediately following cyberattacks encourages dependence on a narrow range of elite frames and the assignment of blame to familiar enemies. Over time this promotes conspiratorial thinking and poses a risk to democratic accountability. When seen in light of these broader costs, the attribution problem becomes a vital political concern with implications that reach beyond the scope of elite-focused cybersecurity research.\n\nAttributional uncertainty plagues cyberattacks. It is difficult to identify attackers, and most incidents leave room for plausible deniability, which puts the public in a difficult position when evaluating claims made by elites. The United States routinely condemns Chinese hacking, while the Chinese government denies what it characterizes as \"groundless accusations and speculations.\"¹ Attacks on the U.S. Democratic National Committee (DNC) were traced to Russian intelligence services, though Russian officials deny having any involvement.² In 2014, North Korean hackers were blamed for breaking into Sony Pictures Entertainment's computers in retaliation for producing the Interview, a film which satirizes an assassination of Kim Jong-Un. North Korea praised the attacks for supporting a good cause, but denied involvement in them and said that they were only a pretext for the United States to tighten its sanctions. Dozens of preeminent cybersecurity experts (including\n\nMarcus Schulzke (MarcusSchulzke@gmail.com) is the author of Pursuing Moral Warfare: Ethical Theory and Practice in Counterinsurgency Operations (forthcoming), Combat Drones and Support for the Use of Force, with James Walsh (forthcoming), Just War Theory and Civilian Casualties (2017), and The Morality of Drone Warfare and the Politics of Regulation (2017).\n\none who had previously hacked Sony) also raised doubts about whether North Korea could have launched the attacks, characterizing the evidence implicating it as \"circumstantial\" and \"flimsy.\"³\n\nThese exchanges pose a recurring challenge: who should we believe? Is China stealing American secrets, or are the intrusions coming from another source? Is the Russian government really attempting to manipulate elections, or are criminals to blame? Did North Korea break into Sony's computers, or was this only a marketing ploy to promote an upcoming film? Following kinetic military and terrorist attacks that inflict direct physical harm, we can usually judge the accuracy of attributions and critique misguided claims about blame with the help of concrete evidence linking attacks to the perpetrators. However, when it comes to cyberattacks, the evidence is often absent, ambiguous, tightly controlled by gatekeepers, or shrouded in doubt and technical jargon. As Rid points out, \"when hard weapons are used, non-attribution is the exception, not the rule—when malicious software is used, non-attribution is the rule, not the exception.\"⁴ In cases when responsibility is eventually established, the investigative process may take months or years, leaving ample time for rumors to take hold and shape perceptions.\n\nThe attribution problem takes a central place in research on cyberattacks, but the existing research focuses on the technical details of attribution or on how this problem affects policymakers. What is missing is a sense\n\nPerspectives on Politics\n\ndoi:10.1017/S153759271800110X\n\n© American Political Science Association 2018\n\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press",
    "of the broader political implications of attributional uncertainty, especially when it comes to how this affects the general public. My goal is to politicize the attribution problem by considering its implications beyond the realm of cybersecurity professionals, law enforcement officials, and policymakers. I do this by evaluating cyberattacks with help from research showing that attributions play a central role in shaping the public's policy preferences when it comes to responding to threats and guarding against them in the future. As Maestas et al. explain, “attributions—beliefs in particular causal stories—are important to study because they form the cornerstone of other key political opinions such as evaluations of leaders and preferences for public policy.”5 Stone likewise observes that “causal argument is at the heart of political problem definition. Problem definition is centrally concerned with attributing bad conditions to human behavior instead of to accident, fate, or nature.”6 Attributions are especially salient if cyberattacks cause a policy shift or an escalation of hostilities.\n\nIn the aftermath of cyberattacks, decreased attributional certainty increases dependence on elite frames, while the control of information by a small number of gatekeepers limits the evidence available to form counterframes. This raises the prospect of elites opportunistically making attributional claims to justify their policy choices, and journalists either accepting official narratives because of the lack of alternative information or contributing to the uncertainty with poorly-informed speculation. In an effort to restore certainty, commentators often blame the most obvious enemies. This can create blame feedback loops in which unattributed attacks fuel ongoing hostilities and create a body of evidence that will be used to tenuously link subsequent incidents to the same offender. For example, the Solar Sunrise virus that was used against U.S. government systems in 1998 was initially linked to Iraq because of circumstantial evidence and ongoing hostilities, though it turned out that a few teenagers were to blame. Elite framing and misplaced blame are well documented processes, and not unique to cyberattacks. However, cyberattacks are special insofar as they generally offer less empirical information than physical attacks and require lengthy investigations that provide ample opportunity for blame claims to be made before conclusive evidence is available.\n\nReduced certainty about the actors responsible for cyberattacks poses two long-term dangers, which may persist regardless of whether investigations are ultimately successful. First, initial blame frames are difficult to update with new information. The shock of an event like an attack creates an opportunity for new opinions to take root,7 but this opportunity is short-lived. Attempts to change perceptions with information that is uncovered during investigations must contend with existing opinions. Information shortages, shifting blame, and dependence on elite gatekeepers invite conspiratorial thinking. Furthermore, cyberattacks incorporate some of the defining characteristics of conspiracy theories, which means that believing an attributional explanation encourages some receptiveness towards conspiratorial thinking. Second, attributional uncertainty when identifying the culprit behind cyberattacks undermines democratic accountability by making it more difficult to evaluate leaders' performance and their plans to counter future security challenges. If citizens do not know who to blame for an attack, then they may struggle to correctly determine whether their leaders responded effectively. Partisanship compounds this by encouraging audiences to mold new information to fit biased narratives.\n\nThese consequences of uncertainty have been borne out in research on other responsibility attribution problems relating to security threats,8 economic performance,9 and responses to natural disasters.10 My analysis of cyberattacks draws heavily on the mechanisms identified in work on those subjects to take a first step towards understanding how cyberattacks are apt to affect the general public. Attributional challenges are not new, but I contend that cyberattacks are distinct from traditional, kinetic security threats because of the ubiquity and extent of attributional uncertainty. Disagreements over who to blame for cyberattacks are so persistent that they thwart efforts to formulate the stable and reliable cognitive map of threats that citizens need to make informed choices about security policies. This risk provides grounds for expanding the scope of research and doing more to educate the public about cybersecurity.\n\n## The Attribution Problem following Cyberattacks\n\nIt is usually relatively easy to determine who is at fault for kinetic attacks. Conventional military operations are typically launched by enemies that can be identified and targeted for retaliation. Belligerents sometimes attempt to interfere with attribution, as Germany did in 1939 by dressing its soldiers in Polish military uniforms to stage a fake assault on a radio station at Gleiwitz in the hope of presenting its invasion of Poland as an act of self-defense. However, blame shifting in interstate warfare rarely succeeds. The trail back to the perpetrator and the underlying strategic thinking are usually too obvious to generate serious doubt. More confusion emerges when multiple belligerents are operating in a single area and there is disagreement about responsibility for a specific attack, which has happened several times during the ongoing war in Syria.11 Nevertheless, the pool of potential culprits is limited to those acting in the battlespace and some physical evidence is usually available, so the level of attributional uncertainty is low. Terrorism may leave more room for speculation, as evidenced by conspiracy theories about who was responsible for 9/11,12 yet such attacks also",
    "have fairly clear and widely agreed on official explanations against which the alternative views can be classified as conspiratorial. With each of these types of kinetic violence a relatively accurate account of events can emerge quickly to frame information as the public is initially attempting to make sense of it.\n\nCyberattacks offer much less attributional certainty. First, cyberattacks do not take place within a clear battlespace and rarely arrive from an identifiable source. Network attacks are usually routed through servers that are located in third-party locations—potentially even third-party locations that provide a convenient scapegoat. “The IP address therefore does not present the attacked state with a physical location to blame or even attack in response. The discovered server could be located in a neutral, friendly, or even your own country.”^{13} Brenner says of an attack's point of origin that “almost invariably that server was merely the last of several through which the attackers passed in order to hide.”^{14} This makes discovering attackers far more difficult than simply tracing IP addresses or other digital signatures.\n\nEven when attacks are introduced to an air-gapped system that is closed off from external networks—attacks that require the physical presence of an attacker—the malicious code may be identified long after its introduction, when it may be impossible to discover who planted it. Moreover, the person introducing the infection could be an unwitting participant who is ignorant of the infected hardware. The Stuxnet worm that damaged Iranian nuclear centrifuges in a secret facility at Natanz is a prime example of this. It was probably delivered through a USB drive by someone working inside, but investigators could not discover who was responsible or whether that person knew about the attack.^{15}\n\nSecond, investigating attacks is time consuming and expensive. Sheldon says that “the forensics of attribution can rarely, if ever, give immediate results and can take days if not weeks to provide solid technical evidence.”^{16} It took a team of investigators working across multiple security companies around seven months to reverse engineer the Stuxnet worm and arrive at some sense of who might have developed it.^{17} The effort was nearly abandoned on several occasions, and only prevailed because the novelty of the threat and presence of multiple zero-day exploits (previously unidentified software vulnerabilities) motivated an inordinate investment of resources in the research. Even then investigators only tentatively linked the attack to the United States and Israel until leaked information substantiated this account. Worse still, some cyberattacks are asynchronous, only being detected long after they are launched and when the evidence is deteriorating.^{18} Stuxnet operated for at least two years and inflicted physical destruction before it was uncovered. Investigatory delays interfere with attribution and prolong the sense of uncertainty even if the attacker is ultimately discovered. This leaves more time for speculation about the source of attacks and for opinions to form without evidentiary support.\n\nThird, investigation is a complex process that must be done collectively. “Attribution is almost always too large and too complex for any single person to handle; attribution is likely to require a division of labour.”^{19} This not only makes the process long and expensive but also means that the final outcome must be judged “against competing evidence in front of a decision authority.”^{20} Disagreements between investigators or conflicting evidence that is uncovered may interfere with efforts to convince audiences that the attribution was made correctly. Partisan and nationalistic biases could also shape the causal accounts developed, as well as influencing which narrative is endorsed by interested political actors.\n\nFinally, cyberattacks raise the “many hands” problem of determining specific individuals' contributions. They are complex assemblages of software developed collectively, with elements being borrowed from those who are not actually involved in attacks. Some exploits are developed and then sold online, meaning that the developer and the actual user might have little in common. The end result is still more confusion about who is behind the attacks and what degree of blame they should have if they are identified. Farwell and Rohozinski ask: “is the responsible party a Russian hacker living in New Zealand who may have contributed part of the code used for the rootkit? Or is it an intermediary that may have passed the code onto a state-based military intelligence actor?”^{21} Even in an ideal scenario in which code can be traced to specific developers, there is often residual doubt about who actually launched the attack and which elements of the code were appropriated from unwitting collaborators. The many hands problem and the routing of attacks through false addresses ensure that cyberattacks come with an abundant supply of circumstantial evidence that can help to sustain some degree of plausible deniability.\n\n## The Politics of Attribution\n\nThe attribution problem is a central issue in research on cybersecurity. Eun and Aßmann argue that “determining the real aggressor is impossible unless the aggressor admits to it.”^{22} Rid characterizes the attribution problem as a unifying characteristic of cyberattacks and says that this “feature of digital conflict represents a fundamental, and in many ways disturbing, change when compared to political confrontations in earlier, analogue times.”^{23} Lindsay makes the more modest claim that attribution is difficult, but that important systems have stronger mechanisms for locating the source of attacks and countering the intruders, with more resources also being devoted to investigations.^{24} With this in mind, we should be cognizant that the type of attack and target may influence the extent of uncertainty following an attack and particularly attentive to how attributional problems arise when systems are inadequately protected.",
    "This existing research on attributing cyberattacks is invaluable, yet it is limited by a focus on elite decision-making processes like deterring future attacks, retaliating against aggressors, and building more effective defenses. To develop a stronger grasp of cyberattacks' political consequences, it is essential to go beyond the elite focus to consider how responsibility attributions affect citizens' perceptions of security issues. Elite responses to cybersecurity threats are constrained by public opinion. In exceptional cases the attacks may themselves become central to partisan disagreements, as evidenced by the ongoing debate over who was responsible for the cyberattacks during the 2016 U.S. presidential election.\n\nBefore considering the potential consequences of the attribution problem with reference to cyberattacks specifically, it is useful to reflect on some of the reasons why responsibility attributions are generally important. At the most basic level, responsibility attributions matter because they are vital for making sense of political phenomena. Iyengar explains that “individuals tend to simplify political issues by reducing them to questions of responsibility and their issue opinions flow from their answers to these questions.”25 Similarly, Atkesan and Maestas argue that “causal attributions form an important link in a chain that runs from citizens' receipt of information (for example, from mass media, elites, friends, or personal experiences) to their issue opinions, political evaluations, and, ultimately, political choices.”26 Divergent political values and policy preferences are affected by divergent perceptions of who deserves praise or blame for events, and voters' ability to hold elected officials accountable depends on how they perceive causal processes and identify those responsible.27\n\nHow members of the public assign blame for transgressions affects their moral judgments. Kühne, Weber, and Sommer report that “whether individuals hold an actor responsible or not for a negative event affects their anger response, which, in turn, predicts the evaluation of the actor.”28 They find that responsibility attributions increase anger and support for punitive actions while ambivalent ones tend to dampen these feelings. This has important implications when it comes to security, indicating that blaming an adversary will fuel a sense of indignation and increase the likelihood of retaliation. Emotional responses related to blame are also apt to influence subsequent evaluations of the transgressor, which can cause a rush to judgment in future disagreements.29 This is potentially disastrous in a security context in which escalation can spiral out of control.\n\nBeing able to blame someone for serious transgressions helps to satisfy a sense of indignation on the part of victims. Walker argues that publicly assigning culpability is vital to alleviating this emotional turmoil and repairing the sense of moral wrongness that arises from it.30 As she points out, one way that communities constitute themselves is through a collective enforcement of norms. Above all, this depends on being able to clearly point to those who have transgressed the norms. When punishment is impossible, assigning blame can at least restore a sense of moral certainty and confidence in the norms and the security they are supposed to provide. “To fail to reprove wrongdoers or to fail to hold responsible those to whom responsibility reasonably falls is to cast doubt on the authority of norms . . . or to indicate that wrongdoers are beyond the reach of the community or its norms.”31 When seen from this perspective, there is a risk of persistent cyberattacks undermining state authority and generating a sense that attackers can violate norms with impunity.\n\nAttribution is also vital for building international solidarity and support for major policy changes. The attacks on Charlie Hebdo and the Bataclan Theater in Paris caused international outrage and created an ideal context for French President François Hollande's successful call for the United Nations Security Council to support the strikes against Islamic State.32 This recalled the pro-American sentiment following the 9/11 attacks and the Bush administration's success in using these to promote the invasion of Afghanistan. Victims of aggression benefit from goodwill that they can channel into retaliation or other shifts in security policies, yet blame frames impose limits on how that support may be directed. The U.S. decision to invade Afghanistan received considerable support, while the invasion of Iraq based on tenuous links to terrorism and weak evidence of Weapons of Mass Destruction was markedly less popular.33 When the attributional links are less clear or more contentious, policymakers may struggle more to reach a consensus.\n\nPredictable and routine events can be mapped onto existing perceptions about who to praise or blame, imposing modest cognitive demands on the public. By contrast, unexpected events shake public confidence, triggering efforts to explain the events and restore a sense of security. People are rarely content with ambiguity when information is not forthcoming, especially if there is a perceived threat. Maestas and Atkinson find that there is a psychological need to have explanations for unexpected threatening events.34 Thus, one consequence of shocking events is that people must search for an explanation that can restore some sense of certainty and rehabilitate their shaken political evaluations. Security threats prompt the same search for causal explanations as other unexpected crises, yet when it comes to cyberattacks the attribution problem compromises citizens' abilities to draw reliable conclusions. The lack of a clear source, involvement of multiple actors, and time delays all conspire to hinder the formation of any clear causal account. If time-consuming forensic work is ultimately successful in identifying the culprit, the explanations will arrive long after the event was initially publicized—after people have drawn their own conclusions about the event",
    "and when the damage of misattribution may have already been done.\n\nOver the following sections I consider four consequences of the search to assign blame without the requisite information: increased reliance on information framed by a relatively small number of elites, blame feedback loops, conspiratorial thinking, and a decline of democratic accountability. These mechanisms have been uncovered in research on attribution in other contexts. My goal is to show that the prevalence and depth of uncertainty when it comes to cyberattacks make the public's perceptions an important political consideration.\n\n## Opportunities for Elite Framing\n\nThe first and most immediate effect of the attribution problem is to increase the public's dependence on a narrow range of elite sources of information that can dominate public discourse without having to contend with strong counter-narratives. Lacking not only the facts needed for deciding who to blame but also the technical expertise for understanding the nuances of how an attack was carried out and by whom, the public must draw conclusions from reports that are offered by a small number of policymakers and security professionals involved in the investigation. This gives those actors considerable power over the causal narrative, especially in the immediate aftermath of an attack when there is a rush to explain an event, but investigators have not had time for careful forensic work. This is an ideal context for “strategic portrayal of causal stories” by elites to create perceptions of responsibility that can be expedient for advancing policies that might otherwise be more controversial.^{35} In most cases, alternative frames tend to come from disagreement among elites or independent blameframes.^{36} However, the effects of cyberattacks are largely invisible and the relevant information is not widely accessible, narrowing the number of elites involved and limiting the range of alternative viewpoints.\n\nWhen information is scarce, journalists tend to aggregate it and have few opportunities for fact checking that requires reliable alternative sources. Dependence on elite gatekeepers has been well documented following other shocking events, such as natural disasters, and increases elites' control over how issues are framed.^{37} With air time and columns to fill, journalists respond to attributional uncertainties, first, by resorting to a less critical acceptance of information from politicians and other experts, and second, by engaging in rampant speculation about events.^{38} The former process intensifies the power of elite frames and the likelihood that these will persist without being contradicted, while the latter can lead to blame frames that are poorly supported by the available evidence. Thus, the framing opportunities following cyberattacks derive from the limited number of actors involved, their ability to control information flows, and the inability of journalists to provide adequate fact checking, which collectively prevent the formation of strong counterframes.\n\nInformation relating to kinetic attacks is also subject to framing and is frequently manipulated to advance strategic goals, but there is a critical difference in the extent of this opportunity compared to cyberattacks. Framing typically occurs because elites emphasize certain parts of an issue or selectively present information.^{39} Frames related to kinetic attacks generally have to compete with counter-frames arising from opposing perspectives, and such competition makes people less susceptible to a single frame by giving them choices about what to believe.^{40} When it comes to cyberattacks, competition between frames is restricted by a lack of information that limits access to counter-frames. For example, the Bush administration's expansive framing of responsibility throughout the War on Terror shaped U.S. policy and helped to mobilize support for the invasion of Iraq in 2003, but it had to compete against some opposition that had access to counterevidence coming from reliable sources like UN investigators.^{41} When it comes to cyberattacks, the information is often simply unavailable beyond those actors who are directly involved in the investigation, leaving them solidly in control of the narrative and with greater capacity to prevent dissenters from evaluating the evidence.\n\nThe unfamiliarity of cyberattacks compared to kinetic attacks poses additional challenges. People with more knowledge of a topic are more able to resist external frames and more inclined to search for alternative sources of information.^{42} The complexity of cyberattacks limits the size of the audience that is in a position to evaluate frames. When victims may be ignorant of an attack for months or even years (as in the case of the Stuxnet, Flame, Duqu, and Gauss worms) because of the technical expertise required for identifying the malicious code in the first place, there is little hope of the general public being in a strong position to evaluate the frames used once reporting begins. Furthermore, technical challenges hinder the public's ability to judge the plausibility of attributional claims. The evidence used to assign blame for specific attacks is often drawn from patterns identified in previous attacks, and explaining the nuances of forensic work to the public is not an easy task.\n\nWe can get a sense of the framing opportunities by looking at how long victims are able to conceal major attacks when it suits their goals. Hackers stole private information on around 57 million users and 600,000 drivers from Uber in 2016, which the company managed to conceal for more than a year by paying the hackers a $100,000 ransom.^{43} The theft of 143 million Americans' private information from Equifax in 2017 was hidden for four months.^{44} These were massive breaches, but the effects were only visible to a small number of senior officials in the affected organizations, which gave them",
    "control over the relevant information. The Equifax hack has been loosely attributed to North Korea, but concealment of the attack delayed investigation, extending the time needed to determine whether this was an act of aggression by a foreign state. Even third-party investigators may have good reasons for restricting information about an attack, at least initially, as this is sometimes vital for preventing news of software vulnerabilities from circulating before they can be patched.45 Because kinetic attacks are more visibly destructive, similar cover-ups are extremely rare and more alternative news frames are available.\n\nFurther evidence of the power of framing comes from the number of false alarms provoked by a handful of security experts. A series of power outages affecting around 50 million Americans in 2003 were widely blamed on Chinese hackers. The reports came from unnamed government sources, yet they had a sense of plausibility given the wave of hacks that had been recently attributed to China. Subsequent investigations found that the outages were more likely caused by trees.46 Brazil suffered several major power outages throughout 2005, 2007, and 2009. In each case dozens of news agencies linked these to cyberattacks, often using the story to highlight the potential for more serious destruction to follow. Once again, the sources were unnamed American security experts who lacked any hard evidence to substantiate the claims.47 Investigations later showed that the outages were probably caused by technical faults, yet by then the events had taken root as examples of Brazil's vulnerability to cyberattacks and the destruction that hackers may inflict. In these instances, the framing was probably more due to sensationalism than a deliberate attempt to mislead the public. However, it is revealing that journalists reported these incidents as attacks because they are heavily dependent on information from a few unidentified sources. Kinetic attacks trigger fear and speculation, but it is uncommon for ostensible attacks to be purely imaginary and sparked because of how unintentional destruction is framed.\n\nWhen attacks are confirmed and widely reported, victims continue to retain greater control over the framing of effects than they would following kinetic attacks. Once again, this is due to the limited number of actors involved and lack of evidence available for opposing voices attempting to develop counter-frames. Cyberattacks rarely inflict physical damage—it is usually information that is compromised—but efforts to protect the information persist in the aftermath. In those rare instances that do cause physical damage may be limited to secretive facilities that lack public oversight, such as the Iranian nuclear facilities damaged by Stuxnet. Admitting to the extent of an attack could trigger a follow-up strike by anyone hoping to capitalize on the moment of weakness, or compromise the careers of officials in the victim state's government.\n\nThus, victims remain largely in control of what costs are officially acknowledged and how these are characterized. Israel claimed that attacks linked to Anonymous in 2013 only inflicted modest financial damage.48 Iran likewise claimed that although Stuxnet showed Western aggression, it was ineffective and caused little damage. Later independent investigations would introduce counter-frames that put the costs higher,49 yet the official accounts clearly have privileged access to the relevant details. It is difficult to mobilize strong counterevidence from the outside. Other estimates have emerged in these and other cases, but come from outside and without the ability to gain the level of accesses needed for investigative work. Framing the costs of attacks in self-serving ways calls the accuracy of information into question and adds to public uncertainty about cyberattacks.\n\n## Blame Feedback Loops\n\nThe well-publicized cyberattacks against the United States that I discussed at the outset were widely attributed to China, Russia, and North Korea, revealing the extent to which attributional uncertainty is resolved by holding existing adversaries responsible. Victims of cyberattacks as well as third-party investigators tend to initially explain these in terms of existing enmities before solid evidence is forthcoming.50 Some commentators even advocate this strategy as one of the best for identifying attackers. In speaking about the continued relevance of geography in cyberattacks, Sheldon argues that fault can often be ascertained by considering the geopolitical interests involved.51 The temptation to blame the most obvious rival is apt to be especially strong soon after an attack when there is a rush to attribute responsibility and to shore up defenses, but before investigations have ended. The problem is that this helps to entrench initial frames and promotes confirmation bias, with new information being melded to the existing frame rather than being used to introduce alternative explanations. Blame feedback loops occur when attacks are explained in terms of existing hostilities and then become accepted as evidence of those hostilities that may influence subsequent threat perceptions. The risk here is that attributional uncertainty could promote a kind of path-dependency in threat perception.\n\nKinetic attacks may also trigger a rush to judgment, which can lead to divergent narratives between those seeking to blame a familiar enemy and those who are taking new evidence into account. However, as I showed in the previous section, when it comes to cyberattacks the evidence is more difficult to grasp and attribution is more ambiguous, limiting the strength of counter-frames, especially at that critical moment when the shock of an event prompts a search for answers. Studies have shown that novel and traumatic events offer a moment for novel frames to arise and question existing biases.52 Initial attributions based on existing threat perceptions tend to",
    "become the dominant frame throughout the lengthy investigative process, and that the tenuous attributional evidence that is forthcoming will have to compete against that initial frame.\n\nThe recurrent attacks on Russia's rivals provide some of the clearest examples of the tendency to explain attacks with reference to geopolitical conditions. Distributed denial of service (DDoS) attacks directed against Estonia for three weeks in 2007 were initially attributed to Russia, especially because they came after Estonia decided to remove a Soviet memorial. But even with a clear motive and the attacks originating in Russia, many cybersecurity experts later questioned this explanation, and even representatives of NATO were reluctant to say that Russia was at fault.^{53} The Russian government fueled this speculation with claims that the attacks could have come from someone within the Russian government who was acting without orders. What initially seemed to be a fairly clear case of aggression by the Russian state gradually became more complex with disagreement over whether the attackers were officially sanctioned government operatives, rogue spies, or nationalistic criminals, third parties attempting to build animosity between rival states. Each of these explanations continues to circulate years after the attack but it continues to serve as an example of Russian aggression in cyberspace that subsequent attacks are judged by. It is highly likely that Russia launched this attack. However, there is a danger in using an ambiguous case like this to identify perpetrators in the future.\n\nDefinitive cases of misattribution based on biased threat perceptions are uncommon, but this is partly because definitive attribution is rare. The cases of confirmed misattribution that are available illustrate how easily mistakes can occur when investigators initially explain attacks by looking at what seem to be the most obvious adversaries. In February 1998 the U.S. Department of Defense came under a series of network attacks that it initially blamed on Iraq. This attribution appeared logical at the time, given the heightened tensions that ultimately led to a US bombing campaign. National Coordinator for Security Richard Clarke said that “for days, critical days, as we were trying to get forces to the Gulf, we didn't know who was doing it. We assumed therefore it was Iraq.”^{54} Deputy Secretary of State John Hamre briefed President Clinton about the possibility that it could be “the first shots of a genuine cyber war” coming from Iraq.^{55} It took three weeks to discover that the attack actually came from a group of teenagers in California, Canada, and Israel, who had no relations with Iraq. The obvious explanation was incorrect, but still had ample time to contribute to the narrative of a growing Iraqi threat that was used to justify U.S. air strikes.\n\nThe true source of the Conficker worm that was first discovered in 2008 remains unknown, but that did not stop initial reports from assigning blame. 60 Minutes linked it and other recent attacks to Russia and showed pictures of ostensible suspects, who turned out to be Finnish students with no involvement.^{56} Some cybersecurity researchers claimed that the virus was the work of the U.S. and Israel because of similarities with Stuxnet.^{57} Subsequent investigations indicated that it may have come from Ukraine or China. In 2015 investigators from Trend Micro blamed Khalid Samraa for an attack on Israeli government systems. As a resident of Gaza with loose connections to the attackers' control server, he was an obvious suspect and investigators made efforts to link him with anti-Israeli groups. Samraa denied the accusations, prompting further investigations that uncovered mistakes in the initial attribution.^{58}\n\nIn 2013 an attack on France's TV5 attempted to physically destroy their computer infrastructure. An Islamic State affiliate called Cyber Caliphate claimed responsibility, and the attackers left jihadist propaganda on the station's website. This version of events was widely accepted because it came soon after the Charlie Hebdo killings and seemed to make sense in light of trends in kinetic terrorism. Investigations found that the attack more likely came from Russian hackers taking advantage of the perceived threat from Islamic State.^{59}\n\nAs forensic research advances, this strategy of masking attacks behind plausible threats may also gain ground. Cybersecurity researchers have found evidence of attackers concealing themselves by using foreign languages and components of previous malware linked to other actors, most commonly relying on materials associated with countries that are frequently blamed for cyberattacks: Russia, China, Iran, and North Korea.^{60} Existing animosities also facilitate attacks by third-party states and non-state actors. For example, tensions between Russia and the United States mean that the countries are unlikely to cooperate fully during investigations, which makes Russia an ideal conduit for anyone attempting to attack the United States without being investigated. Thus, attackers may take advantage of existing rivalries to compound the attribution problem, and in doing so perpetuate blame feedback loops.\n\nIt may usually be accurate to explain attacks with reference to existing rivalries or conventional conflicts, but this is a dangerous strategy to pursue when publicly identifying an attacker. It may have been correct to link the attacks against Estonia and Georgia to Russia, but such claims intensify hostilities with Russia and foreclose alternative possibilities when Russian government responsibility was far from certain. Assigning blame based on past relationships and assumptions about strategic interests reifies the relations of enmity between states, creating a blame feedback loop. It constrains us to interpreting novel events in terms of past events, entrenching hostilities even when they might otherwise subside and obscuring emergent threats. Each unidentifiable attack can be assigned to an",
    "existing enemy, and each attack assigned to that enemy reinforces the perception that it is indeed an enemy and encourages blame to be attributed to that enemy in the future.\n\nRegardless of their true source, attacks can usually be given a convincing explanation by appealing to strategic interests and existing hostilities. We can predict with a high degree of certainty that the next major attack against the United States or its NATO allies will be linked back to Russia or China. An attack on Russia, China, or Iran would probably be linked to the United States. The concern is that this will happen regardless of where the attacks appear to come from or whether it is impossible to trace them back to a particular source. Past attacks and expectations of future conflicts inform judgments of unattributed attacks, fitting these into patterns of behavior that are used to interpret rivals' actions. The imperfectly attributed attacks then form part of the body of evidence by which future attacks are judged, slowly building a sense of precedent even though the specific incidents that comprise that precedent may be plagued by their own attributional doubts. Assigning blame in this way appears obvious and therefore threatens to draw the public into a false sense of certainty. It is all too easy to instinctively blame the usual suspects without sufficient evidence, but looking beyond them and considering new potential culprits requires the kind of clear evidence of responsibility that is unlikely to be forthcoming—or that will at least take extensive forensic work to assemble.\n\nThe tendency to explain attacks in terms of the most prominent existing rivalries invites efforts by lesser rivals or non-state actors to trigger hostilities. As the risk of being caught diminishes, the costs of attack decrease and the potential benefits become even more attractive, lowering the threshold for conducting cyber operations and allowing actors that could not compete in conventional conflicts to launch strikes. Eun and Aßmann argue that “states are more likely to conduct cyber-attacks as the risk of severe consequences are considerably lower than with conventional forms of attack—particularly as the event and the aggressor are evident in physical attacks.”61 The relatively low cost of cyberattacks, both in terms of resources and in terms of the low likelihood of being blamed, makes these more appealing for marginal rivals and incentivizes them to strike when they are low in the hierarchy of potential suspects. States, terrorists, and criminals who are not part of the entrenched relations of enmity that tend to structure explanations of fault for cyberattacks may exploit the opportunities offered by blame feedback loops to launch attacks at a reduced chance of detection or to incite disagreement between the rivals that will reproach each other in the aftermath. This compounds the attribution problem by increasing the number of actors that could potentially be involved and making it difficult to even determine the nature of an attack—whether it was war, espionage, terrorism, theft, or a purposeless display of malice and technical expertise.\n\n## Cultivating Conspiracies\n\nWhen cyberattacks are first identified, the limited information available is highly susceptible to elite framing and to being fit into blame feedback loops. Alternative frames may become available once investigations have run their course, but this leaves time for the initial attributions to gain traction and dominate the initial media coverage. The tendency to blame obvious culprits may also prevent the alternative frames from developing, as investigators have limited resources and may not invest them when the source of an attack appears to be obvious or when there is a low chance of success.62 Any attempts to alter the initial attributions must therefore take the form of corrective frames that arise later, rather than competing frames that are contemporaneous with the attack. Studies have shown that corrective information is rarely able to counteract misperceptions and that persuasion can exacerbate them by repeating the incorrect information.63 It is difficult to update beliefs once they have been accepted even under the ideal circumstances when compelling information is uncovered,64 and when it comes to cyberattacks the corrective information may simply be a different perspective that is not conclusive.\n\nThe long-term consequence of framing attack attributions based on inconclusive evidence, especially at the critical junctures immediately after shocking events when existing biases are more susceptible to change, is persistent misperception about cyberattacks that can develop into conspiratorial thinking. As Oliver and Wood point out, popular conspiracy theories are heavily guided by elite discourses and acceptance of previous conspiratorial frames. “Like ordinary public opinion, conspiracist opinion is highly influenced by encounters with elite discourse, in this case the conspiracy narratives.”65 Surprisingly, they find that people with a high level of political knowledge can be susceptible to conspiracy theories because they are responsive to elite frames and adept at interpreting new information to fit existing beliefs. The higher initial dependence on elite frames when it comes to cyberattacks indicates a higher likelihood of conspiratorial thinking compared to kinetic attacks.\n\nOf course, there is more to conspiracy theories than attributional uncertainties and elite framing. Conspiratorial thinking is widespread, affecting virtually every issue area, including kinetic attacks for which there is clear evidence pointing to the attackers. The 9/11 truth movement demonstrates the persistence of conspiracy theories against corrective information. Multiple studies have shown that certain predispositions can make people more susceptible to conspiracies.66 This helps to account for conspiratorial thinking when evidence is available and multiple frames exist.",
    "Predispositions clearly matter, but their influence is felt in conjunction with the available information. Zaller argues that “every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it.”^{67} Garrett argues that rumour “spreads among a group of people because it promises to resolve uncertainty or provide new insight into important social or political phenomena.”^{68} Miller, Saunders, and Farhart find that “however far-fetched the theory might be, tying up confusing events with a simple, neat conspiratorial bow fulfills the individual's need for order and reduces concomitant anxiety.”^{69} And Konkes and Lester argue that conspiracies tend to emerge over time when information is not forthcoming and audiences develop a sense that something is being hidden. Moreover, some of the relevant predispositions relate to how information is processed.^{70} Swami et al. find that people who are less disposed to conspiratorial thinking tend to show a more analytical thinking style that is characterized by careful attention to the available evidence, while those predisposed to conspiratorial thinking tend to rely more heavily on intuition that does not account for the available evidence.^{71} With this in mind we should expect that when limited information is available and heavily shaped by elite gatekeepers, intuitive thinking will become the default mode of processing.\n\nOne of the predispositions that correlates strongly with conspiratorial thinking is prior acceptance of conspiracy theories,^{72} and this raises another challenge beyond the shortage of information. Many people have factually inaccurate perceptions of kinetic attacks, but it is usually possible for researchers to identify these inaccuracies and to label them as conspiratorial based on the kinds of explanations being posited. For example, Swami and Furnham define conspiracy theories as “a subset of false beliefs in which the ultimate cause of an event is believed to be due to a plot by multiple actors working together with a clear goal in mind, often unlawfully and in secret.”^{73} With fewer facts available, it is more difficult to say whether frames related to cyberattacks are conspiratorial in the sense of being false. Uscinski et al. define a conspiracy theory as “a proposed explanation of events that cites as a main causal factor a small group of persons (the conspirators) acting in secret for their own benefit, against the common good.”^{74} In other contexts this is an excellent definition, but it would cover virtually every cyberattack. By both of these definitions, publicly available information about cyberattacks will likely seem conspiratorial regardless of whether it is accurate. In a sense, we must accept explanations that have some characteristics of conspiracy theories to understand cyberattacks and must therefore develop some predispositions towards conspiratorial thinking.\n\nConsider the Stuxnet attack for example. It was launched by a still unidentified group of clandestine American and Israeli operatives, concealed itself from system administrators, and relied on forged authentication or stolen documents. Related worms were found capturing computer screenshots, recording audio, and accessing webcams in foreign government offices in at least seven countries.^{75} Investigators and leaks have established these points with a high degree of confidence, but the attack still embodies defining characteristics of conspiratorial thinking based on the given definitions. Accepting that such an attack happened (as we should) lures us towards a predisposition to accepting similar conspiratorial accounts in the future.\n\nConspiratorial thinking is sometimes accurate, but it is dangerous in a security context because it fosters a tendency to misidentify threats. Libicki notes that “if events in the real world are indicative, the popular tendency will be to assume that any spectacular computer failure resulted from hostile action.”^{76} One of the most famous suspected cyberattacks arguably falls into this category. In 1982 the Urengoy-Surgut-Chelyabinsk natural gas pipeline in Siberia exploded. Former CIA agents later claimed to have caused this by installing infected software that was set to malfunction.^{77} Rid challenges this story with contradictory reports and contends that it was technically impossible at the time. This leaves the nature of this event, which would be the deadliest cyberattack in history, in doubt.^{78}\n\nThat incident is symptomatic of the ambiguous threats that are continually emerging in cyberspace. In July and August 2016, Iran's oil and natural gas infrastructure was struck by a series of explosions. Iranian officials said that they were investigating the possibility that these were triggered by a cyberattack.^{79} Thus far, research indicates that this account is incorrect and that mechanical faults were the cause, but with worms like Stuxnet disguising themselves as mechanical errors, there are certain to be lingering doubts. Those involved in Stuxnet hoped for this outcome, predicting that their strike would spread paranoia about critical infrastructure threats.^{80} From the attacker's perspective, building a predisposition towards conspiratorial thinking may be a key objective that imposes ongoing costs associated with misattribution and fear.\n\nIt is difficult to find any genuine cases of cyberattacks causing infrastructural damage aside from Stuxnet, and as I pointed out previously, there is a pattern of power outages being misidentified as cyberattacks.^{81} The apparent cyberattacks that turned out to be trees seem laughable in hindsight, but they are difficult to distinguish from genuine threats. A series of power outages in Ukraine in 2016 were blamed on Russian hackers. Based on the available evidence, these attacks appear to be genuine.^{82} However, it is disconcerting that genuine attacks so closely resemble the many preceding false alarms, and this will likely support future claims of infrastructure attacks before all the evidence is in. The ultimate cost of conspiratorial",
    "thinking may be an increased incidence of false alarms, growing doubt for official explanations of real attacks resembling those false alarms, and increased difficulty in forming a consensus about the presence or absence of threats to national security.\n\n## The Threat to Democratic Accountability\n\nThus far, I have dealt with attribution as a challenge related to correctly identifying the perpetrator of an attack, but the effects I have described point to another attributional concern: whether citizens are able to hold policymakers accountable for failing to take adequate defensive measures or for poor responses to them. Exercising popular sovereignty presupposes that citizens have relevant information about who is responsible for major events. “Proper blame (and credit) attribution is necessary for citizens in a democracy to hold elected leaders accountable—they must first form an opinion of who should be held responsible for mistakes (and successes) before forming retrospective performance evaluations or casting their ballots.”83 This is borne out in decades of research in political psychology showing that performance evaluations are not as straightforward as simply judging the available facts.84\n\nDrawing on my previous points, it is clear that the attribution problem poses a significant barrier to retrospective evaluations of elected officials' performance when looking purely at what the facts indicate. If it is difficult to determine when an infrastructure failure is the result of a malfunction or an attack, then the public will likewise struggle to make sense of what it means in terms of leadership performance. If attacks are hidden from view or uncovered long after they initially occurred, then they may not be on the electorate's agenda at all. If past attacks yield unreliable clues about future threats, then voters could struggle when deciding what security concerns to prioritize. However, situating cyberattacks in their political context requires looking beyond information shortages to consider other influences on opinion formation.\n\nPoliticians at all levels have motives for deflecting blame for failed security policies onto others, and routinely demonstrate their skill in doing this.85 The extent to which they are able to succeed partially depends on the issue at stake and the structure of government institutions involved. Responsibility for economic issues tends to be shared by multiple actors. It is susceptible to diffusion and heavily influenced by partisanship.86 The security context is somewhat more straightforward. Partisanship still matters there, but “the public tends to view national security policy as the sole domain of the executive.”87 Cyberattacks fall into the security domain. However, the blame assessment processes may share some characteristics with economic judgments because of the ambiguities these entail. Cybersecurity is also less clearly centralized under executive control than kinetic military power, as much of it comes from the private sector and secretive defense agencies. This, combined with extensive evidence of partisan cues affecting responsibility attributions in other domains88 is grounds for expecting that partisanship will heavily influence how citizens respond to cyberattacks.\n\nThe 2016 U.S. presidential election reveals how partisan framing can compound existing challenges when assigning blame. The Clinton campaign's failure to take adequate measures to protect e-mail became a central point in the effort to show that she was unfit to become president. Conversely, reports that Donald Trump incited the hacking helped Democrats make the case that he was collaborating with foreign leaders to rig an election.89 Public opinion polls reveal that acceptance of these narratives is sharply divided along party lines.90 Trump's presidency has been marred by accusations of complicity in Russian hacking, with ongoing investigations aimed at uncovering those deeply problematic attributional links. Here the intermingled challenges of identifying attackers and identifying fault among officials join together. Any conclusions investigators reach are certain to be decried by the party they adversely affect, and the vagaries of attribution will assist that narrative.\n\nThe election also showed some of the risks associated with voters being able to express their party preferences at the polls. The Federal Bureau of Investigation looked into suspected attacks on electoral computer systems in Arizona and Illinois and said that information from around 200,000 voters was compromised.91 Donald Trump capitalized on those and other attacks by fueling fears that the election results would be fraudulent and that hackers could tamper with computer systems to make him lose. Insisting that some unnamed source could do this following a series of earlier attacks on electoral computer systems generated a conspiratorial narrative and cast doubt on the election results and consequently on the quality of American democracy. American law enforcement officials cited this as a serious concern and warned that paranoia over a potential cyberattack could make it possible for even fraudulent evidence of hacking to undermine public trust in the electoral system.92\n\nUnfortunately, effective cybersecurity may require states to rely more heavily on deception, exacerbating attribution difficulties both in the sense of the public seeing who is responsible for launching attacks and for judging elected officials' decisions. Gartzke and Lindsay argue that the United States and other countries that come under persistent cyberattacks can find strength in a defensive posture if they are willing to embrace the deception that makes offensive cyber operations so successful.93 They say that defenders can create “a virtual minefield” that will ensnare intruders by tricking them into downloading malware or accessing misleading information. This is",
    "Special Section Article | The Politics of Attributing Blame for Cyberattacks\n\nworthwhile advice that may improve security, yet it depends on the elite focus that is so prominent in the literature. For example, the authors say that “deception masks or adds information in order to influence indirectly the beliefs that affect an opponent’s voluntary decisions to act.”94 They may be right in thinking that deception provides the greatest defensive advantages, but the same actions that mislead opponents are also apt to mislead domestic and international audiences.\n\nDeceptive strategies like producing state-sponsored malware and releasing false information about the extent of attacks could increase public concern over how covert operations are being conducted in cyberspace, just as covert operations have generated criticism of counterterrorism operations.95 Effective defense may therefore depend on making an already murky security domain more opaque for those citizens who are supposed to be in a position to exercise democratic oversight over government functions. Even if we assume that the deception is in these citizens’ best interests we must confront the inevitable result that denying them information aggravates the challenges associated with blame attribution. The fact that the denial comes at the hands of the government may be especially damaging, as this lends additional credence to the conspiratorial thinking that a small group of elites may be launching secretive attacks and keeping information away from public view.\n\n## Conclusion\n\nThe literature on cybersecurity tends to approach the attribution problem as a technical matter for investigators and policymakers to contend with, thereby marginalizing the broader political significance of responsibility attributions and missing some of the challenges that arise when the public responds to attacks. Uncertainty about cyberattacks, especially when it comes to attribution, often forces non-elite audiences to make intuitive judgments based on incomplete evidence. The lack of empirically-grounded counter-frames leaves them heavily dependent on frames developed by the elites who are directly involved in the attack and encourages the assignment of blame based on existing threat perceptions. Over the long term, this promotes conspiratorial thinking and limits opportunities for evaluating elected officials’ performance. Attributional uncertainty therefore constitutes a major barrier to the public’s understanding of cybersecurity and taking relevant actions. Nevertheless, efforts to assign blame are essential for making sense of security issues, forming policy preferences, and exercising popular sovereignty. Attributions must continue to be at the heart of political judgment, even as new challenges emerge to obscure this process.\n\nThe attribution problem is likely insoluble, but steps should be taken to manage its effects. In a discussion of how economic issues are framed, Rudolph finds that\n\n“an information environment containing conflicting messages from competing partisan actors complicates the task of determining who is responsible” and shows that institutional divisions of power are particularly important.96 This suggests that one urgent precaution is establishing stronger internal oversight procedures to monitor cybersecurity policy implementation and to ensure that information is publicized whenever possible. This would limit secrecy surrounding cybersecurity, which could be costly if we look narrowly at elites’ strategic calculations. However, the costs of failing to do this strike at the heart of the democratic process and must be prioritized. Greater openness about attacks may require granting access to a broader range of government officials, especially across institutional boundaries and party lines. More than this, oversight bodies should have discretion for publicizing information about events so journalists can rely on a broader range of sources and gain more opportunities for evaluating the competing perspectives.\n\nBeyond this, there is a need for greater public awareness that attribution for cyberattacks is tenuous and that its investigation takes time. The public should be sensitized to the problem and to a security context in which blame takes time to establish. It would be prudent for policymakers and journalists to avoid a rush to judge who is responsible for an attack, regardless of how obvious the answer may initially seem. This would promote greater openness to information that is uncovered by investigators. Political scientists can play a role in this by exploring how these novel threats fit into what previous research has uncovered about opinion formation and conflict processes. Future research should continue to investigate the political challenges associated with attribution and to consider what additional steps could be taken to manage this problem.\n\n## Notes\n\n1. Sanger 2013.\n2. Strohm, Dorning, and Riley 2016.\n3. Associated Press 2014; Zetter 2014.\n4. Rid 2013, 142.\n5. Maestas et al. 2008, 609–610.\n6. Stone 1989, 299.\n7. Forsyth 1980.\n8. Carlin 2014.\n9. Peffley 1984; Rudolph 2003; Gomez and Wilson 2003; Arceneaux 2003; Brown 2012.\n10. Atkeson and Maestas 2012.\n11. Economist 2011; Starr 2016.\n12. Uscinski and Parent 2014. [AU: Not in your References.]\n13. Eun and Aßmann 2014, 13.\n14. Brenner 2011, 32.\n15. Zetter 2011.\n16. Sheldon 2014, 289–9.\n\nPerspectives on Politics\n\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press",
    "17 Zetter 2011.\n18 Brenner 2014, 82.\n19 Rid and Buchanan 2015, 5.\n20 Ibid.\n21 Farwell and Rohozinski 2011, 27.\n22 Eun and Aßmann 2014, 13.\n23 Rid 2013, 139.\n24 Lindsay 2015.\n25 Iyengar 1989, 879.\n26 Atkesan and Maestas 2012, 9.\n27 Gomez and Wilson 2003.\n28 Kühne, Weber, and Sommer 2015, 264.\n29 Marcus, Russell, and MacKuen 2003.\n30 Walker 2006.\n31 Ibid., 32.\n32 Henley and Traynor 2015.\n33 Berinsky 2009; Holsti 2011.\n34 Maestas and Atkinson 2012.\n35 Stone 1989, 299.\n36 Baum and Groeling 2010.\n37 Bennett, Lawrence, and Livingston 2007.\n38 Ibid. 2007; Graber 2005.\n39 Entman 2004.\n40 Druckman 2004, 675.\n41 Kaufmann 2004; Berinsky 2009.\n42 Haider-Markel and Joslyn 2001.\n43 Wong 2017.\n44 Newman 2017.\n45 Zetter 2011.\n46 Poulsen 2008.\n47 Ibid.\n48 Kershner 2013.\n49 Zetter 2011.\n50 Green 2015; Kaplan 2016.\n51 Sheldon 2014.\n52 Brader 2006, Atkeson and Maestas 2012; Marcus, Neuman, and MacKuen 2003.\n53 Traynor 2007.\n54 Arkin 1999.\n55 Zetter 2011, 209.\n56 Poulsen 2009.\n57 Zetter 2011, 54\n58 Fox-Brewster 2015.\n59 Corera 2016.\n60 Bartholomew and Guerrero-Saade 2016.\n61 Eun and Aßmann 2014, 13.\n62 Zetter 2011.\n63 Peffley 1984; Rudolph 2003; Gomez and Wilson 2003; Arceneaux 2003; Brown 2010.\n64 Nyhan, Reifler, and Ubel 2013.\n65 Oliver and Wood 2014, 953.\n66 Oliver and Wood 2014; Uscinski and Parent 2014.\n67 Zaller 1992, 6.\n68 Garrett 2011, 256.\n69 Miller, Saunders, and Farhart 2015, 2.\n\n70 Konkes and Lester 2017.\n71 Swami et al. 2014.\n72 Oliver and Wood 2014.\n73 Swami and Furnham 2014, 220.\n74 Uscinski, Klofstad, and Atkinson 2016, 58.\n75 Zetter 2011.\n76 Libicki 2009, 45.\n77 Russell 2004.\n78 Rid 2013, 5–7.\n79 Serjoie 2016.\n80 Zetter 2011.\n81 Rid 2013.\n82 Zetter 2016.\n83 Malhotra and Kuo 2008, 121.\n84 Iyengar 1998, 1990; Peffley 1984; Rudolph 2003.\n85 Hood 2010.\n86 Rudolph 2003; Peffley 1984; Brown 2010; Gomez and Wilson 2003; Nawara 2015.\n87 Carlin, Love, and Martínez-Gallardo 2014, 443.\n88 Rudolph 2003; Brown 2010; Bartels 2002; Stone 1989; Haider-Markel and Joslyn 2001; Arceneaux 2003; Carlin, Love, and Martínez-Gallardo 2014; Nawara 2015.\n89 Lichtblau and Myers 2016.\n90 YouGov 2016.\n91 Dyer 2016.\n92 Lui 2016.\n93 Gartzke and Lindsay 2015, 328.\n94 Ibid.\n95 Mazzetti 2013; Niva 2013.\n96 Rudolph 2003, 701.\n\n## References\n\nAssociated Press. 2014. \"Evidence in Sony Hack Is Largely Circumstantial, Sources Say. Denver Post, December 18. Available at http://www.denverpost.com/2014/2012/2018/evidence-in-sony-hack-is-largely-circumstantial-sources-say/.\nArceneaux, Kevin. 2003. \"The Conditional Impact of Blame Attribution on the Relationship Between Economic Adversity and Turnout.\" Political Research Quarterly 56(1): 67–75.\nArkin, William M. 1999. \"Sunrise, Sunset.\" Washington Post, March 29. Available at https://www.washingtonpost.com/wp-srv/national/dotmil/arkin032999.htm.\nAtkeson, Lonna Rae and Cherie D. Maestas. 2012. Catastrophic Politics: How Extraordinary Events Redefine Perceptions of Government. Cambridge: Cambridge University Press.\nBartels, Larry M. 2002. \"Beyond the Running Tally: Partisan Bias in Political Perceptions.\" Political Behavior 24(2): 117–50.\nBartholomew, Brian and Juan Andres Guerrero-Saade. 2016. \"Wave Your False Flags!\". Presented at the Virus Bulletin Conference, Denver, CO, October 5–7.\n\nDecember 2018 | Vol. 16/No. 4 965\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press",
    "Special Section Article | The Politics of Attributing Blame for Cyberattacks\n\nBaum, Matthew A. and Tim Groeling. 2010. \"Reality Asserts Itself: Public Opinion on Iraq and the Elasticity of Reality.\" International Organization 64: 443–79.\n\nBennett, W. Lance, Regina G. Lawrence and Steven Livingston. 2007. When the Press Fails: Political Power and the News Media from Iraq to Katrina. Chicago: University of Chicago Press.\n\nBerinsky, Adam J. 2009. In Time of War: Understanding American Public Opinion from World War II to Iraq. Chicago: University of Chicago Press.\n\nBrader, Ted. 2006. Campaigning for Hearts and Minds: How Emotional Appeals in Political Ads Work. Chicago: University of Chicago Press.\n\nBrenner, Joel. 2011. America the Vulnerable: Inside the New Threat Matrix of Digital Espionage, Crime, and Warfare. New York: Penguin\n\nBrenner, Susan. 2014. Cyberthreats and the Decline of the Nation-State. London: Routledge.\n\nBrown, Adam R. 2010. \"Are Governors Responsible for the State Economy? Partisanship, Blame, and Divided Federalism.\" Journal of Politics 72(3): 605–15.\n\nCarlin, Ryan E. Gregory J. Love, and Cecilia Martínez-Gallardo. 2014. \"Security, Clarity of Responsibility, and Presidential Approval.\" Comparative Political Studies 48(4): 438–63.\n\nCorera, Gordon. 2016. \"How France's TV5 Was Almost Destroyed by 'Russian Hackers'.\" BBC News, October 10. Available at http://www.bbc.co.uk/news/technology-37590375.\n\nDruckman, James N. 2004. \"Political Preference Formation: Competition, Deliberation, And The (Ir) Relevance Of Framing effects.\" American Political Science Review 98(4): 671–86.\n\nDyer, Geoff. 2016. \"Hackers Attack Arizona and Illinois Election Computer Systems\" Financial Times, August 29. Available at https://www.ft.com/content/1ea03bf4-6e2e-11e6-9ac1-1055824ca907.\n\nEconomist. 2011. \"Who Is to Blame?\" December 24. Available at http://www.economist.com/blogs/newsbook/2011/2012/attacks-syria.\n\nEntman, Robert M. 2004. Projections of Power: Framing News, Public Opinion, and U.S. Foreign Policy. Chicago: University of Chicago Press.\n\nEun, Yong-Soo and Judith Sita Aßmann. 2016. \"Cyberwar: Taking Stock of Security and Warfare in the Digital Age.\" International Studies Perspectives 17(3): 343–60.\n\nFarwell, James P. and Rafal Rohozinski. 2011. \"Stuxnet and the Future of Cyber War.\" Survival: Global Politics and Strategy 53(1): 23–40.\n\nForsyth, Donelson R. 1980. \"The Functions of Attributions.\" Social Psychology Quarterly 43(2): 184–98.\n\nFox-Brewster, Thomas. 2015. \"Gaza Resident Linked to Cyber Attacks on Israel: Security Company Has Put My Life in Danger.\" Forbes, February 24.\n\nAvailable at https://www.forbes.com/sites/thomasbrewster/2015/02/24/trend-micro-worrying-attribution-of-gaza-strip-businessman/#1dd668392e9e.\n\nGarrett, R. Kelly. 2011. \"Troubling Consequences of Online Political Rumoring.\" Human Communication Research 37: 255–74.\n\nGartzke, Erik and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" Security Studies 24(2): 316–48.\n\nGomez, Brad T. and J. Matthew Wilson. 2003. \"Causal Attribution and Economic Voting in American Congressional Elections.\" Political Research Quarterly 56(3): 271–82.\n\nGraber, Doris A. 2005. Mass Media and American Politics. Washington, DC: CQ Press.\n\nGreen, James A., ed. 2015. Cyber Warfare: A Multidisciplinary Analysis. New York: Routledge.\n\nHaider-Markel, Donald P. and Mark R. Joslyn. 2001. \"Gun Policy, Opinion, Tragedy, and Blame Attribution: The Conditional Influence of Issue-Frames.\" Journal of Politics 63(2): 520–43.\n\nHenley, Jon and Ian Traynor. 2015. \"Fight against Isis Heats Up as UN Backs Action after Paris Attacks.\" The Guardian, November 22. Available at https://www.theguardian.com/world/2015/nov/21/fight-against-isis-heats-up-as-un-backs-action-after-paris-attacks.\n\nHolsti, Ole Rudolf. 2011. American Public Opinion on the Iraq War. Ann Arbor: University of Michigan Press.\n\nHood, Christopher. 2010. The Blame Game: Spin, Bureaucracy, and Self-Preservation in Government. Princeton, NJ: Princeton University Press.\n\nIyengar, Shanto. 1989. \"How Citizens Think about National Issues: A Matter of Responsibility.\" American Journal of Political Science 33(4): 878–900.\n\n——. 1990. \"Framing Responsibility for Political Issues: The Case of Poverty.\" Political Behavior 12(1): 19–40.\n\nKaplan, Fred. 2016. Dark Territory: The Secret History of Cyber War. New York: Simon &amp; Schuster.\n\nKaufmann, Chaim. 2004. \"Threat Inflation and the Failure of the Marketplace of Ideas: The Selling of the Iraq War.\" International Security 29(1): 5–48.\n\nKershner, Isabel. 2013. \"Israel Says It Repelled Most Attacks on Its Web Sites by Pro-Palestinian Hackers.\" New York Times, April 7. Available at http://www.nytimes.com/2013/04/08/world/middleeast/pro-palestinian-hackers-attack-israeli-sites.html?_r=0.\n\nKonkes, Claire and Libby Lester. 2017. \"Incomplete Knowledge, Rumour and Truth Seeking.\" Journalism Studies 18(7): 826–44.\n\nKühne, Rinaldo, Patrick Weber, and Katharina Sommer. 2015. \"Beyond Cognitive Framing Processes: Anger Mediates the Effects of Responsibility Framing on the Preference for Punitive Measures.\" Journal of Communication 65: 259–79.\n\nPerspectives on Politics\n\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press",
    "Libickim Martin, C. 2009 Cyberdeterrence and Cyberwar. Santa Monica, CA: RAND Corporation.\n\nLichtblau, Eric and Steven Lee Myers. 2016. \"Investigating Donald Trump, F.B.I. Sees No Clear Link to Russia.\" New York Times, October 31. Available at http://www.nytimes.com/2016/11/01/us/politics/fbi-russia-election-donald-trump.html?_r=0.\n\nLindsay, Jon R. 2015. \"Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence against Cyberattack.\" Journal of Cybersecurity 1(1): 53-67.\n\nLui, Kevin. 2016. \"Russian Hackers Could Fake Evidence of Electoral Fraud, Warn U.S. Officials.\" Time, October 20. Available at http://time.com/4539904/fake-voter-fraud-russia-us-election-hack-warning/.\n\nMaestas, Cherie D., Lonna Rae Atkeson, Thomas Croom, and Lisa A. Bryant. 2008. \"Shifting the Blame: Federalism, Media, and Public Assignment of Blame Following Hurricane Katrina.\" *Publius: The Journal of Federalism* 38(4): 609-32.\n\nMalhotra, Neil and Alexander G. Kuo. 2008. \"Attributing Blame: The Public's Response to Hurricane Katrina.\" Journal of Politics 70(1): 120-35.\n\nMarcus, George E., W. Russell Neuman, and Michael MacKuen. 2003. Affective Intelligence and Political Judgment. Chicago University of Chicago Press.\n\nMazzetti, Mark. 2013. Way of The Knife: The CIA, A Secret Army, and a War at the Ends of the Earth. New York: Penguin.\n\nMiller, Joanne M., Kyle L. Saunders, and Christina E. Farhart. 2015. \"Conspiracy Endorsement as Motivated Reasoning: The Moderating Roles of Political Knowledge and Trust.\" American Journal of Political Science 60(4): 824-44.\n\nNawara, P. Steven. 2015. \"Who Is Responsible, the Incumbent or the Former President? Motivated Reasoning in Responsibility Attributions.\" *Presidential Studies Quarterly* 45(1): 110-31.\n\nNewman, Lily Hay. 2017. \"The Equifax Breach Exposes America's Identity Crisis.\" Wired, September 8. Available at https://www.wired.com/story/the-equifax-breach-exposes-americas-identity-crisis/.\n\nNiva, Steve. 2013. \"Disappearing Violence: JSOC and the Pentagon's New Cartography of Networked Warfare.\" Security Dialogue 44(3): 185-202.\n\nNyhan, Brendan, Jason Reifler, and Peter A. Ubel. 2013. \"The Hazards of Correcting Myths about Health Care Reform.\" Medical Care 51(2): 127-32.\n\nOliver, J. Eric and Thomas J. Wood. 2014. \"Conspiracy Theories and the Paranoid Style(s) of Mass Opinion.\" American Journal of Political Science 58(4): 952-66.\n\nPeffley, Mark 1984. \"The Voter as Juror: Attributing Responsibility for Economic Conditions.\" Political Behavior 6(3): 275-94.\n\nPoulsen, Kevin. 2008. \"Did Hackers Cause the 2003 Northeast Blackout? Umm, No.\" Wired, May 29.\n\nAvailable at https://www.wired.com/2008/05/did-hackers-cau/.\n\n_____. 2009. \"Report: Cyber Attacks Caused Power Outages in Brazil.\" Wired, November 7. Available at https://www.wired.com/2009/11/brazil/.\n\nRid, Thomas. 2013. Cyber War Will Not Take Place. New York: Oxford University Press.\n\nRid, Thomas and Ben Buchanan. 2015. \"Attributing Cyber Attacks.\" Journal of Strategic Studies 38(1-2): 4-37.\n\nRudolph, Thomas J. 2003. \"Who's Responsible for the Economy? The Formation and Consequences of Responsibility Attributions.\" American Journal of Political Science 47(4): 698-713.\n\nRussell, Alec. 2004. \"CIA Plot Led to a HUGE BLAST in Siberian Gas Pipeline. The Telegraph, February 28. Available at http://www.telegraph.co.uk/news/worldnews/northamerica/usa/1455559/CIA-plot-led-to-huge-blast-in-Siberian-gas-pipeline.html.\n\nSanger, David. 2013. \"U.S. Blames China's Military Directly for Cyberattacks.\" New York Times, May 6. Available at http://www.nytimes.com/2013/2005/2007/world/asia/us-accuses-chinas-military-in-cyberattacks.html?_r=2010.\n\nSerjoie, Kay Armin. 2016. \"Iran Investigates If Series of Oil Industry Accidents Were Caused by Cyber Attack.\" Time, August 12. Available at http://time.com/4450433/iran-investigates-if-series-of-oil-industry-accidents-were-caused-by-cyber-attack/.\n\nSheldon, John. 2014. \"Geopolitics and Cyber Power: Why Geography Still Matters.\" American Foreign Policy Interests 36(5): 286-93.\n\nStarr, Barbara 2016. \"US blames Russia for Syria Convoy Attack; Moscow Points to Terrorists.\" CNN, September 21. Available at http://edition.cnn.com/2016/2009/2020/politics/syria-convoy-strike-us-conclusion-russia/.\n\nStone, Deborah. 1989. \"Causal Stories and the Formation of Policy Agendas.\" Political Science Quarterly 104(2): 281-300.\n\nStrohm, Chris, Mike Dorning, and Michael Riley. 2016. \"FBI Investigating DNC Hack Some Democrats Blame on Russia.\" Bloomberg, July 25. Available at http://www.bloomberg.com/politics/articles/2016-2007-2025/fbi-investigating-dnc-cyber-hack-some-democrats-blame-on-russia.\n\nSwami, Viren, Martin Voracek, Stefan Stieger, Ulrich S. Tran, and Adrian Furnham. 2014. \"Analytic Thinking Reduces Belief in Conspiracy Theories.\" Cognition 133(3): 572-85.\n\nSwami, Viren and A. Furnham. 2014. \"Political Paranoia and Conspiracy Theories.\" In Power Politics, and Paranoia: Why People Are Suspicious of Their Leaders, ed. J. P. Prooijen and P. A. M. van Lange. Cambridge: Cambridge University Press.\n\nDecember 2018 | Vol. 16/No. 4\n\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press",
    "Special Section Article | The Politics of Attributing Blame for Cyberattacks\n\nTraynor, Ian. 2007. \"Russia Accused of Unleashing Cyberwar to Disable Estonia.\" *The Guardian*. Available at https://www.theguardian.com/world/2007/may/2017/topstories2003.russia.\n\nUscinski, Joseph E., Casey Klofstad, and Matthew D. Atkinson. 2016. \"What Drives Conspiratorial Beliefs? The Role of Informational Cues and Predispositions.\" *Political Research Quarterly* 69(1): 57–71.\n\nUscinski, Joseph E. and Joseph M. Parent. 2014. *American Conspiracy Theories*. Oxford: Oxford University Press.\n\nWalker, Margaret Urban. 2006. *Moral Repair: Reconstructing Moral Relations after Wrongdoing*. Cambridge: Cambridge University Press.\n\nWong, Julia Carrie. 2017. \"Uber Concealed Massive Hack that Exposed Data of 57m Users and Drivers.\" *The Guardian*, November 22. Available at https://www.theguardian.com/technology/2017/nov/21/uber-data-hack-cyber-attack.\n\nYouGov. 2016. \"Belief in Conspiracies Largely Depends on Political Identity.\" Available at https://today.yougov.com/news/2016/12/27/belief-conspiracies-largely-depends-political-iden/\n\nZaller, John. 1992. *The Nature and Origins of Mass Opinion*. Cambridge: Cambridge University Press.\n\nZetter, Kim. 2011. *Countdown to Zero Day: Stuxnet and the Launch of the World's First Digital Weapon*. New York: Crown.\n\n——. 2014. \"The Evidence that North Korea Hacked Sony Is Flimsy.\" *Wired*, December 17. Available at https://www.wired.com/2014/2012/evidence-of-north-korea-hack-is-thin/.\n\n——. 2016. \"Inside the Cunning, Unprecedented Hack of Ukraine's Power Grid.\" *Wired*, March 3. Available at https://www.wired.com/2016/03/inside-cunning-unprecedented-hack-ukraines-power-grid/.\n\nPerspectives on Politics\n\nhttps://doi.org/10.1017/S153759271800110X Published online by Cambridge University Press"
  ],
  "metadata": {
    "title": "The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty",
    "subtitle": "doi:10.1017/S153759271800110X",
    "document_type": "unknown",
    "venue": "",
    "publication_year": 2014,
    "authors": [
      "Marcus Schulzke"
    ],
    "affiliations": [],
    "emails": [
      "MarcusSchulzke@gmail.com"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1017/S153759271800110X"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "https://doi.org/10.1017/S153759271800110X"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 165,
    "heading_count": 10,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0
    },
    "footnotes_quality": {
      "intext_total": 26,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.3076923076923077,
      "footnote_coverage": 0.0,
      "unique_index_count": 26,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "author_year",
      "recommended_style": "unknown",
      "aligned": true,
      "signals": {
        "superscript_hits": 4,
        "superscript_definition_lines": 0,
        "numeric_bracket_hits": 0,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 119.0,
      "dominant_bib_coverage_rate": 0.0,
      "dominant_link_target": "bibliography",
      "dominant_unresolved_flag": "unresolved_reference_links"
    },
    "heading_validation": {
      "heading_count": 10,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": false,
        "emails": true,
        "orcids": false,
        "abstract": false,
        "keywords": false,
        "venue": false,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 1,
        "affiliations": 0,
        "emails": 1,
        "orcids": 0,
        "keywords": 0,
        "doi": 1,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 1
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 1.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_abstract_and_keywords"
      ]
    },
    "flags": [
      "footnotes_bucket_unresolved",
      "meta_missing_abstract_and_keywords"
    ]
  },
  "citation_summary": {
    "style": "author_year",
    "dominant_bucket": "author_year",
    "dominant": {
      "intext_total": 0.0,
      "success_occurrences": 0.0,
      "success_unique": 0.0,
      "bib_unique_total": 119.0,
      "occurrence_match_rate": 0.0,
      "bib_coverage_rate": 0.0,
      "success_percentage": 0.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "author_year"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 26.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 56.0,
        "highest_intext_index": 82.0,
        "missing_footnotes_for_seen_total": 26.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 119.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:25:53.402094+00:00"
}