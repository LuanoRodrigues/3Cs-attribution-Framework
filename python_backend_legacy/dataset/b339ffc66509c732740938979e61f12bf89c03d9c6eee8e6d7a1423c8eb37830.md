{
  "full_text": "# Disinformation, deterrence and the politics of attribution\nELSA HEDLING AND HEDVIG ÖRDÉN*\nHow do acts of attribution serve liberal states' attempts at deterring foreign influence operations in their public spheres, and why are they enacted so unevenly? This article nuances the sensitive relationship between domestic politics, the narrow framing of disinformation attribution as a technical question of pinpointing attackers' identities, and the role of disinformation as a security threat to be deterred. As foreign influence operations have (re-)emerged as a critical threat to liberal democracy, efforts to assess and effectively counter their effects have risen on the political agenda. The increase in disinformation campaigns as hostile acts in the context of geopolitical tensions also means that defensive measures serve as deterrence strategies. Like the cybersphere, the information sphere is seen as an extension of physical territory needing credible defence and deterrence.¹ Foreign interference in key political processes such as elections poses an existential risk to democratic states. At the same time, addressing the problem of weaponized disinformation pushes government interventions into the public sphere. Therefore, publicly exposing foreign influence campaigns risks interference with deliberation processes and attracting international attention to a 'structural vulnerability' within democracies.² Decisions by governments to attribute campaigns to state or state-like actors are therefore sensitive and charged with uncertainty. The politics surrounding acts of attribution illustrates why deterring disinformation is a challenge, influenced as much by domestic political considerations as by a need to balance geopolitical interests.\nOver the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an\n* The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.\n¹ Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.\n² Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.\nInternational Affairs 101: 3 (2025) 967–986; DOI: 10.1093/ia/iiaf012\n© The Author(s) 2025. Published by Oxford University Press on behalf of The Royal Institute of International Affairs. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. For commercial re-use, please contact journals.permissions@oup.com\nElsa Hedling and Hedvig Ördén\nopponent's strategic actions through the perception of cost, benefits and risks—remains consistent, strategies and scenarios have widened to achieve this influence. This expansion reflects geopolitical developments—the shift from American supremacy and East-West bipolarity through nuclear balancing and the gradual inclusion of analytical perspectives outside the traditional domains of rationalist International Relations theory.³ Moreover, emerging technologies and the speed and scope in which they change have been firmly integrated into deterrence scholarship as factors influencing the security dilemma—the risk of misinterpretation in situations of uncertainty.⁴\nIn this context of fear over escalation—whether from unchecked provocations or efforts at deterrence—the literature has actively engaged with the cybersphere.⁵ Cyber deterrence poses many additional challenges to the traditional interaction dynamics between the deterrent and the deterred, conceptualized in the central 'attribution problem'.⁶ In the cyber domain, the challenge of identifying a threat actor increases the uncertainty in the deterrence situation.⁷ The ambiguity surrounding the identities of threat actors also exacerbates the disinformation threat, prompting analysts to classify foreign influence campaigns as a subset of cyber attacks.⁸ Consequently, the literature on cyber deterrence and attribution offers a technological solution to identifying the sources of disinformation attacks. The potential to counter the skills and low costs of foreign actors' influence campaigns with an international regime for standardized attribution suggests a reduced advantage for attackers, thereby enhancing deterrence. Although the challenges associated with cyber deterrence offer valuable perspectives on how to address the technical uncertainties of disinformation attacks, this literature obscures the political uncertainties shaping decision-making on attribution in the context of disinformation. The problem of disinformation attribution extends beyond identifying who is responsible and includes the politicization of questions of when and how to attribute.\n³ Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).\n⁴ Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.\n⁵ Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.\n⁶ Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.\n⁷ Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.\n⁸ Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nBy bringing what we call the ‘uncertainty loop’ into focus, this article shows how attribution intersects with deterrence in the disinformation context and offers new opportunities to study, analyse and assess empirical variations in attribution strategies pursued by governments. Over the past decade there has been a marked increase in disinformation attribution efforts, driven by initiatives to enhance resilience and deterrence. This has been especially evident in intensified efforts on the part of western governments following Russia’s 2022 invasion of Ukraine. Although the ‘proof’ underlying attribution is seldom disclosed, the inconsistent application of attribution measures and retrospective criticism of failures to attribute reveal the complex and politically charged nature of these decisions. Showing how the uncertainty loop is at play in different strategies for attribution, and how the interaction between capabilities and timing dictates which sources of uncertainty take precedence when actors assess costs, the article highlights the domestic dynamic of deterrence and answers recent calls for an expansion of the contextual circumstances which condition the use of attribution as deterrence.⁹\nThe aim of this article is threefold. It seeks to: 1) bring together research strands in disinformation studies and the fourth wave of deterrence theory; 2) advance a conceptual framework for attribution as deterrence in the context of disinformation, by introducing the uncertainty loop and laying bare the politics of alternative attribution strategies; and 3) illustrate variations of attribution as deterrence through established empirical cases of foreign interference. Our analysis should not be read as a structured comparison, but as an analysis of how factors related to timing and political context can explain variation in attribution acts. We begin by outlining the state of the art in deterrence theory, the attribution problem and how the latter speaks to the disinformation domain. We then show how uncertainty flows differently when the domestic information sphere is the battlefield. We discuss how and why the uncertainty loop matters in decision-making by disentangling forms of attribution from non-attribution. We conclude by calling for studies that can advance our knowledge about how the pursuit of deterrence is shaped by present-day disinformation, its propagation, and the surrounding domestic and geopolitical contexts.\n## Deterrence and the attribution problem\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’.¹⁰ Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n⁹ Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n¹⁰ Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’.¹¹ While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’,¹² the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack.¹³ Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’¹⁴ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks.¹⁵ Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge.¹⁶ Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment.¹⁷ At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established,¹⁸ causing some scholars to ask whether there could even be ‘such a thing’¹⁹ as a solid case of cyber attribution.\n¹¹ Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n¹² Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n¹³ Libicki, ‘Expectations of cyber deterrence’, p. 51.\n¹⁴ Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n¹⁵ Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n¹⁶ Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n¹⁷ W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n¹⁸ Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n¹⁹ Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard.²⁰ This approach depends on the collection of ‘observable data artifacts’²¹ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’²²—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain.²³ When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’,²⁴ discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’.²⁵ Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments.²⁶ Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’,²⁷ leaving state actors ‘with questions about who to hold accountable’.²⁸ Nevertheless, estab\n20 Milton Mueller, Karl Grindal, Brenden Kuerbis and Farzaneh Badiei, ‘Cyber attribution: can a new institution achieve transnational credibility?’, *The Cyber Defense Review* 4: 1, 2019, pp. 107–24 at p. 108, https://cyberdefensereview.army.mil/Portals/6/9_mueller_cdr_V4N1.pdf.\n21 Brenden Kuerbis, Farzaneh Badiei, Karl Grindal and Milton Mueller, ‘Understanding transnational cyber attribution: moving from “whodunit” to who did it’, in Myriam Dunn Cavelty and Andreas Wenger, eds, *Cyber security politics: socio-technological transformations and political fragmentation* (Abingdon and New York: Routledge, 2022), p. 227.\n22 Kuerbis et al., ‘Understanding transnational cyber attribution’, p. 222.\n23 Mueller et al., ‘Cyber attribution’.\n24 Jon Lindsay and Erik Gartzke, ‘Coercion through cyberspace: the stability–instability paradox revisited’, in Kelly M. Greenhill and Peter Krause, eds, *Coercion: the power to hurt in international politics* (Oxford: Oxford University Press, 2018), p. 192.\n25 Mikael Wigell, ‘Hybrid interference as a wedge strategy: a theory of external interference in liberal democracy’, *International Affairs* 95: 2, 2019, pp. 255–75, https://doi.org/10.1093/ia/iizo96; Elsa Hedling, ‘Transforming practices of diplomacy: the European External Action Service and digital disinformation’, *International Affairs* 97: 3, 2021, pp. 841–59, https://doi.org/10.1093/ia/iiabo35.\n26 James H. Fetzer, ‘Information: does it have to be true?’, *Minds and Machines*, vol. 14, 2004, pp. 223–9, https://doi.org/10.1023/B:MIND.0000021682.61365.56.\n27 Aaron F. Brantly, ‘The cyber deterrence problem’, in *Proceedings of the 10th International Conference on Cyber Conflict (CyCon)*, 2018, p. 45, https://doi.org/10.23919/CYCON.2018.8405009.\n28 Garry S. Floyd, Jr., ‘Attribution and operational art: implications for competing in time’, *Strategic Studies Quarterly* 12: 2, 2018, pp. 17–55, https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-12_Issue-2/Floyd.pdf.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’,²⁹ and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions.³⁰ Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits.³¹ Solutions include behaviour taxonomies, forensic analysis techniques,³² tools for detecting deepfakes³³ and frameworks for identifying social bots.³⁴ As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.³⁵\nTechnological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators.³⁶ An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism³⁷ and the European Union-wide Rapid Alert System.³⁸ The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.³⁹\n39 Henning Lahmann, ‘Infecting the mind: establishing responsibility for transboundary disinformation’, *European Journal of International Law* 33: 2, 2022, pp. 411–40, https://doi.org/10.1093/ejil/chac023.\n40 Anke Sophia Obendiek and Timo Seidl, ‘The (false) promise of solutionism: ideational business power and the construction of epistemic authority in digital security governance’, *Journal of European Public Policy* 30: 7, 2023, pp. 1305–29, https://doi.org/10.1080/13501763.2023.2172060.\n41 Tom Robertson and Teah Pelechaty, *Addressing attribution: theorising a model to identify Russian disinformation campaigns online* (Calgary: Canadian Global Affairs Institute, 2022), https://www.cgai.ca/addressing_attribution_theorizing_a_model_to_identify_russian_disinformation_campaigns_online.\n42 Andrew Dawson and Martin Innes, ‘How Russia’s internet research agency built its disinformation campaign’, *Political Quarterly* 90: 2, 2019, pp. 245–56 at p. 253, https://doi.org/10.1111/1467-923X.12690.\n43 Samuel Henrique Silva et al., ‘Deepfake forensics analysis: an explainable hierarchical ensemble of weakly supervised models’, *Forensic Science International: Synergy*, vol. 4, 2022, https://doi.org/10.1016/j.fsisyn.2022.100217.\n44 Sanjay Goel and Brian Nussbaum, ‘Attribution across cyber attack types: network intrusions and information operations’, *IEEE Open Journal of the Communications Society*, vol. 2, 2021, pp. 1082–93, https://doi.org/10.1109/OJCOMS.2021.3074591.\n45 H. Akin Unver and Arhan S. Ertan, ‘The strategic logic of digital disinformation: offence, defence and deterrence in information warfare’, in Rubén Arcos, Irena Chiru and Cristina Ivan, eds, *Routledge handbook of disinformation and national security* (Abingdon and New York: Routledge, 2024), pp. 192–207.\n46 S. J. Terp and Pablo Breuer, ‘DISARM: a framework for analysis of disinformation campaigns’, in *2022 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)*, 2022, pp. 1–8, https://doi.org/10.1109/CogSIMA54611.2022.9830669.\n47 Nicole J. Jackson, ‘The Canadian government’s response to foreign disinformation: rhetoric, stated policy intentions, and practices’, *International Journal* 76: 4, 2021, pp. 544–63 at p. 560, https://doi.org/10.1177/00207020221076402.\n48 European External Action Service, ‘Tackling disinformation, foreign information manipulation &amp; interference, updated 14 Nov. 2024, https://www.eeas.europa.eu/eeas/tackling-disinformation-foreign-information-manipulation-interference.\n49 Thomas Rid and Ben Buchanan, ‘Attributing cyber attacks’, *Journal of Strategic Studies* 38: 1–2, 2015, pp. 4–37, https://doi.org/10.1080/01402390.2014.977382.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices⁴⁰ and attribution goes beyond identifying a perpetrator.⁴¹ In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’.⁴² Rather than being a means to an end, using naming and shaming as deterrence tactics⁴³ makes attribution into a ‘distinct form of punishment’.⁴⁴ Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’.⁴⁵ Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’⁴⁶ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.⁴⁷\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution).⁴⁸ This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms.⁴⁹ To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation.⁵⁰ Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization.⁵¹ Disinformation as an external threat thereby intersects with essential processes of political deliberation.⁵² The impact of disinformation\n⁴⁰ Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n⁴¹ Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n⁴² J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n⁴³ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁴ Wilner, ‘US cyber deterrence’, pp. 270–1.\n⁴⁵ Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n⁴⁶ Wilner, ‘US cyber deterrence’, p. 171.\n⁴⁷ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁸ Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n⁴⁹ Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n⁵⁰ Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n⁵¹ Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n⁵² Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors,⁵³ or actors from several states working in concert.⁵⁴ For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled.⁵⁵ Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.⁵⁶\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information.⁵⁷ This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts.⁵⁸ In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’⁵⁹ and ‘selectively attribute blame to politicians and media from the opposite side’.⁶⁰ The inherent link between attribution and blame also allows politicians⁶¹ to use attribution as a political tool to ‘delegitimise or attack political opponents’.⁶² By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate.⁶³ While\n⁵³ Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n⁵⁴ Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n⁵⁵ Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n⁵⁶ Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n⁵⁷ Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n⁵⁸ Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n⁵⁹ Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n⁶⁰ Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n⁶¹ Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n⁶² Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n⁶³ Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate,⁶⁴ attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’,⁶⁵ but also to describe citizens or particular communities as ‘useful idiots’⁶⁶ or potential ‘fifth columns’.⁶⁷ The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n# The politics of attribution\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.⁶⁸\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary,⁶⁹ and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\n70 Wilner, 'US cyber deterrence', p. 171.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndistinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFinally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n## Public attribution and its alternatives\nTo further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\n# Public attribution\nSince 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).[78] The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.[79] Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.[80] The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,[81] the Obama administration had intentionally delayed public attribution.\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlatter months of 2016.⁸² Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome.⁸³ Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that\nThe Obama administration ... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.⁸⁴\nWhile the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework.⁸⁵ Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018.⁸⁶ Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi\n⁸² John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n⁸³ Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n⁸⁴ United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n⁸⁵ Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n⁸⁶ US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndent Putin says it's not Russia. I don't see any reason why it would be.⁸⁷ Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.⁸⁸\nBy contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats.⁸⁹ The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security.⁹⁰ The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation.⁹¹ At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic.⁹² In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.\n## Non-attribution\nIn the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany\n⁸⁷ ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\n⁸⁸ Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n⁸⁹ The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n⁹⁰ The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n⁹¹ Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n⁹² RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nbeing a prime target for Russian disinformation efforts among EU member states since 2015,⁹³ successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia.⁹⁴ In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms.⁹⁵ However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful.⁹⁶ Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker.⁹⁷ Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media.⁹⁸ In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images.⁹⁹ Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood.¹⁰⁰ The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter\n⁹³ Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n⁹⁴ Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n⁹⁵ German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n⁹⁶ Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n⁹⁷ Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n⁹⁸ Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n⁹⁹ Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n¹⁰⁰ Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement$^{101}$ and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation,$^{102}$ including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.$^{103}$\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm).$^{104}$ The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).\n## Diffused attribution\nDuring the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms.$^{105}$ Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n$^{101}$ Blumenau, ‘Breaking with convention?’.\n$^{102}$ Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n$^{103}$ Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n$^{104}$ Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n$^{105}$ EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nThe COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’¹⁰⁶ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’¹⁰⁷ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation¹⁰⁸—was disseminated by domestic or intra-EU actors for financial or political gain,¹⁰⁹ or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage,¹¹⁰ and Russia aimed to weaken public trust in European governments’ responses to the pandemic.¹¹¹ In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.¹¹²\nThroughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests.¹¹³ In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,¹¹⁴\n¹⁰⁶ World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n¹⁰⁷ James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n¹⁰⁸ Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n¹⁰⁹ Pamment, *The EU’s role in fighting disinformation*.\n¹¹⁰ Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n¹¹¹ ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n¹¹² Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n¹¹³ Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n¹¹⁴ ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nwhile extremists exploited growing anti-lockdown sentiments within parts of the population.¹¹⁵ These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports¹¹⁶ on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran).¹¹⁷ The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’.¹¹⁸ Following an update in April 2020,¹¹⁹ in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’.¹²⁰ This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors,¹²¹ and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures.¹²² By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.¹²³\n¹¹⁵ Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n¹¹⁶ EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n¹¹⁷ EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n¹¹⁸ EUvsDisinfo, EEAS special report update.\n¹¹⁹ EUvsDisinfo, EEAS special report update.\n¹²⁰ Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n¹²¹ ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n¹²² Borrell, ‘Disinformation around the coronavirus pandemic’.\n¹²³ Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on\nInternational Affairs 101: 3, 2025\nAdditionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia.¹²⁴ Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.¹²⁵\n## Conclusion\nThis article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n¹²⁴ Machado, *Being cautious with attribution*.\n¹²⁵ Machado, *Being cautious with attribution*.\n120",
  "flat_text": "# Disinformation, deterrence and the politics of attribution\nELSA HEDLING AND HEDVIG ÖRDÉN*\nHow do acts of attribution serve liberal states' attempts at deterring foreign influence operations in their public spheres, and why are they enacted so unevenly? This article nuances the sensitive relationship between domestic politics, the narrow framing of disinformation attribution as a technical question of pinpointing attackers' identities, and the role of disinformation as a security threat to be deterred. As foreign influence operations have (re-)emerged as a critical threat to liberal democracy, efforts to assess and effectively counter their effects have risen on the political agenda. The increase in disinformation campaigns as hostile acts in the context of geopolitical tensions also means that defensive measures serve as deterrence strategies. Like the cybersphere, the information sphere is seen as an extension of physical territory needing credible defence and deterrence. Foreign interference in key political processes such as elections poses an existential risk to democratic states. At the same time, addressing the problem of weaponized disinformation pushes government interventions into the public sphere. Therefore, publicly exposing foreign influence campaigns risks interference with deliberation processes and attracting international attention to a 'structural vulnerability' within democracies. Decisions by governments to attribute campaigns to state or state-like actors are therefore sensitive and charged with uncertainty. The politics surrounding acts of attribution illustrates why deterring disinformation is a challenge, influenced as much by domestic political considerations as by a need to balance geopolitical interests.\nOver the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an\n* The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.\n Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.\n Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.\nInternational Affairs 101: 3 (2025) 967–986; DOI: 10.1093/ia/iiaf012\n© The Author(s) 2025. Published by Oxford University Press on behalf of The Royal Institute of International Affairs. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. For commercial re-use, please contact journals.permissions@oup.com\nElsa Hedling and Hedvig Ördén\nopponent's strategic actions through the perception of cost, benefits and risks—remains consistent, strategies and scenarios have widened to achieve this influence. This expansion reflects geopolitical developments—the shift from American supremacy and East-West bipolarity through nuclear balancing and the gradual inclusion of analytical perspectives outside the traditional domains of rationalist International Relations theory. Moreover, emerging technologies and the speed and scope in which they change have been firmly integrated into deterrence scholarship as factors influencing the security dilemma—the risk of misinterpretation in situations of uncertainty.\nIn this context of fear over escalation—whether from unchecked provocations or efforts at deterrence—the literature has actively engaged with the cybersphere. Cyber deterrence poses many additional challenges to the traditional interaction dynamics between the deterrent and the deterred, conceptualized in the central 'attribution problem'. In the cyber domain, the challenge of identifying a threat actor increases the uncertainty in the deterrence situation. The ambiguity surrounding the identities of threat actors also exacerbates the disinformation threat, prompting analysts to classify foreign influence campaigns as a subset of cyber attacks. Consequently, the literature on cyber deterrence and attribution offers a technological solution to identifying the sources of disinformation attacks. The potential to counter the skills and low costs of foreign actors' influence campaigns with an international regime for standardized attribution suggests a reduced advantage for attackers, thereby enhancing deterrence. Although the challenges associated with cyber deterrence offer valuable perspectives on how to address the technical uncertainties of disinformation attacks, this literature obscures the political uncertainties shaping decision-making on attribution in the context of disinformation. The problem of disinformation attribution extends beyond identifying who is responsible and includes the politicization of questions of when and how to attribute.\n Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).\n Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.\n Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.\n Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.\n Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.\n Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nBy bringing what we call the ‘uncertainty loop’ into focus, this article shows how attribution intersects with deterrence in the disinformation context and offers new opportunities to study, analyse and assess empirical variations in attribution strategies pursued by governments. Over the past decade there has been a marked increase in disinformation attribution efforts, driven by initiatives to enhance resilience and deterrence. This has been especially evident in intensified efforts on the part of western governments following Russia’s 2022 invasion of Ukraine. Although the ‘proof’ underlying attribution is seldom disclosed, the inconsistent application of attribution measures and retrospective criticism of failures to attribute reveal the complex and politically charged nature of these decisions. Showing how the uncertainty loop is at play in different strategies for attribution, and how the interaction between capabilities and timing dictates which sources of uncertainty take precedence when actors assess costs, the article highlights the domestic dynamic of deterrence and answers recent calls for an expansion of the contextual circumstances which condition the use of attribution as deterrence.\nThe aim of this article is threefold. It seeks to: 1) bring together research strands in disinformation studies and the fourth wave of deterrence theory; 2) advance a conceptual framework for attribution as deterrence in the context of disinformation, by introducing the uncertainty loop and laying bare the politics of alternative attribution strategies; and 3) illustrate variations of attribution as deterrence through established empirical cases of foreign interference. Our analysis should not be read as a structured comparison, but as an analysis of how factors related to timing and political context can explain variation in attribution acts. We begin by outlining the state of the art in deterrence theory, the attribution problem and how the latter speaks to the disinformation domain. We then show how uncertainty flows differently when the domestic information sphere is the battlefield. We discuss how and why the uncertainty loop matters in decision-making by disentangling forms of attribution from non-attribution. We conclude by calling for studies that can advance our knowledge about how the pursuit of deterrence is shaped by present-day disinformation, its propagation, and the surrounding domestic and geopolitical contexts.\n## Deterrence and the attribution problem\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’. Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’. While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’, the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack. Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks. Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge. Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment. At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established, causing some scholars to ask whether there could even be ‘such a thing’ as a solid case of cyber attribution.\n Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n Libicki, ‘Expectations of cyber deterrence’, p. 51.\n Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard. This approach depends on the collection of ‘observable data artifacts’ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain. When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’, discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’. Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments. Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’, leaving state actors ‘with questions about who to hold accountable’. Nevertheless, estab\n\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’, and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions. Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits. Solutions include behaviour taxonomies, forensic analysis techniques, tools for detecting deepfakes and frameworks for identifying social bots. As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.\nTechnological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators. An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism and the European Union-wide Rapid Alert System. The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.\n\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices and attribution goes beyond identifying a perpetrator. In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’. Rather than being a means to an end, using naming and shaming as deterrence tactics makes attribution into a ‘distinct form of punishment’. Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’. Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution). This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms. To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation. Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization. Disinformation as an external threat thereby intersects with essential processes of political deliberation. The impact of disinformation\n Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n Wilner, ‘US cyber deterrence’, pp. 270–1.\n Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n Wilner, ‘US cyber deterrence’, p. 171.\n Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors, or actors from several states working in concert. For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled. Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information. This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts. In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’ and ‘selectively attribute blame to politicians and media from the opposite side’. The inherent link between attribution and blame also allows politicians to use attribution as a political tool to ‘delegitimise or attack political opponents’. By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate. While\n Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate, attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’, but also to describe citizens or particular communities as ‘useful idiots’ or potential ‘fifth columns’. The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n# The politics of attribution\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary, and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\n\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndistinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFinally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n## Public attribution and its alternatives\nTo further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\n# Public attribution\nSince 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).[78] The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.[79] Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.[80] The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,[81] the Obama administration had intentionally delayed public attribution.\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlatter months of 2016. Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome. Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that\nThe Obama administration ... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.\nWhile the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework. Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018. Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi\n John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndent Putin says it's not Russia. I don't see any reason why it would be. Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.\nBy contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats. The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security. The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation. At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic. In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.\n## Non-attribution\nIn the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany\n ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\n Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nbeing a prime target for Russian disinformation efforts among EU member states since 2015, successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia. In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms. However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful. Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker. Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media. In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images. Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood. The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter\n Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement$^{101}$ and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation,$^{102}$ including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.$^{103}$\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm).$^{104}$ The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).\n## Diffused attribution\nDuring the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms.$^{105}$ Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n$^{101}$ Blumenau, ‘Breaking with convention?’.\n$^{102}$ Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n$^{103}$ Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n$^{104}$ Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n$^{105}$ EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nThe COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation—was disseminated by domestic or intra-EU actors for financial or political gain, or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage, and Russia aimed to weaken public trust in European governments’ responses to the pandemic. In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.\nThroughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests. In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,\n World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n Pamment, *The EU’s role in fighting disinformation*.\n Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nwhile extremists exploited growing anti-lockdown sentiments within parts of the population. These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran). The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’. Following an update in April 2020, in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’. This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors, and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures. By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.\n Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n EUvsDisinfo, EEAS special report update.\n EUvsDisinfo, EEAS special report update.\n Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n Borrell, ‘Disinformation around the coronavirus pandemic’.\n Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on\nInternational Affairs 101: 3, 2025\nAdditionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia. Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.\n## Conclusion\nThis article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n Machado, *Being cautious with attribution*.\n Machado, *Being cautious with attribution*.\n120",
  "toc": [
    [
      1,
      "## Deterrence and the attribution problem"
    ],
    [
      1,
      "## Public attribution and its alternatives To further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis."
    ],
    [
      1,
      "## Non-attribution In the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany ⁸⁷ ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812."
    ],
    [
      1,
      "## Diffused attribution During the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms. Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks."
    ]
  ],
  "sections": {
    "## Deterrence and the attribution problem": "Deterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’.¹⁰ Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n⁹ Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n¹⁰ Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’.¹¹ While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’,¹² the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack.¹³ Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’¹⁴ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks.¹⁵ Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge.¹⁶ Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment.¹⁷ At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established,¹⁸ causing some scholars to ask whether there could even be ‘such a thing’¹⁹ as a solid case of cyber attribution.\n¹¹ Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n¹² Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n¹³ Libicki, ‘Expectations of cyber deterrence’, p. 51.\n¹⁴ Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n¹⁵ Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n¹⁶ Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n¹⁷ W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n¹⁸ Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n¹⁹ Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard.²⁰ This approach depends on the collection of ‘observable data artifacts’²¹ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’²²—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain.²³ When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’,²⁴ discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’.²⁵ Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments.²⁶ Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’,²⁷ leaving state actors ‘with questions about who to hold accountable’.²⁸ Nevertheless, estab\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén lishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’,²⁹ and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions.³⁰ Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits.³¹ Solutions include behaviour taxonomies, forensic analysis techniques,³² tools for detecting deepfakes³³ and frameworks for identifying social bots.³⁴ As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.³⁵ Technological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators.³⁶ An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism³⁷ and the European Union-wide Rapid Alert System.³⁸ The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.³⁹\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices⁴⁰ and attribution goes beyond identifying a perpetrator.⁴¹ In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’.⁴² Rather than being a means to an end, using naming and shaming as deterrence tactics⁴³ makes attribution into a ‘distinct form of punishment’.⁴⁴ Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’.⁴⁵ Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’⁴⁶ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.⁴⁷\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution).⁴⁸ This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms.⁴⁹ To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation.⁵⁰ Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization.⁵¹ Disinformation as an external threat thereby intersects with essential processes of political deliberation.⁵² The impact of disinformation\n⁴⁰ Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n⁴¹ Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n⁴² J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n⁴³ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁴ Wilner, ‘US cyber deterrence’, pp. 270–1.\n⁴⁵ Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n⁴⁶ Wilner, ‘US cyber deterrence’, p. 171.\n⁴⁷ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁸ Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n⁴⁹ Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n⁵⁰ Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n⁵¹ Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n⁵² Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors,⁵³ or actors from several states working in concert.⁵⁴ For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled.⁵⁵ Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.⁵⁶\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information.⁵⁷ This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts.⁵⁸ In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’⁵⁹ and ‘selectively attribute blame to politicians and media from the opposite side’.⁶⁰ The inherent link between attribution and blame also allows politicians⁶¹ to use attribution as a political tool to ‘delegitimise or attack political opponents’.⁶² By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate.⁶³ While\n⁵³ Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n⁵⁴ Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n⁵⁵ Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n⁵⁶ Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n⁵⁷ Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n⁵⁸ Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n⁵⁹ Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n⁶⁰ Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n⁶¹ Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n⁶² Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n⁶³ Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate,⁶⁴ attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’,⁶⁵ but also to describe citizens or particular communities as ‘useful idiots’⁶⁶ or potential ‘fifth columns’.⁶⁷ The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n# The politics of attribution\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.⁶⁸\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary,⁶⁹ and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution distinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén Finally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.",
    "## Public attribution and its alternatives To further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.": "International Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution # Public attribution Since 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).[78] The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.[79] Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.[80] The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,[81] the Obama administration had intentionally delayed public attribution.\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the International Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén latter months of 2016.⁸² Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome.⁸³ Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that The Obama administration... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.⁸⁴ While the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework.⁸⁵ Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018.⁸⁶ Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi ⁸² John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n⁸³ Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n⁸⁴ United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n⁸⁵ Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n⁸⁶ US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution dent Putin says it's not Russia. I don't see any reason why it would be.⁸⁷ Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.⁸⁸ By contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats.⁸⁹ The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security.⁹⁰ The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation.⁹¹ At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic.⁹² In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.",
    "## Non-attribution In the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany ⁸⁷ ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.": "⁸⁸ Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n⁸⁹ The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n⁹⁰ The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n⁹¹ Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n⁹² RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén being a prime target for Russian disinformation efforts among EU member states since 2015,⁹³ successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia.⁹⁴ In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms.⁹⁵ However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful.⁹⁶ Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker.⁹⁷ Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media.⁹⁸ In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images.⁹⁹ Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood.¹⁰⁰ The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter ⁹³ Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n⁹⁴ Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n⁹⁵ German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n⁹⁶ Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n⁹⁷ Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n⁹⁸ Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n⁹⁹ Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n¹⁰⁰ Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution ests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation, including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm). The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).",
    "## Diffused attribution During the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms. Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.": " Blumenau, ‘Breaking with convention?’.\n Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén The COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’¹⁰⁶ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’¹⁰⁷ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation¹⁰⁸—was disseminated by domestic or intra-EU actors for financial or political gain,¹⁰⁹ or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage,¹¹⁰ and Russia aimed to weaken public trust in European governments’ responses to the pandemic.¹¹¹ In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.¹¹² Throughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests.¹¹³ In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,¹¹⁴ ¹⁰⁶ World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n¹⁰⁷ James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n¹⁰⁸ Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n¹⁰⁹ Pamment, *The EU’s role in fighting disinformation*.\n¹¹⁰ Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n¹¹¹ ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n¹¹² Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n¹¹³ Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n¹¹⁴ ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution while extremists exploited growing anti-lockdown sentiments within parts of the population.¹¹⁵ These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports¹¹⁶ on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran).¹¹⁷ The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’.¹¹⁸ Following an update in April 2020,¹¹⁹ in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’.¹²⁰ This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors,¹²¹ and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures.¹²² By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.¹²³ ¹¹⁵ Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n¹¹⁶ EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n¹¹⁷ EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n¹¹⁸ EUvsDisinfo, EEAS special report update.\n¹¹⁹ EUvsDisinfo, EEAS special report update.\n¹²⁰ Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n¹²¹ ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n¹²² Borrell, ‘Disinformation around the coronavirus pandemic’.\n¹²³ Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on International Affairs 101: 3, 2025 Additionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia.¹²⁴ Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.¹²⁵ ## Conclusion This article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n¹²⁴ Machado, *Being cautious with attribution*.\n¹²⁵ Machado, *Being cautious with attribution*.\n120"
  },
  "process_log": {
    "scheme": "markdown",
    "numeric_check": {
      "first_num": null,
      "raw_count": 0,
      "raw_examples": [],
      "filtered_count": 0,
      "filtered_examples": [],
      "seq_score": 0.0
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0
    },
    "toc_count": 4,
    "section_count": 4
  },
  "word_count": 9977,
  "references": [],
  "citations": {
    "style": "superscript",
    "flat_text": "# Disinformation, deterrence and the politics of attribution\nELSA HEDLING AND HEDVIG ÖRDÉN*\nHow do acts of attribution serve liberal states' attempts at deterring foreign influence operations in their public spheres, and why are they enacted so unevenly? This article nuances the sensitive relationship between domestic politics, the narrow framing of disinformation attribution as a technical question of pinpointing attackers' identities, and the role of disinformation as a security threat to be deterred. As foreign influence operations have (re-)emerged as a critical threat to liberal democracy, efforts to assess and effectively counter their effects have risen on the political agenda. The increase in disinformation campaigns as hostile acts in the context of geopolitical tensions also means that defensive measures serve as deterrence strategies. Like the cybersphere, the information sphere is seen as an extension of physical territory needing credible defence and deterrence. Foreign interference in key political processes such as elections poses an existential risk to democratic states. At the same time, addressing the problem of weaponized disinformation pushes government interventions into the public sphere. Therefore, publicly exposing foreign influence campaigns risks interference with deliberation processes and attracting international attention to a 'structural vulnerability' within democracies. Decisions by governments to attribute campaigns to state or state-like actors are therefore sensitive and charged with uncertainty. The politics surrounding acts of attribution illustrates why deterring disinformation is a challenge, influenced as much by domestic political considerations as by a need to balance geopolitical interests.\nOver the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an\n* The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.\n Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.\n Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.\nInternational Affairs 101: 3 (2025) 967–986; DOI: 10.1093/ia/iiaf012\n© The Author(s) 2025. Published by Oxford University Press on behalf of The Royal Institute of International Affairs. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. For commercial re-use, please contact journals.permissions@oup.com\nElsa Hedling and Hedvig Ördén\nopponent's strategic actions through the perception of cost, benefits and risks—remains consistent, strategies and scenarios have widened to achieve this influence. This expansion reflects geopolitical developments—the shift from American supremacy and East-West bipolarity through nuclear balancing and the gradual inclusion of analytical perspectives outside the traditional domains of rationalist International Relations theory. Moreover, emerging technologies and the speed and scope in which they change have been firmly integrated into deterrence scholarship as factors influencing the security dilemma—the risk of misinterpretation in situations of uncertainty.\nIn this context of fear over escalation—whether from unchecked provocations or efforts at deterrence—the literature has actively engaged with the cybersphere. Cyber deterrence poses many additional challenges to the traditional interaction dynamics between the deterrent and the deterred, conceptualized in the central 'attribution problem'. In the cyber domain, the challenge of identifying a threat actor increases the uncertainty in the deterrence situation. The ambiguity surrounding the identities of threat actors also exacerbates the disinformation threat, prompting analysts to classify foreign influence campaigns as a subset of cyber attacks. Consequently, the literature on cyber deterrence and attribution offers a technological solution to identifying the sources of disinformation attacks. The potential to counter the skills and low costs of foreign actors' influence campaigns with an international regime for standardized attribution suggests a reduced advantage for attackers, thereby enhancing deterrence. Although the challenges associated with cyber deterrence offer valuable perspectives on how to address the technical uncertainties of disinformation attacks, this literature obscures the political uncertainties shaping decision-making on attribution in the context of disinformation. The problem of disinformation attribution extends beyond identifying who is responsible and includes the politicization of questions of when and how to attribute.\n Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).\n Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.\n Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.\n Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.\n Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.\n Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nBy bringing what we call the ‘uncertainty loop’ into focus, this article shows how attribution intersects with deterrence in the disinformation context and offers new opportunities to study, analyse and assess empirical variations in attribution strategies pursued by governments. Over the past decade there has been a marked increase in disinformation attribution efforts, driven by initiatives to enhance resilience and deterrence. This has been especially evident in intensified efforts on the part of western governments following Russia’s 2022 invasion of Ukraine. Although the ‘proof’ underlying attribution is seldom disclosed, the inconsistent application of attribution measures and retrospective criticism of failures to attribute reveal the complex and politically charged nature of these decisions. Showing how the uncertainty loop is at play in different strategies for attribution, and how the interaction between capabilities and timing dictates which sources of uncertainty take precedence when actors assess costs, the article highlights the domestic dynamic of deterrence and answers recent calls for an expansion of the contextual circumstances which condition the use of attribution as deterrence.\nThe aim of this article is threefold. It seeks to: 1) bring together research strands in disinformation studies and the fourth wave of deterrence theory; 2) advance a conceptual framework for attribution as deterrence in the context of disinformation, by introducing the uncertainty loop and laying bare the politics of alternative attribution strategies; and 3) illustrate variations of attribution as deterrence through established empirical cases of foreign interference. Our analysis should not be read as a structured comparison, but as an analysis of how factors related to timing and political context can explain variation in attribution acts. We begin by outlining the state of the art in deterrence theory, the attribution problem and how the latter speaks to the disinformation domain. We then show how uncertainty flows differently when the domestic information sphere is the battlefield. We discuss how and why the uncertainty loop matters in decision-making by disentangling forms of attribution from non-attribution. We conclude by calling for studies that can advance our knowledge about how the pursuit of deterrence is shaped by present-day disinformation, its propagation, and the surrounding domestic and geopolitical contexts.\n## Deterrence and the attribution problem\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’. Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’. While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’, the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack. Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks. Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge. Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment. At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established, causing some scholars to ask whether there could even be ‘such a thing’ as a solid case of cyber attribution.\n Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n Libicki, ‘Expectations of cyber deterrence’, p. 51.\n Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard. This approach depends on the collection of ‘observable data artifacts’ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain. When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’, discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’. Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments. Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’, leaving state actors ‘with questions about who to hold accountable’. Nevertheless, estab\n\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’, and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions. Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits. Solutions include behaviour taxonomies, forensic analysis techniques, tools for detecting deepfakes and frameworks for identifying social bots. As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.\nTechnological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators. An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism and the European Union-wide Rapid Alert System. The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.\n\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices and attribution goes beyond identifying a perpetrator. In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’. Rather than being a means to an end, using naming and shaming as deterrence tactics makes attribution into a ‘distinct form of punishment’. Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’. Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution). This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms. To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation. Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization. Disinformation as an external threat thereby intersects with essential processes of political deliberation. The impact of disinformation\n Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n Wilner, ‘US cyber deterrence’, pp. 270–1.\n Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n Wilner, ‘US cyber deterrence’, p. 171.\n Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors, or actors from several states working in concert. For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled. Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information. This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts. In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’ and ‘selectively attribute blame to politicians and media from the opposite side’. The inherent link between attribution and blame also allows politicians to use attribution as a political tool to ‘delegitimise or attack political opponents’. By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate. While\n Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate, attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’, but also to describe citizens or particular communities as ‘useful idiots’ or potential ‘fifth columns’. The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n# The politics of attribution\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary, and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\n\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndistinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFinally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n## Public attribution and its alternatives\nTo further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\n# Public attribution\nSince 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).[78] The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.[79] Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.[80] The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,[81] the Obama administration had intentionally delayed public attribution.\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlatter months of 2016. Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome. Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that\nThe Obama administration ... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.\nWhile the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework. Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018. Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi\n John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndent Putin says it's not Russia. I don't see any reason why it would be. Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.\nBy contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats. The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security. The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation. At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic. In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.\n## Non-attribution\nIn the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany\n ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\n Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nbeing a prime target for Russian disinformation efforts among EU member states since 2015, successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia. In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms. However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful. Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker. Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media. In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images. Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood. The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter\n Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement$^{101}$ and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation,$^{102}$ including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.$^{103}$\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm).$^{104}$ The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).\n## Diffused attribution\nDuring the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms.$^{105}$ Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n$^{101}$ Blumenau, ‘Breaking with convention?’.\n$^{102}$ Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n$^{103}$ Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n$^{104}$ Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n$^{105}$ EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nThe COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation—was disseminated by domestic or intra-EU actors for financial or political gain, or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage, and Russia aimed to weaken public trust in European governments’ responses to the pandemic. In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.\nThroughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests. In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,\n World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n Pamment, *The EU’s role in fighting disinformation*.\n Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nwhile extremists exploited growing anti-lockdown sentiments within parts of the population. These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran). The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’. Following an update in April 2020, in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’. This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors, and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures. By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.\n Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n EUvsDisinfo, EEAS special report update.\n EUvsDisinfo, EEAS special report update.\n Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n Borrell, ‘Disinformation around the coronavirus pandemic’.\n Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on\nInternational Affairs 101: 3, 2025\nAdditionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia. Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.\n## Conclusion\nThis article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n Machado, *Being cautious with attribution*.\n Machado, *Being cautious with attribution*.\n120",
    "footnotes": {
      "items": {},
      "intext": [
        {
          "index": "101",
          "intext_citation": "$^{101}$",
          "preceding_text": "Russia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement",
          "footnote": null
        },
        {
          "index": "102",
          "intext_citation": "$^{102}$",
          "preceding_text": "The German government has made a series of accusations of Russian disinformation,",
          "footnote": null
        },
        {
          "index": "103",
          "intext_citation": "$^{103}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "104",
          "intext_citation": "$^{104}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "105",
          "intext_citation": "$^{105}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "101",
          "intext_citation": "$^{101}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "102",
          "intext_citation": "$^{102}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "103",
          "intext_citation": "$^{103}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "104",
          "intext_citation": "$^{104}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "105",
          "intext_citation": "$^{105}$",
          "preceding_text": "",
          "footnote": null
        }
      ],
      "stats": {
        "intext_total": 10,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 100,
        "missing_intext_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
        ],
        "highest_intext_index": 105,
        "missing_footnotes_for_seen_total": 5,
        "missing_footnotes_for_seen_intext": [
          101,
          102,
          103,
          104,
          105
        ],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 174,
        "success_occurrences": 174,
        "success_unique": 92,
        "bib_unique_total": 93,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.989247311827957,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "",
          "footnote": "Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.",
          "position": 989
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.",
          "position": 1425
        },
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "",
          "footnote": "Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.",
          "position": 2578
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.",
          "position": 2840
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "",
          "footnote": "Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).",
          "position": 4113
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.",
          "position": 4351
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "",
          "footnote": "Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.",
          "position": 4511
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "",
          "footnote": "Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.",
          "position": 4695
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.",
          "position": 4816
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).",
          "position": 5008
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "",
          "footnote": "Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).",
          "position": 5829
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.",
          "position": 6316
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "",
          "footnote": "Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.",
          "position": 6512
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "",
          "footnote": "Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.",
          "position": 6869
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.",
          "position": 7077
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).",
          "position": 7268
        },
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": "",
          "footnote": "Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.",
          "position": 9320
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": "",
          "footnote": "Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.",
          "position": 10997
        },
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": "resume a high order of ratio-\n",
          "footnote": "Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.",
          "position": 11096
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": "",
          "footnote": "Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.",
          "position": 11265
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "",
          "footnote": "Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.",
          "position": 11518
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "ipate what the other will do’,",
          "footnote": "Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.",
          "position": 11630
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "Libicki, ‘Expectations of cyber deterrence’, p. 51.",
          "position": 11794
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": ", signalling ‘meaningful pain’",
          "footnote": "Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.",
          "position": 12170
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.",
          "position": 13059
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.",
          "position": 13279
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.",
          "position": 13520
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "k cannot be fully established,",
          "footnote": "Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.",
          "position": 13615
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "e could even be ‘such a thing’",
          "footnote": "Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.",
          "position": 13689
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "",
          "footnote": "Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.",
          "position": 13730
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "",
          "footnote": "Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.",
          "position": 13851
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "Libicki, ‘Expectations of cyber deterrence’, p. 51.",
          "position": 13983
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "",
          "footnote": "Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.",
          "position": 14038
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.",
          "position": 14171
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.",
          "position": 14661
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.",
          "position": 14903
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.",
          "position": 15030
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "",
          "footnote": "Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.",
          "position": 15195
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "",
          "footnote": "Milton Mueller, Karl Grindal, Brenden Kuerbis and Farzaneh Badiei, ‘Cyber attribution: can a new institution achieve transnational credibility?’, *The Cyber Defense Review* 4: 1, 2019, pp. 107–24 at p. 108, https://cyberdefensereview.army.mil/Portals/6/9_mueller_cdr_V4N1.pdf.",
          "position": 16163
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "of ‘observable data artifacts’",
          "footnote": "Brenden Kuerbis, Farzaneh Badiei, Karl Grindal and Milton Mueller, ‘Understanding transnational cyber attribution: moving from “whodunit” to who did it’, in Myriam Dunn Cavelty and Andreas Wenger, eds, *Cyber security politics: socio-technological transformations and political fragmentation* (Abingdon and New York: Routledge, 2022), p. 227.",
          "position": 16236
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "niques, and procedures (TTPs)’",
          "footnote": "Kuerbis et al., ‘Understanding transnational cyber attribution’, p. 222.",
          "position": 16334
        },
        {
          "index": 23,
          "intext_citation": "²³",
          "preceding_text": "",
          "footnote": "Mueller et al., ‘Cyber attribution’.",
          "position": 16657
        },
        {
          "index": 24,
          "intext_citation": "²⁴",
          "preceding_text": "for ‘deterrence by detection’,",
          "footnote": "Jon Lindsay and Erik Gartzke, ‘Coercion through cyberspace: the stability–instability paradox revisited’, in Kelly M. Greenhill and Peter Krause, eds, *Coercion: the power to hurt in international politics* (Oxford: Oxford University Press, 2018), p. 192.",
          "position": 16776
        },
        {
          "index": 25,
          "intext_citation": "²⁵",
          "preceding_text": "",
          "footnote": "Mikael Wigell, ‘Hybrid interference as a wedge strategy: a theory of external interference in liberal democracy’, *International Affairs* 95: 2, 2019, pp. 255–75, https://doi.org/10.1093/ia/iizo96; Elsa Hedling, ‘Transforming practices of diplomacy: the European External Action Service and digital disinformation’, *International Affairs* 97: 3, 2021, pp. 841–59, https://doi.org/10.1093/ia/iiabo35.",
          "position": 17021
        },
        {
          "index": 26,
          "intext_citation": "²⁶",
          "preceding_text": "",
          "footnote": "James H. Fetzer, ‘Information: does it have to be true?’, *Minds and Machines*, vol. 14, 2004, pp. 223–9, https://doi.org/10.1023/B:MIND.0000021682.61365.56.",
          "position": 17309
        },
        {
          "index": 27,
          "intext_citation": "²⁷",
          "preceding_text": "ially why an attack occurred’,",
          "footnote": "Aaron F. Brantly, ‘The cyber deterrence problem’, in *Proceedings of the 10th International Conference on Cyber Conflict (CyCon)*, 2018, p. 45, https://doi.org/10.23919/CYCON.2018.8405009.",
          "position": 17834
        },
        {
          "index": 28,
          "intext_citation": "²⁸",
          "preceding_text": "",
          "footnote": "Garry S. Floyd, Jr., ‘Attribution and operational art: implications for competing in time’, *Strategic Studies Quarterly* 12: 2, 2018, pp. 17–55, https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-12_Issue-2/Floyd.pdf.",
          "position": 17905
        },
        {
          "index": 39,
          "intext_citation": "³⁹",
          "preceding_text": "",
          "footnote": "Henning Lahmann, ‘Infecting the mind: establishing responsibility for transboundary disinformation’, *European Journal of International Law* 33: 2, 2022, pp. 411–40, https://doi.org/10.1093/ejil/chac023.",
          "position": 21765
        },
        {
          "index": 40,
          "intext_citation": "⁴⁰",
          "preceding_text": "rpinning attribution practices",
          "footnote": "Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.",
          "position": 24823
        },
        {
          "index": 41,
          "intext_citation": "⁴¹",
          "preceding_text": "",
          "footnote": "Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.",
          "position": 24880
        },
        {
          "index": 42,
          "intext_citation": "⁴²",
          "preceding_text": "",
          "footnote": "J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.",
          "position": 25044
        },
        {
          "index": 43,
          "intext_citation": "⁴³",
          "preceding_text": " shaming as deterrence tactics",
          "footnote": "Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.",
          "position": 25130
        },
        {
          "index": 44,
          "intext_citation": "⁴⁴",
          "preceding_text": "",
          "footnote": "Wilner, ‘US cyber deterrence’, pp. 270–1.",
          "position": 25188
        },
        {
          "index": 45,
          "intext_citation": "⁴⁵",
          "preceding_text": "",
          "footnote": "Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.",
          "position": 25288
        },
        {
          "index": 46,
          "intext_citation": "⁴⁶",
          "preceding_text": "ion—and the threat of shaming’",
          "footnote": "Wilner, ‘US cyber deterrence’, p. 171.",
          "position": 25402
        },
        {
          "index": 47,
          "intext_citation": "⁴⁷",
          "preceding_text": "",
          "footnote": "Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.",
          "position": 25655
        },
        {
          "index": 48,
          "intext_citation": "⁴⁸",
          "preceding_text": "",
          "footnote": "Lupovici, ‘The “attribution problem” and the social construction of “violence”’.",
          "position": 25973
        },
        {
          "index": 49,
          "intext_citation": "⁴⁹",
          "preceding_text": "",
          "footnote": "Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.",
          "position": 26178
        },
        {
          "index": 50,
          "intext_citation": "⁵⁰",
          "preceding_text": "",
          "footnote": "Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.",
          "position": 26507
        },
        {
          "index": 51,
          "intext_citation": "⁵¹",
          "preceding_text": "",
          "footnote": "Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.",
          "position": 26657
        },
        {
          "index": 52,
          "intext_citation": "⁵²",
          "preceding_text": "",
          "footnote": "Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.",
          "position": 26767
        },
        {
          "index": 40,
          "intext_citation": "⁴⁰",
          "preceding_text": " The impact of disinformation\n",
          "footnote": "Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.",
          "position": 26799
        },
        {
          "index": 41,
          "intext_citation": "⁴¹",
          "preceding_text": "",
          "footnote": "Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.",
          "position": 27037
        },
        {
          "index": 42,
          "intext_citation": "⁴²",
          "preceding_text": "",
          "footnote": "J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.",
          "position": 27206
        },
        {
          "index": 43,
          "intext_citation": "⁴³",
          "preceding_text": "",
          "footnote": "Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.",
          "position": 27450
        },
        {
          "index": 44,
          "intext_citation": "⁴⁴",
          "preceding_text": "",
          "footnote": "Wilner, ‘US cyber deterrence’, pp. 270–1.",
          "position": 27529
        },
        {
          "index": 45,
          "intext_citation": "⁴⁵",
          "preceding_text": "",
          "footnote": "Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.",
          "position": 27574
        },
        {
          "index": 46,
          "intext_citation": "⁴⁶",
          "preceding_text": "",
          "footnote": "Wilner, ‘US cyber deterrence’, p. 171.",
          "position": 27771
        },
        {
          "index": 47,
          "intext_citation": "⁴⁷",
          "preceding_text": "",
          "footnote": "Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.",
          "position": 27813
        },
        {
          "index": 48,
          "intext_citation": "⁴⁸",
          "preceding_text": "",
          "footnote": "Lupovici, ‘The “attribution problem” and the social construction of “violence”’.",
          "position": 27892
        },
        {
          "index": 49,
          "intext_citation": "⁴⁹",
          "preceding_text": "",
          "footnote": "Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.",
          "position": 27976
        },
        {
          "index": 50,
          "intext_citation": "⁵⁰",
          "preceding_text": "",
          "footnote": "Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.",
          "position": 28068
        },
        {
          "index": 51,
          "intext_citation": "⁵¹",
          "preceding_text": "",
          "footnote": "Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.",
          "position": 28277
        },
        {
          "index": 52,
          "intext_citation": "⁵²",
          "preceding_text": "",
          "footnote": "Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.",
          "position": 28497
        },
        {
          "index": 53,
          "intext_citation": "⁵³",
          "preceding_text": "aigns involve domestic actors,",
          "footnote": "Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.",
          "position": 28868
        },
        {
          "index": 54,
          "intext_citation": "⁵⁴",
          "preceding_text": "",
          "footnote": "Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.",
          "position": 28920
        },
        {
          "index": 55,
          "intext_citation": "⁵⁵",
          "preceding_text": "",
          "footnote": "Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.",
          "position": 29062
        },
        {
          "index": 56,
          "intext_citation": "⁵⁶",
          "preceding_text": "",
          "footnote": "Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.",
          "position": 29304
        },
        {
          "index": 57,
          "intext_citation": "⁵⁷",
          "preceding_text": "",
          "footnote": "Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.",
          "position": 29561
        },
        {
          "index": 58,
          "intext_citation": "⁵⁸",
          "preceding_text": "",
          "footnote": "Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.",
          "position": 29727
        },
        {
          "index": 59,
          "intext_citation": "⁵⁹",
          "preceding_text": " display an ‘attribution bias’",
          "footnote": "Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.",
          "position": 29855
        },
        {
          "index": 60,
          "intext_citation": "⁶⁰",
          "preceding_text": "",
          "footnote": "Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.",
          "position": 29940
        },
        {
          "index": 61,
          "intext_citation": "⁶¹",
          "preceding_text": " blame also allows politicians",
          "footnote": "Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.",
          "position": 30014
        },
        {
          "index": 62,
          "intext_citation": "⁶²",
          "preceding_text": "",
          "footnote": "Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.",
          "position": 30104
        },
        {
          "index": 63,
          "intext_citation": "⁶³",
          "preceding_text": "",
          "footnote": "Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.",
          "position": 30483
        },
        {
          "index": 53,
          "intext_citation": "⁵³",
          "preceding_text": "⁶³ While",
          "footnote": "Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.",
          "position": 30492
        },
        {
          "index": 54,
          "intext_citation": "⁵⁴",
          "preceding_text": "",
          "footnote": "Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.",
          "position": 30758
        },
        {
          "index": 55,
          "intext_citation": "⁵⁵",
          "preceding_text": "",
          "footnote": "Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.",
          "position": 30816
        },
        {
          "index": 56,
          "intext_citation": "⁵⁶",
          "preceding_text": "",
          "footnote": "Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.",
          "position": 31071
        },
        {
          "index": 57,
          "intext_citation": "⁵⁷",
          "preceding_text": "",
          "footnote": "Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.",
          "position": 31363
        },
        {
          "index": 58,
          "intext_citation": "⁵⁸",
          "preceding_text": "",
          "footnote": "Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.",
          "position": 31623
        },
        {
          "index": 59,
          "intext_citation": "⁵⁹",
          "preceding_text": "",
          "footnote": "Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.",
          "position": 31860
        },
        {
          "index": 60,
          "intext_citation": "⁶⁰",
          "preceding_text": "",
          "footnote": "Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.",
          "position": 32109
        },
        {
          "index": 61,
          "intext_citation": "⁶¹",
          "preceding_text": "",
          "footnote": "Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.",
          "position": 32351
        },
        {
          "index": 62,
          "intext_citation": "⁶²",
          "preceding_text": "",
          "footnote": "Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.",
          "position": 32647
        },
        {
          "index": 63,
          "intext_citation": "⁶³",
          "preceding_text": "",
          "footnote": "Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.",
          "position": 32730
        },
        {
          "index": 82,
          "intext_citation": "⁸²",
          "preceding_text": "",
          "footnote": "John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.",
          "position": 46703
        },
        {
          "index": 83,
          "intext_citation": "⁸³",
          "preceding_text": "",
          "footnote": "Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.",
          "position": 47358
        },
        {
          "index": 84,
          "intext_citation": "⁸⁴",
          "preceding_text": "",
          "footnote": "United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.",
          "position": 47937
        },
        {
          "index": 85,
          "intext_citation": "⁸⁵",
          "preceding_text": "",
          "footnote": "Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.",
          "position": 48453
        },
        {
          "index": 86,
          "intext_citation": "⁸⁶",
          "preceding_text": "",
          "footnote": "US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.",
          "position": 49046
        },
        {
          "index": 82,
          "intext_citation": "⁸²",
          "preceding_text": " interference, stating ‘Presi\n",
          "footnote": "John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.",
          "position": 49263
        },
        {
          "index": 83,
          "intext_citation": "⁸³",
          "preceding_text": "",
          "footnote": "Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.",
          "position": 49508
        },
        {
          "index": 84,
          "intext_citation": "⁸⁴",
          "preceding_text": "",
          "footnote": "United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.",
          "position": 49681
        },
        {
          "index": 85,
          "intext_citation": "⁸⁵",
          "preceding_text": "",
          "footnote": "Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.",
          "position": 50025
        },
        {
          "index": 86,
          "intext_citation": "⁸⁶",
          "preceding_text": "",
          "footnote": "US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.",
          "position": 50251
        },
        {
          "index": 87,
          "intext_citation": "⁸⁷",
          "preceding_text": "",
          "footnote": "‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.",
          "position": 50637
        },
        {
          "index": 88,
          "intext_citation": "⁸⁸",
          "preceding_text": "",
          "footnote": "Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.",
          "position": 50821
        },
        {
          "index": 89,
          "intext_citation": "⁸⁹",
          "preceding_text": "",
          "footnote": "The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.",
          "position": 51019
        },
        {
          "index": 90,
          "intext_citation": "⁹⁰",
          "preceding_text": "",
          "footnote": "The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.",
          "position": 51265
        },
        {
          "index": 91,
          "intext_citation": "⁹¹",
          "preceding_text": "",
          "footnote": "Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.",
          "position": 51885
        },
        {
          "index": 92,
          "intext_citation": "⁹²",
          "preceding_text": "",
          "footnote": "RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.",
          "position": 52049
        },
        {
          "index": 87,
          "intext_citation": "⁸⁷",
          "preceding_text": "Despite Germany",
          "footnote": "‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.",
          "position": 52661
        },
        {
          "index": 88,
          "intext_citation": "⁸⁸",
          "preceding_text": "",
          "footnote": "Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.",
          "position": 52794
        },
        {
          "index": 89,
          "intext_citation": "⁸⁹",
          "preceding_text": "",
          "footnote": "The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.",
          "position": 53000
        },
        {
          "index": 90,
          "intext_citation": "⁹⁰",
          "preceding_text": "",
          "footnote": "The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.",
          "position": 53631
        },
        {
          "index": 91,
          "intext_citation": "⁹¹",
          "preceding_text": "",
          "footnote": "Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.",
          "position": 53930
        },
        {
          "index": 92,
          "intext_citation": "⁹²",
          "preceding_text": "",
          "footnote": "RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.",
          "position": 54192
        },
        {
          "index": 93,
          "intext_citation": "⁹³",
          "preceding_text": "g EU member states since 2015,",
          "footnote": "Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.",
          "position": 54594
        },
        {
          "index": 94,
          "intext_citation": "⁹⁴",
          "preceding_text": "",
          "footnote": "Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.",
          "position": 54751
        },
        {
          "index": 95,
          "intext_citation": "⁹⁵",
          "preceding_text": "",
          "footnote": "German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.",
          "position": 55436
        },
        {
          "index": 96,
          "intext_citation": "⁹⁶",
          "preceding_text": "",
          "footnote": "Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).",
          "position": 55607
        },
        {
          "index": 97,
          "intext_citation": "⁹⁷",
          "preceding_text": "",
          "footnote": "Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.",
          "position": 55748
        },
        {
          "index": 98,
          "intext_citation": "⁹⁸",
          "preceding_text": "",
          "footnote": "Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.",
          "position": 55872
        },
        {
          "index": 99,
          "intext_citation": "⁹⁹",
          "preceding_text": "",
          "footnote": "Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.",
          "position": 56001
        },
        {
          "index": 100,
          "intext_citation": "¹⁰⁰",
          "preceding_text": "",
          "footnote": "Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.",
          "position": 56209
        },
        {
          "index": 93,
          "intext_citation": "⁹³",
          "preceding_text": "ressing both deterrence inter\n",
          "footnote": "Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.",
          "position": 56940
        },
        {
          "index": 94,
          "intext_citation": "⁹⁴",
          "preceding_text": "",
          "footnote": "Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.",
          "position": 57133
        },
        {
          "index": 95,
          "intext_citation": "⁹⁵",
          "preceding_text": "",
          "footnote": "German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.",
          "position": 57334
        },
        {
          "index": 96,
          "intext_citation": "⁹⁶",
          "preceding_text": "",
          "footnote": "Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).",
          "position": 57521
        },
        {
          "index": 97,
          "intext_citation": "⁹⁷",
          "preceding_text": "",
          "footnote": "Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.",
          "position": 57971
        },
        {
          "index": 98,
          "intext_citation": "⁹⁸",
          "preceding_text": "",
          "footnote": "Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.",
          "position": 58177
        },
        {
          "index": 99,
          "intext_citation": "⁹⁹",
          "preceding_text": "",
          "footnote": "Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.",
          "position": 58375
        },
        {
          "index": 100,
          "intext_citation": "¹⁰⁰",
          "preceding_text": "",
          "footnote": "Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.",
          "position": 58607
        },
        {
          "index": 106,
          "intext_citation": "¹⁰⁶",
          "preceding_text": " accompanied by an ‘infodemic’",
          "footnote": "World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.",
          "position": 62652
        },
        {
          "index": 107,
          "intext_citation": "¹⁰⁷",
          "preceding_text": "ealth and public safety risks’",
          "footnote": "James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.",
          "position": 62835
        },
        {
          "index": 108,
          "intext_citation": "¹⁰⁸",
          "preceding_text": "ulk of dis- and misinformation",
          "footnote": "Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.",
          "position": 63043
        },
        {
          "index": 109,
          "intext_citation": "¹⁰⁹",
          "preceding_text": "r financial or political gain,",
          "footnote": "Pamment, *The EU’s role in fighting disinformation*.",
          "position": 63127
        },
        {
          "index": 110,
          "intext_citation": "¹¹⁰",
          "preceding_text": "s position on the world stage,",
          "footnote": "Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.",
          "position": 63454
        },
        {
          "index": 111,
          "intext_citation": "¹¹¹",
          "preceding_text": "",
          "footnote": "‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.",
          "position": 63549
        },
        {
          "index": 112,
          "intext_citation": "¹¹²",
          "preceding_text": "",
          "footnote": "Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.",
          "position": 63796
        },
        {
          "index": 113,
          "intext_citation": "¹¹³",
          "preceding_text": "",
          "footnote": "Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.",
          "position": 64151
        },
        {
          "index": 114,
          "intext_citation": "¹¹⁴",
          "preceding_text": "ther support for their causes,",
          "footnote": "‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.",
          "position": 64340
        },
        {
          "index": 106,
          "intext_citation": "¹⁰⁶",
          "preceding_text": " support for their causes,¹¹⁴\n",
          "footnote": "World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.",
          "position": 64344
        },
        {
          "index": 107,
          "intext_citation": "¹⁰⁷",
          "preceding_text": "",
          "footnote": "James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.",
          "position": 64442
        },
        {
          "index": 108,
          "intext_citation": "¹⁰⁸",
          "preceding_text": "",
          "footnote": "Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.",
          "position": 64714
        },
        {
          "index": 109,
          "intext_citation": "¹⁰⁹",
          "preceding_text": "",
          "footnote": "Pamment, *The EU’s role in fighting disinformation*.",
          "position": 64945
        },
        {
          "index": 110,
          "intext_citation": "¹¹⁰",
          "preceding_text": "",
          "footnote": "Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.",
          "position": 65002
        },
        {
          "index": 111,
          "intext_citation": "¹¹¹",
          "preceding_text": "",
          "footnote": "‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.",
          "position": 65341
        },
        {
          "index": 112,
          "intext_citation": "¹¹²",
          "preceding_text": "",
          "footnote": "Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.",
          "position": 65498
        },
        {
          "index": 113,
          "intext_citation": "¹¹³",
          "preceding_text": "",
          "footnote": "Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.",
          "position": 65841
        },
        {
          "index": 114,
          "intext_citation": "¹¹⁴",
          "preceding_text": "",
          "footnote": "‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.",
          "position": 66145
        },
        {
          "index": 115,
          "intext_citation": "¹¹⁵",
          "preceding_text": "",
          "footnote": "Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.",
          "position": 66793
        },
        {
          "index": 116,
          "intext_citation": "¹¹⁶",
          "preceding_text": "ed a series of special reports",
          "footnote": "EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.",
          "position": 67526
        },
        {
          "index": 117,
          "intext_citation": "¹¹⁷",
          "preceding_text": "",
          "footnote": "EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.",
          "position": 67662
        },
        {
          "index": 118,
          "intext_citation": "¹¹⁸",
          "preceding_text": "",
          "footnote": "EUvsDisinfo, EEAS special report update.",
          "position": 67883
        },
        {
          "index": 119,
          "intext_citation": "¹¹⁹",
          "preceding_text": "owing an update in April 2020,",
          "footnote": "EUvsDisinfo, EEAS special report update.",
          "position": 67921
        },
        {
          "index": 120,
          "intext_citation": "¹²⁰",
          "preceding_text": "",
          "footnote": "Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.",
          "position": 68271
        },
        {
          "index": 121,
          "intext_citation": "¹²¹",
          "preceding_text": "ation to Chinese state actors,",
          "footnote": "‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.",
          "position": 68402
        },
        {
          "index": 122,
          "intext_citation": "¹²²",
          "preceding_text": "",
          "footnote": "Borrell, ‘Disinformation around the coronavirus pandemic’.",
          "position": 68586
        },
        {
          "index": 123,
          "intext_citation": "¹²³",
          "preceding_text": "",
          "footnote": "Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on",
          "position": 69320
        },
        {
          "index": 115,
          "intext_citation": "¹¹⁵",
          "preceding_text": "¹²³",
          "footnote": "Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.",
          "position": 69324
        },
        {
          "index": 116,
          "intext_citation": "¹¹⁶",
          "preceding_text": "",
          "footnote": "EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.",
          "position": 69519
        },
        {
          "index": 117,
          "intext_citation": "¹¹⁷",
          "preceding_text": "",
          "footnote": "EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.",
          "position": 69605
        },
        {
          "index": 118,
          "intext_citation": "¹¹⁸",
          "preceding_text": "",
          "footnote": "EUvsDisinfo, EEAS special report update.",
          "position": 69912
        },
        {
          "index": 119,
          "intext_citation": "¹¹⁹",
          "preceding_text": "",
          "footnote": "EUvsDisinfo, EEAS special report update.",
          "position": 69957
        },
        {
          "index": 120,
          "intext_citation": "¹²⁰",
          "preceding_text": "",
          "footnote": "Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.",
          "position": 70002
        },
        {
          "index": 121,
          "intext_citation": "¹²¹",
          "preceding_text": "",
          "footnote": "‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.",
          "position": 70265
        },
        {
          "index": 122,
          "intext_citation": "¹²²",
          "preceding_text": "",
          "footnote": "Borrell, ‘Disinformation around the coronavirus pandemic’.",
          "position": 70437
        },
        {
          "index": 123,
          "intext_citation": "¹²³",
          "preceding_text": "",
          "footnote": "Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on",
          "position": 70500
        },
        {
          "index": 124,
          "intext_citation": "¹²⁴",
          "preceding_text": "",
          "footnote": "Machado, *Being cautious with attribution*.",
          "position": 71243
        },
        {
          "index": 125,
          "intext_citation": "¹²⁵",
          "preceding_text": "",
          "footnote": "Machado, *Being cautious with attribution*.",
          "position": 71563
        },
        {
          "index": 124,
          "intext_citation": "¹²⁴",
          "preceding_text": "",
          "footnote": "Machado, *Being cautious with attribution*.",
          "position": 73583
        },
        {
          "index": 125,
          "intext_citation": "¹²⁵",
          "preceding_text": "",
          "footnote": "Machado, *Being cautious with attribution*.",
          "position": 73631
        }
      ],
      "flat_text": "# Disinformation, deterrence and the politics of attribution\nELSA HEDLING AND HEDVIG ÖRDÉN*\nHow do acts of attribution serve liberal states' attempts at deterring foreign influence operations in their public spheres, and why are they enacted so unevenly? This article nuances the sensitive relationship between domestic politics, the narrow framing of disinformation attribution as a technical question of pinpointing attackers' identities, and the role of disinformation as a security threat to be deterred. As foreign influence operations have (re-)emerged as a critical threat to liberal democracy, efforts to assess and effectively counter their effects have risen on the political agenda. The increase in disinformation campaigns as hostile acts in the context of geopolitical tensions also means that defensive measures serve as deterrence strategies. Like the cybersphere, the information sphere is seen as an extension of physical territory needing credible defence and deterrence. Foreign interference in key political processes such as elections poses an existential risk to democratic states. At the same time, addressing the problem of weaponized disinformation pushes government interventions into the public sphere. Therefore, publicly exposing foreign influence campaigns risks interference with deliberation processes and attracting international attention to a 'structural vulnerability' within democracies. Decisions by governments to attribute campaigns to state or state-like actors are therefore sensitive and charged with uncertainty. The politics surrounding acts of attribution illustrates why deterring disinformation is a challenge, influenced as much by domestic political considerations as by a need to balance geopolitical interests.\nOver the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an\n* The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.\n Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.\n Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.\nInternational Affairs 101: 3 (2025) 967–986; DOI: 10.1093/ia/iiaf012\n© The Author(s) 2025. Published by Oxford University Press on behalf of The Royal Institute of International Affairs. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. For commercial re-use, please contact journals.permissions@oup.com\nElsa Hedling and Hedvig Ördén\nopponent's strategic actions through the perception of cost, benefits and risks—remains consistent, strategies and scenarios have widened to achieve this influence. This expansion reflects geopolitical developments—the shift from American supremacy and East-West bipolarity through nuclear balancing and the gradual inclusion of analytical perspectives outside the traditional domains of rationalist International Relations theory. Moreover, emerging technologies and the speed and scope in which they change have been firmly integrated into deterrence scholarship as factors influencing the security dilemma—the risk of misinterpretation in situations of uncertainty.\nIn this context of fear over escalation—whether from unchecked provocations or efforts at deterrence—the literature has actively engaged with the cybersphere. Cyber deterrence poses many additional challenges to the traditional interaction dynamics between the deterrent and the deterred, conceptualized in the central 'attribution problem'. In the cyber domain, the challenge of identifying a threat actor increases the uncertainty in the deterrence situation. The ambiguity surrounding the identities of threat actors also exacerbates the disinformation threat, prompting analysts to classify foreign influence campaigns as a subset of cyber attacks. Consequently, the literature on cyber deterrence and attribution offers a technological solution to identifying the sources of disinformation attacks. The potential to counter the skills and low costs of foreign actors' influence campaigns with an international regime for standardized attribution suggests a reduced advantage for attackers, thereby enhancing deterrence. Although the challenges associated with cyber deterrence offer valuable perspectives on how to address the technical uncertainties of disinformation attacks, this literature obscures the political uncertainties shaping decision-making on attribution in the context of disinformation. The problem of disinformation attribution extends beyond identifying who is responsible and includes the politicization of questions of when and how to attribute.\n Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).\n Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.\n Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.\n Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.\n Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.\n Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nBy bringing what we call the ‘uncertainty loop’ into focus, this article shows how attribution intersects with deterrence in the disinformation context and offers new opportunities to study, analyse and assess empirical variations in attribution strategies pursued by governments. Over the past decade there has been a marked increase in disinformation attribution efforts, driven by initiatives to enhance resilience and deterrence. This has been especially evident in intensified efforts on the part of western governments following Russia’s 2022 invasion of Ukraine. Although the ‘proof’ underlying attribution is seldom disclosed, the inconsistent application of attribution measures and retrospective criticism of failures to attribute reveal the complex and politically charged nature of these decisions. Showing how the uncertainty loop is at play in different strategies for attribution, and how the interaction between capabilities and timing dictates which sources of uncertainty take precedence when actors assess costs, the article highlights the domestic dynamic of deterrence and answers recent calls for an expansion of the contextual circumstances which condition the use of attribution as deterrence.\nThe aim of this article is threefold. It seeks to: 1) bring together research strands in disinformation studies and the fourth wave of deterrence theory; 2) advance a conceptual framework for attribution as deterrence in the context of disinformation, by introducing the uncertainty loop and laying bare the politics of alternative attribution strategies; and 3) illustrate variations of attribution as deterrence through established empirical cases of foreign interference. Our analysis should not be read as a structured comparison, but as an analysis of how factors related to timing and political context can explain variation in attribution acts. We begin by outlining the state of the art in deterrence theory, the attribution problem and how the latter speaks to the disinformation domain. We then show how uncertainty flows differently when the domestic information sphere is the battlefield. We discuss how and why the uncertainty loop matters in decision-making by disentangling forms of attribution from non-attribution. We conclude by calling for studies that can advance our knowledge about how the pursuit of deterrence is shaped by present-day disinformation, its propagation, and the surrounding domestic and geopolitical contexts.\n## Deterrence and the attribution problem\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’. Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’. While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’, the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack. Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks. Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge. Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment. At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established, causing some scholars to ask whether there could even be ‘such a thing’ as a solid case of cyber attribution.\n Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n Libicki, ‘Expectations of cyber deterrence’, p. 51.\n Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard. This approach depends on the collection of ‘observable data artifacts’ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain. When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’, discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’. Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments. Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’, leaving state actors ‘with questions about who to hold accountable’. Nevertheless, estab\n\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’, and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions. Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits. Solutions include behaviour taxonomies, forensic analysis techniques, tools for detecting deepfakes and frameworks for identifying social bots. As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.\nTechnological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators. An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism and the European Union-wide Rapid Alert System. The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.\n\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices and attribution goes beyond identifying a perpetrator. In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’. Rather than being a means to an end, using naming and shaming as deterrence tactics makes attribution into a ‘distinct form of punishment’. Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’. Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution). This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms. To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation. Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization. Disinformation as an external threat thereby intersects with essential processes of political deliberation. The impact of disinformation\n Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n Wilner, ‘US cyber deterrence’, pp. 270–1.\n Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n Wilner, ‘US cyber deterrence’, p. 171.\n Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors, or actors from several states working in concert. For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled. Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information. This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts. In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’ and ‘selectively attribute blame to politicians and media from the opposite side’. The inherent link between attribution and blame also allows politicians to use attribution as a political tool to ‘delegitimise or attack political opponents’. By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate. While\n Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate, attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’, but also to describe citizens or particular communities as ‘useful idiots’ or potential ‘fifth columns’. The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n# The politics of attribution\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary, and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\n\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndistinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFinally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n## Public attribution and its alternatives\nTo further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\n# Public attribution\nSince 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).[78] The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.[79] Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.[80] The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,[81] the Obama administration had intentionally delayed public attribution.\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlatter months of 2016. Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome. Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that\nThe Obama administration ... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.\nWhile the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework. Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018. Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi\n John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndent Putin says it's not Russia. I don't see any reason why it would be. Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.\nBy contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats. The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security. The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation. At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic. In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.\n## Non-attribution\nIn the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany\n ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\n Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nbeing a prime target for Russian disinformation efforts among EU member states since 2015, successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia. In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms. However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful. Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker. Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media. In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images. Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood. The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter\n Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement$^{101}$ and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation,$^{102}$ including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.$^{103}$\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm).$^{104}$ The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).\n## Diffused attribution\nDuring the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms.$^{105}$ Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n$^{101}$ Blumenau, ‘Breaking with convention?’.\n$^{102}$ Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n$^{103}$ Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n$^{104}$ Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n$^{105}$ EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nThe COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation—was disseminated by domestic or intra-EU actors for financial or political gain, or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage, and Russia aimed to weaken public trust in European governments’ responses to the pandemic. In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.\nThroughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests. In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,\n World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n Pamment, *The EU’s role in fighting disinformation*.\n Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nwhile extremists exploited growing anti-lockdown sentiments within parts of the population. These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran). The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’. Following an update in April 2020, in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’. This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors, and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures. By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.\n Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n EUvsDisinfo, EEAS special report update.\n EUvsDisinfo, EEAS special report update.\n Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n Borrell, ‘Disinformation around the coronavirus pandemic’.\n Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on\nInternational Affairs 101: 3, 2025\nAdditionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia. Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.\n## Conclusion\nThis article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n Machado, *Being cautious with attribution*.\n Machado, *Being cautious with attribution*.\n120"
    },
    "numeric": {
      "total": {
        "intext_total": 12,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "70",
          "intext_citation": "[70]",
          "preceding_text": "Alongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed",
          "footnote": null
        },
        {
          "index": "71",
          "intext_citation": "[71]",
          "preceding_text": "At the same time, governments signal capability and resolve when calling them out.",
          "footnote": null
        },
        {
          "index": "72",
          "intext_citation": "[72]",
          "preceding_text": "rnments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.",
          "footnote": null
        },
        {
          "index": "73",
          "intext_citation": "[73]",
          "preceding_text": "The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',",
          "footnote": null
        },
        {
          "index": "74",
          "intext_citation": "[74]",
          "preceding_text": "The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.",
          "footnote": null
        },
        {
          "index": "75",
          "intext_citation": "[75]",
          "preceding_text": "Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.",
          "footnote": null
        },
        {
          "index": "76",
          "intext_citation": "[76]",
          "preceding_text": "Diffused attribution—for instance EU member states collectively imposing sanctions",
          "footnote": null
        },
        {
          "index": "77",
          "intext_citation": "[77]",
          "preceding_text": "n point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.",
          "footnote": null
        },
        {
          "index": "78",
          "intext_citation": "[78]",
          "preceding_text": "This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).",
          "footnote": null
        },
        {
          "index": "79",
          "intext_citation": "[79]",
          "preceding_text": "President Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.",
          "footnote": null
        },
        {
          "index": "80",
          "intext_citation": "[80]",
          "preceding_text": "of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.",
          "footnote": null
        },
        {
          "index": "81",
          "intext_citation": "[81]",
          "preceding_text": "The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,",
          "footnote": null
        }
      ],
      "flat_text": "# Disinformation, deterrence and the politics of attribution\nELSA HEDLING AND HEDVIG ÖRDÉN*\nHow do acts of attribution serve liberal states' attempts at deterring foreign influence operations in their public spheres, and why are they enacted so unevenly? This article nuances the sensitive relationship between domestic politics, the narrow framing of disinformation attribution as a technical question of pinpointing attackers' identities, and the role of disinformation as a security threat to be deterred. As foreign influence operations have (re-)emerged as a critical threat to liberal democracy, efforts to assess and effectively counter their effects have risen on the political agenda. The increase in disinformation campaigns as hostile acts in the context of geopolitical tensions also means that defensive measures serve as deterrence strategies. Like the cybersphere, the information sphere is seen as an extension of physical territory needing credible defence and deterrence.¹ Foreign interference in key political processes such as elections poses an existential risk to democratic states. At the same time, addressing the problem of weaponized disinformation pushes government interventions into the public sphere. Therefore, publicly exposing foreign influence campaigns risks interference with deliberation processes and attracting international attention to a 'structural vulnerability' within democracies.² Decisions by governments to attribute campaigns to state or state-like actors are therefore sensitive and charged with uncertainty. The politics surrounding acts of attribution illustrates why deterring disinformation is a challenge, influenced as much by domestic political considerations as by a need to balance geopolitical interests.\nOver the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an\n* The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.\n¹ Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.\n² Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.\nInternational Affairs 101: 3 (2025) 967–986; DOI: 10.1093/ia/iiaf012\n© The Author(s) 2025. Published by Oxford University Press on behalf of The Royal Institute of International Affairs. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. For commercial re-use, please contact journals.permissions@oup.com\nElsa Hedling and Hedvig Ördén\nopponent's strategic actions through the perception of cost, benefits and risks—remains consistent, strategies and scenarios have widened to achieve this influence. This expansion reflects geopolitical developments—the shift from American supremacy and East-West bipolarity through nuclear balancing and the gradual inclusion of analytical perspectives outside the traditional domains of rationalist International Relations theory.³ Moreover, emerging technologies and the speed and scope in which they change have been firmly integrated into deterrence scholarship as factors influencing the security dilemma—the risk of misinterpretation in situations of uncertainty.⁴\nIn this context of fear over escalation—whether from unchecked provocations or efforts at deterrence—the literature has actively engaged with the cybersphere.⁵ Cyber deterrence poses many additional challenges to the traditional interaction dynamics between the deterrent and the deterred, conceptualized in the central 'attribution problem'.⁶ In the cyber domain, the challenge of identifying a threat actor increases the uncertainty in the deterrence situation.⁷ The ambiguity surrounding the identities of threat actors also exacerbates the disinformation threat, prompting analysts to classify foreign influence campaigns as a subset of cyber attacks.⁸ Consequently, the literature on cyber deterrence and attribution offers a technological solution to identifying the sources of disinformation attacks. The potential to counter the skills and low costs of foreign actors' influence campaigns with an international regime for standardized attribution suggests a reduced advantage for attackers, thereby enhancing deterrence. Although the challenges associated with cyber deterrence offer valuable perspectives on how to address the technical uncertainties of disinformation attacks, this literature obscures the political uncertainties shaping decision-making on attribution in the context of disinformation. The problem of disinformation attribution extends beyond identifying who is responsible and includes the politicization of questions of when and how to attribute.\n³ Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).\n⁴ Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.\n⁵ Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.\n⁶ Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.\n⁷ Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.\n⁸ Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nBy bringing what we call the ‘uncertainty loop’ into focus, this article shows how attribution intersects with deterrence in the disinformation context and offers new opportunities to study, analyse and assess empirical variations in attribution strategies pursued by governments. Over the past decade there has been a marked increase in disinformation attribution efforts, driven by initiatives to enhance resilience and deterrence. This has been especially evident in intensified efforts on the part of western governments following Russia’s 2022 invasion of Ukraine. Although the ‘proof’ underlying attribution is seldom disclosed, the inconsistent application of attribution measures and retrospective criticism of failures to attribute reveal the complex and politically charged nature of these decisions. Showing how the uncertainty loop is at play in different strategies for attribution, and how the interaction between capabilities and timing dictates which sources of uncertainty take precedence when actors assess costs, the article highlights the domestic dynamic of deterrence and answers recent calls for an expansion of the contextual circumstances which condition the use of attribution as deterrence.⁹\nThe aim of this article is threefold. It seeks to: 1) bring together research strands in disinformation studies and the fourth wave of deterrence theory; 2) advance a conceptual framework for attribution as deterrence in the context of disinformation, by introducing the uncertainty loop and laying bare the politics of alternative attribution strategies; and 3) illustrate variations of attribution as deterrence through established empirical cases of foreign interference. Our analysis should not be read as a structured comparison, but as an analysis of how factors related to timing and political context can explain variation in attribution acts. We begin by outlining the state of the art in deterrence theory, the attribution problem and how the latter speaks to the disinformation domain. We then show how uncertainty flows differently when the domestic information sphere is the battlefield. We discuss how and why the uncertainty loop matters in decision-making by disentangling forms of attribution from non-attribution. We conclude by calling for studies that can advance our knowledge about how the pursuit of deterrence is shaped by present-day disinformation, its propagation, and the surrounding domestic and geopolitical contexts.\n## Deterrence and the attribution problem\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’.¹⁰ Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n⁹ Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n¹⁰ Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’.¹¹ While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’,¹² the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack.¹³ Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’¹⁴ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks.¹⁵ Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge.¹⁶ Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment.¹⁷ At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established,¹⁸ causing some scholars to ask whether there could even be ‘such a thing’¹⁹ as a solid case of cyber attribution.\n¹¹ Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n¹² Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n¹³ Libicki, ‘Expectations of cyber deterrence’, p. 51.\n¹⁴ Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n¹⁵ Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n¹⁶ Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n¹⁷ W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n¹⁸ Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n¹⁹ Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard.²⁰ This approach depends on the collection of ‘observable data artifacts’²¹ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’²²—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain.²³ When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’,²⁴ discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’.²⁵ Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments.²⁶ Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’,²⁷ leaving state actors ‘with questions about who to hold accountable’.²⁸ Nevertheless, estab\n20 Milton Mueller, Karl Grindal, Brenden Kuerbis and Farzaneh Badiei, ‘Cyber attribution: can a new institution achieve transnational credibility?’, *The Cyber Defense Review* 4: 1, 2019, pp. 107–24 at p. 108, https://cyberdefensereview.army.mil/Portals/6/9_mueller_cdr_V4N1.pdf.\n21 Brenden Kuerbis, Farzaneh Badiei, Karl Grindal and Milton Mueller, ‘Understanding transnational cyber attribution: moving from “whodunit” to who did it’, in Myriam Dunn Cavelty and Andreas Wenger, eds, *Cyber security politics: socio-technological transformations and political fragmentation* (Abingdon and New York: Routledge, 2022), p. 227.\n22 Kuerbis et al., ‘Understanding transnational cyber attribution’, p. 222.\n23 Mueller et al., ‘Cyber attribution’.\n24 Jon Lindsay and Erik Gartzke, ‘Coercion through cyberspace: the stability–instability paradox revisited’, in Kelly M. Greenhill and Peter Krause, eds, *Coercion: the power to hurt in international politics* (Oxford: Oxford University Press, 2018), p. 192.\n25 Mikael Wigell, ‘Hybrid interference as a wedge strategy: a theory of external interference in liberal democracy’, *International Affairs* 95: 2, 2019, pp. 255–75, https://doi.org/10.1093/ia/iizo96; Elsa Hedling, ‘Transforming practices of diplomacy: the European External Action Service and digital disinformation’, *International Affairs* 97: 3, 2021, pp. 841–59, https://doi.org/10.1093/ia/iiabo35.\n26 James H. Fetzer, ‘Information: does it have to be true?’, *Minds and Machines*, vol. 14, 2004, pp. 223–9, https://doi.org/10.1023/B:MIND.0000021682.61365.56.\n27 Aaron F. Brantly, ‘The cyber deterrence problem’, in *Proceedings of the 10th International Conference on Cyber Conflict (CyCon)*, 2018, p. 45, https://doi.org/10.23919/CYCON.2018.8405009.\n28 Garry S. Floyd, Jr., ‘Attribution and operational art: implications for competing in time’, *Strategic Studies Quarterly* 12: 2, 2018, pp. 17–55, https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-12_Issue-2/Floyd.pdf.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’,²⁹ and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions.³⁰ Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits.³¹ Solutions include behaviour taxonomies, forensic analysis techniques,³² tools for detecting deepfakes³³ and frameworks for identifying social bots.³⁴ As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.³⁵\nTechnological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators.³⁶ An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism³⁷ and the European Union-wide Rapid Alert System.³⁸ The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.³⁹\n39 Henning Lahmann, ‘Infecting the mind: establishing responsibility for transboundary disinformation’, *European Journal of International Law* 33: 2, 2022, pp. 411–40, https://doi.org/10.1093/ejil/chac023.\n40 Anke Sophia Obendiek and Timo Seidl, ‘The (false) promise of solutionism: ideational business power and the construction of epistemic authority in digital security governance’, *Journal of European Public Policy* 30: 7, 2023, pp. 1305–29, https://doi.org/10.1080/13501763.2023.2172060.\n41 Tom Robertson and Teah Pelechaty, *Addressing attribution: theorising a model to identify Russian disinformation campaigns online* (Calgary: Canadian Global Affairs Institute, 2022), https://www.cgai.ca/addressing_attribution_theorizing_a_model_to_identify_russian_disinformation_campaigns_online.\n42 Andrew Dawson and Martin Innes, ‘How Russia’s internet research agency built its disinformation campaign’, *Political Quarterly* 90: 2, 2019, pp. 245–56 at p. 253, https://doi.org/10.1111/1467-923X.12690.\n43 Samuel Henrique Silva et al., ‘Deepfake forensics analysis: an explainable hierarchical ensemble of weakly supervised models’, *Forensic Science International: Synergy*, vol. 4, 2022, https://doi.org/10.1016/j.fsisyn.2022.100217.\n44 Sanjay Goel and Brian Nussbaum, ‘Attribution across cyber attack types: network intrusions and information operations’, *IEEE Open Journal of the Communications Society*, vol. 2, 2021, pp. 1082–93, https://doi.org/10.1109/OJCOMS.2021.3074591.\n45 H. Akin Unver and Arhan S. Ertan, ‘The strategic logic of digital disinformation: offence, defence and deterrence in information warfare’, in Rubén Arcos, Irena Chiru and Cristina Ivan, eds, *Routledge handbook of disinformation and national security* (Abingdon and New York: Routledge, 2024), pp. 192–207.\n46 S. J. Terp and Pablo Breuer, ‘DISARM: a framework for analysis of disinformation campaigns’, in *2022 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)*, 2022, pp. 1–8, https://doi.org/10.1109/CogSIMA54611.2022.9830669.\n47 Nicole J. Jackson, ‘The Canadian government’s response to foreign disinformation: rhetoric, stated policy intentions, and practices’, *International Journal* 76: 4, 2021, pp. 544–63 at p. 560, https://doi.org/10.1177/00207020221076402.\n48 European External Action Service, ‘Tackling disinformation, foreign information manipulation &amp; interference, updated 14 Nov. 2024, https://www.eeas.europa.eu/eeas/tackling-disinformation-foreign-information-manipulation-interference.\n49 Thomas Rid and Ben Buchanan, ‘Attributing cyber attacks’, *Journal of Strategic Studies* 38: 1–2, 2015, pp. 4–37, https://doi.org/10.1080/01402390.2014.977382.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices⁴⁰ and attribution goes beyond identifying a perpetrator.⁴¹ In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’.⁴² Rather than being a means to an end, using naming and shaming as deterrence tactics⁴³ makes attribution into a ‘distinct form of punishment’.⁴⁴ Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’.⁴⁵ Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’⁴⁶ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.⁴⁷\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution).⁴⁸ This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms.⁴⁹ To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation.⁵⁰ Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization.⁵¹ Disinformation as an external threat thereby intersects with essential processes of political deliberation.⁵² The impact of disinformation\n⁴⁰ Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n⁴¹ Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n⁴² J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n⁴³ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁴ Wilner, ‘US cyber deterrence’, pp. 270–1.\n⁴⁵ Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n⁴⁶ Wilner, ‘US cyber deterrence’, p. 171.\n⁴⁷ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁸ Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n⁴⁹ Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n⁵⁰ Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n⁵¹ Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n⁵² Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors,⁵³ or actors from several states working in concert.⁵⁴ For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled.⁵⁵ Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.⁵⁶\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information.⁵⁷ This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts.⁵⁸ In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’⁵⁹ and ‘selectively attribute blame to politicians and media from the opposite side’.⁶⁰ The inherent link between attribution and blame also allows politicians⁶¹ to use attribution as a political tool to ‘delegitimise or attack political opponents’.⁶² By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate.⁶³ While\n⁵³ Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n⁵⁴ Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n⁵⁵ Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n⁵⁶ Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n⁵⁷ Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n⁵⁸ Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n⁵⁹ Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n⁶⁰ Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n⁶¹ Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n⁶² Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n⁶³ Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate,⁶⁴ attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’,⁶⁵ but also to describe citizens or particular communities as ‘useful idiots’⁶⁶ or potential ‘fifth columns’.⁶⁷ The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n# The politics of attribution\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.⁶⁸\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary,⁶⁹ and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\n70 Wilner, 'US cyber deterrence', p. 171.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndistinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out. In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories. The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood', including perceived levels of resilience. If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected. In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFinally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation. This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n## Public attribution and its alternatives\nTo further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\n# Public attribution\nSince 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI). The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'. Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy. The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July, the Obama administration had intentionally delayed public attribution.\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nlatter months of 2016.⁸² Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome.⁸³ Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that\nThe Obama administration ... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.⁸⁴\nWhile the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework.⁸⁵ Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018.⁸⁶ Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi\n⁸² John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n⁸³ Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n⁸⁴ United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n⁸⁵ Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n⁸⁶ US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\ndent Putin says it's not Russia. I don't see any reason why it would be.⁸⁷ Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.⁸⁸\nBy contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats.⁸⁹ The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security.⁹⁰ The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation.⁹¹ At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic.⁹² In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.\n## Non-attribution\nIn the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany\n⁸⁷ ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\n⁸⁸ Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n⁸⁹ The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n⁹⁰ The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n⁹¹ Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n⁹² RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nbeing a prime target for Russian disinformation efforts among EU member states since 2015,⁹³ successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia.⁹⁴ In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms.⁹⁵ However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful.⁹⁶ Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker.⁹⁷ Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media.⁹⁸ In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images.⁹⁹ Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood.¹⁰⁰ The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter\n⁹³ Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n⁹⁴ Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n⁹⁵ German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n⁹⁶ Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n⁹⁷ Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n⁹⁸ Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n⁹⁹ Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n¹⁰⁰ Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement$^{101}$ and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation,$^{102}$ including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.$^{103}$\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm).$^{104}$ The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).\n## Diffused attribution\nDuring the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms.$^{105}$ Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n$^{101}$ Blumenau, ‘Breaking with convention?’.\n$^{102}$ Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n$^{103}$ Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n$^{104}$ Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n$^{105}$ EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nThe COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’¹⁰⁶ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’¹⁰⁷ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation¹⁰⁸—was disseminated by domestic or intra-EU actors for financial or political gain,¹⁰⁹ or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage,¹¹⁰ and Russia aimed to weaken public trust in European governments’ responses to the pandemic.¹¹¹ In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.¹¹²\nThroughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests.¹¹³ In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,¹¹⁴\n¹⁰⁶ World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n¹⁰⁷ James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n¹⁰⁸ Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n¹⁰⁹ Pamment, *The EU’s role in fighting disinformation*.\n¹¹⁰ Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n¹¹¹ ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n¹¹² Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n¹¹³ Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n¹¹⁴ ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nwhile extremists exploited growing anti-lockdown sentiments within parts of the population.¹¹⁵ These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports¹¹⁶ on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran).¹¹⁷ The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’.¹¹⁸ Following an update in April 2020,¹¹⁹ in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’.¹²⁰ This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors,¹²¹ and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures.¹²² By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.¹²³\n¹¹⁵ Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n¹¹⁶ EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n¹¹⁷ EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n¹¹⁸ EUvsDisinfo, EEAS special report update.\n¹¹⁹ EUvsDisinfo, EEAS special report update.\n¹²⁰ Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n¹²¹ ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n¹²² Borrell, ‘Disinformation around the coronavirus pandemic’.\n¹²³ Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on\nInternational Affairs 101: 3, 2025\nAdditionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia.¹²⁴ Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.¹²⁵\n## Conclusion\nThis article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n¹²⁴ Machado, *Being cautious with attribution*.\n¹²⁵ Machado, *Being cautious with attribution*.\n120"
    },
    "author_year": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 79,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [],
      "flat_text": "# Disinformation, deterrence and the politics of attribution\nELSA HEDLING AND HEDVIG ÖRDÉN*\nHow do acts of attribution serve liberal states' attempts at deterring foreign influence operations in their public spheres, and why are they enacted so unevenly? This article nuances the sensitive relationship between domestic politics, the narrow framing of disinformation attribution as a technical question of pinpointing attackers' identities, and the role of disinformation as a security threat to be deterred. As foreign influence operations have (re-)emerged as a critical threat to liberal democracy, efforts to assess and effectively counter their effects have risen on the political agenda. The increase in disinformation campaigns as hostile acts in the context of geopolitical tensions also means that defensive measures serve as deterrence strategies. Like the cybersphere, the information sphere is seen as an extension of physical territory needing credible defence and deterrence.¹ Foreign interference in key political processes such as elections poses an existential risk to democratic states. At the same time, addressing the problem of weaponized disinformation pushes government interventions into the public sphere. Therefore, publicly exposing foreign influence campaigns risks interference with deliberation processes and attracting international attention to a 'structural vulnerability' within democracies.² Decisions by governments to attribute campaigns to state or state-like actors are therefore sensitive and charged with uncertainty. The politics surrounding acts of attribution illustrates why deterring disinformation is a challenge, influenced as much by domestic political considerations as by a need to balance geopolitical interests.\nOver the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an\n* The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.\n¹ Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.\n² Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.\nInternational Affairs 101: 3 (2025) 967–986; DOI: 10.1093/ia/iiaf012\n© The Author(s) 2025. Published by Oxford University Press on behalf of The Royal Institute of International Affairs. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. For commercial re-use, please contact journals.permissions@oup.com\nElsa Hedling and Hedvig Ördén\nopponent's strategic actions through the perception of cost, benefits and risks—remains consistent, strategies and scenarios have widened to achieve this influence. This expansion reflects geopolitical developments—the shift from American supremacy and East-West bipolarity through nuclear balancing and the gradual inclusion of analytical perspectives outside the traditional domains of rationalist International Relations theory.³ Moreover, emerging technologies and the speed and scope in which they change have been firmly integrated into deterrence scholarship as factors influencing the security dilemma—the risk of misinterpretation in situations of uncertainty.⁴\nIn this context of fear over escalation—whether from unchecked provocations or efforts at deterrence—the literature has actively engaged with the cybersphere.⁵ Cyber deterrence poses many additional challenges to the traditional interaction dynamics between the deterrent and the deterred, conceptualized in the central 'attribution problem'.⁶ In the cyber domain, the challenge of identifying a threat actor increases the uncertainty in the deterrence situation.⁷ The ambiguity surrounding the identities of threat actors also exacerbates the disinformation threat, prompting analysts to classify foreign influence campaigns as a subset of cyber attacks.⁸ Consequently, the literature on cyber deterrence and attribution offers a technological solution to identifying the sources of disinformation attacks. The potential to counter the skills and low costs of foreign actors' influence campaigns with an international regime for standardized attribution suggests a reduced advantage for attackers, thereby enhancing deterrence. Although the challenges associated with cyber deterrence offer valuable perspectives on how to address the technical uncertainties of disinformation attacks, this literature obscures the political uncertainties shaping decision-making on attribution in the context of disinformation. The problem of disinformation attribution extends beyond identifying who is responsible and includes the politicization of questions of when and how to attribute.\n³ Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).\n⁴ Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.\n⁵ Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.\n⁶ Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.\n⁷ Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.\n⁸ Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nBy bringing what we call the ‘uncertainty loop’ into focus, this article shows how attribution intersects with deterrence in the disinformation context and offers new opportunities to study, analyse and assess empirical variations in attribution strategies pursued by governments. Over the past decade there has been a marked increase in disinformation attribution efforts, driven by initiatives to enhance resilience and deterrence. This has been especially evident in intensified efforts on the part of western governments following Russia’s 2022 invasion of Ukraine. Although the ‘proof’ underlying attribution is seldom disclosed, the inconsistent application of attribution measures and retrospective criticism of failures to attribute reveal the complex and politically charged nature of these decisions. Showing how the uncertainty loop is at play in different strategies for attribution, and how the interaction between capabilities and timing dictates which sources of uncertainty take precedence when actors assess costs, the article highlights the domestic dynamic of deterrence and answers recent calls for an expansion of the contextual circumstances which condition the use of attribution as deterrence.⁹\nThe aim of this article is threefold. It seeks to: 1) bring together research strands in disinformation studies and the fourth wave of deterrence theory; 2) advance a conceptual framework for attribution as deterrence in the context of disinformation, by introducing the uncertainty loop and laying bare the politics of alternative attribution strategies; and 3) illustrate variations of attribution as deterrence through established empirical cases of foreign interference. Our analysis should not be read as a structured comparison, but as an analysis of how factors related to timing and political context can explain variation in attribution acts. We begin by outlining the state of the art in deterrence theory, the attribution problem and how the latter speaks to the disinformation domain. We then show how uncertainty flows differently when the domestic information sphere is the battlefield. We discuss how and why the uncertainty loop matters in decision-making by disentangling forms of attribution from non-attribution. We conclude by calling for studies that can advance our knowledge about how the pursuit of deterrence is shaped by present-day disinformation, its propagation, and the surrounding domestic and geopolitical contexts.\n## Deterrence and the attribution problem\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’.¹⁰ Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n⁹ Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n¹⁰ Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’.¹¹ While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’,¹² the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack.¹³ Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’¹⁴ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks.¹⁵ Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge.¹⁶ Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment.¹⁷ At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established,¹⁸ causing some scholars to ask whether there could even be ‘such a thing’¹⁹ as a solid case of cyber attribution.\n¹¹ Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n¹² Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n¹³ Libicki, ‘Expectations of cyber deterrence’, p. 51.\n¹⁴ Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n¹⁵ Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n¹⁶ Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n¹⁷ W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n¹⁸ Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n¹⁹ Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard.²⁰ This approach depends on the collection of ‘observable data artifacts’²¹ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’²²—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain.²³ When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’,²⁴ discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’.²⁵ Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments.²⁶ Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’,²⁷ leaving state actors ‘with questions about who to hold accountable’.²⁸ Nevertheless, estab\n\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén lishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’,²⁹ and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions.³⁰ Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits.³¹ Solutions include behaviour taxonomies, forensic analysis techniques,³² tools for detecting deepfakes³³ and frameworks for identifying social bots.³⁴ As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.³⁵ Technological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators.³⁶ An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism³⁷ and the European Union-wide Rapid Alert System.³⁸ The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.³⁹\n\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices⁴⁰ and attribution goes beyond identifying a perpetrator.⁴¹ In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’.⁴² Rather than being a means to an end, using naming and shaming as deterrence tactics⁴³ makes attribution into a ‘distinct form of punishment’.⁴⁴ Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’.⁴⁵ Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’⁴⁶ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.⁴⁷\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution).⁴⁸ This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms.⁴⁹ To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation.⁵⁰ Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization.⁵¹ Disinformation as an external threat thereby intersects with essential processes of political deliberation.⁵² The impact of disinformation\n⁴⁰ Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n⁴¹ Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n⁴² J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n⁴³ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁴ Wilner, ‘US cyber deterrence’, pp. 270–1.\n⁴⁵ Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n⁴⁶ Wilner, ‘US cyber deterrence’, p. 171.\n⁴⁷ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁸ Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n⁴⁹ Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n⁵⁰ Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n⁵¹ Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n⁵² Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors,⁵³ or actors from several states working in concert.⁵⁴ For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled.⁵⁵ Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.⁵⁶\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information.⁵⁷ This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts.⁵⁸ In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’⁵⁹ and ‘selectively attribute blame to politicians and media from the opposite side’.⁶⁰ The inherent link between attribution and blame also allows politicians⁶¹ to use attribution as a political tool to ‘delegitimise or attack political opponents’.⁶² By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate.⁶³ While\n⁵³ Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n⁵⁴ Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n⁵⁵ Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n⁵⁶ Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n⁵⁷ Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n⁵⁸ Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n⁵⁹ Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n⁶⁰ Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n⁶¹ Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n⁶² Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n⁶³ Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate,⁶⁴ attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’,⁶⁵ but also to describe citizens or particular communities as ‘useful idiots’⁶⁶ or potential ‘fifth columns’.⁶⁷ The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n# The politics of attribution\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.⁶⁸\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary,⁶⁹ and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\n\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution distinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén Finally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n## Public attribution and its alternatives To further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution # Public attribution Since 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).[78] The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.[79] Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.[80] The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,[81] the Obama administration had intentionally delayed public attribution.\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the International Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén latter months of 2016.⁸² Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome.⁸³ Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that The Obama administration... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.⁸⁴ While the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework.⁸⁵ Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018.⁸⁶ Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi ⁸² John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n⁸³ Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n⁸⁴ United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n⁸⁵ Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n⁸⁶ US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution dent Putin says it's not Russia. I don't see any reason why it would be.⁸⁷ Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.⁸⁸ By contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats.⁸⁹ The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security.⁹⁰ The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation.⁹¹ At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic.⁹² In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.\n## Non-attribution In the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany ⁸⁷ ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\n⁸⁸ Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n⁸⁹ The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n⁹⁰ The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n⁹¹ Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n⁹² RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén being a prime target for Russian disinformation efforts among EU member states since 2015,⁹³ successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia.⁹⁴ In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms.⁹⁵ However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful.⁹⁶ Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker.⁹⁷ Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media.⁹⁸ In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images.⁹⁹ Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood.¹⁰⁰ The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter ⁹³ Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n⁹⁴ Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n⁹⁵ German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n⁹⁶ Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n⁹⁷ Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n⁹⁸ Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n⁹⁹ Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n¹⁰⁰ Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution ests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation, including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm). The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).\n## Diffused attribution During the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms. Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n Blumenau, ‘Breaking with convention?’.\n Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén The COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’¹⁰⁶ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’¹⁰⁷ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation¹⁰⁸—was disseminated by domestic or intra-EU actors for financial or political gain,¹⁰⁹ or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage,¹¹⁰ and Russia aimed to weaken public trust in European governments’ responses to the pandemic.¹¹¹ In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.¹¹² Throughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests.¹¹³ In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,¹¹⁴ ¹⁰⁶ World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n¹⁰⁷ James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n¹⁰⁸ Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n¹⁰⁹ Pamment, *The EU’s role in fighting disinformation*.\n¹¹⁰ Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n¹¹¹ ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n¹¹² Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n¹¹³ Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n¹¹⁴ ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution while extremists exploited growing anti-lockdown sentiments within parts of the population.¹¹⁵ These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports¹¹⁶ on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran).¹¹⁷ The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’.¹¹⁸ Following an update in April 2020,¹¹⁹ in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’.¹²⁰ This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors,¹²¹ and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures.¹²² By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.¹²³ ¹¹⁵ Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n¹¹⁶ EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n¹¹⁷ EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic, https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n¹¹⁸ EUvsDisinfo, EEAS special report update.\n¹¹⁹ EUvsDisinfo, EEAS special report update.\n¹²⁰ Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n¹²¹ ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n¹²² Borrell, ‘Disinformation around the coronavirus pandemic’.\n¹²³ Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on International Affairs 101: 3, 2025 Additionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia.¹²⁴ Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.¹²⁵ ## Conclusion This article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n¹²⁴ Machado, *Being cautious with attribution*.\n¹²⁵ Machado, *Being cautious with attribution*.\n120"
    }
  },
  "summary": {
    "full_text": {
      "words": 10674,
      "tokens": 16026
    },
    "flat_text": {
      "words": 9977,
      "tokens": 14577
    }
  },
  "payload": "## ## Deterrence and the attribution problem\n\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’.¹⁰ Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n⁹ Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n¹⁰ Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nnality and calculability’.¹¹ While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’,¹² the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack.¹³ Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’¹⁴ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks.¹⁵ Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge.¹⁶ Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment.¹⁷ At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established,¹⁸ causing some scholars to ask whether there could even be ‘such a thing’¹⁹ as a solid case of cyber attribution.\n¹¹ Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n¹² Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n¹³ Libicki, ‘Expectations of cyber deterrence’, p. 51.\n¹⁴ Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n¹⁵ Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n¹⁶ Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n¹⁷ W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n¹⁸ Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n¹⁹ Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard.²⁰ This approach depends on the collection of ‘observable data artifacts’²¹ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’²²—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain.²³ When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’,²⁴ discouraging potential attackers by signalling a high likelihood of detection and punishment.\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’.²⁵ Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments.²⁶ Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’,²⁷ leaving state actors ‘with questions about who to hold accountable’.²⁸ Nevertheless, estab\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén lishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’,²⁹ and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions.³⁰ Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits.³¹ Solutions include behaviour taxonomies, forensic analysis techniques,³² tools for detecting deepfakes³³ and frameworks for identifying social bots.³⁴ As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.³⁵ Technological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators.³⁶ An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism³⁷ and the European Union-wide Rapid Alert System.³⁸ The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.³⁹\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices⁴⁰ and attribution goes beyond identifying a perpetrator.⁴¹ In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’.⁴² Rather than being a means to an end, using naming and shaming as deterrence tactics⁴³ makes attribution into a ‘distinct form of punishment’.⁴⁴ Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’.⁴⁵ Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’⁴⁶ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.⁴⁷\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution).⁴⁸ This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms.⁴⁹ To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation.⁵⁰ Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization.⁵¹ Disinformation as an external threat thereby intersects with essential processes of political deliberation.⁵² The impact of disinformation\n⁴⁰ Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n⁴¹ Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n⁴² J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n⁴³ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁴ Wilner, ‘US cyber deterrence’, pp. 270–1.\n⁴⁵ Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n⁴⁶ Wilner, ‘US cyber deterrence’, p. 171.\n⁴⁷ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n⁴⁸ Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n⁴⁹ Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n⁵⁰ Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n⁵¹ Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n⁵² Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors,⁵³ or actors from several states working in concert.⁵⁴ For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled.⁵⁵ Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.⁵⁶\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information.⁵⁷ This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts.⁵⁸ In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’⁵⁹ and ‘selectively attribute blame to politicians and media from the opposite side’.⁶⁰ The inherent link between attribution and blame also allows politicians⁶¹ to use attribution as a political tool to ‘delegitimise or attack political opponents’.⁶² By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate.⁶³ While\n⁵³ Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n⁵⁴ Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n⁵⁵ Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n⁵⁶ Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n⁵⁷ Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n⁵⁸ Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n⁵⁹ Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n⁶⁰ Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n⁶¹ Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n⁶² Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n⁶³ Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\nInternational Affairs 101: 3, 2025\nDisinformation, deterrence and the politics of attribution\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate,⁶⁴ attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’,⁶⁵ but also to describe citizens or particular communities as ‘useful idiots’⁶⁶ or potential ‘fifth columns’.⁶⁷ The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.⁶⁸\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary,⁶⁹ and brings a domestic component into deterrence theory.\nInternational Affairs 101: 3, 2025\nElsa Hedling and Hedvig Ördén\nFigure 1: The uncertainty loop\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution distinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén Finally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n\n---\n\n## ## Diffused attribution During the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms. Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n\nBlumenau, ‘Breaking with convention?’.\n Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\nInternational Affairs 101: 3, 2025 Elsa Hedling and Hedvig Ördén The COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’¹⁰⁶ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’¹⁰⁷ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation¹⁰⁸—was disseminated by domestic or intra-EU actors for financial or political gain,¹⁰⁹ or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage,¹¹⁰ and Russia aimed to weaken public trust in European governments’ responses to the pandemic.¹¹¹ In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.¹¹² Throughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests.¹¹³ In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,¹¹⁴ ¹⁰⁶ World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n¹⁰⁷ James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n¹⁰⁸ Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n¹⁰⁹ Pamment, *The EU’s role in fighting disinformation*.\n¹¹⁰ Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n¹¹¹ ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n¹¹² Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n¹¹³ Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n¹¹⁴ ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\nInternational Affairs 101: 3, 2025 Disinformation, deterrence and the politics of attribution while extremists exploited growing anti-lockdown sentiments within parts of the population.¹¹⁵ These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports¹¹⁶ on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran).¹¹⁷ The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’.¹¹⁸ Following an update in April 2020,¹¹⁹ in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’.¹²⁰ This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors,¹²¹ and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures.¹²² By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.¹²³ ¹¹⁵ Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n¹¹⁶ EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n¹¹⁷ EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n¹¹⁸ EUvsDisinfo, EEAS special report update.\n¹¹⁹ EUvsDisinfo, EEAS special report update.\n¹²⁰ Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n¹²¹ ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n¹²² Borrell, ‘Disinformation around the coronavirus pandemic’.\n¹²³ Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on International Affairs 101: 3, 2025 Additionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia.¹²⁴ Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.¹²⁵ ## Conclusion This article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\nChina, 2020), p. 179.\n¹²⁴ Machado, *Being cautious with attribution*.\n¹²⁵ Machado, *Being cautious with attribution*.\n120",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:PARTIAL_BODY\nsections_raw:4\nsections_clean:4\nintro:FOUND\nconclusion:FOUND\npredefined_sections:None\nextra_sections:None\npayload_tokens_before:12669\npayload_tokens_after:10680\ndropped_section:## Non-attribution In the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany ⁸⁷ ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\nadded_section:None\n---LOG_SUMMARY_END---",
  "pages_text": [
    "# Disinformation, deterrence and the politics of attribution\n\nELSA HEDLING AND HEDVIG ÖRDÉN*\n\nHow do acts of attribution serve liberal states' attempts at deterring foreign influence operations in their public spheres, and why are they enacted so unevenly? This article nuances the sensitive relationship between domestic politics, the narrow framing of disinformation attribution as a technical question of pinpointing attackers' identities, and the role of disinformation as a security threat to be deterred. As foreign influence operations have (re-)emerged as a critical threat to liberal democracy, efforts to assess and effectively counter their effects have risen on the political agenda. The increase in disinformation campaigns as hostile acts in the context of geopolitical tensions also means that defensive measures serve as deterrence strategies. Like the cybersphere, the information sphere is seen as an extension of physical territory needing credible defence and deterrence.¹ Foreign interference in key political processes such as elections poses an existential risk to democratic states. At the same time, addressing the problem of weaponized disinformation pushes government interventions into the public sphere. Therefore, publicly exposing foreign influence campaigns risks interference with deliberation processes and attracting international attention to a 'structural vulnerability' within democracies.² Decisions by governments to attribute campaigns to state or state-like actors are therefore sensitive and charged with uncertainty. The politics surrounding acts of attribution illustrates why deterring disinformation is a challenge, influenced as much by domestic political considerations as by a need to balance geopolitical interests.\n\nOver the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an\n\n* The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.\n\n¹ Randolph H. Pherson, Penelope Mort Ranta and Casey Cannon, ‘Strategies for combating the scourge of digital disinformation’, International Journal of Intelligence and Counter Intelligence 34: 2, 2021, pp. 316–41, https://doi.org/10.1080/08850607.2020.1789425.\n\n² Spencer McKay and Chris Tenove, ‘Disinformation as a threat to deliberative democracy’, Political Research Quarterly 74: 3, 2020, pp. 703–17, https://doi.org/10.1177/1065912920938143.\n\nInternational Affairs 101: 3 (2025) 967–986; DOI: 10.1093/ia/iiaf012\n\n© The Author(s) 2025. Published by Oxford University Press on behalf of The Royal Institute of International Affairs. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits non-commercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. For commercial re-use, please contact journals.permissions@oup.com",
    "Elsa Hedling and Hedvig Ördén\n\nopponent's strategic actions through the perception of cost, benefits and risks—remains consistent, strategies and scenarios have widened to achieve this influence. This expansion reflects geopolitical developments—the shift from American supremacy and East-West bipolarity through nuclear balancing and the gradual inclusion of analytical perspectives outside the traditional domains of rationalist International Relations theory.³ Moreover, emerging technologies and the speed and scope in which they change have been firmly integrated into deterrence scholarship as factors influencing the security dilemma—the risk of misinterpretation in situations of uncertainty.⁴\n\nIn this context of fear over escalation—whether from unchecked provocations or efforts at deterrence—the literature has actively engaged with the cybersphere.⁵ Cyber deterrence poses many additional challenges to the traditional interaction dynamics between the deterrent and the deterred, conceptualized in the central 'attribution problem'.⁶ In the cyber domain, the challenge of identifying a threat actor increases the uncertainty in the deterrence situation.⁷ The ambiguity surrounding the identities of threat actors also exacerbates the disinformation threat, prompting analysts to classify foreign influence campaigns as a subset of cyber attacks.⁸ Consequently, the literature on cyber deterrence and attribution offers a technological solution to identifying the sources of disinformation attacks. The potential to counter the skills and low costs of foreign actors' influence campaigns with an international regime for standardized attribution suggests a reduced advantage for attackers, thereby enhancing deterrence. Although the challenges associated with cyber deterrence offer valuable perspectives on how to address the technical uncertainties of disinformation attacks, this literature obscures the political uncertainties shaping decision-making on attribution in the context of disinformation. The problem of disinformation attribution extends beyond identifying who is responsible and includes the politicization of questions of when and how to attribute.\n\n³ Amir Lupovici, ‘The emerging fourth wave of deterrence theory—toward a new research agenda’, *International Studies Quarterly* 54: 3, 2010, pp. 705–32, https://doi.org/10.1111/j.1468-2478.2010.00606.x; Alex Wilner, ‘Deterrence by de-legitimisation in the information environment: concept, theory, and practice’, in Eric Ouellet, Madeleine D’Agata and Keith Stewart, eds, *Deterrence in the 21st century: statecraft in the information age* (Calgary: University of Calgary Press, 2024).\n\n⁴ Amir Lupovici, ‘Ontological security, cyber technology, and states’ responses’, *European Journal of International Relations* 29: 1, 2023, pp. 153–78, https://doi.org/10.1177/13540661221130958.\n\n⁵ Myriam Dunn Cavelty, ‘Breaking the cyber-security dilemma: aligning security needs and removing vulnerabilities’, *Science and Engineering Ethics*, vol. 20, 2014, pp. 701–15, https://doi.org/10.1007/s11948-014-9551-y; Carly E. Beckerman, ‘Is there a cyber security dilemma?’, *Journal of Cybersecurity* 8: 1, 2022, https://doi.org/10.1093/cybsec/tyac012.\n\n⁶ Jon R. Lindsay, ‘Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack’, *Journal of Cybersecurity* 1: 1, 2015, pp. 53–67, https://doi.org/10.1093/cybsec/tyv003.\n\n⁷ Florian Skopik and Timea Pahi, ‘Under false flag: using technical artifacts for cyber attack attribution’, *Cybersecurity* 3: 8, 2020, pp. 1–20. https://doi.org/10.1186/s42400-020-00048-4.\n\n⁸ Cyber attacks target information security through malware, viruses and trojans. Disinformation spreads misappropriated information, manipulated data or deepfakes to sow discord in the public sphere. However, cyber attacks and disinformation campaigns are often pursued in tandem by diffusing leaks manipulated by false information. An example is the case of the ‘Macron leaks’ in 2017. See for instance: Jean-Baptiste Jeangène Vilmer, *The ‘Macron leaks’ operation: a post-mortem* (Washington DC: Atlantic Council, 2019), https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf. (Unless otherwise noted at point of citation, all URLs cited in this article were accessible on 14 Feb. 2025.).\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\nBy bringing what we call the ‘uncertainty loop’ into focus, this article shows how attribution intersects with deterrence in the disinformation context and offers new opportunities to study, analyse and assess empirical variations in attribution strategies pursued by governments. Over the past decade there has been a marked increase in disinformation attribution efforts, driven by initiatives to enhance resilience and deterrence. This has been especially evident in intensified efforts on the part of western governments following Russia’s 2022 invasion of Ukraine. Although the ‘proof’ underlying attribution is seldom disclosed, the inconsistent application of attribution measures and retrospective criticism of failures to attribute reveal the complex and politically charged nature of these decisions. Showing how the uncertainty loop is at play in different strategies for attribution, and how the interaction between capabilities and timing dictates which sources of uncertainty take precedence when actors assess costs, the article highlights the domestic dynamic of deterrence and answers recent calls for an expansion of the contextual circumstances which condition the use of attribution as deterrence.⁹\n\nThe aim of this article is threefold. It seeks to: 1) bring together research strands in disinformation studies and the fourth wave of deterrence theory; 2) advance a conceptual framework for attribution as deterrence in the context of disinformation, by introducing the uncertainty loop and laying bare the politics of alternative attribution strategies; and 3) illustrate variations of attribution as deterrence through established empirical cases of foreign interference. Our analysis should not be read as a structured comparison, but as an analysis of how factors related to timing and political context can explain variation in attribution acts. We begin by outlining the state of the art in deterrence theory, the attribution problem and how the latter speaks to the disinformation domain. We then show how uncertainty flows differently when the domestic information sphere is the battlefield. We discuss how and why the uncertainty loop matters in decision-making by disentangling forms of attribution from non-attribution. We conclude by calling for studies that can advance our knowledge about how the pursuit of deterrence is shaped by present-day disinformation, its propagation, and the surrounding domestic and geopolitical contexts.\n\n## Deterrence and the attribution problem\n\nDeterrence is a tool of statecraft used to prevent an adversary from taking an undesirable course of action. The traditional deterrence theory was developed in a Cold War context of nuclear threats and builds heavily on rationalist assumptions. As Miller underlines, deterrence ‘relies on leaders who are rational enough, informed enough, and value their lives and positions of power’.¹⁰ Deterrence involves cost-benefit calculations which ‘necessarily presume a high order of ratio-\n\n⁹ Alex S. Wilner, ‘US cyber deterrence: practice guiding theory’, *Journal of Strategic Studies* 43: 2, 2020, pp. 245–80, https://doi.org/10.1080/01402390.2018.1563779.\n\n¹⁰ Michael Miller, ‘Nuclear attribution as deterrence’, *The Nonproliferation Review* 14: 1, 2007, pp. 33–60 at p. 43, https://doi.org/10.1080/10736700601178465.\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\nnality and calculability’.¹¹ While any cost-benefit calculation suffers from uncertainty in trying to ‘anticipate what the other will do’,¹² the kinetic weaponry upon which deterrence theory was originally moulded allows actors to estimate the threat and the vulnerability of an adversary to an attack.¹³ Taking such assumptions as a point of departure, an adversary’s desired response can be instigated by raising the (perception of) costs involved in pursuing a particular path of action. This can be achieved by signalling a potential punishment or denying an adversary the necessary capabilities to act. Credible retaliation threats are crucial, signalling ‘meaningful pain’¹⁴ to deter actors from harmful behaviour. Effective attribution capabilities furthermore play a central part as adversaries must weigh the likelihood of being caught. Thus, attribution is critical to the cost-benefit analysis central to deterrence logic.\n\nAs deterrence logic is applied to a novel range of threats—some non-kinetic and asymmetric—the question of attribution emerges as an intricate and pervasive ‘problem’. The cybersecurity literature on deterrence has seen longstanding discussions about the ‘attribution problem’. Cyber attacks are cheaper than kinetic threats, enabling state and non-state actors to interact more equally. The vast number of potential cyber threat actors complicates attribution. Accentuating this problem, threat actors actively exploit the opportunities to obfuscate their identities due to technical issues with traceability in multi-stage attacks.¹⁵ Even if the technological devices employed in an attack can be pinpointed, tracing attacks back to individuals or groups and, in a further step, establishing credible links to state threat actors presents a challenge.¹⁶ Additionally, assessing damage in the cyber domain is more complex than in the kinetic domain. The early cyber deterrence literature therefore emphasizes ‘perfect technical attribution’ as essential for effective deterrence by punishment.¹⁷ At the same time, sometimes even the ‘nature’ of a cyber attack cannot be fully established,¹⁸ causing some scholars to ask whether there could even be ‘such a thing’¹⁹ as a solid case of cyber attribution.\n\n¹¹ Martin C. Libicki, ‘Expectations of cyber deterrence’, *Strategic Studies Quarterly* 12: 4, 2018, pp. 44–57 at p. 47.\n¹² Robert Jervis, ‘Some thoughts on deterrence in the cyber era’, *Journal of Information Warfare* 15: 2, 2016, pp. 66–73 at p. 68.\n¹³ Libicki, ‘Expectations of cyber deterrence’, p. 51.\n¹⁴ Ben Buchanan, ‘Cyber deterrence isn’t MAD; it’s mosaic’, *Georgetown Journal of International Affairs*, vol. 4, 2014, pp. 130–40.\n¹⁵ Richard Clayton, *Anonymity and traceability in cyberspace* (Cambridge, UK: University of Cambridge, Computer Laboratory, 2005), https://doi.org/10.48456/tr-653; National Research Council, *Proceedings of a workshop on deterring cyberattacks: informing strategies and developing options for US policy* (Washington DC: National Academies Press, 2010); Herbert Lin, ‘Attribution of malicious cyber incidents: from soup to nuts’, *Journal of International Affairs* 70: 1, 2016, pp. 75–137.\n¹⁶ Ronald J. Deibert, Rafal Rohozinski and Masashi Crete-Nishihata, ‘Cyclones in cyberspace: information shaping and denial in the 2008 Russia–Georgia war’, *Security Dialogue* 43: 1, 2012, pp. 3–24, https://doi.org/10.1177/0967010611431079.\n¹⁷ W. Earl Boebert, ‘A survey of challenges in attribution’, in National Research Council, *Proceedings of a workshop*, p. 51.\n¹⁸ Susan W. Brenner, ‘At light speed: attribution and response to cybercrime/terrorism/warfare’, *Journal of Criminal Law and Criminology* 97: 2, 2007, pp. 379–475.\n¹⁹ Brian Bartholomew and Juan Andres Guerrero-Saade, *Wave your false flags! Deception tactics muddying attribution in targeted attacks*, paper presented at Virus Bulletin Conference, Denver, CO, 5–7 Oct. 2016, p. ix, available at https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\nThe cybersecurity literature has produced various technological and methodological solutions to address the attribution problem. Researchers and practitioners have developed advanced tools and techniques to enhance attribution capabilities, improve threat detection and strengthen defences. Many analyses support a two-pronged approach, involving technical expertise in ‘threat intelligence and digital forensics experts advising decision-makers’ in combination with international agreements on a common forensic standard.²⁰ This approach depends on the collection of ‘observable data artifacts’²¹ and information on threat actors’ behaviours—their ‘tactics, techniques, and procedures (TTPs)’²²—to build a credible case for attribution. Such methods address the uncertainties of cyber attacks through predictive modelling, enabling actors to estimate the likelihood of an attack by a specific actor. Technical advancements have significantly improved the potential for identifying threat actors in the cyber domain.²³ When technical capabilities are credibly communicated, they also generate a potential for ‘deterrence by detection’,²⁴ discouraging potential attackers by signalling a high likelihood of detection and punishment.\n\nDisinformation, like cyber attacks, stems from the digital age, and both are sometimes referred to as ‘hybrid threats’ or tools of ‘hybrid warfare’.²⁵ Still, they differ significantly in their methods and objectives, as well as their impacts on individuals, organizations and societies. Cyber attacks target technological systems and infrastructure directly, whereas disinformation targets human perception and information environments.²⁶ Nonetheless they are frequently linked, as threat actors often use them together. A cyber attack may precede or follow a foreign influence campaign with the goal of undermining a society or disrupting a political process. For instance, the hacked emails of political candidates can be used to diffuse a disinformation campaign by introducing fake documents among authentic content. Like cyber attacks, a disinformation attack introduces difficulties with ‘attribution of who, what, and potentially why an attack occurred’,²⁷ leaving state actors ‘with questions about who to hold accountable’.²⁸ Nevertheless, estab\n\n20 Milton Mueller, Karl Grindal, Brenden Kuerbis and Farzaneh Badiei, ‘Cyber attribution: can a new institution achieve transnational credibility?’, *The Cyber Defense Review* 4: 1, 2019, pp. 107–24 at p. 108, https://cyberdefensereview.army.mil/Portals/6/9_mueller_cdr_V4N1.pdf.\n21 Brenden Kuerbis, Farzaneh Badiei, Karl Grindal and Milton Mueller, ‘Understanding transnational cyber attribution: moving from “whodunit” to who did it’, in Myriam Dunn Cavelty and Andreas Wenger, eds, *Cyber security politics: socio-technological transformations and political fragmentation* (Abingdon and New York: Routledge, 2022), p. 227.\n22 Kuerbis et al., ‘Understanding transnational cyber attribution’, p. 222.\n23 Mueller et al., ‘Cyber attribution’.\n24 Jon Lindsay and Erik Gartzke, ‘Coercion through cyberspace: the stability–instability paradox revisited’, in Kelly M. Greenhill and Peter Krause, eds, *Coercion: the power to hurt in international politics* (Oxford: Oxford University Press, 2018), p. 192.\n25 Mikael Wigell, ‘Hybrid interference as a wedge strategy: a theory of external interference in liberal democracy’, *International Affairs* 95: 2, 2019, pp. 255–75, https://doi.org/10.1093/ia/iizo96; Elsa Hedling, ‘Transforming practices of diplomacy: the European External Action Service and digital disinformation’, *International Affairs* 97: 3, 2021, pp. 841–59, https://doi.org/10.1093/ia/iiabo35.\n26 James H. Fetzer, ‘Information: does it have to be true?’, *Minds and Machines*, vol. 14, 2004, pp. 223–9, https://doi.org/10.1023/B:MIND.0000021682.61365.56.\n27 Aaron F. Brantly, ‘The cyber deterrence problem’, in *Proceedings of the 10th International Conference on Cyber Conflict (CyCon)*, 2018, p. 45, https://doi.org/10.23919/CYCON.2018.8405009.\n28 Garry S. Floyd, Jr., ‘Attribution and operational art: implications for competing in time’, *Strategic Studies Quarterly* 12: 2, 2018, pp. 17–55, https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-12_Issue-2/Floyd.pdf.\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\nlishing intent is necessary in a context where ‘many different actors spread false and misleading information constantly and without necessarily pursuing distinct or readily identifiable aims’,²⁹ and framing the problem of disinformation deterrence in technological terms paves the way for technological solutions.³⁰ Inspired by cybersecurity, disinformation studies have developed complex methods to identify threat actors and disinformation traits.³¹ Solutions include behaviour taxonomies, forensic analysis techniques,³² tools for detecting deepfakes³³ and frameworks for identifying social bots.³⁴ As with ‘deterrence by detection’ within cybersecurity, this forensic monitoring enables punishment of malicious actors and signals deterrence capabilities to potential offenders.³⁵\n\nTechnological solutions to the attribution problem also underpin contemporary policy practices on foreign information influence. Concerns with identifying behaviours are embedded in the widely used DISARM framework outlining the TTPs of disinformation perpetrators.³⁶ An overarching focus on identifying ‘foreign’ threat actors in the information environment has similarly contributed to international agreements and cooperation on information-sharing between allies, such as the G7 Rapid Response Mechanism³⁷ and the European Union-wide Rapid Alert System.³⁸ The promise of establishing such recognized attribution frameworks is to put in place a standardized and transparent approach, thereby increasing the legitimacy of attribution statements.\n\nWhile improving the understanding of threat actor behaviours, the cybersecurity approach to disinformation attribution overlooks a key point from constructivist deterrence scholars: deterrence is also influenced by the political stakes involved.³⁹\n\n39 Henning Lahmann, ‘Infecting the mind: establishing responsibility for transboundary disinformation’, *European Journal of International Law* 33: 2, 2022, pp. 411–40, https://doi.org/10.1093/ejil/chac023.\n40 Anke Sophia Obendiek and Timo Seidl, ‘The (false) promise of solutionism: ideational business power and the construction of epistemic authority in digital security governance’, *Journal of European Public Policy* 30: 7, 2023, pp. 1305–29, https://doi.org/10.1080/13501763.2023.2172060.\n41 Tom Robertson and Teah Pelechaty, *Addressing attribution: theorising a model to identify Russian disinformation campaigns online* (Calgary: Canadian Global Affairs Institute, 2022), https://www.cgai.ca/addressing_attribution_theorizing_a_model_to_identify_russian_disinformation_campaigns_online.\n42 Andrew Dawson and Martin Innes, ‘How Russia’s internet research agency built its disinformation campaign’, *Political Quarterly* 90: 2, 2019, pp. 245–56 at p. 253, https://doi.org/10.1111/1467-923X.12690.\n43 Samuel Henrique Silva et al., ‘Deepfake forensics analysis: an explainable hierarchical ensemble of weakly supervised models’, *Forensic Science International: Synergy*, vol. 4, 2022, https://doi.org/10.1016/j.fsisyn.2022.100217.\n44 Sanjay Goel and Brian Nussbaum, ‘Attribution across cyber attack types: network intrusions and information operations’, *IEEE Open Journal of the Communications Society*, vol. 2, 2021, pp. 1082–93, https://doi.org/10.1109/OJCOMS.2021.3074591.\n45 H. Akin Unver and Arhan S. Ertan, ‘The strategic logic of digital disinformation: offence, defence and deterrence in information warfare’, in Rubén Arcos, Irena Chiru and Cristina Ivan, eds, *Routledge handbook of disinformation and national security* (Abingdon and New York: Routledge, 2024), pp. 192–207.\n46 S. J. Terp and Pablo Breuer, ‘DISARM: a framework for analysis of disinformation campaigns’, in *2022 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)*, 2022, pp. 1–8, https://doi.org/10.1109/CogSIMA54611.2022.9830669.\n47 Nicole J. Jackson, ‘The Canadian government’s response to foreign disinformation: rhetoric, stated policy intentions, and practices’, *International Journal* 76: 4, 2021, pp. 544–63 at p. 560, https://doi.org/10.1177/00207020221076402.\n48 European External Action Service, ‘Tackling disinformation, foreign information manipulation &amp; interference, updated 14 Nov. 2024, https://www.eeas.europa.eu/eeas/tackling-disinformation-foreign-information-manipulation-interference.\n49 Thomas Rid and Ben Buchanan, ‘Attributing cyber attacks’, *Journal of Strategic Studies* 38: 1–2, 2015, pp. 4–37, https://doi.org/10.1080/01402390.2014.977382.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\nScholars spearheading the ‘fourth wave of deterrence theory’ note that technical attribution only addresses part of the problem with cyber deterrence. Various social and contextual factors feed into the cost–benefit calculation underpinning attribution practices⁴⁰ and attribution goes beyond identifying a perpetrator.⁴¹ In a context of actor and threat complexity, leveraging reputation through attribution has, for instance, emerged as a tool for ‘deterrence by delegitimization’.⁴² Rather than being a means to an end, using naming and shaming as deterrence tactics⁴³ makes attribution into a ‘distinct form of punishment’.⁴⁴ Its effectiveness is dependent on social norms and actors’ sensitivity to ‘public opinion costs’.⁴⁵ Yet, it is still unclear ‘whether, how, and under what conditions public attribution—and the threat of shaming’⁴⁶ functions as a means for deterrence. Calculating the potential effects of deterrence measures is always difficult, but using attribution to delegitimize actors presents a novel problem of calculability, since it serves both domestic and foreign aims.⁴⁷\n\nPerhaps more than any other threat, foreign influence campaigns demonstrate that the question of a perpetrator’s identity is not the only concern of state actors involved in deterrence. Decisions on disinformation attribution are often related to a perceived political need for attribution (or for non-attribution).⁴⁸ This consideration of political factors echoes arguments from the fourth wave of deterrence theory: deterrence is determined by political processes that are mediated through social context(s) and norms.⁴⁹ To adequately address the disinformation attribution problem, we must recognize that foreign influence campaigns differ from both kinetic threats and pure cyber threats. Disinformation unsettles the foundations of liberal democracy. It is the very fact that values and opinions can be contested that weaponizes disinformation.⁵⁰ Disinformation campaigns are known to exploit socio-political cleavages and are most effective when resonating with existing domestic polarization.⁵¹ Disinformation as an external threat thereby intersects with essential processes of political deliberation.⁵² The impact of disinformation\n\n⁴⁰ Amir Lupovici, ‘The “attribution problem” and the social construction of “violence”: taking cyber deterrence literature a step forward’, *International Studies Perspectives* 17: 3, 2016, pp. 322–42, https://doi.org/10.1111/insp.12082.\n\n⁴¹ Jeffrey W. Knopf, ‘The fourth wave in deterrence research’, *Contemporary Security Policy* 31: 1, 2010, pp. 1–33 at p. 25, https://doi.org/10.1080/13523261003640819.\n\n⁴² J. Marshall Palmer and Alex Wilner, ‘Deterrence and foreign election intervention: securing democracy through punishment, denial, and delegitimization’, *Journal of Global Security Studies* 9: 2, 2024, https://doi.org/10.1093/jogss/ogae011.\n\n⁴³ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n\n⁴⁴ Wilner, ‘US cyber deterrence’, pp. 270–1.\n\n⁴⁵ Amir Lupovici, ‘Deterrence through inflicting costs: between deterrence by punishment and deterrence by denial’, *International Studies Review* 25: 3, 2023, https://doi.org/10.1093/isr/viado36.\n\n⁴⁶ Wilner, ‘US cyber deterrence’, p. 171.\n\n⁴⁷ Marshall Palmer and Wilner, ‘Deterrence and foreign election intervention’.\n\n⁴⁸ Lupovici, ‘The “attribution problem” and the social construction of “violence”’.\n\n⁴⁹ Lupovici, ‘The “attribution problem” and the social construction of “violence”’, p. 322.\n\n⁵⁰ Henry Farrell and Bruce Schneier, *Common-knowledge attacks on democracy* (Cambridge, MA: Berkman Klein Center for Internet &amp; Society at Harvard University, 2018), https://doi.org/10.2139/ssrn.3273111.\n\n⁵¹ Vincent Charles Keating and Olivier Schmitt, ‘Ideology and influence in the debate over Russian election interference’, *International Politics*, vol. 58, 2021, pp. 757–71, https://doi.org/10.1057/s41311-020-00270-4.\n\n⁵² Thomas Rid and Ben Buchanan, ‘Hacking democracy’, *SAIS Review of International Affairs* 38: 1, 2018, pp. 3–16. https://doi.org/10.1353/sais.2018.0001.\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\ntion is difficult, if not impossible, to distinguish from ‘authentic’ contestation in public opinion. In some cases, campaigns involve domestic actors,⁵³ or actors from several states working in concert.⁵⁴ For these reasons, impact assessments of disinformation campaigns are scarce, and questions concerning harmful effects are not yet settled.⁵⁵ Attribution in a highly polarized domestic context might even generate contrary results, since ‘overstating the power of propaganda risks amplifying not only the original falsehood but also an even more corrosive and polarizing narrative’.⁵⁶\n\nA diverse body of critical and constructivist scholarship has emphasized the politics involved in attributing disinformation. For instance, attribution theory highlights how people perceive behaviour and assign responsibility based on causal information.⁵⁷ This lens helps explain how public attribution involves blaming an actor for spreading disinformation, particularly in politicized, polarized or populist contexts.⁵⁸ In an ideologically charged environment, citizens concerned with disinformation as a threat may display an ‘attribution bias’⁵⁹ and ‘selectively attribute blame to politicians and media from the opposite side’.⁶⁰ The inherent link between attribution and blame also allows politicians⁶¹ to use attribution as a political tool to ‘delegitimise or attack political opponents’.⁶² By emphasizing these potentially harmful implications of attribution, this research brings attention to the precarious politics of attributing disinformation to citizens or political opponents in a democratic context.\n\nCritical security scholars focus instead on the perils of attributing disinformation to foreign adversaries, but highlight similar risks to democratic debate.⁶³ While\n\n⁵³ Sophie Vériter, ‘European democracy and counter-disinformation: toward a new paradigm?’, Carnegie Endowment for International Peace, 14 Dec. 2021, https://carnegieendowment.org/research/2021/12/european-democracy-and-counter-disinformation-toward-a-new-paradigm.\n\n⁵⁴ Vilmer, *The ‘Macron leaks’ operation: a post-mortem*.\n\n⁵⁵ Wolf J. Schünemann, ‘A threat to democracies? An overview of theoretical approaches and empirical measurements for studying the effects of disinformation’, in Dunn Cavelty and Wenger, *Cyber security politics*, https://doi.org/10.4324/9781003110224-4.\n\n⁵⁶ Olga Belogolova, Lee Foster, Thomas Rid and Gavin Wilde, ‘Don’t hype the disinformation threat: downplaying the risk helps foreign propagandists—but so does exaggerating it’, *Foreign Affairs*, 3 May 2024, https://www.foreignaffairs.com/russian-federation/dont-hype-disinformation-threat.\n\n⁵⁷ Brian H. Spitzberg and Valerie Manusov, ‘Attribution theory: finding good cause in the search for theory’, in Dawn O. Braithwaite and Paul Schrodt, eds, *Engaging theories in interpersonal communication* (New York and Abingdon: Routledge, 2022), pp. 39–51.\n\n⁵⁸ Michael Hameleers, ‘Populist disinformation: exploring intersections between online populism and disinformation in the US and the Netherlands’, *Politics and Governance* 8: 1, 2020, pp. 146–57, https://doi.org/10.17645/pag.v8i1.2478.\n\n⁵⁹ Michael Hameleers and Anna Brosius, ‘You are wrong because I am right! The perceived causes and ideological biases of misinformation beliefs’, *International Journal of Public Opinion Research* 34: 1, 2022, https://doi.org/10.1093/ijpor/edab028.\n\n⁶⁰ Jianing Li and Min-Hsin Su, ‘Real talk about fake news: identity language and disconnected networks of the US public’s “fake news” discourse on Twitter’, *Social Media + Society* 6: 2, 2020, p. 3, https://doi.org/10.1177/2056305120916841.\n\n⁶¹ Michael Hameleers and Sophie Minihold, ‘Constructing discourses on (un)truthfulness: attributions of reality, misinformation, and disinformation by politicians in a comparative social media setting’, *Communication Research* 49: 8, 2022, pp. 1176–99, https://doi.org/10.1177/0093650220982762.\n\n⁶² Hameleers and Minihold, ‘Constructing discourses on (un)truthfulness’, p. 1177.\n\n⁶³ Linda Monsees, ‘Information disorder, fake news and the future of democracy’, *Globalizations* 20: 1, 2023, pp. 153–68 at p. 161, https://doi.org/10.1080/14747731.2021.1927470. See also, for instance: Jakub Eberle and Jan Daniel, *Politics of hybrid warfare: the remaking of security in Czechia after 2014* (Cham, Switzerland: Palgrave Macmillan, 2023), https://link.springer.com/book/10.1007/978-3-031-32703-2.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\nthe foreign/domestic distinction is often mobilized to separate illegitimate disinformation from legitimate public debate,⁶⁴ attributing disinformation to foreign adversaries might raise the political stakes domestically. Attribution in a context of national security not only allows actors to ‘denounce certain opinions’,⁶⁵ but also to describe citizens or particular communities as ‘useful idiots’⁶⁶ or potential ‘fifth columns’.⁶⁷ The blame relayed through attribution is then associated with acting for the benefit of a foreign adversary.\n\nThese insights in disinformation studies show how attribution is productive of political risk. The risk tied to attribution arises from a web of uncertainties that need to be factored into the deterrence strategies used against foreign influence operations. Aligned with the fourth wave of deterrence theory, a thorough understanding of deterrence must encompass the material capabilities and technological aspects of attribution and the intersubjective social context in which deterrence is enacted.\n\n# The politics of attribution\n\nBuilding on these arguments, we conceptualize the politics of attribution as the interaction between sources of uncertainty and risk that are related to the capability to attribute and the timing of the political decision to attribute. While technical attribution capabilities can be purposefully developed to strengthen ‘deterrence by detection’, other sources of uncertainty arise from both domestic and international politics. The presence of such uncertainties compels governments to carefully navigate different deterrence scenarios and can explain variations in attribution strategies. Unpacking the politics of disinformation attribution destabilizes the traditional interactional dynamics of deterrence (between the deterrer and the deterred) and demonstrates why foreign information influence is ‘a unique vulnerability’.⁶⁸\n\nIn figure 1, below, we envision decision-making processes in relation to the attribution of disinformation as an ‘uncertainty loop’ where timing dictates which sources of uncertainty and risk take precedence when government actors assess costs at a given moment. The loop thereby adds a layer of complexity to the interactional dynamics of deterrence, where timing is seen as relative to the undesirable actions of an adversary,⁶⁹ and brings a domestic component into deterrence theory.\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\n![img-0.jpeg](img-0.jpeg)\nFigure 1: The uncertainty loop\n\nIn the uncertainty loop, a continuous flow of uncertainty charges the decision-making situation. Decisions to attribute disinformation (or refrain from attribution) are based on actors' cost-benefit calculations at any given time. Once a decision has been made, however, the timing of that decision may align with a new set of costs entering the equation. This temporal complexity springs from the specific political-contextual uncertainties affecting cost-benefit calculations in relation to disinformation attribution. Uncertainties spring from: 1) the nature of foreign information influence as an external threat intersecting with domestic processes of political deliberation and 2) the act of public attribution as potentially productive of political risk. On the domestic side of the loop, states can assess neither the harmful impact of influence operations in their own 'territory' nor the impact that attribution of foreign interference may have on inter-party relations, the state of public deliberation or levels of public trust. On the international side of the loop, there is uncertainty about whether attribution signals vulnerability or strength to the outside world, whether it would strengthen alliances, and whether it would incur costs to the perpetrator or, in fact, adversely serve their goal. Due to the inherent difficulty of separating domestic politics from the external threat, domestic political risk can also persist even after an attribution decision is made. Because uncertainties continuously generate novel conditions for attribution, it is not the mere accumulation of uncertainty that complicates decision-making, but the unpredictable changes themselves.\n\nAlongside technical attribution capabilities, the dynamic sources of political uncertainty outlined in the loop throw some much-needed[70] light upon the conditions that governments need to consider when navigating public attribution of disinformation. Further grasping the politics of attribution requires that we\n\n70 Wilner, 'US cyber deterrence', p. 171.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\ndistinguish between a set of attribution strategies available to governments, and how these strategies relate to deterrence.\n\nPublic attribution refers to instances where governments publicly identify and respond to interference using measures such as sanctions, indictments, media regulations, bans, official statements or counter-operations. In the disinformation context, acts of public attribution serve deterrence by imposing costs on foreign actors who seek to undermine democratic processes. They do so by exposing attackers' identities, laying bare the tactics and strategies they use and condemning them by reference to international law. By holding state actors, groups or individuals publicly accountable for their efforts to interfere in democratic politics, they are 'named and shamed'. At the same time, governments signal capability and resolve when calling them out.[71] In the logic of 'deterrence by delegitimization', public attribution thereby works by imposing social costs while denying the attacker political victories.[72] The decision to pursue this strategy will, however, depend on the conditions of uncertainty charging the situation at that point in time. The likelihood of attribution around an upcoming election can either increase or decrease based on the policy agenda and the 'public mood',[73] including perceived levels of resilience.[74] If the public is polarized on key policy issues, attribution might be seen as further politicizing the situation. Additionally, if the public shows ideological sympathy with the attackers' regime, attribution could be rejected.[75] In cases where societal resilience is high and disinformation is unlikely to cause significant harm, governments might strategically choose to withhold attribution.\n\nNon-attribution is not merely the absence of attribution or a misdirection of blame, but a deliberate choice to refrain from publicly assigning blame despite having evidence. This approach is therefore distinct from an inability to attribute due to underdeveloped capabilities for 'deterrence by detection', and centres on the strategic political implications of attribution. Non-attribution can act as a deterrent by preserving ambiguity about the nature of threats across different audiences. Decisions to pursue non-attribution are influenced by assessments of domestic resilience capabilities and the potential costs both to the perpetrator and in the domestic sphere. Unlike 'deterrence by denial', which focuses on building societal resilience, non-attribution weighs the risks of backlash and other domestic consequences. It involves a calculated judgement rather than ignoring the perpetrator outright, and considers how attribution might have unintended negative effects. Timing and capabilities remain crucial, as non-attribution can precede eventual attribution, with strategies evolving based on situational factors and accumulating forensic evidence to reduce uncertainty in the domestic context.\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\nFinally, diffused attribution involves managing the balance between being transparent and maintaining discretion in public discourse. By allowing or informally encouraging credible non-state actors or international organizations to publicly assign blame and suggest consequences, governments can support attribution without directly intervening. This method is akin to ‘deterrence by detection’, in that it publicly demonstrates a technical ability to identify threat actors, but crucially enables shared responsibility for public attribution. Diffused attribution—for instance EU member states collectively imposing sanctions[76]—thereby effectively manages the domestic political impact while signalling international determination. A case in point is the EU’s suspension of the activities of the Russian state-owned broadcasters Russia Today (now RT) and Sputnik, both within and directed at EU member states, due to the broadcasters’ spread of disinformation.[77] This approach helps manage uncertainty and reduce vulnerabilities by carefully balancing domestic and geopolitical risks while avoiding publicly assigning blame to citizens. It also strengthens deterrence by fostering credible alliances against threat actors while avoiding direct government intervention in the public sphere.\n\n## Public attribution and its alternatives\n\nTo further explore the politics of attribution, we will illustrate how the uncertainty loop drives variation in attribution acts by examining three recent cases of foreign interference involving disinformation: the 2016 presidential election in the United States; the 2021 federal election in Germany; and the COVID-19 pandemic of 2020–21. The cases were selected because all three involved reports that there was substantial evidence of disinformation, yet governments adopted distinct approaches to attribution. We argue that these diverging responses are driven by the specific uncertainties permeating the political situation at any given time. The cases differ in their liberal democratic contexts (for instance in terms of levels of cohesion and polarization) and in the range of disclosed sources that determine the strength of evidence available to governments. Our analysis is not focused on evaluating the robustness or effectiveness of attribution, but on exploring how the timing of political circumstances feed into attribution decisions. We cannot determine causal effects, but rather offer a deeper understanding of the political-contextual factors that shape and drive these choices. The logic of inquiry is inductive, and our method of analysis serves to trace political decisions on attribution through a triangulation of publicly available documents, reports and news media reporting. While the lack of public attribution naturally results in a sparser paper trail, the timing of political events and eventual acts of attribution have nevertheless provided us with enough empirical material for our illustrative analysis.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\n# Public attribution\n\nSince 2016, the US government has publicly attributed both disinformation and cyber offences with great frequency, but attention to the timing of attribution statements suggests that a degree of political risk and uncertainty is at play as actors assess attribution costs. The US intelligence community notably exposed Russia's disinformation activities during the 2016 presidential election. This disclosure prompted four investigations assessing the potential electoral harm of the threat and the responses of the government and the Federal Bureau of Intelligence (FBI).[78] The reports, totalling 2,500 pages of evidence and testimonies, illustrate how Russia's targeted election interference intersected with domestic political polarization, complicating efforts to investigate and attribute foreign interference. Despite possessing the technical capabilities for attribution, these political factors constrained the US strategy of 'deterrence by detection'.\n\nPresident Barack Obama first issued sanctions against Russia on 29 December 2016 for 'aggressive harassment of U.S. officials and cyber operations aimed at the U.S. election'.[79] Just over a week afterwards, on 6 January 2017, the Office of the Director of National Intelligence released its initial report stating that Russian President Vladimir Putin had orchestrated a campaign to undermine confidence in the US democratic process and to harm Hillary Clinton's candidacy.[80] The Obama administration refrained from attributing these actions during the campaigning that had begun after Clinton and Donald Trump accepted their party nominations for the presidency in July 2016, leading up to the election on 8 November. The timing of attributing statements and the subsequent report findings shed light on the persistent flow of uncertainty over how attribution would affect the election outcome. The report by special counsel Robert S. Mueller III in April 2019 confirmed that despite warnings to the Russian regime, and even though the FBI had initiated an investigation as early as July,[81] the Obama administration had intentionally delayed public attribution.\n\nThe report that was released by special counsel John Durham in 2023 further revealed that uncertainty about how the investigations would be framed in public narratives and the risk of a backlash against politically motivated attribution were involved in the assessment. Most notably, it was perceived that attribution would have benefited the Clinton campaign, which actively sought to highlight the alleged ties between the Russian government and the Trump campaign in the\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\nlatter months of 2016.⁸² Meanwhile, the Trump campaign capitalized on anti-establishment sentiments and warnings of a ‘rigged election’. The risk was thus that a backlash following a perceived ‘attribution bias’ would negatively influence the legitimacy of the election. Delaying attribution was a way of demonstrating detection capabilities to Russia while not risking the domestic costs of meddling in a polarized electorate. However, Republicans—not least President Trump—immediately used the findings of the Mueller report (e.g. the criticism of delayed attribution) to direct blame at the Obama administration, deflecting discussions on the impact on the election outcome.⁸³ Criticism of the Obama administration increased when the bipartisan Senate Select Committee on Intelligence released its multi-volume report. Volume 3, published in February 2020, suggested that\n\nThe Obama administration ... tempered its response over concerns about appearing to act politically on behalf of one candidate, undermining public confidence in the election, and provoking additional Russian actions. Further, administration officials’ options were limited by incomplete information about the threat and having a narrow slate of response options from which to draw.⁸⁴\n\nWhile the report was more vocal in directing blame at Obama, it also went further than the Mueller report in detailing the links between the Trump campaign and the Russian state. In addition to the uncertainty about how the calling out of Clinton’s unfavourable conditions would be received by the electorate, and about what measures to use in a new situation, the Obama administration was criticized—at least by its opponents—for being lenient with Russia to secure the legacy of the Iran nuclear deal framework.⁸⁵ Hence, there was also geopolitical uncertainty about how an adversary (and its allies) would respond to a deterring move and the potential cost of retaliation.\n\nWhen Trump assumed office in January 2017, the question of Russian interference was undoubtedly sensitive. The Trump administration opted to continue to downplay the results of investigations while echoing the failure of the Obama administration to protect the election. The Office of Foreign Assets Control of the US Department of the Treasury did not issue sanctions against Russia for its 2016 election interference until 2018.⁸⁶ Still, Trump made headlines in July 2018 when, after his Helsinki summit meeting with Putin, he publicly sided with the Russian president over the FBI’s allegations (by then proven) of interference, stating ‘Presi\n\n⁸² John H. Durham, Report on matters related to intelligence activities and investigations arising out of the 2016 presidential campaigns (Washington DC: US Department of Justice, 2023), p. 252, https://www.justice.gov/storage/durhamreport.pdf.\n⁸³ Scott Jennings, ‘Mueller’s report looks bad for Obama’, CNN Opinion, 23 April 2019, https://edition.cnn.com/2019/04/19/opinions/mueller-report-obama-jennings/index.html.\n⁸⁴ United States Senate Select Committee on Intelligence, Report on Russian active measures campaigns and interference in the 2016 U.S. election, vol. 3: U.S. government response to Russian activities (Washington DC: Select Committee on Intelligence, 2020), https://www.intelligence.senate.gov/sites/default/files/documents/Report_Volume3.pdf.\n⁸⁵ Philip Ewing, ‘Fact check: why didn’t Obama stop Russia’s election interference in 2016?’, NPR, 21 Feb. 2018, https://www.npr.org/2018/02/21/587614043/fact-check-why-didnt-obama-stop-russia-s-election-interference-in-2016.\n⁸⁶ US Department of the Treasury, ‘Treasury sanctions Russian cyber actors for interference with the 2016 U.S. elections and malicious cyber-attacks’, 15 March 2018, https://home.treasury.gov/news/press-releases/sm0312.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\ndent Putin says it's not Russia. I don't see any reason why it would be.⁸⁷ Thus Trump again mobilized the flow of uncertainty to his own advantage by pointing fingers at Obama's lack of resolve while simultaneously avoiding costs to his own administration.⁸⁸\n\nBy contrast, the Biden administration swiftly addressed Russia's ‘harmful foreign activities’ following the 2020 election through executive orders, economic sanctions and expulsions of diplomats.⁸⁹ The attribution efforts bolstered renewed commitment to multilateralism amid strong domestic and international signals, including expanded sanctions in 2021 targeting Russia-sponsored influence operations and safeguarding US national security.⁹⁰ The flow of uncertainty had shifted, however, and the timing of the Biden administration's decision to attribute was most likely also influenced by other calculations of costs, such as trade-offs in the US debate on privacy rights and the booming digital economy. Big tech, the largest IT companies and dominant owners of social media platforms, represents a growing portion of the US economy. Whereas the EU has leaned towards increasing the accountability of social media platforms that enable and diffuse disinformation (along with other harmful content), the US electorate is divided over the issue of regulation.⁹¹ At the same time, the Biden administration has been criticized for its inability to act on the ‘misinformation plague’ and its handling of the COVID-19 pandemic.⁹² In the US context, public attribution of Russian interference thereby also reassured the public of capable deterrence of ‘a foreign threat’ in the absence of regulatory reform.\n\n## Non-attribution\n\nIn the case of Germany’s 2021 Bundestag election, despite reported disinformation campaigns targeting Annalena Baerbock, the co-leader of Alliance 90/The Greens, officials chose not to publicly attribute the interference to foreign actors. In this example of ‘non-attribution’, the flow of uncertainty led to a distinct pattern of balancing domestic risks and calculating the costs of deterrence. Despite Germany\n\n⁸⁷ ‘Trump sides with Russia against FBI at Helsinki summit’, BBC News, 16 July 2018, https://www.bbc.com/news/world-europe-44852812.\n\n⁸⁸ Emma Ashford, ‘Strategies of restraint: remaking America’s broken foreign policy’, *Foreign Affairs*, 24 Aug. 2021. https://www.foreignaffairs.com/articles/united-states/2021-08-24/strategies-restraint.\n\n⁸⁹ The White House, ‘Fact sheet: imposing costs for harmful foreign activities by the Russian government’, 15 April 2021, https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2021/04/15/fact-sheet-imposing-costs-for-harmful-foreign-activities-by-the-russian-government; The White House, *Executive Order 14024 of April 15, 2021. Blocking property with respect to specified harmful foreign activities of the government of the Russian Federation*, 2021, https://www.federalregister.gov/documents/2021/04/19/2021-08098/blocking-property-with-respect-to-specified-harmful-foreign-activities-of-the-government-of-the.\n\n⁹⁰ The White House, *Executive Order 14114 of December 22, 2023. Taking additional steps with respect to the Russian Federation’s harmful activities*, 2023, https://ofac.treasury.gov/media/932441/download?inline. Executive orders related to Russia’s unprovoked war on Ukraine are a separate matter.\n\n⁹¹ Emiliana De Blasio and Donatella Selva, ‘Who is responsible for disinformation? European approaches to social platforms’ accountability in the post-truth era’, *American Behavioral Scientist* 65: 6, 2021, pp. 825–46, https://doi.org/10.1177/0002764221989784.\n\n⁹² RonNell Andersen Jones and Lisa Grow Sun, ‘Repairing the damage: President Biden and the press’, *University of Illinois Law Review*, 30 April 2021, pp. 111–20, https://illinoislawreview.org/symposium/first-100-days-biden/repairing-the-damage.\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\nbeing a prime target for Russian disinformation efforts among EU member states since 2015,⁹³ successive coalition governments had been hesitant in risking the country's stability and reform efforts by reversing Germany's rapprochement with Russia.⁹⁴ In the aftermath of the annexation of Crimea in 2014, Germany aimed to reconcile economic relations—notably in energy and joint ventures like the Nord Stream 2 pipeline project—with the EU's stance against Russia's breaches of international law. Germany's balancing strategy and stance on the disinformation threat therefore centred on ‘deterrence by denial’ and bolstering resilience to prevent harm on the state of public deliberation. Anticipating disinformation and cyber threats during the 2021 federal election, precautionary measures were implemented that included cybersecurity measures, public education initiatives and proactive collaborations with social media platforms.⁹⁵ However, the distinctively gendered disinformation campaigns targeting Annalena Baerbock, the sole female candidate for the chancellorship, were unexpectedly impactful.⁹⁶ Baerbock faced disproportionate attacks, including misogynistic narratives and doctored nude images portraying her as a former sex worker.⁹⁷ Baerbock's criticism of Nord Stream 2 further fuelled these attacks, which were linked to Russian state actors and media.⁹⁸ In fact, since 2021 Russian state media have continued to circulate the false claims of Baerbock's past along with the images.⁹⁹ Although the origin of this campaign and its online amplification was linked to Russia, German media also engaged in sexist rhetoric questioning of Baerbock's ability to balance leadership with motherhood.¹⁰⁰ The sensitive nature of gender-based attacks thus intersected with value conservatism and ‘home-grown misogyny’, complicating the assessment of interference as well as introducing risks of domestic backlash resulting from attribution. Threat actors—in this context most notably Russia—certainly fuelled negative campaigning in Germany, but the resonance of narratives reflected a polarization over both foreign policy (and the stance on Russia) and gender norms. Amid high stakes and Germany's political transition away from Angela Merkel's leadership, public attribution of interference was likely avoided to prevent further polarization and preserve stability, highlighting the complexity of addressing both deterrence inter\n\n⁹³ Kate Martyr, ‘Russian disinformation mainly targets Germany: report’, Deutsche Welle, 3 Sept. 2021, https://www.dw.com/en/russian-disinformation-mainly-targets-germany-eu-report/a-56812164.\n⁹⁴ Bernhard Blumenau, ‘Breaking with convention? Zeitenwende and the traditional pillars of German foreign policy’, International Affairs 98: 6, 2022, pp. 1895–913, https://doi.org/10.1093/ia/iiac166.\n⁹⁵ German Federal Returning Officer, ‘Bundestagswahl 2021: Erkennen und Bekämpfen von Desinformation’, 2021, https://www.bundeswahlleiterin.de/bundestagswahlen/2021/fakten-fakenews.html.\n⁹⁶ Julia Smirnova et al., Digitale Gewalt und Desinformation gegen Spitzenkandidat: innen vor der Bundestagswahl 2021 (Institute for Strategic Dialogue, 2021), https://www.isdglobal.org/isd-publications/digitale-gewalt-und-desinformation-gegen-spitzenkandidatinnen-vor-der-bundestagswahl-2021; Elsa Hedling ‘Gendered disinformation’, in Karin Aggestam and Jacqui True, eds, Feminist foreign policy analysis (Bristol: Bristol University Press, 2024).\n⁹⁷ Kate Brady, ‘Online trolls direct sexist hatred at Annalena Baerbock’, Deutsche Welle, 5 Oct. 2021, https://www.dw.com/en/germany-annalena-baerbock-becomes-prime-target-of-sexist-hate-speech/a-57484498.\n⁹⁸ Mark Scott, ‘Russia sows distrust on social media ahead of German election’, Politico, 3 Sept. 2021, https://www.politico.eu/article/germany-russia-social-media-distrust-election-vladimir-putin.\n⁹⁹ Salome Giunashvili, ‘Who does the photo depict?—German foreign minister or Russian porn model?’, Myth Detector, 28 March 2023, https://mythdetector.com/en/who-does-the-photo-depict-german-foreign-minister-or-russian-porn-model/.\n¹⁰⁰ Thorsten Faas and Tristan Klingelhöfer, ‘German politics at the traffic light: new beginnings in the election of 2021’, West European Politics 45: 7, 2022, pp. 1506–21, https://doi.org/10.1080/01402382.2022.2045783.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\nests and domestic risks to electoral integrity. Moreover, the combination of non-attribution and prevailing uncertainty could act as a deterrent by preserving ambiguity about the disinformation threat among the German public.\n\nRussia's invasion of Ukraine in 2022 marked the end of Germany's policy of rapprochement$^{101}$ and produced a new context for the politics of attribution. Since 2022, actions by Germany further signal deterrence-seeking and a shift from its choice of non-attribution during the 2021 federal elections. The German government has made a series of accusations of Russian disinformation,$^{102}$ including digital forensic proof of a large-scale disinformation campaign aimed at discouraging public support for German aid to Ukraine.$^{103}$\n\nIn May 2024 Germany went so far as to temporarily recall its ambassador from Moscow, following which then-foreign minister Baerbock publicly attributed interference in German politics to Russian military cyber operators, specifically the advanced persistent threat group APT28 (also known as Fancy Bear or Pawn Storm).$^{104}$ The cyber attack was specifically framed as a threat to the integrity of upcoming European Parliament elections, as well as regional elections in Germany and those in neighbouring states. This strategic move positioned Germany's evolving stance in preparation for the 2025 Bundestag election by providing clear 'deterrence by detection' signals to Russia while mitigating the uncertainties that had charged the 2021 election. The emphasis on the European Parliament elections was not just an opportunity to combat disinformation while keeping a safe distance from the upcoming federal election: it was also a pivotal moment to expose Russia's geopolitical interests and the stakes of the war in Ukraine to the German public, as well as to emphasize Germany's commitment to its international allies through collective deterrence by both punishment (sanctions and public attribution) and denial (resilience-building).\n\n## Diffused attribution\n\nDuring the COVID-19 pandemic, European governments leveraged EU frameworks to balance the protection of domestic accountability with deterrence interests. The European Commission initially aimed to combat harmful COVID-related misinformation by using the Code of Practice on Disinformation, a voluntary self-regulation initiative for online platforms.$^{105}$ Despite this existing measure, European governments also pursued EU-level attribution amid significant domestic political risks.\n\n$^{101}$ Blumenau, ‘Breaking with convention?’.\n\n$^{102}$ Federal Government of Germany, ‘Russische Desinformationskampagnen: Wie aus Narrativen eine Desinformation wird’, 30 Aug. 2022, https://www.bundesregierung.de/breg-de/schwerpunkte/umgang-mit-desinformation/aus-narrativen-desinformation-2080112.\n\n$^{103}$ Kate Connelly, ‘Germany unearths pro-Russia disinformation campaign on X’, *Guardian*, 26 Jan. 2024, https://www.theguardian.com/world/2024/jan/26/germany-unearths-pro-russia-disinformation-campaign-on-x.\n\n$^{104}$ Euro News, ‘Germany recalls ambassador to Russia over hacker attack’, 7 May 2024, https://www.euronews.com/next/2024/05/07/germany-recalls-ambassador-to-russia-over-hacker-attack.\n\n$^{105}$ EU Commission, ‘Tackling coronavirus disinformation’, undated, https://commission.europa.eu/strategy-and-policy/coronavirus-response/fighting-disinformation/tackling-coronavirus-disinformation_en.\n\nInternational Affairs 101: 3, 2025",
    "Elsa Hedling and Hedvig Ördén\n\nThe COVID-19 pandemic presented a challenge for democratic governments. The uncertainties related to the origins of the virus, its transmission and, later, the safety of the newly developed vaccines were accompanied by an ‘infodemic’¹⁰⁶ involving the spread of false and misleading information. The World Health Organization concluded that the spread of disinformation posed ‘profound health and public safety risks’¹⁰⁷ This was especially true for the vaccine-related disinformation, which threatened to reduce the uptake of vaccines. Much COVID-related disinformation—according to some, the bulk of dis- and misinformation¹⁰⁸—was disseminated by domestic or intra-EU actors for financial or political gain,¹⁰⁹ or spread by citizens experiencing uncertainty and fear. A set of coordinated foreign influence campaigns was, however, linked to threat actors, notably Russia and China. China focused on deflecting blame for the spread of the virus by spreading narratives on western failures and enhancing its position on the world stage,¹¹⁰ and Russia aimed to weaken public trust in European governments’ responses to the pandemic.¹¹¹ In-depth studies show how ‘French and German-language reporting from Russian state media highlighted acts of civil disobedience, and tensions with public authorities amid the pandemic’, and thereby tried to fuel existing domestic divisiveness.¹¹²\n\nThroughout the pandemic, European populations held deeply divided views on the stringent government measures employed to tackle the virus, such as lockdowns and, in some states, compulsory vaccination schemes. In many EU states trust in government was low and resilience to disinformation sometimes poor; groups of citizens engaged in public protests.¹¹³ In countries like Germany and Austria, government responses to the pandemic were politicized by domestic actors. Opposition actors saw an opportunity to gather support for their causes,¹¹⁴\n\n¹⁰⁶ World Health Organization, ‘Infodemic’, undated, https://www.who.int/health-topics/infodemic.\n¹⁰⁷ James Pamment, *The EU’s role in fighting disinformation: taking back the initiative* (Washington DC: Carnegie Endowment for International Peace, 2020), https://carnegieendowment.org/research/2020/07/the-eus-role-in-fighting-disinformation-taking-back-the-initiative.\n¹⁰⁸ Gary Machado, *Being cautious with attribution: foreign interference &amp; COVID-19 disinformation* (Brussels: EU DisinfoLab, 2020), https://www.disinfo.eu/wp-content/uploads/2020/04/20200414_foreigninterference-covid19-1.pdf.\n¹⁰⁹ Pamment, *The EU’s role in fighting disinformation*.\n¹¹⁰ Ben Dubow, Edward Lucas and Jake Morris, ‘Jabbed in the back: mapping Russian and Chinese information operations during the COVID-19 pandemic’, *Center for European Policy Analysis*, 2 Dec. 2021, https://cepa.org/comprehensive-reports/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-the-covid-19-pandemic.\n¹¹¹ ‘The Kremlin and disinformation about coronavirus’, EUvsDisinfo, 16 March 2020, https://euvsdisinfo.eu/the-kremlin-and-disinformation-about-coronavirus.\n¹¹² Katarina Rebello et al., *Covid-19 news and information from state-backed outlets targeting French, German and Spanish-speaking social media users* (Oxford: Oxford Internet Institute, 2020), https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2020/06/Covid-19-Misinfo-Targeting-French-German-and-Spanish-Social-Media-Users-Final.pdf.\n¹¹³ Rachel Schraer, ‘Covid: conspiracy and untruths drive Europe’s Covid protests’, *BBC News*, 27 Nov. 2021, https://www.bbc.com/news/59390968; ‘Vaccine fears spark conspiracy theories’, *Deutsche Welle*, 5 Dec. 2020, https://www.dw.com/en/in-germany-vaccine-fears-spark-conspiracy-theories/a-53419073.\n¹¹⁴ ‘Verordnungen zu neuen Corona-Regeln fehlen noch’, *Nön*, 30 April 2020, https://www.noen.at/in-ausland/fpoe-kritik-verordnungen-zu-neuen-corona-regeln-fehlen-noch-oesterreich-epidemie-verordnung-viruserkrankung-203510962; Maria Fiedler, ‘Mit voller Kraft gegen den Lockdown: wie die AfD versucht, aus dem Corona-Tief zu kommen’, *Tagesspiegel*, 8 May 2020, https://www.tagesspiegel.de/politik/wie-die-afd-versucht-aus-dem-corona-tief-zu-kommen-6865738.html.\n\nInternational Affairs 101: 3, 2025",
    "Disinformation, deterrence and the politics of attribution\n\nwhile extremists exploited growing anti-lockdown sentiments within parts of the population.¹¹⁵ These aspects charged the uncertainty loop with a complex set of domestic political risks. Any form of public distribution of blame or social punishment risked being used by domestic political actors to mobilize more support. Attribution of disinformation—even disinformation by foreign adversaries—thereby risked feeding into existing polarized narratives on government overreach and vaccine safety while generating increased support for actors in the opposition.\n\nRather than pursuing a strict strategy of non-attribution, however, European governments navigated the flow of uncertainty by shifting attribution to the EU level. Beginning in 2020, the European External Action Service (EEAS) published a series of special reports¹¹⁶ on the COVID-19 infodemic, attributing coordinated disinformation campaigns to Russia and China (and, to a certain extent, to Iran).¹¹⁷ The EEAS argued that these threat actors were striving to ‘undermine trust in western-made vaccines, EU institutions and western/European vaccination strategies’ and to fuel ‘anti-vaccination movements within the EU’.¹¹⁸ Following an update in April 2020,¹¹⁹ in an opening statement in the European Parliament, the High Representative of the Union for Foreign Affairs and Security Policy, Josep Borrell, reiterated the attributional intent by underlining that the report ‘very clearly points out state-sponsored disinformation campaigns and very specifically names the actors behind them—including China’.¹²⁰ This last comment was made following criticism that the EEAS tried to avoid attributing disinformation to Chinese state actors,¹²¹ and Borrell underlined that ‘[t]here was no “watering down” of our findings, however uncomfortable they could be’ and indicated the potential use of additional diplomatic measures.¹²² By attributing coordinated campaigns to adversary states, the EU aimed to signal resolve internationally through a collective demonstration of capabilities for deterrence by detection, while allowing individual member states to manage domestic political risk. By moving attribution to the EU level, governments could avoid unfavourable political outcomes generated through public attribution and the overt blaming of citizens, such as enhanced polarization and a display of domestic societal vulnerabilities to COVID-19 disinformation. Furthermore, signalling resolve towards Russia and Iran bolstered the EU’s broader geopolitical deterrence stance while navigating uncertainties amid US–China tensions during Trump’s presidency.¹²³\n\n¹¹⁵ Ben Knight, “‘Extremists and terrorists don’t go into lockdown’”, Deutsche Welle, 15 June 2021, https://www.dw.com/en/pandemic-spurred-extremism-says-german-domestic-intelligence/a-57906728.\n¹¹⁶ EUvsDisinfo, ‘EEAS special reports’, https://euvsdisinfo.eu/eeas-special-reports.\n¹¹⁷ EUvsDisinfo, EEAS special report update: short assessment of narratives and disinformation around the COVID-19 pandemic (EUVsDisinfo, 2021), https://euvsdisinfo.eu/eeas-special-report-update-short-assessment-of-narratives-and-disinformation-around-the-covid-19-pandemic-update-december-2020-april-2021.\n¹¹⁸ EUvsDisinfo, EEAS special report update.\n¹¹⁹ EUvsDisinfo, EEAS special report update.\n¹²⁰ Josep Borrell, ‘Disinformation around the coronavirus pandemic’, opening statement at the European Parliament, 30 April 2020, https://www.eeas.europa.eu/eeas/disinformation-around-coronavirus-pandemic-opening-statement-hrvp-josep-borrell-european-parliament.\n¹²¹ ‘EU pressured to give results of leak probe into China disinformation’, Financial Times, 20 July 2020, https://www.ft.com/content/5a323cec-82a6-4e64-9bbb-27e8de7b9929.\n¹²² Borrell, ‘Disinformation around the coronavirus pandemic’.\n¹²³ Mario Esteban et al., eds, Europe in the face of US–China rivalry (Madrid: European Think-tank Network on\n\nInternational Affairs 101: 3, 2025",
    "Additionally, the diffused attribution strategy potentially enhanced domestic resilience by attributing COVID-19 disinformation to foreign adversaries, thereby discouraging acceptance of similar narratives among EU citizens.\n\nEven with these efforts to mitigate multiple uncertainties, attribution was not without criticism. Following the release of the EEAS special reports, the EU DisinfoLab, an independent non-profit organization producing knowledge on disinformation, published a statement calling for EU institutions to be ‘cautious with attribution’ of foreign influence operations to Russia.¹²⁴ Arguing that ‘there is absolutely no evidence that these [pro-Kremlin media] outlets are the “architects” of the massive disinformation around the coronavirus’, the statement underscored that ‘an overwhelming majority of the disinformation and misinformation’ was internal to the EU and required a different toolbox.¹²⁵\n\n## Conclusion\n\nThis article has argued that attribution must be seen as a political challenge, and that variations in governments’ pursuit of deterrence through disinformation attribution can be better understood through attention to the complex and dynamic flow of political uncertainties conditioning the decision-making situation. By attending to the politics of attribution, and introducing the ‘uncertainty loop’, the article makes several contributions to current discussions on disinformation deterrence.\n\nFirst, emphasizing timing as a key aspect alongside attribution capabilities highlighted in the cyber deterrence literature, we show how deterrence in the information sphere necessitates attention to a set of highly dynamic political uncertainties in addition to technical attribution models. While the capability to attribute is crucial for deterrence, the absence of attribution does not necessarily mean the absence of such capabilities. Instead, governments might refrain from attribution due to perceived political costs. Second, by also taking seriously the domestic factors at play in disinformation deterrence, the ‘uncertainty loop’ adds to broader discussions within deterrence theory. Crucially, our model challenges the traditional interactional dynamic of deterrence and shows how political costs might also mean domestic political costs. Third, by conceptualizing three different variations of attribution and empirically illustrating how the uncertainty loop allows for different attribution strategies, the article speaks to current debates about the circumstances conditioning the use of ‘naming and shaming’, and appeals to social punishment as a deterrency strategy. Taken together, these novel insights could potentially be applied to better understand deterrence strategies employed in relation to a broader range of non-kinetic threats which interact with domestic factors, and in contexts where actors draw on social norms and the threat of social punishment.\n\nChina, 2020), p. 179.\n\n¹²⁴ Machado, *Being cautious with attribution*.\n\n¹²⁵ Machado, *Being cautious with attribution*.\n\n120"
  ],
  "metadata": {
    "title": "Disinformation, deterrence and the politics of attribution",
    "subtitle": "Over the past two decades, deterrence theory has undergone a significant expansion. While the fundamental principle of deterrence—influencing an",
    "document_type": "journal_article",
    "venue": "The authors are listed in alphabetical order and contributed equally to this article. An earlier version of this article was presented at a research seminar at the Swedish Institute of International Affairs, and we thank the participants for their feedback. We would also like to thank the International Affairs editorial team and the anonymous reviewers. This research was supported by the Psychological Defence Research Institute at Lund University. Elsa Hedling's research was also supported by the Swedish Research Council-funded project 'Postdigital propaganda' (2022-05414) and Hedvig Ördén's research by IntelHub—a project funded by the Carlsberg foundation.",
    "publication_year": 2020,
    "authors": [
      "ELSA HEDLING",
      "HEDVIG ÖRDÉN"
    ],
    "affiliations": [],
    "emails": [
      "journals.permissions@oup.com"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1080/08850607.2020.1789425",
        "10.1177/1065912920938143",
        "10.1093/ia/iiaf012",
        "10.1111/j.1468-2478.2010.00606.x",
        "10.1177/13540661221130958",
        "10.1007/s11948-014-9551-y",
        "10.1093/cybsec/tyac012",
        "10.1093/cybsec/tyv003",
        "10.1186/s42400-020-00048-4",
        "10.1080/01402390.2018.1563779",
        "10.1080/10736700601178465",
        "10.48456/tr-653",
        "10.1177/0967010611431079",
        "10.1093/ia/iizo96",
        "10.1093/ia/iiabo35",
        "10.1023/B:MIND.0000021682.61365.56",
        "10.23919/CYCON.2018.8405009",
        "10.1093/ejil/chac023",
        "10.1080/13501763.2023.2172060",
        "10.1111/1467-923X.12690",
        "10.1016/j.fsisyn.2022.100217",
        "10.1109/OJCOMS.2021.3074591",
        "10.1109/CogSIMA54611.2022.9830669",
        "10.1177/00207020221076402",
        "10.1080/01402390.2014.977382",
        "10.1111/insp.12082",
        "10.1080/13523261003640819",
        "10.1093/jogss/ogae011",
        "10.1093/isr/viado36",
        "10.2139/ssrn.3273111",
        "10.1057/s41311-020-00270-4",
        "10.1353/sais.2018.0001",
        "10.4324/9781003110224-4",
        "10.17645/pag.v8i1.2478",
        "10.1093/ijpor/edab028",
        "10.1177/2056305120916841",
        "10.1177/0093650220982762",
        "10.1080/14747731.2021.1927470",
        "10.1007/978-3-031-32703-2",
        "10.1177/0002764221989784",
        "10.1093/ia/iiac166",
        "10.1080/01402382.2022.2045783"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "https://doi.org/10.1080/08850607.2020.1789425",
        "https://doi.org/10.1177/1065912920938143",
        "http://creativecommons.org/licenses/by-nc-nd/4.0",
        "https://doi.org/10.1111/j.1468-2478.2010.00606.x",
        "https://doi.org/10.1177/13540661221130958",
        "https://doi.org/10.1007/s11948-014-9551-y",
        "https://doi.org/10.1093/cybsec/tyac012",
        "https://doi.org/10.1093/cybsec/tyv003",
        "https://doi.org/10.1186/s42400-020-00048-4",
        "https://www.atlanticcouncil.org/wp-content/uploads/2019/06/The_Macron_Leaks_Operation-A_Post-Mortem.pdf",
        "https://doi.org/10.1080/01402390.2018.1563779",
        "https://doi.org/10.1080/10736700601178465",
        "https://doi.org/10.48456/tr-653",
        "https://doi.org/10.1177/0967010611431079",
        "https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2017/10/20114955/Bartholomew-GuerreroSaade-VB2016.pdf",
        "https://cyberdefensereview.army.mil/Portals/6/9_mueller_cdr_V4N1.pdf",
        "https://doi.org/10.1093/ia/iizo96",
        "https://doi.org/10.1093/ia/iiabo35",
        "https://doi.org/10.1023/B:MIND.0000021682.61365.56",
        "https://doi.org/10.23919/CYCON.2018.8405009",
        "https://www.airuniversity.af.edu/Portals/10/SSQ/documents/Volume-12_Issue-2/Floyd.pdf",
        "https://doi.org/10.1093/ejil/chac023",
        "https://doi.org/10.1080/13501763.2023.2172060",
        "https://www.cgai.ca/addressing_attribution_theorizing_a_model_to_identify_russian_disinformation_campaigns_online",
        "https://doi.org/10.1111/1467-923X.12690",
        "https://doi.org/10.1016/j.fsisyn.2022.100217",
        "https://doi.org/10.1109/OJCOMS.2021.3074591",
        "https://doi.org/10.1109/CogSIMA54611.2022.9830669",
        "https://doi.org/10.1177/00207020221076402",
        "https://www.eeas.europa.eu/eeas/tackling-disinformation-foreign-information-manipulation-interference",
        "https://doi.org/10.1080/01402390.2014.977382",
        "https://doi.org/10.1111/insp.12082",
        "https://doi.org/10.1080/13523261003640819",
        "https://doi.org/10.1093/jogss/ogae011",
        "https://doi.org/10.1093/isr/viado36",
        "https://doi.org/10.2139/ssrn.3273111",
        "https://doi.org/10.1057/s41311-020-00270-4",
        "https://doi.org/10.1353/sais.2018.0001"
      ]
    },
    "references_block_count": 0,
    "references_entries_estimated": 0,
    "heading_count": 8,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 174,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.1839080459770115,
      "footnote_coverage": 1.0,
      "unique_index_count": 92
    },
    "footnotes_quality": {
      "intext_total": 10,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.2,
      "footnote_coverage": 0.0,
      "unique_index_count": 5,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 190,
        "superscript_definition_lines": 82,
        "numeric_bracket_hits": 12,
        "numeric_endnote_lines": 0,
        "author_year_hits": 1
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 93.0,
      "dominant_bib_coverage_rate": 0.989247311827957,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 8,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": false,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": false,
        "emails": true,
        "orcids": false,
        "abstract": false,
        "keywords": false,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 2,
        "affiliations": 0,
        "emails": 1,
        "orcids": 0,
        "keywords": 0,
        "doi": 42,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 38
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_abstract_and_keywords",
        "meta_missing_affiliations",
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "missing_preceding_text",
      "footnotes_bucket_unresolved",
      "missing_reference_heading",
      "meta_missing_abstract_and_keywords",
      "meta_missing_affiliations",
      "meta_low_email_author_link_rate"
    ]
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 174.0,
      "success_occurrences": 174.0,
      "success_unique": 92.0,
      "bib_unique_total": 93.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.989247311827957,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 10.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 100.0,
        "highest_intext_index": 105.0,
        "missing_footnotes_for_seen_total": 5.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 174.0,
        "success_occurrences": 174.0,
        "success_unique": 92.0,
        "bib_unique_total": 93.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.989247311827957,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 12.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 79.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:25:35.162387+00:00"
}