{
  "full_text": "2015 7th International Conference on Cyber Conflict:\nArchitectures in Cyberspace\nM.Maybaum, A.-M.Osula, L.Lindström (Eds.)\n2015 © NATO CCD COE Publications, Tallinn\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk*\nJason Rivera\nDeloitte &amp; Touche LLP\nThreat Intelligence &amp; Analytics\nCaptain, United States Army National Guard\nGeorgetown School of Foreign Service\nWashington, D.C., United States\njhr47@georgetown.edu\nAbstract: Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical \"walls\" in cyberspace over facilitating deterrent measures.\nThe notion of cyberdeterrence is especially daunting when considering how small states can deter larger, militarily more powerful states. For example, how would Estonia or Japan conduct deterrence through cyberspace against larger regional adversaries with more robust military capabilities? The power disparities between nations of such different military stature are seemingly overwhelming and insurmountable. It is these disparities in cyber power that present conceptual challenges, especially when measuring power in terms of military size, budget, strength, and technological capabilities.\n\"Power,\" however, is a broad term that should be considered beyond the military context. This is especially true in cyberspace, where a nation without a strong military can hold a militarily powerful nation at risk, so long as the former is aware of their strategic advantages as well as the critical vulnerabilities of the latter.\nGiven this reality, this paper shall suspend, or at least cast reasonable doubt on, the notion that cyberdeterrence is either difficult or impossible. Using a deductive method to analyze the components of cyberdeterrence strategy and examine the various challenges involved, this\n* All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte &amp; Touche LLP.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\npaper introduces a hypothesis on how small, less powerful states can hold large powerful states at risk through cyberspace.\nKeywords: attribution, cyberdeterrence, deterrence, use of force\n# 1. INTRODUCTION\nCyberdeterrence strategy remains largely unexplored and underdeveloped, due to a limited understanding of how the principles of deterrence can be applied to the cyber domain. Because cyberspace has only recently become an object of national security focus, the development of cyber theory relative to the other domains of warfare is relatively immature. In a broad sense, cyberspace warfighting strategy today is analogous to the growth of air power strategy during the interwar period between World Wars I and II. While the U.S. is actively developing doctrine, mobilizing forces, and allocating resources, there is still much to be done in developing comprehensive cyberspace warfighting strategies.\nThis paper defines cyberdeterrence as the mechanism through which nation-states can communicate proportionate, reciprocal, and credible military power effects through cyberspace that strategically affect their adversary's decision making calculus. The specific aim of cyberdeterrence is to deter an adversary from conducting hostile actions through cyberspace, although its application could be much broader. For example, a cyberdeterrent could be used to dissuade an adversary from conducting hostile conventional military actions, or even to gain diplomatic leverage.\nFour prevailing viewpoints have arisen in the body of work on cyberdeterrence:\n1. Cyberdeterrence is difficult but potentially achievable, through the ability to hold the adversary's critical cyberspace security objectives at risk.¹\n2. Cyberdeterrence is difficult and potentially unachievable, due to technical restraints pertaining to attribution.²\n3. Cyberdeterrence is legally unattainable, due to the UN Charter's prohibition on the use of force and domestic laws that forbid response actions at the substate echelon.³\n4. Cyberdeterrence is difficult if not impossible to achieve, as any measures taken are unlikely to deter potential adversaries; resources would be better spent pursuing other defensive means.⁴\nAcknowledging that these viewpoints outline the challenges of cyberdeterrence, this paper offers the following hypothesis:\nA nation-state, regardless of its size or military strength, can achieve cyberdeterrence if it can hold an adversary's critical cyberspace security objectives (CSOs) at risk by communicating its own retaliatory or autonomous cyberspace capability.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n¹ The term “hold at risk” should be understood as the means through which nations leverage military capabilities in order to threaten critical national security objectives of other nation-states.\n1. If the deterrence capability is retaliatory,\na. the deterring nation-state need only attribute nefarious actions to the IP space of the adversarial state;\nb. the capability likely would not violate the UN Charter’s prohibition against the use of force if it does not violate national sovereignty, does not damage/destroy people or objects, and does not provide weaponry or training to organized actors.\n2. If the deterrence capability is autonomous,\na. the deterring nation-state need not conduct attribution;\nb. the capability may be acceptable if it does not violate the UN Charter’s prohibition against the use of force or domestic law forbidding unauthorized network access.\n## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK\n### A. National Cyberspace Security Objectives\nAccording to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n1. Powerful states with more socio-political cohesion\n2. Powerful states with less socio-political cohesion\n3. Less powerful states with more socio-political cohesion\n4. Less powerful states with less socio-political cohesion\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech.[10] The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n# B. State Categorization\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\n1. States with more socio-political cohesion and more powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n2. States with more socio-political cohesion and less powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n3. States with less socio-political cohesion and more powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\n4. States with less socio-political cohesion and less powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n# 3. ATTRIBUTION AND CYBERDETERRENCE\nOne key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nwhich is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n## A. Retaliatory Capabilities and Attribution\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 4\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n# B. Autonomous Capabilities and Attribution\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nbetween routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\nTABLE 5\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |\n# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\n# A. Legal Considerations of Retaliatory Capabilities\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nunder international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\nTABLE 640\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 7\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n## B. Legal Considerations of Autonomous Capabilities\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 8\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\nTABLE 9\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n# 5. CONCLUSION\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.\n# 6. APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |",
  "flat_text": "2015 7th International Conference on Cyber Conflict:\nArchitectures in Cyberspace\nM.Maybaum, A.-M.Osula, L.Lindström (Eds.)\n2015 © NATO CCD COE Publications, Tallinn\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk*\nJason Rivera\nDeloitte &amp; Touche LLP\nThreat Intelligence &amp; Analytics\nCaptain, United States Army National Guard\nGeorgetown School of Foreign Service\nWashington, D.C., United States\njhr47@georgetown.edu\nAbstract: Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical \"walls\" in cyberspace over facilitating deterrent measures.\nThe notion of cyberdeterrence is especially daunting when considering how small states can deter larger, militarily more powerful states. For example, how would Estonia or Japan conduct deterrence through cyberspace against larger regional adversaries with more robust military capabilities? The power disparities between nations of such different military stature are seemingly overwhelming and insurmountable. It is these disparities in cyber power that present conceptual challenges, especially when measuring power in terms of military size, budget, strength, and technological capabilities.\n\"Power,\" however, is a broad term that should be considered beyond the military context. This is especially true in cyberspace, where a nation without a strong military can hold a militarily powerful nation at risk, so long as the former is aware of their strategic advantages as well as the critical vulnerabilities of the latter.\nGiven this reality, this paper shall suspend, or at least cast reasonable doubt on, the notion that cyberdeterrence is either difficult or impossible. Using a deductive method to analyze the components of cyberdeterrence strategy and examine the various challenges involved, this\n* All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte &amp; Touche LLP.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\npaper introduces a hypothesis on how small, less powerful states can hold large powerful states at risk through cyberspace.\nKeywords: attribution, cyberdeterrence, deterrence, use of force\n# 1. INTRODUCTION\nCyberdeterrence strategy remains largely unexplored and underdeveloped, due to a limited understanding of how the principles of deterrence can be applied to the cyber domain. Because cyberspace has only recently become an object of national security focus, the development of cyber theory relative to the other domains of warfare is relatively immature. In a broad sense, cyberspace warfighting strategy today is analogous to the growth of air power strategy during the interwar period between World Wars I and II. While the U.S. is actively developing doctrine, mobilizing forces, and allocating resources, there is still much to be done in developing comprehensive cyberspace warfighting strategies.\nThis paper defines cyberdeterrence as the mechanism through which nation-states can communicate proportionate, reciprocal, and credible military power effects through cyberspace that strategically affect their adversary's decision making calculus. The specific aim of cyberdeterrence is to deter an adversary from conducting hostile actions through cyberspace, although its application could be much broader. For example, a cyberdeterrent could be used to dissuade an adversary from conducting hostile conventional military actions, or even to gain diplomatic leverage.\nFour prevailing viewpoints have arisen in the body of work on cyberdeterrence:\n1. Cyberdeterrence is difficult but potentially achievable, through the ability to hold the adversary's critical cyberspace security objectives at risk.¹\n2. Cyberdeterrence is difficult and potentially unachievable, due to technical restraints pertaining to attribution.²\n3. Cyberdeterrence is legally unattainable, due to the UN Charter's prohibition on the use of force and domestic laws that forbid response actions at the substate echelon.³\n4. Cyberdeterrence is difficult if not impossible to achieve, as any measures taken are unlikely to deter potential adversaries; resources would be better spent pursuing other defensive means.⁴\nAcknowledging that these viewpoints outline the challenges of cyberdeterrence, this paper offers the following hypothesis:\nA nation-state, regardless of its size or military strength, can achieve cyberdeterrence if it can hold an adversary's critical cyberspace security objectives (CSOs) at risk by communicating its own retaliatory or autonomous cyberspace capability.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n¹ The term “hold at risk” should be understood as the means through which nations leverage military capabilities in order to threaten critical national security objectives of other nation-states.\n1. If the deterrence capability is retaliatory,\na. the deterring nation-state need only attribute nefarious actions to the IP space of the adversarial state;\nb. the capability likely would not violate the UN Charter’s prohibition against the use of force if it does not violate national sovereignty, does not damage/destroy people or objects, and does not provide weaponry or training to organized actors.\n2. If the deterrence capability is autonomous,\na. the deterring nation-state need not conduct attribution;\nb. the capability may be acceptable if it does not violate the UN Charter’s prohibition against the use of force or domestic law forbidding unauthorized network access.\n## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK\n### A. National Cyberspace Security Objectives\nAccording to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n1. Powerful states with more socio-political cohesion\n2. Powerful states with less socio-political cohesion\n3. Less powerful states with more socio-political cohesion\n4. Less powerful states with less socio-political cohesion\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech. The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n# B. State Categorization\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\n1. States with more socio-political cohesion and more powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n2. States with more socio-political cohesion and less powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n3. States with less socio-political cohesion and more powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\n4. States with less socio-political cohesion and less powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n# 3. ATTRIBUTION AND CYBERDETERRENCE\nOne key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nwhich is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n## A. Retaliatory Capabilities and Attribution\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 4\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n# B. Autonomous Capabilities and Attribution\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nbetween routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\nTABLE 5\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |\n# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\n# A. Legal Considerations of Retaliatory Capabilities\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nunder international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\nTABLE 640\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 7\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n## B. Legal Considerations of Autonomous Capabilities\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 8\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\nTABLE 9\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n# 5. CONCLUSION\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.\n# 6. APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |",
  "toc": [
    [
      1,
      "## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK ### A. National Cyberspace Security Objectives According to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:"
    ],
    [
      1,
      "# 3. ATTRIBUTION AND CYBERDETERRENCE"
    ],
    [
      1,
      "# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE"
    ],
    [
      1,
      "# 5. CONCLUSION"
    ],
    [
      1,
      "# 6. APPENDIX"
    ]
  ],
  "sections": {
    "## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK ### A. National Cyberspace Security Objectives According to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:": "In table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech.[10] The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n# B. State Categorization\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.",
    "# 3. ATTRIBUTION AND CYBERDETERRENCE": "One key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nwhich is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n## A. Retaliatory Capabilities and Attribution\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 4\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n# B. Autonomous Capabilities and Attribution\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nbetween routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\nTABLE 5\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |",
    "# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE": "# A. Legal Considerations of Retaliatory Capabilities\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nunder international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\nTABLE 640\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 7\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n## B. Legal Considerations of Autonomous Capabilities\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 8\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\nTABLE 9\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "# 5. CONCLUSION": "This paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.",
    "# 6. APPENDIX": "|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |"
  },
  "process_log": {
    "scheme": "numeric_hint",
    "numeric_check": {
      "first_num": 2,
      "raw_count": 5,
      "raw_examples": [
        2,
        3,
        4,
        5,
        6
      ],
      "filtered_count": 5,
      "filtered_examples": [
        2,
        3,
        4,
        5,
        6
      ],
      "seq_score": 1.0
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 5,
      "count": 5,
      "min": 2,
      "examples": [
        2,
        3,
        4,
        5,
        6
      ],
      "best_run": 5
    },
    "toc_count": 5,
    "section_count": 5
  },
  "word_count": 6388,
  "references": [
    "# REFERENCES\n[1] Forrest Hare, 'The Significance of Attribution to Cyberspace Coercion: A Political Perspective' 4th International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications, 2012), 131.\n[2] Dmitri Alperovitch, 'Towards Establishment of Cyberspace Deterrence Strategy' 3rd International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications, 2011), 91.\n[3] Michael Schmitt, Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework (Colorado Springs, CO: U.S. Air Force Academy, 1999), 17.\n[4] Gregory Rattray and Jason Healey, 'Categorizing and Understanding Offensive Cyber Capabilities and Their Use' Proceedings of a Workshop on Deterring Cyberattacks (Washington, DC: National Academies Press, 2010), 88.\n[5] John J. Mearsheimer, The Tragedy of Great Power Politics (New York: Norton &amp; Company, 2011), 50.\n[6] Barry Buzan, People, States, &amp; Fear: An Agenda for International Security Studies in the Post-Cold War Era (London, UK: ECPR Press, 1991), 134.\n[7] Forrest Hare, 'The Cyber Threat to National Security: Why Can't We Agree?' 2nd International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications, 2010), 218.\n[8] Ibid.\n[9] Melissa Hathaway, 'Developing International Norms for a Safe, Stable, and Predictable Cyber Environment' Georgetown University Conference on International Engagement on Cyber, March 4, 2014.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n[10] Jason Rivera, 'North Korea Has Crossed the Cyber Red Line by Combining Cyberattacks with the Threat of Terrorism—and the United States Must Respond' (2014) Georgetown Security Studies Review http://georgetownsecuritystudiesreview.org/2014/12/18/north-korea-has-crossed-the-cyber-red-line-by-combining-cyberattacks-with-the-threat-of-terrorism-and-the-united-states-must-respond/ (accessed 19 Dec. 2014).\n[11] British Columbia, 'Security News Digest' http://www.cio.gov.bc.ca/local/cio/informationsecurity/pdf_securitynewsdigest/02_24_2015.pdf (accessed 16 Mar. 2015).\n[12] Ibid.\n[13] RBN Exploit 'Russian Business Network (RBN)' HostExploit, 2014. http://rbnexploit.blogspot.com/ (accessed 4 Nov. 2014).\n[14] Brian Krebs, 'Home Depot Hit by Same Malware as Target' krebsonsecurity.com, 2014. http://krebsonsecurity.com/2014/09/home-depot-hit-by-same-malware-as-target/ (accessed 4 Nov. 2014).\n[15] U.S. Embassy Beijing, 'New PRC Internet Regulations' Federation of American Scientists, 1998. https://www.fas.org/irp/world/china/netreg.htm (accessed 6 Apr. 2014).\n[16] Jonathan Zittrain and Benjamin Edelman, 'Empirical Analysis of Internet Filtering in China' Harvard Law School, Berkman Center for Internet and Society, 2003. http://cyber.law.harvard.edu/filtering/china/ (accessed 6 Apr. 2014).\n[17] Martin Libicki, Cyberdeterrence and Cyberwar (Santa Monica, CA: RAND Corporation, 2009), 27.\n[18] W. Earl Boebert, A Survey of Challenges in Attribution (National Academies Press Online 2010), 44.\n[19] Ibid.\n[20] U.S. Senator Sheldon Whitehouse (Rhode Island), Comments made at Georgetown University Conference—International Engagement on Cyber: Developing International Norms for a Safe, Stable, and Predictable Cyber Environment, March 4, 2014.\n[21] Mandiant, APTI: Exposing One of China's Cyber Espionage Units (Mandiant 2013), 19.\n[22] Jason Healey, 'Beyond Attribution: Seeking National Responsibility for Cyber Attacks' Atlantic Council, Cyber Statecraft Initiative (Washington, DC: Atlantic Council, 2012), 1.\n[23] Ibid.\n[24] Ibid., 2.\n[25] 'Ten Years After: The FBI Since 9/11,' FBI website, 2014. http://www.fbi.gov/about-us/ten-years-after-the-fbi-since-9-11/just-the-facts-1/cyber (accessed 19 Apr. 2014).\n[26] Jaikumar Vijayan, 'US Tops List of Countries Hosting Malware and Botnets' securityintelligence.com, 2014. http://securityintelligence.com/news/us-tops-list-of-countries-hosting-malware-and-botnets/#. VQa82PnF-So (accessed 16 Mar. 2015).\n[27] U.S. House Subcommittee on Counterterrorism and Intelligence and the Subcommittee on Cybersecurity, Infrastructure Protection, and Security Technologies, 'Iranian Cyber Threat to the U.S. Homeland' April 26, 2012. http://www.gpo.gov/fdsys/pkg/CHRG-112hhrg77381/html/CHRG-112hhrg77381.htm (accessed 19 Apr. 2014).\n[28] DHS Office of Cybersecurity &amp; Communications, 'Cyber News Spotlight: Insight on Cybersecurity News &amp; Trends for Critical Infrastructure' http://www.htcia.org/wp-content/uploads/Cyber-News-Spotlight-February-2014.pdf (accessed 16 Mar. 2015).\n[29] Andreas Hagen, 'The Russo-Georgian War 2008' in A Fierce Domain: Conflict in Cyberspace, 1986 to 2012 (Vienna, VA: Cyber Conflict Studies Association, 2013), 197.\n[30] Dorothy Denning, 'Stuxnet: What Has Changed?' (2012) 4 Future Internet, 673.\n[31] Joshua Kopstein, 'Stuxnet Virus Was Planted by Israeli Agents Using USB Sticks, According to New Report' The Verge, 2012. http://www.theverge.com/2012/4/12/2944329/stuxnet-computer-virus-planted-israeli-agent-iran (accessed 19 Apr. 2014).\n[32] Jonathan Diamond, 'Early Patriotic Hacking,' in Jason Healey (ed.) A Fierce Domain: Conflict in Cyberspace, 1986 to 2012 (Vienna, VA: Cyber Conflict Studies Association, 2013), 138-139.\n[33] 'Significant Cyberattack Incidents: Operation Orchard, 2007' Real Clear Politics, 2013. http://www.realclearpolitics.com/lists/cyber_attacks/op_orchard.html (accessed 16 Apr. 2014).\n[34] Ibid., 21.\n[35] Healey, 'Beyond Attribution: Seeking National Responsibility for Cyber Attacks', 4.\n[36] Michael Schmitt et al., Tallinn Manual on the International Law Applicable to Cyber Warfare (Cambridge, UK: Cambridge University Press 2013), 45.\n[37] UN Charter, art. 2, para. 7.\n[38] Ibid., 46.\n[39] International Court of Justice, 'Military and Paramilitary Activities in and against Nicaragua (Nicaragua v. United States of America, 1986)' www.icj-cij.org. http://www.icj-cij.org/docket/index.php?sum=367&amp;p1=3&amp;p2=3&amp;case=70&amp;p3=5 (accessed 22 Apr. 2014).\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n[40] Schmitt, Tallinn Manual on the International Law Applicable to Cyber Warfare, 48-49.\n[41] Patricia Figliola et al., ‘U.S. Initiatives to Promote Global Internet Freedom: Issues, Policy, and Technology’ Congressional Research Service (Washington, DC: GPO 2011), 10.\n[42] Jason Rivera, ‘Understanding and Countering Nation-State Use of Protracted Unconventional Warfare’ (2014) Small Wars Journal http://smallwarsjournal.com/jrnl/art/understanding-and-countering-nation-state-use-of-protracted-unconventional-warfare (accessed 24 Dec. 2014).\n[43] 18 U.S.C. § 1030: US Code—Section 1030: Fraud and related activity in connection with computers.\n[44] Jason Rivera and Forrest Hare ‘The Deployment of Attribution Agnostic Cyberdefense Constructs and Internally Based Cyberthreat Countermeasures’ 6th International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications 2014), 109-110.\n[45] Andru Wall, ‘Demystifying the Title 10-Title 50 Debate: Distinguishing Military Operations, Intelligence Activities &amp; Covert Action’ Harvard National Security Journal 3 (2012), 118.\n[46] Rivera &amp; Hare, ‘The Deployment of Attribution Agnostic Cyberdefense Constructs and Internally Based Cyberthreat Countermeasures’, 112.\n[47] Ibid., 113.\n[48] Global Fire Power, ‘Countries Ranked by Military Strength,’ www.globalfirepower.com, 2014. http://www.globalfirepower.com/countries-listing.asp (accessed 9 May 2014).\n[49] Jeffrey Carr, Inside Cyber Warfare: Mapping the Cyber Underworld (Sebastopol, CA: O’Reilly Media, Inc., 2011), 243-261.\n[50] Arch Puddington, Freedom in the World 2014 (Washington, DC: Freedom House 2014), 18-22.\n[51] Ibid.\n24 Authorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply."
  ],
  "citations": {
    "style": "numeric",
    "flat_text": "2015 7th International Conference on Cyber Conflict:\nArchitectures in Cyberspace\nM.Maybaum, A.-M.Osula, L.Lindström (Eds.)\n2015 © NATO CCD COE Publications, Tallinn\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk*\nJason Rivera\nDeloitte &amp; Touche LLP\nThreat Intelligence &amp; Analytics\nCaptain, United States Army National Guard\nGeorgetown School of Foreign Service\nWashington, D.C., United States\njhr47@georgetown.edu\nAbstract: Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical \"walls\" in cyberspace over facilitating deterrent measures.\nThe notion of cyberdeterrence is especially daunting when considering how small states can deter larger, militarily more powerful states. For example, how would Estonia or Japan conduct deterrence through cyberspace against larger regional adversaries with more robust military capabilities? The power disparities between nations of such different military stature are seemingly overwhelming and insurmountable. It is these disparities in cyber power that present conceptual challenges, especially when measuring power in terms of military size, budget, strength, and technological capabilities.\n\"Power,\" however, is a broad term that should be considered beyond the military context. This is especially true in cyberspace, where a nation without a strong military can hold a militarily powerful nation at risk, so long as the former is aware of their strategic advantages as well as the critical vulnerabilities of the latter.\nGiven this reality, this paper shall suspend, or at least cast reasonable doubt on, the notion that cyberdeterrence is either difficult or impossible. Using a deductive method to analyze the components of cyberdeterrence strategy and examine the various challenges involved, this\n* All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte &amp; Touche LLP.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\npaper introduces a hypothesis on how small, less powerful states can hold large powerful states at risk through cyberspace.\nKeywords: attribution, cyberdeterrence, deterrence, use of force\n# 1. INTRODUCTION\nCyberdeterrence strategy remains largely unexplored and underdeveloped, due to a limited understanding of how the principles of deterrence can be applied to the cyber domain. Because cyberspace has only recently become an object of national security focus, the development of cyber theory relative to the other domains of warfare is relatively immature. In a broad sense, cyberspace warfighting strategy today is analogous to the growth of air power strategy during the interwar period between World Wars I and II. While the U.S. is actively developing doctrine, mobilizing forces, and allocating resources, there is still much to be done in developing comprehensive cyberspace warfighting strategies.\nThis paper defines cyberdeterrence as the mechanism through which nation-states can communicate proportionate, reciprocal, and credible military power effects through cyberspace that strategically affect their adversary's decision making calculus. The specific aim of cyberdeterrence is to deter an adversary from conducting hostile actions through cyberspace, although its application could be much broader. For example, a cyberdeterrent could be used to dissuade an adversary from conducting hostile conventional military actions, or even to gain diplomatic leverage.\nFour prevailing viewpoints have arisen in the body of work on cyberdeterrence:\n1. Cyberdeterrence is difficult but potentially achievable, through the ability to hold the adversary's critical cyberspace security objectives at risk.¹\n2. Cyberdeterrence is difficult and potentially unachievable, due to technical restraints pertaining to attribution.²\n3. Cyberdeterrence is legally unattainable, due to the UN Charter's prohibition on the use of force and domestic laws that forbid response actions at the substate echelon.³\n4. Cyberdeterrence is difficult if not impossible to achieve, as any measures taken are unlikely to deter potential adversaries; resources would be better spent pursuing other defensive means.⁴\nAcknowledging that these viewpoints outline the challenges of cyberdeterrence, this paper offers the following hypothesis:\nA nation-state, regardless of its size or military strength, can achieve cyberdeterrence if it can hold an adversary's critical cyberspace security objectives (CSOs) at risk by communicating its own retaliatory or autonomous cyberspace capability.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n¹ The term “hold at risk” should be understood as the means through which nations leverage military capabilities in order to threaten critical national security objectives of other nation-states.\n1. If the deterrence capability is retaliatory,\na. the deterring nation-state need only attribute nefarious actions to the IP space of the adversarial state;\nb. the capability likely would not violate the UN Charter’s prohibition against the use of force if it does not violate national sovereignty, does not damage/destroy people or objects, and does not provide weaponry or training to organized actors.\n2. If the deterrence capability is autonomous,\na. the deterring nation-state need not conduct attribution;\nb. the capability may be acceptable if it does not violate the UN Charter’s prohibition against the use of force or domestic law forbidding unauthorized network access.\n## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK\n### A. National Cyberspace Security Objectives\nAccording to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n1. Powerful states with more socio-political cohesion\n2. Powerful states with less socio-political cohesion\n3. Less powerful states with more socio-political cohesion\n4. Less powerful states with less socio-political cohesion\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech. The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n# B. State Categorization\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\n1. States with more socio-political cohesion and more powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n2. States with more socio-political cohesion and less powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n3. States with less socio-political cohesion and more powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\n4. States with less socio-political cohesion and less powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n# 3. ATTRIBUTION AND CYBERDETERRENCE\nOne key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nwhich is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n## A. Retaliatory Capabilities and Attribution\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 4\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n# B. Autonomous Capabilities and Attribution\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nbetween routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\nTABLE 5\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |\n# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\n# A. Legal Considerations of Retaliatory Capabilities\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nunder international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\nTABLE 640\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 7\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n## B. Legal Considerations of Autonomous Capabilities\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 8\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\nTABLE 9\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n# 5. CONCLUSION\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.\n# 6. APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |",
    "footnotes": {
      "items": {},
      "intext": [
        {
          "index": "49",
          "intext_citation": "^{49}",
          "preceding_text": "APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs",
          "footnote": null
        },
        {
          "index": "50",
          "intext_citation": "^{50}",
          "preceding_text": "APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights",
          "footnote": null
        },
        {
          "index": "51",
          "intext_citation": "^{51}",
          "preceding_text": "APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties",
          "footnote": null
        }
      ],
      "stats": {
        "intext_total": 3,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 48,
        "missing_intext_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48
        ],
        "highest_intext_index": 51,
        "missing_footnotes_for_seen_total": 3,
        "missing_footnotes_for_seen_intext": [
          49,
          50,
          51
        ],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 1,
        "success_occurrences": 1,
        "success_unique": 1,
        "bib_unique_total": 51,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.0196078431372549,
        "success_percentage": 100.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "10",
          "intext_citation": "[10]",
          "preceding_text": "commercial sector's capacity to exercise freedom of speech.",
          "footnote": "Jason Rivera, 'North Korea Has Crossed the Cyber Red Line by Combining Cyberattacks with the Threat of Terrorism—and the United States Must Respond' (2014) Georgetown Security Studies Review http://georgetownsecuritystudiesreview.org/2014/12/18/north-korea-has-crossed-the-cyber-red-line-by-combining-cyberattacks-with-the-threat-of-terrorism-and-the-united-states-must-respond/ (accessed 19 Dec. 2014)."
        }
      ],
      "flat_text": "2015 7th International Conference on Cyber Conflict:\nArchitectures in Cyberspace\nM.Maybaum, A.-M.Osula, L.Lindström (Eds.)\n2015 © NATO CCD COE Publications, Tallinn\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk*\nJason Rivera\nDeloitte &amp; Touche LLP\nThreat Intelligence &amp; Analytics\nCaptain, United States Army National Guard\nGeorgetown School of Foreign Service\nWashington, D.C., United States\njhr47@georgetown.edu\nAbstract: Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical \"walls\" in cyberspace over facilitating deterrent measures.\nThe notion of cyberdeterrence is especially daunting when considering how small states can deter larger, militarily more powerful states. For example, how would Estonia or Japan conduct deterrence through cyberspace against larger regional adversaries with more robust military capabilities? The power disparities between nations of such different military stature are seemingly overwhelming and insurmountable. It is these disparities in cyber power that present conceptual challenges, especially when measuring power in terms of military size, budget, strength, and technological capabilities.\n\"Power,\" however, is a broad term that should be considered beyond the military context. This is especially true in cyberspace, where a nation without a strong military can hold a militarily powerful nation at risk, so long as the former is aware of their strategic advantages as well as the critical vulnerabilities of the latter.\nGiven this reality, this paper shall suspend, or at least cast reasonable doubt on, the notion that cyberdeterrence is either difficult or impossible. Using a deductive method to analyze the components of cyberdeterrence strategy and examine the various challenges involved, this\n* All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte &amp; Touche LLP.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\npaper introduces a hypothesis on how small, less powerful states can hold large powerful states at risk through cyberspace.\nKeywords: attribution, cyberdeterrence, deterrence, use of force\n# 1. INTRODUCTION\nCyberdeterrence strategy remains largely unexplored and underdeveloped, due to a limited understanding of how the principles of deterrence can be applied to the cyber domain. Because cyberspace has only recently become an object of national security focus, the development of cyber theory relative to the other domains of warfare is relatively immature. In a broad sense, cyberspace warfighting strategy today is analogous to the growth of air power strategy during the interwar period between World Wars I and II. While the U.S. is actively developing doctrine, mobilizing forces, and allocating resources, there is still much to be done in developing comprehensive cyberspace warfighting strategies.\nThis paper defines cyberdeterrence as the mechanism through which nation-states can communicate proportionate, reciprocal, and credible military power effects through cyberspace that strategically affect their adversary's decision making calculus. The specific aim of cyberdeterrence is to deter an adversary from conducting hostile actions through cyberspace, although its application could be much broader. For example, a cyberdeterrent could be used to dissuade an adversary from conducting hostile conventional military actions, or even to gain diplomatic leverage.\nFour prevailing viewpoints have arisen in the body of work on cyberdeterrence:\n1. Cyberdeterrence is difficult but potentially achievable, through the ability to hold the adversary's critical cyberspace security objectives at risk.¹\n2. Cyberdeterrence is difficult and potentially unachievable, due to technical restraints pertaining to attribution.²\n3. Cyberdeterrence is legally unattainable, due to the UN Charter's prohibition on the use of force and domestic laws that forbid response actions at the substate echelon.³\n4. Cyberdeterrence is difficult if not impossible to achieve, as any measures taken are unlikely to deter potential adversaries; resources would be better spent pursuing other defensive means.⁴\nAcknowledging that these viewpoints outline the challenges of cyberdeterrence, this paper offers the following hypothesis:\nA nation-state, regardless of its size or military strength, can achieve cyberdeterrence if it can hold an adversary's critical cyberspace security objectives (CSOs) at risk by communicating its own retaliatory or autonomous cyberspace capability.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n¹ The term “hold at risk” should be understood as the means through which nations leverage military capabilities in order to threaten critical national security objectives of other nation-states.\n1. If the deterrence capability is retaliatory,\na. the deterring nation-state need only attribute nefarious actions to the IP space of the adversarial state;\nb. the capability likely would not violate the UN Charter’s prohibition against the use of force if it does not violate national sovereignty, does not damage/destroy people or objects, and does not provide weaponry or training to organized actors.\n2. If the deterrence capability is autonomous,\na. the deterring nation-state need not conduct attribution;\nb. the capability may be acceptable if it does not violate the UN Charter’s prohibition against the use of force or domestic law forbidding unauthorized network access.\n## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK\n### A. National Cyberspace Security Objectives\nAccording to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n1. Powerful states with more socio-political cohesion\n2. Powerful states with less socio-political cohesion\n3. Less powerful states with more socio-political cohesion\n4. Less powerful states with less socio-political cohesion\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech. The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n# B. State Categorization\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\n1. States with more socio-political cohesion and more powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n2. States with more socio-political cohesion and less powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n3. States with less socio-political cohesion and more powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\n4. States with less socio-political cohesion and less powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n# 3. ATTRIBUTION AND CYBERDETERRENCE\nOne key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nwhich is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n## A. Retaliatory Capabilities and Attribution\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 4\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n# B. Autonomous Capabilities and Attribution\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nbetween routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\nTABLE 5\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |\n# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\n# A. Legal Considerations of Retaliatory Capabilities\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nunder international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\nTABLE 640\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 7\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n## B. Legal Considerations of Autonomous Capabilities\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 8\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\nTABLE 9\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n# 5. CONCLUSION\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.\n# 6. APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |"
    },
    "numeric": {
      "total": {
        "intext_total": 1,
        "success_occurrences": 1,
        "success_unique": 1,
        "bib_unique_total": 51,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.0196078431372549,
        "success_percentage": 100.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "10",
          "intext_citation": "[10]",
          "preceding_text": "commercial sector's capacity to exercise freedom of speech.",
          "footnote": "Jason Rivera, 'North Korea Has Crossed the Cyber Red Line by Combining Cyberattacks with the Threat of Terrorism—and the United States Must Respond' (2014) Georgetown Security Studies Review http://georgetownsecuritystudiesreview.org/2014/12/18/north-korea-has-crossed-the-cyber-red-line-by-combining-cyberattacks-with-the-threat-of-terrorism-and-the-united-states-must-respond/ (accessed 19 Dec. 2014)."
        }
      ],
      "flat_text": "2015 7th International Conference on Cyber Conflict:\nArchitectures in Cyberspace\nM.Maybaum, A.-M.Osula, L.Lindström (Eds.)\n2015 © NATO CCD COE Publications, Tallinn\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk*\nJason Rivera\nDeloitte &amp; Touche LLP\nThreat Intelligence &amp; Analytics\nCaptain, United States Army National Guard\nGeorgetown School of Foreign Service\nWashington, D.C., United States\njhr47@georgetown.edu\nAbstract: Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical \"walls\" in cyberspace over facilitating deterrent measures.\nThe notion of cyberdeterrence is especially daunting when considering how small states can deter larger, militarily more powerful states. For example, how would Estonia or Japan conduct deterrence through cyberspace against larger regional adversaries with more robust military capabilities? The power disparities between nations of such different military stature are seemingly overwhelming and insurmountable. It is these disparities in cyber power that present conceptual challenges, especially when measuring power in terms of military size, budget, strength, and technological capabilities.\n\"Power,\" however, is a broad term that should be considered beyond the military context. This is especially true in cyberspace, where a nation without a strong military can hold a militarily powerful nation at risk, so long as the former is aware of their strategic advantages as well as the critical vulnerabilities of the latter.\nGiven this reality, this paper shall suspend, or at least cast reasonable doubt on, the notion that cyberdeterrence is either difficult or impossible. Using a deductive method to analyze the components of cyberdeterrence strategy and examine the various challenges involved, this\n* All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte &amp; Touche LLP.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\npaper introduces a hypothesis on how small, less powerful states can hold large powerful states at risk through cyberspace.\nKeywords: attribution, cyberdeterrence, deterrence, use of force\n# 1. INTRODUCTION\nCyberdeterrence strategy remains largely unexplored and underdeveloped, due to a limited understanding of how the principles of deterrence can be applied to the cyber domain. Because cyberspace has only recently become an object of national security focus, the development of cyber theory relative to the other domains of warfare is relatively immature. In a broad sense, cyberspace warfighting strategy today is analogous to the growth of air power strategy during the interwar period between World Wars I and II. While the U.S. is actively developing doctrine, mobilizing forces, and allocating resources, there is still much to be done in developing comprehensive cyberspace warfighting strategies.\nThis paper defines cyberdeterrence as the mechanism through which nation-states can communicate proportionate, reciprocal, and credible military power effects through cyberspace that strategically affect their adversary's decision making calculus. The specific aim of cyberdeterrence is to deter an adversary from conducting hostile actions through cyberspace, although its application could be much broader. For example, a cyberdeterrent could be used to dissuade an adversary from conducting hostile conventional military actions, or even to gain diplomatic leverage.\nFour prevailing viewpoints have arisen in the body of work on cyberdeterrence:\n1. Cyberdeterrence is difficult but potentially achievable, through the ability to hold the adversary's critical cyberspace security objectives at risk.¹\n2. Cyberdeterrence is difficult and potentially unachievable, due to technical restraints pertaining to attribution.²\n3. Cyberdeterrence is legally unattainable, due to the UN Charter's prohibition on the use of force and domestic laws that forbid response actions at the substate echelon.³\n4. Cyberdeterrence is difficult if not impossible to achieve, as any measures taken are unlikely to deter potential adversaries; resources would be better spent pursuing other defensive means.⁴\nAcknowledging that these viewpoints outline the challenges of cyberdeterrence, this paper offers the following hypothesis:\nA nation-state, regardless of its size or military strength, can achieve cyberdeterrence if it can hold an adversary's critical cyberspace security objectives (CSOs) at risk by communicating its own retaliatory or autonomous cyberspace capability.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n¹ The term “hold at risk” should be understood as the means through which nations leverage military capabilities in order to threaten critical national security objectives of other nation-states.\n1. If the deterrence capability is retaliatory,\na. the deterring nation-state need only attribute nefarious actions to the IP space of the adversarial state;\nb. the capability likely would not violate the UN Charter’s prohibition against the use of force if it does not violate national sovereignty, does not damage/destroy people or objects, and does not provide weaponry or training to organized actors.\n2. If the deterrence capability is autonomous,\na. the deterring nation-state need not conduct attribution;\nb. the capability may be acceptable if it does not violate the UN Charter’s prohibition against the use of force or domestic law forbidding unauthorized network access.\n## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK\n### A. National Cyberspace Security Objectives\nAccording to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n1. Powerful states with more socio-political cohesion\n2. Powerful states with less socio-political cohesion\n3. Less powerful states with more socio-political cohesion\n4. Less powerful states with less socio-political cohesion\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech. The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n# B. State Categorization\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\n1. States with more socio-political cohesion and more powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n2. States with more socio-political cohesion and less powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n3. States with less socio-political cohesion and more powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\n4. States with less socio-political cohesion and less powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n# 3. ATTRIBUTION AND CYBERDETERRENCE\nOne key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nwhich is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n## A. Retaliatory Capabilities and Attribution\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 4\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n# B. Autonomous Capabilities and Attribution\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nbetween routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\nTABLE 5\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |\n# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\n# A. Legal Considerations of Retaliatory Capabilities\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nunder international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\nTABLE 640\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 7\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n## B. Legal Considerations of Autonomous Capabilities\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 8\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\nTABLE 9\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n# 5. CONCLUSION\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.\n# 6. APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |"
    },
    "author_year": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 119,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [],
      "flat_text": "Architectures in Cyberspace M.Maybaum, A.-M.Osula, L.Lindström (Eds.)\n\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk* Jason Rivera Deloitte &amp; Touche LLP Threat Intelligence &amp; Analytics Captain, United States Army National Guard Georgetown School of Foreign Service Washington, D.C., United States jhr47@georgetown.edu Abstract: Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical\"walls\"in cyberspace over facilitating deterrent measures.\nThe notion of cyberdeterrence is especially daunting when considering how small states can deter larger, militarily more powerful states. For example, how would Estonia or Japan conduct deterrence through cyberspace against larger regional adversaries with more robust military capabilities? The power disparities between nations of such different military stature are seemingly overwhelming and insurmountable. It is these disparities in cyber power that present conceptual challenges, especially when measuring power in terms of military size, budget, strength, and technological capabilities.\"Power,\"however, is a broad term that should be considered beyond the military context. This is especially true in cyberspace, where a nation without a strong military can hold a militarily powerful nation at risk, so long as the former is aware of their strategic advantages as well as the critical vulnerabilities of the latter.\nGiven this reality, this paper shall suspend, or at least cast reasonable doubt on, the notion that cyberdeterrence is either difficult or impossible. Using a deductive method to analyze the components of cyberdeterrence strategy and examine the various challenges involved, this * All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte &amp; Touche LLP.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\npaper introduces a hypothesis on how small, less powerful states can hold large powerful states at risk through cyberspace.\nKeywords: attribution, cyberdeterrence, deterrence, use of force # 1. INTRODUCTION Cyberdeterrence strategy remains largely unexplored and underdeveloped, due to a limited understanding of how the principles of deterrence can be applied to the cyber domain. Because cyberspace has only recently become an object of national security focus, the development of cyber theory relative to the other domains of warfare is relatively immature. In a broad sense, cyberspace warfighting strategy today is analogous to the growth of air power strategy during the interwar period between World Wars I and II. While the U.S. is actively developing doctrine, mobilizing forces, and allocating resources, there is still much to be done in developing comprehensive cyberspace warfighting strategies.\nThis paper defines cyberdeterrence as the mechanism through which nation-states can communicate proportionate, reciprocal, and credible military power effects through cyberspace that strategically affect their adversary's decision making calculus. The specific aim of cyberdeterrence is to deter an adversary from conducting hostile actions through cyberspace, although its application could be much broader. For example, a cyberdeterrent could be used to dissuade an adversary from conducting hostile conventional military actions, or even to gain diplomatic leverage.\nFour prevailing viewpoints have arisen in the body of work on cyberdeterrence: Acknowledging that these viewpoints outline the challenges of cyberdeterrence, this paper offers the following hypothesis: A nation-state, regardless of its size or military strength, can achieve cyberdeterrence if it can hold an adversary's critical cyberspace security objectives (CSOs) at risk by communicating its own retaliatory or autonomous cyberspace capability.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n¹ The term “hold at risk” should be understood as the means through which nations leverage military capabilities in order to threaten critical national security objectives of other nation-states.\n\na. the deterring nation-state need only attribute nefarious actions to the IP space of the adversarial state; b. the capability likely would not violate the UN Charter’s prohibition against the use of force if it does not violate national sovereignty, does not damage/destroy people or objects, and does not provide weaponry or training to organized actors.\n\na. the deterring nation-state need not conduct attribution; b. the capability may be acceptable if it does not violate the UN Charter’s prohibition against the use of force or domestic law forbidding unauthorized network access.\n## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK ### A. National Cyberspace Security Objectives According to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech.[10] The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n# B. State Categorization\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\n\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n# 3. ATTRIBUTION AND CYBERDETERRENCE\nOne key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nwhich is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n## A. Retaliatory Capabilities and Attribution\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 4\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n# B. Autonomous Capabilities and Attribution\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nbetween routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\nTABLE 5\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |\n# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\n# A. Legal Considerations of Retaliatory Capabilities\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nunder international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\nTABLE 640\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 7\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n## B. Legal Considerations of Autonomous Capabilities\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 8\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\nTABLE 9\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n# 5. CONCLUSION\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.\n# 6. APPENDIX\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |"
    }
  },
  "summary": {
    "full_text": {
      "words": 6678,
      "tokens": 9668
    },
    "flat_text": {
      "words": 6388,
      "tokens": 9257
    }
  },
  "payload": "## ## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK ### A. National Cyberspace Security Objectives According to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTABLE 18\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\nTABLE 29\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nconducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech.[10] The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\nTABLE 3\nSocio-political Cohesion\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nTable 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n## C. Retaliatory and Autonomous Capabilities\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\nand, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n\n---\n\n## # 5. CONCLUSION\n\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:PARTIAL_BODY\nsections_raw:5\nsections_clean:5\nintro:FOUND\nconclusion:FOUND\npredefined_sections:None\nextra_sections:None\npayload_tokens_before:8323\npayload_tokens_after:4276\ndropped_section:# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\nadded_section:None\n---LOG_SUMMARY_END---",
  "pages_text": [
    "2015 7th International Conference on Cyber Conflict:\nArchitectures in Cyberspace\nM.Maybaum, A.-M.Osula, L.Lindström (Eds.)\n2015 © NATO CCD COE Publications, Tallinn\n\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n\n# Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk*\n\nJason Rivera\nDeloitte &amp; Touche LLP\nThreat Intelligence &amp; Analytics\nCaptain, United States Army National Guard\nGeorgetown School of Foreign Service\nWashington, D.C., United States\njhr47@georgetown.edu\n\nAbstract: Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical \"walls\" in cyberspace over facilitating deterrent measures.\n\nThe notion of cyberdeterrence is especially daunting when considering how small states can deter larger, militarily more powerful states. For example, how would Estonia or Japan conduct deterrence through cyberspace against larger regional adversaries with more robust military capabilities? The power disparities between nations of such different military stature are seemingly overwhelming and insurmountable. It is these disparities in cyber power that present conceptual challenges, especially when measuring power in terms of military size, budget, strength, and technological capabilities.\n\n\"Power,\" however, is a broad term that should be considered beyond the military context. This is especially true in cyberspace, where a nation without a strong military can hold a militarily powerful nation at risk, so long as the former is aware of their strategic advantages as well as the critical vulnerabilities of the latter.\n\nGiven this reality, this paper shall suspend, or at least cast reasonable doubt on, the notion that cyberdeterrence is either difficult or impossible. Using a deductive method to analyze the components of cyberdeterrence strategy and examine the various challenges involved, this\n\n* All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte &amp; Touche LLP.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "paper introduces a hypothesis on how small, less powerful states can hold large powerful states at risk through cyberspace.\n\nKeywords: attribution, cyberdeterrence, deterrence, use of force\n\n# 1. INTRODUCTION\n\nCyberdeterrence strategy remains largely unexplored and underdeveloped, due to a limited understanding of how the principles of deterrence can be applied to the cyber domain. Because cyberspace has only recently become an object of national security focus, the development of cyber theory relative to the other domains of warfare is relatively immature. In a broad sense, cyberspace warfighting strategy today is analogous to the growth of air power strategy during the interwar period between World Wars I and II. While the U.S. is actively developing doctrine, mobilizing forces, and allocating resources, there is still much to be done in developing comprehensive cyberspace warfighting strategies.\n\nThis paper defines cyberdeterrence as the mechanism through which nation-states can communicate proportionate, reciprocal, and credible military power effects through cyberspace that strategically affect their adversary's decision making calculus. The specific aim of cyberdeterrence is to deter an adversary from conducting hostile actions through cyberspace, although its application could be much broader. For example, a cyberdeterrent could be used to dissuade an adversary from conducting hostile conventional military actions, or even to gain diplomatic leverage.\n\nFour prevailing viewpoints have arisen in the body of work on cyberdeterrence:\n\n1. Cyberdeterrence is difficult but potentially achievable, through the ability to hold the adversary's critical cyberspace security objectives at risk.¹\n2. Cyberdeterrence is difficult and potentially unachievable, due to technical restraints pertaining to attribution.²\n3. Cyberdeterrence is legally unattainable, due to the UN Charter's prohibition on the use of force and domestic laws that forbid response actions at the substate echelon.³\n4. Cyberdeterrence is difficult if not impossible to achieve, as any measures taken are unlikely to deter potential adversaries; resources would be better spent pursuing other defensive means.⁴\n\nAcknowledging that these viewpoints outline the challenges of cyberdeterrence, this paper offers the following hypothesis:\n\nA nation-state, regardless of its size or military strength, can achieve cyberdeterrence if it can hold an adversary's critical cyberspace security objectives (CSOs) at risk by communicating its own retaliatory or autonomous cyberspace capability.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.\n\n¹ The term “hold at risk” should be understood as the means through which nations leverage military capabilities in order to threaten critical national security objectives of other nation-states.",
    "1. If the deterrence capability is retaliatory,\na. the deterring nation-state need only attribute nefarious actions to the IP space of the adversarial state;\nb. the capability likely would not violate the UN Charter’s prohibition against the use of force if it does not violate national sovereignty, does not damage/destroy people or objects, and does not provide weaponry or training to organized actors.\n\n2. If the deterrence capability is autonomous,\na. the deterring nation-state need not conduct attribution;\nb. the capability may be acceptable if it does not violate the UN Charter’s prohibition against the use of force or domestic law forbidding unauthorized network access.\n\n## 2. HOLDING A LARGE STATE’S CRITICAL CYBERSPACE SECURITY OBJECTIVES AT RISK\n\n### A. National Cyberspace Security Objectives\n\nAccording to realist theory, anarchy forces states to compete for power because that is the best way to achieve security, and achieving security is the only way to ensure survival. This concept is no different in cyberspace, and it applies to the security objectives of nation-states within the cyber domain. In *People, States, and Fear: An Agenda for International Security Studies in the Post-Cold War Era*, Barry Buzan cites two principle lenses through which states view their security interests: their ability to leverage military power and their internal socio-political cohesion.⁶ In his article ‘The Cyber Threat to National Security: Why Can’t We Agree?’ military strategist and author Forrest Hare argues that these two lenses also heavily affect a nation-state’s security objectives in cyberspace.⁷ These two lenses divide states into four broad categories:\n\n1. Powerful states with more socio-political cohesion\n2. Powerful states with less socio-political cohesion\n3. Less powerful states with more socio-political cohesion\n4. Less powerful states with less socio-political cohesion\n\nIn table 1, Hare sums up states’ cyberspace vulnerabilities based on their socio-political cohesion and military strength.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "TABLE 18\nSocio-political Cohesion\n\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Destabilizing political actions in cyberspace, attacks on Internet infrastructure, criminal activities | DDoS and major attacks on critical infrastructure  |\n|  More Powerful | Destabilizing political actions in cyberspace | Criminal activities in cyberspace  |\n\nHave's table can be used to categorize states according to their greatest perceived threats in the cyber domain, which in turn can be leveraged to hold an adversarial state at risk. Subsequently, these perceived threats indicate a state's most valuable Cyberspace Security Objectives (CSOs). Expanding on this concept, this paper assumes that humanity inherently aspires to be safe, free, generally private, and unoppressed by their governments. CSOs that promote these aspirations are inherently positive, whereas those that detract from these aspirations are inherently negative. States that pursue only positive CSOs do not fear internal insurrection and likely have strong socio-political cohesion. States that pursue negative CSOs likely fear internal insurrection, which indicates a lower degree socio-political cohesion. To classify these objectives further (see table 2), this paper draws from statements by Melissa Hathaway, former director for cyberspace at the U.S. National Security Council, that pertain to security-related aims in cyberspace:\n\nTABLE 29\n\n|  Positive CSOs | Negative CSOs  |\n| --- | --- |\n|  1. The promotion of Internet freedom: freedom of speech, content hosting, and browsing | 1. The restriction of Internet freedom: censorship, controlling content, shaping opinions, forbidding opposition ideas  |\n|  2. Promoting the availability of services: preventing denial of service, combating malware, etc. | 2. Controlling popular unrest: restrictions on social media coordination, web-forum gatherings, etc.  |\n|  3. Combating cybercriminals: identity theft, data breach, hacking, Internet predators | 3. Promoting lawlessness in cyberspace: crime facilitation, corruption, lack of accountability for actions in cyberspace  |\n|  4. Combating industrial espionage: copyright adherence, defense of intellectual property | 4. State-sponsored industrial espionage: copyright violations, intellectual property theft  |\n\nBy understanding these CSOs, one can categorize nation-states and enumerate which equities can be held at risk through cyberdeterrence. This categorization is fundamental to a small state's ability to hold a large state at risk: understanding the adversary's critical cyberspace security objectives is the most important aspect of leveraging a viable cyberdeterrence strategy. Consider, for example, the series of cyberattacks in November-December 2014, allegedly\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "conducted by North Korea against the United States' entertainment industry. By conducting devastating attacks against a company's network, invoking memories of 9/11, and indirectly threatening moviegoers, North Korea, which is militarily less powerful than the U.S., directly deterred the U.S. commercial sector's capacity to exercise freedom of speech.[10] The effect of this cyberspace deterrent was the direct denial of positive CSO one: the promotion of Internet freedom. This paper will continue to expand on this core concept as the various aspects of cyberdeterrence are analyzed.\n\n# B. State Categorization\n\nUsing the Buzan/Hare model, nation-states can be categorized in terms of socio-political cohesion and cyber power. This paper proposes four such categories: $^b$\n\n1. States with more socio-political cohesion and more powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n2. States with more socio-political cohesion and less powerful cyberwarfare programs: These states support all positive CSOs, do not support negative CSOs, and can be held at risk if their positive CSOs are threatened.\n3. States with less socio-political cohesion and more powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\n4. States with less socio-political cohesion and less powerful cyberwarfare programs: These states support one or more negative CSOs and can be held at risk if their negative CSOs are threatened.\n\nDrawing on these four categories, table 3 presents a sample of nation-states categorized by cyber power and socio-political cohesion:\n\nTABLE 3\nSocio-political Cohesion\n\n|   | Less Socio-Political Cohesion | More Socio-Political Cohesion  |\n| --- | --- | --- |\n|  Less Powerful | Bahrain, Belarus, Malaysia, Morocco, Venezuela | Belgium, Denmark, Estonia, Japan, New Zealand, Panama  |\n|  More Powerful | China, Egypt, Iran, North Korea, Pakistan, Russia | Australia, Brazil, Germany, India, Israel, U.K., U.S.  |\n\nb A listing of 77 categorized nations can be found in the appendix of this paper.\nc The author defines the term \"socio-political cohesion\" as a function of civil liberties and political rights, as measured by Freedom House's yearly publication, Freedom in the World.\nd Cyber power measured as a function of military power, status of cyber warfare capabilities, and relative strength compared to regional competitors.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "Table 3 provides a tool for determining an effective way to hold a nation's critical CSOs at risk. Estonia and Japan, for example, both support the positive CSOs and are not known to support any negative ones. Both countries are in the less powerful cyber power category, due to having cyberwarfare programs that fall short of those of their primary regional rivals. History demonstrates that Estonia, for example, can be held at risk by an ability to deny positive CSO number two: promoting the availability of services. This disparity was made evident in 2007 when patriotic Russian hackers allegedly conducted distributed denial of service (DDoS) attacks against Estonian websites, causing a major disruption in Estonian governance. Japan is also vulnerable to large and militarily more powerful actors and, as a result, continually experiences cyberattacks from more powerful entities. In 2014, approximately 25 billion cyberattacks were reported to have taken place against the Japanese government, with approximately 40 percent of them traced to regional rivals.11 This is an exponential increase from the 2005 total of 310 million, when the first Japanese national cyberattack survey took place.12\n\nThose nations in the lower left quadrant of table 3, in contrast, are categorized as strong cyber powers due to their heavy investment in military, intelligence, and law enforcement cyber equities. These nations are unlikely to be held at risk in the same manner as Estonia or Japan, due to their robust capabilities. However, to combat internal socio-political shortcomings, these nations subsequently support negative CSOs. For example the Russian Business Network (RBN) actively supports negative CSO three: the promotion of lawlessness in cyberspace. The RBN is a well-known and relatively blatant supporter of cybercrime that is alleged to have ties to Russian politics; its known nefarious activities include the creation of malware, spam centers, illegal pornographic content, botnets, and monopolization of the market for stolen identities.13 Two recent and potentially significant examples of such cybercrimes are the point-of-sale identity theft attacks that have been plaguing the retail sector, which were confirmed to have contained the BlackPOS malware with embedded materials that suggest links to a cybercriminal network.14 These activities and their possible links to politics imply that a deterring entity could hold an aggressor at risk if it could expose the links between criminal and political actors.\n\nOther countries, in contrast, have strict Internet laws and practices designed to control content. For example, according to Section Five of China's Computer Information Network and Internet Security, Protection and Management Regulations, no unit or individual may use the Internet to engage in \"making falsehoods or distorting the truth, spreading rumors, destroying the order of society [or] injuring the reputation of state organs.\"15 This has led to the widespread filtering of web servers or domain name IP addresses, Domain Name Server redirection, and keyword filtering.16 These sorts of measures imply that a government that supports negative CSO number one, the restriction of Internet freedom, could be held at risk if a deterring entity were capable of \"enabling\" unrestricted Internet freedom to the restrictive government's population.\n\n## C. Retaliatory and Autonomous Capabilities\n\nThe capacity to hold an adversary's critical CSOs at risk is paramount to this paper's hypothesis. Once these security objectives are identified, the deterrer must then develop, communicate,\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "and, if necessary, deploy a capability that can fulfill its cyberdeterrence objective. In terms of deterrent actions, a nation-state is generally capable of levying either retaliatory or autonomous capabilities.\n\nA retaliatory deterrence capability is one that falls in line with Martin Libicki’s notion of “the need to develop a capability in cyberspace to do unto others what others may want to do unto us.”¹⁷ Employing this capability insinuates a response-focused cyberdeterrence mechanism that threatens the adversary with use of force if it continues to conduct nefarious actions. Retaliatory responses, in general, are problematic on two fronts. First, they require a certain extent of attribution. Precise attribution is problematic with currently available technology and will likely be so in the immediate future. Second, a retaliatory response may require the threat of use of force, which violates article 2(4) of the UN Charter’s prohibition against the use of force. These problems will be discussed later in this paper, but it should be made clear that levying a retaliatory capability requires the deterrer to address attribution and legal concerns.\n\nA deterrer also can leverage autonomous deterrence capabilities, which are mechanisms that do not require active response or counteroffensive actions to be effective, such as a firewall or a honeynet. At a minimum, a firewall or honeynet will force a nefarious actor to expend valuable time. It is even better if the firewall reports the IP address of those attempting an intrusion, or if the honeynet reveals the attacker’s methodologies and tools. Autonomous capabilities, while potentially less effective than retaliatory capabilities, have a lower threshold in terms of attribution requirements and conform more with international legal norms.\n\nBoth retaliatory and autonomous capabilities must be communicated to an adversary in a way that effectively demonstrates that the deterrer can harm their CSOs. However, the deterrer must not communicate its capability in a way that allows the adversary to render it useless. An adversary who censors the Internet, for example, must be made to believe, via deterrence communication channels, that the deterrer is able to restrict or eliminate the adversary’s capacity to censor the web. Similarly, an adversary state that sponsors industrial espionage must believe that the deterrer has the cyber capability to harm it if it continues to support espionage activities.\n\n# 3. ATTRIBUTION AND CYBERDETERRENCE\n\nOne key challenge in achieving cyberdeterrence is the notion of attribution. The attribution problem has technical and human components, and both can be challenging. Technical attribution includes analyzing malicious code, functions, and packets and then leveraging this analysis to locate the networked node where the nefarious activity originated.¹⁸ Human attribution involves leveraging the results of technical attribution to identify an organization or person responsible for the nefarious activity.¹⁹ In both cases, attribution is not an end in itself but a means for holding the adversary’s critical cyber equities and objectives at risk. Because attribution is a means, not an end, this paper disputes the notion that one must unequivocally identify the adversary’s location and networks to achieve deterrence. To levy a retaliatory capability, one need only conduct attribution back to the IP space of the offending nation-state,\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "which is achievable with currently available technology. If using an autonomous capability, the deterring state need not confirm attribution, since the capability will autonomously levy adverse effects against intruding adversaries.\n\n## A. Retaliatory Capabilities and Attribution\n\nThe nature of state-sponsored cyber activity suggests that attribution can be achieved in tiers. U.S. Senator Sheldon Whitehouse suggests that tiered attribution can be achieved as follows: nation → region → city → group → individual.²⁰ Cybersecurity firm Mandiant’s exposure of Advanced Persistent Threat 1 illustrates this concept. Starting with suspected Chinese state-sponsored industrial espionage activities, Mandiant managed to narrow down the aggressors to → large-scale infrastructure in Shanghai → specific fiber optic infrastructure provided by state-owned enterprise China Telecom → PLA Unit 61398 → specific individuals.²¹ This demonstrates attribution for nefarious activities from the nation-state echelon down to the individual. However, to achieve cyberdeterrence a nation-state need not attribute blame to the individual but to the responsible state, thus it would have been sufficient to attribute the nefarious actions back to the country in which the Internet service provider was hosted.\n\nThe capacity for a small state to achieve attribution against a large state is especially relevant in the discussion of retaliatory capabilities. Far too often, small states see the inability to gain precise attribution as a non-starter for employing retaliatory capabilities, but this simply need not be the case. In the article ‘Beyond Attribution: Seeking National Responsibility for Cyber Attacks,’ Jason Healey notes that “analysts often fall into the trap of ‘attribution fixation,’ the belief that they cannot assess which organization or nation was behind an attack until technical forensics discovers the identity of the attacking machines.”²² Healey adds that “knowing ‘who is to blame?’ can be more important than ‘who did it?’ Moreover, attribution becomes far more tractable when approached as a top-down policy issue with nations held responsible for major attacks originating from their territory or conducted by their citizens.”²³ It logically follows that nation-states are almost always (wittingly or unwittingly) responsible for cyber aggression ranging from the IP space of their geographic borders. Table 4 juxtaposes a spectrum of state responsibility with historical incidents of cyber aggression.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "TABLE 4\n\n|  Spectrum of State Responsibility24 | Historical Example  |\n| --- | --- |\n|  1. State-prohibited: National government will help stop third-party attacks. | In 2002, the U.S. Federal Bureau of Investigation creates a Cyber Division to combat cyber-based terrorism, foreign intelligence operations, and cybercrime.25  |\n|  2. State-prohibited-but-inadequate: National government is cooperative but unable to stop the third-party attacks. | In 2014, a report indicate that the United States, despite having stringent Internet law enforcement measures, is host to approximately 40% of malware serving botnets, more than any other country in the world.26  |\n|  3. State-ignored: National government knows about the third-party attacks but is unwilling to take any official action. | In 2007, “patriotic hackers” conduct DDoS attacks against Estonian state websites.  |\n|  4. State-encouraged: Third parties control and conduct the attack, but the national government encourages them as a matter of policy. | Around 2007, Iran creates the Basij Cyber Council to organize Iranian civilian hackers under the supervision of the Iranian Revolutionary Guard Corps.27  |\n|  5. State-shaped: Third parties control and conduct the attack, but the state provides some support. | The Syrian Electronic Army, a group that supports the Syrian regime and likely receives some state support, hacks into several news producing entity.28  |\n|  6. State-coordinated: National government coordinates third-party attacks, such as by “suggesting” operational details. | In 2008, Russia sponsors website “StopGeorgia.ru,” which encourages the hacker population to engage targets within Georgian web space.29  |\n|  7. State-ordered: National government directs third-party proxies to conduct attacks on its behalf. | In 2005-2007, in an effort to delay the Iranian nuclear program, the United States, under the George W. Bush administration, allegedly initiates an effort code-named Olympic Games,30 and coordinates with third-party Israeli proxies to plant USB devices in key Iranian nuclear facilities.31  |\n|  8. State-rogue-conducted: Out-of-control elements of government cyber forces conduct the attack. | In 1999, after the accidental bombing of the Chinese embassy in Belgrade, rogue hacker elements from Russia, Latvia, Lithuania, and Serbia conduct anti-NATO cyberattacks.32  |\n|  9. State-executed: National government conducts attack using cyber forces under their direct control. | In 2007, Israeli forces infiltrate Syrian air space and destroy the al-Kibar nuclear reactor by triggering a kill-switch installed in Syrian air defense radar systems.33  |\n|  10. State-integrated: National government attacks using integrated third-party proxies and government cyber forces. | For the last decade, several government entities have used third parties to conduct targeted exfiltration attacks against firms and major industries to enhance their economy and defense industry.34  |\n\nThis section demonstrates that the attribution threshold for deploying retaliatory capabilities only requires a nation-state to attribute nefarious actions back to the IP space of the offending state. Even if malicious actors employ proxies in third-party countries to conduct cyberattacks, the third-party nation still has the responsibility to act. Healey once coined the term \"Cyber Somalia,\" which refers to a tendency in the international community to treat cyberattacks \"as if every country were Somalia: helpless to restrain attacks from its territory or mitigate their downstream impacts.\"35 This is simply not the case. States, especially highly capable and technologically developed states, typically have the law enforcement means to assume responsibility for actions within their borders.\n\n# B. Autonomous Capabilities and Attribution\n\nWhereas the physical domain is characterized by variations in the terrain, cyberspace is characterized by environmental variables, including the emplacement of and interaction\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "between routers, switches, servers, firewalls, and transmission mediums. One central difference from the physical domain is that cyberspace is manmade and therefore can be altered, which is the premise on which autonomous capabilities not focused on attribution can be leveraged.\n\nAutonomous capabilities can support a small nation-state's pursuit of cyberdeterrence if the deterrer correctly conducts organizational characterization and predictive cyberthreat analysis. Organizational characterization will help the deterrer understand the equities that a nefarious adversary may threaten; predictive cyberthreat analysis will help the deterrer understand the tactics, methods, and means the adversary will most likely use. Once a deterrer achieves organizational understanding and can reasonably predict the nature of a cyberthreat, attribution is no longer required, as the deterrer will have the knowledge needed to levy an autonomous capability. Table 5 presents examples of autonomous cyberdeterrent capabilities that do not require attribution.\n\nTABLE 5\n\n|  Organization | Cyberthreat | Autonomous Cyberdeterrent Capability  |\n| --- | --- | --- |\n|  Intelligence Agency | Hacktivist conducting website defacement | Firewall with attached intrusion prevention system that conducts reverse IP address look up of nefarious actor; broadcasts location of all proxy IP addresses and actors to law enforcement forces, thereby degrading anonymity.  |\n|  Host-Nation Military | Adversarial military force conducting offensive operations | Intentionally seed deterrer's network with malware so that when data is exfiltrated back through the ISP of the aggressor country, the ISP's ability to censor the Internet or social media is degraded, thereby hampering the strategic objectives of autocratic states.  |\n\n# 4. LEGAL CONSIDERATIONS AND CYBERDETERRENCE\n\n# A. Legal Considerations of Retaliatory Capabilities\n\nThe Tallinn Manual on the International Law Applicable to Cyber Warfare is the most comprehensive work outlining the international laws and norms of cyberspace in accordance with the UN Charter. This section of the paper focuses in particular on Tallinn Manual Rule 10: Prohibition of Threat or Use of Force: \"A cyber operation that constitutes a threat or use of force against the territorial integrity or political independence of any State, or that is in any other manner inconsistent with the purposes of the United Nations, is unlawful.\"36\n\nTaking into account the Tallinn Manual, a deterrer considering using a retaliatory capability will need to comply with two things: the UN Charter's prohibition on the use of force and the non-intervention principle. Compliance is critical, as deterrence actions occur before hostilities begin, and thus, are generally recognized as not covered under the right to self-defense and must not be characterized by the use of force. As for the non-intervention principle, article 2(7) of the UN Charter states that \"the United Nations has no authority to intervene in matters which are within domestic jurisdiction of any State.\"37 The Tallinn Manual states that \"the fact that a cyber operation does not rise to the level of a use of force does not necessarily render it lawful\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "under international law.\"38 A good example of crossing the non-intervention threshold is when the U.S. provided training and weapons to the Contras in Nicaragua. Although the U.S. was not directly involved in kinetic operations, in 1986 the International Court of Justice ruled that U.S. actions constituted a use of force.39\n\nTable 6 gives examples of what the Tallinn Manual would and would not consider state-sponsored use of force.\n\nTABLE 640\n\n|  Use of Force | Below Use-of-Force Threshold  |\n| --- | --- |\n|  Cyber actions that kill people or damage/destroy objects | Conducting psychological operations designed to undermine confidence in government or economy  |\n|  Providing an organized group with malware and the requisite training to conduct a cyberattack | Funding a hacktivist group conducting cyber operations as part of an insurgency  |\n|  Training an organized group to conduct a cyberattack | Granting sanctuary to non-state actors to conduct cyber operations  |\n|  Providing sanctuary in addition to cyber defenses for a non-state group | Failing to police territory and prevent launch of cyber operation by non-state actors  |\n\nIn addressing the four retaliatory capabilities listed above in the \"below use-of-force\" column, a full-fledged cyber power will be unable to levy the \"Cyber Somalia\" excuse within the international community. This means that granting sanctuary or failing to police a state's territory are not viable options. Moreover, funding a \"hacktivist\" organization will require leasing control of national-level CSOs to unpredictable and unquantifiable entities, which would defeat the purpose of conducting proportional, reciprocal, and credible deterrence operations. Therefore, to achieve cyberdeterrence using a retaliatory capability while adhering to the Tallinn Manual's guidance on the use of force, deterrers should levy psychological operations within the cyber domain. Psychological cyber operations should be designed to have a widespread effect on the targeted nation's populace while remaining below the threshold of force.\n\nThe notion of CSOs was referenced above as the key cyber aim point needed to hold an adversary at risk. Therefore, an examination of the suitability of retaliatory capabilities should be premised on how these objectives are held at risk and whether the retaliatory capability in question crosses the use-of-force threshold. Table 7 presents some retaliatory psychological operations capabilities that could be deployed against adversaries with negative CSOs that would not cross the use-of-force threshold.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "TABLE 7\n\n|  Potential Adversary & Activity in Support of a Negative CSO | Retaliatory Deterrence Capability That Is below Use-of-Force Threshold  |\n| --- | --- |\n|  A government entity that monitors online content and communications through a centralized location in the regime's telecommunications monopoly.41 | Enable externally hosted search engines outside of the jurisdiction of a nations ISPs, thereby negating the government's ability to censor web searches.42  |\n|  In response to ongoing protest activity, a government that blocks and degrades content on popular social media websites. | Provide proxy access to unrestricted social media websites, thereby enabling the population's ability to coordinate ideas and protest against the government.  |\n|  Large government entities known for their heavy concentration of corrupt bureaucrats that are responsible for the facilitation of cybercrime syndicates. | Expose intelligence-related information that provides proof of corrupt relations between government officials and cybercriminals.  |\n\nNote that a retaliatory capability that does not violate the UN prohibition on the use of force may not necessarily imply that the capability is in compliance with article 2(4) of the UN Charter. Any action that violates nation-state sovereignty or intervenes in domestic affairs may still be prohibited, even if such actions are akin to the national intelligence collection process levied by nations throughout the world. Therefore, levying a retaliatory cyberdeterrence capability requires decision makers to make a conscious decision on their usage and therefore accept the potential of a negative outcome.\n\n## B. Legal Considerations of Autonomous Capabilities\n\nIf a deterrer is operating at the substate echelon, it is critical that it stays within both international law and the boundaries of domestic law—especially when leveraging autonomous capabilities. There is a strong inclination, particularly in Western law, to outlaw unauthorized access to computer networks, known as hacking. This includes “hack-backs,” private companies that attempt to retaliate against cybercriminals in order to deter crime, steal back information, shut down the assailant’s network, or seek revenge. For example, 18 U.S. Code § 1030 states that “knowingly access[ing] a computer without authorization or exceeding authorized access, and by means of such conduct having obtained information,” is illegal.43 Given this restriction, it is critical that autonomous cyberdeterrent capabilities not be dependent on gaining unauthorized access.\n\nTo abide by domestic law, the deterrer must execute cyberdeterrence functions from within its own network. Thus when the deterrer’s network has been compromised, it should implement internally based cyberthreat countermeasures (IBCC), which are designed to autonomously levy a negative response against an adversary.44 The organization levying an IBCC would be required to act within legal constraints. In the U.S., for example, title 10 (military) and title 50 (intelligence) organizations have the legal authority to employ malware in the execution of their roles.45 Examples of autonomous capabilities that could be used by those with the legal authority to employ malware appear in table 8.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "TABLE 8\n\n|  Deterring Organization | Adversary | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Intelligence Agency | Rival Intelligence Agency | A foreign intelligence agency conducts operations to exfiltrate valuable national security data. | Intentionally host malware within the deterrer's intelligence agency network; when that malware is exfiltrated to the rival intelligence agency's network, the malware opens up a back door, allowing the deterrer's organization to conduct Computer Network Exploitation (CNE).  |\n|  Law Enforcement Agency | Organized Criminals | Groups of organized criminals conduct financial crimes against a deterring nation's citizens and corporations. | Flood the Internet with intentionally hosted proxy networks, applications, and web forums that attract users within the organized crime echelons. An example of such a service is the Silk Road, a Tor hidden service designed to allow users to anonymously conduct illicit trade activities online. When those proxy networks, applications, and web forums have gained sufficient bona fides, push Trojan updates to those hosted entities that compromise the computers of the organized criminals and subsequently reveal their location and activities.  |\n\nOther entities may not have the legal authority to host malware but nonetheless be critical to a nation-state's cyberspace security posture. These include the defense industrial base, information technology, telecommunications, energy sectors, etc. These sectors may be required to levy autonomous deterrents that affect the risk calculus and operational strategy of the adversary, as opposed to infecting the adversary's networks with malware. Examples of such capabilities are presented in table 9.\n\nTABLE 9\n\n|  Deterring Organization | Cyberthreat | Threatening Action through Cyberspace | Autonomous Deterrence Capability  |\n| --- | --- | --- | --- |\n|  Defense Industrial Base (DIB) | Intellectual Property Thief | In order to gain a competitive advantage, a foreign military conducts industrial espionage through cyberspace. | Develop a honeynet that includes intentionally seeded and flawed information designed to sow confusion, misdirection, false intent, and deception. For the DIB, honeynets should contain technology/personnel counter-data that is relevant, yet disadvantageous to an adversary.46  |\n|  The Energy Sector | Terrorists | Terrorists seeking to cause chaos attempt to gain access to the electrical power grid by using a sniffer on a network in order to compromise electrical power company usernames and passwords. | Develop and deploy software that would make it so, that for every legitimate login attempt that took place, the software would simultaneously fabricate additional username and password attempts across the network. The aim would be that the employee endpoint terminal itself would be unable to differentiate between the legitimate login attempt and the fabricated login attempt. Login attempts would be transmitted via encrypted channels to a highly secure central processing location, and fabricated login attempts would be sent to another centralized database. If a criminal/terrorist entity were to use fabricated login data to log in to the close network, it would be flagged and thus cue law enforcement authorities.47  |\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "# 5. CONCLUSION\n\nThis paper has discussed the plausibility of cyberdeterrence and the challenges in achieving it. By breaking down the various challenges, which include the ability to hold the adversary at risk, the notion of attribution, and the need to operate within legal norms, the paper gives credence to its hypothesis that cyberdeterrence can be achieved, and that even small nation-states can achieve it using retaliatory and autonomous capabilities. Small states can levy retaliatory capabilities to achieve deterrence so long as they can attribute nefarious actions to the IP space of the adversarial state and the retaliatory capability does not violate the UN prohibition on the use of force. Alternatively, small nation-states can achieve cyberdeterrence using autonomous capabilities, which do not require attribution and can be leveraged in conformity with article 2(4) of the UN Charter as long as they violate neither the UN prohibition on the use of force nor domestic law forbidding unauthorized network access.\n\nCyberdeterrence, like conventional deterrence, centers on understanding the adversary's center of gravity, having a threatening capability, and communicating to the adversary the willingness to unleash the capability if a red line is crossed. To position the cyberspace environment to their advantage, cybersecurity practitioners at both the interstate and substate echelons should integrate cyberdeterrence into their defensive plans.\n\n# 6. APPENDIX\n\n|  Nation-State^{e} | Military Power Index^{f 48} | Presence of Government Sponsored Cyberwarfare Programs^{49} | Political Rights^{50} | Civil Liberties^{51}  |\n| --- | --- | --- | --- | --- |\n|  Argentina* | 2 |  | High | High  |\n|  Australia+* | 4 | Yes | High | High  |\n|  Austria* | 3 |  | High | High  |\n|  Azerbaijan | 2 |  | Low | Low  |\n|  Bahrain | 1 |  | Low | Low  |\n|  Bangladesh | 2 |  | Medium | Medium  |\n|  Belarus | 2 |  | Low | Low  |\n|  Belgium* | 3 |  | High | High  |\n|  Bolivia | 1 |  | Medium | Medium  |\n|  Brazil+* | 4 | Yes | High | High  |\n|  Bulgaria* | 1 |  | High | High  |\n|  Canada+* | 4 | Yes | High | High  |\n|  Chile* | 2 |  | High | High  |\n|  China+ | 5 | Yes | Low | Low  |\n|  Colombia | 2 |  | Medium | Medium  |\n|  Croatia* | 2 |  | High | High  |\n\ne The + symbol = strong cyber power relative to adversaries; the * symbol = relatively strong socio-political cohesion.\nf 5 = most powerful; 4 = highly powerful; 3 = powerful; 2 = less powerful; 1 = minimally powerful\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "|  Czech Republic* | 3 | Yes | High | High  |\n| --- | --- | --- | --- | --- |\n|  Denmark* | 3 |  | High | High  |\n|  Ecuador | 1 |  | Medium | Medium  |\n|  Egypt | 4 |  | Low | Medium  |\n|  Estonia* | 1 | Yes | High | High  |\n|  Finland* | 2 |  | High | High  |\n|  France+* | 5 | Yes | High | High  |\n|  Georgia | 2 |  | Medium | Medium  |\n|  Germany+* | 5 | Yes | High | High  |\n|  Greece* | 2 |  | High | High  |\n|  Hungary* | 2 |  | High | High  |\n|  India+* | 5 | Yes | High | Medium  |\n|  Indonesia* | 4 |  | High | Medium  |\n|  Iran+ | 4 | Yes | Low | Low  |\n|  Israel+* | 4 | Yes | High | High  |\n|  Italy+* | 4 | Yes | High | High  |\n|  Japan* | 4 | Yes | High | High  |\n|  Jordan | 2 |  | Low | Medium  |\n|  Kazakhstan | 1 |  | Low | Medium  |\n|  Kenya | 2 | Yes | Medium | Medium  |\n|  Kuwait | 1 |  | Medium | Medium  |\n|  Lebanon | 1 |  | Low | Low  |\n|  Lithuania* | 1 |  | High | High  |\n|  Malaysia | 3 |  | Medium | Medium  |\n|  Mexico | 3 |  | Medium | Medium  |\n|  Morocco | 2 |  | Medium | Medium  |\n|  Netherlands* | 3 | Yes | High | High  |\n|  New Zealand* | 1 | Yes | High | High  |\n|  Nigeria+ | 3 | Yes | Medium | Medium  |\n|  Norway* | 3 |  | High | High  |\n|  Oman | 1 |  | Low | Medium  |\n|  Pakistan | 4 | Yes | Medium | Medium  |\n|  Panama* | 1 |  | High | High  |\n|  Peru* | 2 |  | High | Medium  |\n|  Philippines | 3 |  | Medium | Medium  |\n|  Poland* | 4 | Yes | High | High  |\n|  Portugal* | 2 |  | High | High  |\n|  Qatar | 1 |  | High | High  |\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "|  Romania* | 2 |  | High | High  |\n| --- | --- | --- | --- | --- |\n|  Russia+ | 5 | Yes | Low | Medium  |\n|  Saudi Arabia+ | 3 | Yes | Low | Low  |\n|  Serbia* | 2 |  | High | High  |\n|  Singapore | 3 | Yes | Medium | Medium  |\n|  Slovenia* | 1 |  | High | High  |\n|  South Africa+* | 3 | Yes | High | High  |\n|  South Korea* | 4 | Yes | High | High  |\n|  Spain* | 3 |  | High | High  |\n|  Sweden* | 3 | Yes | High | High  |\n|  Switzerland* | 3 |  | High | High  |\n|  Syria+ | 3 | Yes | Low | Low  |\n|  Thailand | 3 |  | Medium | Medium  |\n|  Tunisia | 2 |  | Medium | Medium  |\n|  Turkey+ | 4 | Yes | Medium | Medium  |\n|  Ukraine | 3 |  | Medium | Medium  |\n|  United Arab Emirates | 3 |  | Low | Low  |\n|  United Kingdom+* | 5 | Yes | High | High  |\n|  United States+* | 5 | Yes | High | High  |\n|  Uruguay* | 3 |  | High | High  |\n|  Uzbekistan | 2 |  | Low | Low  |\n|  Venezuela | 2 |  | Medium | Medium  |\n|  Vietnam | 3 |  | Low | Medium  |\n\n# REFERENCES\n\n[1] Forrest Hare, 'The Significance of Attribution to Cyberspace Coercion: A Political Perspective' 4th International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications, 2012), 131.\n[2] Dmitri Alperovitch, 'Towards Establishment of Cyberspace Deterrence Strategy' 3rd International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications, 2011), 91.\n[3] Michael Schmitt, Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework (Colorado Springs, CO: U.S. Air Force Academy, 1999), 17.\n[4] Gregory Rattray and Jason Healey, 'Categorizing and Understanding Offensive Cyber Capabilities and Their Use' Proceedings of a Workshop on Deterring Cyberattacks (Washington, DC: National Academies Press, 2010), 88.\n[5] John J. Mearsheimer, The Tragedy of Great Power Politics (New York: Norton &amp; Company, 2011), 50.\n[6] Barry Buzan, People, States, &amp; Fear: An Agenda for International Security Studies in the Post-Cold War Era (London, UK: ECPR Press, 1991), 134.\n[7] Forrest Hare, 'The Cyber Threat to National Security: Why Can't We Agree?' 2nd International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications, 2010), 218.\n[8] Ibid.\n[9] Melissa Hathaway, 'Developing International Norms for a Safe, Stable, and Predictable Cyber Environment' Georgetown University Conference on International Engagement on Cyber, March 4, 2014.\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "[10] Jason Rivera, 'North Korea Has Crossed the Cyber Red Line by Combining Cyberattacks with the Threat of Terrorism—and the United States Must Respond' (2014) Georgetown Security Studies Review http://georgetownsecuritystudiesreview.org/2014/12/18/north-korea-has-crossed-the-cyber-red-line-by-combining-cyberattacks-with-the-threat-of-terrorism-and-the-united-states-must-respond/ (accessed 19 Dec. 2014).\n\n[11] British Columbia, 'Security News Digest' http://www.cio.gov.bc.ca/local/cio/informationsecurity/pdf_securitynewsdigest/02_24_2015.pdf (accessed 16 Mar. 2015).\n\n[12] Ibid.\n\n[13] RBN Exploit 'Russian Business Network (RBN)' HostExploit, 2014. http://rbnexploit.blogspot.com/ (accessed 4 Nov. 2014).\n\n[14] Brian Krebs, 'Home Depot Hit by Same Malware as Target' krebsonsecurity.com, 2014. http://krebsonsecurity.com/2014/09/home-depot-hit-by-same-malware-as-target/ (accessed 4 Nov. 2014).\n\n[15] U.S. Embassy Beijing, 'New PRC Internet Regulations' Federation of American Scientists, 1998. https://www.fas.org/irp/world/china/netreg.htm (accessed 6 Apr. 2014).\n\n[16] Jonathan Zittrain and Benjamin Edelman, 'Empirical Analysis of Internet Filtering in China' Harvard Law School, Berkman Center for Internet and Society, 2003. http://cyber.law.harvard.edu/filtering/china/ (accessed 6 Apr. 2014).\n\n[17] Martin Libicki, Cyberdeterrence and Cyberwar (Santa Monica, CA: RAND Corporation, 2009), 27.\n\n[18] W. Earl Boebert, A Survey of Challenges in Attribution (National Academies Press Online 2010), 44.\n\n[19] Ibid.\n\n[20] U.S. Senator Sheldon Whitehouse (Rhode Island), Comments made at Georgetown University Conference—International Engagement on Cyber: Developing International Norms for a Safe, Stable, and Predictable Cyber Environment, March 4, 2014.\n\n[21] Mandiant, APTI: Exposing One of China's Cyber Espionage Units (Mandiant 2013), 19.\n\n[22] Jason Healey, 'Beyond Attribution: Seeking National Responsibility for Cyber Attacks' Atlantic Council, Cyber Statecraft Initiative (Washington, DC: Atlantic Council, 2012), 1.\n\n[23] Ibid.\n\n[24] Ibid., 2.\n\n[25] 'Ten Years After: The FBI Since 9/11,' FBI website, 2014. http://www.fbi.gov/about-us/ten-years-after-the-fbi-since-9-11/just-the-facts-1/cyber (accessed 19 Apr. 2014).\n\n[26] Jaikumar Vijayan, 'US Tops List of Countries Hosting Malware and Botnets' securityintelligence.com, 2014. http://securityintelligence.com/news/us-tops-list-of-countries-hosting-malware-and-botnets/#. VQa82PnF-So (accessed 16 Mar. 2015).\n\n[27] U.S. House Subcommittee on Counterterrorism and Intelligence and the Subcommittee on Cybersecurity, Infrastructure Protection, and Security Technologies, 'Iranian Cyber Threat to the U.S. Homeland' April 26, 2012. http://www.gpo.gov/fdsys/pkg/CHRG-112hhrg77381/html/CHRG-112hhrg77381.htm (accessed 19 Apr. 2014).\n\n[28] DHS Office of Cybersecurity &amp; Communications, 'Cyber News Spotlight: Insight on Cybersecurity News &amp; Trends for Critical Infrastructure' http://www.htcia.org/wp-content/uploads/Cyber-News-Spotlight-February-2014.pdf (accessed 16 Mar. 2015).\n\n[29] Andreas Hagen, 'The Russo-Georgian War 2008' in A Fierce Domain: Conflict in Cyberspace, 1986 to 2012 (Vienna, VA: Cyber Conflict Studies Association, 2013), 197.\n\n[30] Dorothy Denning, 'Stuxnet: What Has Changed?' (2012) 4 Future Internet, 673.\n\n[31] Joshua Kopstein, 'Stuxnet Virus Was Planted by Israeli Agents Using USB Sticks, According to New Report' The Verge, 2012. http://www.theverge.com/2012/4/12/2944329/stuxnet-computer-virus-planted-israeli-agent-iran (accessed 19 Apr. 2014).\n\n[32] Jonathan Diamond, 'Early Patriotic Hacking,' in Jason Healey (ed.) A Fierce Domain: Conflict in Cyberspace, 1986 to 2012 (Vienna, VA: Cyber Conflict Studies Association, 2013), 138-139.\n\n[33] 'Significant Cyberattack Incidents: Operation Orchard, 2007' Real Clear Politics, 2013. http://www.realclearpolitics.com/lists/cyber_attacks/op_orchard.html (accessed 16 Apr. 2014).\n\n[34] Ibid., 21.\n\n[35] Healey, 'Beyond Attribution: Seeking National Responsibility for Cyber Attacks', 4.\n\n[36] Michael Schmitt et al., Tallinn Manual on the International Law Applicable to Cyber Warfare (Cambridge, UK: Cambridge University Press 2013), 45.\n\n[37] UN Charter, art. 2, para. 7.\n\n[38] Ibid., 46.\n\n[39] International Court of Justice, 'Military and Paramilitary Activities in and against Nicaragua (Nicaragua v. United States of America, 1986)' www.icj-cij.org. http://www.icj-cij.org/docket/index.php?sum=367&amp;p1=3&amp;p2=3&amp;case=70&amp;p3=5 (accessed 22 Apr. 2014).\n\nAuthorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply.",
    "[40] Schmitt, Tallinn Manual on the International Law Applicable to Cyber Warfare, 48-49.\n[41] Patricia Figliola et al., ‘U.S. Initiatives to Promote Global Internet Freedom: Issues, Policy, and Technology’ Congressional Research Service (Washington, DC: GPO 2011), 10.\n[42] Jason Rivera, ‘Understanding and Countering Nation-State Use of Protracted Unconventional Warfare’ (2014) Small Wars Journal http://smallwarsjournal.com/jrnl/art/understanding-and-countering-nation-state-use-of-protracted-unconventional-warfare (accessed 24 Dec. 2014).\n[43] 18 U.S.C. § 1030: US Code—Section 1030: Fraud and related activity in connection with computers.\n[44] Jason Rivera and Forrest Hare ‘The Deployment of Attribution Agnostic Cyberdefense Constructs and Internally Based Cyberthreat Countermeasures’ 6th International Conference on Cyber Conflict (Tallinn, Estonia: NATO CCD COE Publications 2014), 109-110.\n[45] Andru Wall, ‘Demystifying the Title 10-Title 50 Debate: Distinguishing Military Operations, Intelligence Activities &amp; Covert Action’ Harvard National Security Journal 3 (2012), 118.\n[46] Rivera &amp; Hare, ‘The Deployment of Attribution Agnostic Cyberdefense Constructs and Internally Based Cyberthreat Countermeasures’, 112.\n[47] Ibid., 113.\n[48] Global Fire Power, ‘Countries Ranked by Military Strength,’ www.globalfirepower.com, 2014. http://www.globalfirepower.com/countries-listing.asp (accessed 9 May 2014).\n[49] Jeffrey Carr, Inside Cyber Warfare: Mapping the Cyber Underworld (Sebastopol, CA: O’Reilly Media, Inc., 2011), 243-261.\n[50] Arch Puddington, Freedom in the World 2014 (Washington, DC: Freedom House 2014), 18-22.\n[51] Ibid.\n\n24 Authorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply."
  ],
  "metadata": {
    "title": "Achieving Cyberdeterrence and the Ability of Small States to Hold Large States at Risk",
    "subtitle": "Captain, United States Army National Guard",
    "document_type": "conference_paper",
    "venue": "2015 7th International Conference on Cyber Conflict:",
    "publication_year": 2015,
    "authors": [
      "Architectures in Cyberspace",
      "Jason Rivera",
      "Touche LLP",
      "Threat Intelligence",
      "United States"
    ],
    "affiliations": [
      "Georgetown School of Foreign Service",
      "All views and concepts expressed in this paper originate solely with the author and do not represent the official positions or opinions of the U.S. Army National Guard, the U.S. Department of Defense, or Deloitte & Touche LLP.",
      "Authorized licensed use limited to: University College London. Downloaded on April 11,2025 at 19:51:21 UTC from IEEE Xplore. Restrictions apply."
    ],
    "emails": [
      "jhr47@georgetown.edu"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "Achieving cyberdeterrence is a seemingly elusive goal in the international cyberdefense community. The consensus among experts is that cyberdeterrence is difficult at best and perhaps impossible, due to difficulties in holding aggressors at risk, the technical challenges of attribution, and legal restrictions such as the UN Charter's prohibition against the use of force. Consequently, cyberspace defenders have prioritized increasing the size and strength of the metaphorical \"walls\" in cyberspace over facilitating deterrent measures.",
    "keywords": [
      "attribution",
      "cyberdeterrence",
      "deterrence",
      "use of force"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": []
    },
    "references_block_count": 1,
    "references_entries_estimated": 52,
    "heading_count": 15,
    "max_heading_level": 3,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "title_looks_like_mid_paragraph_sentence",
        "no_identifier"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 1,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 1.0,
      "unique_index_count": 1
    },
    "footnotes_quality": {
      "intext_total": 3,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 3,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "numeric",
      "recommended_style": "unknown",
      "aligned": true,
      "signals": {
        "superscript_hits": 14,
        "superscript_definition_lines": 1,
        "numeric_bracket_hits": 1,
        "numeric_endnote_lines": 14,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 51.0,
      "dominant_bib_coverage_rate": 0.0196078431372549,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 15,
      "max_heading_level": 3,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": true,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": true,
        "persistent_identifier": false,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 5,
        "affiliations": 3,
        "emails": 1,
        "orcids": 0,
        "keywords": 4,
        "doi": 0,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 0
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "title_looks_like_mid_paragraph_sentence",
          "no_identifier"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_persistent_identifier",
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "low_bib_coverage",
      "footnotes_bucket_unresolved",
      "meta_missing_persistent_identifier",
      "meta_low_email_author_link_rate"
    ]
  },
  "citation_summary": {
    "style": "numeric",
    "dominant_bucket": "numeric",
    "dominant": {
      "intext_total": 1.0,
      "success_occurrences": 1.0,
      "success_unique": 1.0,
      "bib_unique_total": 51.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.0196078431372549,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "numeric"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 3.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 48.0,
        "highest_intext_index": 51.0,
        "missing_footnotes_for_seen_total": 3.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 1.0,
        "success_occurrences": 1.0,
        "success_unique": 1.0,
        "bib_unique_total": 51.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.0196078431372549,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "numeric": {
        "intext_total": 1.0,
        "success_occurrences": 1.0,
        "success_unique": 1.0,
        "bib_unique_total": 51.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.0196078431372549,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 119.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:16:43.329097+00:00"
}