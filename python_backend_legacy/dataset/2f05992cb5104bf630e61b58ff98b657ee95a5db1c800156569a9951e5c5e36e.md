{
  "full_text": "European Journal of Operational Research 306 (2023) 1399-1416\nELSEVIER\nContents lists available at ScienceDirect\nEuropean Journal of Operational Research\njournal homepage: www.elsevier.com/locate/ejor\nEJSEVIER\nInnovative Applications of O.R.\n# Cyber deterrence with imperfect attribution and unverifiable signaling\nJonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$\n$^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA\n$^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA\n# ARTICLE INFO\nArticle history:\nReceived 17 August 2021\nAccepted 12 July 2022\nAvailable online 18 July 2022\nKeywords:\nGame theory\nDecision analysis\nSecurity\n# ABSTRACT\nMotivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n© 2022 Elsevier B.V. All rights reserved.\n# 1. Introduction\nDefensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\n\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\nHowever, traditional deterrence (Powell, 1990; Schelling, 1980) relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory:\n- \"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\" or in other words deterrence requires \"the possibility of a clear demonstration of the defender's capabilities (Morgan, 2003).\"\n- \"The deterring state must first know who to counterattack (Goodman, 2010).\"\nWhen considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that \"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\" and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect \"demonstrations\" such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations (Lynch, 2002; Riedel, 2007; Saran, 2016) as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to \"respond when necessary\" major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states \"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means (Parly, 2019).\" Chinese mili\nhttps://doi.org/10.1016/j.ejor.2022.07.021\n0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntary strategy documents have made similar threats: \"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks (Harris, 2017).\" All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space (Iasiello, 2014; Jensen, 2012; Libicki, 2009) and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\n1. The defender can only imperfectly attribute attacks.\n2. The attacker has uncertainty over the defender's retaliatory and defensive capability.\n3. The defender can signal its capability not by revealing its true capability but through costless and unverifiable cheap talk.\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas (Baliga et al., 2020) focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and (Baliga et al., 2020).\nAlthough (Baliga et al., 2020) is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy (Konrad, 2020), optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n# 2. Model outline\nWe consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.\nThat is, regardless of what the defender's true capability is, she can costlessly signal any capability.\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n## Model specification\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→[0, 1]. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→[0, 1]. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→[0, 1]. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.\n# 4. Results and analysis\nTo more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.\n# 4.1. The attribution game\nSince in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\n1. If  $1 - \\pi_1c + \\pi_2\\nu &lt; 0$ , there exists an equilibrium of the attribution game where the attacker randomizes with probability\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and the defender never retaliates after observing  $o_2$  and randomizes between retaliating and not retaliating after  $o_1$  with probability  $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$ .\n2. If  $1 - \\pi_1c + \\pi_2v &gt; 0$ , there exists an equilibrium of the attribution game where the attacker randomizes with probability  $\\beta = \\beta_2^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  and the defender always retaliates after observing  $o_1$  and randomizes between retaliating and not retaliating after  $o_2$  with probability  $\\rho_2^* = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v}$ .\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique\nProposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\n1. Always retaliate\n2. Never retaliate\n3. Retaliate after  $o_1$  and do not retaliate after  $o_2$ .\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\nFig. 2. Defender's expected utility for each of her FL strategies.\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n(b)  $r + w &lt; 1$\nTable 2 Equilibrium expected utilities in the attribution game.\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"\n# 4.2. The signaling game\nWe now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.\n# 4.2.1. Separating equilibria\nFirst we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.\n# 4.2.2. Pooling equilibria\nBefore analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.\n# 4.2.3. Semi-separating equilibria\nThus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\n1. There is no equilibrium where the defender of type  $L$  always signals  $s_L$  and a defender of type  $H$  randomizes between signaling  $s_L$  and  $s_H$  and the attacker randomizes with probability  $\\beta_L$  after receiving  $s_L$  and  $\\beta_H$  after receiving  $s_H$  and  $\\beta_L \\neq \\beta_H$ .\n2. There is no equilibrium where the defender of type  $H$  always signals  $s_H$  and a defender of type  $L$  randomizes between signaling  $s_L$  and  $s_H$  and the attacker randomized with probability  $\\beta_L$  after receiving  $s_L$  and  $\\beta_H$  after receiving  $s_H$  and  $\\beta_L \\neq \\beta_H$ .\nProposition 4 says that if an defender of type  $L$  has relatively high ability to punish (relatively high value of  $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a \"negative result,\" it is useful as context for the following result, established in proposition 5.\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where:\n- A defender of type  $H$  always signals  $s_H$  and always retaliates.\n- A defender of type  $L$  signals  $s_H$  with probability  $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$ . After signaling  $s_H$ , the defender always retaliates. After signaling  $s_L$ , the defender retaliates with probability  $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$  after observing  $o_1$  and never retaliates after observing  $o_2$ .\n- An attacker that receives signal  $s_H$  attacks with probability  $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$ .\n- An attacker that receives signal  $s_L$  attacks with probability  $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ .\nif and only if\n1.  $1 - c_{L} &gt; -v$\n2.  $\\pi_1c_L - \\pi_2v &gt; 1$\n3.  $\\pi_2 &lt;   \\pi_1r_L + \\pi_2w &lt;   1$\n4.  $r_{L} + w &gt; 1$\n5.  $\\frac{\\gamma}{1 - \\gamma} &lt; \\frac{r_L - v - 1}{1 - c_H + v}$\n6.  $w(\\pi_1r_L + \\pi_2w - \\pi_2) &lt; (r_L + w - 1)(\\pi_1r_L + \\pi_2w)$\nFurthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type  $H$  defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type  $L$  will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type  $H$ , the defender might be bluffing. Upon receiving a signal that the defender is type  $H$  the attacker is willing to attack more often than if he knew the defender was type  $H$  with certainty. The increase in attack probability allows the defender of type  $H$  (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type  $L$  can credibly randomize because by signaling she is type  $L$ , she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type  $L$  is because a type  $L$  defender does not always retaliate (as she does when she is type  $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type  $L$  is indifferent between revealing she is type  $L$  and incurring a low attack probability with few correct retaliations and signaling she is type  $H$ , inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type  $H$  he is willing to randomize between (1) attacking in the hopes that the defender is actually type  $L$  and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type  $H$  defender. Although for simplicity we only have one cost for an incorrect retaliation.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\niation  $(v)$ , we could in principal have two costs,  $v_{H}$  and  $v_{L}$ . Condition 5 says that the semi-separating equilibrium cannot exist if  $v_{H} = c_{H}$  and  $v_{L} = c_{L}$ . In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by  $\\pi_1$  and  $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type  $L$  defender would not be willing to randomize and would instead always signal she was type  $L$  and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type  $H$  too often, as given in condition 5. This is because if the defender signals she is type  $H$  the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type  $L$ ; the prior probability that the defender is type  $H$  is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type  $L$ .\nTo see how such an equilibrium exists, consider Fig. 7. The two values,  $\\beta_{H}$  and  $\\beta_{L}$  are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability  $\\beta_{L}$ , the defender of type  $L$  is indifferent between never retaliating and retaliating after  $a_{1}$ . This is where the purple line intersects the dotted blue line. When the attacker attacks with probability  $\\beta_{H}$ , the type  $L$  defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type  $L$  is indifferent between these two outcomes and thus is willing to randomize her signal when she is type  $L$ . A defender of type  $H$  receives a higher utility when the attacker attacks with probability  $\\beta_{H}$  and always retaliates (solid red line) than when the attacker attacks with probability  $\\beta_{L}$  and the attacker retaliates after  $a_{1}$  only\n(dotted blue line). Therefore, the defender of type  $H$  would always signal  $s_H$ , as indicated in the semi-separating equilibrium.\n# 4.2.4. Gains from signaling\nFinally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\nProposition 6 (Deterrence Equilibrium). Define:\n$P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$\n$\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$\n-  $\\beta_{H}, \\beta_{L}$  and  $\\alpha_{L}$  as in proposition 5\nThere exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that\n1.  $0 &lt; P_{2} &lt; 1$\n2.  $\\gamma \\beta_{H} + (1 - \\gamma)\\alpha_{L}\\beta_{H} + (1 - \\gamma)(1 - \\alpha_{L})\\beta_{L} &lt;   \\beta_{p}$\n3.  $(1 - \\gamma)\\beta_{p}(r_{L} + w - 1) + \\gamma \\beta_{p}(r_{H} + w - 1) - w &lt;   (1-$ $\\gamma)\\beta_{H}(r_{L} + w - 1) + \\gamma \\beta_{H}(r_{H} + w - 1) - w$\nCondition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability  $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ . In the semi-separating equilibrium, the attacker will randomize either at probability  $\\beta_{H}$  or  $\\beta_{L}$ . While  $\\beta_{H}$  is slightly higher than  $\\beta_{p}$ ,  $\\beta_{L}$  is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type  $L$  has a higher expected utility at  $\\beta_{H}$  and  $\\beta_{L}$  then at  $\\beta_{p}$ , the defender gains with signaling through a deterrence effect.\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\nProposition 7 (Anti-deterrence Equilibrium). Define:\n$P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$\n$\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$\n-  $\\beta_{H}, \\beta_{L}$  and  $\\alpha_{L}$  as in proposition 5\nThere exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that\n1.  $0 &lt; P_{1} &lt; 1$\n2.  $\\gamma \\beta_{H} + (1 - \\gamma)\\alpha_{L}\\beta_{H} + (1 - \\gamma)(1 - \\alpha_{L})\\beta_{L} &gt; \\beta_{p}$\n3.  $-\\beta_{p} &lt;   (1 - \\gamma)\\beta_{H}(r_{L} + w - 1) + \\gamma \\beta_{H}(r_{H} + w - 1) - w$\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n(a) $w = .6$\n(b) $w = 1$\n(c) $w = 1.5$\n(d) $w = 2$\n(e) $w = 2.5$\n(f) $w = 3$\nFig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\n1408\nThis is especially true if there exists a pooling equilibrium that yields a higher payoff for the defender even when the anti-deterrence equilibrium exists. In other words, it would not be reasonable to expect the defender to strategically signal if she could do better by not signaling and earning the expected payoff at the pooling equilibrium. One way to increase the relevance of the anti-deterrence equilibrium is if it was also the sender-preferred equilibrium (Kamenica & Gentzkow, 2011) so that the defender was better off at that equilibrium than any of the pooling equilibria.\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.\n## Conclusion--towards a cyber deterrence policy\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.\n## Appendix A\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\nFor this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\nnot gain anything from such a deviation it must be:\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\nEqs. (A.17) and (A.19) together imply that\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n# Proof of Proposition 6. Define the parameters as follows.\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\nTable A4 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n# Proof of Proposition 7. Define the parameters as follows.\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\nTable A5 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$",
  "flat_text": "European Journal of Operational Research 306 (2023) 1399-1416 ELSEVIER Contents lists available at ScienceDirect European Journal of Operational Research journal homepage: www.elsevier.com/locate/ejor EJSEVIER Innovative Applications of O.R.\n# Cyber deterrence with imperfect attribution and unverifiable signaling Jonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$ $^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA $^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA # ARTICLE INFO Article history: Received 17 August 2021 Accepted 12 July 2022 Available online 18 July 2022 Keywords: Game theory Decision analysis Security # ABSTRACT Motivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n© 2022 Elsevier B.V. All rights reserved.\n# 1. Introduction Defensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\nHowever, traditional deterrence relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory: -\"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\"or in other words deterrence requires\"the possibility of a clear demonstration of the defender's capabilities.\"-\"The deterring state must first know who to counterattack.\"When considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that\"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\"and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect\"demonstrations\"such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to\"respond when necessary\"major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states\"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means.\"Chinese mili https://doi.org/10.1016/j.ejor.2022.07.021 0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 tary strategy documents have made similar threats:\"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks.\"All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\n\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas  focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and .\nAlthough  is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy , optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n# 2. Model outline\nWe consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.\nThat is, regardless of what the defender's true capability is, she can costlessly signal any capability.\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n## Model specification\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→[0, 1]. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→[0, 1]. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→[0, 1]. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.\n# 4. Results and analysis\nTo more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.\n# 4.1. The attribution game\nSince in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\n\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 $\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$ and the defender never retaliates after observing $o_2$ and randomizes between retaliating and not retaliating after $o_1$ with probability $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$.\n\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique Proposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\n\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\nFig. 2. Defender's expected utility for each of her FL strategies.\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n(b)  $r + w &lt; 1$\nTable 2 Equilibrium expected utilities in the attribution game.\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"\n# 4.2. The signaling game\nWe now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.\n# 4.2.1. Separating equilibria\nFirst we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.\n# 4.2.2. Pooling equilibria\nBefore analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.\n# 4.2.3. Semi-separating equilibria\nThus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\n\nProposition 4 says that if an defender of type $L$ has relatively high ability to punish (relatively high value of $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a\"negative result,\"it is useful as context for the following result, established in proposition 5.\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where: - A defender of type $H$ always signals $s_H$ and always retaliates.\n- A defender of type $L$ signals $s_H$ with probability $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$. After signaling $s_H$, the defender always retaliates. After signaling $s_L$, the defender retaliates with probability $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$ after observing $o_1$ and never retaliates after observing $o_2$.\n- An attacker that receives signal $s_H$ attacks with probability $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$.\n- An attacker that receives signal $s_L$ attacks with probability $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$.\nif and only if Furthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type $H$ defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type $L$ will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type $H$, the defender might be bluffing. Upon receiving a signal that the defender is type $H$ the attacker is willing to attack more often than if he knew the defender was type $H$ with certainty. The increase in attack probability allows the defender of type $H$ (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type $L$ can credibly randomize because by signaling she is type $L$, she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type $L$ is because a type $L$ defender does not always retaliate (as she does when she is type $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type $L$ is indifferent between revealing she is type $L$ and incurring a low attack probability with few correct retaliations and signaling she is type $H$, inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type $H$ he is willing to randomize between (1) attacking in the hopes that the defender is actually type $L$ and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type $H$ defender. Although for simplicity we only have one cost for an incorrect retaliation.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\niation $(v)$, we could in principal have two costs, $v_{H}$ and $v_{L}$. Condition 5 says that the semi-separating equilibrium cannot exist if $v_{H} = c_{H}$ and $v_{L} = c_{L}$. In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by $\\pi_1$ and $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type $L$ defender would not be willing to randomize and would instead always signal she was type $L$ and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type $H$ too often, as given in condition 5. This is because if the defender signals she is type $H$ the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type $L$; the prior probability that the defender is type $H$ is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type $L$.\nTo see how such an equilibrium exists, consider Fig. 7. The two values, $\\beta_{H}$ and $\\beta_{L}$ are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability $\\beta_{L}$, the defender of type $L$ is indifferent between never retaliating and retaliating after $a_{1}$. This is where the purple line intersects the dotted blue line. When the attacker attacks with probability $\\beta_{H}$, the type $L$ defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type $L$ is indifferent between these two outcomes and thus is willing to randomize her signal when she is type $L$. A defender of type $H$ receives a higher utility when the attacker attacks with probability $\\beta_{H}$ and always retaliates (solid red line) than when the attacker attacks with probability $\\beta_{L}$ and the attacker retaliates after $a_{1}$ only (dotted blue line). Therefore, the defender of type $H$ would always signal $s_H$, as indicated in the semi-separating equilibrium.\n# 4.2.4. Gains from signaling Finally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\nProposition 6 (Deterrence Equilibrium). Define: $P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$ $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that Condition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$. In the semi-separating equilibrium, the attacker will randomize either at probability $\\beta_{H}$ or $\\beta_{L}$. While $\\beta_{H}$ is slightly higher than $\\beta_{p}$, $\\beta_{L}$ is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type $L$ has a higher expected utility at $\\beta_{H}$ and $\\beta_{L}$ then at $\\beta_{p}$, the defender gains with signaling through a deterrence effect.\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\nProposition 7 (Anti-deterrence Equilibrium). Define: $P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$ $\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that J. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n(a) $w =.6$ (b) $w = 1$ (c) $w = 1.5$ (d) $w = 2$ (e) $w = 2.5$ (f) $w = 3$ Fig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\n\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.\n## Conclusion--towards a cyber deterrence policy\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.\n## Appendix A\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\nFor this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\nnot gain anything from such a deviation it must be:\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\nEqs. (A.17) and (A.19) together imply that\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n# Proof of Proposition 6. Define the parameters as follows.\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\nTable A4 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n# Proof of Proposition 7. Define the parameters as follows.\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\nTable A5 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$",
  "toc": [
    [
      1,
      "__preamble__"
    ],
    [
      1,
      "# 1. Introduction Defensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018)."
    ],
    [
      1,
      "# 2. Model outline"
    ],
    [
      1,
      "# 4. Results and analysis"
    ],
    [
      1,
      "# 4.1. The attribution game"
    ],
    [
      1,
      "# 4.2. The signaling game"
    ],
    [
      1,
      "# 4.2.1. Separating equilibria"
    ],
    [
      1,
      "# 4.2.2. Pooling equilibria"
    ],
    [
      1,
      "# 4.2.3. Semi-separating equilibria"
    ],
    [
      1,
      "# 4.2.4. Gains from signaling Finally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect."
    ],
    [
      1,
      "## Conclusion--towards a cyber deterrence policy"
    ],
    [
      1,
      "__postscript__"
    ]
  ],
  "sections": {
    "__preamble__": "European Journal of Operational Research 306 (2023) 1399-1416 ELSEVIER Contents lists available at ScienceDirect European Journal of Operational Research journal homepage: www.elsevier.com/locate/ejor EJSEVIER Innovative Applications of O.R.\n# Cyber deterrence with imperfect attribution and unverifiable signaling Jonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$ $^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA $^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA # ARTICLE INFO Article history: Received 17 August 2021 Accepted 12 July 2022 Available online 18 July 2022 Keywords: Game theory Decision analysis Security # ABSTRACT Motivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n© 2022 Elsevier B.V. All rights reserved.",
    "# 1. Introduction Defensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).": "However, traditional deterrence (Powell, 1990; Schelling, 1980) relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory: -\"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\"or in other words deterrence requires\"the possibility of a clear demonstration of the defender's capabilities (Morgan, 2003).\"-\"The deterring state must first know who to counterattack (Goodman, 2010).\"When considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that\"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\"and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect\"demonstrations\"such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations (Lynch, 2002; Riedel, 2007; Saran, 2016) as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to\"respond when necessary\"major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states\"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means (Parly, 2019).\"Chinese mili https://doi.org/10.1016/j.ejor.2022.07.021 0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 tary strategy documents have made similar threats:\"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks (Harris, 2017).\"All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space (Iasiello, 2014; Jensen, 2012; Libicki, 2009) and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas (Baliga et al., 2020) focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and (Baliga et al., 2020).\nAlthough (Baliga et al., 2020) is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy (Konrad, 2020), optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).",
    "# 2. Model outline": "We consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.\nThat is, regardless of what the defender's true capability is, she can costlessly signal any capability.\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n## Model specification\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→[0, 1]. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→[0, 1]. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→[0, 1]. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.",
    "# 4. Results and analysis": "To more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.",
    "# 4.1. The attribution game": "Since in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 $\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$ and the defender never retaliates after observing $o_2$ and randomizes between retaliating and not retaliating after $o_1$ with probability $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$.\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique Proposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\nFig. 2. Defender's expected utility for each of her FL strategies.\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n(b)  $r + w &lt; 1$\nTable 2 Equilibrium expected utilities in the attribution game.\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"",
    "# 4.2. The signaling game": "We now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.",
    "# 4.2.1. Separating equilibria": "First we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.",
    "# 4.2.2. Pooling equilibria": "Before analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.",
    "# 4.2.3. Semi-separating equilibria": "Thus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\nProposition 4 says that if an defender of type $L$ has relatively high ability to punish (relatively high value of $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a\"negative result,\"it is useful as context for the following result, established in proposition 5.\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where: - A defender of type $H$ always signals $s_H$ and always retaliates.\n- A defender of type $L$ signals $s_H$ with probability $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$. After signaling $s_H$, the defender always retaliates. After signaling $s_L$, the defender retaliates with probability $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$ after observing $o_1$ and never retaliates after observing $o_2$.\n- An attacker that receives signal $s_H$ attacks with probability $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$.\n- An attacker that receives signal $s_L$ attacks with probability $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$.\nif and only if Furthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type $H$ defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type $L$ will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type $H$, the defender might be bluffing. Upon receiving a signal that the defender is type $H$ the attacker is willing to attack more often than if he knew the defender was type $H$ with certainty. The increase in attack probability allows the defender of type $H$ (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type $L$ can credibly randomize because by signaling she is type $L$, she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type $L$ is because a type $L$ defender does not always retaliate (as she does when she is type $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type $L$ is indifferent between revealing she is type $L$ and incurring a low attack probability with few correct retaliations and signaling she is type $H$, inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type $H$ he is willing to randomize between (1) attacking in the hopes that the defender is actually type $L$ and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type $H$ defender. Although for simplicity we only have one cost for an incorrect retaliation.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\niation $(v)$, we could in principal have two costs, $v_{H}$ and $v_{L}$. Condition 5 says that the semi-separating equilibrium cannot exist if $v_{H} = c_{H}$ and $v_{L} = c_{L}$. In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by $\\pi_1$ and $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type $L$ defender would not be willing to randomize and would instead always signal she was type $L$ and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type $H$ too often, as given in condition 5. This is because if the defender signals she is type $H$ the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type $L$; the prior probability that the defender is type $H$ is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type $L$.\nTo see how such an equilibrium exists, consider Fig. 7. The two values, $\\beta_{H}$ and $\\beta_{L}$ are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability $\\beta_{L}$, the defender of type $L$ is indifferent between never retaliating and retaliating after $a_{1}$. This is where the purple line intersects the dotted blue line. When the attacker attacks with probability $\\beta_{H}$, the type $L$ defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type $L$ is indifferent between these two outcomes and thus is willing to randomize her signal when she is type $L$. A defender of type $H$ receives a higher utility when the attacker attacks with probability $\\beta_{H}$ and always retaliates (solid red line) than when the attacker attacks with probability $\\beta_{L}$ and the attacker retaliates after $a_{1}$ only (dotted blue line). Therefore, the defender of type $H$ would always signal $s_H$, as indicated in the semi-separating equilibrium.",
    "# 4.2.4. Gains from signaling Finally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.": "Proposition 6 (Deterrence Equilibrium). Define: $P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$ $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that Condition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$. In the semi-separating equilibrium, the attacker will randomize either at probability $\\beta_{H}$ or $\\beta_{L}$. While $\\beta_{H}$ is slightly higher than $\\beta_{p}$, $\\beta_{L}$ is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type $L$ has a higher expected utility at $\\beta_{H}$ and $\\beta_{L}$ then at $\\beta_{p}$, the defender gains with signaling through a deterrence effect.\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\nProposition 7 (Anti-deterrence Equilibrium). Define: $P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$ $\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that J. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n(a) $w =.6$ (b) $w = 1$ (c) $w = 1.5$ (d) $w = 2$ (e) $w = 2.5$ (f) $w = 3$ Fig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.",
    "## Conclusion--towards a cyber deterrence policy": "This work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.",
    "__postscript__": "## Appendix A\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\nFor this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\nnot gain anything from such a deviation it must be:\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\nEqs. (A.17) and (A.19) together imply that\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n# Proof of Proposition 6. Define the parameters as follows.\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\nTable A4 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n# Proof of Proposition 7. Define the parameters as follows.\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\nTable A5 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$"
  },
  "process_log": {
    "scheme": "markdown",
    "numeric_check": {
      "first_num": 1,
      "raw_count": 9,
      "raw_examples": [
        1,
        2,
        4,
        4,
        4,
        4,
        4,
        4
      ],
      "filtered_count": 9,
      "filtered_examples": [
        1,
        2,
        4,
        4,
        4,
        4,
        4,
        4
      ],
      "seq_score": 0.2222222222222222
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 9,
      "count": 3,
      "min": 1,
      "examples": [
        1,
        2,
        4
      ],
      "best_run": 2
    },
    "toc_count": 10,
    "section_count": 12
  },
  "word_count": 18347,
  "references": [
    "# References\n115th Congress (2018). H.R.5515 - John S. McCain National Defense Authorization Act for Fiscal Year 2019. Technical Report.\nBaliga, S., De Mesquita, E. B., &amp; Wolitzky, A. (2020). Deterrence with imperfect attribution. American Political Science Review, 114(4), 1155-1178.\nBendiek, A., &amp; Metzger, T. (2015). Deterrence theory in the cyber-century. INFOR-MATIK 2015.\nCheung, K.-F., &amp; Bell, M. G. (2021). Attacker-defender model against quantal response adversaries for cyber security in logistics management: An introductory study. European Journal of Operational Research, 291(2), 471-481. https://doi.org/10.1016/j.ejor.2019.10.019.\nDefense Science Board (2017). Task force on cyber deterrence. Technical Report.\nEdwards, B., Furnas, A., Forrest, S., &amp; Axelrod, R. (2017). Strategic aspects of cyberattack, attribution, and blame. Proceedings of the National Academy of Sciences, 114(11), 2825-2830.\nGoodman, W. (2010). Cyber deterrence: Tougher in theory than in practice? Technical Report. SENATE (UNITED STATES) WASHINGTON DC COMMITTEE ON ARMED SERVICES.\nHarris, S. (2017). China reveals its cyberwar secrets. https://www.thedailybeast.com/china-reveals-its-cyberwar-secrets.\nIasiello, E. (2014). Is cyber deterrence an illusory course of action? Journal of Strategic Security, 7(1), 54-67.\nJensen, E. T. (2012). Cyber deterrence. Emory International Law Review, 26, 773.\nJohnson, J. C., Leeds, B. A., &amp; Wu, A. (2015). Capability, credibility, and extended general deterrence. International Interactions, 41(2), 309-336.\nKamenica, E., &amp; Gentzkow, M. (2011). Bayesian persuasion. American Economic Review, 101(6), 2590-2615.\nKonrad, K. A. (2020). Attacking and defending multiple valuable secrets in a big data world. European Journal of Operational Research, 280(3), 1122-1129. https://doi.org/10.1016/j.ejor.2019.07.064.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLevitin, G., &amp; Hausken, K. (2009). False targets efficiency in defense strategy. European Journal of Operational Research, 194(1), 155-162.\nLiang, L., Chen, J., &amp; Siqueira, K. (2020). Revenge or continued attack and defense in defender-attacker conflicts. European Journal of Operational Research, 287(3), 1180-1190. https://doi.org/10.1016/j.ejor.2020.05.026.\nLibicki, M. C. (2009). Cyberdeterrence and cyberwar. Rand Corporation.\nLynch, M. (2002). Why engage? china and the logic of communicative engagement. European Journal of International Relations, 8(2), 187-230.\nMorgan, P. M. (2003). Deterrence now: vol. 89. Cambridge University Press.\nParly, M. F. (2019). Stratgie cyber des armes.\nPowell, R. (1990). Nuclear deterrence theory: The search for credibility. Cambridge University Press.\nRiedel, B. (2007). Al Qaeda strikes back (pp. 24-40). Foreign Affairs.\nSaran, V. (2016). Media manipulation and psychological war in ukraine and the republic of MoldovaCentre for European Studies (CES) Working Papers, 8(4).\nSchelling, T. C. (1980). The strategy of conflict. Harvard university press.\nShakarian, P., Simari, G. I., Moores, G., &amp; Parsons, S. (2015). Cyber attribution: An argumentation-based approach. In *Cyber warfare* (pp. 151-171). Springer.\nSimon, J., &amp; Omar, A. (2020). Cybersecurity investments in the supply chain: Coordination and a strategic attacker. European Journal of Operational Research, 282(1), 161-171.\nSolak, S., &amp; Zhuo, Y. (2020). Optimal policies for information sharing in information system security. European Journal of Operational Research, 284(3), 934-950. https://doi.org/10.1016/j.ejor.2019.12.016.\nTaddeo, M. (2018). The limits of deterrence theory in cyberspace. Philosophy &amp; Technology, 31(3), 339-355.\nZhou, X., Huang, J., &amp; Cheng, G. (2015). Attacker-defender signaling game in multi-period based on technology accumulation and bayesian learning. In Proceedings of the 3rd international conference on machinery, materials and information technology applications. Atlantis Press.\nZhuang, J., Bier, V. M., &amp; Alagoz, O. (2010). Modeling secrecy and deception in a multiple-period attacker-defender signaling game. European Journal of Operational Research, 203(2), 409-418.\n1416"
  ],
  "citations": {
    "style": "author_year",
    "flat_text": "European Journal of Operational Research 306 (2023) 1399-1416 ELSEVIER Contents lists available at ScienceDirect European Journal of Operational Research journal homepage: www.elsevier.com/locate/ejor EJSEVIER Innovative Applications of O.R.\n# Cyber deterrence with imperfect attribution and unverifiable signaling Jonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$ $^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA $^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA # ARTICLE INFO Article history: Received 17 August 2021 Accepted 12 July 2022 Available online 18 July 2022 Keywords: Game theory Decision analysis Security # ABSTRACT Motivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n© 2022 Elsevier B.V. All rights reserved.\n# 1. Introduction Defensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\nHowever, traditional deterrence relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory: -\"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\"or in other words deterrence requires\"the possibility of a clear demonstration of the defender's capabilities.\"-\"The deterring state must first know who to counterattack.\"When considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that\"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\"and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect\"demonstrations\"such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to\"respond when necessary\"major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states\"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means.\"Chinese mili https://doi.org/10.1016/j.ejor.2022.07.021 0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 tary strategy documents have made similar threats:\"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks.\"All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\n\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas  focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and .\nAlthough  is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy , optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n# 2. Model outline\nWe consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.\nThat is, regardless of what the defender's true capability is, she can costlessly signal any capability.\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n## Model specification\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→[0, 1]. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→[0, 1]. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→[0, 1]. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.\n# 4. Results and analysis\nTo more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.\n# 4.1. The attribution game\nSince in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\n\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 $\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$ and the defender never retaliates after observing $o_2$ and randomizes between retaliating and not retaliating after $o_1$ with probability $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$.\n\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique Proposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\n\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\nFig. 2. Defender's expected utility for each of her FL strategies.\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n(b)  $r + w &lt; 1$\nTable 2 Equilibrium expected utilities in the attribution game.\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"\n# 4.2. The signaling game\nWe now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.\n# 4.2.1. Separating equilibria\nFirst we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.\n# 4.2.2. Pooling equilibria\nBefore analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.\n# 4.2.3. Semi-separating equilibria\nThus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\n\nProposition 4 says that if an defender of type $L$ has relatively high ability to punish (relatively high value of $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a\"negative result,\"it is useful as context for the following result, established in proposition 5.\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where: - A defender of type $H$ always signals $s_H$ and always retaliates.\n- A defender of type $L$ signals $s_H$ with probability $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$. After signaling $s_H$, the defender always retaliates. After signaling $s_L$, the defender retaliates with probability $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$ after observing $o_1$ and never retaliates after observing $o_2$.\n- An attacker that receives signal $s_H$ attacks with probability $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$.\n- An attacker that receives signal $s_L$ attacks with probability $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$.\nif and only if Furthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type $H$ defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type $L$ will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type $H$, the defender might be bluffing. Upon receiving a signal that the defender is type $H$ the attacker is willing to attack more often than if he knew the defender was type $H$ with certainty. The increase in attack probability allows the defender of type $H$ (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type $L$ can credibly randomize because by signaling she is type $L$, she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type $L$ is because a type $L$ defender does not always retaliate (as she does when she is type $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type $L$ is indifferent between revealing she is type $L$ and incurring a low attack probability with few correct retaliations and signaling she is type $H$, inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type $H$ he is willing to randomize between (1) attacking in the hopes that the defender is actually type $L$ and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type $H$ defender. Although for simplicity we only have one cost for an incorrect retaliation.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\niation $(v)$, we could in principal have two costs, $v_{H}$ and $v_{L}$. Condition 5 says that the semi-separating equilibrium cannot exist if $v_{H} = c_{H}$ and $v_{L} = c_{L}$. In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by $\\pi_1$ and $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type $L$ defender would not be willing to randomize and would instead always signal she was type $L$ and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type $H$ too often, as given in condition 5. This is because if the defender signals she is type $H$ the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type $L$; the prior probability that the defender is type $H$ is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type $L$.\nTo see how such an equilibrium exists, consider Fig. 7. The two values, $\\beta_{H}$ and $\\beta_{L}$ are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability $\\beta_{L}$, the defender of type $L$ is indifferent between never retaliating and retaliating after $a_{1}$. This is where the purple line intersects the dotted blue line. When the attacker attacks with probability $\\beta_{H}$, the type $L$ defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type $L$ is indifferent between these two outcomes and thus is willing to randomize her signal when she is type $L$. A defender of type $H$ receives a higher utility when the attacker attacks with probability $\\beta_{H}$ and always retaliates (solid red line) than when the attacker attacks with probability $\\beta_{L}$ and the attacker retaliates after $a_{1}$ only (dotted blue line). Therefore, the defender of type $H$ would always signal $s_H$, as indicated in the semi-separating equilibrium.\n# 4.2.4. Gains from signaling Finally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\nProposition 6 (Deterrence Equilibrium). Define: $P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$ $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that Condition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$. In the semi-separating equilibrium, the attacker will randomize either at probability $\\beta_{H}$ or $\\beta_{L}$. While $\\beta_{H}$ is slightly higher than $\\beta_{p}$, $\\beta_{L}$ is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type $L$ has a higher expected utility at $\\beta_{H}$ and $\\beta_{L}$ then at $\\beta_{p}$, the defender gains with signaling through a deterrence effect.\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\nProposition 7 (Anti-deterrence Equilibrium). Define: $P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$ $\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that J. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n(a) $w =.6$ (b) $w = 1$ (c) $w = 1.5$ (d) $w = 2$ (e) $w = 2.5$ (f) $w = 3$ Fig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\n\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.\n## Conclusion--towards a cyber deterrence policy\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.\n## Appendix A\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\nFor this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\nnot gain anything from such a deviation it must be:\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\nEqs. (A.17) and (A.19) together imply that\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n# Proof of Proposition 6. Define the parameters as follows.\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\nTable A4 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n# Proof of Proposition 7. Define the parameters as follows.\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\nTable A5 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$",
    "footnotes": {
      "items": {},
      "intext": [
        {
          "index": "1",
          "intext_citation": "$^{1}$",
          "preceding_text": "",
          "footnote": null
        }
      ],
      "stats": {
        "intext_total": 1,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 1,
        "missing_footnotes_for_seen_total": 1,
        "missing_footnotes_for_seen_intext": [
          1
        ],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 0,
        "style": "tex_superscript"
      },
      "results": [],
      "flat_text": "European Journal of Operational Research 306 (2023) 1399-1416 ELSEVIER Contents lists available at ScienceDirect European Journal of Operational Research journal homepage: www.elsevier.com/locate/ejor EJSEVIER Innovative Applications of O.R.\n# Cyber deterrence with imperfect attribution and unverifiable signaling Jonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$ $^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA $^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA # ARTICLE INFO Article history: Received 17 August 2021 Accepted 12 July 2022 Available online 18 July 2022 Keywords: Game theory Decision analysis Security # ABSTRACT Motivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n© 2022 Elsevier B.V. All rights reserved.\n# 1. Introduction Defensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\nHowever, traditional deterrence (Powell, 1990; Schelling, 1980) relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory: -\"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\"or in other words deterrence requires\"the possibility of a clear demonstration of the defender's capabilities (Morgan, 2003).\"-\"The deterring state must first know who to counterattack (Goodman, 2010).\"When considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that\"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\"and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect\"demonstrations\"such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations (Lynch, 2002; Riedel, 2007; Saran, 2016) as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to\"respond when necessary\"major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states\"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means (Parly, 2019).\"Chinese mili https://doi.org/10.1016/j.ejor.2022.07.021 0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 tary strategy documents have made similar threats:\"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks (Harris, 2017).\"All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space (Iasiello, 2014; Jensen, 2012; Libicki, 2009) and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\n\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas (Baliga et al., 2020) focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and (Baliga et al., 2020).\nAlthough (Baliga et al., 2020) is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy (Konrad, 2020), optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n# 2. Model outline\nWe consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.\nThat is, regardless of what the defender's true capability is, she can costlessly signal any capability.\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n## Model specification\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→[0, 1]. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→[0, 1]. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→[0, 1]. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.\n# 4. Results and analysis\nTo more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.\n# 4.1. The attribution game\nSince in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\n\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 $\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$ and the defender never retaliates after observing $o_2$ and randomizes between retaliating and not retaliating after $o_1$ with probability $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$.\n\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique Proposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\n\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\nFig. 2. Defender's expected utility for each of her FL strategies.\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n(b)  $r + w &lt; 1$\nTable 2 Equilibrium expected utilities in the attribution game.\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"\n# 4.2. The signaling game\nWe now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.\n# 4.2.1. Separating equilibria\nFirst we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.\n# 4.2.2. Pooling equilibria\nBefore analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.\n# 4.2.3. Semi-separating equilibria\nThus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\n\nProposition 4 says that if an defender of type $L$ has relatively high ability to punish (relatively high value of $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a\"negative result,\"it is useful as context for the following result, established in proposition 5.\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where: - A defender of type $H$ always signals $s_H$ and always retaliates.\n- A defender of type $L$ signals $s_H$ with probability $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$. After signaling $s_H$, the defender always retaliates. After signaling $s_L$, the defender retaliates with probability $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$ after observing $o_1$ and never retaliates after observing $o_2$.\n- An attacker that receives signal $s_H$ attacks with probability $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$.\n- An attacker that receives signal $s_L$ attacks with probability $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$.\nif and only if Furthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type $H$ defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type $L$ will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type $H$, the defender might be bluffing. Upon receiving a signal that the defender is type $H$ the attacker is willing to attack more often than if he knew the defender was type $H$ with certainty. The increase in attack probability allows the defender of type $H$ (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type $L$ can credibly randomize because by signaling she is type $L$, she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type $L$ is because a type $L$ defender does not always retaliate (as she does when she is type $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type $L$ is indifferent between revealing she is type $L$ and incurring a low attack probability with few correct retaliations and signaling she is type $H$, inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type $H$ he is willing to randomize between (1) attacking in the hopes that the defender is actually type $L$ and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type $H$ defender. Although for simplicity we only have one cost for an incorrect retaliation.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\niation $(v)$, we could in principal have two costs, $v_{H}$ and $v_{L}$. Condition 5 says that the semi-separating equilibrium cannot exist if $v_{H} = c_{H}$ and $v_{L} = c_{L}$. In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by $\\pi_1$ and $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type $L$ defender would not be willing to randomize and would instead always signal she was type $L$ and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type $H$ too often, as given in condition 5. This is because if the defender signals she is type $H$ the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type $L$; the prior probability that the defender is type $H$ is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type $L$.\nTo see how such an equilibrium exists, consider Fig. 7. The two values, $\\beta_{H}$ and $\\beta_{L}$ are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability $\\beta_{L}$, the defender of type $L$ is indifferent between never retaliating and retaliating after $a_{1}$. This is where the purple line intersects the dotted blue line. When the attacker attacks with probability $\\beta_{H}$, the type $L$ defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type $L$ is indifferent between these two outcomes and thus is willing to randomize her signal when she is type $L$. A defender of type $H$ receives a higher utility when the attacker attacks with probability $\\beta_{H}$ and always retaliates (solid red line) than when the attacker attacks with probability $\\beta_{L}$ and the attacker retaliates after $a_{1}$ only (dotted blue line). Therefore, the defender of type $H$ would always signal $s_H$, as indicated in the semi-separating equilibrium.\n# 4.2.4. Gains from signaling Finally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\nProposition 6 (Deterrence Equilibrium). Define: $P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$ $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that Condition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$. In the semi-separating equilibrium, the attacker will randomize either at probability $\\beta_{H}$ or $\\beta_{L}$. While $\\beta_{H}$ is slightly higher than $\\beta_{p}$, $\\beta_{L}$ is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type $L$ has a higher expected utility at $\\beta_{H}$ and $\\beta_{L}$ then at $\\beta_{p}$, the defender gains with signaling through a deterrence effect.\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\nProposition 7 (Anti-deterrence Equilibrium). Define: $P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$ $\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that J. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n(a) $w =.6$ (b) $w = 1$ (c) $w = 1.5$ (d) $w = 2$ (e) $w = 2.5$ (f) $w = 3$ Fig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\n\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.\n## Conclusion--towards a cyber deterrence policy\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.\n## Appendix A\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\nFor this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\nnot gain anything from such a deviation it must be:\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\nEqs. (A.17) and (A.19) together imply that\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n# Proof of Proposition 6. Define the parameters as follows.\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\nTable A4 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n# Proof of Proposition 7. Define the parameters as follows.\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\nTable A5 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$"
    },
    "numeric": {
      "total": {
        "intext_total": 6,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "0",
          "intext_citation": "[0, 1]",
          "preceding_text": "Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→",
          "footnote": null
        },
        {
          "index": "1",
          "intext_citation": "[0, 1]",
          "preceding_text": "Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→",
          "footnote": null
        },
        {
          "index": "0",
          "intext_citation": "[0, 1]",
          "preceding_text": "The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→",
          "footnote": null
        },
        {
          "index": "1",
          "intext_citation": "[0, 1]",
          "preceding_text": "The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→",
          "footnote": null
        },
        {
          "index": "0",
          "intext_citation": "[0, 1]",
          "preceding_text": "That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→",
          "footnote": null
        },
        {
          "index": "1",
          "intext_citation": "[0, 1]",
          "preceding_text": "That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→",
          "footnote": null
        }
      ],
      "flat_text": "European Journal of Operational Research 306 (2023) 1399-1416\nELSEVIER\nContents lists available at ScienceDirect\nEuropean Journal of Operational Research\njournal homepage: www.elsevier.com/locate/ejor\nEJSEVIER\nInnovative Applications of O.R.\n# Cyber deterrence with imperfect attribution and unverifiable signaling\nJonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$\n$^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA\n$^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA\n# ARTICLE INFO\nArticle history:\nReceived 17 August 2021\nAccepted 12 July 2022\nAvailable online 18 July 2022\nKeywords:\nGame theory\nDecision analysis\nSecurity\n# ABSTRACT\nMotivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n© 2022 Elsevier B.V. All rights reserved.\n# 1. Introduction\nDefensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\n\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\nHowever, traditional deterrence (Powell, 1990; Schelling, 1980) relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory:\n- \"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\" or in other words deterrence requires \"the possibility of a clear demonstration of the defender's capabilities (Morgan, 2003).\"\n- \"The deterring state must first know who to counterattack (Goodman, 2010).\"\nWhen considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that \"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\" and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect \"demonstrations\" such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations (Lynch, 2002; Riedel, 2007; Saran, 2016) as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to \"respond when necessary\" major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states \"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means (Parly, 2019).\" Chinese mili\nhttps://doi.org/10.1016/j.ejor.2022.07.021\n0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntary strategy documents have made similar threats: \"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks (Harris, 2017).\" All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space (Iasiello, 2014; Jensen, 2012; Libicki, 2009) and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\n1. The defender can only imperfectly attribute attacks.\n2. The attacker has uncertainty over the defender's retaliatory and defensive capability.\n3. The defender can signal its capability not by revealing its true capability but through costless and unverifiable cheap talk.\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas (Baliga et al., 2020) focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and (Baliga et al., 2020).\nAlthough (Baliga et al., 2020) is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy (Konrad, 2020), optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n# 2. Model outline\nWe consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.\nThat is, regardless of what the defender's true capability is, she can costlessly signal any capability.\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n## Model specification\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.\n# 4. Results and analysis\nTo more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.\n# 4.1. The attribution game\nSince in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\n1. If  $1 - \\pi_1c + \\pi_2\\nu &lt; 0$ , there exists an equilibrium of the attribution game where the attacker randomizes with probability\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and the defender never retaliates after observing  $o_2$  and randomizes between retaliating and not retaliating after  $o_1$  with probability  $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$ .\n2. If  $1 - \\pi_1c + \\pi_2v &gt; 0$ , there exists an equilibrium of the attribution game where the attacker randomizes with probability  $\\beta = \\beta_2^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  and the defender always retaliates after observing  $o_1$  and randomizes between retaliating and not retaliating after  $o_2$  with probability  $\\rho_2^* = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v}$ .\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique\nProposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\n1. Always retaliate\n2. Never retaliate\n3. Retaliate after  $o_1$  and do not retaliate after  $o_2$ .\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\nFig. 2. Defender's expected utility for each of her FL strategies.\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n(b)  $r + w &lt; 1$\nTable 2 Equilibrium expected utilities in the attribution game.\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"\n# 4.2. The signaling game\nWe now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.\n# 4.2.1. Separating equilibria\nFirst we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.\n# 4.2.2. Pooling equilibria\nBefore analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.\n# 4.2.3. Semi-separating equilibria\nThus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\n1. There is no equilibrium where the defender of type  $L$  always signals  $s_L$  and a defender of type  $H$  randomizes between signaling  $s_L$  and  $s_H$  and the attacker randomizes with probability  $\\beta_L$  after receiving  $s_L$  and  $\\beta_H$  after receiving  $s_H$  and  $\\beta_L \\neq \\beta_H$ .\n2. There is no equilibrium where the defender of type  $H$  always signals  $s_H$  and a defender of type  $L$  randomizes between signaling  $s_L$  and  $s_H$  and the attacker randomized with probability  $\\beta_L$  after receiving  $s_L$  and  $\\beta_H$  after receiving  $s_H$  and  $\\beta_L \\neq \\beta_H$ .\nProposition 4 says that if an defender of type  $L$  has relatively high ability to punish (relatively high value of  $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a \"negative result,\" it is useful as context for the following result, established in proposition 5.\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where:\n- A defender of type  $H$  always signals  $s_H$  and always retaliates.\n- A defender of type  $L$  signals  $s_H$  with probability  $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$ . After signaling  $s_H$ , the defender always retaliates. After signaling  $s_L$ , the defender retaliates with probability  $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$  after observing  $o_1$  and never retaliates after observing  $o_2$ .\n- An attacker that receives signal  $s_H$  attacks with probability  $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$ .\n- An attacker that receives signal  $s_L$  attacks with probability  $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ .\nif and only if\n1.  $1 - c_{L} &gt; -v$\n2.  $\\pi_1c_L - \\pi_2v &gt; 1$\n3.  $\\pi_2 &lt;   \\pi_1r_L + \\pi_2w &lt;   1$\n4.  $r_{L} + w &gt; 1$\n5.  $\\frac{\\gamma}{1 - \\gamma} &lt; \\frac{r_L - v - 1}{1 - c_H + v}$\n6.  $w(\\pi_1r_L + \\pi_2w - \\pi_2) &lt; (r_L + w - 1)(\\pi_1r_L + \\pi_2w)$\nFurthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type  $H$  defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type  $L$  will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type  $H$ , the defender might be bluffing. Upon receiving a signal that the defender is type  $H$  the attacker is willing to attack more often than if he knew the defender was type  $H$  with certainty. The increase in attack probability allows the defender of type  $H$  (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type  $L$  can credibly randomize because by signaling she is type  $L$ , she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type  $L$  is because a type  $L$  defender does not always retaliate (as she does when she is type  $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type  $L$  is indifferent between revealing she is type  $L$  and incurring a low attack probability with few correct retaliations and signaling she is type  $H$ , inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type  $H$  he is willing to randomize between (1) attacking in the hopes that the defender is actually type  $L$  and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type  $H$  defender. Although for simplicity we only have one cost for an incorrect retaliation.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\niation  $(v)$ , we could in principal have two costs,  $v_{H}$  and  $v_{L}$ . Condition 5 says that the semi-separating equilibrium cannot exist if  $v_{H} = c_{H}$  and  $v_{L} = c_{L}$ . In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by  $\\pi_1$  and  $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type  $L$  defender would not be willing to randomize and would instead always signal she was type  $L$  and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type  $H$  too often, as given in condition 5. This is because if the defender signals she is type  $H$  the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type  $L$ ; the prior probability that the defender is type  $H$  is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type  $L$ .\nTo see how such an equilibrium exists, consider Fig. 7. The two values,  $\\beta_{H}$  and  $\\beta_{L}$  are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability  $\\beta_{L}$ , the defender of type  $L$  is indifferent between never retaliating and retaliating after  $a_{1}$ . This is where the purple line intersects the dotted blue line. When the attacker attacks with probability  $\\beta_{H}$ , the type  $L$  defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type  $L$  is indifferent between these two outcomes and thus is willing to randomize her signal when she is type  $L$ . A defender of type  $H$  receives a higher utility when the attacker attacks with probability  $\\beta_{H}$  and always retaliates (solid red line) than when the attacker attacks with probability  $\\beta_{L}$  and the attacker retaliates after  $a_{1}$  only\n(dotted blue line). Therefore, the defender of type  $H$  would always signal  $s_H$ , as indicated in the semi-separating equilibrium.\n# 4.2.4. Gains from signaling\nFinally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\nProposition 6 (Deterrence Equilibrium). Define:\n$P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$\n$\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$\n-  $\\beta_{H}, \\beta_{L}$  and  $\\alpha_{L}$  as in proposition 5\nThere exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that\n1.  $0 &lt; P_{2} &lt; 1$\n2.  $\\gamma \\beta_{H} + (1 - \\gamma)\\alpha_{L}\\beta_{H} + (1 - \\gamma)(1 - \\alpha_{L})\\beta_{L} &lt;   \\beta_{p}$\n3.  $(1 - \\gamma)\\beta_{p}(r_{L} + w - 1) + \\gamma \\beta_{p}(r_{H} + w - 1) - w &lt;   (1-$ $\\gamma)\\beta_{H}(r_{L} + w - 1) + \\gamma \\beta_{H}(r_{H} + w - 1) - w$\nCondition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability  $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ . In the semi-separating equilibrium, the attacker will randomize either at probability  $\\beta_{H}$  or  $\\beta_{L}$ . While  $\\beta_{H}$  is slightly higher than  $\\beta_{p}$ ,  $\\beta_{L}$  is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type  $L$  has a higher expected utility at  $\\beta_{H}$  and  $\\beta_{L}$  then at  $\\beta_{p}$ , the defender gains with signaling through a deterrence effect.\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\nProposition 7 (Anti-deterrence Equilibrium). Define:\n$P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$\n$\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$\n-  $\\beta_{H}, \\beta_{L}$  and  $\\alpha_{L}$  as in proposition 5\nThere exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that\n1.  $0 &lt; P_{1} &lt; 1$\n2.  $\\gamma \\beta_{H} + (1 - \\gamma)\\alpha_{L}\\beta_{H} + (1 - \\gamma)(1 - \\alpha_{L})\\beta_{L} &gt; \\beta_{p}$\n3.  $-\\beta_{p} &lt;   (1 - \\gamma)\\beta_{H}(r_{L} + w - 1) + \\gamma \\beta_{H}(r_{H} + w - 1) - w$\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n(a) $w = .6$\n(b) $w = 1$\n(c) $w = 1.5$\n(d) $w = 2$\n(e) $w = 2.5$\n(f) $w = 3$\nFig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\n1408\nThis is especially true if there exists a pooling equilibrium that yields a higher payoff for the defender even when the anti-deterrence equilibrium exists. In other words, it would not be reasonable to expect the defender to strategically signal if she could do better by not signaling and earning the expected payoff at the pooling equilibrium. One way to increase the relevance of the anti-deterrence equilibrium is if it was also the sender-preferred equilibrium (Kamenica & Gentzkow, 2011) so that the defender was better off at that equilibrium than any of the pooling equilibria.\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.\n## Conclusion--towards a cyber deterrence policy\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.\n## Appendix A\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\nFor this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\nnot gain anything from such a deviation it must be:\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\nEqs. (A.17) and (A.19) together imply that\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n# Proof of Proposition 6. Define the parameters as follows.\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\nTable A4 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n# Proof of Proposition 7. Define the parameters as follows.\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\nTable A5 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$"
    },
    "author_year": {
      "total": {
        "intext_total": 12,
        "success_occurrences": 12,
        "success_unique": 10,
        "bib_unique_total": 57,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.17543859649122806,
        "success_percentage": 100.0,
        "style": "author_year"
      },
      "results": [
        {
          "index": "powell|1990",
          "intext_citation": "(Powell, 1990; Schelling, 1980)",
          "preceding_text": "However, traditional deterrence",
          "footnote": "Powell, R. (1990). Nuclear deterrence theory: The search for credibility. Cambridge University Press."
        },
        {
          "index": "morgan|2003",
          "intext_citation": "(Morgan, 2003)",
          "preceding_text": "- \"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\" or in other words deterrence requires \"the possibility of a clear demonstration of the defender's capabilities",
          "footnote": "Morgan, P. M. (2003). Deterrence now: vol. 89. Cambridge University Press."
        },
        {
          "index": "goodman|2010",
          "intext_citation": "(Goodman, 2010)",
          "preceding_text": "- \"The deterring state must first know who to counterattack",
          "footnote": "Goodman, W. (2010). Cyber deterrence: Tougher in theory than in practice? Technical Report. SENATE (UNITED STATES) WASHINGTON DC COMMITTEE ON ARMED SERVICES."
        },
        {
          "index": "lynch|2002",
          "intext_citation": "(Lynch, 2002; Riedel, 2007; Saran, 2016)",
          "preceding_text": "These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations",
          "footnote": "Lynch, M. (2002). Why engage? china and the logic of communicative engagement. European Journal of International Relations, 8(2), 187-230."
        },
        {
          "index": "parly|2019",
          "intext_citation": "(Parly, 2019)",
          "preceding_text": "ave made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states \"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means",
          "footnote": "Parly, M. F. (2019). Stratgie cyber des armes."
        },
        {
          "index": "harris|2017",
          "intext_citation": "(Harris, 2017)",
          "preceding_text": "tary strategy documents have made similar threats: \"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks",
          "footnote": "Harris, S. (2017). China reveals its cyberwar secrets. https://www.thedailybeast.com/china-reveals-its-cyberwar-secrets."
        },
        {
          "index": "iasiello|2014",
          "intext_citation": "(Iasiello, 2014; Jensen, 2012; Libicki, 2009)",
          "preceding_text": "Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space",
          "footnote": "Iasiello, E. (2014). Is cyber deterrence an illusory course of action? Journal of Strategic Security, 7(1), 54-67."
        },
        {
          "index": "baliga|2020",
          "intext_citation": "(Baliga et al., 2020)",
          "preceding_text": "Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas",
          "footnote": "Baliga, S., De Mesquita, E. B., &amp; Wolitzky, A. (2020). Deterrence with imperfect attribution. American Political Science Review, 114(4), 1155-1178."
        },
        {
          "index": "baliga|2020",
          "intext_citation": "(Baliga et al., 2020)",
          "preceding_text": "Table 1 summarizes the main similarities and departures of the current work and",
          "footnote": "Baliga, S., De Mesquita, E. B., &amp; Wolitzky, A. (2020). Deterrence with imperfect attribution. American Political Science Review, 114(4), 1155-1178."
        },
        {
          "index": "baliga|2020",
          "intext_citation": "(Baliga et al., 2020)",
          "preceding_text": "Although",
          "footnote": "Baliga, S., De Mesquita, E. B., &amp; Wolitzky, A. (2020). Deterrence with imperfect attribution. American Political Science Review, 114(4), 1155-1178."
        },
        {
          "index": "konrad|2020",
          "intext_citation": "(Konrad, 2020)",
          "preceding_text": "The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy",
          "footnote": "Konrad, K. A. (2020). Attacking and defending multiple valuable secrets in a big data world. European Journal of Operational Research, 280(3), 1122-1129. https://doi.org/10.1016/j.ejor.2019.07.064."
        },
        {
          "index": "kamenica|2011",
          "intext_citation": "(Kamenica & Gentzkow, 2011)",
          "preceding_text": "One way to increase the relevance of the anti-deterrence equilibrium is if it was also the sender-preferred equilibrium",
          "footnote": "Kamenica, E., &amp; Gentzkow, M. (2011). Bayesian persuasion. American Economic Review, 101(6), 2590-2615."
        }
      ],
      "flat_text": "European Journal of Operational Research 306 (2023) 1399-1416 ELSEVIER Contents lists available at ScienceDirect European Journal of Operational Research journal homepage: www.elsevier.com/locate/ejor EJSEVIER Innovative Applications of O.R.\n# Cyber deterrence with imperfect attribution and unverifiable signaling Jonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$ $^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA $^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA # ARTICLE INFO Article history: Received 17 August 2021 Accepted 12 July 2022 Available online 18 July 2022 Keywords: Game theory Decision analysis Security # ABSTRACT Motivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n© 2022 Elsevier B.V. All rights reserved.\n# 1. Introduction Defensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\nHowever, traditional deterrence relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory: -\"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\"or in other words deterrence requires\"the possibility of a clear demonstration of the defender's capabilities.\"-\"The deterring state must first know who to counterattack.\"When considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that\"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\"and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect\"demonstrations\"such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to\"respond when necessary\"major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states\"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means.\"Chinese mili https://doi.org/10.1016/j.ejor.2022.07.021 0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 tary strategy documents have made similar threats:\"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks.\"All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\n\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas  focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and .\nAlthough  is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy , optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n# 2. Model outline\nWe consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.\nThat is, regardless of what the defender's true capability is, she can costlessly signal any capability.\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n## Model specification\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→[0, 1]. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→[0, 1]. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→[0, 1]. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.\n# 4. Results and analysis\nTo more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.\n# 4.1. The attribution game\nSince in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\n\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 $\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$ and the defender never retaliates after observing $o_2$ and randomizes between retaliating and not retaliating after $o_1$ with probability $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$.\n\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique Proposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\n\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\nFig. 2. Defender's expected utility for each of her FL strategies.\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n(b)  $r + w &lt; 1$\nTable 2 Equilibrium expected utilities in the attribution game.\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"\n# 4.2. The signaling game\nWe now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.\n# 4.2.1. Separating equilibria\nFirst we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.\n# 4.2.2. Pooling equilibria\nBefore analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.\n# 4.2.3. Semi-separating equilibria\nThus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\n\nProposition 4 says that if an defender of type $L$ has relatively high ability to punish (relatively high value of $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a\"negative result,\"it is useful as context for the following result, established in proposition 5.\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where: - A defender of type $H$ always signals $s_H$ and always retaliates.\n- A defender of type $L$ signals $s_H$ with probability $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$. After signaling $s_H$, the defender always retaliates. After signaling $s_L$, the defender retaliates with probability $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$ after observing $o_1$ and never retaliates after observing $o_2$.\n- An attacker that receives signal $s_H$ attacks with probability $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$.\n- An attacker that receives signal $s_L$ attacks with probability $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$.\nif and only if Furthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type $H$ defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type $L$ will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type $H$, the defender might be bluffing. Upon receiving a signal that the defender is type $H$ the attacker is willing to attack more often than if he knew the defender was type $H$ with certainty. The increase in attack probability allows the defender of type $H$ (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type $L$ can credibly randomize because by signaling she is type $L$, she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type $L$ is because a type $L$ defender does not always retaliate (as she does when she is type $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type $L$ is indifferent between revealing she is type $L$ and incurring a low attack probability with few correct retaliations and signaling she is type $H$, inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type $H$ he is willing to randomize between (1) attacking in the hopes that the defender is actually type $L$ and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type $H$ defender. Although for simplicity we only have one cost for an incorrect retaliation.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\niation $(v)$, we could in principal have two costs, $v_{H}$ and $v_{L}$. Condition 5 says that the semi-separating equilibrium cannot exist if $v_{H} = c_{H}$ and $v_{L} = c_{L}$. In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by $\\pi_1$ and $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type $L$ defender would not be willing to randomize and would instead always signal she was type $L$ and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type $H$ too often, as given in condition 5. This is because if the defender signals she is type $H$ the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type $L$; the prior probability that the defender is type $H$ is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type $L$.\nTo see how such an equilibrium exists, consider Fig. 7. The two values, $\\beta_{H}$ and $\\beta_{L}$ are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability $\\beta_{L}$, the defender of type $L$ is indifferent between never retaliating and retaliating after $a_{1}$. This is where the purple line intersects the dotted blue line. When the attacker attacks with probability $\\beta_{H}$, the type $L$ defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type $L$ is indifferent between these two outcomes and thus is willing to randomize her signal when she is type $L$. A defender of type $H$ receives a higher utility when the attacker attacks with probability $\\beta_{H}$ and always retaliates (solid red line) than when the attacker attacks with probability $\\beta_{L}$ and the attacker retaliates after $a_{1}$ only (dotted blue line). Therefore, the defender of type $H$ would always signal $s_H$, as indicated in the semi-separating equilibrium.\n# 4.2.4. Gains from signaling Finally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\nProposition 6 (Deterrence Equilibrium). Define: $P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$ $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that Condition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$. In the semi-separating equilibrium, the attacker will randomize either at probability $\\beta_{H}$ or $\\beta_{L}$. While $\\beta_{H}$ is slightly higher than $\\beta_{p}$, $\\beta_{L}$ is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type $L$ has a higher expected utility at $\\beta_{H}$ and $\\beta_{L}$ then at $\\beta_{p}$, the defender gains with signaling through a deterrence effect.\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\nProposition 7 (Anti-deterrence Equilibrium). Define: $P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$ $\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$ - $\\beta_{H}, \\beta_{L}$ and $\\alpha_{L}$ as in proposition 5 There exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that J. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 Fig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n(a) $w =.6$ (b) $w = 1$ (c) $w = 1.5$ (d) $w = 2$ (e) $w = 2.5$ (f) $w = 3$ Fig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\n\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.\n## Conclusion--towards a cyber deterrence policy\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.\n## Appendix A\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac\nARTICLE IN PRESS\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\nFor this deviation to not be profitable for the defender it must be that:\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\nnot gain anything from such a deviation it must be:\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\nEqs. (A.17) and (A.19) together imply that\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal\nJ. Welburn, J. Grana and K. Schwindt\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n# Proof of Proposition 6. Define the parameters as follows.\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\nTable A4 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n# Proof of Proposition 7. Define the parameters as follows.\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\nTable A5 Parameter values where there are gains from signaling through deterrence.\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$"
    }
  },
  "summary": {
    "full_text": {
      "words": 18832,
      "tokens": 31775
    },
    "flat_text": {
      "words": 18347,
      "tokens": 30528
    }
  },
  "payload": "## # 1. Introduction Defensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\n\nHowever, traditional deterrence (Powell, 1990; Schelling, 1980) relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory: -\"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\"or in other words deterrence requires\"the possibility of a clear demonstration of the defender's capabilities (Morgan, 2003).\"-\"The deterring state must first know who to counterattack (Goodman, 2010).\"When considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that\"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\"and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect\"demonstrations\"such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations (Lynch, 2002; Riedel, 2007; Saran, 2016) as key elements of deterrence.\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to\"respond when necessary\"major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states\"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means (Parly, 2019).\"Chinese mili https://doi.org/10.1016/j.ejor.2022.07.021 0377-2217/© 2022 Elsevier B.V. All rights reserved.\nJ. Welburn, J. Grana and K. Schwindt European Journal of Operational Research 306 (2023) 1399-1416 tary strategy documents have made similar threats:\"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks (Harris, 2017).\"All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space (Iasiello, 2014; Jensen, 2012; Libicki, 2009) and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas (Baliga et al., 2020) focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and (Baliga et al., 2020).\nAlthough (Baliga et al., 2020) is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy (Konrad, 2020), optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n\n---\n\n## ## Conclusion--towards a cyber deterrence policy\n\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:SUCCESS\nsections_raw:12\nsections_clean:12\nintro:FOUND\nconclusion:FOUND\npredefined_sections:# 4. Results and analysis|# 4.2.4. Gains from signaling Finally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\nextra_sections:None\npayload_tokens_before:5418\npayload_tokens_after:5418\ndropped_section:None\nadded_section:None\n---LOG_SUMMARY_END---",
  "pages_text": [
    "European Journal of Operational Research 306 (2023) 1399-1416\n\nELSEVIER\n\nContents lists available at ScienceDirect\n\nEuropean Journal of Operational Research\n\njournal homepage: www.elsevier.com/locate/ejor\n\nEJSEVIER\n\nInnovative Applications of O.R.\n\n# Cyber deterrence with imperfect attribution and unverifiable signaling\n\nJonathan Welburn$^{a}$, Justin Grana$^{b,*}$, Karen Schwindt$^{a}$\n\n$^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA\n$^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA\n\n# ARTICLE INFO\n\nArticle history:\nReceived 17 August 2021\nAccepted 12 July 2022\nAvailable online 18 July 2022\n\nKeywords:\nGame theory\nDecision analysis\nSecurity\n\n# ABSTRACT\n\nMotivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more.\n\n© 2022 Elsevier B.V. All rights reserved.\n\n# 1. Introduction\n\nDefensive cyber security best practices have proved to be insufficient for protecting both public and private assets. Cyber aggression against Sony Pictures, the U.S. Office of Personnel Management, the Central Bank of Bangladesh, the Germain Parliament, and ransom-ware attacks WannaCry and NotPetya represent only a small sample of cyber attacks that led to substantial political and economic disruptions and costs. More generally, the threat of cyber attacks against key institutions and critical infrastructure has outpaced defensive efforts to reduce vulnerabilities (Defense Science Board, 2017). As a result, the focus of international cyber defense has shifted toward deterrence. For example, the 2019 National Defense Authorization Act (NDAA) specifically calls for such a U.S. cyber deterrence policy:\n\n\"It shall be the policy of the United States, with respect to matters pertaining to cyberspace, cybersecurity and cyber warfare, that the United States should employ all instruments of national power, including the use of offensive cyber capabilities, to deter if possible, and respond to when necessary, all cyber attacks or other malicious cyber activities (115th Congress, 2018).\n\nHowever, traditional deterrence (Powell, 1990; Schelling, 1980) relies on numerous assumptions that in new domains of attack — especially computer networks — are no longer valid. Consider the following two assumptions that are central to classic deterrence theory:\n\n- \"General deterrent threats are likely to be more effective when a potential challenger views them as capable (Johnson, Leeds, &amp; Wu, 2015).\" or in other words deterrence requires \"the possibility of a clear demonstration of the defender's capabilities (Morgan, 2003).\"\n- \"The deterring state must first know who to counterattack (Goodman, 2010).\"\n\nWhen considering cyberwarfare, neither of these assumptions are likely to hold. First, it is unlikely that potential attackers know their target's retaliatory capability. The reason is that \"cyber weapons rely largely on previously unknown, so called zero-day, vulnerabilities\" and thus demonstrating a capability to a potential attacker renders the capability ineffective (Bendiek &amp; Metzger, 2015; Taddeo, 2018). Furthermore, imperfect \"demonstrations\" such as cyber defense budgets are often classified, further limiting a defender's ability to display force. Second, properly attributing a cyber attack is a recognized difficult problem due to both the technical acumen required to conduct forensic analysis and the ease in which an attacker can deliberately obscure its identity (Shakarian, Simari, Moores, &amp; Parsons, 2015). These complexities are not limited to digital interactions; imperfect attribution and signaling are also gaining relevance in domains such as traditional warfare and international relations (Lynch, 2002; Riedel, 2007; Saran, 2016) as key elements of deterrence.\n\nNevertheless, the new tenants of deterrence have not quelled the threat of aggression and retaliation. In addition to the 2019 NDAA where the United States promises to \"respond when necessary\" major world superpowers have made similar retaliatory threats. For example in the 2019 French cyber strategy from the Ministre Des Armées states \"We will also be ready to use the cyber weapon in external operations for offensive purposes, alone or in support of our conventional means (Parly, 2019).\" Chinese mili\n\nhttps://doi.org/10.1016/j.ejor.2022.07.021\n\n0377-2217/© 2022 Elsevier B.V. All rights reserved.",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\ntary strategy documents have made similar threats: \"A high-level Chinese military organization has for the first time formally acknowledged that the country's military and its intelligence community have specialized units for waging war on computer networks (Harris, 2017).\" All told, despite the unverifiable nature of these cyber threats, world powers are still publicizing their intentions to use cyber weapons when necessary.\n\nThese new features of modern deterrence scenarios demand a formal and rigorous treatment. Such an exercise would provide a needed foundation for the growing literature focused on the feasibility of deterrence in cyber space (Iasiello, 2014; Jensen, 2012; Libicki, 2009) and establish a standard for expanding traditional deterrence theory. To address this need, we develop a model of an attacker (he) and defender (she) with three main features designed to bridge the gap between traditional and modern deterrence theory:\n\n1. The defender can only imperfectly attribute attacks.\n2. The attacker has uncertainty over the defender's retaliatory and defensive capability.\n3. The defender can signal its capability not by revealing its true capability but through costless and unverifiable cheap talk.\n\nOur focus is on the relevance and importance of item 3. Specifically, since verifiable signaling is unlikely in many domains, including cyberwarfare, we examine whether signaling via cheap talk can be effective in deterring adversaries. Alternatively put, in addition to the traditional levers such as penetration testing, red teaming and user training, we ask whether signaling can be used as yet another lever to manage cyber threats.\n\nThe results of our formal analysis illuminate at least four key insights regarding signaling. First, there is no separating equilibrium in which the defender always noiselessly signals her true retaliatory capability. The reason is that if a defender could convince an adversary that she is indeed signaling her true capability, then the defender would have an incentive to always signal a strong retaliatory capability. Second, there are several babbling equilibria in which the defender's signal provides no information regarding her true capability. While not intrinsically interesting, these babbling equilibria provide a baseline of comparison for any potential signaling equilibria. Third, there exists semi-separating equilibria in which the defender (a) releases noisy signals regarding her true retaliatory capability and (b) increases deterrence through a reduction in the attack probability relative to a babbling equilibrium and (c) increases her expected utility relative to a babbling equilibrium. Or simply put, signaling can be used to increase deterrence.\n\nThe fourth and arguably most surprising result is that in some parameter regimes, there exists a sender-preferred semi-separating equilibrium in which the defender increases her expected utility over a babbling equilibrium by inducing the attacker to increase the probability of attack. The reasons for this counter-intuitive result are two-fold. First, an increase in the attack probability reduces the frequency in which the defender is punished for an incorrect retaliation. Secondly, the defender can use its signal to induce the attacker to attack when the defender has a higher defensive and retaliatory capability. This result, which we call \"anti-deterrence,\" adds a new consideration to the conversation around cyber deterrence. In contrast to the current discussion that mainly asks \"is cyber deterrence possible?\" the results of our model suggest that an equally important question is \"should cyber deterrence be the goal?\"\n\nOur work is undoubtedly most related to the model of deterrence games with imperfect attribution in Baliga, De Mesquita, and Wolitzky (2020). That model - also motivated by cyber warfare - has a single defender and  $N$  possible attackers. The attackers\n\nTable 1 Modeling assumptions in comparison to Baliga et al. (2020).\n\n|   | Current model | Model of Baliga et al. (2020)  |\n| --- | --- | --- |\n|  Number of attackers | 1 | N  |\n|  Defender's retaliation capability | Private information | Common knowledge  |\n|  Communication | Costless and unverifiable | None  |\n|  Defender attribution ability | Imperfect | Imperfect  |\n\nchoose whether to attack and the defender receives a noisy signal and chooses whether to retaliate against one or more attackers. The main finding is endogenous complementarity among attackers where increasing aggression from the most aggressive attacker incentivizes increasing aggression from all others. Furthermore, jointly enhancing attack detection and attacker identification (which they jointly refer to as attribution) strengthens deterrence but enhancing only one of either attack detection or identification may weaken deterrence. Our model builds on but is distinct from Baliga et al. (2020) in that our model focuses on signaling whereas (Baliga et al., 2020) focuses on attribution with multiple attackers. Table 1 summarizes the main similarities and departures of the current work and (Baliga et al., 2020).\n\nAlthough (Baliga et al., 2020) is the closest model to ours, our model synthesizes elements of attacker and defender games that are typically analyzed in isolation. Further examples of attacker and defender games with imperfect attribution can be found in Edwards, Furnas, Forrest, and Axelrod (2017), while examples of signaling is a key feature in Zhou, Huang, and Cheng (2015). Examples that include retaliation in an attacker and defender formulation can be found in Liang, Chen, and Siqueira (2020) whereas strategic deception (though not via signaling) is prominent in Zhuang, Bier, and Alagoz (2010) and Levitin and Hausken (2009).\n\nFurthermore, our model also contributes to the literature on strategic cyber attack and defense. Recent work applies attacker and defender models to security where the attacker has imperfect (quantal response) rationality (Cheung &amp; Bell, 2021). The attacker and defender formulation is further extended in the cyber domain to explicitly consider data security and privacy (Konrad, 2020), optimal information sharing with a strategic attacker (Solak &amp; Zhuo, 2020) and digital supply chain security (Simon &amp; Omar, 2020).\n\n# 2. Model outline\n\nWe consider a two-player sequential-move game of imperfect information between an attacker (he/him) and a defender (she/her). At the start of the game, nature assigns the defender either a \"high\" or \"low\" type, signifying her retaliatory capabilities. In the model, the defender knows its capability with certainty while the attacker does not. Instead, the attacker only knows the probability with which nature assigns the defender's retaliation capability. If our game is interpreted as one instance of an infinitely repeated game, the defender's capability fluctuating between high and low can come about due to the dynamics of bugs and exploits being discovered and patches subsequently released. $^{1}$\n\nAfter the defender realizes her capability, it chooses how to signal her capability to the attacker. The defender can either signal that she has a high capability or a low capability. We do not place any restrictions on these signals and there is no cost to signaling.",
    "That is, regardless of what the defender's true capability is, she can costlessly signal any capability.\n\nNext, the attacker perfectly observes the defender's signal and then chooses whether or not to attack. The attacker's decision to attack is binary and he can only condition its decision on the signal he received from the defender and not the defender's true capability.\n\nFollowing the attacker's decision to attack, the defender receives a signal that is correlated but not perfectly correlated with the attacker's action. As a realistic example, it is possible that an attacker initiates an attack but the defender's threat detection software never notices the attack and thus the defender receives a signal that she is not under attack. This represents an undetected attack. On the other hand, it is possible for the attacker to choose not to attack but the defender receives a signal that she is under attack. This represents a false alarm or possibly an attack by an exogenous and unmodeled attacker. This signal generating process captures the imperfect attribution aspect of the model. That is to say, even when the attacker chooses to attack, the defender does not know with certainty whether she was attacked. We note that this signal generating procedure is the same as in the one attacker case of Baliga et al. (2020).\n\nAfter observing the signal, the defender chooses whether to retaliate against the attacker. There is no restriction on the defender's actions conditional on the signal. So for example, a defender can choose to retaliate even when she did not receive a signal that she was attacked. This might happen if a defender knows that her detection capabilities are poor and it is likely that an attacker chose to attack and subverted detection methods. Similarly, the defender can forego retaliation even if she receives a signal that her systems are under attack.\n\nThe payoffs depend on the defender's capability, the attacker's decision to attack and the defender's decision to retaliate. The attacker incurs a reward for attacking but also incurs a cost if the defender retaliates. If the attacker does not attack but the defender retaliates anyway, the attacker still incurs a cost. The attacker incurs a higher cost of retaliation from a defender that has a high capability. The defender incurs a cost when she is attacked but receives a small benefit (less than the cost of being attacked) for correctly retaliating. The defender incurs a cost if she incorrectly retaliates against the attacker. That is, if the attacker chooses not to attack but the defender retaliates, the defender incurs a cost. If the attacker does not attack and the defender does not retaliate, neither player incurs rewards or costs.\n\nThere are several justifications as to why a defender would receive a benefit from retaliating. One reason, as noted in Baliga et al. (2020) is that a retaliation can be reinterpreted as stopping an ongoing attack. Another source of benefit is that there may be political pressure to retaliate after an attack. Yet another motivation for the defender receiving a benefit by retaliating is to establish a long-run reputation as a player that is willing to retaliate, which may deter other potential attackers in the future.\n\nA key assumption in our model is that a defender with high capability both delivers a stronger strike to the attacker and also receives a higher benefit for a correct retaliation than a defender of low capability. This assumption is supported through various interpretations. If a retaliation is a proxy for stopping an ongoing attack, then a defender that delivers a strong strike to the adversary does more damage to the adversary's systems and thus is more effective at stopping the ongoing attack. An additional interpretation is that the damage to the adversary and the benefit to the defender is independent of the defender's type but the probability of a successful retaliation is higher for a defender of high capability. Therefore, the parameters describing the defender's benefit from a correct retaliation and the harm inflicted on the attacker can be interpreted as the expected benefit and harm.\n\n## Model specification\n\nThe game has two players, an attacker (he), o, and a defender (she), d, and a nature player to capture stochastic elements. In the first stage of the game, nature chooses the type of the defender. The defender is of type H—representing high capability—with probability *γ* and is type L with probability (1-*γ*).\n\nAfter the defender is assigned her type, she signals either she is type H by sending signal *s*_{*H*} or that she is type L by sending signal *s*_{*L*}. Specifically, the defender's pure strategy at this stage is a mapping from {*H*, *L*} to {*s*_{*H*}, *s*_{*L*}}. Therefore, the defender's mixed strategy is a mapping *F*:{*H*, *L*}→[0, 1]. That is, the defender chooses the probability for which she signals a high capability for each of her possible types. This function can be represented by two real numbers *α*_{*H*} and *α*_{*L*}. Specifically, *α*_{*H*} is the probability that the defender signals *s*_{*H*}— a high capability signal—given she was assigned a high capability and *α*_{*L*} is the probability the defender signals *s*_{*H*} given that nature assigned her a low capability. Analogously, (1-*α*_{*H*}) and (1-*α*_{*L*}) is the probability that the defender signals *s*_{*L*}—a low capability signal— given that nature assigned it a high and low capability, respectively.\n\nAfter the defender's signal, the attacker observes the signal and chooses whether or not to attack, denoted by A for “attack” and DA for “do not attack”. The attacker's pure strategy is then a mapping from {*s*_{*H*}, *s*_{*L*}} to {*A*, *D**A*}. and thus the attacker's mixed strategy is a mapping *G*:{*s*_{*H*}, *s*_{*L*}}→[0, 1]. Intuitively, the attacker's mixed strategy assigns the probability of attack, A, conditional on the signal that he received. This strategy can be represented by two real numbers *β*_{*H*} and *β*_{*L*} where *β*_{*H*} is the probability the attacker chooses A given that he received the signal *s*_{*H*} and *β*_{*L*} is the probability that attacker chooses A given it received the signal *s*_{*L*}. Of course, (1-*β*_{*H*}) and (1-*β*_{*L*}) is the probability the attacker does not attack (chooses action DA), given he received signal *s*_{*H*} and *s*_{*L*}, respectively. We do not impose a cost on the attacker for choosing to attack.\n\nAfter the attacker's action is drawn according to the attacker's mixed strategy, the defender's observation is drawn by nature. Specifically, the defender either observes *o*_{1} or *o*_{2} but the probability of each signal depends on the attacker's action. Specifically, if the attacker chooses to attack, the defender observes *o*_{1} with probability *π*_{1} and *o*_{2} with probability (1-*π*_{1}). If the attacker does not attack, then the defender observes *o*_{1} with probability *π*_{2} and and *o*_{2} with probability (1-*π*_{2}). Intuitively, *π*_{1} and *π*_{2} represent the defender's ability to attribute an attack. For example, if *π*_{1} = *π*_{2}, then the signal does not depend on the attacker's action and the defender does not learn anything from the signal. If *π*_{1} = 1 and *π*_{2} = 0, then the defender can perfectly attribute attacks. Without loss of generality, we assume that *π*_{1} ≥ *π*_{2}.\n\nFinally, the defender must choose whether to retaliate given it's observation. The defender's pure strategy maps her capability, observation and the signal she sent to an action {*R*, *D**R*}(*R* for retaliate and *D**R* for do not retaliate). That means that the defender's mixed strategy is a function *F*:{*o*_{1}, *o*_{2}} × {*s*_{*H*}, *s*_{*L*}} × {*H*, *L*}→[0, 1]. This strategy represents the probability that the defender retaliates—chooses action *R*— given her signal, observation and type. Let *ρ*(*x*,*y*,*z*) be the probability the defender retaliates after observing observation x, signaling y and having type H. For example *ρ*(*o*_{1}, *s*_{*H*}, *H*) is the probability that a defender of high capability that signaled *s*_{*H*} and observed *o*, chooses to retaliate. Let *ρ* (without subscripts) be shorthand for the set of *ρ*(*x*,*y*,*z*) in the defender's strategy that give the retaliation probabilities.\n\nThe payoffs depend on the attacker's action, the defender's capability and the defender's choice to retaliate. If the attacker attacks, he accrues payoff of 1. However, if the defender retaliates, the attacker incurs a cost of *c*_{*H*} if the defender has high capability and *c*_{*L*} if the defender has low capability. If the attacker does not",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n![img-0.jpeg](img-0.jpeg)\nFig. 1. Extensive form representation of the signaling game. \"Circle\" nodes are attacker nodes and \"square\" nodes are defender nodes. Nodes of the same color are in the same information set. Probabilities for the nature player are given in Greek letters and actions for the attacker and defender are given in Latin letters. The payoff as described in the model specification are given in the boxes.\n\nattack but the defender retaliates, we assume the attacker incurs a cost of  $\\nu$ , regardless of the defender's type. Since a defender of high capability is more able to punish, we assume  $c_{H} &gt; c_{L}$ . We also assume that  $c_{H} &gt; 1 + \\nu$ . This assumption implies that when the defender has high capability, the attacker would prefer to not attack and not be retaliated against over attacking and incurring a retaliation. Secondly, we assume that  $c_{L} &gt; \\nu$ . This means that the cost to being correctly retaliated against is always worse than being incorrectly retaliated against. For technical convenience, we assume that  $1 - \\pi_{1}c_{L} - \\pi_{2}\\nu \\neq 0$  and  $1 - \\pi_{1}c_{H} - \\pi_{2}\\nu \\neq 0$ . This is an innocuous assumption that allows us to ignore sets of parameters that have measure 0.2\n\nFor the defender, if she is attacked she incurs a cost of  $-1$ . If she correctly retaliates, she earns  $r_H$  if she is high capability and  $r_L$  if she is low capability. We assume  $r_H &gt; r_L$ . We also assume that  $r_H$ ,  $r_L &lt; 1$  which means that the defender would rather not be attacked than be attacked and correctly retaliate. If the defender retaliates when the attacker did not actually attack, she incurs a cost of  $w$ . If there is no attack and no retaliation, both players earn 0. The extensive form version of the game is given in Fig. 1 which illustrates the sequence of events, the information sets and the payoffs.\n\nThe solution concept we will use to analyze this game is the Perfect Bayesian Equilibrium (henceforth equilibrium). Under such a solution concept, player's strategies are optimal given their beliefs and beliefs are derived using Bayes rule wherever possible. We do not need any further equilibrium refinement because our main result holds for all possible actions off of the equilibrium path.\n\n# 4. Results and analysis\n\nTo more cleanly present the results, we first analyze an attribution game and then analyze the associated signaling game. The attribution game is the same as the game described above except the defender's capability is fixed and common knowledge (this would happen if, for example,  $\\gamma = 1$  or  $\\gamma = 0$ ). This renders signaling unnecessary since the attacker knows the defender's capability with certainty. Therefore, in the attribution game the sequence of events are: (1) the attacker chooses whether or not to attack, (2) the defender receives a signal that is correlated with the attack and then (3) the defender chooses whether or not to retaliate. After establishing intuition in the attribution game, we return to the full signaling game in which the defender's capability is not common knowledge and the defender can signal.\n\n# 4.1. The attribution game\n\nSince in the attribution game we assume that the defender's capability is common knowledge in the attribution game, we drop subscripts and let  $r$  be the reward the defender receives from correctly retaliating and  $c$  be the cost to the attacker from being retaliated against after attacking. In the proofs, we assume that  $1 - c &lt; -\\nu$  in the attribution game. Otherwise, there is a trivial equilibrium where the attacker always attacks and the defender always retaliates. However, when considering the full signaling game later, a key equilibrium arises when  $1 - c_{H} &lt; -\\nu$  but  $1 - c_{L} &gt; -\\nu$ , which is obscured in the attribution game. All formal proofs are given in the appendix.\n\nProposition 1 (Equilibrium in the Attribution Game). Suppose  $1 - c &lt; -\\nu$ . Let  $\\beta$  be the probability the attacker attacks in the attribution game. Then:\n\n1. If  $1 - \\pi_1c + \\pi_2\\nu &lt; 0$ , there exists an equilibrium of the attribution game where the attacker randomizes with probability",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n$\\beta = \\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and the defender never retaliates after observing  $o_2$  and randomizes between retaliating and not retaliating after  $o_1$  with probability  $\\rho_1^* = \\frac{1}{\\pi_1c - \\pi_2v}$ .\n\n2. If  $1 - \\pi_1c + \\pi_2v &gt; 0$ , there exists an equilibrium of the attribution game where the attacker randomizes with probability  $\\beta = \\beta_2^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  and the defender always retaliates after observing  $o_1$  and randomizes between retaliating and not retaliating after  $o_2$  with probability  $\\rho_2^* = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v}$ .\n\nCorollary 1 (Uniqueness of Equilibrium in Attribution Game). The equilibria in proposition 1 are unique\n\nProposition 1 and corollary 1 establish that there is a unique equilibrium in the attribution game but the nature of the equilibrium depends on the value of the parameters. To better understand the equilibrium, first consider why it is impossible for there to be an equilibrium in pure strategies. If the attacker always attacks, then the defender has a best response to retaliate, regardless of her signal. However, if the defender always retaliates, the attacker is better off not attacking. Similarly, from the perspective of the defender, if she chooses the pure strategy of never retaliating, the attacker's best response is to always attack, in which case the defender would have a profitable deviation to always retaliate. Therefore, there cannot be a pure strategy equilibrium.\n\nA necessary condition for a mixed strategy equilibrium is that both the defender and the attacker are indifferent among at least two of their strategies. The defender only has to consider three out of four pure strategies:\n\n1. Always retaliate\n2. Never retaliate\n3. Retaliate after  $o_1$  and do not retaliate after  $o_2$ .\n\nThe strategy \"Retaliate after  $o_2$  and do not retaliate after  $o_1$ \" is dominated because for any fixed value of attack probability,  $\\beta$ , Bayesian beliefs necessitate that an attack was more likely if the defender observes  $o_1$  then if she observed  $o_2$ . Therefore, retaliating after  $o_2$  when the defender is less certain there was an attack and not retaliating after  $o_1$  when the defender is more certain there was an attack—is a dominated strategy.\n\nFig. 2 illustrates the defender's expected payoff  $U_{d}$  for each of her three strategies as a function of the attack probability,  $\\beta$ . The purple line extending from the origin is the defender's expected utility from never retaliating. The blue line with an intercept at  $-\\pi_2w$  is the defender's expected utility from retaliating after observing  $o_1$  and not retaliating after  $o_2$ . The red line is the defender's expected utility from always retaliating. Finally, the gray shaded line outlines the defender's best response for each value of  $\\beta$ . Specifically, for  $\\beta &lt; \\frac{\\pi_2w}{\\pi_1r + \\pi_2w}$ , the defender's best response is to never retaliate. For  $\\frac{\\pi_2w}{\\pi_1r + \\pi_2w} &lt; \\beta &lt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is to retaliate only after observing  $o_1$ . Finally, for  $\\beta &gt; \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , the defender's best response is the always retaliate. The legend in the figure lists the equations of each of the lines.\n\nThe slope of the blue line and the red line in Fig. 2 are determined by  $\\pi_1r + \\pi_2w - 1$  and  $r + w - 1$ , respectively. By assumption, these are never 0. However, there is no restriction on their sign (except that  $\\pi_1r + \\pi_2w - 1 &lt; r + w - 1$ ). Therefore, the defender's best response curve may appear qualitatively different, as shown in Fig. 3.\n\nIndependent of the slope of the curves, there are two points where the defender is indifferent between two of her strategies. These occur at  $\\beta_{1}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r + \\pi_{2}w}$  and  $\\beta_{2}^{*} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r + (1 - \\pi_{2}w)}$ . Since the defender cannot have a pure strategy in equilibrium, she must be willing to randomize between at least two strategies. Therefore,\n\n![img-1.jpeg](img-1.jpeg)\nFig. 2. Defender's expected utility for each of her FL strategies.\n\nthe equilibrium attacker randomization probability must be at either one of these two values of  $\\beta$ .\n\nFrom the attacker's perspective, he is willing to randomize if he is indifferent between attacking and not attacking. That means the defender must randomize either after observing  $o_1$  or after observing  $o_2$  to make the attacker indifferent. Suppose the defender randomizes after  $o_1$  and never retaliates after  $o_2$ . The randomization probability that would make the attacker indifferent between attacking and not attacking is  $\\frac{1}{\\pi_1c - \\pi_2v}$ . Of course, this is only a proper probability if  $\\pi_1c - \\pi_2v &gt; 1$ . This means that if the cost of an attacker getting caught is too low (low value of  $c$ ) or if his penalty of being incorrectly retaliated against is too high (high value of  $v$ ), the defender cannot retaliate with a high enough probability after  $o_1$  to make the attacker indifferent between attacking and not attacking. In other words, if the cost of being correctly retaliated against is sufficiently close to the cost of being incorrectly retaliated against, the attacker should always just attack since the cost he incurs due to a retaliation does not significantly depend on whether or not he attacked.\n\nThe attacker's willingness to attack can also be phrased in terms of the defender's attribution probabilities. If the defender's attribution ability are low ( $\\pi_1$  is only slightly greater than  $\\pi_2$ ), then the attacker knows that his attack is not correlated with the defender's signal and thus attacking has little effect on whether or not the defender will retaliate. If this is the case, it is always in the attacker's best interest to attack. Conversely, if the defender's attribution ability is high ( $\\pi_1$  significantly greater than  $\\pi_2$ ) the attacker knows that if he attacks, it is likely to generate a signal leading to detection and therefore the defender is capable of randomizing to make the attacker indifferent between attacking and not attacking.\n\nNow consider the case when the defender always retaliates after  $o_1$  and randomizes her retaliation after  $o_2$ . The attacker can only be made indifferent between attacking and not attacking if  $\\pi_1c - \\pi_2v &lt; 1$ . In this case, if  $c$  is relatively high and  $v$  is relatively low and the defender will always retaliate after  $o_1$ , the attacker will incur a high cost when he does attack and is retaliated against. Since the defender's strategy says to always retaliate after  $o_1$ , the defender cannot randomize with a low enough probability after  $o_2$  to ever induce the attacker to attack because the potential cost to attacking is so high.",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n![img-2.jpeg](img-2.jpeg)\n(a)  $\\pi_1r + \\pi_2w &gt; 1$\nFig. 3. Two different versions of Fig. 2 with different slopes for defender strategies.\n\n![img-3.jpeg](img-3.jpeg)\n(b)  $r + w &lt; 1$\n\nTable 2 Equilibrium expected utilities in the attribution game.\n\n|   | 1 - π1c + π2v ≤ 0 | 1 - π1c + π2v ≥ 0  |\n| --- | --- | --- |\n|  Ud | -β1* | β2*(r-1) - (1 - β2*)w  |\n|  Ud | -π2ρ1*v | -(π2 + (1 - π2)ρ2*)v  |\n\nAgain, the analysis can be phrased in terms of the defender's attribution parameters. If the defender has high attribution ability  $(\\pi_{1}$  much greater than  $\\pi_{2})$  then the attacker knows that if he attacks, it is likely that the defender retaliates. This is because the defender retaliates after observing  $o_1$  and when  $\\pi_{1}$  is high, the defender is more likely to observe  $o_1$ . Therefore, the defender cannot retaliate with a low enough probability after observing  $o_2$  to compensate for the loss the attacker incurs when he attacks and is retaliated against because the attack generated signal  $o_1$ .\n\nSince  $\\beta_{1}^{*} &lt; \\beta_{2}^{*}$ , the attacker attacks with a lower probability when  $\\pi_1c - \\pi_2v &gt; 1$ , which occurs when either the defender has the ability to attribute with a high degree of certainty or the punishment for correctly retaliating is significantly higher than the punishment for incorrect retaliation. However, this does not mean that the defender is better off in the equilibrium where the attacker attacks less. Table 2 shows the defender's expected utility under each equilibrium. If  $\\pi_1r_H + \\pi_2w &gt; 1$ , then the defender's expected utility is higher when the attacker attacks more. We will return to this point later when we discuss the question \"should deterrence be the goal?\"\n\n# 4.2. The signaling game\n\nWe now turn our attention to the signaling game. Specifically, we examine whether there are equilibria in which the defender attempts to signal her true capability to the attacker. As we will see, an important parametric assumption is whether  $1 - c_{L} &gt; -\\nu$  (by assumption  $1 - c_{H} &lt; -\\nu$  always holds). Specifically, if  $1 - c_{L} &gt; -\\nu$ , then the attacker's best response to a type  $L$  defender that always retaliates is to attack. This is because the attacker's payoff for attacking and getting punished  $(1 - c_{L})$  is greater than his pay\n\noff from not attacking and getting punished  $(-v)$ . This will drive our results in the case of a semi-separating equilibrium.\n\n# 4.2.1. Separating equilibria\n\nFirst we establish that there is no separating equilibrium in which the defender's signal truthfully reveals her type, regardless of the sign of  $1 - c_{L} + \\nu$ :\n\nProposition 2 (No Separating Equilibrium). Assume  $1 - c_{L} &lt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\n\nProposition 3 (No Separating Equilibrium II). Assume  $1 - c_{L} &gt; -\\nu$ . Then, there is no equilibrium where the defender truthfully signals her type in the signaling game. Formally, there is no PBE where  $\\alpha_{1} = 1$  and  $\\alpha_{2} = 0$ .\n\nAlthough the formal proofs of propositions 2 and 3 proceed differently, the logic is similar. If the defender truthfully signals her type to the attacker, then after the signal, the attacker and defender just play the attribution game analyzed in the previous section. However, the defender of type  $L$  or type  $H$  would be better off if she could deceive the attacker in playing a different attribution game. In other words, in some cases a defender of type  $H$  would be better off if she could convince the attacker she is type  $L$  and have the attacker choose his strategy as if the defender is type  $L$ . In other cases, the defender of type  $L$  would be better off if she could convince the attacker that she was type  $H$  and have the attacker play the attribution game as if the defender were type  $H$ .\n\nFig. 4 illustrates the payoff for the defender of type  $L$  and type  $H$  in the signaling game and illustrates why there can not be a separating equilibrium. If the defender did truthfully signal her type, then after the signal, the attacker and defender play the attribution game described above. Since there is a unique equilibrium in the attribution game, the attacker's randomization probabilities after receiving signal  $s_H$  are either  $\\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  and after receiving signal  $s_L$ , randomizes with probability  $\\frac{\\pi_2w}{\\pi_2r_L + \\pi_2w}$  or  $\\frac{(1 - \\pi_2w)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . All four of these randomization probabilities are annotated in Fig. 4.",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n![img-4.jpeg](img-4.jpeg)\nFig. 4. Defender's best responses in the signaling game. The solid purple line extending from the origin is the defender's payoffs from never retaliating. The solid lines represent the defender's payoff when she FL is type  $H$  and the dashed lines represent her FL payoffs when she FL is type  $L$ . The four labeled values of  $\\beta$  denote the points where the defender is indifferent between two of her FL strategies\n\nFor any two of the equilibrium probabilities annotated in the figure, it is clear that either a defender of type  $H$  or a defender of type  $L$  would have an incentive to switch her signal. For example, suppose the parameters were such that in the attribution game, when the defender is type  $H$  the attacker randomizes with probability  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and when the defender is type  $L$  randomizes with probability  $\\beta_{L} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$ . These points are where the solid blue line and the dashed blue line intersect the purple line extending from the origin, respectively. In this case, the defender of type  $L$  would have an incentive to signal  $s_{H}$  because her expected utility along her best response curve is higher at  $\\beta_{H}$ . Of course, there are other possible equilibrium randomization probabilities in the attribution game and other versions of the graph (versions with the blue lines sloping upward) but in all cases, either a defender of type  $H$  or a defender of type  $L$  would have an incentive to not truthfully signal.\n\n# 4.2.2. Pooling equilibria\n\nBefore analyzing semi-separating equilibria, we present the possible pooling equilibria. In a pooling equilibrium, the defender's signal conveys no information regarding her true type and thus the attacker ignores the signal and only chooses one value of  $\\beta$  for which to randomize his attack.\n\nThere exists a pure strategy equilibrium if  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &gt; -\\nu$ . In such an equilibrium, the attacker always attacks and the defender always retaliates. This is because the (net) cost to the attacker of being correctly retaliated against when the defender is type  $L$  is relatively small compared to his cost of being incorrectly retaliated against. Therefore, if the defender is significantly likely to be of type  $L$  (one value of  $\\gamma$ ), then an equilibrium attacker strategy is to always attack because the frequency in which the defender is type  $H$  and retaliates is not enough to deter the attacker from attacking when the defender is type  $L$  and has a relatively weak ability to punish.\n\nIf  $\\gamma (1 - c_H) + (1 - \\gamma)(1 - c_L) &lt; -\\nu$ , there is no pure strategy equilibrium in which the attacker always attacks or never attacks. This implies that the defender must also play a mixed strategy in\n\nTable 3 Possible Pooling Equilibria. Column's 2-5 give the defender's actions given her FL type and observation. For example column  $(L,o_1)$  gives the defender's action when the defender is type  $L$  and observes  $o_1$ . The defender's action can be either pure-  $R$  or  $DR-$  or mixed. When the defender's action is mixed, the probability is the probability that the defender retaliates.  $P_{1} = \\frac{1}{\\gamma(\\pi_{1}r_{H} + \\pi_{2}w)} P_{2} = \\frac{1 - (1 - \\gamma)(c_{1}\\pi_{1} - \\pi_{2}\\sigma) - \\gamma(c_{2}\\sqrt{\\sigma})}{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - \\pi_{2}\\sigma} P_{3} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{4} = \\frac{1 - \\gamma(\\pi_{1}r_{H} - \\pi_{2}\\sigma)}{1 - \\gamma(\\pi_{1}r_{L} - \\pi_{2}\\sigma)} P_{5} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})} P_{6} = \\frac{1 - \\gamma(c_{1}\\sqrt{\\sigma}) - (1 - \\pi_{1})(\\pi_{1}r_{L} - \\pi_{2}\\sigma)}{1 - \\pi_{1}r_{H} + (1 - \\pi_{2})(\\pi_{1}r_{L})}$\n\n|   | β | (L,o1) | (L,o2) | (H,o1) | (H,o2)  |\n| --- | --- | --- | --- | --- | --- |\n|  1 | σ1w/σ1rH+σ2w | DR | DR | P1 | DR  |\n|  2 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | R | P2 | R | R  |\n|  3 | σ1w/σ1rL+σ2w | P3 | DR | R | DR  |\n|  4 | σ2w/σ1rL+σ2w | P4 | DR | R | R  |\n|  5 | (1-σ1)w/(1-σ1)rH+(1-σ1)w | DR | DR | R | P5  |\n|  6 | (1-σ2)w/(1-σ1)rH+(1-σ2)w | R | DR | R | p6  |\n\n![img-5.jpeg](img-5.jpeg)\nFig. 5. Defender's of type  $L$ 's best response at  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$  is to retaliate after  $o_1$  and not retaliate after  $o_2$ .\n\norder to make the attacker indifferent between attacking and not attacking $^3$  For the defender to be willing to randomize at one of her information sets, she must be indifferent between two actions at that information set. This implies that a pooling equilibrium must have the attacker randomize with one of the four probabilities given in Fig. 4. Table 3 gives the possible pooling equilibria.\n\nNot all of the equilibria in Table 3 are possible simultaneously. First, the parameters must be such that the defender's randomization probabilities are between 0 and 1. In addition, the equilibria in lines 3 and 4 cannot exist simultaneously and lines 5 and 6 cannot exist simultaneously. To see why the equilibria in lines 5 and 6 cannot exist simultaneously, consider Fig. 3. Again, the gray highlighted line traces the defender's best response for each of her types. If the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ , then a defender of type  $H$  is indifferent between always retaliating and retaliating after  $o_1$  only. However, a defender of type  $L$  may have a best response of either retaliating after  $o_1$  and not retaliating after  $o_2$ , as shown in Fig. 5 or to never retaliate, as shown in Fig. 6. With the exception of a measure zero set of parameters, the defender defender cannot be indifferent between",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n![img-6.jpeg](img-6.jpeg)\nFig. 6. Defender's of type  $L$  best response at  $\\beta = \\frac{(1 - \\pi_1)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$  is to never retaliate.\n\nnever retaliating and retaliating after  $o_1$  only when the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_0 + (1 - \\pi_2)w}$ , and thus only one of the two equilibria can exist for a given value of the parameters. The same type of argument can be used to show that only one of the equilibria in rows 5 and 6 can exist simultaneously $^4$ .\n\nSince there always exists a babbling equilibrium in cheap talk games, at least one equilibrium in Table 3 exists. On the other hand, for some values of the parameters, there are multiple babbling equilibria. For example, when  $\\pi_1 = 9$ ,  $\\pi_2 = 1$ ,  $c_H = 4$ ,  $c_L = 2$ ,  $\\nu = 2$  and  $\\gamma = 4$ , the randomization probabilities in row 1,2,4 and 5 are all proper probabilities and thus there are multiple equilibria. Additionally, at those parameter values, the equilibrium in which the attacker always attacks and the defender always retaliates also exists. We will continue the analysis of pooling equilibria when we discuss each equilibrium relative to the semi-separating equilibrium derived in the following section.\n\n# 4.2.3. Semi-separating equilibria\n\nThus far, we have established that there are never separating equilibria, and depending on the parameter regime, many possible pooling equilibria and one possible pure strategy equilibrium. In this section, we establish the conditions in which there are equilibria where the defender's signal contains some - but not perfect-- information regarding her true type.\n\nProposition 4 (No Semi-Separating Equilibria when.  $1 - c_{L} &lt; -v$  Assume  $1 - c_{L} &lt; -v$ . Then:\n\n1. There is no equilibrium where the defender of type  $L$  always signals  $s_L$  and a defender of type  $H$  randomizes between signaling  $s_L$  and  $s_H$  and the attacker randomizes with probability  $\\beta_L$  after receiving  $s_L$  and  $\\beta_H$  after receiving  $s_H$  and  $\\beta_L \\neq \\beta_H$ .\n2. There is no equilibrium where the defender of type  $H$  always signals  $s_H$  and a defender of type  $L$  randomizes between signaling  $s_L$  and  $s_H$  and the attacker randomized with probability  $\\beta_L$  after receiving  $s_L$  and  $\\beta_H$  after receiving  $s_H$  and  $\\beta_L \\neq \\beta_H$ .\n\nProposition 4 says that if an defender of type  $L$  has relatively high ability to punish (relatively high value of  $c_{L}$ ), then there is no equilibrium in which the defender truthfully signals when she is one type and randomizes its signal when she is another type. While this proposition, in isolation is a \"negative result,\" it is useful as context for the following result, established in proposition 5.\n\nProposition 5 (Semi-Separating Equilibrium with Low Punishment Power). There exists a semi-separating equilibrium where:\n\n- A defender of type  $H$  always signals  $s_H$  and always retaliates.\n- A defender of type  $L$  signals  $s_H$  with probability  $\\alpha_L = \\frac{\\gamma}{1 - \\gamma} \\frac{1 - c_H + \\nu}{c_L - \\nu - 1}$ . After signaling  $s_H$ , the defender always retaliates. After signaling  $s_L$ , the defender retaliates with probability  $\\rho(o_1, s_L, L) = \\frac{1}{\\pi_1 c_L - \\pi_2 v}$  after observing  $o_1$  and never retaliates after observing  $o_2$ .\n- An attacker that receives signal  $s_H$  attacks with probability  $\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)}$ .\n- An attacker that receives signal  $s_L$  attacks with probability  $\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ .\n\nif and only if\n\n1.  $1 - c_{L} &gt; -v$\n2.  $\\pi_1c_L - \\pi_2v &gt; 1$\n3.  $\\pi_2 &lt;   \\pi_1r_L + \\pi_2w &lt;   1$\n4.  $r_{L} + w &gt; 1$\n5.  $\\frac{\\gamma}{1 - \\gamma} &lt; \\frac{r_L - v - 1}{1 - c_H + v}$\n6.  $w(\\pi_1r_L + \\pi_2w - \\pi_2) &lt; (r_L + w - 1)(\\pi_1r_L + \\pi_2w)$\n\nFurthermore, the equilibrium is the unique semi-separating equilibrium in the parameter regime described by 1-6 and there does not exist another semi-separating equilibrium in any other parameter regime.\n\nWhile there are many and somewhat complicated necessary conditions for the semi-separating equilibrium, the intuition behind the equilibrium is more straightforward. A type  $H$  defender always signals her true capability and can credibly retaliate regardless of her observation because she receives a relatively high reward for correct retaliations. The defender of type  $L$  will randomize her signals. This means the attacker knows that when he receives a signal that the defender is type  $H$ , the defender might be bluffing. Upon receiving a signal that the defender is type  $H$  the attacker is willing to attack more often than if he knew the defender was type  $H$  with certainty. The increase in attack probability allows the defender of type  $H$  (that always truthfully signals) to limit her costs due to an incorrect retaliation. Put succinctly, the defender can signal to induce a higher attack probability but simultaneously reduce the cost due to false retaliations. The defender of type  $L$  can credibly randomize because by signaling she is type  $L$ , she reduces the attack probability. The reason the attack probability is lower when the defender reveals herself as type  $L$  is because a type  $L$  defender does not always retaliate (as she does when she is type  $H$ ). Knowing this, the attacker is willing to attack less in an effort to hide from retaliation.\n\nThe necessary conditions for the semi-separating equilibrium are to ensure the randomization probabilities are indeed proper probabilities. Specifically, conditions 3,4 and 6 ensure the defender of type  $L$  is indifferent between revealing she is type  $L$  and incurring a low attack probability with few correct retaliations and signaling she is type  $H$ , inducing a high attack probability with many correct retaliations. Conditions 1,2 and 5 ensure that when the attacker receives a signal that the defender is type  $H$  he is willing to randomize between (1) attacking in the hopes that the defender is actually type  $L$  and is bluffing and (2) not attacking to avoid the correct retaliation of a possibly type  $H$  defender. Although for simplicity we only have one cost for an incorrect retaliation.",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n![img-7.jpeg](img-7.jpeg)\nFig. 7. The attack probabilities for the pooling and semi-separating equilibrium.\n\niation  $(v)$ , we could in principal have two costs,  $v_{H}$  and  $v_{L}$ . Condition 5 says that the semi-separating equilibrium cannot exist if  $v_{H} = c_{H}$  and  $v_{L} = c_{L}$ . In practical terms, this means that a necessary condition for the semi-separating equilibrium is that the attacker must be able to recoup some of his costs after suffering a false retaliation.\n\nThe necessary conditions for the semi-separating equilibria also yield higher level intuition regarding the existence of the semi-separating equilibrium. First, the defender's attribution ability (as represented by  $\\pi_1$  and  $\\pi_2$ ) cannot be neither too low nor too high as implied by conditions 2 and 6. If attribution is relatively poor, the attacker would not be willing to randomize his attack since the attack would not provide a meaningful signal to the defender. If the defender's attribution ability is too high, the type  $L$  defender would not be willing to randomize and would instead always signal she was type  $L$  and take advantage of the low attack probability. Taken to an extreme, this means imperfect attribution is necessary for a semi-separating equilibrium. Secondly, the defender cannot be type  $H$  too often, as given in condition 5. This is because if the defender signals she is type  $H$  the attacker would not attack sufficiently often, even though he knows that the defender might be lying and actually be type  $L$ ; the prior probability that the defender is type  $H$  is just too high. This is especially important because it means that by increasing the likelihood of a high retaliation capability, the defender may inadvertently preclude a semi-separating equilibrium that allows her to deceive the attacker when she is type  $L$ .\n\nTo see how such an equilibrium exists, consider Fig. 7. The two values,  $\\beta_{H}$  and  $\\beta_{L}$  are the attacker randomization probabilities in the semi-separating equilibrium. When the attacker attacks with probability  $\\beta_{L}$ , the defender of type  $L$  is indifferent between never retaliating and retaliating after  $a_{1}$ . This is where the purple line intersects the dotted blue line. When the attacker attacks with probability  $\\beta_{H}$ , the type  $L$  defender's best response is to always retaliate. The horizontal green line illustrates that a defender of type  $L$  is indifferent between these two outcomes and thus is willing to randomize her signal when she is type  $L$ . A defender of type  $H$  receives a higher utility when the attacker attacks with probability  $\\beta_{H}$  and always retaliates (solid red line) than when the attacker attacks with probability  $\\beta_{L}$  and the attacker retaliates after  $a_{1}$  only\n\n(dotted blue line). Therefore, the defender of type  $H$  would always signal  $s_H$ , as indicated in the semi-separating equilibrium.\n\n# 4.2.4. Gains from signaling\n\nFinally we investigate whether it is possible for the defender to gain from signaling. To carry out such an analysis, we say that there is a gain from signaling if for a fixed set of parameters, the semi-separating equilibrium exists and the defender's expected utility in the semi-separating equilibrium is higher than her expected utility in a pooling equilibrium that exists simultaneously. We also say that it is possible for the defender to gain with signaling through a deterrence effect if the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium and the attacker's attack probability of attacking is lower in the semi-separating equilibrium than in the pooling equilibrium. The following proposition establishes the existence of an equilibrium with gains through signaling and a deterrence effect.\n\nProposition 6 (Deterrence Equilibrium). Define:\n\n$P_{2} = \\frac{1 - (1 - \\gamma)(c_{L}\\pi_{1} - \\pi_{2}v) - \\gamma(c_{H} - v)}{(1 - \\gamma)(c_{L}(1 - \\pi_{1}) - v(1 - \\pi_{2}))}$\n$\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$\n-  $\\beta_{H}, \\beta_{L}$  and  $\\alpha_{L}$  as in proposition 5\n\nThere exists a positive measure parameter region where the defender's expected utility (attacker's attack probability) in the semi-separating equilibrium is higher (lower) than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that\n\n1.  $0 &lt; P_{2} &lt; 1$\n2.  $\\gamma \\beta_{H} + (1 - \\gamma)\\alpha_{L}\\beta_{H} + (1 - \\gamma)(1 - \\alpha_{L})\\beta_{L} &lt;   \\beta_{p}$\n3.  $(1 - \\gamma)\\beta_{p}(r_{L} + w - 1) + \\gamma \\beta_{p}(r_{H} + w - 1) - w &lt;   (1-$ $\\gamma)\\beta_{H}(r_{L} + w - 1) + \\gamma \\beta_{H}(r_{H} + w - 1) - w$\n\nCondition 1 in proposition 6 ensures that the pooling equilibrium in row 2 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is higher than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\n\nFig. 7 illustrates the deterrent effect of the semi-separating equilibrium. In the pooling equilibrium, the attacker randomizes with probability  $\\beta_{p} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})c_{L} + (1 - \\pi_{2})w}$ . In the semi-separating equilibrium, the attacker will randomize either at probability  $\\beta_{H}$  or  $\\beta_{L}$ . While  $\\beta_{H}$  is slightly higher than  $\\beta_{p}$ ,  $\\beta_{L}$  is sufficiently low such that on average, the attacker attacks less and the defender's expected utility increases by reducing the probability in which the attacker attacks. Since the defender of type  $L$  has a higher expected utility at  $\\beta_{H}$  and  $\\beta_{L}$  then at  $\\beta_{p}$ , the defender gains with signaling through a deterrence effect.\n\nFinally, we show that the defender can benefit through signaling by luring the attacker to attack more. We refer to this luring equilibrium as anti-deterrence.\n\nProposition 7 (Anti-deterrence Equilibrium). Define:\n\n$P_{1} = \\frac{1}{\\gamma(\\pi_{1}c_{H} - \\pi_{2}v)}$\n$\\beta_{p} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$\n-  $\\beta_{H}, \\beta_{L}$  and  $\\alpha_{L}$  as in proposition 5\n\nThere exists a positive measure parameter region where the defender's expected utility and attacker's attack probability in the semi-separating equilibrium is higher than in a pooling equilibrium. Formally, the conditions in proposition 5 hold such that\n\n1.  $0 &lt; P_{1} &lt; 1$\n2.  $\\gamma \\beta_{H} + (1 - \\gamma)\\alpha_{L}\\beta_{H} + (1 - \\gamma)(1 - \\alpha_{L})\\beta_{L} &gt; \\beta_{p}$\n3.  $-\\beta_{p} &lt;   (1 - \\gamma)\\beta_{H}(r_{L} + w - 1) + \\gamma \\beta_{H}(r_{H} + w - 1) - w$",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n![img-8.jpeg](img-8.jpeg)\nFig. 8. Semi-separating equilibrium where the defender gains by inducing the attacker to attack more.\n\nAgain, condition 1 in proposition 7 ensures that the pooling equilibrium in row 1 of Table 3 exists. Condition 2 says that the a priori attack probability in the pooling equilibrium is less than in the semi-separating equilibrium. Finally, condition 3 says that the defender's expected utility under the semi-separating equilibrium is higher than in the pooling equilibrium.\n\nThere are two driving factors behind this counter-intuitive result. The first reason has to do with the trade-off the defender faces between an incorrect retaliation and an undetected attack. If the cost to an incorrect retaliation is relatively high, then the defender has little incentive to retaliate because she risks the possibility of being incorrect. However, if the attacker were to attack with a higher probability, then the defender would incorrectly retaliate less often. So, if the cost of an incorrect retaliation is high enough, then the defender would benefit from being attacked slightly more but incorrectly retaliating less often.\n\nThe second effect is due to the defender inducing the attacker to attack against a defender of type $H$ where the defender gains the most from a correct retaliation. Consider Fig. 8. The figure illustrates the pooling equilibrium at $\\beta_{p}$ and the semi-separating equilibrium where the attacker randomizes either at $\\beta_{L}$ and $\\beta_{H}$, depending on the signal he receives from the defender. The defender of type $L$'s expected utility when the attacker attack with probability $\\beta_{p}$ is higher than if the attacker were to attack with probability $\\beta_{L}$ or $\\beta_{H}$, indicating that a defender of type $L$ is worse off when the attacker attacks more. However, the expected utility of an attacker of type $H$ is higher at $\\beta_{H}$ than at $\\beta_{p}$. Therefore, if the defender can randomize her signal such that the benefit she receives from retaliating when she is type $H$ outweighs the loss she would incur from a higher attack probability when the defender is type $L$, then the defender stands to gain from a higher attack probability. In other words, the defender can gain when the attacker attacks more as long as the increased attack probability mostly occurs when the defender is type $H$ and can more effectively retaliate.\n\nSince this signaling game is rife with multiple equilibria, the existence of an anti-deterrence equilibrium does not necessarily speak to the likelihood of it occurring in real deterrence scenarios.\n\n![img-9.jpeg](img-9.jpeg)\n(a) $w = .6$\n\n![img-10.jpeg](img-10.jpeg)\n(b) $w = 1$\n\n![img-11.jpeg](img-11.jpeg)\n(c) $w = 1.5$\n\n![img-12.jpeg](img-12.jpeg)\n(d) $w = 2$\n\n![img-13.jpeg](img-13.jpeg)\n(e) $w = 2.5$\n\n![img-14.jpeg](img-14.jpeg)\n(f) $w = 3$\n\nFig. 9. Region in $\\pi_1$, $\\pi_2$ space where the semi-separating equilibrium exists and the defender can gain from signaling by inducing the attacker to attack more. The parameters other than $\\pi_1$, $\\pi_2$ and $w$ are as in Table A.5.\n\n1408",
    "This is especially true if there exists a pooling equilibrium that yields a higher payoff for the defender even when the anti-deterrence equilibrium exists. In other words, it would not be reasonable to expect the defender to strategically signal if she could do better by not signaling and earning the expected payoff at the pooling equilibrium. One way to increase the relevance of the anti-deterrence equilibrium is if it was also the sender-preferred equilibrium (Kamenica & Gentzkow, 2011) so that the defender was better off at that equilibrium than any of the pooling equilibria.\n\nAs Fig. 8 demonstrates, if the semi-separating equilibrium exists, then the defender's expected utility at the equilibrium is always greater than any pooling equilibrium in which the attacker randomizes with probability other than $\\hat{\\beta}_{p} = \\frac{\\pi_{2}w}{\\pi_{1}t_{b} + \\pi_{2}w}$. However, proposition 7 establishes that there are parameter regions where the defender's expected payoff at the anti-deterrence equilibrium is also higher than her payoff at the equilibrium where the attacker randomizes with probability $\\hat{\\beta}_{p}$. Therefore, proposition 7 is stronger than initially claimed and actually shows that there exists parameter regions where there is a sender-preferred anti-deterrence equilibrium.\n\nAs a final illustration of the equilibrium and its properties, Fig. 9 shows the parameter region where the sender-preferred anti-deterrence equilibrium exists. In the figure, the blue region is the region where the anti-deterrence equilibrium exists and is sender-preferred. In the orange region, the anti-deterrence equilibrium exists but is not sender preferred. Generally speaking, the lower right corner of the plot is where attribution capabilities are the highest (high value of *π*_{1} and low value of *π*_{2}. By varying w, the figure shows that as the cost of an incorrect retaliation increases, the defender's attribution ability must increase in order to support a semi-separating equilibrium. However, as w increases, the defender has an incentive to retaliate less and thus the pooling equilibrium where only a type H defender retaliates after *o*_{1} is more prevalent in the parameter region where the anti-deterrence equilibrium exists. Or in other words, increasing w may widen the parameter region where the anti-deterrence equilibrium exists but will also widen the region where the anti-deterrence equilibrium is not sender preferred.\n\n## Conclusion--towards a cyber deterrence policy\n\nThis work responds to an active conversation on the strategy of cyber deterrence where calls for a cyber deterrence policy have been met with debate on the desirability and feasibility of deterring aggression in cyberspace. The challenges emanating from the cyber domain on conflict are a marked departure from the challenges of the nuclear domain. Thus, while the fundamental building blocks of deterrence outlined by Schelling persist, the lessons of nuclear deterrence may not. We offer a model with two players, imperfect information, and signaling to analyze the viability of deterrence in domains with imperfect attribution and signaling.\n\nUnfortunately, our results show that complete deterrence will not come easy for the foreseeable future; with imperfect attribution, there are no equilibria in which the attacker will never attack and therefore we find complete deterrence unlikely. However, that does not render some deterrence unfeasible. To the contrary, when a defender is able to signal her capability, she may partially deter an attacker from launching an attack. Specifically, we show that there are semi-separating equilibria in which the attacker attacks with a lower probability than in a game without signaling and the defender receives the benefits from the reduced attacks. Thus, while signaling does not bring the attack probability to zero, she can reduce the chances of an attack. Signaling, therefore, is a key feature of a deterrence policy worthy of further exploration.\n\nOur findings also point to a curious concept of anti-deterrence that raises the question: is deterrence the only option? In a world without perfect information and verifiable signals, our results suggest that anti-deterrence may be a means of increasing the defender's well-being while also welcoming a higher probability of attack. We show that in some cases, a defender would be willing to take on a higher probability of being attacked if (1) the higher probability of attack reduces the probability (and therefore costs) of an incorrect retaliation and (2) the increase in the probability of attack is more heavily weighted to when the defender is most able to respond to attack and not when she cannot effectively respond.\n\nOne caution in interpreting these insights is that our model and results are prescriptive and not descriptive. That is, we do not claim that our model accurately captures how real world leaders are currently making decisions regarding deterrence in cyberspace. Instead, this work derives its value from two sources. First, it formalizes many of the informal and rhetorical arguments regarding deterrence in cyber space. While signaling and attribution are indeed oft cited reasons why deterrence in the digital domain is distinct from the nuclear domain, we give these concepts a precise definition on which to build further rigorous arguments. Second, instead of describing current policy and outcomes, our results suggest a new policy that may take the place of a pure deterrence policy. Specifically, our results are the first — to our knowledge — to suggest a policy in which a defender signals to increase the attack probability in order to reduce the prevalence of false retaliations.\n\nThe conversation on cyber deterrence is ripe for further debate. A natural extension to this model would be to combine signaling with multiple attackers as in Baliga et al. (2020). The main question would be to examine whether having a higher attack probability might still be optimal if incorrect retaliations befall other attackers. Is it the case that luring one attacker increases the probability of an incorrect retaliation on another attacker, thus incentivizing all attackers to attack more since they are more likely to be retaliated against? This question can be further enriched when there is heterogeneity among the attackers in terms of the damage they can inflict. A model with multiple attacker might answer whether luring relatively insignificant attackers can deter the strong attackers. Lastly, what are the strategic benefits of luring when an attack by one attacker can provide the defender with information about other potential attackers? Answering such questions require careful modeling decisions including (1) can the defender signal multiple attackers? (2) Can the defender retaliate against multiple attackers simultaneously? (3) Can the defender be attacked by multiple attackers simultaneously. As such, a full model with multiple attackers is out of scope for this work but a natural and fruitful extension.\n\n## Appendix A\n\nProposition 1 To prove proposition 1, we begin with two lemmas that establish there are no pure strategy equilibria and then prove the proposition by looking for mixed strategy equi",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\nLemma 1 (No Pure Strategy Equilibrium for the Attacker in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the attacker plays a pure strategy.\n\nProof. Suppose the attacker's pure strategy is to never attack. The defender's best response against such a strategy is to never retaliate. However, the attacker's best response to the defender never retaliating is to always attack. Therefore, there is no pure strategy equilibrium where the attacker never attacks. Now, suppose the attacker's pure strategy is to always attack. In this case, the defender's best response is to always retaliate. However, the attacker's best response to the defender always retaliating is to never attack (since by assumption, the total payoff to attacking and being correctly retaliated against, $1 - c$, is less than the total payoff of being incorrectly retaliated against $-\\nu$.) Therefore, there is no pure strategy equilibrium where the attacker always attacks. $\\square$\n\nLemma 2 (No Pure Strategy Equilibrium for the Defender in the Attribution Game). If $1 - c &lt; -\\nu$ there is no equilibrium in the attribution game where the defender plays a pure strategy.\n\nProof. Suppose the defender's pure strategy is to always retaliate. Then the attacker's best response would be to never attack and thus the defender's best response would be to never retaliate. Therefore, always retaliating cannot be part of an equilibrium. A parallel argument shows that never retaliating cannot be part of equilibrium. The only other pure strategy for the defender in the attribution game is to always retaliate after receiving signal $o_1$ and never retaliate after signal $o_2$ (since $\\pi_1 &gt; \\pi_2$, the strategy always retaliate after $o_2$ and never retaliate after $o_1$ is strictly dominated). If the defender adopts this strategy, the attacker's expected utility from attacking and not attacking is given by:\n\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, D R)) = P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\\\\n= \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\\\\n\\end{array}\n$$\n\n$$\nU _ {a} (N A, (R, D R)) = P r \\left(o _ {1} | N A\\right) (- \\nu) + P r \\left(o _ {2} | N A\\right) \\times 0 = \\pi_ {2} \\nu\n$$\n\nwhere $U_{a}(X,(Y,Z))$ is the expected utility of the attacker for choosing action $X$ where the defender chooses (the probability of) action $Y$ after observing $o_1$ and (the probability of action) $Z$ after observing $o_2$. These expected utilities implies that if $1 - \\pi_1c - \\pi_2\\nu &gt; 0$, then the attacker would always attack and if $1 - \\pi_1c - \\pi_2\\nu &lt; 0$ then attacker would never attack both of which by Lemma 1 cannot be part of an equilibrium (Recall that by assumption $1 - \\pi_1c - \\pi_2\\nu \\neq 0$). $\\square$\n\nLemmas 1 and 2 establish that there cannot be an equilibrium in which either the attacker or the defender play pure strategies. Therefore, we prove proposition 1 by searching for mixed strategy equilibria only.\n\nProof of Proposition 1. Suppose the attacker randomizes with probability $\\beta$. Then equilibrium defender beliefs are determined as follows:\n\n$$\n\\begin{array}{l}\nP r (A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (A)}{P r (o _ {1})} = \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\nP r (D A | o _ {1}) = \\frac {P r (o _ {1} | A) P r (D A)}{P r (o _ {1})} = \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n\n$$\n\\begin{array}{l}\nP r (A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (A)}{P r (o _ {2})} \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n\n$$\nP r (D A | o _ {2}) = \\frac {P r (o _ {2} | A) P r (D A)}{P r (o _ {2})}\n$$\n\n$$\n= \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)}\n$$\n\nWith these probabilities, it is possible to write the defender's expected utility from retaliating and not retaliating for each of its observations. They are given by:\n\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {1}) = P r (A | o _ {1}) (r - 1) - P r (D A | o _ {1}) w \\\\\n= \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} (r - 1) \\\\\n- \\frac {\\pi_ {2} (1 - \\beta)}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} w \\\\\n\\end{array}\n$$\n\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta ; o _ {1}) = - P r (A | o _ {1}) - 0 \\times P r (D A | o _ {1}) \\\\\n= - \\frac {\\pi_ {1} \\beta}{\\pi_ {1} \\beta + \\pi_ {2} (1 - \\beta)} \\\\\n\\end{array}\n$$\n\n$$\n\\begin{array}{l}\nU _ {d} (R, \\beta ; o _ {2}) = P r (A | o _ {2}) (r - 1) - P r (D A | o _ {2}) w \\\\\n= \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} (r - 1) \\\\\n- \\frac {(1 - \\pi_ {2}) (1 - \\beta)}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} w \\\\\n\\end{array}\n$$\n\n$$\n\\begin{array}{l}\nU _ {d} (D R, \\beta_ {H}; o _ {2}) = - P r (A | o _ {2}) - 0 \\times P r (D A | o _ {2}) \\\\\n= - \\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {1}) \\beta + (1 - \\pi_ {2}) (1 - \\beta)} \\\\\n\\end{array}\n$$\n\nwhere $U_{d}(X,\\beta ;o)$ is the expected utility of the defender by choosing action $X$ given the attacker randomizes with probability $\\beta$ and the defender observed observation $o$. Since there is no equilibrium where the defender plays a pure strategy and must randomize, it must be indifferent at (at least) one of its information sets.\n\nAfter observing $o_1$ the defender is indifferent between retaliating and not retaliating when:\n\n$$\n\\frac {\\pi_ {1} \\beta}{\\pi_ {2} (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {\\pi_ {2} w}{\\pi_ {1} r + \\pi_ {2} w} \\tag {A.1}\n$$\n\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.1) and not retaliate if $\\beta$ is less than the RHS.\n\nAfter observing $o_2$, the defender is indifferent between retaliating and not retaliating when\n\n$$\n\\frac {(1 - \\pi_ {1}) \\beta}{(1 - \\pi_ {2}) (1 - \\beta)} = \\frac {w}{r} \\Rightarrow \\beta = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r + (1 - \\pi_ {2}) w} \\tag {A.2}\n$$\n\nwhere it is optimal for the defender to retaliate if $\\beta$ is greater than the right hand side (RHS) of Eq. (A.2) and not retaliate if $\\beta$ is less than the RHS. Since $\\pi_1 &gt; \\pi_2$ by assumption, the RHS of A.1 is less than the RHS of A.2.\n\nSince the defender must be indifferent at least one of its information sets, Eqs. (A.1) and (A.2) give the only two possible values of equilibrium attacker randomization probability. We will now establish the sufficient conditions for the values in Eqs. (A.1) and (A.2) to be part of a PBE.\n\nCase 1: $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$ Suppose the attacker randomizes with probability $\\beta = \\frac{\\pi_2 w}{\\pi_1 r + \\pi_2 w}$, then the defender will never retaliate after receiving $o_2$ and is indifferent after observing $o_1$, and therefore is willing to randomize with probability $\\rho$ after observing $o_1$. The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n\n$$\n\\begin{array}{l}\nU _ {a} (A, (\\rho , D R)) = U _ {a} (N A, (\\rho , D R)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (1 - c) + P r \\left(o _ {1} | A\\right) P r \\left(N R \\mid o _ {1}\\right) \\\\\n+ P r \\left(o _ {2} | A\\right) = P r \\left(o _ {1} | A\\right) P r \\left(R \\mid o _ {1}\\right) (- \\nu) \\\\\n\\end{array}\n$$",
    "ARTICLE IN PRESS\n\nJ. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n$$\n\\begin{array}{l}\n\\Rightarrow \\pi_ {1} \\rho (1 - c) + \\pi_ {1} (1 - \\rho) + 1 - \\pi_ {1} = - \\pi_ {2} \\rho v \\\\\n\\Rightarrow \\rho = \\frac {1}{\\pi_ {1} c - \\pi_ {2} v}. \\tag {A.3}\n\\end{array}\n$$\n\nSince  $\\rho$  is a probability, it only takes on the values between 0 and 1, which holds only when  $1 - \\pi_1c + \\pi_2v\\leq 0$ . Therefore, if  $1 - \\pi_{1}c + \\pi_{2}v\\leq 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{\\pi_2w}{\\pi_1c + \\pi_2w} = \\beta_1^*$  and the defender never retaliates after observing  $o_2$  and randomizes with probability  $\\rho = \\frac{1}{\\pi_1c - \\pi_2v} = \\rho_1^*$  after observing  $o_1$ . This proves item 1 of the proposition.\n\nCase 2:  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$  Suppose the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w}$ , then the defender will always retaliate after receiving  $o_1$  and is willing to randomize with probability  $\\rho$  after observing  $o_2$ . The necessary and sufficient condition for the attacker to be willing to randomize is if its expected utility from attacking is equal to its expected utility from not attacking. This is satisfied when:\n\n$$\n\\begin{array}{l}\nU _ {a} (A, (R, \\rho)) = U _ {a} (N A, (R, \\rho)) \\\\\n\\Rightarrow P r \\left(o _ {1} | A\\right) (1 - c) + P r \\left(o _ {2} | A\\right) \\rho (1 - c) \\\\\n+ P r \\left(o _ {2} | A\\right) (1 - \\rho) = P r \\left(o _ {1} | N A\\right) (- v) + P r \\left(o _ {2} | N A\\right) \\rho (- v) \\\\\n\\Rightarrow \\pi_ {1} (1 - c) + (1 - \\pi_ {1}) \\rho (1 - c) + (1 - \\pi_ {1}) (1 - \\rho) \\\\\n= - v \\left(\\pi_ {2} + (1 - \\pi_ {2}) \\rho\\right) \\\\\n\\Rightarrow \\rho = \\frac {1 - \\pi_ {1} c + \\pi_ {2} v}{(1 - \\pi_ {1}) c - (1 - \\pi_ {2}) v}. \\tag {A.4}\n\\end{array}\n$$\n\nSince by assumption  $c - v &gt; 1$  the numerator is less than the denominator and thus the only way that  $\\rho$  represents a proper probability is if  $1 - \\pi_1c + \\pi_2v &gt; 0$ . Therefore, if  $1 - \\pi_1c + \\pi_2v &gt; 0$ , then there is a Nash equilibrium where the attacker randomizes with probability  $\\beta = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r + (1 - \\pi_2)w} = \\beta_2^*$  and the defender always retaliates after observing  $o_1$  and randomizes with probability  $\\rho = \\frac{1 - \\pi_1c + \\pi_2v}{(1 - \\pi_1)c - (1 - \\pi_2)v} = \\rho_2^*$  after observing  $o_2$ . This proves item 2 of the proposition.\n\n- Proof of Corollary 1. As shown in the proof of proposition 1, there are only two possible values of  $\\beta$  that can be part of a Nash equilibrium. For each value of  $\\beta$ , there is only one mixed strategy for the defender that would make the attacker indifferent and thus willing to randomize. This suggests that there may be two equilibria. However, under one value of  $\\beta$  the existence of a defender's equilibrium mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &gt; 0$  where for the other value of  $\\beta$ , the existence of the defender's mixed strategy relies on  $1 - \\pi_1c + \\pi_2v &lt; 0$ . Since both conditions can not hold simultaneously, there is a unique Nash equilibrium determined by the sign of  $1 - \\pi_1c + \\pi_2v$ .\n\n- Proof of Proposition 2. If the defender truthfully signals its capability, then Bayes rule dictates that the attacker assigns probability 1 to the defender's true capability and 0 otherwise. Therefore, after the truthful signal, a separating equilibrium would have the players play the equilibrium profile of the attribution game where the parameters are determined by the defender's true type and the payoffs would be as in Table 2 where the values of  $r$  and  $c$  are given according to the defender's type. This proof shows that for all possible values of  $1 - \\pi_1c_k + \\pi_2v$  where  $k \\in [H,L]$ , the defender can improve its expected utility by lying to the attacker about its type.\n\nFormally, let  $\\beta_{L}^{*}$  be the attacker's equilibrium probability of attacking when the players play the attribution game and the defender is type  $L$  and let  $\\beta_{H}^{*}$  be the attacker's equilibrium probability of attacking when they play the attribution game and the defender is type  $H$ .\n\n- Case 1:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &lt; 0$ . Consider when the defender truthfully signals  $s_L$ , indicating that it\n\nhas a low capability. In this case, the attacker's equilibrium probability in the attribution game is  $\\beta_{L}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  and the defender's expected utility is  $-\\beta_{L}^{*}$ . If instead of signaling  $s_{L}$  the defender signaled  $s_{H}$ , the attacker would randomize with probability  $\\beta_{H}^{*} = \\frac{\\pi_{2}w}{\\pi_{1}r_{H} + \\pi_{2}w}$  and the defender's payoff would be  $-\\beta_{H}^{*} &gt; -\\beta_{L}^{*}$ . Therefore the defender has an incentive to signal it is type  $H$  when it is truly type  $L$  and thus there is not a separating equilibrium when  $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$  and  $1 - \\pi_{1}c_{L} + \\pi_{2}v &lt; 0$\n\n- Case 2:  $1 - \\pi_1c_H + \\pi_2v &gt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender were to signal its true capability, the attacker would attack with probability  $\\beta_k^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_k + (1 - \\pi_2)w}$  where  $k$  is either  $H$  or  $L$  depending on the defenders signal. The defender of type  $k$  has an expected utility of  $\\beta_k^*(r - 1) - (1 - \\beta_k^*)w = \\beta_k^*(r_k - 1 + w) - w$ . If  $(r_H - 1 + w) &gt; 0$ , then the defender's utility is increasing in the attack probability. Therefore when the defender is type  $H$  it would prefer that the attacker attack with a higher probability thus would signal that it is type  $L$  and induce the attacker to attack with probability  $\\beta_l^* &gt; \\beta_H^*$ . Therefore, there cannot be a separating equilibrium if  $(r_H - 1 + w) &gt; 0$ . Now suppose  $(r_H - 1 + w) \\leq 0$ . Then it must be the case that  $(r_L - 1 + w) &lt; 0$ , which implies that when the defender is type  $L$ , its expected utility is decreasing in the attack probability. This means that when the defender is truly type  $L$  it would prefer to signal that it was type  $H$  so that the attacker randomizes with probability  $\\beta_H^* &lt; \\beta_L^*$ . As a result, there cannot be a separating equilibrium when  $(r_H - 1 + w) \\leq 0$ .\n\n- Case 3:  $1 - \\pi_1c_H + \\pi_2v &lt; 0$  and  $1 - \\pi_1c_L + \\pi_2v &gt; 0$  In this regime, if the defender is type  $H$  and signals such, the attacker randomizes with probability  $\\beta_H^* = \\frac{\\pi_2w}{\\pi_1r_H + \\pi_2w}$  and the defender's expected utility when it is type  $H$  is  $-\\beta_H^*$ . If the defender is type  $L$  and it signals such, the attacker randomizes with probability  $\\beta_L^* = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$  and the defender earns an expected utility of  $\\beta_L*(\\pi_1r_L + \\pi_2w - 1) - \\pi_2w$  (which by indifference is the same as  $\\beta_L^*(r_L - 1 + w) - w$ ). Since  $\\pi_1 &gt; \\pi_2$  and  $r_H &gt; r_L$ , it can be shown that  $\\beta_L^* &gt; \\beta_H^*$ . Consider the defender's deviation of signaling that it is type  $L$  when it is actually type  $H$  and changing its strategy to retaliating after  $o_1$  and not retaliating after  $o_2$ . In this case, the defender's utility is given by:\n\n$$\nU _ {d} ((R, D R), \\beta_ {L} ^ {*}) = \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\tag {A.5}\n$$\n\nwhere  $U_{d}((A,B),C)$  is the defender's expected utility from playing  $A$  after  $o_1$  and  $B$  after  $o_2$  when the attacker randomizes with probability  $C$ . For this deviation to not be profitable for the defender it must be that:\n\n$$\n\\begin{array}{l}\nU _ {d} ((D R, D R), \\beta_ {H} ^ {*}) \\\\\n\\geq U _ {d} ((R, D R), \\beta_ {L} ^ {*}) \\\\\n- \\beta_ {H} ^ {*} \\geq \\pi_ {1} \\beta_ {L} ^ {*} (r _ {H} - 1) - (1 - \\pi_ {1}) \\beta_ {L} ^ {*} - (1 - \\beta_ {L} ^ {*}) \\pi_ {2} v \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\pi_ {2} w + \\beta_ {L} \\pi_ {2} w \\\\\n- \\beta_ {H} ^ {*} \\geq \\beta_ {L} ^ {*} \\pi_ {1} r _ {H} - \\beta_ {L} ^ {*} - \\beta_ {H} ^ {*} (\\pi_ {1} r _ {H} + \\pi_ {2} w) + \\beta_ {L} \\pi_ {2} w \\\\\n\\beta_ {H} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right) \\\\\n\\geq \\beta_ {L} ^ {*} \\left(\\pi_ {2} w + \\pi_ {1} r _ {H} - 1\\right). \\tag {A.6}\n\\end{array}\n$$\n\nSince  $\\beta_H^* &lt; \\beta_1^*$  the inequality in Eq. (A.6) only holds if  $\\pi_2w + \\pi_1r_H - 1 \\leq 0$ . So if  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ , then the deviation is profitable and there is no incentive for the defender to truthfully signal its type. What remains to be shown is that the defender does not have an incentive to truthfully signal its type when  $\\pi_2w + \\pi_1r_H - 1 &gt; 0$ . To do this, consider the defender's deviation of signaling it is type  $H$  when it is ac",
    "ARTICLE IN PRESS\n\nJ. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\ntually type $L$ and retaliating after $o_1$ and not retaliating after $o_2$. Under this deviation, the defender's expected utility is\n\n$$\nU _ {d} \\left(\\left(R, D R\\right), \\beta_ {H} ^ {*}\\right) = \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} + \\pi_ {2} w - 1\\right) - \\pi_ {2} w \\tag {A.7}\n$$\n\nFor this deviation to not be profitable for the defender it must be that:\n\n$$\n\\begin{array}{l} U _ {d} ((R, R), \\beta_ {L} ^ {*}) \\geq U _ {d} ((R, R), \\beta_ {H} ^ {*}) \\\\ \\beta_ {L} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w \\\\ \\geq \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {L} - 1 + \\pi_ {2} w\\right) - \\pi_ {2} w. \\tag {A.8} \\\\ \\end{array}\n$$\n\nSince $\\beta_{L}^{*} &gt; \\beta_{H}^{*}$, the only way for the inequality in Eq. (A.8) to hold is if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$. However, if $\\pi_1r_L - 1 + \\pi_2w\\geq 0$ then $\\pi_1r_H - 1 + \\pi_2w\\geq 0$ since $r_H &gt; r_L$. But from the first part of case 3, if $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, then the defender would have an incentive to deviate when it is type $L$. Therefore, when $\\pi_1r_H - 1 + \\pi_2w\\geq 0$, the defender has an incentive to deviate from truthful signaling and when $\\pi_1r_H - 1 + \\pi_2w\\leq 0$, the defender has an incentive to deviate from truthful signaling. Ignoring the measure 0 case where $\\pi_1r_H - 1 + \\pi_2w = 0$, the defender always has an incentive to deviate from truthful signaling.\n\nAll three cases cover all possible parameter values and illustrate the for all values of the parameters, there is always a profitable deviation from truthful signaling for the defender and thus there is no separating equilibrium. $\\square$\n\n- **Proof of Proposition 3.** In this case, if the attacker knows the defender is type $L$, then it is always a best response for the attacker to attack. As a result, it is always the defender's best response to retaliate when it truthfully signals it is type $L$. To show this cannot be an equilibrium, consider the following two cases.:\n\n- **Case 1:** Suppose $\\pi_1r_H + \\pi_2w - 1 &gt; 0$. Under a separating equilibrium, when the defender signals it is type $L$, the attacker attacks with probability 1. Also, when the defender is type $H$ and truthfully signals its type, its expected utility is $-\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v \\leq 0$ and $\\beta_H(r_H + w - 1) - w$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Consider each of the two cases separately:\n\n* Suppose $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Since by assumption $\\pi_1r_H + \\pi_2w - 1 &gt; 0$, then $r_H + w - 1 &gt; 0$ and thus the attacker's expected utility is increasing in $\\beta_H$ when $1 - \\pi_1c_H + \\pi_2v &gt; 0$. Therefore, if $1 - \\pi_1c_H + \\pi_2v &gt; 0$ and the defender is type $H$, it would be better off signaling it is type $L$ and thus there cannot be a separating equilibrium in which it truthfully signals its type.\n\n* Suppose $1 - \\pi_1c_H + \\pi_2v &lt; 0$. Then when the defender is type $H$ and truthfully signals its type, it's expected utility is $-\\beta_H^* = \\frac{-\\pi_2w}{\\pi_1r_H - \\pi_2w}$. If it were to instead switch its strategy by signaling that it is type $L$ and always retaliating, it's expected utility is $r_H - 1$. For the defender to not have an incentive to make this switch it must be that:\n\n$$\n\\begin{array}{l} \\frac {- \\pi_ {2} w}{\\pi_ {1} r _ {H} - \\pi_ {2} w} \\geq r _ {H} - 1 \\\\ \\rightarrow 0 \\geq r _ {H} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} w - \\pi_ {1}\\right) \\tag {A.9} \\\\ \\end{array}\n$$\n\nHowever by assumption, $\\pi_1r_H + \\pi_2w - 1 &gt; 0$ so it is impossible for the inequality in Eq. (A.9) to hold and this there cannot be a separating equilibrium.\n\n- **Case 2:** Suppose $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. Again, there are two sub-cases:\n\n* Suppose $r_{L} + w - 1 &lt; 0$. The defender's expected utility by truthfully signaling when it is type $L$ is $r_{L} - 1$. If instead it signaled it was type $H$ and always retaliated, its expected utility would be $\\beta_{H}^{*}(r_{L} + w - 1) - w$. For it to\n\nnot gain anything from such a deviation it must be:\n\n$$\n\\begin{array}{l} r _ {L} - 1 \\geq \\beta_ {H} ^ {*} \\left(r _ {L} + w - 1\\right) - w \\\\ \\rightarrow 1 \\leq \\beta_ {H} ^ {*} \\tag {A.10} \\\\ \\end{array}\n$$\n\nSince $\\beta_{H}^{*}$ is a probability less than 1, the inequality in Eq. (A.10) cannot hold and therefore there cannot be a separating equilibrium.\n\n* Suppose $r_{L} + w - 1 &gt; 0$. If the defender signals that it is type $L$ when it is type $H$ and always retaliates, it will earn $r_{H} - 1$. If it signals it is type $L$ when it is truly type $L$, it earns $r_{L} - 1$. If $1 - \\pi_{1}c_{H} + \\pi_{2}v &lt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$. Two possible deviations the defender can make is 1) when $L$ signal that it is type $H$ and never retaliate and 2) when $H$ signal that it is type $L$ and always retaliate. For neither of these deviations to be profitable it must be:\n\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\\\ r _ {L} - 1 &gt; \\beta_ {H} ^ {*} \\\\ \\end{array}\n$$\n\nSince $r_{H} &gt; r_{L}$, it is impossible for both conditions to hold simultaneously. Finally, if $1 - \\pi_{1}c_{H} + \\pi_{2}v &gt; 0$, then when the defender signals it is type $H$, the attacker attacks with probability $-\\beta_{H}^{*} = \\frac{-\\pi_{2}w}{\\pi_{1}r_{H} - \\pi_{2}w}$ and the defender earns an expected utility of $\\beta_{H}^{*}(\\pi_{1}r_{H} + \\pi_{2}v - 1) - w$. If instead, the defender signaled it was type $L$ when it is type $H$, and always retaliate it would earn $r_{H} - 1$. For there to be no incentive for the defender to deviate it must be that:\n\n$$\n\\begin{array}{l} r _ {H} - 1 &lt;   \\beta_ {H} ^ {*} \\left(\\pi_ {1} r _ {H} + \\pi_ {2} v - 1\\right) - w \\\\ \\rightarrow \\frac {r _ {H} - 1 + w}{\\pi_ {1} r _ {H} + \\pi_ {2} v - 1} &gt; \\beta_ {H} ^ {*} \\tag {A.11} \\\\ \\end{array}\n$$\n\nSince by assumption $r_{H} - 1 + w &gt; 0 &gt; \\pi_{1}r_{H} + \\pi_{2}v - 1$, the left hand side of Eq. (A.11) is negative. Since $\\beta_{H}^{*}$ is a proper probability, such an equality can never be satisfied and thus the defender would have an incentive to deviate.\n\n- **Proof of proposition 4.** First, recall the equilibrium probabilities from the attribution game and label them as:\n\n$$\n\\begin{array}{l} \\beta_ {H 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {H} + \\pi_ {2} w} \\\\ \\beta_ {H 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {H} + (1 - \\pi_ {2}) w} \\\\ \\beta_ {L 1} = \\frac {\\pi_ {2} w}{\\pi_ {1} r _ {L} + \\pi_ {2} w} \\\\ \\beta_ {L 2} = \\frac {(1 - \\pi_ {2}) w}{(1 - \\pi_ {1}) r _ {L} + (1 - \\pi_ {2}) w} \\tag {A.12} \\\\ \\end{array}\n$$\n\nSince $\\pi_1 &gt; \\pi_2$ and $r_H &gt; r_L$, it can be shown that $\\beta_{H1} &lt; \\beta_{L1} &lt; \\beta_{H2} &lt; \\beta_{L2}$. By the same argument as in the attribution game, any equilibrium must have $\\beta_{H1} &lt; \\beta_H &lt; \\beta_{L2}$ and $\\beta_{H1} &lt; \\beta_L &lt; \\beta_{L2}$. The reason is that if any of the attacker's randomization probabilities are outside these bounds, the defender's best response, regardless of its type, is to either always retaliate or never retaliate, which cannot be part of an equilibrium (because then the attacker would no longer be willing to randomize). Given this fact, we will now prove each claim in the proposition.\n\n- **Proof of Part 1:** Under the strategy profile described in part 1, Bayes rule dictates that when the attacker receives signal $s_H$, it knows with probability 1 that the defender is type $H$. Therefore, when the attacker receives signal $s_H$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_H = \\beta_{H1}$ or $\\beta_H = \\beta_{H2}$.",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\ndepending on the sign of $1 - \\pi_1c_H + \\pi_2v$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n\n* Suppose $\\beta_{H} = \\beta_{H2}$. When the defender signals $s_H$, it is indifferent between retaliating after $o_1$ only and always retaliating. Thus, it's expected utility is $\\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{H}(r_{H} + w - 1) - w$. Let $\\beta_{L}$ be the probability the attacker attacks when it receives signal $s_L$.\n\n- Suppose $\\beta_{L} &lt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, then when the defender of type $H$ signals $s_{L}$ and only attacks after $o_{1}$, it earns $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is strictly greater than its expected utility from signaling $s_{H}$ because $\\beta_{L} &lt; \\beta_{H}$ and $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$ by assumption. Therefore, the attacker would not be willing to randomize between signals when it is type $H$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the attacker would not be willing to signal $s_{L}$ and only attack after $o_{1}$ because $\\beta_{L} &lt; \\beta_{H}$, and the payoff for only attacking after $o_{1}$ is increasing in $\\beta$. Therefore, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if $\\beta_{L}$ is such that the defender's best response is to never retaliates after signaling $s_{L}$. This condition is given by\n\n$$\n\\begin{array}{l}\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n- \\beta_{L} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) \\\\\n- \\beta_{H1} \\left(\\pi_{1} r_{H} + \\pi_{2} w\\right) \\\\\n\\end{array}\n$$\n\n$$\n\\frac{\\beta_{H} - \\beta_{L}}{\\beta_{H} - \\beta_{H1}} = \\pi_{1} r_{H} + \\pi_{2} w \\tag{A.13}\n$$\n\nFor the condition in Eq. (A.13) to hold, it must be that $\\beta_{L} &lt; \\beta_{H1}$ since by assumption $\\pi_1r_H + \\pi_2w &gt; 1$. However, by the argument above, there is no equilibrium in which the attacker randomizes with a probability $\\beta_{L} &lt; \\beta_{H1}$ so there cannot be an equilibrium with $\\beta_{L} &lt; \\beta_{H}$.\n\n- Suppose $\\beta_{L} &gt; \\beta_{H}$. This means that when the defender of type $H$ signals $s_{L}$ and the attacker randomizes with probability $\\beta_{L}$, the defender's best response is to always retaliate. This implies that for all values of $\\beta$ such that $\\beta_{H} &lt; \\beta &lt; \\beta_{L}$, the defender's expected utility is either strictly increasing or strictly decreasing in $\\beta$, depending on the sign of $r_{H} + w - 1$. Due to strict monotonicity of the defender's utility with respect to $\\beta$, it cannot be indifferent between signaling $\\beta_{H}$ and $\\beta_{L}$.\n\nSince there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$ and $\\beta_{L} &lt; \\beta_{H}$ or $\\beta_{L} &gt; \\beta_{H}$, there cannot be an equilibrium with $\\beta_{H} = \\beta_{H2}$.\n\n* Suppose $\\beta_{H} = \\beta_{H1}$. In this case, the defender of type $H$ is indifferent between never retaliating and retaliating after $o_1$ only and earns an expected utility of $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$. By the argument above $\\beta_{L}$ cannot be less than $\\beta H1$. Therefore, suppose $\\beta_{L} &gt; \\beta_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$, then the defender's expected utility of signaling $s_{L}$ and only retaliating after $o_1$ is $\\beta_{L}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than it's expected utility of after signaling $s_{H}$. Therefore, the defender of type $H$ would not be willing to randomize between signaling $s_{L}$ and $s_{H}$. If $\\pi_{1}r_{H} + \\pi_{2}w - 1 &lt; 0$, the only way the defender can be indifferent between signaling $s_{H}$ and $s_{L}$ is if it always retaliates after signaling $s_{L}$. This implies\n\n$$\n- \\beta_{H} = \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w = \\beta_{L} \\left(r_{H} + w - 1\\right) \\tag{A.14}\n$$\n\nwhere the first equality comes from the fact that at $\\beta_{H1}$ the attacker must be indifferent between never retaliating and retaliating after $o_1$ only. Now consider a defender of type $L$ that always signals it is type $L$. In this case, it's utility is either $-\\beta_{L}$, $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ or $\\beta_{L}(r_{L} + v - 1)$, depending on which of its strategies are optimal at $\\beta_{L}$. If a defender of type $L$ instead signaled $s_H$ and never retaliated, its expected utility would be $-\\beta_{H} = \\beta_{H}(\\pi_{1}r_{H} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{H} + v - 1)$. The following inequalities show that this regardless of which one of the defender's strategies is optimal at $\\beta_{L}$, there exists a profitable deviation where the defender of type $L$ signals $s_H$ and never retaliates:\n\n$$\n\\begin{array}{l}\n- \\beta_{L} &lt; -\\beta_{H} \\text{ (By assumption)} \\\\\n\\beta_{L} \\left(r_{L} + w - 1\\right) - w &lt; \\beta_{L} \\left(r_{H} + w - 1\\right) \\\\\n\\text{ (Because } r_{H} &gt; r_{L} \\text{)} \\\\\n\\beta_{L} \\left(\\pi_{1} r_{L} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n&lt; \\beta_{H} \\left(\\pi_{1} r_{H} + \\pi_{2} w - 1\\right) - \\pi_{2} w \\\\\n\\end{array}\n$$\n\nThe last line follows because $r_H &gt; r_L$ and $\\pi_1r_H + \\pi_2w - 1 &lt; 0$. This shows that there cannot be a PBE where $\\beta_H = \\beta_{H1}$.\n\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{H1}$ or $\\beta_{H2}$ after observing $s_H$, there cannot be a PBE where a defender of type $L$ always signals $s_L$ and a defender of type $H$ randomizes between signaling $s_L$ and $s_H$.\n\n- Proof of Part 2: Under the strategy profile described in part 2, Bayes rule dictates that when the attacker receives signal $s_L$, it knows with probability 1 that the defender is type $L$. Therefore, when the attacker receives signal $s_L$, any equilibrium must have the players play the attribution game and the attacker attacks with probability $\\beta_L = \\beta_{L1}$ or $\\beta_L = \\beta_{L2}$, depending on the sign of $1 - \\pi_1c_L + \\pi_2w$. For the defender to be willing to randomize between signaling $s_L$ and $s_H$, it must be indifferent between sending the two signals. We examine the cases separately.\n\n* Suppose $\\beta_{L} = \\beta_{L2}$. In this case, the defender of type $L$ is indifferent between retaliating after $o_1$ only and always retaliating and earns $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w = \\beta_{L}(r_{L} + w - 1) - w$. There cannot be an equilibrium where $\\beta_{H} &gt; \\beta_{L}$ because then the defender's best response would be to always retaliate regardless of its type. Therefore, it is sufficient to only consider the case where $\\beta_{H} &lt; \\beta_{L}$. If $\\pi_{1}r_{L} + \\pi_{2}w - 1 &lt; 0$, then the defender of type $L$ has a profitable deviation to signal it is type $H$ and only retaliate after $o_1$ and earn $\\beta_{H}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$ which is greater than $\\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Now suppose $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$. Since there is no equilibrium where the attacker ever randomizes with a probability $\\beta &lt; \\beta_{H1}$ it must be that $\\beta_{H1} &lt; \\beta_{H} &lt; \\beta_{L}$. This means that the attacker's best response at $\\beta_{H}$ is either to retaliate after $o_1$ only or always retaliates. However, since $\\pi_{1}r_{L} + \\pi_{2}w - 1 &gt; 0$ then $\\pi_{1}r_{H} + \\pi_{2}w - 1 &gt; 0$ and $r_{H} + \\pi_{2}w - 1 &gt; 0$ which means that the expected utility of the defender of type $H$ is increasing in $\\beta$ and thus a defender of type $H$ would prefer to signal $s_L$. Consequently, there cannot be an equilibrium where $\\beta_{L} = \\beta_{L2}$.\n\n* Suppose $\\beta_{L} = \\beta_{L1}$. In this case, a defender of type $L$ is indifferent between never retaliating and retaliating after $o_1$ only and earns $-\\beta_{L} = \\beta_{L}(\\pi_{1}r_{L} + \\pi_{2}w - 1) - \\pi_{2}w$. Suppose $\\beta_{H} &lt; \\beta_{L}$, then there defender of type $L$ would not be willing to randomize between $s_{L}$ and $s_{H}$ because it can signal $s_{H}$, never retaliate and earn $\\beta_{H}$, which is greater than its expected utility of $-\\beta_{L}$ by signal-",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\ning $s_L$. Now suppose $\\beta_H &gt; \\beta_L$. If $\\pi_1 r_L + \\pi_2 w - 1 &gt; 0$, the defender of type $L$ can earn $\\beta_H (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_H$ and only retaliates after $o_1$. Since this is higher than its maximum expected utility of $\\beta_L (\\pi_1 r_L + \\pi_2 w - 1) - \\pi_2 w$ when it signals $s_L$, a defender of type $L$ would not be willing to randomize its signals. Lastly, if $\\pi_1 r_L + \\pi_2 w - 1 &lt; 0$, the defender can only be indifferent between signaling $s_H$ and $s_L$ if its best response is to always retaliate when it is type $L$ and signals $s_H$ (because its expected utility of only retaliating after $o_1$ is strictly monotonic in $\\beta$). However, if the defender's of type $L$'s best response to an attacker randomizing with probability $\\beta_H$ is to always retaliate, it is also a defender of type $H$'s best response to always retaliate. Since the defender always retaliating after a signal cannot be part of an equilibrium, there cannot be an equilibrium where $\\beta_H &gt; \\beta_L$.\n\nSince there cannot be an equilibrium where the attacker randomizes with either $\\beta_{L1}$ or $\\beta_{L2}$ after observing $s_L$, there cannot be an equilibrium where a defender of type $H$ always signals $s_H$ and a defender of type $L$ randomizes between signaling $s_L$ and $s_H$.\n\n- Proof of Proposition 5. We prove necessity. Sufficiency is trivial since if any the conditions 1–6 are not satisfied, then the players' equilibrium randomization probabilities are not proper probabilities. The proof of uniqueness follows.\n\nBegin by considering the attacker. If the attacker receives signal $s_L$, then Bayes rules necessitate it knows the defender is type $L$ and thus the attacker and defender play the attribution game. As proposition 1 shows, there is an equilibrium in the attribution game where the attacker randomizes with probability $\\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and the defender retaliates with probability $\\frac{1}{\\pi_1 r_L - \\pi_2 v}$, which by assumption 2 is a proper probability. Now consider the attacker that receives signal $s_H$. For it to be willing to randomize, it must be indifferent between attacking and not attacking. Assuming the defender retaliates regardless of its type, this condition is given by:\n\n$$\n\\begin{array}{l}\nP(H|s_H)(1 - c_H) + P(L|s_H)(1 - c_L) = -v \\\\\n\\frac{P(s_H|H)P(H)(1 - c_H)}{P(s_H|H)P(H) + P(s_H|L)P(L)} \\\\\n+ \\frac{P(s_H|L)P(L)(1 - c_L)}{P(s_H|H)P(H) + P(s_H|L)P(L)} = -v \\\\\n\\frac{\\gamma(1 - c_H)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} \\\\\n+ \\frac{\\gamma(1 - c_L)P(s_H|L)}{\\gamma(1 - c_H) + (1 - \\gamma)P(s_H|L)} = -v \\\\\nP(s_H|L) = \\frac{\\gamma}{(1 - \\gamma)} \\frac{1 - c_H + v}{c_L - v - 1} \\tag{A.15}\n\\end{array}\n$$\n\nBy assumption, $1 - c_H + v$ and $c_L - v - 1$ are both less than 0, so the second fraction in Eq. (A.15) is positive. By assumption, 5, the entire right hand side of Eq. (A.15) is less than 1 and thus a proper probability.\n\nNow consider the defender. To begin, consider a defender of type $L$. A necessary condition for the defender of type $L$ to be willing to randomize between signaling (1) $s_L$ and earning a payoff of $\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$ and randomizing between never retaliating and retaliating after $o_1$ only and (2) $s_H$, inducing the attacker to attack with probability $\\beta_H$, and always retaliating, it must be indifferent between the two signals. This implies\n\n$$\n\\frac{-\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w\n$$\n\n$$\n\\beta_H = \\frac{w(\\pi_1 r_L + \\pi_2 w - \\pi_2)}{(r_L + w - 1)(\\pi_1 r_L + \\pi_2 w)} \\tag{A.16}\n$$\n\nSince, $\\pi_1 r_L + \\pi_2 w &lt; 1$ by assumption, the defender's expected utility from retaliating after $o_1$ only is decreasing in $\\beta$ and thus, the defender's best response at $\\beta_H$ is to always retaliate. Therefore, the defender of type $L$ is indifferent between signaling $s_H$ and $s_L$. Finally, consider the defender of type $H$. When the attacker randomizes with probability $\\beta_H$, because it is a defender's of type $L$ best response to always retaliate, it must also be a defender of type $H$'s best response to always retaliate. The defender's payoff from always retaliating is $\\beta_H(r_H + w - 1) - w = -\\beta_L + \\beta_H(r_H - r_L)$. What remains to be shown is that a defender of type $H$ does not have an incentive to signal $s_L$. If the defender signals $s_L$ and always retaliates, its payoff must be less than if it signals $s_H$ because its payoff to always retaliating is increasing in $\\beta$. It's payoff by signaling $s_L$ and never retaliating is $\\frac{-\\pi_2 w}{\\beta_{L} r_L + \\pi_2 w} = \\beta_H(r_L + w - 1) - w &lt; \\beta_H(r_H + w - 1) - w$. Finally, it's payoff of signaling $s_L$ and retaliating after $o_1$ only is $\\beta_L(\\pi_1 (r_H - r_L) - 1)$ which is strictly less than $-\\beta_L + \\beta_H(r_H - r_L)$. Therefore, the defender does not have an incentive to change its strategy.\n\nNo other semi-separating equilibrium. First, we will show that there is no equilibrium in which the defender randomizes its signal for each of its types. Then we will show there is no equilibrium in which the defender randomizes only when it is type $H$.\n\nFor contractiction, suppose there is a signaling equilibrium where the defender randomizes its signal for each of its types and induces the attacker to randomize with probability $\\beta_H$ and $\\beta_L$ and without loss of generality, assume $\\beta_H &gt; \\beta_L$. There is no equilibrium where $\\beta_L$ is so low that the attacker of type $H$ would never retaliate. Therefore, the defender of type $H$ must be indifferent between retaliating after $o_1$ only and always retaliating. This implies\n\n$$\n\\beta_L(\\pi_1 r_H + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_H + w - 1) - w \\tag{A.17}\n$$\n\nof course, this can only happen when $(\\pi_1 r_H + \\pi_2 w - 1) &lt; 0$ and $(r_H + w - 1)$. For a defender of type $L$ to be indifferent, there are two cases.\n\n- Consider the case where the defender of type $L$ is indifferent between retaliating only after $o_1$ when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $\\beta_H$. This implies\n\n$$\n\\beta_L(\\pi_1 r_L + \\pi_2 w - 1) = \\pi_2 w = \\beta_H(r_L + w - 1) - w \\tag{A.18}\n$$\n\nHowever, solving for Eqs. (A.17) and (A.18) yields $\\beta_H = \\pi_1 \\beta_L$ which violates the fact that $\\beta_H &gt; \\beta_L$.\n\n- Consider the case where the defender of type $L$ is indifferent between never retaliating when the attacker attacks with probability $\\beta_L$ and always retaliating when the attacker attacks with probability $beta_H$. This implies\n\n$$\n\\beta_L = \\beta_H(r_L + w - 1) - w \\tag{A.19}\n$$\n\nEqs. (A.17) and (A.19) together imply that\n\n$$\n\\beta_L = \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w} + (r_H - r_L)(\\beta_H - \\pi_1 \\beta_L) \\tag{A.20}\n$$\n\nHowever, the solution to Eq. (A.20) yields a value of $\\beta_L &gt; \\frac{\\pi_2 w}{\\pi_1 r_L + \\pi_2 w}$, which cannot be part of an equilibrium because at such a value of $\\beta_L$, the defender would prefer to retaliate after $o_1$.\n\nNow consider the semi-separating strategy where the defender randomizes its signal when it is type $H$ and always signals $s_L$ when it is type $L$. If the attacker randomizes its signal when it is type $H$, then Bayes rule will dictate that when the attacker receives signal",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\n$s_H$ , it knows the attacker is type  $H$  with certainty; Let  $\\beta_H$  be the attacker's randomization probability when it receives signal  $s_H$ . Since the attacker knows the defender's type when the defender signals  $s_H$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_H = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_H + (1 - \\pi_2)w}$ . We consider these cases separately.\n\n- Suppose  $\\beta_{H} = \\frac{\\pi_{2}w}{\\pi_{1}r_{L} + \\pi_{2}w}$  where the defender of type  $H$  is indifferent between never retaliating and retaliating after  $o_1$  only. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and always retaliating. However, at such a  $\\beta_{L}$ , the defender of type  $L$ 's expected utility for any of its strategies is strictly less than its expected utility from signaling  $s_H$  and never retaliating, therefore, the defender would never be willing to signal  $s_L$ .\n- Suppose  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$  where the defender of type  $H$  is indifferent between retaliating after  $o_1$  only and always retaliating. For the defender of type  $H$  to be willing to randomize its signal, it must be that the defender is indifferent between signaling  $s_H$  and signaling  $s_L$ , inducing the attacker to attack with probability  $\\beta_{L}$  and never retaliating. However, at such a value of  $\\beta_{L}$ , the defender of type  $H$  or type  $L$  would never retaliate and thus the attacker would not be willing to randomize but instead would attack with probability 1. Therefore, there can not be an equilibrium in which  $\\beta_{H} = \\frac{(1 - \\pi_{2})w}{(1 - \\pi_{1})r_{H} + (1 - \\pi_{2})w}$ .\n\nFinally consider the semi-separating strategy where the defender randomizes its signal when it is type  $L$  and always signals  $s_H$  when it is type  $H$ . If the attacker randomizes its signal when it is type  $L$ , then Bayes rule will dictate that when the attacker receives signal  $s_L$ , it knows the attacker is type  $L$  with certainty. Let  $\\beta_L$  be the attacker's randomization probability when it receives signal  $s_L$ . Since the attacker knows the defender's type when the defender signals  $s_L$ , the players play the attribution game and therefore the attacker either randomizes with  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  or  $\\beta_H = \\frac{(1 - \\pi_2)w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . Our main proposition showed that there can be an equilibrium when  $\\beta_L = \\frac{\\pi_2w}{\\pi_1r_L + \\pi_2w}$  so here, we consider the case where  $\\beta_L = \\frac{(\\pi_2 - )w}{(1 - \\pi_1)r_L + (1 - \\pi_2)w}$ . The only way the defender can be indifferent between the attacker attacking with probability  $\\beta_L$  and  $\\beta_H$  is if  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$  and the defender of type  $L$  never retaliates at  $\\beta_H &lt; \\beta_L$ . However, since  $\\pi_1r_L + \\pi_2w - 1 &gt; 0$ , the attacker of type  $H$ 's expected utility is increasing in  $\\beta$  and therefore would prefer to signal  $s_L$  and not  $s_H$ .\n\nAll of the cases show that there are no other semi-separating equilibria.  $\\square$\n\n# Proof of Proposition 6. Define the parameters as follows.\n\nIn this parameter regime, the conditions in proposition 5 are satisfied and thus the semi-separating equilibrium exists. At this equilibrium, the attacker attacks with probability .715 (LHS of condition 2) and the defender's expected utility before realizing its type is -.298 (RHS of condition 3). At these parameter values, the equilibrium in row 2 of Table 3 also exists, which implies condition 1 is met. At this equilibrium, the attacker attacks with probability .772 (RHS of condition 2) and the defender earns an expected utility of -.36 (LHS of condition 3). Since .715 &lt; 772 and -.298 &gt; -.36, all three conditions are satisfied and thus there exists an equilibrium where there is defender improves over a pooling equilibrium through deterrence. Furthermore, since the inequalities define open sets and satisfying all inequalities is equivalent to the intersection of open sets, if a solution to the inequalities exist, then\n\nTable A4 Parameter values where there are gains from signaling through deterrence.\n\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .8  |\n|  π2 | .45  |\n|  cH | 4  |\n|  cL | 3  |\n|  v | 2.6  |\n|  γ | .4  |\n|  rH | .9  |\n|  rL | .65  |\n|  w | .8  |\n\nthe set of parameters that satisfy the inequalities is open and thus has positive measure.  $\\square$\n\n# Proof of Proposition 7. Define the parameters as follows.\n\nIn this parameter regime, the semi-separating equilibrium exists and the attacker attacks with probability .729 and the defender earns an expected payoff of -.249. At those parameter values, the equilibrium in row 1 of Table 3 also exists. This equilibrium is\n\nTable A5 Parameter values where there are gains from signaling through deterrence.\n\n|  Parameter | Value  |\n| --- | --- |\n|  π1 | .95  |\n|  π2 | .5  |\n|  cH | 5  |\n|  cL | 3  |\n|  v | 3  |\n|  γ | .32  |\n|  rH | .9  |\n|  rL | .7  |\n|  w | .6  |\n\nthe pooling equilibrium in which the attacker randomizes its attack with the lowest probability. At that pooling equilibrium, the attacker attacks with probability .260 and the defender's expected payoff is -.260. These satisfy conditions 1-3 and by the same argument in the proof of proposition 6, the set of parameters has positive measure.  $\\square$\n\n# References\n\n115th Congress (2018). H.R.5515 - John S. McCain National Defense Authorization Act for Fiscal Year 2019. Technical Report.\nBaliga, S., De Mesquita, E. B., &amp; Wolitzky, A. (2020). Deterrence with imperfect attribution. American Political Science Review, 114(4), 1155-1178.\nBendiek, A., &amp; Metzger, T. (2015). Deterrence theory in the cyber-century. INFOR-MATIK 2015.\nCheung, K.-F., &amp; Bell, M. G. (2021). Attacker-defender model against quantal response adversaries for cyber security in logistics management: An introductory study. European Journal of Operational Research, 291(2), 471-481. https://doi.org/10.1016/j.ejor.2019.10.019.\nDefense Science Board (2017). Task force on cyber deterrence. Technical Report.\nEdwards, B., Furnas, A., Forrest, S., &amp; Axelrod, R. (2017). Strategic aspects of cyberattack, attribution, and blame. Proceedings of the National Academy of Sciences, 114(11), 2825-2830.\nGoodman, W. (2010). Cyber deterrence: Tougher in theory than in practice? Technical Report. SENATE (UNITED STATES) WASHINGTON DC COMMITTEE ON ARMED SERVICES.\nHarris, S. (2017). China reveals its cyberwar secrets. https://www.thedailybeast.com/china-reveals-its-cyberwar-secrets.\nIasiello, E. (2014). Is cyber deterrence an illusory course of action? Journal of Strategic Security, 7(1), 54-67.\nJensen, E. T. (2012). Cyber deterrence. Emory International Law Review, 26, 773.\nJohnson, J. C., Leeds, B. A., &amp; Wu, A. (2015). Capability, credibility, and extended general deterrence. International Interactions, 41(2), 309-336.\nKamenica, E., &amp; Gentzkow, M. (2011). Bayesian persuasion. American Economic Review, 101(6), 2590-2615.\nKonrad, K. A. (2020). Attacking and defending multiple valuable secrets in a big data world. European Journal of Operational Research, 280(3), 1122-1129. https://doi.org/10.1016/j.ejor.2019.07.064.",
    "J. Welburn, J. Grana and K. Schwindt\n\nEuropean Journal of Operational Research 306 (2023) 1399-1416\n\nLevitin, G., &amp; Hausken, K. (2009). False targets efficiency in defense strategy. European Journal of Operational Research, 194(1), 155-162.\nLiang, L., Chen, J., &amp; Siqueira, K. (2020). Revenge or continued attack and defense in defender-attacker conflicts. European Journal of Operational Research, 287(3), 1180-1190. https://doi.org/10.1016/j.ejor.2020.05.026.\nLibicki, M. C. (2009). Cyberdeterrence and cyberwar. Rand Corporation.\nLynch, M. (2002). Why engage? china and the logic of communicative engagement. European Journal of International Relations, 8(2), 187-230.\nMorgan, P. M. (2003). Deterrence now: vol. 89. Cambridge University Press.\nParly, M. F. (2019). Stratgie cyber des armes.\nPowell, R. (1990). Nuclear deterrence theory: The search for credibility. Cambridge University Press.\nRiedel, B. (2007). Al Qaeda strikes back (pp. 24-40). Foreign Affairs.\nSaran, V. (2016). Media manipulation and psychological war in ukraine and the republic of MoldovaCentre for European Studies (CES) Working Papers, 8(4).\nSchelling, T. C. (1980). The strategy of conflict. Harvard university press.\n\nShakarian, P., Simari, G. I., Moores, G., &amp; Parsons, S. (2015). Cyber attribution: An argumentation-based approach. In *Cyber warfare* (pp. 151-171). Springer.\nSimon, J., &amp; Omar, A. (2020). Cybersecurity investments in the supply chain: Coordination and a strategic attacker. European Journal of Operational Research, 282(1), 161-171.\nSolak, S., &amp; Zhuo, Y. (2020). Optimal policies for information sharing in information system security. European Journal of Operational Research, 284(3), 934-950. https://doi.org/10.1016/j.ejor.2019.12.016.\nTaddeo, M. (2018). The limits of deterrence theory in cyberspace. Philosophy &amp; Technology, 31(3), 339-355.\nZhou, X., Huang, J., &amp; Cheng, G. (2015). Attacker-defender signaling game in multi-period based on technology accumulation and bayesian learning. In Proceedings of the 3rd international conference on machinery, materials and information technology applications. Atlantis Press.\nZhuang, J., Bier, V. M., &amp; Alagoz, O. (2010). Modeling secrecy and deception in a multiple-period attacker-defender signaling game. European Journal of Operational Research, 203(2), 409-418.\n\n1416"
  ],
  "metadata": {
    "title": "Cyber deterrence with imperfect attribution and unverifiable signaling",
    "subtitle": "$^{a}$ RAND Corporation, 1776 Main St. Santa Monica, CA 90401, USA",
    "document_type": "journal_article",
    "venue": "European Journal of Operational Research 306 (2023) 1399-1416",
    "publication_year": 2021,
    "authors": [],
    "affiliations": [
      "$^{b}$ Microsoft and Pardee RAND Graduate School, 1200 S. Hayes St. Arlington, VA 33303, USA"
    ],
    "emails": [],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "Motivated by the asymmetric information inherent to cyberwarfare, we examine a game of deterrence between an attacker and a defender in which the defender can signal its retaliatory capability but can only imperfectly attribute an attack. We show that there are equilibria in which the defender sends noisy signals to increase its expected payoff. In some equilibria, the defender can use signaling to deter an attacker and increase its payoff. In a different and somewhat counter-intuitive equilibrium, the defender can increase its expected payoff through signaling by luring the attacker to attack more. © 2022 Elsevier B.V. All rights reserved.",
    "keywords": [
      "Game theory"
    ],
    "publication_dates": {
      "received": "17 August 2021",
      "accepted": "12 July 2022",
      "online": "18 July 2022"
    },
    "identifiers": {
      "doi": [
        "10.1016/j.ejor.2022.07.021",
        "10.1016/j.ejor.2019.10.019",
        "10.1016/j.ejor.2019.07.064",
        "10.1016/j.ejor.2020.05.026",
        "10.1016/j.ejor.2019.12.016"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "www.elsevier.com/locate/ejor",
        "https://doi.org/10.1016/j.ejor.2022.07.021"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 27,
    "heading_count": 18,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_authors"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 12,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 1.0,
      "unique_index_count": 10
    },
    "footnotes_quality": {
      "intext_total": 1,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 1,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "author_year",
      "recommended_style": "unknown",
      "aligned": true,
      "signals": {
        "superscript_hits": 0,
        "superscript_definition_lines": 0,
        "numeric_bracket_hits": 3,
        "numeric_endnote_lines": 22,
        "author_year_hits": 8
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 57.0,
      "dominant_bib_coverage_rate": 0.17543859649122806,
      "dominant_link_target": "bibliography",
      "dominant_unresolved_flag": "unresolved_reference_links"
    },
    "heading_validation": {
      "heading_count": 18,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 6,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": false,
        "affiliations": true,
        "emails": false,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 0,
        "affiliations": 1,
        "emails": 0,
        "orcids": 0,
        "keywords": 1,
        "doi": 5,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 2
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_authors"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_authors"
      ]
    },
    "flags": [
      "low_bib_coverage",
      "footnotes_bucket_unresolved",
      "heading_numbering_parent_violation",
      "meta_missing_authors"
    ]
  },
  "citation_summary": {
    "style": "author_year",
    "dominant_bucket": "author_year",
    "dominant": {
      "intext_total": 12.0,
      "success_occurrences": 12.0,
      "success_unique": 10.0,
      "bib_unique_total": 57.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.17543859649122806,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "author_year"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 1.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 1.0,
        "missing_footnotes_for_seen_total": 1.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 0.0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0,
        "bib_coverage_rate": 0,
        "success_percentage": 0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "tex_superscript"
      },
      "numeric": {
        "intext_total": 6.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 12.0,
        "success_occurrences": 12.0,
        "success_unique": 10.0,
        "bib_unique_total": 57.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.17543859649122806,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:18:33.512947+00:00"
}