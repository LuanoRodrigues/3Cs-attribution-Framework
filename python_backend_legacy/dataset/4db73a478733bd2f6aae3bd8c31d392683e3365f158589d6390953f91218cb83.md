{
  "full_text": "International Studies Perspectives Advance Access published February 2, 2016\nInternational Studies Perspectives (2014) 0, 1-21\n# The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward¹\nAMIR LUPOVICI\nTel Aviv University\nMany scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and \"violence\" are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet\nThere is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic\n¹I am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082\n© The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nmeans that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a \"theoretical vacuum.\" More generally, Lindsay (2013:367) points out, \"Most work on international cyber security originates from the policy analysis community.\" Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace (Eriksson and Giacomello 2006; Dunn Cavelty 2008:7; Hansen and Nissenbaum 2009:1156).\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security (Saco 1999; Deibert 2002; Bendrath 2003; Yould 2003; Dunn Cavelty 2008, 2010, 2013; Hansen and Nissenbaum 2009; Deibert and Rohozinski 2010). However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence (Luke 1989; Williams 1992; Klein 1994; Tannenwald 2007; Adler 2009). This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of \"violence.\" Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\n2 As Dunn Cavelty argues, employing the concept of securitization is a notable exception to the tendency of cyber security studies to avoid integrating IR theories (Dunn Cavelty 2013:106).\n3 For example, scholars focus on the question of what the United States should do to enhance its deterrence posture in cyberspace, see Kramer (2009), Morgan (2010).\n4 See also Lupovici (2010).\nAMIR LUPOVICI\n3\nThe paper is structured as follows. The first section briefly reviews cyber deterrence scholarship and points to the advantages both of rethinking the term *cyber deterrence* and of using a constructivist approach to further theorize cyber deterrence scholarship. In the second section, and based on the suggested view of cyber deterrence, I will develop a constructivist approach that reveals the effects both of the “attribution problem” and of the social constructions of “violence” on deterrence failure and success. Finally, in the last section, I demonstrate the significance of these notions using the case of Stuxnet.\n## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges\nMost scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means (Wheatley and Hayes 1996:13, 19–20; Cordesman and Cordesman 2001:7; Kramer 2009:15–16; Kugler 2009:328; Morgan 2010:59, 68). However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger (Morgan 2003:15–20)⁶—are difficult to meet when facing a cyberwarfare threat (Morgan 2010; Stevens 2012:149–153). Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders (Harknett 1996; Molander, Riddle, and Wilson 1996:87; Berkowitz 1997:183–184; Cordesman and Cordesman 2001:7; Arquilla 2003:210–213; Libicki 2007:272, 2009:1–3, 26, 44–45; Morgan 2010:55–76).⁷ However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.\n## What Do We Mean When We Say Cyber Deterrence?\nThe meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” (Stevens 2012:149–152). These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\n⁵For a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\n⁶For a detailed review of this scholarship, see also Lupovici (2011).\n⁷Given these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nan acceptable cost” (Libicki 2009:27–35). Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.⁸\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures.⁹ Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional.¹⁰ In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.\n## Who Are the Deterring Actors?\nOne implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent¹¹ regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\n⁸Such discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats (Wheatley and Hayes 1996:v–vi, 5–6; Molander et al. 1996:81–92). In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation (Libicki 2009:23–25). Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” (Lindsay 2013:372).\n⁹To some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\n¹⁰The same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\n¹¹More fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).\nAMIR LUPOVICI\n5\n|  The Actor\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\ndeterrence focus on state versus state interactions.¹² Some scholars—for example, Libicki—provide rationales for focusing only on state actors (Libicki 2009:26); however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources.¹³ From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.\n## Intersections among Cyber and Kinetic Means\nConceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways,¹⁴ we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" (Libicki 2009:27; my emphasis). But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n¹² A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n¹³ Michael D. Horvath (March 2008) Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n¹⁴ See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it (Lonsdale 2004:227; see also Kramer 2009:15, 20–23; Betz and Stevens 2011:105).\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law (Wheatley and Hayes 1996:13, 19–20; Kugler 2009:328, 335; Morgan 2010:68).¹⁵ Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace.¹⁶ In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests (Deibert and Rohozinski 2010; see also Nye 2011:207–208).\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility (Morgan 2003:20). In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”\n## The Need to Further Theorize Cyber Deterrence\nA second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n¹⁵ See also in Cordesman and Cordesman (2001:7).\n¹⁶ Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.\nAMIR LUPOVICI\n7\nexplore changes in cyberspace and to encompass the variety of actors involved (Choucri 2012:15–16). While I build on these arguments, which are highly pertinent to moving cyber deterrence scholarship forward, I think that Choucri too quickly dismisses the potential of the constructivist approach in IR in her claims that it is not mature enough to make such a contribution and cannot address these precise issues. I argue the opposite: That integrating notions drawn from constructivist approaches will take the thinking and literature a step further. To better understand actors’ behavior, we need to acknowledge the existence of intersubjective understandings, that knowledge is socially constructed and that it is dependent on language and on the social context (Searle 1995:76–77; Adler 1997; Hopf 1998:199; Milliken 1999:229, 236).\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer (Deibert and Rohozinski 2010:22). After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed” (Saco 1999:290; see also Hansen and Nissenbaum 2009:1164–1165).¹⁷ In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process (Gorove 2000).\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined (Kramer 2009:12); in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted” (Libicki 2007:6). These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms (Freedman 2004; Tannenwald 2007), and discourse (Luke 1989; Klein 1994). Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality (Luke 1989:212), of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve (Hopf 1994:9–11; Milliken 1996:218, 228). Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting) (Tannenwald 2007).¹⁸\n¹⁷Rid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\n¹⁸For further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nIn addition, the emerging scholarship on practices in IR helps to further elaborate on these issues,¹⁹ as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game” (Adler and Pouliot 2011:12–14, 18).²⁰ For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized (Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim), forming a deterrence community (of practice) (Lupovici 2008:4).\n## Toward a Constructivist Approach to Cyber Deterrence\nWhile it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.\n## The Attribution Problem\nA large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it (Kello 2013:33; Lindsay 2013:378). Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).²¹\nThe attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity (Libicki 2009:41–52; Betz and Stevens 2011:32, 88). Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack (Libicki 2009:41, 43).\n¹⁹ According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n²⁰ Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).\n²¹ Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).\nHowever, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design” (Lindsay 2013:375--376). In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification (Stevens 2012:164; but see Rid 2013:140--141). Even Libicki acknowledges such a scenario in the future (Libicki 2009:43). Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem (Lucas 2013:17--18). While deducing the identity of an attacker from their interests may sometimes be misleading (Libicki 2009:44), anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation ... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network” (Farwell and Rohozinski 2011:31). Likewise, Sterner suggests,\nThere appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US] ... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. (Sterner 2011:73)\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nThe \"attribution problem,\" then, becomes a legal, technical, or strategic challenge (Betz and Stevens 2011:32) through practice²² and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty.²³ Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons \"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\" (Dipert 2010:393). While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.²⁴\nMy argument here is not that this situation is normatively desirable;²⁵ rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice.²⁶ Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.\n## The Social Construction of Violence\nViolence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed (Weldes 1999). The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that\n²²On the role of practice in international law, see Brunnée and Toope (2011).\n²³A similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\n²⁴In a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\n²⁵For example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\n²⁶As Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances \"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\" (2011:24–25).\nAMIR LUPOVICI\n11\nsomething is an existential threat (Buzan, Waever and Wilde 1998:30–31; Balzacq 2011). Violence can be seen in a similar way—as a social construction that, such as securitization, depends on a social process, can be accepted or rejected by a target audience, is related to language (that is, use of the term *violence*), and affects the legitimacy of how to act in response to a challenge.²⁷\nSuch labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons (Morgan 2011:151). This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes.²⁸ The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.²⁹\nSome scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered (Waxman 2011). This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force (Schmitt 1999:914–915).³⁰ However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims,\nTraditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75)\nThe ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral\n²⁷ One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n²⁸ For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).\n²⁹ For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).\n³⁰ The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nlevel. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare.³¹ Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified (Libicki 2009:179–180).\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar (Lawson 2012).³² This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar (Hansen and Nissenbaum 2009).\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible.³³ Furthermore, in such cases, retaliation may be employed to address or preempt public demands (Adler 2010). All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors (Tang 2005:40–41).\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is\n³¹ An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n³² In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).\n³³ Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.\nAMIR LUPOVICI\n13\nnot seen as violent, more limitations, both domestic and international, are placed upon executing a retaliatory attack, burdening deterrence credibility. For example, Waxman suggests that restricting the definition of armed attacks to include only severe cyberwarfare attacks will undermine American deterrence vis-à-vis lower levels of cyber-attacks (Waxman 2011:439). Likewise, Dunn Cavelty argues that during the Kosovo War, American plans to retaliate against a potential Serbian computer attack were rejected out of fear that they would be considered war crimes (Dunn Cavelty 2008:79). In addition, in such contexts—in which cyber means are not seen as violent—the needs arising from the “cult of reputation” and from the desire of actors to preserve their deterrent posture are less prominent, enabling defender actors to contain or ignore them. In cases where it is questionable whether cyber-attacks are acts of violence, a putative challenger will estimate that initiating a cyber-attack will be less likely to result in retaliation, an assumption that may weaken the perceived deterrent posture. Furthermore, given the difficulties in retaliating to a challenge seen as “nonviolent,” actors may divert their activity to such means if they fear the (more traditional) challenge they consider inflicting upon their opponent will yield a retaliatory attack with kinetic means (for example, with air, ground forces). In other words, more traditional deterrent threats may lead actors to use cyber means. This, of course, does not imply that deterrence of “nonviolent” means is doomed to fail, but, other factors being equal (such as the degree of harm), deterrence of such means is more difficult.\nIt is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior” (Lewis 2010:4; see also Clarke and Knake 2010:253–254; Nye 2011:208). While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^[34]^\n## The Case of Stuxnet\nStuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^[36]^\nA number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^[38]^ He further contended that Israel would not attack\n^[34]On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n^[35]According to some estimations, Stuxnet was operative as early as 2005 (Rid 2013:32). Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet” (Langner 2013).\n^[36]For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n^[37]Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n^[38]On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nbecause \"it has already done so,\" as evidenced through the case of Stuxnet.³⁹ Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack.⁴⁰ A similar argument was advanced by Lindsay (2013:398), who suggested that the United States \"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\" In this respect, he argued that a covert cyber option was a useful solution.\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.\n## The Limited Influence of the Attribution Problem\nUsing the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the \"attribution problem\" exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack (Farwell and Rohozinski 2011:29). Indeed, some security analysts have considered Iranian threats in this regard to be credible (Kam 2012). This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.\nSecond, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013).⁴² In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n³⁹ For a similar argument, see also Waxman (2011:442–443).\n⁴⁰ Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n⁴¹ Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n⁴² See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.\nAMIR LUPOVICI\n15\nThird, anonymity is not necessarily a problem because even when victims do not have clear evidence, in most cases, the identity of the attackers can be concluded from the context. With regard to Stuxnet, there were some hints pointing to the identity of the actors behind it.⁴³ While these were perhaps false flags that aimed to associate Israel, for example, with the attack (see in Lindsay 2013: ftn, 16, pp. 400–401), other indications point more directly to American and Israeli involvement.⁴⁴ Furthermore, as discussed by Harrison Dinniss (2012:37), Ahmadinejad blamed the West and Israel for being behind the attacks. In other words, not only did the Iranian authorities know that the nuclear facility at Natanz was attacked,⁴⁵ they publicly pointed to its alleged suspects. Indeed, while Stuxnet operated clandestinely for a period of time (Langner 2013) and successfully sabotaged the Iranian nuclear program, the main question is why, after it and the extent of its damage were revealed, there was no retaliation—despite the threats to respond if the Iranian nuclear program were attacked. In fact, as Langner argues, at some point, the “attacks should have been recognizable by plant floor staff just by the old eardrum.” This fact, according to Langner, emphasizes that the makers of Stuxnet were willing to accept the risk of its detection (Langner 2013). It also further challenges the argument that anonymity was the main reason for diverting the attack to cyberspace. Saeed Jalili, who served as Iranian secretary of the Supreme National Security Council, publicly admitted in January 2011 that “our experts already warded off this attack a long time ago” (Bednarz and Follath 2011). However, by stating this, he also implied that despite experiencing an attack and despite the time that had passed, Iran had not retaliated.\nTaking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.\n## The Effects of the Social Construction of Violence on Cyber Deterrence\nThe partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nA number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison\n⁴³Markoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\n⁴⁴See for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\n⁴⁵Interestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal (Sanger 2012).\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nDinniss 2012:81–82).⁴⁶ However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial⁴⁷—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives” (Sanger 2012). We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran,⁴⁸ which may indicate, among other things, the fear of an Iranian retaliation.⁴⁹\nAssertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions” (Bednarz and Follath 2011). The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study\n⁴⁶However, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\n⁴⁷On the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\n⁴⁸Verter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index (July 2012) Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\n⁴⁹For a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).\nAMIR LUPOVICI\n17\nregarding how social conventions about violence affect the manner in which even a target of such an attack refers to it. Furthermore, this also further confirms the assertions made above regarding the advantages in diverting the activity to cyberspace, wherein the cost of attack is lower.\nAnother counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.\n## Conclusions\nIn this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this\n50 In fact, the “easy” case for the emergence of such a treaty will be following events in which a cyber-attack causes substantial physical damage.\n51 BBC (2010) Iran Says Nuclear Programme Was Hit by Sabotage. *BBC*, November 29. Available at: http://www.bbc.co.uk/news/world-middle-east-11868596. Similarly, Kello (2013:27) argues that the Iranian response to Stuxnet has been muted.\n52 Mehr News Agency (2011) Iran to Take Pre-Emptive Action against Cyber Terrorism. *Mehr News Agency*, February 26. Available at: http://seclists.org/isn/2011/Feb/95.\n53 *Iran Times* (2011) Pasdar Officer Says Iran Set to Launch Cyber Attacks. *Iran Times*, March 25. Available at: http://iran-times.com/pasdar-officer-says-iran-set-to-launch-cyber-attacks.\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\n18 The \"Attribution Problem\" and the Social Construction of \"Violence\"\nconcept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence.",
  "flat_text": "International Studies Perspectives Advance Access published February 2, 2016\nInternational Studies Perspectives (2014) 0, 1-21\n# The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward\nAMIR LUPOVICI\nTel Aviv University\nMany scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and \"violence\" are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet\nThere is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic\nI am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082\n© The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nmeans that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a \"theoretical vacuum.\" More generally, Lindsay (2013:367) points out, \"Most work on international cyber security originates from the policy analysis community.\" Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace (Eriksson and Giacomello 2006; Dunn Cavelty 2008:7; Hansen and Nissenbaum 2009:1156).\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security (Saco 1999; Deibert 2002; Bendrath 2003; Yould 2003; Dunn Cavelty 2008, 2010, 2013; Hansen and Nissenbaum 2009; Deibert and Rohozinski 2010). However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence (Luke 1989; Williams 1992; Klein 1994; Tannenwald 2007; Adler 2009). This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of \"violence.\" Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\n\nAMIR LUPOVICI\n\n## Deterrence and Cyber(warfare) Scholarship and Its Challenges\nMost scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means (Wheatley and Hayes 1996:13, 19–20; Cordesman and Cordesman 2001:7; Kramer 2009:15–16; Kugler 2009:328; Morgan 2010:59, 68). However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger (Morgan 2003:15–20)—are difficult to meet when facing a cyberwarfare threat (Morgan 2010; Stevens 2012:149–153). Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders (Harknett 1996; Molander, Riddle, and Wilson 1996:87; Berkowitz 1997:183–184; Cordesman and Cordesman 2001:7; Arquilla 2003:210–213; Libicki 2007:272, 2009:1–3, 26, 44–45; Morgan 2010:55–76). However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.\n## What Do We Mean When We Say Cyber Deterrence?\nThe meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” (Stevens 2012:149–152). These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\nFor a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\nFor a detailed review of this scholarship, see also Lupovici (2011).\nGiven these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nan acceptable cost” (Libicki 2009:27–35). Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures. Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional. In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.\n## Who Are the Deterring Actors?\nOne implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\nSuch discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats (Wheatley and Hayes 1996:v–vi, 5–6; Molander et al. 1996:81–92). In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation (Libicki 2009:23–25). Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” (Lindsay 2013:372).\nTo some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\nThe same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\nMore fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).\nAMIR LUPOVICI\n\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\ndeterrence focus on state versus state interactions. Some scholars—for example, Libicki—provide rationales for focusing only on state actors (Libicki 2009:26); however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources. From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.\n## Intersections among Cyber and Kinetic Means\nConceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways, we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" (Libicki 2009:27; my emphasis). But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n Michael D. Horvath (March 2008) Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it (Lonsdale 2004:227; see also Kramer 2009:15, 20–23; Betz and Stevens 2011:105).\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law (Wheatley and Hayes 1996:13, 19–20; Kugler 2009:328, 335; Morgan 2010:68). Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace. In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests (Deibert and Rohozinski 2010; see also Nye 2011:207–208).\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility (Morgan 2003:20). In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”\n## The Need to Further Theorize Cyber Deterrence\nA second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n See also in Cordesman and Cordesman (2001:7).\n Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.\nAMIR LUPOVICI\n\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer (Deibert and Rohozinski 2010:22). After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed” (Saco 1999:290; see also Hansen and Nissenbaum 2009:1164–1165). In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process (Gorove 2000).\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined (Kramer 2009:12); in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted” (Libicki 2007:6). These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms (Freedman 2004; Tannenwald 2007), and discourse (Luke 1989; Klein 1994). Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality (Luke 1989:212), of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve (Hopf 1994:9–11; Milliken 1996:218, 228). Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting) (Tannenwald 2007).\nRid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\nFor further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nIn addition, the emerging scholarship on practices in IR helps to further elaborate on these issues, as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game” (Adler and Pouliot 2011:12–14, 18). For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized (Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim), forming a deterrence community (of practice) (Lupovici 2008:4).\n## Toward a Constructivist Approach to Cyber Deterrence\nWhile it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.\n## The Attribution Problem\nA large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it (Kello 2013:33; Lindsay 2013:378). Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).\nThe attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity (Libicki 2009:41–52; Betz and Stevens 2011:32, 88). Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack (Libicki 2009:41, 43).\n According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).\n Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).\nHowever, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design” (Lindsay 2013:375--376). In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification (Stevens 2012:164; but see Rid 2013:140--141). Even Libicki acknowledges such a scenario in the future (Libicki 2009:43). Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem (Lucas 2013:17--18). While deducing the identity of an attacker from their interests may sometimes be misleading (Libicki 2009:44), anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation ... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network” (Farwell and Rohozinski 2011:31). Likewise, Sterner suggests,\nThere appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US] ... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. (Sterner 2011:73)\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nThe \"attribution problem,\" then, becomes a legal, technical, or strategic challenge (Betz and Stevens 2011:32) through practice and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty. Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons \"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\" (Dipert 2010:393). While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.\nMy argument here is not that this situation is normatively desirable; rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice. Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.\n## The Social Construction of Violence\nViolence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed (Weldes 1999). The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that\nOn the role of practice in international law, see Brunnée and Toope (2011).\nA similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\nIn a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\nFor example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\nAs Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances \"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\" (2011:24–25).\nAMIR LUPOVICI\n\nSuch labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons (Morgan 2011:151). This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes. The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.\nSome scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered (Waxman 2011). This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force (Schmitt 1999:914–915). However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims,\nTraditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75)\nThe ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral\n One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).\n For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).\n The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nlevel. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare. Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified (Libicki 2009:179–180).\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar (Lawson 2012). This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar (Hansen and Nissenbaum 2009).\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible. Furthermore, in such cases, retaliation may be employed to address or preempt public demands (Adler 2010). All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors (Tang 2005:40–41).\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is\n An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).\n Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.\nAMIR LUPOVICI\n\nIt is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior” (Lewis 2010:4; see also Clarke and Knake 2010:253–254; Nye 2011:208). While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^[34]^\n## The Case of Stuxnet\nStuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^[36]^\nA number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^[38]^ He further contended that Israel would not attack\n^[34]On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n^[35]According to some estimations, Stuxnet was operative as early as 2005 (Rid 2013:32). Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet” (Langner 2013).\n^[36]For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n^[37]Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n^[38]On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nbecause \"it has already done so,\" as evidenced through the case of Stuxnet. Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack. A similar argument was advanced by Lindsay (2013:398), who suggested that the United States \"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\" In this respect, he argued that a covert cyber option was a useful solution.\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.\n## The Limited Influence of the Attribution Problem\nUsing the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the \"attribution problem\" exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand. Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack (Farwell and Rohozinski 2011:29). Indeed, some security analysts have considered Iranian threats in this regard to be credible (Kam 2012). This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.\nSecond, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013). In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n For a similar argument, see also Waxman (2011:442–443).\n Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.\nAMIR LUPOVICI\n\nTaking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.\n## The Effects of the Social Construction of Violence on Cyber Deterrence\nThe partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nA number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison\nMarkoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\nSee for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\nInterestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal (Sanger 2012).\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nDinniss 2012:81–82). However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives” (Sanger 2012). We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran, which may indicate, among other things, the fear of an Iranian retaliation.\nAssertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions” (Bednarz and Follath 2011). The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study\nHowever, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\nOn the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\nVerter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index (July 2012) Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\nFor a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).\nAMIR LUPOVICI\n\nAnother counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.\n## Conclusions\nIn this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this\n\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\n\nconcept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence.",
  "toc": [
    [
      1,
      "__preamble__"
    ],
    [
      1,
      "## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges"
    ],
    [
      1,
      "## What Do We Mean When We Say Cyber Deterrence?"
    ],
    [
      1,
      "## Who Are the Deterring Actors?"
    ],
    [
      1,
      "## Intersections among Cyber and Kinetic Means"
    ],
    [
      1,
      "## The Need to Further Theorize Cyber Deterrence"
    ],
    [
      1,
      "## Toward a Constructivist Approach to Cyber Deterrence While it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context."
    ],
    [
      1,
      "## The Attribution Problem A large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it. Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).²¹ The attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity. Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack."
    ],
    [
      1,
      "## The Social Construction of Violence Violence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed. The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that ²²On the role of practice in international law, see Brunnée and Toope (2011)."
    ],
    [
      1,
      "## The Limited Influence of the Attribution Problem Using the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the\"attribution problem\"exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack. Indeed, some security analysts have considered Iranian threats in this regard to be credible. This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack."
    ],
    [
      1,
      "## The Effects of the Social Construction of Violence on Cyber Deterrence The partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges."
    ],
    [
      1,
      "## Conclusions In this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence."
    ]
  ],
  "sections": {
    "__preamble__": "International Studies Perspectives Advance Access published February 2, 2016 International Studies Perspectives (2014) 0, 1-21 # The\"Attribution Problem\"and the Social Construction of\"Violence\": Taking Cyber Deterrence Literature a Step Forward¹ AMIR LUPOVICI Tel Aviv University Many scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and\"violence\"are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet There is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic ¹I am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The\"Attribution Problem\"and the Social Construction of\"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082 © The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com The\"Attribution Problem\"and the Social Construction of\"Violence\"means that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a\"theoretical vacuum.\"More generally, Lindsay (2013:367) points out,\"Most work on international cyber security originates from the policy analysis community.\"Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace.\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security. However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence. This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of\"violence.\"Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\nAMIR LUPOVICI",
    "## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges": "Most scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means . However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger ⁶—are difficult to meet when facing a cyberwarfare threat . Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders .⁷ However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.",
    "## What Do We Mean When We Say Cyber Deterrence?": "The meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” . These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\n⁵For a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\n⁶For a detailed review of this scholarship, see also Lupovici (2011).\n⁷Given these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nan acceptable cost” . Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.⁸\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures.⁹ Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional.¹⁰ In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.",
    "## Who Are the Deterring Actors?": "One implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent¹¹ regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\n⁸Such discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats . In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation . Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” .\n⁹To some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\n¹⁰The same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\n¹¹More fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).\nAMIR LUPOVICI\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\ndeterrence focus on state versus state interactions.¹² Some scholars—for example, Libicki—provide rationales for focusing only on state actors ; however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources.¹³ From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.",
    "## Intersections among Cyber and Kinetic Means": "Conceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways,¹⁴ we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" . But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n¹² A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n¹³ Michael D. Horvath  Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n¹⁴ See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it .\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law .¹⁵ Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace.¹⁶ In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests .\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility . In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”",
    "## The Need to Further Theorize Cyber Deterrence": "A second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n¹⁵ See also in Cordesman and Cordesman (2001:7).\n¹⁶ Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.\nAMIR LUPOVICI\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer. After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed”.¹⁷ In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process.\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined; in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted”. These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge, norms, and discourse. Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality, of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve. Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting).¹⁸ ¹⁷Rid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\n¹⁸For further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).\nThe\"Attribution Problem\"and the Social Construction of\"Violence\"In addition, the emerging scholarship on practices in IR helps to further elaborate on these issues,¹⁹ as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game”.²⁰ For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized, forming a deterrence community (of practice).",
    "## Toward a Constructivist Approach to Cyber Deterrence While it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.": "",
    "## The Attribution Problem A large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it. Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).²¹ The attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity. Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack.": "¹⁹ According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n²⁰ Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share”.\n²¹ Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).\nHowever, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design”. In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification. Even Libicki acknowledges such a scenario in the future. Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem. While deducing the identity of an attacker from their interests may sometimes be misleading, anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network”. Likewise, Sterner suggests, There appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US]... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. The\"Attribution Problem\"and the Social Construction of\"Violence\"The\"attribution problem,\"then, becomes a legal, technical, or strategic challenge through practice²² and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty.²³ Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons\"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\". While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.²⁴ My argument here is not that this situation is normatively desirable;²⁵ rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice.²⁶ Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.",
    "## The Social Construction of Violence Violence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed. The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that ²²On the role of practice in international law, see Brunnée and Toope (2011).": "²³A similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\n²⁴In a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\n²⁵For example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\n²⁶As Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances\"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\"(2011:24–25).\nAMIR LUPOVICI Such labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons. This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes.²⁸ The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.²⁹ Some scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered. This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force.³⁰ However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims, Traditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75) The ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral ²⁷ One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war. However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n²⁸ For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting.\n²⁹ For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence, and they indicate the establishment of common knowledge in this regard.\n³⁰ The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.\nThe\"Attribution Problem\"and the Social Construction of\"Violence\"level. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare.³¹ Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified.\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar.³² This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar.\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible.³³ Furthermore, in such cases, retaliation may be employed to address or preempt public demands. All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors.\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is ³¹ An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n³² In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality”.\n³³ Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails, and thus is seen as a way to demonstrate resolve.\nAMIR LUPOVICI It is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior”. While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^[34]^ ## The Case of Stuxnet Stuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^[36]^ A number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^[38]^ He further contended that Israel would not attack ^[34]On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n^[35]According to some estimations, Stuxnet was operative as early as 2005. Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet”.\n^[36]For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n^[37]Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n^[38]On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).\nThe\"Attribution Problem\"and the Social Construction of\"Violence\"because\"it has already done so,\"as evidenced through the case of Stuxnet.³⁹ Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack.⁴⁰ A similar argument was advanced by Lindsay (2013:398), who suggested that the United States\"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\"In this respect, he argued that a covert cyber option was a useful solution.\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.",
    "## The Limited Influence of the Attribution Problem Using the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the\"attribution problem\"exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack. Indeed, some security analysts have considered Iranian threats in this regard to be credible. This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.": "Second, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013).⁴² In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n³⁹ For a similar argument, see also Waxman (2011:442–443).\n⁴⁰ Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n⁴¹ Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n⁴² See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.\nAMIR LUPOVICI Taking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.",
    "## The Effects of the Social Construction of Violence on Cyber Deterrence The partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.": "A number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison ⁴³Markoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\n⁴⁴See for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\n⁴⁵Interestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal.\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016 The\"Attribution Problem\"and the Social Construction of\"Violence\"Dinniss 2012:81–82).⁴⁶ However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial⁴⁷—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives”. We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran,⁴⁸ which may indicate, among other things, the fear of an Iranian retaliation.⁴⁹ Assertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions”. The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study ⁴⁶However, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\n⁴⁷On the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\n⁴⁸Verter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\n⁴⁹For a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).\nAMIR LUPOVICI Another counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.",
    "## Conclusions In this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.": "With regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this Downloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016 concept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence."
  },
  "process_log": {
    "scheme": "markdown",
    "numeric_check": {
      "first_num": null,
      "raw_count": 0,
      "raw_examples": [],
      "filtered_count": 0,
      "filtered_examples": [],
      "seq_score": 0.0
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0
    },
    "toc_count": 11,
    "section_count": 12
  },
  "word_count": 10112,
  "references": [
    "## References\nADLER, EMANUEL. (1992) The Emergence of Cooperation: National Epistemic Communities and the International Evolution of the Idea of Nuclear Arms Control. *International Organization* 46 (1): 101–145.\nADLER, EMANUEL. (1997) Seizing the Middle Ground: Constructivism in World Politics. *European Journal of International Relations* 3 (3): 319–363.\nADLER, EMANUEL. (2009) Complex Deterrence in the Asymmetrical Warfare Era. In *Complex Deterrence: Theory and Practice in a New Era*, edited by T. V. Paul, Patrick M. Morgan, and James J. Wirtz. Chicago: University of Chicago Press.\nADLER, EMANUEL. (2010) Damned If You Do, Damned If You Don’t: Performative Power and the Strategy of Conventional and Nuclear Defusing. *Security Studies* 19 (2): 199–229.\nADLER, EMANUEL, AND VINCENT POULIOT. (2011) International Practices. *International Theory* 3 (1): 1–36.\nARQUILLA, JOHN. (2003) Thinking About New Security Paradigms. *Contemporary Security Policy* 24 (1): 299–225.\nBALZACQ, THIERRY. (2011) A Theory of Securitization: Origins, Core Assumptions, and Variants. In *Securitization Theory: How Security Problems Emerge and Dissolve*, edited by Thierry Balzacq. Oxon: Routledge.\nAMIR LUPOVICI\n19\nBARZASHKA, IVANKA. (2013) Are Cyber-Weapons Effective? The RUSI Journal 158 (2): 48–56.\nBEDNARZ, DIETER, AND ERICH FOLLATH. (2011) Iran’s Chief Nuclear Negotiator: “We Have to Be Constantly on Guard.” Der Spiegel, January 18. Available at: http://www.spiegel.de/international/world/iran-s-chief-nuclear-negotiator-we-have-to-be-constantly-on-guard-a-739945.html\nBEN MEIR, YEHUDA, AND OLENA BAGNO-MOLDAVSKY. (2013) The Voice of the People Israeli Public Opinion on National Security 2012. Tel Aviv: The Institute for National Security Studies.\nBENDRATH, RALF. (2003) The American Cyber-Angst and the Real World: Any Link? In Bombs and Bandwidth: The Emerging Relationship Between Information Technology and Security, edited by Robert Latham. New York: New Press.\nBERKOWITZ, BRUCE D. (1997) Warfare in the Information Age. In Athena’s Camp: Preparing for Conflict in the Information Age, edited by John Arquilla and David F. Ronfeldt. Santa Monica, CA: RAND.\nBETZ, DAVID J., AND TIM STEVENS. (2011) Cyberspace and the State: Toward a Strategy for Cyber-Power. Oxon: Routledge.\nBRUNNÉE, JUTTA, AND J. STEPHEN TOOPE. (2011) Interactional International Law and the Practice of Legality. In International Practices, edited by Emanuel Adler and Vincent Pouliot. New York: Cambridge University Press.\nBUZAN, BARRY, OLE WJEVER, AND JAAP DE WILDE. (1998) Security: A New Framework for Analysis. Boulder: Lynne Rienner.\nBVRES, ERIC, ANDREW GINTER, AND JOEL LANGILL. (2011) How Stuxnet Spreads—A Study of Infection Paths in Best Practice Systems. Tofino Security, white paper.\nCHOUCKI, NAZLI. (2012) Cyberpolitics in International Relations. Cambridge, MA: MIT Press.\nCLARKE, RICHARD A., AND ROBERT KNAKE. (2010) Cyber War: The Next Threat to National Security and What to Do About It. New York: Harper Collins.\nCORDESMAN, ANTHONY, AND JUSTIN CORDESMAN. (2001) Cyberthreats, Information Warfare, and Critical Infrastructure Protection: Defending the US Homeland. Westport: Praeger.\nDEIBERT, RON. (2002) Circuits of Power: Security in the Internet Environment. In Information Technologies and Global Politics: The Changing Scope of Power and Governance, edited by J. P. Singh and James N. Rosenau. New York: SUNY Press.\nDEIBERT, RON, AND RAFAL ROHOZINSKI. (2010) Risking Security: The Policies and Paradoxes of Cyberspace Security. International Political Sociology 4 (1): 15–32.\nDEIBERT, J. RONALD, RAFAL ROHOZINSKI, AND MASASHI CRETE-NISHIHATA. (2012) Cyclones in Cyberspace: Information Shaping and Denial in the 2008 Russia-Georgia War. Security Dialogue 43 (1): 3–24.\nDEVENNY, PATRICK. (2006) Hezbollah’s Strategic Threat to Israel. Middle East Quarterly 13 (1): 31–38.\nDIPERT, R. RANDALL. (2010) The Ethics of Cyberwarfare. Journal of Military Ethics 9 (4): 384–410.\nDUNN CAVELTY, MYRIAM. (2008) Cyber-Security and Threat Politics. New York: Routledge.\nDUNN CAVELTY, MYRIAM. (2010) Cyber-Security. In Routledge Handbook of Security Studies, edited by Victor Mauer and Myriam Dunn Cavelty. Oxon: Routledge.\nDUNN CAVELTY, MYRIAM. (2013) From Cyber-Bombs to Political Fallout: Threat Representations with an Impact in the Cyber-Security Discourse. International Studies Review 15 (1): 105–122.\nERIKSSON, JOHAN, AND GIAMPIERO GIACOMELLO. (2006) The Information Revolution, Security, and International Relations: (IR)Relevant Theory? International Political Science Review 27 (3): 221–244.\nFALK, JIM. (1989) The Discursive Shaping of Nuclear Militarism. Current Research on Peace and Violence 12 (2): 53–76.\nFARWELL, JAMES P., AND RAFAL ROHOZINSKI. (2011) Stuxnet and the Future of Cyber War. Survival 53 (1): 23–40.\nFEARON, JAMES. (2002) Selection Effects and Deterrence. International Interactions 28 (1): 5–29.\nFREDERKING, BRIAN. (2007) The United States and the Security Council: Collective Security Since the Cold War. London: Routledge.\nFREEDMAN, LAWRENCE. (2004) Deterrence. Cambridge: Polity Press.\nGOROVE, M. KATHERINE. (2000) Delimitation of Outer Space and the Aerospace Object—Where Is the Law? Journal of Space Law 28 (1): 11–28.\nGUITTON, CLEMENT, AND ELAINE KORZAK. (2013) The Sophistication Criterion for Attribution. The RUSI Journal 158 (4): 62–68.\nHANSEN, LENE, AND HELEN NISSENBAUM. (2009) Digital Disaster, Cyber Security, and the Copenhagen School. International Studies Quarterly 53 (4): 1155–1173.\nHARKNETT, J. RICHARD. (1996) Information Warfare and Deterrence. Parameters 26 (3): 93–107.\nHARRISON DINNISS, HEATHER. (2012) Cyber Warfare and the Laws of War. Cambridge: Cambridge University Press.\nHOPF, TED. (1994) Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965–1990. Ann Arbor: University of Michigan Press.\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nHOPF, TED. (1998) The Promise of Constructivism in International Relations Theory. International Security 23 (1): 171-200.\nJACKSON, ROBERT. (2007) Sovereignty: The Evolution of an Idea. Cambridge: Polity.\nJOHNSTON, ALASTAIR IAIN. (1995) Thinking About Strategic Culture. International Security 19 (4): 32-64.\nKAM, EPHRAIM. (2012) An Attack on Iran: The Morning After. Strategic Assessment 15 (1): 15-27.\nKAYE, DALIA DASSA, ALIREZA NADER, AND PARISA ROSHAN. (2011) Israel and Iran. A Dangerous Rivalry. Santa Monica, CA: RAND.\nKELLO, LUCAS. (2013) The Meaning of the Cyber Revolution: Perils to Theory and Statecraft. International Security 38 (2): 7-40.\nKLEIN, BRADLEY. (1994) Strategic Studies and World Order. New York: Cambridge University Press.\nKRAMER, D. FRANKLIN. (2009) Cyberpower and National Security: Policy Recommendations for a Strategic Framework. In *Cyberpower and National Security*, edited by Franklin D. Kramer, Stuart H. Starr, and Larry K. Wentz. Washington, DC: National Defense University Press.\nKUGLER, L. RICHARD. (2009) Deterrence of Cyber Attacks. In *Cyberpower and National Security*, edited by Franklin D. Kramer, Stuart H. Starr, and Larry K. Wentz. Washington, DC: National Defense University Press.\nLACHOW, IRVING. (2009) Cyber Terrorism: Menace or Myth. In *Cyberpower and National Security*, edited by Franklin D. Kramer, Stuart H. Starr, and Larry K. Wentz. Washington: National Defense University Press.\nLANGNER, RALPH. (2013) Stuxnet's Secret Twin. Foreign Policy. Available at: http://www.foreignpolicy.com/articles/2013/11/19/stuxnets_secret_twin_iran_nukes_cyber_attack.\nLAWSON, SEAN. (2012) Putting the \"War\" in Cyber War: Metaphor, Analogy, and Cyber Security Discourse in the United States. First Monday 17 (7). Available at: http://firstmonday.org/ojs/index.php/fm/article/view/3848/3270.\nLEBOW, NED RICHARD. (2010) Forbidden Fruit: Counterfactuals and International Relations. Princeton: Princeton University Press.\nLEWIS, A. JAMES. (2010) Cross-Domain Deterrence and Credible Threats. Washington, DC: Center for Strategic and International Studies.\nLIBICKI, C. MARTIN. (2007) Conquest in Cyberspace. Cambridge: Cambridge University Press.\nLIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation.\nLIFF, P. ADAM. (2012) Cyberwar: A New, \"Absolute Weapon?\" The Proliferation of Cyberwarfare Capabilities and Interstate War. Journal of Strategic Studies 35 (3): 401-428.\nLINDSAY, R. JON. (2013) Stuxnet and the Limits of Cyber Warfare. Security Studies 22 (3): 365-404.\nLONSDALE, DAVID J. (2004) The Nature of War in the Information Age: Clausewitzian Future. Oxon: Routledge.\nLUCAS, R. GEORGE JR. (2013) Can There Be an Ethical Cyber War? In Conflict and Cooperation in Cyberspace: The Challenge to National Security, edited by Panayotis A. Yannakogeorgos and Adam Lowther. Boca Raton, FL: Taylor &amp; Francis.\nLUKASIK, J. STEPHEN. (2010) A Framework for Thinking About Cyber Conflict and Cyber Deterrence with Possible Declaratory Policies for These Domains. In Proceedings of a Workshop on Deterring Cyberattacks, edited by John D. Steinbruner, et al. Washington, DC: The National Academies.\nLUKE, W. TIMOTHY. (1989) What's Wrong with Deterrence? A Semiotic Interpretation of National Security Policy. In International/Intertextual Relations, edited by James Der Derian and Michael J. Shapiro. New York: Lexington Books.\nLUPOVICI, AMIR. (2008) Deterrence Communities: The Success of a Rational Norm in the Relations of the Superpowers, 1950-1973. PhD Thesis, The Hebrew University, Jerusalem [in Hebrew].\nLUPOVICI, AMIR. (2010) The Emerging Fourth Wave of Deterrence Theory—Toward a New Research Agenda. International Studies Quarterly 54 (3): 705-732.\nLUPOVICI, AMIR. (2011) Cyber Warfare and Deterrence: Trends and Challenges. Military and Strategic Affairs 3 (3): 41-52.\nLUPOVICI, AMIR, AND ILAN DANJOUX. (2009) Deterrence in the Media Age: Public Opinion, and the Emergence of Deterrence 2.0. Paper presented at the American Political Science Association Annual Conference. Toronto, 2009.\nMILLIKEN, L. JENNIFER. (1996) Metaphors of Prestige and Reputation. In Post-Realism. The Rhetorical Turn in International Relations, edited by Francis A. Beer and Robert Hariman. Michigan: University of Michigan Press.\nMILLIKEN, L. JENNIFER. (1999) The Study of Discourse in International Relations: A Critique of Research and Methods. European Journal of International Relations 5 (2): 225-254.\nMOLANDER, ROGER C., ANDREW S. RIDDILE, AND PETER A. WILSON. (1996) Strategic Information Warfare: A New Face of War. Parameters 26 (3): 81-92.\nAMIR LUPOVICI\n21\nMORGAN, M. PATRICK. (2003) *Deterrence Now*. New York: Cambridge University Press.\nMORGAN, M. PATRICK. (2010) Applicability of Traditional Deterrence Concepts and Theory to the Cyber Realm. In *Proceedings of a Workshop on Deterring Cyberattacks*, edited by John D. Steinbruner, et al. Washington, DC: The National Academies.\nMORGAN, M. PATRICK. (2011) The Practice of Deterrence. In *International Practices*, edited by Emanuel Adler and Vincent Pouliot. New York: Cambridge University Press.\nNEUMANN, B. IVER. (1998) Identity and the Outbreak of War: Or Why the Copenhagen School of Security Studies Should Include the Idea of “Violisation” in Its Framework of Analysis. *International Journal of Peace Studies* 3: 7–22.\nNYE, JOSEPH S. (2011) *The Future of Power*. New York: Public Affairs.\nPAUL, T. V., PATRICK M. MORGAN, AND JAMES J. WIRTZ, Eds. (2009) *Complex Deterrence: Theory and Practice in a New Era*. Chicago: University of Chicago Press.\nPRICE, M. RICHARD. (1997) *The Chemical Weapons Taboo*. Ithaca, NY: Cornell University Press.\nRID, THOMAS. (2013) *Cyber War Will Not Take Place*. London: Hurst.\nSACO, DIANA. (1999) Colonizing Cyberspace: National Security and the Internet. In *Cultures of Insecurity: States, Communities and the Production of Danger*, edited by Jutta Weldes, Mark Laffey, Hugh Gusterson, and Raymond Duvall. Minneapolis: University of Minnesota Press.\nSADR, EHSANEH. (2005) The Impact of Iran’s Nuclearization on Israel. *Middle East Policy* 12 (2): 58–72.\nSANGER, DAVID. (2012) Obama Order Sped Up Wave of Cyberattacks Against Iran. *New York Times*, June 1. Available at: http://www.nytimes.com/2012/06/01/world/middleeast/obama-ordered-wave-of-cyberattacks-against-iran.html?pagewanted=all&amp;_r=0.\nSCHMITT, N. MICHAEL. (1999) Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework. *Columbia Journal of Transnational Law* 37: 885–937.\nSCHMITT, N. MICHAEL, ED. (2013) *Tallinn Manual on the International Law Applicable to Cyber Warfare*. New York: Cambridge University Press.\nSEARLE, JOHN R. (1995) *The Construction of Social Reality*. London: Penguin.\nSTERNER, ERIC. (2011) Retaliatory Deterrence in Cyberspace. *Strategic Studies Quarterly* 5 (1): 62–80.\nSTEVENS, TIM. (2012) A Cyberwar of Ideas? Deterrence and Norms in Cyberspace. *Contemporary Security Policy* 33 (1): 148–170.\nSTONE, JOHN. (2013) Cyber War Will Take Place! *Journal of Strategic Studies* 36 (1): 101–108.\nTALBOT, J. BRENT. (2011) Stuxnet and After. *Journal of International Security Affairs* 21: 69–78.\nTANG, SHIPING. (2005) Reputation, Cult of Reputation, and International Conflict. *Security Studies* 14 (1): 34–61.\nTANNENWALD, NINA. (2007) *The Nuclear Taboo: The United States and the Non-Use of Nuclear Weapons*. New York: Cambridge University Press.\nTETLOCK, PHILIP, AND AARON BELKIN. (1996) *Counterfactual Thought Experiments in World Politics: Logical, Psychological Perspectives*. Princeton: Princeton University Press.\nUS DEPARTMENT OF DEFENSE. (2010) *Dictionary of Military and Associated Terms*. Washington, DC: US Department of Defense.\nVUORI, A. JUHA. (2008) Illocutionary Logic and Strands of Securitization: Applying the Theory of Securitization to the Study of Non-Democratic Political Orders. *European Journal of International Relations* 14 (1): 65–99.\nWAXMAN, C. MATTHEW. (2011) Cyberattacks and the Use of Force: Back to the Future of Article 2(4). *Yale Journal of International Law* 36 (2): 421–459.\nWEHREY, FREDERIC, E. DAVID THALER, NORA BENSAHEL, KIM CRAGIN, JERROLD D. GREEN, DALIA DASSA KAYE, NADIA OWEIDAT, AND JENNIFER LI. (2009) *Dangerous but Not Omnipotent*. Santa Monica, CA: RAND.\nWELDES, JUTTA. (1999) *Constructing National Interests. The United States and the Cuban Missile Crisis*. Minneapolis: University of Minnesota Press.\nWHEATLEY, GARY F., AND E. RICHARD HAYES. (1996) *Information Warfare and Deterrence*. Washington: National Defense University Press.\nWILLIAMS, C. MICHAEL. (1992) Rethinking the “Logic” of Deterrence. *Alternatives* 17 (1): 67–93.\nYOULD, E. D. RACHEL. (2003) Beyond American Fortress: Understanding Homeland Security. In *Bombs and Bandwidth: The Emerging Relationship between Information Technology and Security*, edited by Robert Latham. New York: New Press.\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016"
  ],
  "citations": {
    "style": "superscript",
    "flat_text": "International Studies Perspectives Advance Access published February 2, 2016\nInternational Studies Perspectives (2014) 0, 1-21\n# The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward\nAMIR LUPOVICI\nTel Aviv University\nMany scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and \"violence\" are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet\nThere is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic\nI am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082\n© The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nmeans that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a \"theoretical vacuum.\" More generally, Lindsay (2013:367) points out, \"Most work on international cyber security originates from the policy analysis community.\" Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace (Eriksson and Giacomello 2006; Dunn Cavelty 2008:7; Hansen and Nissenbaum 2009:1156).\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security (Saco 1999; Deibert 2002; Bendrath 2003; Yould 2003; Dunn Cavelty 2008, 2010, 2013; Hansen and Nissenbaum 2009; Deibert and Rohozinski 2010). However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence (Luke 1989; Williams 1992; Klein 1994; Tannenwald 2007; Adler 2009). This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of \"violence.\" Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\n\nAMIR LUPOVICI\n\n## Deterrence and Cyber(warfare) Scholarship and Its Challenges\nMost scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means (Wheatley and Hayes 1996:13, 19–20; Cordesman and Cordesman 2001:7; Kramer 2009:15–16; Kugler 2009:328; Morgan 2010:59, 68). However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger (Morgan 2003:15–20)—are difficult to meet when facing a cyberwarfare threat (Morgan 2010; Stevens 2012:149–153). Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders (Harknett 1996; Molander, Riddle, and Wilson 1996:87; Berkowitz 1997:183–184; Cordesman and Cordesman 2001:7; Arquilla 2003:210–213; Libicki 2007:272, 2009:1–3, 26, 44–45; Morgan 2010:55–76). However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.\n## What Do We Mean When We Say Cyber Deterrence?\nThe meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” (Stevens 2012:149–152). These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\nFor a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\nFor a detailed review of this scholarship, see also Lupovici (2011).\nGiven these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nan acceptable cost” (Libicki 2009:27–35). Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures. Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional. In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.\n## Who Are the Deterring Actors?\nOne implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\nSuch discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats (Wheatley and Hayes 1996:v–vi, 5–6; Molander et al. 1996:81–92). In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation (Libicki 2009:23–25). Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” (Lindsay 2013:372).\nTo some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\nThe same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\nMore fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).\nAMIR LUPOVICI\n\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\ndeterrence focus on state versus state interactions. Some scholars—for example, Libicki—provide rationales for focusing only on state actors (Libicki 2009:26); however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources. From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.\n## Intersections among Cyber and Kinetic Means\nConceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways, we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" (Libicki 2009:27; my emphasis). But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n Michael D. Horvath (March 2008) Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it (Lonsdale 2004:227; see also Kramer 2009:15, 20–23; Betz and Stevens 2011:105).\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law (Wheatley and Hayes 1996:13, 19–20; Kugler 2009:328, 335; Morgan 2010:68). Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace. In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests (Deibert and Rohozinski 2010; see also Nye 2011:207–208).\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility (Morgan 2003:20). In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”\n## The Need to Further Theorize Cyber Deterrence\nA second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n See also in Cordesman and Cordesman (2001:7).\n Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.\nAMIR LUPOVICI\n\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer (Deibert and Rohozinski 2010:22). After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed” (Saco 1999:290; see also Hansen and Nissenbaum 2009:1164–1165). In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process (Gorove 2000).\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined (Kramer 2009:12); in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted” (Libicki 2007:6). These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms (Freedman 2004; Tannenwald 2007), and discourse (Luke 1989; Klein 1994). Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality (Luke 1989:212), of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve (Hopf 1994:9–11; Milliken 1996:218, 228). Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting) (Tannenwald 2007).\nRid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\nFor further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nIn addition, the emerging scholarship on practices in IR helps to further elaborate on these issues, as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game” (Adler and Pouliot 2011:12–14, 18). For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized (Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim), forming a deterrence community (of practice) (Lupovici 2008:4).\n## Toward a Constructivist Approach to Cyber Deterrence\nWhile it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.\n## The Attribution Problem\nA large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it (Kello 2013:33; Lindsay 2013:378). Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).\nThe attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity (Libicki 2009:41–52; Betz and Stevens 2011:32, 88). Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack (Libicki 2009:41, 43).\n According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).\n Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).\nHowever, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design” (Lindsay 2013:375--376). In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification (Stevens 2012:164; but see Rid 2013:140--141). Even Libicki acknowledges such a scenario in the future (Libicki 2009:43). Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem (Lucas 2013:17--18). While deducing the identity of an attacker from their interests may sometimes be misleading (Libicki 2009:44), anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation ... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network” (Farwell and Rohozinski 2011:31). Likewise, Sterner suggests,\nThere appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US] ... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. (Sterner 2011:73)\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nThe \"attribution problem,\" then, becomes a legal, technical, or strategic challenge (Betz and Stevens 2011:32) through practice and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty. Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons \"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\" (Dipert 2010:393). While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.\nMy argument here is not that this situation is normatively desirable; rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice. Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.\n## The Social Construction of Violence\nViolence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed (Weldes 1999). The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that\nOn the role of practice in international law, see Brunnée and Toope (2011).\nA similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\nIn a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\nFor example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\nAs Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances \"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\" (2011:24–25).\nAMIR LUPOVICI\n\nSuch labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons (Morgan 2011:151). This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes. The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.\nSome scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered (Waxman 2011). This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force (Schmitt 1999:914–915). However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims,\nTraditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75)\nThe ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral\n One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).\n For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).\n The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nlevel. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare. Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified (Libicki 2009:179–180).\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar (Lawson 2012). This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar (Hansen and Nissenbaum 2009).\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible. Furthermore, in such cases, retaliation may be employed to address or preempt public demands (Adler 2010). All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors (Tang 2005:40–41).\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is\n An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).\n Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.\nAMIR LUPOVICI\n\nIt is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior” (Lewis 2010:4; see also Clarke and Knake 2010:253–254; Nye 2011:208). While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^[34]^\n## The Case of Stuxnet\nStuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^[36]^\nA number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^[38]^ He further contended that Israel would not attack\n^[34]On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n^[35]According to some estimations, Stuxnet was operative as early as 2005 (Rid 2013:32). Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet” (Langner 2013).\n^[36]For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n^[37]Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n^[38]On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nbecause \"it has already done so,\" as evidenced through the case of Stuxnet. Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack. A similar argument was advanced by Lindsay (2013:398), who suggested that the United States \"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\" In this respect, he argued that a covert cyber option was a useful solution.\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.\n## The Limited Influence of the Attribution Problem\nUsing the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the \"attribution problem\" exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand. Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack (Farwell and Rohozinski 2011:29). Indeed, some security analysts have considered Iranian threats in this regard to be credible (Kam 2012). This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.\nSecond, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013). In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n For a similar argument, see also Waxman (2011:442–443).\n Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.\nAMIR LUPOVICI\n\nTaking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.\n## The Effects of the Social Construction of Violence on Cyber Deterrence\nThe partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nA number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison\nMarkoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\nSee for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\nInterestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal (Sanger 2012).\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nDinniss 2012:81–82). However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives” (Sanger 2012). We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran, which may indicate, among other things, the fear of an Iranian retaliation.\nAssertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions” (Bednarz and Follath 2011). The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study\nHowever, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\nOn the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\nVerter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index (July 2012) Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\nFor a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).\nAMIR LUPOVICI\n\nAnother counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.\n## Conclusions\nIn this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this\n\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\n\nconcept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 48,
        "success_occurrences": 48,
        "success_unique": 24,
        "bib_unique_total": 31,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.7741935483870968,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "## Deterrence",
          "footnote": "|  The Actor",
          "position": 8115
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "explore changes in cyberspace and to encompass the variety of actors involved (Choucri 2012:15–16). While I build on these arguments, which are highly pertinent to moving cyber deterrence scholarship forward, I think that Choucri too quickly dismisses the potential of the constructivist approach in IR in her claims that it is not mature enough to make such a contribution and cannot address these precise issues. I argue the opposite: That integrating notions drawn from constructivist approaches will take the thinking and literature a step further. To better understand actors’ behavior, we need to acknowledge the existence of intersubjective understandings, that knowledge is socially constructed and that it is dependent on language and on the social context (Searle 1995:76–77; Adler 1997; Hopf 1998:199; Milliken 1999:229, 236).",
          "position": 9568
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "cks to an acceptable level at\n",
          "footnote": "|  The Actor",
          "position": 10965
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "explore changes in cyberspace and to encompass the variety of actors involved (Choucri 2012:15–16). While I build on these arguments, which are highly pertinent to moving cyber deterrence scholarship forward, I think that Choucri too quickly dismisses the potential of the constructivist approach in IR in her claims that it is not mature enough to make such a contribution and cannot address these precise issues. I argue the opposite: That integrating notions drawn from constructivist approaches will take the thinking and literature a step further. To better understand actors’ behavior, we need to acknowledge the existence of intersubjective understandings, that knowledge is socially constructed and that it is dependent on language and on the social context (Searle 1995:76–77; Adler 1997; Hopf 1998:199; Milliken 1999:229, 236).",
          "position": 11118
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "the defender wishes to prevent",
          "footnote": "something is an existential threat (Buzan, Waever and Wilde 1998:30–31; Balzacq 2011). Violence can be seen in a similar way—as a social construction that, such as securitization, depends on a social process, can be accepted or rejected by a target audience, is related to language (that is, use of the term *violence*), and affects the legitimacy of how to act in response to a challenge.²⁷",
          "position": 13714
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "",
          "footnote": "something is an existential threat (Buzan, Waever and Wilde 1998:30–31; Balzacq 2011). Violence can be seen in a similar way—as a social construction that, such as securitization, depends on a social process, can be accepted or rejected by a target audience, is related to language (that is, use of the term *violence*), and affects the legitimacy of how to act in response to a challenge.²⁷",
          "position": 15994
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "",
          "footnote": "A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).",
          "position": 16853
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "not seen as violent, more limitations, both domestic and international, are placed upon executing a retaliatory attack, burdening deterrence credibility. For example, Waxman suggests that restricting the definition of armed attacks to include only severe cyberwarfare attacks will undermine American deterrence vis-à-vis lower levels of cyber-attacks (Waxman 2011:439). Likewise, Dunn Cavelty argues that during the Kosovo War, American plans to retaliate against a potential Serbian computer attack were rejected out of fear that they would be considered war crimes (Dunn Cavelty 2008:79). In addition, in such contexts—in which cyber means are not seen as violent—the needs arising from the “cult of reputation” and from the desire of actors to preserve their deterrent posture are less prominent, enabling defender actors to contain or ignore them. In cases where it is questionable whether cyber-attacks are acts of violence, a putative challenger will estimate that initiating a cyber-attack will be less likely to result in retaliation, an assumption that may weaken the perceived deterrent posture. Furthermore, given the difficulties in retaliating to a challenge seen as “nonviolent,” actors may divert their activity to such means if they fear the (more traditional) challenge they consider inflicting upon their opponent will yield a retaliatory attack with kinetic means (for example, with air, ground forces). In other words, more traditional deterrent threats may lead actors to use cyber means. This, of course, does not imply that deterrence of “nonviolent” means is doomed to fail, but, other factors being equal (such as the degree of harm), deterrence of such means is more difficult.",
          "position": 17706
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "c spaces) in a number of ways,",
          "footnote": "See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).",
          "position": 18326
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "order to sharpen some notions\n",
          "footnote": "A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).",
          "position": 18940
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "not seen as violent, more limitations, both domestic and international, are placed upon executing a retaliatory attack, burdening deterrence credibility. For example, Waxman suggests that restricting the definition of armed attacks to include only severe cyberwarfare attacks will undermine American deterrence vis-à-vis lower levels of cyber-attacks (Waxman 2011:439). Likewise, Dunn Cavelty argues that during the Kosovo War, American plans to retaliate against a potential Serbian computer attack were rejected out of fear that they would be considered war crimes (Dunn Cavelty 2008:79). In addition, in such contexts—in which cyber means are not seen as violent—the needs arising from the “cult of reputation” and from the desire of actors to preserve their deterrent posture are less prominent, enabling defender actors to contain or ignore them. In cases where it is questionable whether cyber-attacks are acts of violence, a putative challenger will estimate that initiating a cyber-attack will be less likely to result in retaliation, an assumption that may weaken the perceived deterrent posture. Furthermore, given the difficulties in retaliating to a challenge seen as “nonviolent,” actors may divert their activity to such means if they fear the (more traditional) challenge they consider inflicting upon their opponent will yield a retaliatory attack with kinetic means (for example, with air, ground forces). In other words, more traditional deterrent threats may lead actors to use cyber means. This, of course, does not imply that deterrence of “nonviolent” means is doomed to fail, but, other factors being equal (such as the degree of harm), deterrence of such means is more difficult.",
          "position": 19191
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "",
          "footnote": "See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).",
          "position": 19542
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "Third, anonymity is not necessarily a problem because even when victims do not have clear evidence, in most cases, the identity of the attackers can be concluded from the context. With regard to Stuxnet, there were some hints pointing to the identity of the actors behind it.⁴³ While these were perhaps false flags that aimed to associate Israel, for example, with the attack (see in Lindsay 2013: ftn, 16, pp. 400–401), other indications point more directly to American and Israeli involvement.⁴⁴ Furthermore, as discussed by Harrison Dinniss (2012:37), Ahmadinejad blamed the West and Israel for being behind the attacks. In other words, not only did the Iranian authorities know that the nuclear facility at Natanz was attacked,⁴⁵ they publicly pointed to its alleged suspects. Indeed, while Stuxnet operated clandestinely for a period of time (Langner 2013) and successfully sabotaged the Iranian nuclear program, the main question is why, after it and the extent of its damage were revealed, there was no retaliation—despite the threats to respond if the Iranian nuclear program were attacked. In fact, as Langner argues, at some point, the “attacks should have been recognizable by plant floor staff just by the old eardrum.” This fact, according to Langner, emphasizes that the makers of Stuxnet were willing to accept the risk of its detection (Langner 2013). It also further challenges the argument that anonymity was the main reason for diverting the attack to cyberspace. Saeed Jalili, who served as Iranian secretary of the Supreme National Security Council, publicly admitted in January 2011 that “our experts already warded off this attack a long time ago” (Bednarz and Follath 2011). However, by stating this, he also implied that despite experiencing an attack and despite the time that had passed, Iran had not retaliated.",
          "position": 20822
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.",
          "position": 21359
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "nd kinetic means interact, to\n",
          "footnote": "Third, anonymity is not necessarily a problem because even when victims do not have clear evidence, in most cases, the identity of the attackers can be concluded from the context. With regard to Stuxnet, there were some hints pointing to the identity of the actors behind it.⁴³ While these were perhaps false flags that aimed to associate Israel, for example, with the attack (see in Lindsay 2013: ftn, 16, pp. 400–401), other indications point more directly to American and Israeli involvement.⁴⁴ Furthermore, as discussed by Harrison Dinniss (2012:37), Ahmadinejad blamed the West and Israel for being behind the attacks. In other words, not only did the Iranian authorities know that the nuclear facility at Natanz was attacked,⁴⁵ they publicly pointed to its alleged suspects. Indeed, while Stuxnet operated clandestinely for a period of time (Langner 2013) and successfully sabotaged the Iranian nuclear program, the main question is why, after it and the extent of its damage were revealed, there was no retaliation—despite the threats to respond if the Iranian nuclear program were attacked. In fact, as Langner argues, at some point, the “attacks should have been recognizable by plant floor staff just by the old eardrum.” This fact, according to Langner, emphasizes that the makers of Stuxnet were willing to accept the risk of its detection (Langner 2013). It also further challenges the argument that anonymity was the main reason for diverting the attack to cyberspace. Saeed Jalili, who served as Iranian secretary of the Supreme National Security Council, publicly admitted in January 2011 that “our experts already warded off this attack a long time ago” (Bednarz and Follath 2011). However, by stating this, he also implied that despite experiencing an attack and despite the time that had passed, Iran had not retaliated.",
          "position": 23361
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.",
          "position": 23410
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "regarding how social conventions about violence affect the manner in which even a target of such an attack refers to it. Furthermore, this also further confirms the assertions made above regarding the advantages in diverting the activity to cyberspace, wherein the cost of attack is lower.",
          "position": 25454
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "The \"Attribution Problem\" and the Social Construction of \"Violence\"",
          "position": 27659
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "¹⁸",
          "footnote": "regarding how social conventions about violence affect the manner in which even a target of such an attack refers to it. Furthermore, this also further confirms the assertions made above regarding the advantages in diverting the activity to cyberspace, wherein the cost of attack is lower.",
          "position": 27662
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "The \"Attribution Problem\" and the Social Construction of \"Violence\"",
          "position": 27755
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "her elaborate on these issues,",
          "footnote": "According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).",
          "position": 28054
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "",
          "footnote": "Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).",
          "position": 28295
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).",
          "position": 30044
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "",
          "footnote": "According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).",
          "position": 30931
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "",
          "footnote": "Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).",
          "position": 31386
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).",
          "position": 31571
        },
        {
          "index": 27,
          "intext_citation": "²⁷",
          "preceding_text": "",
          "footnote": "One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.",
          "position": 40708
        },
        {
          "index": 28,
          "intext_citation": "²⁸",
          "preceding_text": "",
          "footnote": "For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).",
          "position": 41265
        },
        {
          "index": 29,
          "intext_citation": "²⁹",
          "preceding_text": "",
          "footnote": "For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).",
          "position": 41483
        },
        {
          "index": 30,
          "intext_citation": "³⁰",
          "preceding_text": "",
          "footnote": "The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.",
          "position": 42570
        },
        {
          "index": 27,
          "intext_citation": "²⁷",
          "preceding_text": "el and also at the unilateral\n",
          "footnote": "One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.",
          "position": 43502
        },
        {
          "index": 28,
          "intext_citation": "²⁸",
          "preceding_text": "",
          "footnote": "For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).",
          "position": 43870
        },
        {
          "index": 29,
          "intext_citation": "²⁹",
          "preceding_text": "",
          "footnote": "For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).",
          "position": 44184
        },
        {
          "index": 30,
          "intext_citation": "³⁰",
          "preceding_text": "",
          "footnote": "The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.",
          "position": 44423
        },
        {
          "index": 31,
          "intext_citation": "³¹",
          "preceding_text": "",
          "footnote": "An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).",
          "position": 44802
        },
        {
          "index": 32,
          "intext_citation": "³²",
          "preceding_text": "",
          "footnote": "In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).",
          "position": 45799
        },
        {
          "index": 33,
          "intext_citation": "³³",
          "preceding_text": "",
          "footnote": "Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.",
          "position": 47234
        },
        {
          "index": 31,
          "intext_citation": "³¹",
          "preceding_text": "When an activity is",
          "footnote": "An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).",
          "position": 48282
        },
        {
          "index": 32,
          "intext_citation": "³²",
          "preceding_text": "",
          "footnote": "In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).",
          "position": 48456
        },
        {
          "index": 33,
          "intext_citation": "³³",
          "preceding_text": "",
          "footnote": "Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.",
          "position": 48848
        },
        {
          "index": 39,
          "intext_citation": "³⁹",
          "preceding_text": "",
          "footnote": "For a similar argument, see also Waxman (2011:442–443).",
          "position": 53845
        },
        {
          "index": 40,
          "intext_citation": "⁴⁰",
          "preceding_text": "",
          "footnote": "Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).",
          "position": 54254
        },
        {
          "index": 41,
          "intext_citation": "⁴¹",
          "preceding_text": "",
          "footnote": "Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.",
          "position": 55756
        },
        {
          "index": 42,
          "intext_citation": "⁴²",
          "preceding_text": "",
          "footnote": "See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.",
          "position": 56749
        },
        {
          "index": 39,
          "intext_citation": "³⁹",
          "preceding_text": "",
          "footnote": "For a similar argument, see also Waxman (2011:442–443).",
          "position": 57305
        },
        {
          "index": 40,
          "intext_citation": "⁴⁰",
          "preceding_text": "",
          "footnote": "Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).",
          "position": 57364
        },
        {
          "index": 41,
          "intext_citation": "⁴¹",
          "preceding_text": "",
          "footnote": "Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.",
          "position": 57549
        },
        {
          "index": 42,
          "intext_citation": "⁴²",
          "preceding_text": "",
          "footnote": "See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.",
          "position": 57755
        }
      ],
      "flat_text": "International Studies Perspectives Advance Access published February 2, 2016\nInternational Studies Perspectives (2014) 0, 1-21\n# The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward\nAMIR LUPOVICI\nTel Aviv University\nMany scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and \"violence\" are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet\nThere is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic\nI am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082\n© The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nmeans that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a \"theoretical vacuum.\" More generally, Lindsay (2013:367) points out, \"Most work on international cyber security originates from the policy analysis community.\" Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace (Eriksson and Giacomello 2006; Dunn Cavelty 2008:7; Hansen and Nissenbaum 2009:1156).\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security (Saco 1999; Deibert 2002; Bendrath 2003; Yould 2003; Dunn Cavelty 2008, 2010, 2013; Hansen and Nissenbaum 2009; Deibert and Rohozinski 2010). However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence (Luke 1989; Williams 1992; Klein 1994; Tannenwald 2007; Adler 2009). This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of \"violence.\" Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\n\nAMIR LUPOVICI\n\n## Deterrence and Cyber(warfare) Scholarship and Its Challenges\nMost scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means (Wheatley and Hayes 1996:13, 19–20; Cordesman and Cordesman 2001:7; Kramer 2009:15–16; Kugler 2009:328; Morgan 2010:59, 68). However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger (Morgan 2003:15–20)—are difficult to meet when facing a cyberwarfare threat (Morgan 2010; Stevens 2012:149–153). Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders (Harknett 1996; Molander, Riddle, and Wilson 1996:87; Berkowitz 1997:183–184; Cordesman and Cordesman 2001:7; Arquilla 2003:210–213; Libicki 2007:272, 2009:1–3, 26, 44–45; Morgan 2010:55–76). However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.\n## What Do We Mean When We Say Cyber Deterrence?\nThe meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” (Stevens 2012:149–152). These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\nFor a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\nFor a detailed review of this scholarship, see also Lupovici (2011).\nGiven these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nan acceptable cost” (Libicki 2009:27–35). Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures. Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional. In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.\n## Who Are the Deterring Actors?\nOne implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\nSuch discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats (Wheatley and Hayes 1996:v–vi, 5–6; Molander et al. 1996:81–92). In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation (Libicki 2009:23–25). Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” (Lindsay 2013:372).\nTo some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\nThe same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\nMore fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).\nAMIR LUPOVICI\n\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\ndeterrence focus on state versus state interactions. Some scholars—for example, Libicki—provide rationales for focusing only on state actors (Libicki 2009:26); however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources. From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.\n## Intersections among Cyber and Kinetic Means\nConceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways, we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" (Libicki 2009:27; my emphasis). But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n Michael D. Horvath (March 2008) Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it (Lonsdale 2004:227; see also Kramer 2009:15, 20–23; Betz and Stevens 2011:105).\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law (Wheatley and Hayes 1996:13, 19–20; Kugler 2009:328, 335; Morgan 2010:68). Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace. In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests (Deibert and Rohozinski 2010; see also Nye 2011:207–208).\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility (Morgan 2003:20). In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”\n## The Need to Further Theorize Cyber Deterrence\nA second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n See also in Cordesman and Cordesman (2001:7).\n Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.\nAMIR LUPOVICI\n\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer (Deibert and Rohozinski 2010:22). After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed” (Saco 1999:290; see also Hansen and Nissenbaum 2009:1164–1165). In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process (Gorove 2000).\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined (Kramer 2009:12); in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted” (Libicki 2007:6). These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms (Freedman 2004; Tannenwald 2007), and discourse (Luke 1989; Klein 1994). Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality (Luke 1989:212), of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve (Hopf 1994:9–11; Milliken 1996:218, 228). Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting) (Tannenwald 2007).\nRid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\nFor further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nIn addition, the emerging scholarship on practices in IR helps to further elaborate on these issues, as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game” (Adler and Pouliot 2011:12–14, 18). For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized (Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim), forming a deterrence community (of practice) (Lupovici 2008:4).\n## Toward a Constructivist Approach to Cyber Deterrence\nWhile it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.\n## The Attribution Problem\nA large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it (Kello 2013:33; Lindsay 2013:378). Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).\nThe attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity (Libicki 2009:41–52; Betz and Stevens 2011:32, 88). Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack (Libicki 2009:41, 43).\n According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).\n Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).\nHowever, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design” (Lindsay 2013:375--376). In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification (Stevens 2012:164; but see Rid 2013:140--141). Even Libicki acknowledges such a scenario in the future (Libicki 2009:43). Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem (Lucas 2013:17--18). While deducing the identity of an attacker from their interests may sometimes be misleading (Libicki 2009:44), anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation ... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network” (Farwell and Rohozinski 2011:31). Likewise, Sterner suggests,\nThere appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US] ... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. (Sterner 2011:73)\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nThe \"attribution problem,\" then, becomes a legal, technical, or strategic challenge (Betz and Stevens 2011:32) through practice and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty. Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons \"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\" (Dipert 2010:393). While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.\nMy argument here is not that this situation is normatively desirable; rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice. Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.\n## The Social Construction of Violence\nViolence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed (Weldes 1999). The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that\nOn the role of practice in international law, see Brunnée and Toope (2011).\nA similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\nIn a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\nFor example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\nAs Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances \"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\" (2011:24–25).\nAMIR LUPOVICI\n\nSuch labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons (Morgan 2011:151). This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes. The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.\nSome scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered (Waxman 2011). This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force (Schmitt 1999:914–915). However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims,\nTraditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75)\nThe ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral\n One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).\n For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).\n The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nlevel. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare. Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified (Libicki 2009:179–180).\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar (Lawson 2012). This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar (Hansen and Nissenbaum 2009).\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible. Furthermore, in such cases, retaliation may be employed to address or preempt public demands (Adler 2010). All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors (Tang 2005:40–41).\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is\n An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).\n Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.\nAMIR LUPOVICI\n\nIt is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior” (Lewis 2010:4; see also Clarke and Knake 2010:253–254; Nye 2011:208). While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^[34]^\n## The Case of Stuxnet\nStuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^[36]^\nA number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^[38]^ He further contended that Israel would not attack\n^[34]On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n^[35]According to some estimations, Stuxnet was operative as early as 2005 (Rid 2013:32). Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet” (Langner 2013).\n^[36]For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n^[37]Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n^[38]On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nbecause \"it has already done so,\" as evidenced through the case of Stuxnet. Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack. A similar argument was advanced by Lindsay (2013:398), who suggested that the United States \"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\" In this respect, he argued that a covert cyber option was a useful solution.\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.\n## The Limited Influence of the Attribution Problem\nUsing the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the \"attribution problem\" exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand. Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack (Farwell and Rohozinski 2011:29). Indeed, some security analysts have considered Iranian threats in this regard to be credible (Kam 2012). This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.\nSecond, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013). In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n For a similar argument, see also Waxman (2011:442–443).\n Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.\nAMIR LUPOVICI\n\nTaking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.\n## The Effects of the Social Construction of Violence on Cyber Deterrence\nThe partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nA number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison\nMarkoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\nSee for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\nInterestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal (Sanger 2012).\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nDinniss 2012:81–82). However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives” (Sanger 2012). We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran, which may indicate, among other things, the fear of an Iranian retaliation.\nAssertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions” (Bednarz and Follath 2011). The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study\nHowever, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\nOn the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\nVerter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index (July 2012) Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\nFor a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).\nAMIR LUPOVICI\n\nAnother counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.\n## Conclusions\nIn this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this\n\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\n\nconcept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence."
    },
    "numeric": {
      "total": {
        "intext_total": 10,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "34",
          "intext_citation": "[34]",
          "preceding_text": "While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^",
          "footnote": null
        },
        {
          "index": "35",
          "intext_citation": "[35]",
          "preceding_text": "This attack was reported in June 2010,^",
          "footnote": null
        },
        {
          "index": "36",
          "intext_citation": "[36]",
          "preceding_text": "attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^",
          "footnote": null
        },
        {
          "index": "37",
          "intext_citation": "[37]",
          "preceding_text": "For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^",
          "footnote": null
        },
        {
          "index": "38",
          "intext_citation": "[38]",
          "preceding_text": "ence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^",
          "footnote": null
        },
        {
          "index": "34",
          "intext_citation": "[34]",
          "preceding_text": "^",
          "footnote": null
        },
        {
          "index": "35",
          "intext_citation": "[35]",
          "preceding_text": "^",
          "footnote": null
        },
        {
          "index": "36",
          "intext_citation": "[36]",
          "preceding_text": "^",
          "footnote": null
        },
        {
          "index": "37",
          "intext_citation": "[37]",
          "preceding_text": "^",
          "footnote": null
        },
        {
          "index": "38",
          "intext_citation": "[38]",
          "preceding_text": "^",
          "footnote": null
        }
      ],
      "flat_text": "International Studies Perspectives Advance Access published February 2, 2016\nInternational Studies Perspectives (2014) 0, 1-21\n# The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward¹\nAMIR LUPOVICI\nTel Aviv University\nMany scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and \"violence\" are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet\nThere is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic\n¹I am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082\n© The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nmeans that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a \"theoretical vacuum.\" More generally, Lindsay (2013:367) points out, \"Most work on international cyber security originates from the policy analysis community.\" Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace (Eriksson and Giacomello 2006; Dunn Cavelty 2008:7; Hansen and Nissenbaum 2009:1156).\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security (Saco 1999; Deibert 2002; Bendrath 2003; Yould 2003; Dunn Cavelty 2008, 2010, 2013; Hansen and Nissenbaum 2009; Deibert and Rohozinski 2010). However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence (Luke 1989; Williams 1992; Klein 1994; Tannenwald 2007; Adler 2009). This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of \"violence.\" Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\n2 As Dunn Cavelty argues, employing the concept of securitization is a notable exception to the tendency of cyber security studies to avoid integrating IR theories (Dunn Cavelty 2013:106).\n3 For example, scholars focus on the question of what the United States should do to enhance its deterrence posture in cyberspace, see Kramer (2009), Morgan (2010).\n4 See also Lupovici (2010).\nAMIR LUPOVICI\n3\nThe paper is structured as follows. The first section briefly reviews cyber deterrence scholarship and points to the advantages both of rethinking the term *cyber deterrence* and of using a constructivist approach to further theorize cyber deterrence scholarship. In the second section, and based on the suggested view of cyber deterrence, I will develop a constructivist approach that reveals the effects both of the “attribution problem” and of the social constructions of “violence” on deterrence failure and success. Finally, in the last section, I demonstrate the significance of these notions using the case of Stuxnet.\n## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges\nMost scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means (Wheatley and Hayes 1996:13, 19–20; Cordesman and Cordesman 2001:7; Kramer 2009:15–16; Kugler 2009:328; Morgan 2010:59, 68). However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger (Morgan 2003:15–20)⁶—are difficult to meet when facing a cyberwarfare threat (Morgan 2010; Stevens 2012:149–153). Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders (Harknett 1996; Molander, Riddle, and Wilson 1996:87; Berkowitz 1997:183–184; Cordesman and Cordesman 2001:7; Arquilla 2003:210–213; Libicki 2007:272, 2009:1–3, 26, 44–45; Morgan 2010:55–76).⁷ However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.\n## What Do We Mean When We Say Cyber Deterrence?\nThe meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” (Stevens 2012:149–152). These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\n⁵For a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\n⁶For a detailed review of this scholarship, see also Lupovici (2011).\n⁷Given these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nan acceptable cost” (Libicki 2009:27–35). Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.⁸\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures.⁹ Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional.¹⁰ In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.\n## Who Are the Deterring Actors?\nOne implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent¹¹ regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\n⁸Such discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats (Wheatley and Hayes 1996:v–vi, 5–6; Molander et al. 1996:81–92). In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation (Libicki 2009:23–25). Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” (Lindsay 2013:372).\n⁹To some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\n¹⁰The same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\n¹¹More fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).\nAMIR LUPOVICI\n5\n|  The Actor\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\ndeterrence focus on state versus state interactions.¹² Some scholars—for example, Libicki—provide rationales for focusing only on state actors (Libicki 2009:26); however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources.¹³ From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.\n## Intersections among Cyber and Kinetic Means\nConceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways,¹⁴ we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" (Libicki 2009:27; my emphasis). But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n¹² A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n¹³ Michael D. Horvath (March 2008) Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n¹⁴ See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it (Lonsdale 2004:227; see also Kramer 2009:15, 20–23; Betz and Stevens 2011:105).\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law (Wheatley and Hayes 1996:13, 19–20; Kugler 2009:328, 335; Morgan 2010:68).¹⁵ Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace.¹⁶ In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests (Deibert and Rohozinski 2010; see also Nye 2011:207–208).\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility (Morgan 2003:20). In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”\n## The Need to Further Theorize Cyber Deterrence\nA second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n¹⁵ See also in Cordesman and Cordesman (2001:7).\n¹⁶ Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.\nAMIR LUPOVICI\n7\nexplore changes in cyberspace and to encompass the variety of actors involved (Choucri 2012:15–16). While I build on these arguments, which are highly pertinent to moving cyber deterrence scholarship forward, I think that Choucri too quickly dismisses the potential of the constructivist approach in IR in her claims that it is not mature enough to make such a contribution and cannot address these precise issues. I argue the opposite: That integrating notions drawn from constructivist approaches will take the thinking and literature a step further. To better understand actors’ behavior, we need to acknowledge the existence of intersubjective understandings, that knowledge is socially constructed and that it is dependent on language and on the social context (Searle 1995:76–77; Adler 1997; Hopf 1998:199; Milliken 1999:229, 236).\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer (Deibert and Rohozinski 2010:22). After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed” (Saco 1999:290; see also Hansen and Nissenbaum 2009:1164–1165).¹⁷ In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process (Gorove 2000).\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined (Kramer 2009:12); in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted” (Libicki 2007:6). These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms (Freedman 2004; Tannenwald 2007), and discourse (Luke 1989; Klein 1994). Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality (Luke 1989:212), of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve (Hopf 1994:9–11; Milliken 1996:218, 228). Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting) (Tannenwald 2007).¹⁸\n¹⁷Rid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\n¹⁸For further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nIn addition, the emerging scholarship on practices in IR helps to further elaborate on these issues,¹⁹ as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game” (Adler and Pouliot 2011:12–14, 18).²⁰ For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized (Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim), forming a deterrence community (of practice) (Lupovici 2008:4).\n## Toward a Constructivist Approach to Cyber Deterrence\nWhile it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.\n## The Attribution Problem\nA large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it (Kello 2013:33; Lindsay 2013:378). Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).²¹\nThe attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity (Libicki 2009:41–52; Betz and Stevens 2011:32, 88). Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack (Libicki 2009:41, 43).\n¹⁹ According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n²⁰ Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).\n²¹ Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).\nHowever, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design” (Lindsay 2013:375--376). In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification (Stevens 2012:164; but see Rid 2013:140--141). Even Libicki acknowledges such a scenario in the future (Libicki 2009:43). Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem (Lucas 2013:17--18). While deducing the identity of an attacker from their interests may sometimes be misleading (Libicki 2009:44), anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation ... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network” (Farwell and Rohozinski 2011:31). Likewise, Sterner suggests,\nThere appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US] ... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. (Sterner 2011:73)\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nThe \"attribution problem,\" then, becomes a legal, technical, or strategic challenge (Betz and Stevens 2011:32) through practice²² and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty.²³ Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons \"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\" (Dipert 2010:393). While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.²⁴\nMy argument here is not that this situation is normatively desirable;²⁵ rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice.²⁶ Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.\n## The Social Construction of Violence\nViolence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed (Weldes 1999). The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that\n²²On the role of practice in international law, see Brunnée and Toope (2011).\n²³A similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\n²⁴In a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\n²⁵For example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\n²⁶As Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances \"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\" (2011:24–25).\nAMIR LUPOVICI\n11\nsomething is an existential threat (Buzan, Waever and Wilde 1998:30–31; Balzacq 2011). Violence can be seen in a similar way—as a social construction that, such as securitization, depends on a social process, can be accepted or rejected by a target audience, is related to language (that is, use of the term *violence*), and affects the legitimacy of how to act in response to a challenge.²⁷\nSuch labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons (Morgan 2011:151). This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes.²⁸ The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.²⁹\nSome scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered (Waxman 2011). This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force (Schmitt 1999:914–915).³⁰ However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims,\nTraditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75)\nThe ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral\n²⁷ One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n²⁸ For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).\n²⁹ For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).\n³⁰ The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nlevel. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare.³¹ Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified (Libicki 2009:179–180).\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar (Lawson 2012).³² This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar (Hansen and Nissenbaum 2009).\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible.³³ Furthermore, in such cases, retaliation may be employed to address or preempt public demands (Adler 2010). All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors (Tang 2005:40–41).\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is\n³¹ An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n³² In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).\n³³ Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.\nAMIR LUPOVICI\n13\nnot seen as violent, more limitations, both domestic and international, are placed upon executing a retaliatory attack, burdening deterrence credibility. For example, Waxman suggests that restricting the definition of armed attacks to include only severe cyberwarfare attacks will undermine American deterrence vis-à-vis lower levels of cyber-attacks (Waxman 2011:439). Likewise, Dunn Cavelty argues that during the Kosovo War, American plans to retaliate against a potential Serbian computer attack were rejected out of fear that they would be considered war crimes (Dunn Cavelty 2008:79). In addition, in such contexts—in which cyber means are not seen as violent—the needs arising from the “cult of reputation” and from the desire of actors to preserve their deterrent posture are less prominent, enabling defender actors to contain or ignore them. In cases where it is questionable whether cyber-attacks are acts of violence, a putative challenger will estimate that initiating a cyber-attack will be less likely to result in retaliation, an assumption that may weaken the perceived deterrent posture. Furthermore, given the difficulties in retaliating to a challenge seen as “nonviolent,” actors may divert their activity to such means if they fear the (more traditional) challenge they consider inflicting upon their opponent will yield a retaliatory attack with kinetic means (for example, with air, ground forces). In other words, more traditional deterrent threats may lead actors to use cyber means. This, of course, does not imply that deterrence of “nonviolent” means is doomed to fail, but, other factors being equal (such as the degree of harm), deterrence of such means is more difficult.\nIt is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior” (Lewis 2010:4; see also Clarke and Knake 2010:253–254; Nye 2011:208). While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^^\n## The Case of Stuxnet\nStuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^^\nA number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^^ He further contended that Israel would not attack\n^On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n^According to some estimations, Stuxnet was operative as early as 2005 (Rid 2013:32). Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet” (Langner 2013).\n^For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n^Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n^On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nbecause \"it has already done so,\" as evidenced through the case of Stuxnet.³⁹ Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack.⁴⁰ A similar argument was advanced by Lindsay (2013:398), who suggested that the United States \"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\" In this respect, he argued that a covert cyber option was a useful solution.\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.\n## The Limited Influence of the Attribution Problem\nUsing the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the \"attribution problem\" exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack (Farwell and Rohozinski 2011:29). Indeed, some security analysts have considered Iranian threats in this regard to be credible (Kam 2012). This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.\nSecond, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013).⁴² In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n³⁹ For a similar argument, see also Waxman (2011:442–443).\n⁴⁰ Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n⁴¹ Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n⁴² See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.\nAMIR LUPOVICI\n15\nThird, anonymity is not necessarily a problem because even when victims do not have clear evidence, in most cases, the identity of the attackers can be concluded from the context. With regard to Stuxnet, there were some hints pointing to the identity of the actors behind it.⁴³ While these were perhaps false flags that aimed to associate Israel, for example, with the attack (see in Lindsay 2013: ftn, 16, pp. 400–401), other indications point more directly to American and Israeli involvement.⁴⁴ Furthermore, as discussed by Harrison Dinniss (2012:37), Ahmadinejad blamed the West and Israel for being behind the attacks. In other words, not only did the Iranian authorities know that the nuclear facility at Natanz was attacked,⁴⁵ they publicly pointed to its alleged suspects. Indeed, while Stuxnet operated clandestinely for a period of time (Langner 2013) and successfully sabotaged the Iranian nuclear program, the main question is why, after it and the extent of its damage were revealed, there was no retaliation—despite the threats to respond if the Iranian nuclear program were attacked. In fact, as Langner argues, at some point, the “attacks should have been recognizable by plant floor staff just by the old eardrum.” This fact, according to Langner, emphasizes that the makers of Stuxnet were willing to accept the risk of its detection (Langner 2013). It also further challenges the argument that anonymity was the main reason for diverting the attack to cyberspace. Saeed Jalili, who served as Iranian secretary of the Supreme National Security Council, publicly admitted in January 2011 that “our experts already warded off this attack a long time ago” (Bednarz and Follath 2011). However, by stating this, he also implied that despite experiencing an attack and despite the time that had passed, Iran had not retaliated.\nTaking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.\n## The Effects of the Social Construction of Violence on Cyber Deterrence\nThe partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nA number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison\n⁴³Markoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\n⁴⁴See for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\n⁴⁵Interestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal (Sanger 2012).\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nDinniss 2012:81–82).⁴⁶ However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial⁴⁷—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives” (Sanger 2012). We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran,⁴⁸ which may indicate, among other things, the fear of an Iranian retaliation.⁴⁹\nAssertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions” (Bednarz and Follath 2011). The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study\n⁴⁶However, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\n⁴⁷On the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\n⁴⁸Verter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index (July 2012) Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\n⁴⁹For a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).\nAMIR LUPOVICI\n17\nregarding how social conventions about violence affect the manner in which even a target of such an attack refers to it. Furthermore, this also further confirms the assertions made above regarding the advantages in diverting the activity to cyberspace, wherein the cost of attack is lower.\nAnother counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.\n## Conclusions\nIn this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this\n50 In fact, the “easy” case for the emergence of such a treaty will be following events in which a cyber-attack causes substantial physical damage.\n51 BBC (2010) Iran Says Nuclear Programme Was Hit by Sabotage. *BBC*, November 29. Available at: http://www.bbc.co.uk/news/world-middle-east-11868596. Similarly, Kello (2013:27) argues that the Iranian response to Stuxnet has been muted.\n52 Mehr News Agency (2011) Iran to Take Pre-Emptive Action against Cyber Terrorism. *Mehr News Agency*, February 26. Available at: http://seclists.org/isn/2011/Feb/95.\n53 *Iran Times* (2011) Pasdar Officer Says Iran Set to Launch Cyber Attacks. *Iran Times*, March 25. Available at: http://iran-times.com/pasdar-officer-says-iran-set-to-launch-cyber-attacks.\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016\n18 The \"Attribution Problem\" and the Social Construction of \"Violence\"\nconcept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence."
    },
    "author_year": {
      "total": {
        "intext_total": 74,
        "success_occurrences": 74,
        "success_unique": 48,
        "bib_unique_total": 136,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.35294117647058826,
        "success_percentage": 100.0,
        "style": "author_year"
      },
      "results": [
        {
          "index": "eriksson|2006",
          "intext_citation": "(Eriksson and Giacomello 2006; Dunn Cavelty 2008:7; Hansen and Nissenbaum 2009:1156)",
          "preceding_text": "erally, Lindsay (2013:367) points out, \"Most work on international cyber security originates from the policy analysis community.\" Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace",
          "footnote": "ERIKSSON, JOHAN, AND GIAMPIERO GIACOMELLO. (2006) The Information Revolution, Security, and International Relations: (IR)Relevant Theory? International Political Science Review 27 (3): 221–244."
        },
        {
          "index": "saco|1999",
          "intext_citation": "(Saco 1999; Deibert 2002; Bendrath 2003; Yould 2003; Dunn Cavelty 2008, 2010, 2013; Hansen and Nissenbaum 2009; Deibert and Rohozinski 2010)",
          "preceding_text": "Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security",
          "footnote": "SACO, DIANA. (1999) Colonizing Cyberspace: National Security and the Internet. In *Cultures of Insecurity: States, Communities and the Production of Danger*, edited by Jutta Weldes, Mark Laffey, Hugh Gusterson, and Raymond Duvall. Minneapolis: University of Minnesota Press."
        },
        {
          "index": "luke|1989",
          "intext_citation": "(Luke 1989; Williams 1992; Klein 1994; Tannenwald 2007; Adler 2009)",
          "preceding_text": "Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence",
          "footnote": "LUKE, W. TIMOTHY. (1989) What's Wrong with Deterrence? A Semiotic Interpretation of National Security Policy. In International/Intertextual Relations, edited by James Der Derian and Michael J. Shapiro. New York: Lexington Books."
        },
        {
          "index": "wheatley|1996",
          "intext_citation": "(Wheatley and Hayes 1996:13, 19–20; Cordesman and Cordesman 2001:7; Kramer 2009:15–16; Kugler 2009:328; Morgan 2010:59, 68)",
          "preceding_text": "nt in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means",
          "footnote": "WHEATLEY, GARY F., AND E. RICHARD HAYES. (1996) *Information Warfare and Deterrence*. Washington: National Defense University Press."
        },
        {
          "index": "morgan|2003",
          "intext_citation": "(Morgan 2003:15–20)",
          "preceding_text": "Most scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger",
          "footnote": "MORGAN, M. PATRICK. (2003) *Deterrence Now*. New York: Cambridge University Press."
        },
        {
          "index": "morgan|2010",
          "intext_citation": "(Morgan 2010; Stevens 2012:149–153)",
          "preceding_text": "Most scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger (Morgan 2003:15–20)⁶—are difficult to meet when facing a cyberwarfare threat",
          "footnote": "MORGAN, M. PATRICK. (2010) Applicability of Traditional Deterrence Concepts and Theory to the Cyber Realm. In *Proceedings of a Workshop on Deterring Cyberattacks*, edited by John D. Steinbruner, et al. Washington, DC: The National Academies."
        },
        {
          "index": "harknett|1996",
          "intext_citation": "(Harknett 1996; Molander, Riddle, and Wilson 1996:87; Berkowitz 1997:183–184; Cordesman and Cordesman 2001:7; Arquilla 2003:210–213; Libicki 2007:272, 2009:1–3, 26, 44–45; Morgan 2010:55–76)",
          "preceding_text": "they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders",
          "footnote": "HARKNETT, J. RICHARD. (1996) Information Warfare and Deterrence. Parameters 26 (3): 93–107."
        },
        {
          "index": "stevens|2012",
          "intext_citation": "(Stevens 2012:149–152)",
          "preceding_text": "ed to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services”",
          "footnote": "STEVENS, TIM. (2012) A Cyberwar of Ideas? Deterrence and Norms in Cyberspace. *Contemporary Security Policy* 33 (1): 148–170."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:27–35)",
          "preceding_text": "an acceptable cost”",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "wheatley|1996",
          "intext_citation": "(Wheatley and Hayes 1996:v–vi, 5–6; Molander et al. 1996:81–92)",
          "preceding_text": "dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats",
          "footnote": "WHEATLEY, GARY F., AND E. RICHARD HAYES. (1996) *Information Warfare and Deterrence*. Washington: National Defense University Press."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:23–25)",
          "preceding_text": "Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "lindsay|2013",
          "intext_citation": "(Lindsay 2013:372)",
          "preceding_text": "23–25). Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain”",
          "footnote": "LINDSAY, R. JON. (2013) Stuxnet and the Limits of Cyber Warfare. Security Studies 22 (3): 365-404."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:26)",
          "preceding_text": "deterrence focus on state versus state interactions.¹² Some scholars—for example, Libicki—provide rationales for focusing only on state actors",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:27; my emphasis)",
          "preceding_text": "needs to develop a capability in cyberspace to do unto others what others may want to do unto us\"",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "lonsdale|2004",
          "intext_citation": "(Lonsdale 2004:227; see also Kramer 2009:15, 20–23; Betz and Stevens 2011:105)",
          "preceding_text": "es other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it",
          "footnote": "LONSDALE, DAVID J. (2004) The Nature of War in the Information Age: Clausewitzian Future. Oxon: Routledge."
        },
        {
          "index": "wheatley|1996",
          "intext_citation": "(Wheatley and Hayes 1996:13, 19–20; Kugler 2009:328, 335; Morgan 2010:68)",
          "preceding_text": "need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law",
          "footnote": "WHEATLEY, GARY F., AND E. RICHARD HAYES. (1996) *Information Warfare and Deterrence*. Washington: National Defense University Press."
        },
        {
          "index": "deibert|2010",
          "intext_citation": "(Deibert and Rohozinski 2010; see also Nye 2011:207–208)",
          "preceding_text": "actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests",
          "footnote": "DEIBERT, RON, AND RAFAL ROHOZINSKI. (2010) Risking Security: The Policies and Paradoxes of Cyberspace Security. International Political Sociology 4 (1): 15–32."
        },
        {
          "index": "morgan|2003",
          "intext_citation": "(Morgan 2003:20)",
          "preceding_text": "Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility",
          "footnote": "MORGAN, M. PATRICK. (2003) *Deterrence Now*. New York: Cambridge University Press."
        },
        {
          "index": "choucri|2012",
          "intext_citation": "(Choucri 2012:15–16)",
          "preceding_text": "explore changes in cyberspace and to encompass the variety of actors involved",
          "footnote": "CHOUCKI, NAZLI. (2012) Cyberpolitics in International Relations. Cambridge, MA: MIT Press."
        },
        {
          "index": "searle|1995",
          "intext_citation": "(Searle 1995:76–77; Adler 1997; Hopf 1998:199; Milliken 1999:229, 236)",
          "preceding_text": "ke the thinking and literature a step further. To better understand actors’ behavior, we need to acknowledge the existence of intersubjective understandings, that knowledge is socially constructed and that it is dependent on language and on the social context",
          "footnote": "SEARLE, JOHN R. (1995) *The Construction of Social Reality*. London: Penguin."
        },
        {
          "index": "deibert|2010",
          "intext_citation": "(Deibert and Rohozinski 2010:22)",
          "preceding_text": "cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer",
          "footnote": "DEIBERT, RON, AND RAFAL ROHOZINSKI. (2010) Risking Security: The Policies and Paradoxes of Cyberspace Security. International Political Sociology 4 (1): 15–32."
        },
        {
          "index": "saco|1999",
          "intext_citation": "(Saco 1999:290; see also Hansen and Nissenbaum 2009:1164–1165)",
          "preceding_text": "Such dichotomies can be misleading, however, in part because all social space is socially constructed”",
          "footnote": "SACO, DIANA. (1999) Colonizing Cyberspace: National Security and the Internet. In *Cultures of Insecurity: States, Communities and the Production of Danger*, edited by Jutta Weldes, Mark Laffey, Hugh Gusterson, and Raymond Duvall. Minneapolis: University of Minnesota Press."
        },
        {
          "index": "gorove|2000",
          "intext_citation": "(Gorove 2000)",
          "preceding_text": "90; see also Hansen and Nissenbaum 2009:1164–1165).¹⁷ In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process",
          "footnote": "GOROVE, M. KATHERINE. (2000) Delimitation of Outer Space and the Aerospace Object—Where Is the Law? Journal of Space Law 28 (1): 11–28."
        },
        {
          "index": "kramer|2009",
          "intext_citation": "(Kramer 2009:12)",
          "preceding_text": "As Kramer explains, the meaning of cyberspace should be socially determined",
          "footnote": "KRAMER, D. FRANKLIN. (2009) Cyberpower and National Security: Policy Recommendations for a Strategic Framework. In *Cyberpower and National Security*, edited by Franklin D. Kramer, Stuart H. Starr, and Larry K. Wentz. Washington, DC: National Defense University Press."
        },
        {
          "index": "libicki|2007",
          "intext_citation": "(Libicki 2007:6)",
          "preceding_text": "In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted”",
          "footnote": "LIBICKI, C. MARTIN. (2007) Conquest in Cyberspace. Cambridge: Cambridge University Press."
        },
        {
          "index": "williams|1992",
          "intext_citation": "(Williams 1992; Adler 2009)",
          "preceding_text": "These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge",
          "footnote": "WILLIAMS, C. MICHAEL. (1992) Rethinking the “Logic” of Deterrence. *Alternatives* 17 (1): 67–93."
        },
        {
          "index": "freedman|2004",
          "intext_citation": "(Freedman 2004; Tannenwald 2007)",
          "preceding_text": "These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms",
          "footnote": "FREEDMAN, LAWRENCE. (2004) Deterrence. Cambridge: Polity Press."
        },
        {
          "index": "luke|1989",
          "intext_citation": "(Luke 1989; Klein 1994)",
          "preceding_text": "These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms (Freedman 2004; Tannenwald 2007), and discourse",
          "footnote": "LUKE, W. TIMOTHY. (1989) What's Wrong with Deterrence? A Semiotic Interpretation of National Security Policy. In International/Intertextual Relations, edited by James Der Derian and Michael J. Shapiro. New York: Lexington Books."
        },
        {
          "index": "luke|1989",
          "intext_citation": "(Luke 1989:212)",
          "preceding_text": "These include the social constructions of rationality",
          "footnote": "LUKE, W. TIMOTHY. (1989) What's Wrong with Deterrence? A Semiotic Interpretation of National Security Policy. In International/Intertextual Relations, edited by James Der Derian and Michael J. Shapiro. New York: Lexington Books."
        },
        {
          "index": "hopf|1994",
          "intext_citation": "(Hopf 1994:9–11; Milliken 1996:218, 228)",
          "preceding_text": "strategy and the chances of its success. These include the social constructions of rationality (Luke 1989:212), of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve",
          "footnote": "HOPF, TED. (1994) Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965–1990. Ann Arbor: University of Michigan Press."
        },
        {
          "index": "tannenwald|2007",
          "intext_citation": "(Tannenwald 2007)",
          "preceding_text": ". Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting)",
          "footnote": "TANNENWALD, NINA. (2007) *The Nuclear Taboo: The United States and the Non-Use of Nuclear Weapons*. New York: Cambridge University Press."
        },
        {
          "index": "adler|2011",
          "intext_citation": "(Adler and Pouliot 2011:12–14, 18)",
          "preceding_text": "In other words, practices create and shape norms, conventions, and the “rules of game”",
          "footnote": "ADLER, EMANUEL, AND VINCENT POULIOT. (2011) International Practices. *International Theory* 3 (1): 1–36."
        },
        {
          "index": "adler|2011",
          "intext_citation": "(Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim)",
          "preceding_text": "and shape norms, conventions, and the “rules of game” (Adler and Pouliot 2011:12–14, 18).²⁰ For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized",
          "footnote": "ADLER, EMANUEL, AND VINCENT POULIOT. (2011) International Practices. *International Theory* 3 (1): 1–36."
        },
        {
          "index": "lupovici|2008",
          "intext_citation": "(Lupovici 2008:4)",
          "preceding_text": "lars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized (Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim), forming a deterrence community (of practice)",
          "footnote": "LUPOVICI, AMIR. (2008) Deterrence Communities: The Success of a Rational Norm in the Relations of the Superpowers, 1950-1973. PhD Thesis, The Hebrew University, Jerusalem [in Hebrew]."
        },
        {
          "index": "kello|2013",
          "intext_citation": "(Kello 2013:33; Lindsay 2013:378)",
          "preceding_text": "Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it",
          "footnote": "KELLO, LUCAS. (2013) The Meaning of the Cyber Revolution: Perils to Theory and Statecraft. International Security 38 (2): 7-40."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:41–52; Betz and Stevens 2011:32, 88)",
          "preceding_text": "First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:41, 43)",
          "preceding_text": "These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "adler|2011",
          "intext_citation": "(Adler and Pouliot 2011:20)",
          "preceding_text": "²⁰ Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share”",
          "footnote": "ADLER, EMANUEL, AND VINCENT POULIOT. (2011) International Practices. *International Theory* 3 (1): 1–36."
        },
        {
          "index": "lindsay|2013",
          "intext_citation": "(Lindsay 2013:375--376)",
          "preceding_text": "e anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design”",
          "footnote": "LINDSAY, R. JON. (2013) Stuxnet and the Limits of Cyber Warfare. Security Studies 22 (3): 365-404."
        },
        {
          "index": "stevens|2012",
          "intext_citation": "(Stevens 2012:164; but see Rid 2013:140--141)",
          "preceding_text": "For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification",
          "footnote": "STEVENS, TIM. (2012) A Cyberwar of Ideas? Deterrence and Norms in Cyberspace. *Contemporary Security Policy* 33 (1): 148–170."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:43)",
          "preceding_text": "Even Libicki acknowledges such a scenario in the future",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "lucas|2013",
          "intext_citation": "(Lucas 2013:17--18)",
          "preceding_text": "Third, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem",
          "footnote": "LUCAS, R. GEORGE JR. (2013) Can There Be an Ethical Cyber War? In Conflict and Cooperation in Cyberspace: The Challenge to National Security, edited by Panayotis A. Yannakogeorgos and Adam Lowther. Boca Raton, FL: Taylor &amp; Francis."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:44)",
          "preceding_text": "While deducing the identity of an attacker from their interests may sometimes be misleading",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "farwell|2011",
          "intext_citation": "(Farwell and Rohozinski 2011:31)",
          "preceding_text": "[in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network”",
          "footnote": "FARWELL, JAMES P., AND RAFAL ROHOZINSKI. (2011) Stuxnet and the Future of Cyber War. Survival 53 (1): 23–40."
        },
        {
          "index": "sterner|2011",
          "intext_citation": "(Sterner 2011:73)",
          "preceding_text": "But, the challenge [is that the US] ... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain.",
          "footnote": "STERNER, ERIC. (2011) Retaliatory Deterrence in Cyberspace. *Strategic Studies Quarterly* 5 (1): 62–80."
        },
        {
          "index": "betz|2011",
          "intext_citation": "(Betz and Stevens 2011:32)",
          "preceding_text": "The \"attribution problem,\" then, becomes a legal, technical, or strategic challenge",
          "footnote": "BETZ, DAVID J., AND TIM STEVENS. (2011) Cyberspace and the State: Toward a Strategy for Cyber-Power. Oxon: Routledge."
        },
        {
          "index": "dipert|2010",
          "intext_citation": "(Dipert 2010:393)",
          "preceding_text": "He argues that for consequentialist reasons \"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\"",
          "footnote": "DIPERT, R. RANDALL. (2010) The Ethics of Cyberwarfare. Journal of Military Ethics 9 (4): 384–410."
        },
        {
          "index": "weldes|1999",
          "intext_citation": "(Weldes 1999)",
          "preceding_text": "Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed",
          "footnote": "WELDES, JUTTA. (1999) *Constructing National Interests. The United States and the Cuban Missile Crisis*. Minneapolis: University of Minnesota Press."
        },
        {
          "index": "morgan|2011",
          "intext_citation": "(Morgan 2011:151)",
          "preceding_text": "e constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons",
          "footnote": "MORGAN, M. PATRICK. (2011) The Practice of Deterrence. In *International Practices*, edited by Emanuel Adler and Vincent Pouliot. New York: Cambridge University Press."
        },
        {
          "index": "waxman|2011",
          "intext_citation": "(Waxman 2011)",
          "preceding_text": "While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered",
          "footnote": "WAXMAN, C. MATTHEW. (2011) Cyberattacks and the Use of Force: Back to the Future of Article 2(4). *Yale Journal of International Law* 36 (2): 421–459."
        },
        {
          "index": "schmitt|1999",
          "intext_citation": "(Schmitt 1999:914–915)",
          "preceding_text": "within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force",
          "footnote": "SCHMITT, N. MICHAEL. (1999) Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework. *Columbia Journal of Transnational Law* 37: 885–937."
        },
        {
          "index": "neumann|1998",
          "intext_citation": "(Neumann 1998)",
          "preceding_text": "²⁷ One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war",
          "footnote": "NEUMANN, B. IVER. (1998) Identity and the Outbreak of War: Or Why the Copenhagen School of Security Studies Should Include the Idea of “Violisation” in Its Framework of Analysis. *International Journal of Peace Studies* 3: 7–22."
        },
        {
          "index": "falk|1989",
          "intext_citation": "(Falk 1989:68; Johnston 1995:32, 41, 61–62)",
          "preceding_text": "ample, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting",
          "footnote": "FALK, JIM. (1989) The Discursive Shaping of Nuclear Militarism. Current Research on Peace and Violence 12 (2): 53–76."
        },
        {
          "index": "tannenwald|2007",
          "intext_citation": "(Tannenwald 2007)",
          "preceding_text": "²⁹ For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence",
          "footnote": "TANNENWALD, NINA. (2007) *The Nuclear Taboo: The United States and the Non-Use of Nuclear Weapons*. New York: Cambridge University Press."
        },
        {
          "index": "adler|1992",
          "intext_citation": "(Adler 1992)",
          "preceding_text": "²⁹ For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard",
          "footnote": "ADLER, EMANUEL. (1992) The Emergence of Cooperation: National Epistemic Communities and the International Evolution of the Idea of Nuclear Arms Control. *International Organization* 46 (1): 101–145."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009:179–180)",
          "preceding_text": "harter and the lack of a global treaty on cyberwarfare.³¹ Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified",
          "footnote": "LIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "lawson|2012",
          "intext_citation": "(Lawson 2012)",
          "preceding_text": "actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar",
          "footnote": "LAWSON, SEAN. (2012) Putting the \"War\" in Cyber War: Metaphor, Analogy, and Cyber Security Discourse in the United States. First Monday 17 (7). Available at: http://firstmonday.org/ojs/index.php/fm/article/view/3848/3270."
        },
        {
          "index": "hansen|2009",
          "intext_citation": "(Hansen and Nissenbaum 2009)",
          "preceding_text": "For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar",
          "footnote": "HANSEN, LENE, AND HELEN NISSENBAUM. (2009) Digital Disaster, Cyber Security, and the Copenhagen School. International Studies Quarterly 53 (4): 1155–1173."
        },
        {
          "index": "adler|2010",
          "intext_citation": "(Adler 2010)",
          "preceding_text": "om policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible.³³ Furthermore, in such cases, retaliation may be employed to address or preempt public demands",
          "footnote": "ADLER, EMANUEL. (2010) Damned If You Do, Damned If You Don’t: Performative Power and the Strategy of Conventional and Nuclear Defusing. *Security Studies* 19 (2): 199–229."
        },
        {
          "index": "tang|2005",
          "intext_citation": "(Tang 2005:40–41)",
          "preceding_text": "em holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors",
          "footnote": "TANG, SHIPING. (2005) Reputation, Cult of Reputation, and International Conflict. *Security Studies* 14 (1): 34–61."
        },
        {
          "index": "stone|2013",
          "intext_citation": "(Stone 2013:104)",
          "preceding_text": "As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality”",
          "footnote": "STONE, JOHN. (2013) Cyber War Will Take Place! *Journal of Strategic Studies* 36 (1): 101–108."
        },
        {
          "index": "fearon|2002",
          "intext_citation": "(Fearon 2002:13–16)",
          "preceding_text": "In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails",
          "footnote": "FEARON, JAMES. (2002) Selection Effects and Deterrence. International Interactions 28 (1): 5–29."
        },
        {
          "index": "waxman|2011",
          "intext_citation": "(Waxman 2011:439)",
          "preceding_text": "For example, Waxman suggests that restricting the definition of armed attacks to include only severe cyberwarfare attacks will undermine American deterrence vis-à-vis lower levels of cyber-attacks",
          "footnote": "WAXMAN, C. MATTHEW. (2011) Cyberattacks and the Use of Force: Back to the Future of Article 2(4). *Yale Journal of International Law* 36 (2): 421–459."
        },
        {
          "index": "lewis|2010",
          "intext_citation": "(Lewis 2010:4; see also Clarke and Knake 2010:253–254; Nye 2011:208)",
          "preceding_text": "in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior”",
          "footnote": "LEWIS, A. JAMES. (2010) Cross-Domain Deterrence and Credible Threats. Washington, DC: Center for Strategic and International Studies."
        },
        {
          "index": "rid|2013",
          "intext_citation": "(Rid 2013:32)",
          "preceding_text": "^[35]According to some estimations, Stuxnet was operative as early as 2005",
          "footnote": "RID, THOMAS. (2013) *Cyber War Will Not Take Place*. London: Hurst."
        },
        {
          "index": "langner|2013",
          "intext_citation": "(Langner 2013)",
          "preceding_text": "Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet”",
          "footnote": "LANGNER, RALPH. (2013) Stuxnet's Secret Twin. Foreign Policy. Available at: http://www.foreignpolicy.com/articles/2013/11/19/stuxnets_secret_twin_iran_nukes_cyber_attack."
        },
        {
          "index": "farwell|2011",
          "intext_citation": "(Farwell and Rohozinski 2011:29)",
          "preceding_text": "te against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack",
          "footnote": "FARWELL, JAMES P., AND RAFAL ROHOZINSKI. (2011) Stuxnet and the Future of Cyber War. Survival 53 (1): 23–40."
        },
        {
          "index": "kam|2012",
          "intext_citation": "(Kam 2012)",
          "preceding_text": "Indeed, some security analysts have considered Iranian threats in this regard to be credible",
          "footnote": "KAM, EPHRAIM. (2012) An Attack on Iran: The Morning After. Strategic Assessment 15 (1): 15-27."
        },
        {
          "index": "langner|2013",
          "intext_citation": "(Langner 2013)",
          "preceding_text": "Indeed, while Stuxnet operated clandestinely for a period of time",
          "footnote": "LANGNER, RALPH. (2013) Stuxnet's Secret Twin. Foreign Policy. Available at: http://www.foreignpolicy.com/articles/2013/11/19/stuxnets_secret_twin_iran_nukes_cyber_attack."
        },
        {
          "index": "langner|2013",
          "intext_citation": "(Langner 2013)",
          "preceding_text": "acked. In fact, as Langner argues, at some point, the “attacks should have been recognizable by plant floor staff just by the old eardrum.” This fact, according to Langner, emphasizes that the makers of Stuxnet were willing to accept the risk of its detection",
          "footnote": "LANGNER, RALPH. (2013) Stuxnet's Secret Twin. Foreign Policy. Available at: http://www.foreignpolicy.com/articles/2013/11/19/stuxnets_secret_twin_iran_nukes_cyber_attack."
        },
        {
          "index": "bednarz|2011",
          "intext_citation": "(Bednarz and Follath 2011)",
          "preceding_text": "Saeed Jalili, who served as Iranian secretary of the Supreme National Security Council, publicly admitted in January 2011 that “our experts already warded off this attack a long time ago”",
          "footnote": "BEDNARZ, DIETER, AND ERICH FOLLATH. (2011) Iran’s Chief Nuclear Negotiator: “We Have to Be Constantly on Guard.” Der Spiegel, January 18. Available at: http://www.spiegel.de/international/world/iran-s-chief-nuclear-negotiator-we-have-to-be-constantly-on-guard-a-739945.html"
        },
        {
          "index": "sanger|2012",
          "intext_citation": "(Sanger 2012)",
          "preceding_text": "⁴⁵Interestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal",
          "footnote": "SANGER, DAVID. (2012) Obama Order Sped Up Wave of Cyberattacks Against Iran. *New York Times*, June 1. Available at: http://www.nytimes.com/2012/06/01/world/middleeast/obama-ordered-wave-of-cyberattacks-against-iran.html?pagewanted=all&amp;_r=0."
        },
        {
          "index": "sanger|2012",
          "intext_citation": "(Sanger 2012)",
          "preceding_text": "given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives”",
          "footnote": "SANGER, DAVID. (2012) Obama Order Sped Up Wave of Cyberattacks Against Iran. *New York Times*, June 1. Available at: http://www.nytimes.com/2012/06/01/world/middleeast/obama-ordered-wave-of-cyberattacks-against-iran.html?pagewanted=all&amp;_r=0."
        },
        {
          "index": "bednarz|2011",
          "intext_citation": "(Bednarz and Follath 2011)",
          "preceding_text": "Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions”",
          "footnote": "BEDNARZ, DIETER, AND ERICH FOLLATH. (2011) Iran’s Chief Nuclear Negotiator: “We Have to Be Constantly on Guard.” Der Spiegel, January 18. Available at: http://www.spiegel.de/international/world/iran-s-chief-nuclear-negotiator-we-have-to-be-constantly-on-guard-a-739945.html"
        }
      ],
      "flat_text": "International Studies Perspectives Advance Access published February 2, 2016 International Studies Perspectives (2014) 0, 1-21 # The\"Attribution Problem\"and the Social Construction of\"Violence\": Taking Cyber Deterrence Literature a Step Forward¹ AMIR LUPOVICI Tel Aviv University Many scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and\"violence\"are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet There is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic ¹I am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The\"Attribution Problem\"and the Social Construction of\"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082 © The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com The\"Attribution Problem\"and the Social Construction of\"Violence\"means that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a\"theoretical vacuum.\"More generally, Lindsay (2013:367) points out,\"Most work on international cyber security originates from the policy analysis community.\"Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace.\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security. However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence. This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of\"violence.\"Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\n\nAMIR LUPOVICI\n\n## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges\nMost scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means . However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger ⁶—are difficult to meet when facing a cyberwarfare threat . Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders .⁷ However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.\n## What Do We Mean When We Say Cyber Deterrence?\nThe meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” . These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\n⁵For a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\n⁶For a detailed review of this scholarship, see also Lupovici (2011).\n⁷Given these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nan acceptable cost” . Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.⁸\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures.⁹ Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional.¹⁰ In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.\n## Who Are the Deterring Actors?\nOne implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent¹¹ regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\n⁸Such discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats . In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation . Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” .\n⁹To some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\n¹⁰The same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\n¹¹More fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).\nAMIR LUPOVICI\n\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\ndeterrence focus on state versus state interactions.¹² Some scholars—for example, Libicki—provide rationales for focusing only on state actors ; however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources.¹³ From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.\n## Intersections among Cyber and Kinetic Means\nConceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways,¹⁴ we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" . But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n¹² A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n¹³ Michael D. Horvath  Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n¹⁴ See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).\nThe \"Attribution Problem\" and the Social Construction of \"Violence\"\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it .\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law .¹⁵ Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace.¹⁶ In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests .\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility . In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”\n## The Need to Further Theorize Cyber Deterrence\nA second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n¹⁵ See also in Cordesman and Cordesman (2001:7).\n¹⁶ Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.\nAMIR LUPOVICI\n\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer. After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed”.¹⁷ In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process.\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined; in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted”. These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge, norms, and discourse. Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality, of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve. Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting).¹⁸ ¹⁷Rid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\n¹⁸For further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).\nThe\"Attribution Problem\"and the Social Construction of\"Violence\"In addition, the emerging scholarship on practices in IR helps to further elaborate on these issues,¹⁹ as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game”.²⁰ For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized, forming a deterrence community (of practice).\n## Toward a Constructivist Approach to Cyber Deterrence While it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.\n## The Attribution Problem A large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it. Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).²¹ The attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity. Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack.\n¹⁹ According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n²⁰ Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share”.\n²¹ Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).\nHowever, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design”. In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification. Even Libicki acknowledges such a scenario in the future. Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem. While deducing the identity of an attacker from their interests may sometimes be misleading, anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network”. Likewise, Sterner suggests, There appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US]... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. The\"Attribution Problem\"and the Social Construction of\"Violence\"The\"attribution problem,\"then, becomes a legal, technical, or strategic challenge through practice²² and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty.²³ Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons\"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\". While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.²⁴ My argument here is not that this situation is normatively desirable;²⁵ rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice.²⁶ Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.\n## The Social Construction of Violence Violence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed. The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that ²²On the role of practice in international law, see Brunnée and Toope (2011).\n²³A similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\n²⁴In a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\n²⁵For example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\n²⁶As Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances\"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\"(2011:24–25).\nAMIR LUPOVICI Such labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons. This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes.²⁸ The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.²⁹ Some scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered. This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force.³⁰ However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims, Traditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75) The ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral ²⁷ One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war. However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n²⁸ For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting.\n²⁹ For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence, and they indicate the establishment of common knowledge in this regard.\n³⁰ The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.\nThe\"Attribution Problem\"and the Social Construction of\"Violence\"level. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare.³¹ Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified.\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar.³² This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar.\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible.³³ Furthermore, in such cases, retaliation may be employed to address or preempt public demands. All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors.\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is ³¹ An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n³² In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality”.\n³³ Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails, and thus is seen as a way to demonstrate resolve.\nAMIR LUPOVICI It is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior”. While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^[34]^ ## The Case of Stuxnet Stuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^[36]^ A number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^[38]^ He further contended that Israel would not attack ^[34]On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n^[35]According to some estimations, Stuxnet was operative as early as 2005. Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet”.\n^[36]For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n^[37]Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n^[38]On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).\nThe\"Attribution Problem\"and the Social Construction of\"Violence\"because\"it has already done so,\"as evidenced through the case of Stuxnet.³⁹ Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack.⁴⁰ A similar argument was advanced by Lindsay (2013:398), who suggested that the United States\"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\"In this respect, he argued that a covert cyber option was a useful solution.\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.\n## The Limited Influence of the Attribution Problem Using the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the\"attribution problem\"exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack. Indeed, some security analysts have considered Iranian threats in this regard to be credible. This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.\nSecond, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013).⁴² In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n³⁹ For a similar argument, see also Waxman (2011:442–443).\n⁴⁰ Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n⁴¹ Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n⁴² See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.\nAMIR LUPOVICI Taking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.\n## The Effects of the Social Construction of Violence on Cyber Deterrence The partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nA number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison ⁴³Markoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\n⁴⁴See for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\n⁴⁵Interestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal.\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016 The\"Attribution Problem\"and the Social Construction of\"Violence\"Dinniss 2012:81–82).⁴⁶ However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial⁴⁷—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives”. We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran,⁴⁸ which may indicate, among other things, the fear of an Iranian retaliation.⁴⁹ Assertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions”. The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study ⁴⁶However, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\n⁴⁷On the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\n⁴⁸Verter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\n⁴⁹For a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).\nAMIR LUPOVICI Another counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.\n## Conclusions In this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this Downloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016 concept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence."
    }
  },
  "summary": {
    "full_text": {
      "words": 11636,
      "tokens": 15990
    },
    "flat_text": {
      "words": 10112,
      "tokens": 13379
    }
  },
  "payload": "## __preamble__\n\nInternational Studies Perspectives Advance Access published February 2, 2016 International Studies Perspectives (2014) 0, 1-21 # The\"Attribution Problem\"and the Social Construction of\"Violence\": Taking Cyber Deterrence Literature a Step Forward¹ AMIR LUPOVICI Tel Aviv University Many scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and\"violence\"are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\nKeywords: cyber, deterrence, constructivism, Stuxnet There is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic ¹I am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\nLupovici, Amir (2014) The\"Attribution Problem\"and the Social Construction of\"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082 © The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com The\"Attribution Problem\"and the Social Construction of\"Violence\"means that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a\"theoretical vacuum.\"More generally, Lindsay (2013:367) points out,\"Most work on international cyber security originates from the policy analysis community.\"Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace.\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security. However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence. This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of\"violence.\"Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\nAMIR LUPOVICI\n\n---\n\n## ## Conclusions In this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\n\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this Downloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016 concept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence.",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:SUCCESS\nsections_raw:12\nsections_clean:11\nintro:FOUND\nconclusion:FOUND\npredefined_sections:## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges|## The Social Construction of Violence Violence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed. The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that ²²On the role of practice in international law, see Brunnée and Toope (2011).|## The Limited Influence of the Attribution Problem Using the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the\"attribution problem\"exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack. Indeed, some security analysts have considered Iranian threats in this regard to be credible. This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.|## The Effects of the Social Construction of Violence on Cyber Deterrence The partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nextra_sections:## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges\npayload_tokens_before:7986\npayload_tokens_after:5254\ndropped_section:## The Effects of the Social Construction of Violence on Cyber Deterrence The partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\nadded_section:## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges\n---LOG_SUMMARY_END---",
  "pages_text": [
    "International Studies Perspectives Advance Access published February 2, 2016\n\nInternational Studies Perspectives (2014) 0, 1-21\n\n# The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward¹\n\nAMIR LUPOVICI\nTel Aviv University\n\nMany scholars suggest that the difficulty of attaining cyber deterrence is due to the intrinsic characteristics of cyberspace. While this article does not aim to entirely refute this assertion, it suggests that the failure to successfully employ cyber deterrence is not determined by the technical challenges of cyberspace, but rather that the effects of these challenges are mediated through social context(s) and norms. To present this, I elaborate on the meaning of cyber deterrence and suggest that a rethinking of this term allows us to better address the various actors involved in the practices of cyber deterrence, as well as to better describe the intersections between the cyber and kinetic means affecting these practices. Building on the concept of cyber deterrence and borrowing from the constructivist approach to International Relations, I focus on how anonymity and \"violence\" are affected by social constructions and norms and in turn influence the success or failure of cyber deterrence. I briefly illustrate these assertions and their importance with regard to the case of Stuxnet.\n\nKeywords: cyber, deterrence, constructivism, Stuxnet\n\nThere is common consensus in International Relations (IR) literature that cyber deterrence, due to the intrinsic characteristics of cyberspace, is doomed to fail. While this line of thought is based on significant insights, which have enriched both deterrence and cyberwarfare scholarship, I suggest that we can take the study of cyber deterrence forward in two interrelated directions.\n\nFirst, we can develop a more nuanced view of cyber deterrence—the need for which arises when we consider, for example, that it is not entirely clear what the adjective cyber in cyber deterrence means. In other words, does cyber refer to the defender's (that is, the deterrer actor's) cyber infrastructures requiring protection, to the means the putative challenger is about to use, or to the means the defender uses to deter (threaten) a putative challenger? While scholars usually refer to the first and second meanings, and while these meanings may overlap, the concept of cyber deterrence logically should include the third meaning as well. I suggest that clarifying this concept helps to address the various kinds of actors engaging in these practices and the intersections between cyber and kinetic\n\n¹I am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.\n\n[Corrections added 27 February 2015, after original online publication: grammatical changes have been made to this article to improve clarity.]\n\nLupovici, Amir (2014) The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward. International Studies Perspectives, doi: 10.1111/insp.12082\n\n© The Author (2014). Published by Oxford University Press on behalf of International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nmeans that influence them. Furthermore, such a clarification is a useful point of departure for considering the social dynamics that affect the practices of cyber deterrence, which are discussed below.\n\nSecond, with a number of exceptions—which I will discuss later in the article—cyber deterrence scholarship tends toward a policy-oriented perspective. As Liff (2012:403, 408) argues, cyber deterrence is frequently studied in a \"theoretical vacuum.\" More generally, Lindsay (2013:367) points out, \"Most work on international cyber security originates from the policy analysis community.\" Moreover, a parallel criticism could be made that IR scholars need to further develop theories to address practices in cyberspace (Eriksson and Giacomello 2006; Dunn Cavelty 2008:7; Hansen and Nissenbaum 2009:1156).\n\nI claim that the emerging interpretative scholarship in IR provides a promising avenue for further theorizing cyber deterrence scholarship. Indeed, in recent years, a growing number of scholars have relied on or used different interpretative approaches to explore issues of cyber security (Saco 1999; Deibert 2002; Bendrath 2003; Yould 2003; Dunn Cavelty 2008, 2010, 2013; Hansen and Nissenbaum 2009; Deibert and Rohozinski 2010). However, these illuminating approaches have been incorporated into the study of cyber deterrence only to a limited extent (but see Stevens 2012). Likewise, emerging scholarly research employing interpretative approaches to explore deterrence, while insightful, does not focus on cyber deterrence (Luke 1989; Williams 1992; Klein 1994; Tannenwald 2007; Adler 2009). This paper thus aimed to connect three main streams of scholarships: cyber deterrence research, which is dominated by positivist scholars and is policy oriented; interpretative research on cyberspace, which has tended to avoid the topic of cyber deterrence; and interpretative research of deterrence, which tends to focus on more traditional means.\n\nMore specifically, I suggest that a constructivist approach to deterrence helps to shed light on cyber deterrence success by focusing on social factors that affect the problem of attribution and the question of \"violence.\" Although a comprehensive consideration of all the social constructions affecting cyber deterrence is beyond the scope of this article, I emphasize the two above because they have been key factors in some current discussions of cyber deterrence. The main aim of this paper, then, is to demonstrate that an examination of the social processes that relate to cyber deterrence is valuable to understanding the failures and successes of this strategy.\n\nWhile this paper is mainly theoretical, I briefly illustrate my assertions through the case of Stuxnet, a computer worm discovered in 2010 that very likely damaged Iran's nuclear program. Despite the fact that this case has already been extensively studied, and although many of its details are still unknown, it is a useful example for the purposes of my research for a number of reasons. First, in most of the studies that refer to this case, deterrence is not the main focus. Second, the case of Stuxnet is affected by practices of deterrence in interesting ways. Finally, social factors may help to shed some new light on this case—which, despite the existence of some material on it in previous studies, has remained inconclusive. In this respect, I suggest that Iran's failure to deter diversion to cyberspace (in light of their more effective deterrence in other spaces) was influenced by social processes shaping the effects of anonymity and violence. Furthermore, Iran's lack of meaningful response to this cyber-attack can be explained by how violence is constructed.\n\n2 As Dunn Cavelty argues, employing the concept of securitization is a notable exception to the tendency of cyber security studies to avoid integrating IR theories (Dunn Cavelty 2013:106).\n\n3 For example, scholars focus on the question of what the United States should do to enhance its deterrence posture in cyberspace, see Kramer (2009), Morgan (2010).\n\n4 See also Lupovici (2010).",
    "AMIR LUPOVICI\n3\n\nThe paper is structured as follows. The first section briefly reviews cyber deterrence scholarship and points to the advantages both of rethinking the term *cyber deterrence* and of using a constructivist approach to further theorize cyber deterrence scholarship. In the second section, and based on the suggested view of cyber deterrence, I will develop a constructivist approach that reveals the effects both of the “attribution problem” and of the social constructions of “violence” on deterrence failure and success. Finally, in the last section, I demonstrate the significance of these notions using the case of Stuxnet.\n\n## Deterrence⁵ and Cyber(warfare) Scholarship and Its Challenges\n\nMost scholars tend to agree that there are a number of obstacles that significantly limit the successful employment of the strategy of deterrence by punishment in cyberspace. Indeed, some have suggested various methods to enhance deterrence vis-à-vis cyberwarfare, such as establishing tailored deterrence, “deterrence by active defense,” serial deterrence, or deterrence by denial, as well as by using kinetic means (Wheatley and Hayes 1996:13, 19–20; Cordesman and Cordesman 2001:7; Kramer 2009:15–16; Kugler 2009:328; Morgan 2010:59, 68). However, even those who see some prospect in the feasibility of cyber deterrence join more skeptical voices.\n\nMost scholars agree that the basic conditions for deterrence success—that is, capabilities, credibility, and communicating the threatening message to the challenger (Morgan 2003:15–20)⁶—are difficult to meet when facing a cyberwarfare threat (Morgan 2010; Stevens 2012:149–153). Among other things, they argue that defending actors are restricted in their ability to pose a credible threat in advance because of the problems in identifying the challenger, the large number of potential challengers, and the asymmetry between the challengers and the defenders (Harknett 1996; Molander, Riddle, and Wilson 1996:87; Berkowitz 1997:183–184; Cordesman and Cordesman 2001:7; Arquilla 2003:210–213; Libicki 2007:272, 2009:1–3, 26, 44–45; Morgan 2010:55–76).⁷ However, despite the contributions of current scholarship, the study of cyber deterrence—and more specifically the understanding of how deterrence succeeds or fails—would benefit from further elaboration of the meaning of cyber deterrence and the incorporation of IR theories into the research.\n\n## What Do We Mean When We Say Cyber Deterrence?\n\nThe meaning of the term cyber deterrence needs to be further clarified. Although its meanings and emphases vary, cyber deterrence (like similar concepts, such as deterrence of cyber-attacks and deterrence of information warfare) is generally seen as a strategy that aims to prevent opponents from using their cyber capabilities or to prevent attacks on defenders’ (usually states) cyber infrastructures. This is clearly demonstrated in Stevens’ useful review of current cyber deterrence scholarship, in which he notes that recent cyber deterrence research “has tended to concern itself with the deterrence of ‘cyber-attacks,’ understood as adversarial computer-mediated actions against critical information infrastructures (CII) and other ICT-networked national assets, including those of the military and security services” (Stevens 2012:149–152). These views are reflected in specific studies. For example, Libicki suggests that the aim of cyber deterrence is to enhance cyber security, “reducing the risk of cyber-attacks to an acceptable level at\n\n⁵For a very useful discussion of definitions of deterrence, see Morgan (2003:1–2).\n\n⁶For a detailed review of this scholarship, see also Lupovici (2011).\n\n⁷Given these problems, some scholars have suggested employing alternative measures to deterrence, such as defensive means (see Wheatley and Hayes 1996; Lukasik 2010; Liff 2012:412–413).",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nan acceptable cost” (Libicki 2009:27–35). Likewise, Wheatley and Hayes (1996:6, 10) aimed to expand the concept of national security and deterrence to include the protection of information systems, but debated over what kinds of systems should be considered.⁸\n\nHowever, cyber deterrence should not only be seen as a strategy to dissuade attacks that are made by cyber means or that target the defender’s cyber infrastructures.⁹ Cyber deterrence can also refer to situations in which actors threaten to use cyber means to prevent different kinds of undesired activities. In fact, it is interesting to note that common views of deterrence usually use an adjective attached to the word *deterrence* to denote precisely this meaning. For example, *nuclear* deterrence clearly refers to the means through which the defender aims to dissuade a putative challenger from executing an attack: regardless of whether the attack is nuclear, chemical, or conventional.¹⁰ In other words, the term nuclear deterrence encompasses the usage of nuclear means to dissuade a variety of challenges, with the adjective (that is, nuclear) referring to the means through which the deterrent threat is employed, and not necessarily to the challenge the defender aims to dissuade (preventing a *nuclear* attack) or the target the putative challenger might attack (*nuclear* capabilities of the defender). Conversely, when scholars use the term *cyber deterrence*, the adjective (that is, *cyber*) refers, as shown above, to the kind of threat the defender aims to prevent (dissuading a *cyber*-attack) or to the target the challenger might attack (the defender’s cyber infrastructures).\n\nI suggest therefore that cyber means can provide the point of departure to define and study cyber deterrence. In this respect, cyber deterrence concerns *deterring cyber-attacks* (either through kinetic or cyber means) and/or using cyber means to deter attacks (either kinetic or cyber) (see Figure 1). This view of cyber deterrence helps to, among other things, clarify some issues concerning the involved actors and the intersections between kinetic and cyber practices of deterrence.\n\n## Who Are the Deterring Actors?\n\nOne implication of the suggested view of cyber deterrence is that it allows us to explore the various kinds of undesired activities the defender wishes to prevent¹¹ regardless of the identity of the defender and the challenger and whether they are state or nonstate actors. Most scholars who study the practices of cyber\n\n⁸Such discussions are also based on the meaning of cyberwarfare and related terms, which thus concern the acts the defender aims to dissuade. More classical studies on cyber security used the term *information warfare* to denote various attempts to prevent, disrupt, or destroy the enemy’s information systems while protecting the information systems of the defender against similar threats (Wheatley and Hayes 1996:v–vi, 5–6; Molander et al. 1996:81–92). In recent years, scholars prefer to limit the usage of this concept to several kinds of psychological operations and propaganda (Harrison Dinniss 2012:27). In contrast, as Harrison Dinniss notes, many authors prefer using the term “computer network attacks,” and to follow the US Department of Defense definition of it: “Actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves” (US Department of Defense 2010; Harrison Dinniss 2012:2). Nonetheless, some prefer even a more limited view of cyber-attacks that excludes information-gathering or computer network exploitation (Libicki 2009:23–25). Such a view is evident, for example, with Linsday’s definition of *cyber warfare*, which concerns the strategic dimension of employment of “computer network attacks as a use of force to disrupt an opponent’s physical infrastructure for political gain” (Lindsay 2013:372).\n\n⁹To some extent there is an overlap between a challenger’s use of cyber means and a challenger attacking the cyber infrastructures or cyber capabilities of another actor, as a prominent way to attack them is through cyber means. Nonetheless, these two should be distinguished, as cyber means may also be employed to attack kinetic means, and cyber infrastructures and cyber means can be targeted by kinetic means. For a similar argument on the distinction between “intra cyberspace power” and “extra cyberspace power,” see Nye (2011).\n\n¹⁰The same applies of course to *conventional deterrence*, which concerns the means through which a defender threatens to retaliate.\n\n¹¹More fundamentally, Deibert (2002) distinguishes among four images of security: national security, state security, private security, and network security, as each portrays threats to a different referent object. For additional discussion of cyber security, see Choucri (2012:39, 134–142).",
    "AMIR LUPOVICI\n5\n\n|  The Actor\nChallenger\nDefender | The means the challenger uses to attack the defender  |   |   |\n| --- | --- | --- | --- |\n|   |   |  Kinetic means | Cyber means  |\n|  The means the defender uses to pose a deterrent threat | Kinetic means | Not cyber deterrence | (A defender aims to dissuade a cyber-attack by employing kinetic means)  |\n|   |  Cyber means | (A defender uses cyber means to dissuade an attack)  |   |\n\nFig. 1. Cyber Deterrence and the Means Used by the Defender and the Challenger\n\ndeterrence focus on state versus state interactions.¹² Some scholars—for example, Libicki—provide rationales for focusing only on state actors (Libicki 2009:26); however, while there is little empirical evidence on how nonstate actors use cyberwarfare, there is no a priori reason to limit the scope of this concept. Furthermore, from the point of view of the defender's strategy, we can see that states use \"cyber deterrence\" to prevent activities of nonstate actors. An example of this can be seen in the American conception of how to deter Wikileaks' users from distributing information. As early as July 2008, a report issued by the US Army Counterintelligence Center called for the need to \"deter others from using Wikileaks.org to make such information public.\" The report concludes that one of the most effective characteristics of Wikileaks is its ability to maintain the anonymity of its sources.¹³ From the US perspective, as evident in this report, an efficient deterrent threat vis-à-vis Wikileaks and potential leakers would be to demonstrate the ability to reveal leaker identities. In this respect, the report suggests relying on cyber technology to achieve the deterrent aims.\n\n## Intersections among Cyber and Kinetic Means\n\nConceptualizing cyber deterrence through the actors' means furthers our discussion of the intersections of this strategy's cyber and kinetic measures. While scholars have acknowledged the interactions among these spaces (for example, cyberspace and kinetic spaces) in a number of ways,¹⁴ we could develop these issues further in the study of deterrence. For example, even Libicki, in his discussion of the different aspects of kinetic means affecting cyber deterrence, mainly addresses the usage of cyber means to deter cyber threats. As he explains, \"we have chosen to define cyber deterrence as deterrence in kind to test the proposition that the United States ... needs to develop a capability in cyberspace to do unto others what others may want to do unto us\" (Libicki 2009:27; my emphasis). But while it is important to think of cyberspace as a distinct space in order to sharpen some notions\n\n¹² A main exception is research that focuses on deterring cyber terror, see in Lachow (2009:437–464). For a more general discussion concerning the complexity of the practices of deterrence in the post-Cold War era, see Paul, Morgan, and Wirtz (2009).\n\n¹³ Michael D. Horvath (March 2008) Wikileaks.org—An Online Reference to Foreign Intelligence Services, Insurgents, or Terrorist Groups? Army Counterintelligence Center. Available at: http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf, pp. 4, 18 (italics added). For further discussion of this issue, see Lupovici and Danjoux (2009).\n\n¹⁴ See for example, Libicki (2009:69–71, passim), Choucri (2012:11–12, 16), Harrison Dinniss (2012:104, passim), Rid (2013:166).",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nregarding it, it is also important to contemplate how cyber deterrence influences other modes of deterrence, and vice versa. Furthermore, we must emphasize, as Lonsdale asserts, that it is not clear why we should assume—as some experts on cyberwarfare do—that cyberwarfare would replace conventional warfare, rather than become part of it (Lonsdale 2004:227; see also Kramer 2009:15, 20–23; Betz and Stevens 2011:105).\n\nCyber deterrence and kinetic means of deterrence can intersect in a number of ways. First, cyber and kinetic means may complement each other in order to enhance a defender’s deterrent posture to deter a cyber-attack. Some scholars have suggested that the deterrent threat of a retaliatory strike aimed at dissuading a cyber-attack need not be restricted to cyberwarfare, but can also be based on the various capabilities of the defender actor: military weaponry, diplomatic and political means, domestic security forces such as the police, and even the justice system and international law (Wheatley and Hayes 1996:13, 19–20; Kugler 2009:328, 335; Morgan 2010:68).¹⁵ Thus, responding—and threatening to respond—to threats through retaliation in other spaces may enhance deterrence efficiency and credibility. In fact, US President Bill Clinton in 1998 declared that a cyber-attack on the United States would result in a retaliation that would include a military response that might be based on kinetic means (see Dunn Cavelty 2008:96; see also Waxman 2011:432). Similar deterrent threats have also been issued since then, for example, in the President’s May 2011 International Strategy for Cyberspace.¹⁶ In a similar way, Deibert and Rohozinski argue that a norm of deterrence is emerging in cyberspace as the result of a growing recognition of the mutual interdependence among states. They contend that actors are not only legally constrained from cyber-attacks, but are deterred, or self-deterred, by recognizing the cascading effects that a cyberspace attack would have on, for example, international financial institutions that would hurt their own interests (Deibert and Rohozinski 2010; see also Nye 2011:207–208).\n\nSecond, cyber and kinetic means may complement each other to deter a somewhat more conventional attack employed through kinetic means. A prominent example of this can already be seen in Revolution in Military Affairs (RMA) systems. Such systems, among other things, improve command-and-control abilities and thus may advance deterrence credibility (Morgan 2003:20). In addition, they can improve the capabilities of kinetic means (that is, make them more accurate) and as a result enhance their deterrent effectiveness.\n\nThird, and last, cyber and kinetic spaces intersect in situations where actors, deterred by a defender’s kinetic retaliatory attack, may divert their activity to cyberspace, especially if putative challengers see the defender’s cyber deterrent posture as less credible. As recently suggested by Lindsay (2013:398), “successful deterrence can lead strategic actors to choose cyber means when other options are deemed too risky.”\n\n## The Need to Further Theorize Cyber Deterrence\n\nA second main challenge for the study of cyber deterrence is to further theorize this scholarship, building on IR theories (see also Deibert, Rohozinski, and Crete-Nishihata 2012:4–5). In fact, scholars have called for such a move, challenging the capability of current IR theories (that is, the main paradigms) to encompass the interactions of actors in cyberspace. For example, Choucri argues that the main challenges are the need to explain how cyber and kinetic means interact, to\n\n¹⁵ See also in Cordesman and Cordesman (2001:7).\n\n¹⁶ Department of Defense Cyberspace Policy Report, A Report to Congress Pursuant to the National Defense Authorization Act for Fiscal Year 2011, Section 934 November 2011. Available at: http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf, p.2.",
    "AMIR LUPOVICI\n7\n\nexplore changes in cyberspace and to encompass the variety of actors involved (Choucri 2012:15–16). While I build on these arguments, which are highly pertinent to moving cyber deterrence scholarship forward, I think that Choucri too quickly dismisses the potential of the constructivist approach in IR in her claims that it is not mature enough to make such a contribution and cannot address these precise issues. I argue the opposite: That integrating notions drawn from constructivist approaches will take the thinking and literature a step further. To better understand actors’ behavior, we need to acknowledge the existence of intersubjective understandings, that knowledge is socially constructed and that it is dependent on language and on the social context (Searle 1995:76–77; Adler 1997; Hopf 1998:199; Milliken 1999:229, 236).\n\nTherefore, from a constructivist point of view, when considering how cyberspace is shaped, we must emphasize not only, as Libicki (2009:12) suggests, the physical layer (that is, boxes and wires), the syntactic layer (that is, protocols), and the semantic layer (that is, information), but also the intersubjective social layer (Deibert and Rohozinski 2010:22). After all, cyberspace “was manufactured by human ingenuity and is distinct from nature” (see Choucri 2012:130). Hence, what cyberspace is and the boundaries between it and other spaces are socially created. Furthermore, as Saco argues, “[C]yberspace is often treated as a constructed ‘virtual’ space in contrast to the ‘real’ physical spaces it simulates. Such dichotomies can be misleading, however, in part because all social space is socially constructed” (Saco 1999:290; see also Hansen and Nissenbaum 2009:1164–1165).¹⁷ In fact, even the boundaries between more “conventional” spaces, such as between aerial and outer space, are not clear cut but have been determined and shaped through evolving ideas and a political process (Gorove 2000).\n\nIt follows then that not only is cyberspace—along with its boundaries with other spaces—socially shaped, but its specific characteristics, which affect how actors behave, are constructed as well. As Kramer explains, the meaning of cyberspace should be socially determined (Kramer 2009:12); in other words, our understanding of how cyberspace affects behavior is not given, but is socially shaped. In this way, cyberspace is not only a construct, “but the rules of cyberspace are largely constructs … There is no inherent ‘there’ there except as mutually accepted” (Libicki 2007:6). These rules shape what is feasible, appropriate, and useful and thus affect the way defenders pose threats and, more importantly, how these threats are interpreted by putative challengers. It is because of this that a constructivist approach to cyber deterrence emphasizing intersubjective understandings becomes highly pertinent.\n\nA number of scholars have started to incorporate interpretative notions into more traditional studies of deterrence. These scholars have shown in various ways how the strategy of deterrence depends on knowledge or common knowledge (Williams 1992; Adler 2009), norms (Freedman 2004; Tannenwald 2007), and discourse (Luke 1989; Klein 1994). Furthermore, scholars have shown how the strategy of deterrence is shaped by social constructions, which affect the adoption and implementation of this strategy and the chances of its success. These include the social constructions of rationality (Luke 1989:212), of threat and (in)security (Buzan, Wæver, and de Wilde 1998:204; Hopf 1998:186–187; Weldes 1999:18–19; Vuori 2008), and of credibility and resolve (Hopf 1994:9–11; Milliken 1996:218, 228). Furthermore, while actors’ capabilities are an important element in the strategy of deterrence, their effect is mediated through social structures, which constitute them as a means of deterrence (that is, deterrent weapons rather than means of war-fighting) (Tannenwald 2007).¹⁸\n\n¹⁷Rid (2013:166) goes as far as to suggest that cyber is not a space, but rather a metaphor.\n\n¹⁸For further discussion of the contribution of interpretative approaches to the study of deterrence, see Lupovici (2010:710–718).",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nIn addition, the emerging scholarship on practices in IR helps to further elaborate on these issues,¹⁹ as practices constitute strategic interactions by both reproducing a pattern of behavior and changing it over time. In other words, practices create and shape norms, conventions, and the “rules of game” (Adler and Pouliot 2011:12–14, 18).²⁰ For example, scholars have argued that the Cold War strategy of MAD was based on practices and background knowledge that the superpowers adopted and institutionalized (Adler and Pouliot 2011:21, 24–25; Morgan 2011:158–162; passim), forming a deterrence community (of practice) (Lupovici 2008:4).\n\n## Toward a Constructivist Approach to Cyber Deterrence\n\nWhile it is beyond the scope of this paper, and probably any one single paper, to fully present a constructivist cyber deterrence approach, I consider two main elements that are crucial in the understanding of cyber deterrence: anonymity and violence. These elements clearly demonstrate how the material and physical characteristics of cyberspace influence actors’ behavior through the mediation of ideas that evolve in a social context.\n\n## The Attribution Problem\n\nA large number of scholars point to the attribution problem as a key burden in cyber deterrence. Challengers can disguise themselves in various ways to obscure the source of attack, and defenders must make great efforts to discover it (Kello 2013:33; Lindsay 2013:378). Furthermore, the difficulty may stem from the challenge not only of identifying the source of attack itself, but of establishing whether a state actor was directly behind it or not. Deibert, Rohozinski and Crete-Nishihata (2012), for example, demonstrate this point through the fact that experts could not find decisive evidence of Russia’s involvement in the cyber-attack on Georgia during the confrontation between these two countries in August 2008. One of the sources of this challenge is the ability of state actors to privatize their cyber operations “to confuse the battle space and muddy attribution” (Deibert, Rohozinski and Crete-Nishihata 2012:18).²¹\n\nThe attribution problem complicates the ability to deter in a number of ways. First, it is very difficult for defenders to deliver a threat to a challenger when, even post-factum, they cannot definitively trace its identity (Libicki 2009:41–52; Betz and Stevens 2011:32, 88). Second, as the time that is needed to gather hard evidence increases, the legitimacy of executing the retaliatory attack decreases. The more time that passes, the fewer are the chances that the undesired event the defender faced will be “classified as an armed reprisal rather than an action taken in self-defense. Armed reprisals are prohibited under international law” (Harrison Dinniss 2012:102). These difficulties are magnified by the fact that a putative challenger needs to believe in advance that the defender is ready to retaliate and is able to identify the source of attack (Libicki 2009:41, 43).\n\n¹⁹ According to Adler and Pouliot, practices are “socially meaningful patterns of action, which, in being performed more or less competently, simultaneously embody, act out, and possibly reify background knowledge and discourse in and on the material world” (2011:4, see also pp. 5–7). As such, while explanations based on practices overlap with (traditional) constructivist approaches, they also differ from them, see Adler and Pouliot (2011:14–15, 19).\n\n²⁰ Thus, the interactions between states, the signals they deliver to each other, and the language they speak “are constituted by the practices they share” (Adler and Pouliot 2011:20).\n\n²¹ Nonetheless, it should be noted that despite these difficulties, Deibert et al. do attempt to trace the level of governmental involvement, and more importantly provide useful methods and tools to attempt to determine such involvement (see Deibert et al. 2012:6, 12–17).",
    "However, while these elements certainly complicate the ability to present a credible cyber deterrent threat, anonymity is not an a priori characteristic of cyberspace. Moreover, the attribution problem does not necessarily prevent deterrence success. These understandings of cyberspace have been constructed and managed through social processes—and thus, practices and international norms have made the attribution problem a more significant challenge for deterrence success.\n\nFirst, while indeed it is difficult to trace the sources of a cyber-attack, the attribution problem is not unique to the cyber domain. In fact, armed attacks are often carried out anonymously (Harrison Dinniss 2012:100; see also Rid 2013:141--142).\n\nSecond, the attribution problem is not inherent to the cyber domain: rather, cyberspace has been constructed in a way that has made anonymity easier to attain. As Lindsay explains, “The Internet was designed to make connections easy and reliable even when the true identity of the connector and the path of the connection were unknown; security did not figure strongly in its early design” (Lindsay 2013:375--376). In other words, the anonymity of cyberspace can be understood as a “practice” based on background knowledge and skills that further ratify actors' behavior. The point, however, is that—given that anonymity is a socially attributed characteristic of cyberspace—other forms of cyberspace could be established in which the preservation of anonymity would be less easily maintained. For example, ideas have been put forward even in the United States to “reengineer” the Internet as an identified and attributed network, where logging in entails specific personal verification (Stevens 2012:164; but see Rid 2013:140--141). Even Libicki acknowledges such a scenario in the future (Libicki 2009:43). Whether or not such technologies mature or would fully resolve the attribution problem, the ability to clearly conceptualize them demonstrates that cyberspace is not an inherently anonymous space, but rather that the attribution problem exists because of how cyberspace was designed and is practiced.\n\nThird, some scholars suggest that because in most cases the identity of the actor can be concluded from the context (for example, who benefits from the deeds), anonymity is not necessarily a problem (Lucas 2013:17--18). While deducing the identity of an attacker from their interests may sometimes be misleading (Libicki 2009:44), anonymity, as Kugler (2009:310, 317--318) contends, is not likely to be a major problem when the stakes are grave. Cyberwarfare means will likely be employed along with other (kinetic) means during an international crisis, so that the challenger's identity will be known (see also Sterner 2011:74). In this respect, although minor cyber-attacks may still be conducted anonymously, the main challenges can be successfully deterred.\n\nFinally, and most importantly, the effects of anonymity on deterrence are derived from social conventions, which legitimize retaliations only if the defender is able to fully identify the source of attack. In this respect, as Farwell and Rohozinski suggest, “attribution is a matter of interpretation ... [in cyberwar] where attacks emanate externally, outside a targeted nation, there are huge questions about the responsibility of the victim to identify the physical location of a computer or network” (Farwell and Rohozinski 2011:31). Likewise, Sterner suggests,\n\nThere appears to be an unwritten assumption that knowing the physical-world identity of a cyber attacker is a prerequisite to retaliation. This is eminently reasonable when one's primary retaliatory tools were designed for attackers in the physical world. But, the challenge [is that the US] ... needs the ability to retaliate against cyber attackers without necessarily knowing who they are in the physical domain. (Sterner 2011:73)",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nThe \"attribution problem,\" then, becomes a legal, technical, or strategic challenge (Betz and Stevens 2011:32) through practice²² and social norms that may change over time. If this is the case, it is possible to imagine a scenario emerging following repeated severe unidentified cyber-attacks in which there has been an erosion of the norm that emphasizes the need for certain identification of attackers prior to retaliation. Given the perceived pressure to enhance the deterrent posture, actors might retaliate with a lower degree of certainty.²³ Dipert, for example, suggests—based on game theory exploration—that a preemptive attack can be morally defended if the evidence exceeds a certain threshold of objective likelihood (roughly 90%) and if a high level of damage is expected without preemptive action. He argues that for consequentialist reasons \"if every state followed such a policy, overall damage to all parties over the long run would be minimized because of a deterrent effect\" (Dipert 2010:393). While the exact percentage, and even the ability to quantify the threshold, can be debated, Dipert's assertion demonstrates how a different normative context can be conceived.²⁴\n\nMy argument here is not that this situation is normatively desirable;²⁵ rather, it intends to demonstrate that the attribution problem, although influenced by technical elements, also affects deterrence through social forces. Thus, practices and the manner in which actors respond to cyber-attacks will likely take part in shaping norms and conventions, which in turn will affect actors' strategies. If an actor is reluctant to accept a current norm that does not justify retaliation based on circumstantial evidence of the identity of the challenger, they might resist it by responding to attacks, gradually lowering the threshold of the required evidence and modifying the norm through practice.²⁶ Conversely, the current assumption that the attribution problem is inherent to cyberspace may have further effects on actors' strategies. Defenders, discouraged from relying on cyber deterrence, may refuse to invest in efforts to establish it. This will decrease the efficiency of cyber deterrence and, as a result, reinforce the existing common knowledge that this strategy is doomed to fail. Such common knowledge may also influence the putative challenger, which would be more likely to divert its activity to cyber means.\n\n## The Social Construction of Violence\n\nViolence is another construction that affects the practices of cyber deterrence. Established scholarship in the field focuses on a related issue—that is, on how (in)security is socially constructed (Weldes 1999). The discussion in this regard is further advanced through the concept of securitization, which concerns how enunciators, through discourse or practices, frame an issue as a source of insecurity for a target audience and in this way attempt to justify taking emergency and extraordinary measures to address it. For these scholars, what is at issue is not the degree of harm or destruction, but rather the intersubjective understanding that\n\n²²On the role of practice in international law, see Brunnée and Toope (2011).\n\n²³A similar argument is suggested by Rid (2013:161), who sees the problem of attribution as a political issue. While it is indeed a political issue, my point of contention, as further clarified in the next section, is that it becomes political through a social process in which cyber-attacks are framed as acts of violence.\n\n²⁴In a similar way, difficulties in attribution may not only result in changing the required level of certainty that justifies retaliation, but also lead actors to change the current expectation of an immediate retaliation whenever deterrence fails. For example, a new practice may be created according to which actors will retaliate when some degree of (circumstantial) evidence is acquired, regardless of the time that has passed. In such a scenario, actors will try to create a deterrent effect by threatening the putative challenger with a possible retaliation at some point in the future.\n\n²⁵For example, Guitton and Korzak (2013:67) warn of the ethical implications that may stem from lowering the standards of attribution.\n\n²⁶As Adler and Pouliot suggest, attention should be given to generative interactions, that is, instances \"of formative interactions, which, due to either material or ideational reasons, or both, facilitate the emergence of a new practice\" (2011:24–25).",
    "AMIR LUPOVICI\n11\n\nsomething is an existential threat (Buzan, Waever and Wilde 1998:30–31; Balzacq 2011). Violence can be seen in a similar way—as a social construction that, such as securitization, depends on a social process, can be accepted or rejected by a target audience, is related to language (that is, use of the term *violence*), and affects the legitimacy of how to act in response to a challenge.²⁷\n\nSuch labeling of specific means is also closely related to the constructions of different kinds of weapons, such as the framing of conventional and non-conventional weapons—evident, for example, in chemical and nuclear taboos (for example, Price 1997; Tannenwald 2007)—and in the *practice* of “non-use” of these weapons (Morgan 2011:151). This, of course, does not mean that the level of destruction is completely unimportant. Rather, as these studies show, these weapons have acquired their meaning and how they should be used through social processes.²⁸ The behavior of actors is shaped not only by each actor’s understandings, but also by the common knowledge and intersubjective understandings manifested in international norms, international agreements, or treaties.²⁹\n\nSome scholars have already begun to look at how the meaning of violence affects cyber issues from a legal perspective. These studies mainly focus on interpreting Article 4(2) and Article 51 of the UN charter to determine the conditions under which using force is legitimate when faced with cyber threats. While a retaliatory response is justified if it is a response to an armed attack, the question of what constitutes an armed attack when cyberwarfare means are operated is not fully answered (Waxman 2011). This issue has been informed by a debate between two general legal approaches: the restrictive and the extensive. As Harrison Dinniss (2012:58) argues, the first, “tending to come from the positivist school, provides a definition of ‘force’ and determines whether a particular incident falls within the accepted definition. The extensive or contextualist approach tends to focus more on custom and the context of force.” In order to bridge these approaches, Schmitt suggests seven criteria to determine whether an act can be considered a use of force (Schmitt 1999:914–915).³⁰ However, Harrison Dinniss challenges these criteria, suggesting that Schmitt does not fully acknowledge the unique characteristics of computer network attacks—their indirectness, intangibility, and the problem concerning the locus of the attack and the target (Harrison Dinniss 2012:63–74). Therefore, she claims,\n\nTraditional international law focuses on personal injury, fatality and damage to physical property as measures of the seriousness of an attack. This approach is favored by most commentators writing on the subject to date; however, many catastrophically damaging computer network attacks will not cause any of these deleterious consequences. (Harrison Dinniss 2012:75)\n\nThe ambiguity is also evident with regard to what constitutes an act of war in cyberspace. Libicki suggests that an act of war can be seen at the international levels: for example, at the universal or multilateral level and also at the unilateral\n\n²⁷ One of the few attempts to directly connect securitization scholarship with violence is Neumann’s concept of violation, which concerns framing the “extra-ordinary measures” that an actor takes—a war (Neumann 1998). However, this concept differs from the focus of this article, which discusses the implications of labeling the means actors use as means of violence.\n\n²⁸ For example, despite the fact that nuclear weapons are extremely lethal, framing them as weapons of deterrence was not self-given but required a social process, as initially they were thought by many both in the United States and the USSR as a means of war-fighting (Falk 1989:68; Johnston 1995:32, 41, 61–62).\n\n²⁹ For example, it can be suggested that the SALT agreements institutionalized the idea that nuclear weapons are weapons of deterrence (Tannenwald 2007), and they indicate the establishment of common knowledge in this regard (Adler 1992).\n\n³⁰ The seven factors are severity, immediacy, directness, invasiveness, measurability, presumptive legitimacy, and responsibility.",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nlevel. However, there is no universal definition, as is demonstrated in the debates concerning the interpretation of the UN charter and the lack of a global treaty on cyberwarfare.³¹ Likewise, while any state that experiences a cyber-attack can unilaterally declare that it is an act of war, the question remains as to whether this view is legitimate and thus retaliation is justified (Libicki 2009:179–180).\n\nNonetheless, the question of what cyber violence is is not only legal and technological, but also political and social. Drawing on the constructivist approach, it is clear that the question of violence is intersubjective. In this respect, while Rid is fully correct to argue that most cyber-attacks are nonviolent, this nonetheless cannot simply be determined by drawing a line between a violent act and a nonviolent act, as he suggests (2013:11–12). Rather, an act is an act of violence if the actors agree that it is so. Understandings in this regard are derived from long-term processes that allow or disallow seeing a certain mean as means of violence, as well as from enunciators’ ability to frame different means and situations as part of cyberwar (Lawson 2012).³² This social context also affects how actors may struggle over these meanings. For example, Estonia attempted (though failed) to securitize the Russian cyber-attack that damaged its public and commercial institutions in 2007 and to frame and label it as a cyberwar (Hansen and Nissenbaum 2009).\n\nThese notions about both the social and legal aspects of violence are directly related to deterrence. Not only are international law and international norms, by determining what is allowed and what is prohibited, part of a deterrent mechanism (defining what is considered a challenge), but they may also affect deterrence credibility. I suggest that seeing a challenge as “violent” increases an actor’s willingness to employ threats to dissuade it, thus enhancing deterrence effectiveness.\n\nAn actor’s retaliation is more legitimate if it follows the receipt of a violent act. A deterrent threat is therefore more credible in these situations than it is in situations where there is no consensus on whether the challenge can be seen as a violent attack. The important point is that the question is not necessarily how much damage was caused, but rather how we frame the means that were used to cause it. Responding to an attack that is seen as violent attains more support from policymakers, the media, and domestic and international audiences and encounters less powerful opposition, all of which make the deterrent posture more credible.³³ Furthermore, in such cases, retaliation may be employed to address or preempt public demands (Adler 2010). All this is simply because actors—both elites and the public—have been socialized to not tolerate a violent armed attack, which is considered a supreme violation of the state’s sovereignty (see Jackson 2007; see also Frederking 2007:13). To some extent, this is also captured by the notion of the cult of reputation, which is “a belief system holding as its central premise a conviction (or fear) that backing down in a crisis will lead one’s adversaries or allies to underestimate one’s resolve in the next crisis.” This cult, according to Tang, affects both the behavior and the rhetoric of actors (Tang 2005:40–41).\n\nConversely, when there is ambiguity regarding the violence of the means, as with cyber-attacks, it will be more difficult to deter such attacks. In other words, according to common knowledge of cyber means, it is widely accepted that the question of whether they are means of violence remains open. When an activity is\n\n³¹ An attempt in this direction is evident with the Talin Manuel, which was taken by scholars who aimed to codify the international law of cyber warfare, see Schmitt (2013).\n\n³² In a similar way, conceptual clarification of “violence” is crucial in this respect. For example, Stone (2013) challenges Rid’s arguments, pointing to the need to elucidate the terms force, violence, and lethality, which Rid conflates. As Stone puts it, “[A]ll war involves force, but force does not necessarily imply violence—particularly if violence implies lethality” (Stone 2013:104).\n\n³³ Scholars have pointed, for example, to how domestic pressure may be used to enhance deterrent posture. In this respect, using costly signals, such as issuing public threats or mobilizing forces, increases the domestic costs of not retaliating in case deterrence fails (Fearon 2002:13–16), and thus is seen as a way to demonstrate resolve.",
    "AMIR LUPOVICI\n13\n\nnot seen as violent, more limitations, both domestic and international, are placed upon executing a retaliatory attack, burdening deterrence credibility. For example, Waxman suggests that restricting the definition of armed attacks to include only severe cyberwarfare attacks will undermine American deterrence vis-à-vis lower levels of cyber-attacks (Waxman 2011:439). Likewise, Dunn Cavelty argues that during the Kosovo War, American plans to retaliate against a potential Serbian computer attack were rejected out of fear that they would be considered war crimes (Dunn Cavelty 2008:79). In addition, in such contexts—in which cyber means are not seen as violent—the needs arising from the “cult of reputation” and from the desire of actors to preserve their deterrent posture are less prominent, enabling defender actors to contain or ignore them. In cases where it is questionable whether cyber-attacks are acts of violence, a putative challenger will estimate that initiating a cyber-attack will be less likely to result in retaliation, an assumption that may weaken the perceived deterrent posture. Furthermore, given the difficulties in retaliating to a challenge seen as “nonviolent,” actors may divert their activity to such means if they fear the (more traditional) challenge they consider inflicting upon their opponent will yield a retaliatory attack with kinetic means (for example, with air, ground forces). In other words, more traditional deterrent threats may lead actors to use cyber means. This, of course, does not imply that deterrence of “nonviolent” means is doomed to fail, but, other factors being equal (such as the degree of harm), deterrence of such means is more difficult.\n\nIt is not surprising therefore that scholars have called for promoting and establishing norms that would make the use of cyber violence more costly and in this way deter cyber-attacks. As Lewis argues, “Deterring some kinds of attacks may require stigmatization—the creation of a credible international norm that says some forms of attack (in space or cyberspace) run counter to accepted international behavior” (Lewis 2010:4; see also Clarke and Knake 2010:253–254; Nye 2011:208). While some efforts have been taken to develop such an “arms control” treaty, the gaps among different actors with conflicting interests are still very wide.^[34]^\n\n## The Case of Stuxnet\n\nStuxnet is a sophisticated computer worm that most likely targeted the Iranian nuclear facility at Natanz. This attack was reported in June 2010,^[35]^ and experts argue that it succeeded in sabotaging the controls of the centrifuges, although it has been suggested that eventually the damage to Iran’s nuclear program was limited.^[36]^\n\nA number of scholars and commentators claim that the use of Stuxnet was an outcome of successful Iranian (kinetic) deterrence. For example, Yossi Melman, former Haaretz’s intelligence and military affairs correspondent,^[37]^ suggested that Israel would not attack Iran, as such a strike would likely prompt Iran and Hezbollah to retaliate.^[38]^ He further contended that Israel would not attack\n\n^[34]On these challenges, see Waxman (2011:425, 453–457), Stevens (2012:160–164), but see Deibert (2002), Deibert and Rohozinski (2010:21).\n\n^[35]According to some estimations, Stuxnet was operative as early as 2005 (Rid 2013:32). Langner, who analyzed the Stuxnet malware, notes that there were two Stuxnet variants. The first one was “an order of magnitude more complex and stealthy,” and it aimed at targeting Nataz’ protection systems. The second one targeted the speed of the rotors of the centrifuges. Langner asserts that as early as 2007, a site that analyzes suspicious files received what “later turned out to be the first variant of Stuxnet” (Langner 2013).\n\n^[36]For a discussion of Stuxnet and its effects, see Farwell and Rohozinski (2011), Barzashka (2013), Langner (2013), Lindsay (2013), Rid 2013:43–46, passim).\n\n^[37]Melman, Yossi. (2011) Israel Has Already Attacked Iran, Haaretz, January 17. Available at: http://www.haaretz.com/print-edition/opinion/israel-has-already-attacked-iran-1.337446.\n\n^[38]On the Iranian credible threat to retaliate if its nuclear devices are attacked, see Kam 2012; For additional estimations that in the case of such an attack, Iran would retaliate directly—or indirectly through the assistance of its protégée, Hezbollah, which can deliver rockets missiles into Israel—see Sadr (2005:62), Devenny (2006), Kaye, Nader, and Roshan (2011:64).",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nbecause \"it has already done so,\" as evidenced through the case of Stuxnet.³⁹ Melman, alluding to the connection between the fear of an Iranian retaliation and the usage of Stuxnet, illustrates that traditional deterrence (by punishment) through kinetic means encouraged a diversion to cyberspace. As Landau asserts, employing cyber measures allowed avoiding an Iranian retaliatory strike. She argues that this is because it is more difficult to identify the source of a cyber-attack.⁴⁰ A similar argument was advanced by Lindsay (2013:398), who suggested that the United States \"sought to halt Iran's nuclear program, but it also desired to avoid sparking a new war.\" In this respect, he argued that a covert cyber option was a useful solution.\n\nWhile I accept the views according to which the development and usage of Stuxnet were affected by Iranian deterrence, I nonetheless suggest that the advantage of using Stuxnet, as well as the Iranian lack of response to it, is closely related not just to the difficulty of attribution, as these scholars claim, but also to how violence is socially constructed.\n\n## The Limited Influence of the Attribution Problem\n\nUsing the theoretical discussion above, I posit that the attribution problem in cyberspace cannot fully explain Iran's limited cyber deterrence effectiveness, and thus the diversion of the efforts to attack Iran's nuclear program to cyber means. First, the \"attribution problem\" exists through social norms, which determine the legitimacy of responding to an attack whose source is unknown. Therefore, the challenges to deterrence are not a priori characteristics of cyberspace, but rather they result from actors' adherence or disobedience to these norms. The Iranian case clearly demonstrates this point, as anonymous attacks targeting its nuclear program (for example, the assassination of Iranian nuclear scientists) resulted in what seemed to be Iranian attempts to retaliate against Israeli targets in India and Thailand.⁴¹ Furthermore, if in fact its nuclear facilities were attacked, Iran would likely hold Israel and the United States responsible and launch a retaliatory strike, even if it could not detect the source of attack (Farwell and Rohozinski 2011:29). Indeed, some security analysts have considered Iranian threats in this regard to be credible (Kam 2012). This may imply that the main questions regarding retaliation are social or political, rather than stemming directly from the inability to detect the source of attack.\n\nSecond, anonymity is not a characteristic unique to cyber operations. For example, one of the leading estimations is that Stuxnet was implanted through a memory stick. Thus, while the action involved cyber capabilities, it also involved more traditional anonymous operations, most likely including physical infiltration to infect the machines and computers, or even delivery through Iranian employees without their awareness (Byres, Ginter, and Langill 2011:11; Langner 2013).⁴² In this respect, the manner in which Stuxnet was delivered—probably through traditional means—limits the importance of the assertion that cyberspace was used because it preserves the anonymity of the attacker, or that this is the reason Iran did not respond to it. Put simply, this case not only demonstrates the intersection between spaces, but it also shows that difficulties of attribution concern traditional means as well. Therefore, cyber anonymity provides only a partial explanation to the challenges of successfully employing cyber deterrence.\n\n³⁹ For a similar argument, see also Waxman (2011:442–443).\n\n⁴⁰ Landau, Emily B. (2011) Cyber Warfare against Iran. *Yisrael Hayom*, January 17. Available at http://www.inss.org.il/upload/(FILE)1295346776.JPG (In Hebrew). See also Talbot (2011).\n\n⁴¹ Hariraksapitak, Pracha (2012) Thais Find Possible Bomb Link in Thai, India Attacks. *Reuters*, February 15. Available at http://www.reuters.com/article/2012/02/15/us-bombings-iran-idUSTRE81E0C020120215.\n\n⁴² See also Ynetnews (2012) Stuxnet Implanted in Iran Nuke Plant with Memory Stick. *Ynetnews*, April 13. Available at: http://www.ynetnews.com/articles/0,7340,L-4215663,00.html.",
    "AMIR LUPOVICI\n15\n\nThird, anonymity is not necessarily a problem because even when victims do not have clear evidence, in most cases, the identity of the attackers can be concluded from the context. With regard to Stuxnet, there were some hints pointing to the identity of the actors behind it.⁴³ While these were perhaps false flags that aimed to associate Israel, for example, with the attack (see in Lindsay 2013: ftn, 16, pp. 400–401), other indications point more directly to American and Israeli involvement.⁴⁴ Furthermore, as discussed by Harrison Dinniss (2012:37), Ahmadinejad blamed the West and Israel for being behind the attacks. In other words, not only did the Iranian authorities know that the nuclear facility at Natanz was attacked,⁴⁵ they publicly pointed to its alleged suspects. Indeed, while Stuxnet operated clandestinely for a period of time (Langner 2013) and successfully sabotaged the Iranian nuclear program, the main question is why, after it and the extent of its damage were revealed, there was no retaliation—despite the threats to respond if the Iranian nuclear program were attacked. In fact, as Langner argues, at some point, the “attacks should have been recognizable by plant floor staff just by the old eardrum.” This fact, according to Langner, emphasizes that the makers of Stuxnet were willing to accept the risk of its detection (Langner 2013). It also further challenges the argument that anonymity was the main reason for diverting the attack to cyberspace. Saeed Jalili, who served as Iranian secretary of the Supreme National Security Council, publicly admitted in January 2011 that “our experts already warded off this attack a long time ago” (Bednarz and Follath 2011). However, by stating this, he also implied that despite experiencing an attack and despite the time that had passed, Iran had not retaliated.\n\nTaking these points together, it seems that in the case of Stuxnet, anonymity was not necessarily the key element burdening Iran’s ability to retaliate or to hold an effective deterrent posture vis-à-vis the cyber-attack.\n\n## The Effects of the Social Construction of Violence on Cyber Deterrence\n\nThe partial explanation provided by the attribution problem points to the need to address other characteristics that affect cyber activity—such as the construction of violence. This latter explanation indicates that the difficulty in deterring a cyber-attack is due to how these means are understood and reveals the challenger’s advantage in using these means, which are supposedly not seen as acts of war. Likewise, the ambiguity with regard to the violence of the means makes retaliation unnecessary, because actors do not see themselves facing a critical test of their resolve as they do when facing kinetic (violent) challenges.\n\nA number of scholars have considered issues related to the question of whether Stuxnet can be considered a means of violence. As Harrison Dinniss summarizes, reports on the effect of Stuxnet differed widely, including some that acknowledge that the worm had a significant impact, yielding a substantial destruction of property but causing limited damage to Iran’s nuclear program. Unlike the events in Estonia (2007) and Georgia (2008), “it would appear that while the Stuxnet worm would undoubtedly amount to a use of force, the scale and effects of the attack do not appear to have sufficient gravity to amount to an armed attack” (my emphasis) (Harrison\n\n⁴³Markoff, John, and David E. Sanger (2010) In a Computer Worm, a Possible Biblical Clue. New York Times, September 29. Available at http://www.nytimes.com/2010/09/30/world/middleeast/30worm.html?pagewanted=all.\n\n⁴⁴See for example, Williams, Christopher (2011) Israeli Security Chief Celebrates Stuxnet Cyber Attack. The Telegraph, February 16. Available at: http://www.telegraph.co.uk/technology/news/8326274/Israeli-security-chief-celebrates-Stuxnet-cyber-attack.html; Halliday, Josh (2010). Stuxnet Worm Is the “Work of a National Government Agency.” The Guardian, June 1. Available at: http://www.theguardian.com/technology/2010/sep/24/stuxnet-worm-national-agency. For additional indications, see Sanger (2012) and Lindsay (2013:386).\n\n⁴⁵Interestingly, it is argued that one of the sophisticated elements of Stuxnet was that it delivered signals to the control, indicating that everything was normal (Sanger 2012).\n\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nDinniss 2012:81–82).⁴⁶ However, Harrison Dinniss notes that despite the fact that Stuxnet was probably the clearest manifestation of a computer network attack, international reaction to it has been decidedly muted. This indicates that “states remain cautious about labeling computer network attacks as a use of force” (Harrison Dinniss 2012:57). This gap between the implications of cyberwarfare and how it is framed in the international arena is an incentive to divert the attack to these means. The point, however, is that this is due not only to legal considerations, but also to the social understanding of the usage of these means—more specifically, they are not categorized as violence.\n\nWhile it is hard to prove the assertion that social understandings influence the practices of deterrence, considering the Iranian side helps to further support these arguments. To this end, using counterfactuals may be beneficial⁴⁷—for example, a situation in which a kinetic attack (for example, an air attack) caused similar damage to that created by Stuxnet. Indeed, given the sophistication and ambitious aims of Stuxnet, some have made such explicit comparisons, suggesting that Stuxnet achieved “with computer code, what until then could be accomplished only by bombing a country or sending in agents to planet explosives” (Sanger 2012). We can therefore speculate that such an air strike would have provoked an Iranian retaliatory attack, even if the Iranians could not with certainty trace the attack’s source. In fact, as presented above, Iran would likely hold the United States and Israel responsible (see also Farwell and Rohozinski 2011:29). Also as we have seen above, Iran has retaliated against other anonymous activities targeting their nuclear program that have not occurred in cyberspace. To a putative challenger considering such an air strike, Iranian retaliation would seem tangible and credible, which would discourage the attack. Interestingly, a number of surveys conducted in Israel in recent years found that most people oppose or strongly oppose a unilateral Israeli strike against Iran,⁴⁸ which may indicate, among other things, the fear of an Iranian retaliation.⁴⁹\n\nAssertions made by an Iranian senior official further support this interpretation. Thus, when Saeed Jalili was asked about the threat of a future and more sophisticated cyber-attack, he answered that Iran should be constantly on guard. However, when he was asked whether a conventional attack is not a realistic threat, he responded, “No, I don’t. Would the world tolerate such an attack? Would anything legitimize such an attack? Does the law of the jungle apply?… Anyone who tries nevertheless will be making a serious miscalculation. The international community must take a stance against such intentions” (Bednarz and Follath 2011). The difference in the answers to these two questions is striking. While in both scenarios the extent of the damage is not discussed, and it potentially may be similar, it is actually with regard to the more conventional threat that Jalili emphasizes the reluctance of the international community to accept such an event. In contrast, he presents a very different line of argument when a cyber-attack is discussed. In this respect, he reaffirms the claims advanced in this study\n\n⁴⁶However, see, for example, Harrison Dinniss (2012:131), for a more expansive interpretation, based on the International Committee of the Red Cross (ICRC) approach, which regards even minor acts of violence as sufficient to constitute an international armed conflict. These views further support the idea that in a different social context, Stuxnet could be seen as an act of violence.\n\n⁴⁷On the methodological use of counterfactuals, see Tetlock and Belkin (1996:3–38), Lebow (2010:17, passim).\n\n⁴⁸Verter, Yossi (2012) Haaretz Poll: Most of the Public Opposes an Israeli Strike on Iran. Haaretz, March 8. Available at: www.haaretz.com/news/diplomacy-defense/haaretz-poll-most-of-the-public-opposes-an-israeli-strike-on-iran-1.417282; Peace Index (July 2012) Israel Democracy Institute, and Gutman Centre, Tel Aviv University. Available at: http://www.idi.org.il/media/665402/The%20Peace%20Index%20Data%20-%20July%202012.pdf.\n\n⁴⁹For a similar argument, which explains the level of opposition to such a move by suggesting that the Iranian threat has become more concrete in recent years, see Ben Meir and Bagno-Moldavsky (2013:65). Similar findings are evident in the United States. As Wehrey et al. argue, “[B]oth official discourse and public opinion appear firmly opposed to a US strike, citing the threat of Iranian military retaliation” (2009:152).",
    "AMIR LUPOVICI\n17\n\nregarding how social conventions about violence affect the manner in which even a target of such an attack refers to it. Furthermore, this also further confirms the assertions made above regarding the advantages in diverting the activity to cyberspace, wherein the cost of attack is lower.\n\nAnother counterfactual scenario is one in which cyber-attacks are seen as means of violence, regardless of whether or not their actual use inflicts harm. In a different social context—for example, in a practice that may emerge in the future—we can speculate that an international (“arms control”) treaty will more clearly determine not only what is allowed in cyberspace and what is not, but also what kinds of acts are considered *violence*.50 Social acceptance that the definition of violence includes cyberwarfare attacks like Stuxnet would clarify the conditions for self-defense and thus reduce the cost of employing a retaliatory attack. This would make the deterrent threat against such cyber-attacks more credible. While an actor, in such conditions, might again use cyberwarfare to disrupt a nascent nuclear project—despite the additional costs of it—it would be far more difficult for a victim of such an attack to avoid retaliation given the costs perceived by domestic and international audiences for such a “*violent act*.” In such a context, the needs arising from the actor’s desire to preserve its deterrent posture would become more prominent, leading to a different response than, for example, was seen in the Stuxnet case. In the latter, while Iranian authorities (after a few months) were willing to admit experiencing an attack (thus, in fact, acknowledging a significant challenge to Iran’s sovereignty), they suggested that the damage was only limited, and while they considered it “an electronic war,” they nonetheless did not highlight the need for retaliation.51 Brigadier General Mohammad Hejazi, deputy chairman of Iran’s joint chief of staff, later warned that Iran was planning preemptive operations “against the known centers that launch cyber-attack on our facilities so that they cannot take such actions against us.”52 From his assertions, as well as from other Iranian statements, it seems that Iran’s retaliation efforts and threats aimed to target cyber facilities or to “attack the Web sites of Iranian enemies.”53 These assertions are interesting in that they emphasize future attacks (rather than responding to Stuxnet) and only consider cyber targets as relevant objects. The implication is that cyber-attacks are different from other means of warfare—means that would justify retaliating against additional kinds of targets and not only against those in cyberspace. Lastly, it is notable that Iranian officials were able to publicly admit that Iran was attacked without entrapping themselves into a retaliation move.\n\n## Conclusions\n\nIn this paper, I pointed to the need to move the scholarship of cyber deterrence forward. I posited that current research faces two main shortcomings: First, it holds a somewhat limited view of what cyber deterrence is, and second, it overemphasizes a policy-oriented perspective at the expense of further clarifying more general aspects concerning the practices of cyber deterrence.\n\nWith regard to the first challenge, I argued that focusing on the means actors use as a point of departure for cyber deterrence allows us to better connect this\n\n50 In fact, the “easy” case for the emergence of such a treaty will be following events in which a cyber-attack causes substantial physical damage.\n\n51 BBC (2010) Iran Says Nuclear Programme Was Hit by Sabotage. *BBC*, November 29. Available at: http://www.bbc.co.uk/news/world-middle-east-11868596. Similarly, Kello (2013:27) argues that the Iranian response to Stuxnet has been muted.\n\n52 Mehr News Agency (2011) Iran to Take Pre-Emptive Action against Cyber Terrorism. *Mehr News Agency*, February 26. Available at: http://seclists.org/isn/2011/Feb/95.\n\n53 *Iran Times* (2011) Pasdar Officer Says Iran Set to Launch Cyber Attacks. *Iran Times*, March 25. Available at: http://iran-times.com/pasdar-officer-says-iran-set-to-launch-cyber-attacks.\n\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016",
    "18 The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nconcept with the various means the challenger and the defender employ. This point of departure also corresponds with a key distinction in deterrence scholarship that emphasizes (mainly) the means the deterrer actor uses (that is, *conventional* deterrence or *nuclear* deterrence). In addition, this perspective helps us to consider the behavior of actors who in practice use cyber and kinetic means interchangeably to achieve their strategic goals.\n\nWith regard to the second challenge, I suggested that using a broader view of cyber deterrence and drawing insights from constructivist IR literature will help to further theorize cyber deterrence scholarship. To be clear, these interpretative notions do not necessarily refute more conventional views of deterrence strategy. Nonetheless, social context(s) and social constructions help to clarify a number of issues regarding the practices of deterrence. For example, constructing cyberspace as a space in which the attribution problem inherently prevails discourages actors from posing deterrent threats—as they assume they probably will not be effective—and encourages challengers to divert their activity to cyber means. In addition, I showed how constructions of “violence” affect the practices of deterrence. In this respect, seeing a threat as an act of violence enhances deterrence credibility.\n\nBased on the assertion made above, I conclude by suggesting that reconsidering the practices of cyber deterrence through the theoretical framework presented in this article helps to sharpen traditional theories of deterrence. This study helps to elucidate another factor that affects the practices of deterrence in general: that is, the meaning of violence. As obvious as it may seem, framing or recognizing an attack as a violent act raises the cost of employing it as well as the cost of not retaliating after experiencing it. For example, it helps to clarify the term “cult of reputation,” which refers to actors’ need to demonstrate resolve. In this respect, it can be suggested that one of the elements that affects this need is whether the challenge is seen as a violent act or not. Likewise, although deterrence success does not require that actors share the exact same views of violence, having a common knowledge about what acts are considered “violent” might, as in the Cold War, enhance its chances.\n\nConsideration of these implications provides an interesting twist to current cyber deterrence scholarship, which has usually employed more traditional models of deterrence to explore deterrence in cyberspace. This paper suggests another move that could prove illuminating: applying insights from the study of cyber deterrence practices to more traditional practices of deterrence—that is, nuclear or conventional deterrence.\n\n## References\n\nADLER, EMANUEL. (1992) The Emergence of Cooperation: National Epistemic Communities and the International Evolution of the Idea of Nuclear Arms Control. *International Organization* 46 (1): 101–145.\n\nADLER, EMANUEL. (1997) Seizing the Middle Ground: Constructivism in World Politics. *European Journal of International Relations* 3 (3): 319–363.\n\nADLER, EMANUEL. (2009) Complex Deterrence in the Asymmetrical Warfare Era. In *Complex Deterrence: Theory and Practice in a New Era*, edited by T. V. Paul, Patrick M. Morgan, and James J. Wirtz. Chicago: University of Chicago Press.\n\nADLER, EMANUEL. (2010) Damned If You Do, Damned If You Don’t: Performative Power and the Strategy of Conventional and Nuclear Defusing. *Security Studies* 19 (2): 199–229.\n\nADLER, EMANUEL, AND VINCENT POULIOT. (2011) International Practices. *International Theory* 3 (1): 1–36.\n\nARQUILLA, JOHN. (2003) Thinking About New Security Paradigms. *Contemporary Security Policy* 24 (1): 299–225.\n\nBALZACQ, THIERRY. (2011) A Theory of Securitization: Origins, Core Assumptions, and Variants. In *Securitization Theory: How Security Problems Emerge and Dissolve*, edited by Thierry Balzacq. Oxon: Routledge.",
    "AMIR LUPOVICI\n19\n\nBARZASHKA, IVANKA. (2013) Are Cyber-Weapons Effective? The RUSI Journal 158 (2): 48–56.\nBEDNARZ, DIETER, AND ERICH FOLLATH. (2011) Iran’s Chief Nuclear Negotiator: “We Have to Be Constantly on Guard.” Der Spiegel, January 18. Available at: http://www.spiegel.de/international/world/iran-s-chief-nuclear-negotiator-we-have-to-be-constantly-on-guard-a-739945.html\nBEN MEIR, YEHUDA, AND OLENA BAGNO-MOLDAVSKY. (2013) The Voice of the People Israeli Public Opinion on National Security 2012. Tel Aviv: The Institute for National Security Studies.\nBENDRATH, RALF. (2003) The American Cyber-Angst and the Real World: Any Link? In Bombs and Bandwidth: The Emerging Relationship Between Information Technology and Security, edited by Robert Latham. New York: New Press.\nBERKOWITZ, BRUCE D. (1997) Warfare in the Information Age. In Athena’s Camp: Preparing for Conflict in the Information Age, edited by John Arquilla and David F. Ronfeldt. Santa Monica, CA: RAND.\nBETZ, DAVID J., AND TIM STEVENS. (2011) Cyberspace and the State: Toward a Strategy for Cyber-Power. Oxon: Routledge.\nBRUNNÉE, JUTTA, AND J. STEPHEN TOOPE. (2011) Interactional International Law and the Practice of Legality. In International Practices, edited by Emanuel Adler and Vincent Pouliot. New York: Cambridge University Press.\nBUZAN, BARRY, OLE WJEVER, AND JAAP DE WILDE. (1998) Security: A New Framework for Analysis. Boulder: Lynne Rienner.\nBVRES, ERIC, ANDREW GINTER, AND JOEL LANGILL. (2011) How Stuxnet Spreads—A Study of Infection Paths in Best Practice Systems. Tofino Security, white paper.\nCHOUCKI, NAZLI. (2012) Cyberpolitics in International Relations. Cambridge, MA: MIT Press.\nCLARKE, RICHARD A., AND ROBERT KNAKE. (2010) Cyber War: The Next Threat to National Security and What to Do About It. New York: Harper Collins.\nCORDESMAN, ANTHONY, AND JUSTIN CORDESMAN. (2001) Cyberthreats, Information Warfare, and Critical Infrastructure Protection: Defending the US Homeland. Westport: Praeger.\nDEIBERT, RON. (2002) Circuits of Power: Security in the Internet Environment. In Information Technologies and Global Politics: The Changing Scope of Power and Governance, edited by J. P. Singh and James N. Rosenau. New York: SUNY Press.\nDEIBERT, RON, AND RAFAL ROHOZINSKI. (2010) Risking Security: The Policies and Paradoxes of Cyberspace Security. International Political Sociology 4 (1): 15–32.\nDEIBERT, J. RONALD, RAFAL ROHOZINSKI, AND MASASHI CRETE-NISHIHATA. (2012) Cyclones in Cyberspace: Information Shaping and Denial in the 2008 Russia-Georgia War. Security Dialogue 43 (1): 3–24.\nDEVENNY, PATRICK. (2006) Hezbollah’s Strategic Threat to Israel. Middle East Quarterly 13 (1): 31–38.\nDIPERT, R. RANDALL. (2010) The Ethics of Cyberwarfare. Journal of Military Ethics 9 (4): 384–410.\nDUNN CAVELTY, MYRIAM. (2008) Cyber-Security and Threat Politics. New York: Routledge.\nDUNN CAVELTY, MYRIAM. (2010) Cyber-Security. In Routledge Handbook of Security Studies, edited by Victor Mauer and Myriam Dunn Cavelty. Oxon: Routledge.\nDUNN CAVELTY, MYRIAM. (2013) From Cyber-Bombs to Political Fallout: Threat Representations with an Impact in the Cyber-Security Discourse. International Studies Review 15 (1): 105–122.\nERIKSSON, JOHAN, AND GIAMPIERO GIACOMELLO. (2006) The Information Revolution, Security, and International Relations: (IR)Relevant Theory? International Political Science Review 27 (3): 221–244.\nFALK, JIM. (1989) The Discursive Shaping of Nuclear Militarism. Current Research on Peace and Violence 12 (2): 53–76.\nFARWELL, JAMES P., AND RAFAL ROHOZINSKI. (2011) Stuxnet and the Future of Cyber War. Survival 53 (1): 23–40.\nFEARON, JAMES. (2002) Selection Effects and Deterrence. International Interactions 28 (1): 5–29.\nFREDERKING, BRIAN. (2007) The United States and the Security Council: Collective Security Since the Cold War. London: Routledge.\nFREEDMAN, LAWRENCE. (2004) Deterrence. Cambridge: Polity Press.\nGOROVE, M. KATHERINE. (2000) Delimitation of Outer Space and the Aerospace Object—Where Is the Law? Journal of Space Law 28 (1): 11–28.\nGUITTON, CLEMENT, AND ELAINE KORZAK. (2013) The Sophistication Criterion for Attribution. The RUSI Journal 158 (4): 62–68.\nHANSEN, LENE, AND HELEN NISSENBAUM. (2009) Digital Disaster, Cyber Security, and the Copenhagen School. International Studies Quarterly 53 (4): 1155–1173.\nHARKNETT, J. RICHARD. (1996) Information Warfare and Deterrence. Parameters 26 (3): 93–107.\nHARRISON DINNISS, HEATHER. (2012) Cyber Warfare and the Laws of War. Cambridge: Cambridge University Press.\nHOPF, TED. (1994) Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965–1990. Ann Arbor: University of Michigan Press.\n\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016",
    "The \"Attribution Problem\" and the Social Construction of \"Violence\"\n\nHOPF, TED. (1998) The Promise of Constructivism in International Relations Theory. International Security 23 (1): 171-200.\nJACKSON, ROBERT. (2007) Sovereignty: The Evolution of an Idea. Cambridge: Polity.\nJOHNSTON, ALASTAIR IAIN. (1995) Thinking About Strategic Culture. International Security 19 (4): 32-64.\nKAM, EPHRAIM. (2012) An Attack on Iran: The Morning After. Strategic Assessment 15 (1): 15-27.\nKAYE, DALIA DASSA, ALIREZA NADER, AND PARISA ROSHAN. (2011) Israel and Iran. A Dangerous Rivalry. Santa Monica, CA: RAND.\nKELLO, LUCAS. (2013) The Meaning of the Cyber Revolution: Perils to Theory and Statecraft. International Security 38 (2): 7-40.\nKLEIN, BRADLEY. (1994) Strategic Studies and World Order. New York: Cambridge University Press.\nKRAMER, D. FRANKLIN. (2009) Cyberpower and National Security: Policy Recommendations for a Strategic Framework. In *Cyberpower and National Security*, edited by Franklin D. Kramer, Stuart H. Starr, and Larry K. Wentz. Washington, DC: National Defense University Press.\nKUGLER, L. RICHARD. (2009) Deterrence of Cyber Attacks. In *Cyberpower and National Security*, edited by Franklin D. Kramer, Stuart H. Starr, and Larry K. Wentz. Washington, DC: National Defense University Press.\nLACHOW, IRVING. (2009) Cyber Terrorism: Menace or Myth. In *Cyberpower and National Security*, edited by Franklin D. Kramer, Stuart H. Starr, and Larry K. Wentz. Washington: National Defense University Press.\nLANGNER, RALPH. (2013) Stuxnet's Secret Twin. Foreign Policy. Available at: http://www.foreignpolicy.com/articles/2013/11/19/stuxnets_secret_twin_iran_nukes_cyber_attack.\nLAWSON, SEAN. (2012) Putting the \"War\" in Cyber War: Metaphor, Analogy, and Cyber Security Discourse in the United States. First Monday 17 (7). Available at: http://firstmonday.org/ojs/index.php/fm/article/view/3848/3270.\nLEBOW, NED RICHARD. (2010) Forbidden Fruit: Counterfactuals and International Relations. Princeton: Princeton University Press.\nLEWIS, A. JAMES. (2010) Cross-Domain Deterrence and Credible Threats. Washington, DC: Center for Strategic and International Studies.\nLIBICKI, C. MARTIN. (2007) Conquest in Cyberspace. Cambridge: Cambridge University Press.\nLIBICKI, C. MARTIN. (2009) Cyber Deterrence and Cyberwar. Santa Monica, CA: RAND Corporation.\nLIFF, P. ADAM. (2012) Cyberwar: A New, \"Absolute Weapon?\" The Proliferation of Cyberwarfare Capabilities and Interstate War. Journal of Strategic Studies 35 (3): 401-428.\nLINDSAY, R. JON. (2013) Stuxnet and the Limits of Cyber Warfare. Security Studies 22 (3): 365-404.\nLONSDALE, DAVID J. (2004) The Nature of War in the Information Age: Clausewitzian Future. Oxon: Routledge.\nLUCAS, R. GEORGE JR. (2013) Can There Be an Ethical Cyber War? In Conflict and Cooperation in Cyberspace: The Challenge to National Security, edited by Panayotis A. Yannakogeorgos and Adam Lowther. Boca Raton, FL: Taylor &amp; Francis.\nLUKASIK, J. STEPHEN. (2010) A Framework for Thinking About Cyber Conflict and Cyber Deterrence with Possible Declaratory Policies for These Domains. In Proceedings of a Workshop on Deterring Cyberattacks, edited by John D. Steinbruner, et al. Washington, DC: The National Academies.\nLUKE, W. TIMOTHY. (1989) What's Wrong with Deterrence? A Semiotic Interpretation of National Security Policy. In International/Intertextual Relations, edited by James Der Derian and Michael J. Shapiro. New York: Lexington Books.\nLUPOVICI, AMIR. (2008) Deterrence Communities: The Success of a Rational Norm in the Relations of the Superpowers, 1950-1973. PhD Thesis, The Hebrew University, Jerusalem [in Hebrew].\nLUPOVICI, AMIR. (2010) The Emerging Fourth Wave of Deterrence Theory—Toward a New Research Agenda. International Studies Quarterly 54 (3): 705-732.\nLUPOVICI, AMIR. (2011) Cyber Warfare and Deterrence: Trends and Challenges. Military and Strategic Affairs 3 (3): 41-52.\nLUPOVICI, AMIR, AND ILAN DANJOUX. (2009) Deterrence in the Media Age: Public Opinion, and the Emergence of Deterrence 2.0. Paper presented at the American Political Science Association Annual Conference. Toronto, 2009.\nMILLIKEN, L. JENNIFER. (1996) Metaphors of Prestige and Reputation. In Post-Realism. The Rhetorical Turn in International Relations, edited by Francis A. Beer and Robert Hariman. Michigan: University of Michigan Press.\nMILLIKEN, L. JENNIFER. (1999) The Study of Discourse in International Relations: A Critique of Research and Methods. European Journal of International Relations 5 (2): 225-254.\nMOLANDER, ROGER C., ANDREW S. RIDDILE, AND PETER A. WILSON. (1996) Strategic Information Warfare: A New Face of War. Parameters 26 (3): 81-92.",
    "AMIR LUPOVICI\n21\n\nMORGAN, M. PATRICK. (2003) *Deterrence Now*. New York: Cambridge University Press.\nMORGAN, M. PATRICK. (2010) Applicability of Traditional Deterrence Concepts and Theory to the Cyber Realm. In *Proceedings of a Workshop on Deterring Cyberattacks*, edited by John D. Steinbruner, et al. Washington, DC: The National Academies.\nMORGAN, M. PATRICK. (2011) The Practice of Deterrence. In *International Practices*, edited by Emanuel Adler and Vincent Pouliot. New York: Cambridge University Press.\nNEUMANN, B. IVER. (1998) Identity and the Outbreak of War: Or Why the Copenhagen School of Security Studies Should Include the Idea of “Violisation” in Its Framework of Analysis. *International Journal of Peace Studies* 3: 7–22.\nNYE, JOSEPH S. (2011) *The Future of Power*. New York: Public Affairs.\nPAUL, T. V., PATRICK M. MORGAN, AND JAMES J. WIRTZ, Eds. (2009) *Complex Deterrence: Theory and Practice in a New Era*. Chicago: University of Chicago Press.\nPRICE, M. RICHARD. (1997) *The Chemical Weapons Taboo*. Ithaca, NY: Cornell University Press.\nRID, THOMAS. (2013) *Cyber War Will Not Take Place*. London: Hurst.\nSACO, DIANA. (1999) Colonizing Cyberspace: National Security and the Internet. In *Cultures of Insecurity: States, Communities and the Production of Danger*, edited by Jutta Weldes, Mark Laffey, Hugh Gusterson, and Raymond Duvall. Minneapolis: University of Minnesota Press.\nSADR, EHSANEH. (2005) The Impact of Iran’s Nuclearization on Israel. *Middle East Policy* 12 (2): 58–72.\nSANGER, DAVID. (2012) Obama Order Sped Up Wave of Cyberattacks Against Iran. *New York Times*, June 1. Available at: http://www.nytimes.com/2012/06/01/world/middleeast/obama-ordered-wave-of-cyberattacks-against-iran.html?pagewanted=all&amp;_r=0.\nSCHMITT, N. MICHAEL. (1999) Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework. *Columbia Journal of Transnational Law* 37: 885–937.\nSCHMITT, N. MICHAEL, ED. (2013) *Tallinn Manual on the International Law Applicable to Cyber Warfare*. New York: Cambridge University Press.\nSEARLE, JOHN R. (1995) *The Construction of Social Reality*. London: Penguin.\nSTERNER, ERIC. (2011) Retaliatory Deterrence in Cyberspace. *Strategic Studies Quarterly* 5 (1): 62–80.\nSTEVENS, TIM. (2012) A Cyberwar of Ideas? Deterrence and Norms in Cyberspace. *Contemporary Security Policy* 33 (1): 148–170.\nSTONE, JOHN. (2013) Cyber War Will Take Place! *Journal of Strategic Studies* 36 (1): 101–108.\nTALBOT, J. BRENT. (2011) Stuxnet and After. *Journal of International Security Affairs* 21: 69–78.\nTANG, SHIPING. (2005) Reputation, Cult of Reputation, and International Conflict. *Security Studies* 14 (1): 34–61.\nTANNENWALD, NINA. (2007) *The Nuclear Taboo: The United States and the Non-Use of Nuclear Weapons*. New York: Cambridge University Press.\nTETLOCK, PHILIP, AND AARON BELKIN. (1996) *Counterfactual Thought Experiments in World Politics: Logical, Psychological Perspectives*. Princeton: Princeton University Press.\nUS DEPARTMENT OF DEFENSE. (2010) *Dictionary of Military and Associated Terms*. Washington, DC: US Department of Defense.\nVUORI, A. JUHA. (2008) Illocutionary Logic and Strands of Securitization: Applying the Theory of Securitization to the Study of Non-Democratic Political Orders. *European Journal of International Relations* 14 (1): 65–99.\nWAXMAN, C. MATTHEW. (2011) Cyberattacks and the Use of Force: Back to the Future of Article 2(4). *Yale Journal of International Law* 36 (2): 421–459.\nWEHREY, FREDERIC, E. DAVID THALER, NORA BENSAHEL, KIM CRAGIN, JERROLD D. GREEN, DALIA DASSA KAYE, NADIA OWEIDAT, AND JENNIFER LI. (2009) *Dangerous but Not Omnipotent*. Santa Monica, CA: RAND.\nWELDES, JUTTA. (1999) *Constructing National Interests. The United States and the Cuban Missile Crisis*. Minneapolis: University of Minnesota Press.\nWHEATLEY, GARY F., AND E. RICHARD HAYES. (1996) *Information Warfare and Deterrence*. Washington: National Defense University Press.\nWILLIAMS, C. MICHAEL. (1992) Rethinking the “Logic” of Deterrence. *Alternatives* 17 (1): 67–93.\nYOULD, E. D. RACHEL. (2003) Beyond American Fortress: Understanding Homeland Security. In *Bombs and Bandwidth: The Emerging Relationship between Information Technology and Security*, edited by Robert Latham. New York: New Press.\n\nDownloaded from http://isp.oxfordjournals.org/ by guest on April 25, 2016"
  ],
  "metadata": {
    "title": "The \"Attribution Problem\" and the Social Construction of \"Violence\": Taking Cyber Deterrence Literature a Step Forward¹",
    "subtitle": "Tel Aviv University",
    "document_type": "journal_article",
    "venue": "¹I am grateful to Gallia Lindenstrauss, Deganit Paikowsky, and two anonymous reviewers for their helpful comments on previous drafts of this article.",
    "publication_year": 2012,
    "authors": [
      "AMIR LUPOVICI"
    ],
    "affiliations": [
      "Tel Aviv University"
    ],
    "emails": [
      "journals.permissions@oup.com"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [
      "cyber",
      "deterrence",
      "constructivism",
      "Stuxnet"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1111/insp.12082"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "http://www.wired.com/images_blogs/threatlevel/2010/03/wikithreat.pdf",
        "http://www.defense.gov/home/features/2011/0411_cyberstrategy/docs/NDAA%20Section%20934%20Report_For%20webpage.pdf"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 90,
    "heading_count": 14,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "title_looks_like_mid_paragraph_sentence",
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 48,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.20833333333333334,
      "footnote_coverage": 1.0,
      "unique_index_count": 24
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 82,
        "superscript_definition_lines": 19,
        "numeric_bracket_hits": 10,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 31.0,
      "dominant_bib_coverage_rate": 0.7741935483870968,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 14,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": true,
        "orcids": false,
        "abstract": false,
        "keywords": true,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 1,
        "affiliations": 1,
        "emails": 1,
        "orcids": 0,
        "keywords": 4,
        "doi": 1,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 2
      },
      "coverage": {
        "core_coverage": 1.0,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "title_looks_like_mid_paragraph_sentence",
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "missing_preceding_text",
      "meta_low_email_author_link_rate"
    ]
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 48.0,
      "success_occurrences": 48.0,
      "success_unique": 24.0,
      "bib_unique_total": 31.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.7741935483870968,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 48.0,
        "success_occurrences": 48.0,
        "success_unique": 24.0,
        "bib_unique_total": 31.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.7741935483870968,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 10.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 74.0,
        "success_occurrences": 74.0,
        "success_unique": 48.0,
        "bib_unique_total": 136.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.35294117647058826,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:18:15.082499+00:00"
}