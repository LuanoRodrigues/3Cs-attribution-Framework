{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\GMJ49DID\\(Justin Key Canfil, 2020).pdf",
  "custom_id": "267",
  "response": {
    "id": "batch-b6235e9e-268-3494455d-6cfe-4f33-91bf-2b3a0c1ee41d",
    "custom_id": "267",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "# Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay\n\nJustin Key Canfil\n\nJune 20, 2020\n\n## Abstract\n\nIt is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict.\n\nWord Count: 12,500\n\nKeywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 1,
            "markdown": "FORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.\n\nHow have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.\n\nScholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 2,
            "markdown": "it even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.”\n\nIn this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14].\n\nThe proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 3,
            "markdown": "response to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.\n\nThat is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.\n\n# 1 Cyber Proxies: What We Know\n\nWhether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident [24–27]. Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization [24, 30]. Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors [31].\n\n¹Long ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft [19]. Scholars have found that a majority of rebel groups since 1945 receive tacit state support [20] and this support has made these groups more powerful and influential [21]. They are observed most often between great power dyads [6, 22, 23], presumably because the risks associated with direct action are higher when targets can strike back.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 4,
            "markdown": "But states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto [33] explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.”² I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.\n\nThis of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting.³ More recent work by Florian Egloff [32] refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible [36].\n\nDetection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability [8, 35, 37–42]. Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.\n\n²Proxies \"may or may not be part of state security and intelligence agencies and may be criminal syndicates or private cybersecurity companies ... Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\" [33].\n\n³Maurer [35] writes that state sponsors can actively fund or otherwise support non-state cyber actors with the expectation that these actors will accomplish some military, intelligence, or foreign policy objective on behalf of the state (what Maurer terms “orchestrating”). Alternatively, sponsors can simply permit offensive operations by non-state actors by turning a blind eye (“sanctioning”). At the opposite end, a sponsor can establish effective in-house command and control over the group (“delegating”).\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 5,
            "markdown": "Victim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors [43]. If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.\n\nSome non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998 [44]. Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors [8]. Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments [45] to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy's fidelity, and plausible deniability is strengthened.\n\nThis logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea [47] – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries [38, 42, 49–51]. On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation [35, 46]. Between 9/11 and the start of the Iraq War, for example, when US nationalism soared,\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 6,
            "markdown": "the US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets [53]. On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.\n\nSo just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-$n$ datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto [33] explains, these data limitations have “crippled efforts to study … cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.\n\nThe third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.\n\nFor researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas [54–56], but for this reason the study of cyber proxies faces a special set of challenges.\n\n## 1.1 Observational Equivalence in Existing Data\n\nThe crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 7,
            "markdown": "doesn't convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.\n\nTo illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.[8]\n\nOne reasonable expectation might be that states are likelier to delegate certain tasks to proxies – for example, less sophisticated or less sensitive operations. We can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.[10] However, it only tracks proxy relationship onset.[11] As a strictly cumulative measure, it cannot be used to measure whether outsourcing has declined. Instead, we can use it to observe the rate at which states have continued to outsource to new groups in recent years.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 8,
            "markdown": "![img-0.jpeg](img-0.jpeg)\nFigure 1: Comparisons of trends over time from three datasets [33, 57, 58]. The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade.\n\nFigure 1 compares observations from all three datasets. The  $Y$ -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction.[12] Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [
              {
                "id": "img-0.jpeg",
                "top_left_x": 193,
                "top_left_y": 193,
                "bottom_right_x": 1502,
                "bottom_right_y": 926,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 9,
            "markdown": "We can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.\n\nThese trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto [33] explains that in order for the onset of a proxy relationship to appear in the dataset, \"there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government\" (emphasis mine). Akoto [33] continues: \"It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.\"¹³ Data collection is scoped on proxies which are already known to work for the state. Conclusion in the dataset is therefore inversely related the plausibility of a sponsor's deniability.\n\nWhat this means is that the large-$n$ information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.\n\nDirect measurements of outsourcing in available data cannot distinguish between these\n\n¹³ Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 10,
            "markdown": "competing accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn't plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.\n\n## 2 The Illogic of Plausible Deniability\n\nIt has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true.\n\nIn the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its \"most difficult problem\" [61]. The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible [12, 13, 64]. Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns [65].\n\nEven if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose [33]. States are often sensitive about divulging how they know what they know [66]. Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 11,
            "markdown": "a direct command role can be held responsible for the actions of their proxies [36, 67].¹⁴\n\nThese barriers are what make outsourcing so attractive, according to conventional wisdom [35]. But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal [33, 68]? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers [33, 69]. A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal [71] described plans to adopt a model reminiscent of US Cyber Command.\n\nFrom 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support [28]. Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000 [24], however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang [73] catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets [75]. Since then, the Chinese government has relied more on specialized units at the Ministry of State Security [35, 71]. Attacks\n\n¹⁴The International Law Commission (ILC)'s 2001 Draft Articles is perhaps the clearest articulation of the law on state responsibility (though often cited, it is actually a nonbinding source). In the ILC's view, a host state can only be held responsible if it directly conducts or oversees the offending operation at the operational level (see International Law Commission (ILC) Draft Articles on State Responsibility, 2001, http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf). International courts have held variously that the relationship must be one of \"effective control\" (Nicaragua v. United States), \"overall control\" plus the commission of specific acts (Prosecutor v. Dusko Tadic (1999)), or \"complete dependence\" (Bosnia and Herzegovina v. Serbia and Montenegro (1996)) – all very strict standards that elide the possibility of measures short of command or operational involvement. And in more than 4,700 claims proceedings, all but one tribunal (Dames &amp; Moore v. Iran) found that the burden of proof for wrongdoing rests with the defender (see Iran Claims Tribunal, https://www.state.gov/iran-u-s-claims-tribunal/).\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 12,
            "markdown": "originating from that country reveal a more direct government hand [76].¹⁵ If proxies pay for the reasons we usually suspect, then this behavior is puzzling.\n\nRarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect [12, 13, 77, 78]. Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.\n\nIn particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment [79]. Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices [80] – a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” [79].\n\n¹⁵ For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 13,
            "markdown": "It is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.”¹⁶ In a separate piece, Carlin [43] explains that the Criminal and National Security Divisions at DOJ \"increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases),\" including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.¹⁷\n\nThis level of cooperation gives the government specially enhanced attribution capabilities. Carlin [43] describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are” [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak [13].\n\nEspecially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin [43] admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: \"the government must demonstrate, among other things, that the ‘target ... is a foreign power or an agent of a foreign power’” if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.\n\nIndictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement [85–87]. To my knowledge, there is no institutional\n\n¹⁶ [for a detailed exposition in this journal, see 78].\n\n¹⁷ “The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 14,
            "markdown": "requirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” [89], they now seem more willing to punish sponsors for the activities of their proxies.¹⁸\n\nAfter all, why wouldn't victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate [90]. States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.\n\nRaising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.\n\n## 2.1 A Model of Outsourcing\n\nHow can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology\n\n¹⁸ Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 15,
            "markdown": "for checking and comparing a theory's internal validity this way. Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev [91], I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work \"under the hood\" in cases where data are questionable or unavailable.\n\nEvery theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large- $n$  data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes [92].\n\nIn the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims' beliefs and the level of investment. Under this framework, the sponsor's deniability is a function of its involvement and the target state's independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.\n\nThe model shows how a sponsor's concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 16,
            "markdown": "this holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship [8]. The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability's role in decisions about whether to outsource.\n\n## 2.2 Model setup\n\nA host government $(G)$ oversees a pool of non-state hackers $(H)$. The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as $\\varphi \\in [0,1]$, where $\\varphi &gt; 0$ is some positive degree of outsourcing. One can imagine that low levels of $\\varphi$ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at $\\varphi = 0$, for instance by implementing and enforcing laws against hacking foreign targets. In the game, $G$'s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.\n\nThe government's return on investment is given as $\\hat{u} x$, where $x$ is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker's level of sophistication, $\\psi_{i}$. The probability of a successful campaign is $\\psi_{i}$. I assume that individual operations are scalable, and thus the government obtains either full benefit $\\hat{u} x$ from a successful campaign $(\\psi = 1)$ or no benefit at all $(1 - \\psi)$.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 17,
            "markdown": "Consistent with default explanations, $G$ faces principal-agent problems vis-a-vis $H$. The degree of agent drift – a function of $H$'s operational discipline and its ideological sympathy with government objectives – is written as $\\theta$. The government's level of investment $x$, and thus its expected payoffs, are penalized increasing in $\\theta$. In other words, the less reliable the agent $(\\theta \\uparrow)$, the less useful its efforts.\n\nFinally, $G$ gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, $f(\\varphi)$, and that the attacker faces penalties increasing in attack scale, $x$. This would be modeled as $x \\times \\varphi$: the less centralized, the more deniability when scale is held constant.²⁰ The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target's right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.\n\n|  Term | Description | Range | Type  |\n| --- | --- | --- | --- |\n|  φ | Extent of outsourcing strategy | ∈ [0,1] | G’s Strategy  |\n|  ψ | Operational sophistication (probability of success) | ∈ [0,1] | Exogenous  |\n|  u | Return on scale of investment | ∈ R>0 | Exogenous  |\n|  x | Campaign investment | ∈ R>0 | Exogenous  |\n|  θ | Distance between principal / agent ideal points | ∈ R>0 | Exogenous  |\n|  γ | Fixed cost of centralization | ∈ R>0 | Exogenous  |\n|  c | Penalty of being caught & attributed | ∈ R>0 | Exogenous  |\n|  τ | Target’s ability to attribute (technical attrib.) | ∈ [0,1] | Exogenous  |\n|  α | Target’s willingness to accuse (political attrib.) | ∈ R>0 | Exogenous  |\n\nTable 1: Parameter Guide\n\nDeparting from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted $\\tau$, and political attribution, $\\alpha$.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 18,
            "markdown": "Attribution $\\tau_v$ is simply the probability of detection, determined by the target state's capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, $\\alpha_v &gt; 1$, is determined by the target state's tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state's capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence.\n\nThe government's payoff can be modeled as\n\n$$\nU_G(\\varphi) = \\psi \\hat{u} x (2 - \\varphi) - \\theta \\varphi x - \\gamma (1 - \\varphi) - \\tau_v c \\left(\\alpha_v(\\varphi) + x (1 - \\varphi)\\right)\n$$\n\nIn plain terms, $G$'s expected benefit is given by the balance of participation, $\\hat{u}(2 - \\varphi)$, times the probability the campaign is successful ($\\psi$), and the amount of material investment required ($x$). If the campaign is successful, $G$'s investment yields a return of $\\hat{u}x$. $G$ has a choice whether to outsource ($\\varphi &gt; 0$) or centralize the campaign ($\\varphi = 0$). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment ($\\theta x$). Centralization may also involve investment of some fixed downpayment $\\gamma$. For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, $G$ incurs some penalty based on the target's ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes $\\varphi$ given the parameters.\n\nAs a stricter test of the theory, eliminate any agent drift $\\theta$ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that $H$'s\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 19,
            "markdown": "skill is equivalent to $G$'s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in $\\varphi$ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, $G$'s decision hinges on $\\alpha$.\n\nFor simplicity, assume the return on investment is linearly increasing in average attack scale $(\\hat{u} = 1)$. Also equalize the $\\theta$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal.²¹ Like the model employed by Lindsay [13], this setup allows us to locate the optimal attack scale. Since I regard $x$ as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, $\\psi$, as a constant. Set $\\psi = 1$ for the most interesting case. As a final simplification, assume technical attribution is certain whenever $G$ attacks $(\\tau = 1)$, and that the penalty $c$ is linearly increasing in scale as a function of the cumulative evidence left behind $x$. This implies a one-to-one increase in the target's ability to implicate the host state if the host state runs the campaign directly, since in this case \"responsibility\" can be proven through technical means alone. Set $x, c = 1$.\n\nThis set of assumptions simplifies the equation to $U_{G}(\\varphi) = x(2 - \\varphi) - c(\\alpha_{\\varphi}(\\varphi) + x(1 - \\varphi))$. In order to constitute an equilibrium where $G$ outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies\n\n$$\n\\varphi &gt; \\frac{1}{a}\n$$\n\nwhich illustrates the general relationship between outsourcing $(\\varphi)$ and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us\n\n²¹ I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 20,
            "markdown": "$$\nU _ {G} (\\varphi) = x (2 - \\varphi) - (\\alpha_ {v} (\\varphi) + (1 - \\varphi))\n$$\n\nwhere expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and $\\varphi$ in Theorem 1.\n\nTheorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter's borders $(\\alpha)$, the lower the host state's incentive to outsource $(\\varphi)$.\n\nProof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of $\\varphi$ via straightforward optimization. The proof is concise enough to show in the body of the paper.\n\nWith no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: $(\\alpha_v(\\varphi) + (1 - \\varphi))^2$, which gives us the transformation\n\n$$\n\\max U _ {G} (\\varphi) = x (2 - \\varphi) - \\tau (\\alpha_ {v} (\\varphi) + (1 - \\varphi)) ^ {2}\n$$\n\nThe first order condition (FOC) must isolate at least one extremum in order to find a critical point at which $G$ will choose to switch between strategies. Differentiate the function with respect to $\\varphi$:\n\n$$\n\\frac {\\partial}{\\partial \\varphi} U _ {G} (\\cdot) = - (\\alpha + 1) (\\alpha \\varphi + \\varphi - 1) - x\n$$\n\nWe can then solve for the optimal level of $\\varphi$ by simply setting the derivative equal to zero and rearranging algebraically for $\\varphi$. This produces:\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 21,
            "markdown": "$$\n\\varphi^ {*} = \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\text{ where } \\alpha \\geq 0 \\text{ by assumption} \\tag{1}\n$$\n\nThe second order condition (SOC) confirms that $\\varphi^{*}$ is indeed a global maximum:\n\n$$\n\\frac {\\partial^ {2}}{\\partial^ {2} \\varphi} U _ {G} (\\varphi) = - a ^ {2} - 2 a - 1 \\text{ which is } &lt; 0 \\tag{2}\n$$\n\nWe observe from Equation 2 that the slope is decreasing at $U_{G}^{\\prime \\prime}$, proving that $\\varphi^{*}$ maximizes $G$'s payoff function.\n\n## 2.3 Analysis\n\nWe wish to know how $U_{G}(\\varphi^{*})$ changes with $\\alpha, x$. Substituting $\\varphi^{*}$ into the original equation find calculate $G$'s expected utility, we obtain\n\n$$\nU _ {G} (\\varphi^ {*}) = x \\left[ 2 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\right] - x \\left[ \\alpha \\left(\\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) + \\left(1 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) \\right]\n$$\n\n$$\n\\text{which is equivalent to } U _ {G} \\left(\\varphi^ {*}\\right) = \\frac {\\alpha x ^ {2} + \\alpha x + x}{\\alpha^ {2} + 2 \\alpha + 1} \\tag{3}\n$$\n\nEquation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility $G$ can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between $\\alpha$ and $x$, neither Equation 1 nor Equation 3 is immediately intuitive. The relationship becomes more apparent when $\\alpha$ is $\\varphi^{*}$ is plotted. Figure 2 (right)\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 22,
            "markdown": "![img-1.jpeg](img-1.jpeg)\nFigure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim's propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their \"plausible deniability\" appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able).\n\n![img-2.jpeg](img-2.jpeg)\n\nshows the utility gained for different levels of  $\\varphi$ . Outsourcing becomes less advantageous as  $\\alpha$  increases. In this model, the target state's  $\\alpha$  is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal  $\\varphi^{*}$ . As  $\\alpha$  increases, the expected gains of centralization  $(\\varphi^{*} \\downarrow)$  begin to exceed the gains from outsourcing  $(\\varphi^{*} \\uparrow)$ . The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay [13]'s findings on deterrence. Imputing values can help give us more precise point estimates.\n\nExample 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence  $(\\alpha = 0)$ . Then the optimal level of outsourcing is  $\\varphi^{*} = x$  and  $G$  would receive  $U_{G}(\\varphi^{*}) = \\tilde{u} x$  for any level of  $x$ . The value of  $x$  that maximizes this relationship is 1, so  $\\varphi^{*} = 1$ . In other\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [
              {
                "id": "img-1.jpeg",
                "top_left_x": 258,
                "top_left_y": 231,
                "bottom_right_x": 802,
                "bottom_right_y": 781,
                "image_base64": null,
                "image_annotation": null
              },
              {
                "id": "img-2.jpeg",
                "top_left_x": 897,
                "top_left_y": 237,
                "bottom_right_x": 1451,
                "bottom_right_y": 792,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 23,
            "markdown": "words, $G$ gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming $\\hat{u} &gt; 1$) that $G$ would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom.\n\nExample 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. $\\alpha = 10$. Then $\\varphi^{*} = (10x^{2} + 11x) / 121$, and the calculation becomes more complex.²² Fixing $\\varphi^{*} = 0.148$, $x^{*} = 0.895$ at their optima (see previous footnote), $G$ can expect to receive $0.148\\hat{u}$. Note that $G$'s maximum payoff is strictly (and significantly) lower when $\\alpha = 1$ no matter what its strategy. Payoffs diminish further as $\\alpha$ increases or return on investment $\\hat{u}$ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.\n\n## 2.4 Discussion\n\nIn nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states' increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.\n\nIn practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however,\n\n²² In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 24,
            "markdown": "that unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions [55] as opposed to decentralized strategies, such as outsourcing.\n\nPursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay [13] argues compellingly that a target’s willingness to assign blame and/or retaliate could be positively related to the scale of the attack. If true, the results may even underestimate the influence of $\\alpha$, and therefore overstate the rate of outsourcing. Operations that are serious enough to be of interest to the attacking state would likely invite in-kind retaliation even if the evidence were extremely flimsy. As technical attribution capabilities continue to improve and norms become more conducive as a consequence of emerging state practice, political attributions will only become more common.\n\n# 3 Empirical Strategy\n\nResearchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?\n\nThere is no dataset that tracks negative variation in proxy relationships over time. As mentioned,\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 25,
            "markdown": "|  EVIDENCE | VALUE |   | SUSPICIOUS TARGET  |\n| --- | --- | --- | --- |\n|  Uniformed Personnel | (5) | Direct proof | Implausibly deniable  |\n|  Agency/Contractor | (4) | Strong proof | Implausibly deniable  |\n|  IoCs: Known Group | (3) | Technical proof | Questionably deniable  |\n|  IoCs: Location | (2) | Technical proof | Plausibly deniable  |\n|  Cui bono | (1) | Circumstantial proof | Plausibly deniable  |\n|  No evidence | (0) | No proof | Plausibly deniable  |\n\nTable 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a  $\\{0:5\\}$  scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).\n\nAkoto [33] tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.\n\nEach observation in CFR's dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.[23] While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).\n\nFor information on victim responses, I rely on Hinck and Maurer [99]'s data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer [99] dataset up to date (2022) by\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 26,
            "markdown": "searching the DOJ's website for news and press releases under the category of cyber crime.²⁴\n\nUnsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive [100]. Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 [101]. Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step.²⁵ This generates a daily count variable ranging from 1 to 4.²⁶\n\nThe data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.\n\nIn Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a\n\n²⁴ https://www.justice.gov/news\n\n²⁵ These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.\n\n²⁶ It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 27,
            "markdown": "![img-3.jpeg](img-3.jpeg)\n\nFigure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time.\n\ngreater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof.²⁷ Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.\n\n²⁷ Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [
              {
                "id": "img-3.jpeg",
                "top_left_x": 277,
                "top_left_y": 261,
                "bottom_right_x": 1441,
                "bottom_right_y": 893,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 28,
            "markdown": "# 3.1 Analysis\n\nTo explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsourcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn't actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.\n\nIn the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.\n\nFor tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, *more insourcing* should imply *less outsourcing*.\n\nNext, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country $i$ was implicated in year $j$. In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 29,
            "markdown": "measuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.\n\nI include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony.\n\n|   | Dependent variables:  |   |   |   |\n| --- | --- | --- | --- | --- |\n|   | Observe Insourcing → Sponsor FE |   | Public Response  |   |\n|   | (1) | Two-Way FE | Sponsor FE | Two-Way FE  |\n|  Public Response (t-1) | 0.049*** (0.016) | 0.050*** (0.017) |  |   |\n|  Obs. Insourcing (t-1) |  |  | 0.028 (0.043) | 0.035 (0.042)  |\n|  Year (Control) | 0.015*** (0.005) |  | 0.013** (0.006) |   |\n|  Incident (Control) | 0.114*** (0.015) | 0.112*** (0.010) | 0.088*** (0.022) | 0.082*** (0.021)  |\n|  Observations | 186 | 186 | 186 | 186  |\n|  R2 | 0.450 | 0.304 | 0.355 | 0.207  |\n|  Adjusted R2 | 0.409 | 0.180 | 0.307 | 0.065  |\n|  Note: |  |  | *p<0.1; **p<0.05; ***p<0.01  |   |\n\nTable 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries' propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government's willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.\n\nTable 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 30,
            "markdown": "are presented in the odd columns as a robustness check.²⁸ Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insure operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.\n\nFirst examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t−1) are positively associated with decisions by other countries to insure in subsequent periods (p &lt; 0.01).²⁹ Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods.³⁰ Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.\n\nModels 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of\n\n²⁸ Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.\n\n²⁹ The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.\n\n³⁰ Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 31,
            "markdown": "a sponsor's involvement and its willingness to respond publicly ($p = 0.35$). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.\n\nWhy might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.\n\nMoreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\" [104].\n\nThough caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal [105]. The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 32,
            "markdown": "# 4 Conclusion\n\nScholars have long been interested in the conditions under which new cyber norms can emerge and proliferate [106–109]. Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible [110, 111]. Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is *in fact* on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.\n\nOn the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a *true* decline, or a turn away from *ineffective* proxies in favor of even stealthier alternatives.\n\nThis potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their *own* operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 33,
            "markdown": "attacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.\n\nAs opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.³¹\n\nWithout plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts [112]. In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway [56, 58]. If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.\n\nIf not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes [26, 115]. And at times and in places where online nationalism\n\n³¹ It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 34,
            "markdown": "is elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own [20, 116], a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals [117], helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.\n\nFormalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets [118], Gorwa and Smeets [119], and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance [119]. Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.\n\nCyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-$n$ studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 35,
            "markdown": "# Acknowledgements\n\nThe author is indebted to William Akoto, Jason Healey, Nadiya Kostyuk, Jon Lindsay, Mike Poznansky, Jack Snyder, Brandon Valeriano, JD Work, participants of the Digital Issues Discussion Group (DIDG), and four anonymous reviewers for helpful comments that improved this manuscript. This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484 (September 2021-November 2021) and 2021-2970 (November 2021 on).\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 36,
            "markdown": "# References\n\n1. Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46.\n\n2. Borghard, Erica. “Friends with Benefits? Power and Influence in Proxy Warfare”. PhD thesis. Columbia University, 2014.\n\n3. Salehyan, Idean, Siroky, David, and Wood, Reed M. “External Rebel Sponsorship and Civilian Abuse: A Principal-Agent Analysis of Wartime Atrocities”. In: *International Organization* 68.3 (2014). Publisher: [The MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 633–661.\n\n4. Szekely, Ora. “A Friend in Need: The Impact of the Syrian Civil War on Syria’s Clients (A Principal-Agent Approach)”. In: *Foreign Policy Analysis* 12.3 (July 1, 2016). Publisher: Oxford Academic, pp. 450–468.\n\n5. Abbott, Kenneth W. *Economic Sanctions and International Terrorism*. SSRN Scholarly Paper ID 1402844. Rochester, NY: Social Science Research Network, 1987.\n\n6. Kirchner, Magdalena. “‘A good investment?’ State sponsorship of terrorism as an instrument of Iraqi foreign policy (1979–1991)”. In: *Cambridge Review of International Affairs* 27.3 (July 3, 2014). Publisher: Routledge _eprint: https://doi.org/10.1080/09557571.2013.839629, pp. 521–537.\n\n7. Byman, Daniel and Kreps, Sarah E. “Agents of Destruction? Applying Principal-Agent Analysis to State-Sponsored Terrorism”. In: *International Studies Perspectives* 11.1 (Feb. 1, 2010). Publisher: Oxford Academic, pp. 1–18.\n\n8. Borghard, Erica D. and Lonergan, Shawn W. “Can States Calculate the Risks of Using Cyber Proxies?” In: *Orbis* 60.3 (Jan. 1, 2016), pp. 395–416.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 37,
            "markdown": "9. Applegate, Scott. \"Cybermilitias and Political Hackers: Use of Irregular Forces in Cyberwarfare\". In: IEEE Security Privacy 9.5 (Sept. 2011). Conference Name: IEEE Security Privacy, pp. 16–22.\n\n10. Poznansky, Michael and Perkoski, Evan. \"Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\". In: Journal of Global Security Studies 3.4 (Oct. 1, 2018), pp. 402–416.\n\n11. Brown, Joseph M. and Fazal, Tanisha M. “#SorryNotSorry: Why states neither confirm nor deny responsibility for cyber operations”. In: European Journal of International Security (Aug. 28, 2021). Publisher: Cambridge University Press, pp. 1–17.\n\n12. Baliga, Sandeep, Mesquita, Ethan Bueno de, and Wolitzky, Alexander. \"Deterrence with Imperfect Attribution\". In: American Political Science Review (2020).\n\n13. Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67.\n\n14. Cormac, Rory and Aldrich, Richard J. \"Grey is the new black: covert action and implausible deniability\". In: International Affairs 94.3 (May 1, 2018), pp. 477–494.\n\n15. Lin-Greenberg, Erik and Milonopoulos, Theo. \"Private Eyes in the Sky: Emerging Technology and the Political Consequences of Eroding Government Secrecy\". In: Journal of Conflict Resolution 65.6 (July 1, 2021). Publisher: SAGE Publications Inc, pp. 1067–1097.\n\n16. Vaynman, Jane. \"Better Monitoring and Better Spying: The Implications of Emerging Technology for Arms Control\". In: Texas National Security Review 4.4 (Sept. 23, 2021).\n\n17. Pitrelli, Monica Buchanan. 'For the first time in history anyone can join a war': Volunteers join Russia-Ukraine cyber fight. CNBC. Section: Technology. Mar. 14, 2022. URL: https://www.cnbc.com/2022/03/14/volunteers-sign-up-to-help-in-cyberwars-between-russia-and-ukraine-.html.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 38,
            "markdown": "18. Fedorov, Mykhailo. We are creating an IT army. We need digital talents. All operational tasks will be given here: https://t.me/itarmyofurraine. There will be tasks for everyone. We continue to fight on the cyber front. The first task is on the channel for cyber specialists. @FedorovMykhailo. Feb. 26, 2022. URL: https://twitter.com/FedorovMykhailo/status/1497642156076511233.\n\n19. Stephenson, Evan. “Does United Nations War Prevention Encourage State-Sponsorship of International Terrorism - An Economic Analysis”. In: Virginia Journal of International Law 44 (2003), p. 1197.\n\n20. Salehyan, Idean, Gleditsch, Kristian Skrede, and Cunningham, David E. “Explaining External Support for Insurgent Groups”. In: International Organization 65.4 (2011). Publisher: [MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 709–744.\n\n21. Hoffman, Bruce. Inside Terrorism. REV - Revised, 2. Columbia University Press, 2006.\n\n22. Findley, Michael G., Piazza, James A., and Young, Joseph K. “Games Rivals Play: Terrorism in International Rivalries”. In: The Journal of Politics 74.1 (Jan. 1, 2012). Publisher: The University of Chicago Press, pp. 235–248.\n\n23. Conrad, Justin. “Interstate Rivalry and Terrorism: An Unprobed Link”. In: Journal of Conflict Resolution 55.4 (Aug. 1, 2011). Publisher: SAGE Publications Inc, pp. 529–555.\n\n24. Singer, P. W. and Friedman, Allan. Cybersecurity and Cyberwar: What Everyone Needs to Know®. Google-Books-ID: B88ZAgAAQBAJ. Oxford University Press, Dec. 4, 2013. 836 pp.\n\n25. Gries, Peter Hays. China’s New Nationalism. First edition. Berkeley Los Angeles London: University of California Press, July 5, 2005. 226 pp.\n\n26. Weiss, Jessica Chen. *Powerful Patriots: Nationalist Protest in China’s Foreign Relations*. 1 edition. New York, NY: Oxford University Press, Sept. 1, 2014. 360 pp.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 39,
            "markdown": "27. Lemos, Robert. Defacements rise in China hacker war. CNET. Library Catalog: www.cnet.com. URL: https://www.cnet.com/news/defacements-rise-in-china-hacker-war/.\n\n28. Mulvenon, James C. et al. Chinese Responses to U.S. Military Transformation and Implications for the Department of Defense. Google-Books-ID: zHwnDNZNmdUC. Rand Corporation, Apr. 5, 2006. 187 pp.\n\n29. Bahovski, Erkki. Francis Maude: The Cyber-Attack against Estonia Was a Big Wake-Up Call for the World. Diplomaatria. Library Catalog: icds.ee. Aug. 2012. URL: https://icds.ee/francis-maude-the-cyber-attack-against-estonia-was-a-big-wake-up-call-for-the-world/.\n\n30. Shachtman, Noah. \"Kremlin Kids: We Launched the Estonian Cyber War\". In: Wired (Mar. 11, 2009).\n\n31. Nye, Joseph S. \"Cyber Power\". In: *Belfer Center for Science and International Affairs* (May 2010).\n\n32. Egloff, Florian J. Semi-State Actors in Cybersecurity. Oxford University Press, Dec. 20, 2021. 294 pp.\n\n33. Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264.\n\n34. Healey, Jason. \"The Spectrum of National Responsibility for Cyberattacks\". In: The Brown Journal of World Affairs 18.1 (2011). Publisher: Brown Journal of World Affairs, pp. 57–70.\n\n35. Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 40,
            "markdown": "36. Damrosch, Lori and Murphy, Sean. International Law. 6 edition. St. Paul, MN: West Academic Publishing, July 8, 2014. 1250 pp.\n\n37. Maurer, Tim. \"Cyber Proxies and Their Implications for Liberal Democracies\". In: The Washington Quarterly 41.2 (Apr. 3, 2018). Publisher: Routledge _eprint: https://doi.org/10.1080/0163660X.2018.1485332, pp. 171-188.\n\n38. Schmoldt, Janine. The Rising Power of Cyber Proxies. Vol. Thaddeus Eze (ed.) Google-Books-ID: wCo4EAAAQBAJ. Conferences Proceedings of 20th European Conference on Cyber Warfare and Security, June 24, 2021. 646 pp.\n\n39. Atwell, Kyle, Portzer, Joshua M., and McCurdy, Daphne. \"Negotiating [Im]plausible Deniability: Strategic Guidelines for U.S. Engagement in Modern Indirect Warfare\". In: PRISM 9.2 (2021). Publisher: Institute for National Strategic Security, National Defense University, pp. 112-121.\n\n40. Feuer, Samantha V. From the Shadows to the Front Page: State Use of Proxies for Cyber Operations. Freeman Spogli Institute for International Studies, Stanford University, 2020.\n\n41. Collier, Jamie. \"Proxy Actors in the Cyber Domain: Implications for State Strategy\". In: St Antony's International Review 13.1 (May 1, 2017), pp. 25-47.\n\n42. Maurer, Tim. Cyber Proxies and the Crisis in Ukraine. Vol. Cyber war in perspective: Russian aggression against Ukraine, Kenneth Geers (ed.) OCLC: 960393919. NATO Cooperative Cyber Defence Centre of Excellence, 2015.\n\n43. Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436.\n\n44. Denning, Dorothy. \"Cyber Conflict as an Emergent Social Phenomenon\". In: Corporate Hacking and Technology-driven Crime, Thomas J. Holt and Bernadette Hlubik Schell (eds.) IGI Global, Jan. 1, 2011.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 41,
            "markdown": "45. Segal, Adam. Beware the Patriotic Geek: The Risk of Cyber Militias in Asia. Council on Foreign Relations. Library Catalog: www.cfr.org. Feb. 22, 2012. URL: https://www.cfr.org/blog/beware-patriotic-geek-risk-cyber-militias-asia.\n\n46. Klimburg, Alexander. “Mobilising Cyber Power”. In: *Survival* 53.1 (Feb. 1, 2011). Publisher: Routledge _eprint: https://doi.org/10.1080/00396338.2011.555595, pp. 41–60.\n\n47. Trozzo, Eric. The Cyberdimension: A Political Theology of Cyberspace and Cybersecurity. Google-Books-ID: H0i6DwAAQBAJ. Wipf and Stock Publishers, Apr. 29, 2019. 293 pp.\n\n48. Ottis, Rain. “From Pitch Forks to Laptops: Volunteers in Cyber Conflicts”. In: *Conference on Cyber Conflict Proceedings* (2010), pp. 97–109.\n\n49. Pagliery, Jose. Meet the vigilante who’s hacked jihadist websites for years. CNNMoney. Library Catalog: money.cnn.com. Jan. 16, 2015. URL: https://money.cnn.com/2015/01/16/technology/security/jester-hacker-vigilante/index.html.\n\n50. Thornburgh, Nathan. “The Invasion of the Chinese Cyberspies”. In: *Time* (Aug. 29, 2005).\n\n51. Winter, Jana. Patriot hacker 'The Raptor' gains flock of followers after FoxNews.com report. Fox News. Last Modified: 2015-03-26T17:42:51-04:00 Library Catalog: www.foxnews.com Publisher: Fox News. Mar. 26, 2015. URL: https://www.foxnews.com/us/patriot-hacker-the-raptor-gains-flock-of-followers-after-foxnews-com-report.\n\n52. Bob, Yonah Jeremy and Joffre, Tzvi. *Iran’s Mahan Air hit by cyberattack*, materials allegedly linked to IRGC. The Jerusalem Post | JPost.com. Nov. 21, 2021. URL: https://www.jpost.com/breaking-news/irans-mahan-air-hit-by-cyberattack-685575.\n\n53. NIPC Encourages Heightened Cyber Security as Iraq - US Tensions Increase. National Infrastructure Protection Center (NIPC) Advisory 03-002. Feb. 11, 2003. URL: https://www.2600.com/news/mirrors/www.nipc.gov/warnings/advisories/2003/03-002.htm.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 42,
            "markdown": "54. Kostyuk, Nadiya and Zhukov, Yuri M. \"Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\" In: Journal of Conflict Resolution 63.2 (Feb. 1, 2019). Publisher: SAGE Publications Inc, pp. 317-347.\n\n55. Kostyuk, Nadiya. \"Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\". In: International Studies Quarterly (sqab039 May 28, 2021).\n\n56. Valeriano, Brandon. Cyber War versus Cyber Realities: Cyber Conflict in the International System. 1 edition. Oxford; New York: Oxford University Press, May 26, 2015. 288 pp.\n\n57. Tracking State-Sponsored Cyberattacks Around the World. Council on Foreign Relations. 2021. URL: https://www.cfr.org/cyber-operations.\n\n58. Valeriano, Brandon, Jensen, Benjamin, and Maness, Ryan C. Cyber Strategy: The Evolving Character of Power and Coercion. New York, NY: Oxford University Press, May 15, 2018. 320 pp.\n\n59. Franklin Kramer, Stuart H. Starr, and Larry Wentz, eds. Cyberpower and National Security. 1 edition. Washington, D.C: Potomac Books, Apr. 1, 2009. 664 pp.\n\n60. Libicki, Martin C. Cyberdeterrence and Cyberwar. Google-Books-ID: MJX6jL6IeF0C. Rand Corporation, Sept. 22, 2009. 239 pp.\n\n61. Betz, David and Stevens, Tim. Techniques for Cyber Attack Attribution. Institute for Defense Analyses, 2003. 82 pp.\n\n62. Landau, Susan and Lubin, Asaf. \"Examining the Anomalies, Explaining the Value: Should the USA Freedom Act's Metadata Program Be Extended?\" In: Harvard National Security Journal 11.3 (2020), pp. 308-358.\n\n63. Lin, Herbert. \"Attribution of Malicious Cyber Incidents: From Soup to Nuts\". In: Journal of International Affairs 70.1 (2016). Publisher: Journal of International Affairs Editorial Board, pp. 75-137.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 43,
            "markdown": "64. Rid, Thomas and Buchanan, Ben. “Attributing Cyber Attacks”. In: Journal of Strategic Studies 38.1 (Jan. 2, 2015). Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2014.977382, pp. 4–37.\n\n65. Canfil, Justin Key. Intelligence and Adversaries: What Do We Know? New York NY: Cyber Conflict Studies Association (CCSA), 2016.\n\n66. Carnegie, Allison and Carson, Austin. “The Disclosure Dilemma: Nuclear Intelligence and International Organizations”. In: American Journal of Political Science 63.2 (2019). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12426, pp. 269–285.\n\n67. Murphy, Sean D. Principles of International Law. Thomson/West, 2012. 575 pp.\n\n68. Canfil, Justin Key. “A Framework for Assessing Foreign State Complicity: A Framework for Assessing Foreign State Complicity”. In: Journal of International Affairs 70.1 (2016). Publisher: Journal of International Affairs Editorial Board, pp. 217–226.\n\n69. Weber, Valentin. “States and Their Proxies in Cyber Operations”. In: Lawfare (May 15, 2018).\n\n70. Cole, August and Healey, Jason. United States should discourage \"patriotic hackers\" from attacking North Korea. Atlantic Council. Library Catalog: www.atlanticcouncil.org. Dec. 23, 2014. URL: https://www.atlanticcouncil.org/blogs/new-atlanticist/us-should-discourage-patriotic-hackers-from-attacking-north-korea/.\n\n71. Segal, Adam. The Hacked World Order: How Nations Fight, Trade, Maneuver, and Manipulate in the Digital Age. 1 edition. New York: PublicAffairs, Feb. 23, 2016. 320 pp.\n\n72. Wu, Xu. Chinese Cyber Nationalism: Evolution, Characteristics, and Implications: Evolution, Characteristics, and Implications. Lexington Books, Sept. 26, 2007. 280 pp.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 44,
            "markdown": "73. Hang, Ryan. Freedom for Authoritarianism: Patriotic Hackers and Chinese Nationalism. The Yale Review of International Studies. Library Catalog: yris.yira.org. Oct. 12, 2014. URL: http://yris.yira.org/essays/1447.\n\n74. Henderson, Scott. The Dark Visitor. First edition. Scott Henderson, Oct. 24, 2007. 148 pp.\n\n75. Fletcher, Owen. *Patriotic Chinese Hacking Group Reboots*. WSJ. ISSN: 0099-9660 Library Catalog: blogs.wsj.com Section: World. Oct. 5, 2011. URL: https://blogs.wsj.com/chinarealtime/2011/10/05/patriotic-chinese-hacking-group-reboots/.\n\n76. Newman, Lily Hay. \"China Escalates Hacks Against the US as Trade Tensions Rise\". In: Wired (June 22, 2018).\n\n77. Egloff, Florian J. and Smeets, Max. \"Publicly attributing cyber attacks: a framework\". In: Journal of Strategic Studies 0.0 (Mar. 10, 2021). Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, pp. 1-32.\n\n78. Egloff, Florian J. \"Public attribution of cyber intrusions\". In: Journal of Cybersecurity 6.1 (Jan. 1, 2020).\n\n79. DOJ Press Release: U.S. Charges Five Chinese Military Hackers for Cyber Espionage Against U.S. Corporations and a Labor Organization for Commercial Advantage. Department of Justice Office of Public Affairs, May 19, 2014.\n\n80. Berghel, Hal. \"The Equifax Hack Revisited and Repurposed\". In: Computer 53.5 (May 1, 2020). Publisher: IEEE Computer Society, pp. 85-90.\n\n81. DOJ Press Release: U.S. Charges Three Chinese Hackers Who Work at Internet Security Firm for Hacking Three Corporations for Commercial Advantage. Department of Justice Office of Public Affairs, Nov. 27, 2017.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 45,
            "markdown": "82. DOJ Press Release: Two Chinese Hackers Associated With the Ministry of State Security Charged with Global Computer Intrusion Campaigns Targeting Intellectual Property and Confidential Business Information. Department of Justice Office of Public Affairs, Dec. 20, 2018.\n\n83. DOJ Press Release: Member of Sophisticated China-Based Hacking Group Indicted for Series of Computer Intrusions, Including 2015 Data Breach of Health Insurer Anthem Inc. Affecting Over 78 Million People. Department of Justice Office of Public Affairs, May 9, 2019.\n\n84. DOJ Press Release: Attorney General William P. Barr Announces Indictment of Four Members of China's Military for Hacking into Equifax. Department of Justice Office of Public Affairs, Feb. 10, 2020.\n\n85. Nakashima, Ellen and Lynch, David J. U. S. charges Chinese hackers in alleged theft of vast trove of confidential data in 12 countries. Washington Post. Dec. 21, 2018. URL: https://www.washingtonpost.com/world/national-security/us-and-more-than-a-dozen-allies-to-condemn-china-for-economic-espionage/2018/12/20/cdfd0338-0455-11e9-b5df-5d3874f1ac36_story.html.\n\n86. Harknett, Richard and Fischerkeller, Michael. Persistent Engagement and Tacit Bargaining: A Path Toward Constructing Norms in Cyberspace. Lawfare. Nov. 9, 2018. URL: https://www.lawfareblog.com/persistent-engagement-and-tacit-bargaining-path-toward-constructing-norms-cyberspace.\n\n87. Miller, James N. and Pollard, Neal A. Persistent Engagement, Agreed Competition and Deterrence in Cyberspace. Lawfare. Apr. 30, 2019. URL: https://www.lawfareblog.com/persistent-engagement-agreed-competition-and-deterrence-cyberspace.\n\n88. Waxman, Matthew C. \"Cyber-Attacks and the Use of Force: Back to the Future of Article 2(4)\". In: Yale Journal of International Law 36.2 (2011), pp. 421-460.\n\n89. Kaminska, Monica. \"Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks\". In: Journal of Cybersecurity 7.1 (Jan. 1, 2021), tyab008.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 46,
            "markdown": "90. Egloff, Florian J and Dunn Cavelty, Myriam. \"Attribution and Knowledge Creation Assemblages in Cybersecurity Politics\". In: Journal of Cybersecurity 7.1 (Jan. 1, 2021), tyab002.\n\n91. Axelrod, Robert and Iliev, Rumen. \"Timing of cyber conflict\". In: Proceedings of the National Academy of Sciences 111.4 (Jan. 28, 2014). Publisher: National Academy of Sciences Section: Physical Sciences, pp. 1298–1303.\n\n92. Gailmard, Sean and Patty, John W. “Preventing Prevention”. In: American Journal of Political Science 63.2 (2019). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12411, pp. 342–352.\n\n93. Byman, Daniel et al. \"Iraq, Afghanistan and the War on Terror\". In: Middle East Policy 12.1 (2005). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1061-1924.2005.00183.x, pp. 1–24.\n\n94. Quillen, Chris. “A Historical Analysis of Mass Casualty Bombers”. In: Studies in Conflict &amp; Terrorism 25.5 (Sept. 1, 2002). Publisher: Routledge _eprint: https://doi.org/10.1080/10576100290101197, pp. 279–292.\n\n95. Hoffman, Bruce. *Terrorism and Weapons of Mass Destruction: An Analysis of Trends and Motivations*. Product Page. Publisher: RAND Corporation. RAND, 1999.\n\n96. Benjamin, Daniel and Simon, Steven. The Age of Sacred Terror: Radical Islam’s War Against America. Reprint edition. New York: Random House Trade Paperbacks, Oct. 14, 2003. 560 pp.\n\n97. Merari, Ariel. \"Terrorism as a strategy of insurgency\". In: Terrorism and Political Violence 5.4 (Dec. 1, 1993). Publisher: Routledge _eprint: https://doi.org/10.1080/09546559308427227, pp. 213–251.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 47,
            "markdown": "98. Anderson, Sean K. \"US Counterinsurgency vs Iranian-Sponsored Terrorism\". In: *Low Intensity Conflict &amp; Law Enforcement* 11.2 (June 1, 2002). Publisher: Routledge _eprint: https://doi.org/10.1080/0966284042000279027, pp. 254–270.\n\n99. Hinck, Garrett and Maurer, Tim. \"Persistent Enforcement: Criminal Charges as a Response to Nation-State Malicious Cyber Activity\". In: *Journal of National Security Law and Policy* 10.3 (2019), pp. 525–562.\n\n100. Gomez, Miguel Alberto and Whyte, Christopher. \"Unpacking Strategic Behavior in Cyberspace: A Schema-Driven Approach\". In: *Journal of Cybersecurity* (2022). forthcoming, pp. 1–16.\n\n101. Franceschi-Bicchierai, Lorenzo. *Chinese Cybersecurity Company Doxes Apparent NSA Hacking Operation*. Vice. Feb. 23, 2022. URL: https://www.vice.com/en/article/v7dxg3/chinese-cybersecurity-company-doxes-apparent-nsa-hacking-operation.\n\n102. Kropko, Jonathan and Kubinec, Robert. \"Interpretation and identification of within-unit and cross-sectional variation in panel data models\". In: *PLOS ONE* 15.4 (Apr. 21, 2020). Publisher: Public Library of Science, e0231349.\n\n103. Hanson, Bruce E. “A Modern Gauss-Markov Theorem”. In: *Econometrica* (Dec. 1, 2021).\n\n104. Mummolo, Jonathan and Peterson, Erik. \"Improving the Interpretation of Fixed Effects Regression Results\". In: *Political Science Research and Methods* 6.4 (Oct. 2018). Publisher: Cambridge University Press, pp. 829–835.\n\n105. Healey, Jason. *China Is a Cyber Victim, Too*. Foreign Policy. Apr. 16, 2013. URL: https://foreignpolicy.com/2013/04/16/china-is-a-cyber-victim-too/.\n\n106. Hollis, Duncan B. *Why States Need an International Law for Information Operations*. SSRN Scholarly Paper ID 1083889. Rochester, NY: Social Science Research Network, Jan. 17, 2008.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 48,
            "markdown": "107. Healey, Jason and Maurer, Tim. \"What it'll take to forge peace in cyberspace\". In: Christian Science Monitor (Mar. 20, 2017).\n\n108. Finnemore, Martha and Hollis, Duncan B. \"Constructing Norms for Global Cybersecurity\". In: American Journal of International Law 110.3 (July 2016). Publisher: Cambridge University Press, pp. 425–479.\n\n109. Maurer, Tim. \"Cyber Norm Emergence at the United Nations—An Analysis of the UN's Activities Regarding Cyber-security\". In: Science, Technology, and Public Policy Program, Belfer Center (2011).\n\n110. Hare, Forrest B. \"Privateering in Cyberspace: Should Patriotic Hacking Be Promoted as National Policy?\" In: *Asian Security* 15.2 (May 4, 2019). Publisher: Routledge _eprint: https://doi.org/10.1080/14799855.2017.1414803, pp. 93–102.\n\n111. Egloff, Florian J. \"Cybersecurity and non-state actors: a historical analogy with mercantile companies, privateers, and pirates\". http://purl.org/dc/dcmitype/Text. University of Oxford, 2018.\n\n112. Sandler, Todd and Siqueira, Kevin. \"Global terrorism: deterrence versus pre-emption\". In: Canadian Journal of Economics/Revue canadienne d'économique 39.4 (2006). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-5982.2006.00393.x, pp. 1370–1387.\n\n113. Crosston, Matthew. \"Virtual Patriots and a New American Cyber Strategy: Changing the Zero-Sum Game\". In: Strategic Studies Quarterly 6.4 (2012). Publisher: Air University Press, pp. 100–118.\n\n114. MacKinnon, Rebecca. \"China's Networked Authoritarianism\". In: \"Journal of Democracy 22.2 (2011), pp. 32–46.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 49,
            "markdown": "115. Hjortdal, Magnus. “China’s Use of Cyber Warfare: Espionage Meets Strategic Deterrence”. In: *Journal of Strategic Security* 4.2 (2011). Publisher: University of South Florida Board of Trustees, pp. 1–24.\n\n116. Freeman, Michael. “The Sources of Terrorist Financing: Theory and Typology”. In: *Studies in Conflict &amp; Terrorism* 34.6 (June 1, 2011). Publisher: Routledge _eprint: https://doi.org/10.1080/1057610X.2011.571193, pp. 461–475.\n\n117. DeVore, Marc R. “Exploring the Iran-Hezbollah Relationship: A Case Study of how State Sponsorship affects Terrorist Group Decision-Making”. In: *Perspectives on Terrorism* 6.4 (2012). Publisher: Terrorism Research Institute, pp. 85–107.\n\n118. Herr, Trey, Laudrain, Arthur P. B., and Smeets, Max. “Mapping the Known Unknowns of Cybersecurity Education: A Review of Syllabi on Cyber Conflict and Security”. In: *Journal of Political Science Education* 0.0 (Feb. 28, 2020). Publisher: Routledge _eprint: https://doi.org/10.1080/15512169.2020.1729166, pp. 1–17.\n\n119. Gorwa, Robert and Smeets, Max. *Cyber Conflict in Political Science: A Review of Methods and Literature*. 2019 ISA Working Paper. July 25, 2019.\n\nElectronic copy available at: https://ssrn.com/abstract=3611582",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 50,
          "doc_size_bytes": 2193584
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "# Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay\nJustin Key Canfil\nJune 20, 2020\n## Abstract\nIt is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict.\nWord Count: 12,500\nKeywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.\nHow have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.\nScholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give\nElectronic copy available at: https://ssrn.com/abstract=3611582\nit even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.”\nIn this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14].\nThe proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in\nElectronic copy available at: https://ssrn.com/abstract=3611582\nresponse to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.\nThat is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.\n# 1 Cyber Proxies: What We Know\nWhether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident [24–27]. Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization [24, 30]. Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors [31].\n¹Long ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft [19]. Scholars have found that a majority of rebel groups since 1945 receive tacit state support [20] and this support has made these groups more powerful and influential [21]. They are observed most often between great power dyads [6, 22, 23], presumably because the risks associated with direct action are higher when targets can strike back.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nBut states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto [33] explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.”² I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.\nThis of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting.³ More recent work by Florian Egloff [32] refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible [36].\nDetection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability [8, 35, 37–42]. Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.\n²Proxies \"may or may not be part of state security and intelligence agencies and may be criminal syndicates or private cybersecurity companies ... Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\" [33].\n³Maurer [35] writes that state sponsors can actively fund or otherwise support non-state cyber actors with the expectation that these actors will accomplish some military, intelligence, or foreign policy objective on behalf of the state (what Maurer terms “orchestrating”). Alternatively, sponsors can simply permit offensive operations by non-state actors by turning a blind eye (“sanctioning”). At the opposite end, a sponsor can establish effective in-house command and control over the group (“delegating”).\nElectronic copy available at: https://ssrn.com/abstract=3611582\nVictim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors [43]. If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.\nSome non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998 [44]. Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors [8]. Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments [45] to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy's fidelity, and plausible deniability is strengthened.\nThis logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea [47] – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries [38, 42, 49–51]. On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation [35, 46]. Between 9/11 and the start of the Iraq War, for example, when US nationalism soared,\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthe US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets [53]. On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.\nSo just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-$n$ datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto [33] explains, these data limitations have “crippled efforts to study … cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.\nThe third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.\nFor researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas [54–56], but for this reason the study of cyber proxies faces a special set of challenges.\n## 1.1 Observational Equivalence in Existing Data\nThe crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing\nElectronic copy available at: https://ssrn.com/abstract=3611582\ndoesn't convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.\nTo illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.[8]\nOne reasonable expectation might be that states are likelier to delegate certain tasks to proxies – for example, less sophisticated or less sensitive operations. We can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.[10] However, it only tracks proxy relationship onset.[11] As a strictly cumulative measure, it cannot be used to measure whether outsourcing has declined. Instead, we can use it to observe the rate at which states have continued to outsource to new groups in recent years.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 1: Comparisons of trends over time from three datasets [33, 57, 58]. The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade.\nFigure 1 compares observations from all three datasets. The  $Y$ -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction.[12] Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nWe can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.\nThese trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto [33] explains that in order for the onset of a proxy relationship to appear in the dataset, \"there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government\" (emphasis mine). Akoto [33] continues: \"It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.\"¹³ Data collection is scoped on proxies which are already known to work for the state. Conclusion in the dataset is therefore inversely related the plausibility of a sponsor's deniability.\nWhat this means is that the large-$n$ information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.\nDirect measurements of outsourcing in available data cannot distinguish between these\n¹³ Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].\nElectronic copy available at: https://ssrn.com/abstract=3611582\ncompeting accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn't plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.\n## 2 The Illogic of Plausible Deniability\nIt has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true.\nIn the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its \"most difficult problem\" [61]. The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible [12, 13, 64]. Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns [65].\nEven if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose [33]. States are often sensitive about divulging how they know what they know [66]. Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on\nElectronic copy available at: https://ssrn.com/abstract=3611582\na direct command role can be held responsible for the actions of their proxies [36, 67].¹⁴\nThese barriers are what make outsourcing so attractive, according to conventional wisdom [35]. But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal [33, 68]? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers [33, 69]. A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal [71] described plans to adopt a model reminiscent of US Cyber Command.\nFrom 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support [28]. Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000 [24], however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang [73] catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets [75]. Since then, the Chinese government has relied more on specialized units at the Ministry of State Security [35, 71]. Attacks\n¹⁴The International Law Commission (ILC)'s 2001 Draft Articles is perhaps the clearest articulation of the law on state responsibility (though often cited, it is actually a nonbinding source). In the ILC's view, a host state can only be held responsible if it directly conducts or oversees the offending operation at the operational level (see International Law Commission (ILC) Draft Articles on State Responsibility, 2001, http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf). International courts have held variously that the relationship must be one of \"effective control\" (Nicaragua v. United States), \"overall control\" plus the commission of specific acts (Prosecutor v. Dusko Tadic (1999)), or \"complete dependence\" (Bosnia and Herzegovina v. Serbia and Montenegro (1996)) – all very strict standards that elide the possibility of measures short of command or operational involvement. And in more than 4,700 claims proceedings, all but one tribunal (Dames &amp; Moore v. Iran) found that the burden of proof for wrongdoing rests with the defender (see Iran Claims Tribunal, https://www.state.gov/iran-u-s-claims-tribunal/).\nElectronic copy available at: https://ssrn.com/abstract=3611582\noriginating from that country reveal a more direct government hand [76].¹⁵ If proxies pay for the reasons we usually suspect, then this behavior is puzzling.\nRarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect [12, 13, 77, 78]. Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.\nIn particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment [79]. Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices [80] – a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” [79].\n¹⁵ For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nIt is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.”¹⁶ In a separate piece, Carlin [43] explains that the Criminal and National Security Divisions at DOJ \"increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases),\" including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.¹⁷\nThis level of cooperation gives the government specially enhanced attribution capabilities. Carlin [43] describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are” [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak [13].\nEspecially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin [43] admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: \"the government must demonstrate, among other things, that the ‘target ... is a foreign power or an agent of a foreign power’” if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.\nIndictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement [85–87]. To my knowledge, there is no institutional\n¹⁶ [for a detailed exposition in this journal, see 78].\n¹⁷ “The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].\nElectronic copy available at: https://ssrn.com/abstract=3611582\nrequirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” [89], they now seem more willing to punish sponsors for the activities of their proxies.¹⁸\nAfter all, why wouldn't victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate [90]. States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.\nRaising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.\n## 2.1 A Model of Outsourcing\nHow can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology\n¹⁸ Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nfor checking and comparing a theory's internal validity this way. Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev [91], I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work \"under the hood\" in cases where data are questionable or unavailable.\nEvery theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large- $n$  data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes [92].\nIn the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims' beliefs and the level of investment. Under this framework, the sponsor's deniability is a function of its involvement and the target state's independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.\nThe model shows how a sponsor's concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthis holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship [8]. The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability's role in decisions about whether to outsource.\n## 2.2 Model setup\nA host government $(G)$ oversees a pool of non-state hackers $(H)$. The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as $\\varphi \\in [0,1]$, where $\\varphi &gt; 0$ is some positive degree of outsourcing. One can imagine that low levels of $\\varphi$ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at $\\varphi = 0$, for instance by implementing and enforcing laws against hacking foreign targets. In the game, $G$'s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.\nThe government's return on investment is given as $\\hat{u} x$, where $x$ is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker's level of sophistication, $\\psi_{i}$. The probability of a successful campaign is $\\psi_{i}$. I assume that individual operations are scalable, and thus the government obtains either full benefit $\\hat{u} x$ from a successful campaign $(\\psi = 1)$ or no benefit at all $(1 - \\psi)$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nConsistent with default explanations, $G$ faces principal-agent problems vis-a-vis $H$. The degree of agent drift – a function of $H$'s operational discipline and its ideological sympathy with government objectives – is written as $\\theta$. The government's level of investment $x$, and thus its expected payoffs, are penalized increasing in $\\theta$. In other words, the less reliable the agent $(\\theta \\uparrow)$, the less useful its efforts.\nFinally, $G$ gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, $f(\\varphi)$, and that the attacker faces penalties increasing in attack scale, $x$. This would be modeled as $x \\times \\varphi$: the less centralized, the more deniability when scale is held constant.²⁰ The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target's right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.\n|  Term | Description | Range | Type  |\n| --- | --- | --- | --- |\n|  φ | Extent of outsourcing strategy | ∈ [0,1] | G’s Strategy  |\n|  ψ | Operational sophistication (probability of success) | ∈ [0,1] | Exogenous  |\n|  u | Return on scale of investment | ∈ R>0 | Exogenous  |\n|  x | Campaign investment | ∈ R>0 | Exogenous  |\n|  θ | Distance between principal / agent ideal points | ∈ R>0 | Exogenous  |\n|  γ | Fixed cost of centralization | ∈ R>0 | Exogenous  |\n|  c | Penalty of being caught & attributed | ∈ R>0 | Exogenous  |\n|  τ | Target’s ability to attribute (technical attrib.) | ∈ [0,1] | Exogenous  |\n|  α | Target’s willingness to accuse (political attrib.) | ∈ R>0 | Exogenous  |\nTable 1: Parameter Guide\nDeparting from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted $\\tau$, and political attribution, $\\alpha$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nAttribution $\\tau_v$ is simply the probability of detection, determined by the target state's capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, $\\alpha_v &gt; 1$, is determined by the target state's tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state's capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence.\nThe government's payoff can be modeled as\n$$\nU_G(\\varphi) = \\psi \\hat{u} x (2 - \\varphi) - \\theta \\varphi x - \\gamma (1 - \\varphi) - \\tau_v c \\left(\\alpha_v(\\varphi) + x (1 - \\varphi)\\right)\n$$\nIn plain terms, $G$'s expected benefit is given by the balance of participation, $\\hat{u}(2 - \\varphi)$, times the probability the campaign is successful ($\\psi$), and the amount of material investment required ($x$). If the campaign is successful, $G$'s investment yields a return of $\\hat{u}x$. $G$ has a choice whether to outsource ($\\varphi &gt; 0$) or centralize the campaign ($\\varphi = 0$). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment ($\\theta x$). Centralization may also involve investment of some fixed downpayment $\\gamma$. For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, $G$ incurs some penalty based on the target's ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes $\\varphi$ given the parameters.\nAs a stricter test of the theory, eliminate any agent drift $\\theta$ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that $H$'s\nElectronic copy available at: https://ssrn.com/abstract=3611582\nskill is equivalent to $G$'s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in $\\varphi$ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, $G$'s decision hinges on $\\alpha$.\nFor simplicity, assume the return on investment is linearly increasing in average attack scale $(\\hat{u} = 1)$. Also equalize the $\\theta$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal.²¹ Like the model employed by Lindsay [13], this setup allows us to locate the optimal attack scale. Since I regard $x$ as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, $\\psi$, as a constant. Set $\\psi = 1$ for the most interesting case. As a final simplification, assume technical attribution is certain whenever $G$ attacks $(\\tau = 1)$, and that the penalty $c$ is linearly increasing in scale as a function of the cumulative evidence left behind $x$. This implies a one-to-one increase in the target's ability to implicate the host state if the host state runs the campaign directly, since in this case \"responsibility\" can be proven through technical means alone. Set $x, c = 1$.\nThis set of assumptions simplifies the equation to $U_{G}(\\varphi) = x(2 - \\varphi) - c(\\alpha_{\\varphi}(\\varphi) + x(1 - \\varphi))$. In order to constitute an equilibrium where $G$ outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies\n$$\n\\varphi &gt; \\frac{1}{a}\n$$\nwhich illustrates the general relationship between outsourcing $(\\varphi)$ and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us\n²¹ I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\nU _ {G} (\\varphi) = x (2 - \\varphi) - (\\alpha_ {v} (\\varphi) + (1 - \\varphi))\n$$\nwhere expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and $\\varphi$ in Theorem 1.\nTheorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter's borders $(\\alpha)$, the lower the host state's incentive to outsource $(\\varphi)$.\nProof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of $\\varphi$ via straightforward optimization. The proof is concise enough to show in the body of the paper.\nWith no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: $(\\alpha_v(\\varphi) + (1 - \\varphi))^2$, which gives us the transformation\n$$\n\\max U _ {G} (\\varphi) = x (2 - \\varphi) - \\tau (\\alpha_ {v} (\\varphi) + (1 - \\varphi)) ^ {2}\n$$\nThe first order condition (FOC) must isolate at least one extremum in order to find a critical point at which $G$ will choose to switch between strategies. Differentiate the function with respect to $\\varphi$:\n$$\n\\frac {\\partial}{\\partial \\varphi} U _ {G} (\\cdot) = - (\\alpha + 1) (\\alpha \\varphi + \\varphi - 1) - x\n$$\nWe can then solve for the optimal level of $\\varphi$ by simply setting the derivative equal to zero and rearranging algebraically for $\\varphi$. This produces:\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\n\\varphi^ {*} = \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\text{ where } \\alpha \\geq 0 \\text{ by assumption} \\tag{1}\n$$\nThe second order condition (SOC) confirms that $\\varphi^{*}$ is indeed a global maximum:\n$$\n\\frac {\\partial^ {2}}{\\partial^ {2} \\varphi} U _ {G} (\\varphi) = - a ^ {2} - 2 a - 1 \\text{ which is } &lt; 0 \\tag{2}\n$$\nWe observe from Equation 2 that the slope is decreasing at $U_{G}^{\\prime \\prime}$, proving that $\\varphi^{*}$ maximizes $G$'s payoff function.\n## 2.3 Analysis\nWe wish to know how $U_{G}(\\varphi^{*})$ changes with $\\alpha, x$. Substituting $\\varphi^{*}$ into the original equation find calculate $G$'s expected utility, we obtain\n$$\nU _ {G} (\\varphi^ {*}) = x \\left[ 2 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\right] - x \\left[ \\alpha \\left(\\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) + \\left(1 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) \\right]\n$$\n$$\n\\text{which is equivalent to } U _ {G} \\left(\\varphi^ {*}\\right) = \\frac {\\alpha x ^ {2} + \\alpha x + x}{\\alpha^ {2} + 2 \\alpha + 1} \\tag{3}\n$$\nEquation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility $G$ can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between $\\alpha$ and $x$, neither Equation 1 nor Equation 3 is immediately intuitive. The relationship becomes more apparent when $\\alpha$ is $\\varphi^{*}$ is plotted. Figure 2 (right)\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim's propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their \"plausible deniability\" appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able).\nshows the utility gained for different levels of  $\\varphi$ . Outsourcing becomes less advantageous as  $\\alpha$  increases. In this model, the target state's  $\\alpha$  is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal  $\\varphi^{*}$ . As  $\\alpha$  increases, the expected gains of centralization  $(\\varphi^{*} \\downarrow)$  begin to exceed the gains from outsourcing  $(\\varphi^{*} \\uparrow)$ . The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay [13]'s findings on deterrence. Imputing values can help give us more precise point estimates.\nExample 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence  $(\\alpha = 0)$ . Then the optimal level of outsourcing is  $\\varphi^{*} = x$  and  $G$  would receive  $U_{G}(\\varphi^{*}) = \\tilde{u} x$  for any level of  $x$ . The value of  $x$  that maximizes this relationship is 1, so  $\\varphi^{*} = 1$ . In other\nElectronic copy available at: https://ssrn.com/abstract=3611582\nwords, $G$ gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming $\\hat{u} &gt; 1$) that $G$ would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom.\nExample 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. $\\alpha = 10$. Then $\\varphi^{*} = (10x^{2} + 11x) / 121$, and the calculation becomes more complex.²² Fixing $\\varphi^{*} = 0.148$, $x^{*} = 0.895$ at their optima (see previous footnote), $G$ can expect to receive $0.148\\hat{u}$. Note that $G$'s maximum payoff is strictly (and significantly) lower when $\\alpha = 1$ no matter what its strategy. Payoffs diminish further as $\\alpha$ increases or return on investment $\\hat{u}$ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.\n## 2.4 Discussion\nIn nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states' increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.\nIn practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however,\n²² In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthat unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions [55] as opposed to decentralized strategies, such as outsourcing.\nPursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay [13] argues compellingly that a target’s willingness to assign blame and/or retaliate could be positively related to the scale of the attack. If true, the results may even underestimate the influence of $\\alpha$, and therefore overstate the rate of outsourcing. Operations that are serious enough to be of interest to the attacking state would likely invite in-kind retaliation even if the evidence were extremely flimsy. As technical attribution capabilities continue to improve and norms become more conducive as a consequence of emerging state practice, political attributions will only become more common.\n# 3 Empirical Strategy\nResearchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?\nThere is no dataset that tracks negative variation in proxy relationships over time. As mentioned,\nElectronic copy available at: https://ssrn.com/abstract=3611582\n|  EVIDENCE | VALUE |   | SUSPICIOUS TARGET  |\n| --- | --- | --- | --- |\n|  Uniformed Personnel | (5) | Direct proof | Implausibly deniable  |\n|  Agency/Contractor | (4) | Strong proof | Implausibly deniable  |\n|  IoCs: Known Group | (3) | Technical proof | Questionably deniable  |\n|  IoCs: Location | (2) | Technical proof | Plausibly deniable  |\n|  Cui bono | (1) | Circumstantial proof | Plausibly deniable  |\n|  No evidence | (0) | No proof | Plausibly deniable  |\nTable 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a  $\\{0:5\\}$  scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).\nAkoto [33] tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.\nEach observation in CFR's dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.[23] While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).\nFor information on victim responses, I rely on Hinck and Maurer [99]'s data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer [99] dataset up to date (2022) by\nElectronic copy available at: https://ssrn.com/abstract=3611582\nsearching the DOJ's website for news and press releases under the category of cyber crime.²⁴\nUnsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive [100]. Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 [101]. Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step.²⁵ This generates a daily count variable ranging from 1 to 4.²⁶\nThe data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.\nIn Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a\n²⁴ https://www.justice.gov/news\n²⁵ These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.\n²⁶ It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time.\ngreater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof.²⁷ Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.\n²⁷ Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 3.1 Analysis\nTo explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsourcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn't actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.\nIn the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.\nFor tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, *more insourcing* should imply *less outsourcing*.\nNext, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country $i$ was implicated in year $j$. In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are\nElectronic copy available at: https://ssrn.com/abstract=3611582\nmeasuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.\nI include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony.\n|   | Dependent variables:  |   |   |   |\n| --- | --- | --- | --- | --- |\n|   | Observe Insourcing → Sponsor FE |   | Public Response  |   |\n|   | (1) | Two-Way FE | Sponsor FE | Two-Way FE  |\n|  Public Response (t-1) | 0.049*** (0.016) | 0.050*** (0.017) |  |   |\n|  Obs. Insourcing (t-1) |  |  | 0.028 (0.043) | 0.035 (0.042)  |\n|  Year (Control) | 0.015*** (0.005) |  | 0.013** (0.006) |   |\n|  Incident (Control) | 0.114*** (0.015) | 0.112*** (0.010) | 0.088*** (0.022) | 0.082*** (0.021)  |\n|  Observations | 186 | 186 | 186 | 186  |\n|  R2 | 0.450 | 0.304 | 0.355 | 0.207  |\n|  Adjusted R2 | 0.409 | 0.180 | 0.307 | 0.065  |\n|  Note: |  |  | *p<0.1; **p<0.05; ***p<0.01  |   |\nTable 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries' propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government's willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.\nTable 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects\nElectronic copy available at: https://ssrn.com/abstract=3611582\nare presented in the odd columns as a robustness check.²⁸ Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insure operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.\nFirst examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t−1) are positively associated with decisions by other countries to insure in subsequent periods (p &lt; 0.01).²⁹ Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods.³⁰ Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.\nModels 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of\n²⁸ Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.\n²⁹ The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.\n³⁰ Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\na sponsor's involvement and its willingness to respond publicly ($p = 0.35$). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.\nWhy might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.\nMoreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\" [104].\nThough caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal [105]. The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 4 Conclusion\nScholars have long been interested in the conditions under which new cyber norms can emerge and proliferate [106–109]. Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible [110, 111]. Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is *in fact* on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.\nOn the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a *true* decline, or a turn away from *ineffective* proxies in favor of even stealthier alternatives.\nThis potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their *own* operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected\nElectronic copy available at: https://ssrn.com/abstract=3611582\nattacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.\nAs opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.³¹\nWithout plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts [112]. In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway [56, 58]. If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.\nIf not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes [26, 115]. And at times and in places where online nationalism\n³¹ It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nis elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own [20, 116], a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals [117], helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.\nFormalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets [118], Gorwa and Smeets [119], and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance [119]. Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.\nCyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-$n$ studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# Acknowledgements\nThe author is indebted to William Akoto, Jason Healey, Nadiya Kostyuk, Jon Lindsay, Mike Poznansky, Jack Snyder, Brandon Valeriano, JD Work, participants of the Digital Issues Discussion Group (DIDG), and four anonymous reviewers for helpful comments that improved this manuscript. This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484 (September 2021-November 2021) and 2021-2970 (November 2021 on).\nElectronic copy available at: https://ssrn.com/abstract=3611582",
  "references": [
    "# References\n1. Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46.\n2. Borghard, Erica. “Friends with Benefits? Power and Influence in Proxy Warfare”. PhD thesis. Columbia University, 2014.\n3. Salehyan, Idean, Siroky, David, and Wood, Reed M. “External Rebel Sponsorship and Civilian Abuse: A Principal-Agent Analysis of Wartime Atrocities”. In: *International Organization* 68.3 (2014). Publisher: [The MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 633–661.\n4. Szekely, Ora. “A Friend in Need: The Impact of the Syrian Civil War on Syria’s Clients (A Principal-Agent Approach)”. In: *Foreign Policy Analysis* 12.3 (July 1, 2016). Publisher: Oxford Academic, pp. 450–468.\n5. Abbott, Kenneth W. *Economic Sanctions and International Terrorism*. SSRN Scholarly Paper ID 1402844. Rochester, NY: Social Science Research Network, 1987.\n6. Kirchner, Magdalena. “‘A good investment?’ State sponsorship of terrorism as an instrument of Iraqi foreign policy (1979–1991)”. In: *Cambridge Review of International Affairs* 27.3 (July 3, 2014). Publisher: Routledge _eprint: https://doi.org/10.1080/09557571.2013.839629, pp. 521–537.\n7. Byman, Daniel and Kreps, Sarah E. “Agents of Destruction? Applying Principal-Agent Analysis to State-Sponsored Terrorism”. In: *International Studies Perspectives* 11.1 (Feb. 1, 2010). Publisher: Oxford Academic, pp. 1–18.\n8. Borghard, Erica D. and Lonergan, Shawn W. “Can States Calculate the Risks of Using Cyber Proxies?” In: *Orbis* 60.3 (Jan. 1, 2016), pp. 395–416.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n9. Applegate, Scott. \"Cybermilitias and Political Hackers: Use of Irregular Forces in Cyberwarfare\". In: IEEE Security Privacy 9.5 (Sept. 2011). Conference Name: IEEE Security Privacy, pp. 16–22.\n10. Poznansky, Michael and Perkoski, Evan. \"Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\". In: Journal of Global Security Studies 3.4 (Oct. 1, 2018), pp. 402–416.\n11. Brown, Joseph M. and Fazal, Tanisha M. “#SorryNotSorry: Why states neither confirm nor deny responsibility for cyber operations”. In: European Journal of International Security (Aug. 28, 2021). Publisher: Cambridge University Press, pp. 1–17.\n12. Baliga, Sandeep, Mesquita, Ethan Bueno de, and Wolitzky, Alexander. \"Deterrence with Imperfect Attribution\". In: American Political Science Review (2020).\n13. Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67.\n14. Cormac, Rory and Aldrich, Richard J. \"Grey is the new black: covert action and implausible deniability\". In: International Affairs 94.3 (May 1, 2018), pp. 477–494.\n15. Lin-Greenberg, Erik and Milonopoulos, Theo. \"Private Eyes in the Sky: Emerging Technology and the Political Consequences of Eroding Government Secrecy\". In: Journal of Conflict Resolution 65.6 (July 1, 2021). Publisher: SAGE Publications Inc, pp. 1067–1097.\n16. Vaynman, Jane. \"Better Monitoring and Better Spying: The Implications of Emerging Technology for Arms Control\". In: Texas National Security Review 4.4 (Sept. 23, 2021).\n17. Pitrelli, Monica Buchanan. 'For the first time in history anyone can join a war': Volunteers join Russia-Ukraine cyber fight. CNBC. Section: Technology. Mar. 14, 2022. URL: https://www.cnbc.com/2022/03/14/volunteers-sign-up-to-help-in-cyberwars-between-russia-and-ukraine-.html.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n18. Fedorov, Mykhailo. We are creating an IT army. We need digital talents. All operational tasks will be given here: https://t.me/itarmyofurraine. There will be tasks for everyone. We continue to fight on the cyber front. The first task is on the channel for cyber specialists. @FedorovMykhailo. Feb. 26, 2022. URL: https://twitter.com/FedorovMykhailo/status/1497642156076511233.\n19. Stephenson, Evan. “Does United Nations War Prevention Encourage State-Sponsorship of International Terrorism - An Economic Analysis”. In: Virginia Journal of International Law 44 (2003), p. 1197.\n20. Salehyan, Idean, Gleditsch, Kristian Skrede, and Cunningham, David E. “Explaining External Support for Insurgent Groups”. In: International Organization 65.4 (2011). Publisher: [MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 709–744.\n21. Hoffman, Bruce. Inside Terrorism. REV - Revised, 2. Columbia University Press, 2006.\n22. Findley, Michael G., Piazza, James A., and Young, Joseph K. “Games Rivals Play: Terrorism in International Rivalries”. In: The Journal of Politics 74.1 (Jan. 1, 2012). Publisher: The University of Chicago Press, pp. 235–248.\n23. Conrad, Justin. “Interstate Rivalry and Terrorism: An Unprobed Link”. In: Journal of Conflict Resolution 55.4 (Aug. 1, 2011). Publisher: SAGE Publications Inc, pp. 529–555.\n24. Singer, P. W. and Friedman, Allan. Cybersecurity and Cyberwar: What Everyone Needs to Know®. Google-Books-ID: B88ZAgAAQBAJ. Oxford University Press, Dec. 4, 2013. 836 pp.\n25. Gries, Peter Hays. China’s New Nationalism. First edition. Berkeley Los Angeles London: University of California Press, July 5, 2005. 226 pp.\n26. Weiss, Jessica Chen. *Powerful Patriots: Nationalist Protest in China’s Foreign Relations*. 1 edition. New York, NY: Oxford University Press, Sept. 1, 2014. 360 pp.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n27. Lemos, Robert. Defacements rise in China hacker war. CNET. Library Catalog: www.cnet.com. URL: https://www.cnet.com/news/defacements-rise-in-china-hacker-war/.\n28. Mulvenon, James C. et al. Chinese Responses to U.S. Military Transformation and Implications for the Department of Defense. Google-Books-ID: zHwnDNZNmdUC. Rand Corporation, Apr. 5, 2006. 187 pp.\n29. Bahovski, Erkki. Francis Maude: The Cyber-Attack against Estonia Was a Big Wake-Up Call for the World. Diplomaatria. Library Catalog: icds.ee. Aug. 2012. URL: https://icds.ee/francis-maude-the-cyber-attack-against-estonia-was-a-big-wake-up-call-for-the-world/.\n30. Shachtman, Noah. \"Kremlin Kids: We Launched the Estonian Cyber War\". In: Wired (Mar. 11, 2009).\n31. Nye, Joseph S. \"Cyber Power\". In: *Belfer Center for Science and International Affairs* (May 2010).\n32. Egloff, Florian J. Semi-State Actors in Cybersecurity. Oxford University Press, Dec. 20, 2021. 294 pp.\n33. Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264.\n34. Healey, Jason. \"The Spectrum of National Responsibility for Cyberattacks\". In: The Brown Journal of World Affairs 18.1 (2011). Publisher: Brown Journal of World Affairs, pp. 57–70.\n35. Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n36. Damrosch, Lori and Murphy, Sean. International Law. 6 edition. St. Paul, MN: West Academic Publishing, July 8, 2014. 1250 pp.\n37. Maurer, Tim. \"Cyber Proxies and Their Implications for Liberal Democracies\". In: The Washington Quarterly 41.2 (Apr. 3, 2018). Publisher: Routledge _eprint: https://doi.org/10.1080/0163660X.2018.1485332, pp. 171-188.\n38. Schmoldt, Janine. The Rising Power of Cyber Proxies. Vol. Thaddeus Eze (ed.) Google-Books-ID: wCo4EAAAQBAJ. Conferences Proceedings of 20th European Conference on Cyber Warfare and Security, June 24, 2021. 646 pp.\n39. Atwell, Kyle, Portzer, Joshua M., and McCurdy, Daphne. \"Negotiating [Im]plausible Deniability: Strategic Guidelines for U.S. Engagement in Modern Indirect Warfare\". In: PRISM 9.2 (2021). Publisher: Institute for National Strategic Security, National Defense University, pp. 112-121.\n40. Feuer, Samantha V. From the Shadows to the Front Page: State Use of Proxies for Cyber Operations. Freeman Spogli Institute for International Studies, Stanford University, 2020.\n41. Collier, Jamie. \"Proxy Actors in the Cyber Domain: Implications for State Strategy\". In: St Antony's International Review 13.1 (May 1, 2017), pp. 25-47.\n42. Maurer, Tim. Cyber Proxies and the Crisis in Ukraine. Vol. Cyber war in perspective: Russian aggression against Ukraine, Kenneth Geers (ed.) OCLC: 960393919. NATO Cooperative Cyber Defence Centre of Excellence, 2015.\n43. Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436.\n44. Denning, Dorothy. \"Cyber Conflict as an Emergent Social Phenomenon\". In: Corporate Hacking and Technology-driven Crime, Thomas J. Holt and Bernadette Hlubik Schell (eds.) IGI Global, Jan. 1, 2011.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n45. Segal, Adam. Beware the Patriotic Geek: The Risk of Cyber Militias in Asia. Council on Foreign Relations. Library Catalog: www.cfr.org. Feb. 22, 2012. URL: https://www.cfr.org/blog/beware-patriotic-geek-risk-cyber-militias-asia.\n46. Klimburg, Alexander. “Mobilising Cyber Power”. In: *Survival* 53.1 (Feb. 1, 2011). Publisher: Routledge _eprint: https://doi.org/10.1080/00396338.2011.555595, pp. 41–60.\n47. Trozzo, Eric. The Cyberdimension: A Political Theology of Cyberspace and Cybersecurity. Google-Books-ID: H0i6DwAAQBAJ. Wipf and Stock Publishers, Apr. 29, 2019. 293 pp.\n48. Ottis, Rain. “From Pitch Forks to Laptops: Volunteers in Cyber Conflicts”. In: *Conference on Cyber Conflict Proceedings* (2010), pp. 97–109.\n49. Pagliery, Jose. Meet the vigilante who’s hacked jihadist websites for years. CNNMoney. Library Catalog: money.cnn.com. Jan. 16, 2015. URL: https://money.cnn.com/2015/01/16/technology/security/jester-hacker-vigilante/index.html.\n50. Thornburgh, Nathan. “The Invasion of the Chinese Cyberspies”. In: *Time* (Aug. 29, 2005).\n51. Winter, Jana. Patriot hacker 'The Raptor' gains flock of followers after FoxNews.com report. Fox News. Last Modified: 2015-03-26T17:42:51-04:00 Library Catalog: www.foxnews.com Publisher: Fox News. Mar. 26, 2015. URL: https://www.foxnews.com/us/patriot-hacker-the-raptor-gains-flock-of-followers-after-foxnews-com-report.\n52. Bob, Yonah Jeremy and Joffre, Tzvi. *Iran’s Mahan Air hit by cyberattack*, materials allegedly linked to IRGC. The Jerusalem Post | JPost.com. Nov. 21, 2021. URL: https://www.jpost.com/breaking-news/irans-mahan-air-hit-by-cyberattack-685575.\n53. NIPC Encourages Heightened Cyber Security as Iraq - US Tensions Increase. National Infrastructure Protection Center (NIPC) Advisory 03-002. Feb. 11, 2003. URL: https://www.2600.com/news/mirrors/www.nipc.gov/warnings/advisories/2003/03-002.htm.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n54. Kostyuk, Nadiya and Zhukov, Yuri M. \"Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\" In: Journal of Conflict Resolution 63.2 (Feb. 1, 2019). Publisher: SAGE Publications Inc, pp. 317-347.\n55. Kostyuk, Nadiya. \"Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\". In: International Studies Quarterly (sqab039 May 28, 2021).\n56. Valeriano, Brandon. Cyber War versus Cyber Realities: Cyber Conflict in the International System. 1 edition. Oxford; New York: Oxford University Press, May 26, 2015. 288 pp.\n57. Tracking State-Sponsored Cyberattacks Around the World. Council on Foreign Relations. 2021. URL: https://www.cfr.org/cyber-operations.\n58. Valeriano, Brandon, Jensen, Benjamin, and Maness, Ryan C. Cyber Strategy: The Evolving Character of Power and Coercion. New York, NY: Oxford University Press, May 15, 2018. 320 pp.\n59. Franklin Kramer, Stuart H. Starr, and Larry Wentz, eds. Cyberpower and National Security. 1 edition. Washington, D.C: Potomac Books, Apr. 1, 2009. 664 pp.\n60. Libicki, Martin C. Cyberdeterrence and Cyberwar. Google-Books-ID: MJX6jL6IeF0C. Rand Corporation, Sept. 22, 2009. 239 pp.\n61. Betz, David and Stevens, Tim. Techniques for Cyber Attack Attribution. Institute for Defense Analyses, 2003. 82 pp.\n62. Landau, Susan and Lubin, Asaf. \"Examining the Anomalies, Explaining the Value: Should the USA Freedom Act's Metadata Program Be Extended?\" In: Harvard National Security Journal 11.3 (2020), pp. 308-358.\n63. Lin, Herbert. \"Attribution of Malicious Cyber Incidents: From Soup to Nuts\". In: Journal of International Affairs 70.1 (2016). Publisher: Journal of International Affairs Editorial Board, pp. 75-137.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n64. Rid, Thomas and Buchanan, Ben. “Attributing Cyber Attacks”. In: Journal of Strategic Studies 38.1 (Jan. 2, 2015). Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2014.977382, pp. 4–37.\n65. Canfil, Justin Key. Intelligence and Adversaries: What Do We Know? New York NY: Cyber Conflict Studies Association (CCSA), 2016.\n66. Carnegie, Allison and Carson, Austin. “The Disclosure Dilemma: Nuclear Intelligence and International Organizations”. In: American Journal of Political Science 63.2 (2019). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12426, pp. 269–285.\n67. Murphy, Sean D. Principles of International Law. Thomson/West, 2012. 575 pp.\n68. Canfil, Justin Key. “A Framework for Assessing Foreign State Complicity: A Framework for Assessing Foreign State Complicity”. In: Journal of International Affairs 70.1 (2016). Publisher: Journal of International Affairs Editorial Board, pp. 217–226.\n69. Weber, Valentin. “States and Their Proxies in Cyber Operations”. In: Lawfare (May 15, 2018).\n70. Cole, August and Healey, Jason. United States should discourage \"patriotic hackers\" from attacking North Korea. Atlantic Council. Library Catalog: www.atlanticcouncil.org. Dec. 23, 2014. URL: https://www.atlanticcouncil.org/blogs/new-atlanticist/us-should-discourage-patriotic-hackers-from-attacking-north-korea/.\n71. Segal, Adam. The Hacked World Order: How Nations Fight, Trade, Maneuver, and Manipulate in the Digital Age. 1 edition. New York: PublicAffairs, Feb. 23, 2016. 320 pp.\n72. Wu, Xu. Chinese Cyber Nationalism: Evolution, Characteristics, and Implications: Evolution, Characteristics, and Implications. Lexington Books, Sept. 26, 2007. 280 pp.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n73. Hang, Ryan. Freedom for Authoritarianism: Patriotic Hackers and Chinese Nationalism. The Yale Review of International Studies. Library Catalog: yris.yira.org. Oct. 12, 2014. URL: http://yris.yira.org/essays/1447.\n74. Henderson, Scott. The Dark Visitor. First edition. Scott Henderson, Oct. 24, 2007. 148 pp.\n75. Fletcher, Owen. *Patriotic Chinese Hacking Group Reboots*. WSJ. ISSN: 0099-9660 Library Catalog: blogs.wsj.com Section: World. Oct. 5, 2011. URL: https://blogs.wsj.com/chinarealtime/2011/10/05/patriotic-chinese-hacking-group-reboots/.\n76. Newman, Lily Hay. \"China Escalates Hacks Against the US as Trade Tensions Rise\". In: Wired (June 22, 2018).\n77. Egloff, Florian J. and Smeets, Max. \"Publicly attributing cyber attacks: a framework\". In: Journal of Strategic Studies 0.0 (Mar. 10, 2021). Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, pp. 1-32.\n78. Egloff, Florian J. \"Public attribution of cyber intrusions\". In: Journal of Cybersecurity 6.1 (Jan. 1, 2020).\n79. DOJ Press Release: U.S. Charges Five Chinese Military Hackers for Cyber Espionage Against U.S. Corporations and a Labor Organization for Commercial Advantage. Department of Justice Office of Public Affairs, May 19, 2014.\n80. Berghel, Hal. \"The Equifax Hack Revisited and Repurposed\". In: Computer 53.5 (May 1, 2020). Publisher: IEEE Computer Society, pp. 85-90.\n81. DOJ Press Release: U.S. Charges Three Chinese Hackers Who Work at Internet Security Firm for Hacking Three Corporations for Commercial Advantage. Department of Justice Office of Public Affairs, Nov. 27, 2017.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n82. DOJ Press Release: Two Chinese Hackers Associated With the Ministry of State Security Charged with Global Computer Intrusion Campaigns Targeting Intellectual Property and Confidential Business Information. Department of Justice Office of Public Affairs, Dec. 20, 2018.\n83. DOJ Press Release: Member of Sophisticated China-Based Hacking Group Indicted for Series of Computer Intrusions, Including 2015 Data Breach of Health Insurer Anthem Inc. Affecting Over 78 Million People. Department of Justice Office of Public Affairs, May 9, 2019.\n84. DOJ Press Release: Attorney General William P. Barr Announces Indictment of Four Members of China's Military for Hacking into Equifax. Department of Justice Office of Public Affairs, Feb. 10, 2020.\n85. Nakashima, Ellen and Lynch, David J. U. S. charges Chinese hackers in alleged theft of vast trove of confidential data in 12 countries. Washington Post. Dec. 21, 2018. URL: https://www.washingtonpost.com/world/national-security/us-and-more-than-a-dozen-allies-to-condemn-china-for-economic-espionage/2018/12/20/cdfd0338-0455-11e9-b5df-5d3874f1ac36_story.html.\n86. Harknett, Richard and Fischerkeller, Michael. Persistent Engagement and Tacit Bargaining: A Path Toward Constructing Norms in Cyberspace. Lawfare. Nov. 9, 2018. URL: https://www.lawfareblog.com/persistent-engagement-and-tacit-bargaining-path-toward-constructing-norms-cyberspace.\n87. Miller, James N. and Pollard, Neal A. Persistent Engagement, Agreed Competition and Deterrence in Cyberspace. Lawfare. Apr. 30, 2019. URL: https://www.lawfareblog.com/persistent-engagement-agreed-competition-and-deterrence-cyberspace.\n88. Waxman, Matthew C. \"Cyber-Attacks and the Use of Force: Back to the Future of Article 2(4)\". In: Yale Journal of International Law 36.2 (2011), pp. 421-460.\n89. Kaminska, Monica. \"Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks\". In: Journal of Cybersecurity 7.1 (Jan. 1, 2021), tyab008.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n90. Egloff, Florian J and Dunn Cavelty, Myriam. \"Attribution and Knowledge Creation Assemblages in Cybersecurity Politics\". In: Journal of Cybersecurity 7.1 (Jan. 1, 2021), tyab002.\n91. Axelrod, Robert and Iliev, Rumen. \"Timing of cyber conflict\". In: Proceedings of the National Academy of Sciences 111.4 (Jan. 28, 2014). Publisher: National Academy of Sciences Section: Physical Sciences, pp. 1298–1303.\n92. Gailmard, Sean and Patty, John W. “Preventing Prevention”. In: American Journal of Political Science 63.2 (2019). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12411, pp. 342–352.\n93. Byman, Daniel et al. \"Iraq, Afghanistan and the War on Terror\". In: Middle East Policy 12.1 (2005). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1061-1924.2005.00183.x, pp. 1–24.\n94. Quillen, Chris. “A Historical Analysis of Mass Casualty Bombers”. In: Studies in Conflict &amp; Terrorism 25.5 (Sept. 1, 2002). Publisher: Routledge _eprint: https://doi.org/10.1080/10576100290101197, pp. 279–292.\n95. Hoffman, Bruce. *Terrorism and Weapons of Mass Destruction: An Analysis of Trends and Motivations*. Product Page. Publisher: RAND Corporation. RAND, 1999.\n96. Benjamin, Daniel and Simon, Steven. The Age of Sacred Terror: Radical Islam’s War Against America. Reprint edition. New York: Random House Trade Paperbacks, Oct. 14, 2003. 560 pp.\n97. Merari, Ariel. \"Terrorism as a strategy of insurgency\". In: Terrorism and Political Violence 5.4 (Dec. 1, 1993). Publisher: Routledge _eprint: https://doi.org/10.1080/09546559308427227, pp. 213–251.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n98. Anderson, Sean K. \"US Counterinsurgency vs Iranian-Sponsored Terrorism\". In: *Low Intensity Conflict &amp; Law Enforcement* 11.2 (June 1, 2002). Publisher: Routledge _eprint: https://doi.org/10.1080/0966284042000279027, pp. 254–270.\n99. Hinck, Garrett and Maurer, Tim. \"Persistent Enforcement: Criminal Charges as a Response to Nation-State Malicious Cyber Activity\". In: *Journal of National Security Law and Policy* 10.3 (2019), pp. 525–562.\n100. Gomez, Miguel Alberto and Whyte, Christopher. \"Unpacking Strategic Behavior in Cyberspace: A Schema-Driven Approach\". In: *Journal of Cybersecurity* (2022). forthcoming, pp. 1–16.\n101. Franceschi-Bicchierai, Lorenzo. *Chinese Cybersecurity Company Doxes Apparent NSA Hacking Operation*. Vice. Feb. 23, 2022. URL: https://www.vice.com/en/article/v7dxg3/chinese-cybersecurity-company-doxes-apparent-nsa-hacking-operation.\n102. Kropko, Jonathan and Kubinec, Robert. \"Interpretation and identification of within-unit and cross-sectional variation in panel data models\". In: *PLOS ONE* 15.4 (Apr. 21, 2020). Publisher: Public Library of Science, e0231349.\n103. Hanson, Bruce E. “A Modern Gauss-Markov Theorem”. In: *Econometrica* (Dec. 1, 2021).\n104. Mummolo, Jonathan and Peterson, Erik. \"Improving the Interpretation of Fixed Effects Regression Results\". In: *Political Science Research and Methods* 6.4 (Oct. 2018). Publisher: Cambridge University Press, pp. 829–835.\n105. Healey, Jason. *China Is a Cyber Victim, Too*. Foreign Policy. Apr. 16, 2013. URL: https://foreignpolicy.com/2013/04/16/china-is-a-cyber-victim-too/.\n106. Hollis, Duncan B. *Why States Need an International Law for Information Operations*. SSRN Scholarly Paper ID 1083889. Rochester, NY: Social Science Research Network, Jan. 17, 2008.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n107. Healey, Jason and Maurer, Tim. \"What it'll take to forge peace in cyberspace\". In: Christian Science Monitor (Mar. 20, 2017).\n108. Finnemore, Martha and Hollis, Duncan B. \"Constructing Norms for Global Cybersecurity\". In: American Journal of International Law 110.3 (July 2016). Publisher: Cambridge University Press, pp. 425–479.\n109. Maurer, Tim. \"Cyber Norm Emergence at the United Nations—An Analysis of the UN's Activities Regarding Cyber-security\". In: Science, Technology, and Public Policy Program, Belfer Center (2011).\n110. Hare, Forrest B. \"Privateering in Cyberspace: Should Patriotic Hacking Be Promoted as National Policy?\" In: *Asian Security* 15.2 (May 4, 2019). Publisher: Routledge _eprint: https://doi.org/10.1080/14799855.2017.1414803, pp. 93–102.\n111. Egloff, Florian J. \"Cybersecurity and non-state actors: a historical analogy with mercantile companies, privateers, and pirates\". http://purl.org/dc/dcmitype/Text. University of Oxford, 2018.\n112. Sandler, Todd and Siqueira, Kevin. \"Global terrorism: deterrence versus pre-emption\". In: Canadian Journal of Economics/Revue canadienne d'économique 39.4 (2006). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-5982.2006.00393.x, pp. 1370–1387.\n113. Crosston, Matthew. \"Virtual Patriots and a New American Cyber Strategy: Changing the Zero-Sum Game\". In: Strategic Studies Quarterly 6.4 (2012). Publisher: Air University Press, pp. 100–118.\n114. MacKinnon, Rebecca. \"China's Networked Authoritarianism\". In: \"Journal of Democracy 22.2 (2011), pp. 32–46.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n115. Hjortdal, Magnus. “China’s Use of Cyber Warfare: Espionage Meets Strategic Deterrence”. In: *Journal of Strategic Security* 4.2 (2011). Publisher: University of South Florida Board of Trustees, pp. 1–24.\n116. Freeman, Michael. “The Sources of Terrorist Financing: Theory and Typology”. In: *Studies in Conflict &amp; Terrorism* 34.6 (June 1, 2011). Publisher: Routledge _eprint: https://doi.org/10.1080/1057610X.2011.571193, pp. 461–475.\n117. DeVore, Marc R. “Exploring the Iran-Hezbollah Relationship: A Case Study of how State Sponsorship affects Terrorist Group Decision-Making”. In: *Perspectives on Terrorism* 6.4 (2012). Publisher: Terrorism Research Institute, pp. 85–107.\n118. Herr, Trey, Laudrain, Arthur P. B., and Smeets, Max. “Mapping the Known Unknowns of Cybersecurity Education: A Review of Syllabi on Cyber Conflict and Security”. In: *Journal of Political Science Education* 0.0 (Feb. 28, 2020). Publisher: Routledge _eprint: https://doi.org/10.1080/15512169.2020.1729166, pp. 1–17.\n119. Gorwa, Robert and Smeets, Max. *Cyber Conflict in Political Science: A Review of Methods and Literature*. 2019 ISA Working Paper. July 25, 2019.\nElectronic copy available at: https://ssrn.com/abstract=3611582"
  ],
  "flat_text": "# Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay\nJustin Key Canfil\nJune 20, 2020\n## Abstract\nIt is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict.\nWord Count: 12,500\nKeywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.\nHow have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.\nScholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give\nElectronic copy available at: https://ssrn.com/abstract=3611582\nit even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.”\nIn this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14].\nThe proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in\nElectronic copy available at: https://ssrn.com/abstract=3611582\nresponse to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.\nThat is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.\n# 1 Cyber Proxies: What We Know\nWhether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict. For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident [24–27]. Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization [24, 30]. Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors [31].\nLong ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft [19]. Scholars have found that a majority of rebel groups since 1945 receive tacit state support [20] and this support has made these groups more powerful and influential [21]. They are observed most often between great power dyads [6, 22, 23], presumably because the risks associated with direct action are higher when targets can strike back.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nBut states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto [33] explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.” I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.\nThis of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting. More recent work by Florian Egloff [32] refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible [36].\nDetection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability [8, 35, 37–42]. Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.\nProxies \"may or may not be part of state security and intelligence agencies and may be criminal syndicates or private cybersecurity companies ... Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\" [33].\nMaurer [35] writes that state sponsors can actively fund or otherwise support non-state cyber actors with the expectation that these actors will accomplish some military, intelligence, or foreign policy objective on behalf of the state (what Maurer terms “orchestrating”). Alternatively, sponsors can simply permit offensive operations by non-state actors by turning a blind eye (“sanctioning”). At the opposite end, a sponsor can establish effective in-house command and control over the group (“delegating”).\nElectronic copy available at: https://ssrn.com/abstract=3611582\nVictim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors [43]. If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.\nSome non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998 [44]. Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors [8]. Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments [45] to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy's fidelity, and plausible deniability is strengthened.\nThis logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea [47] – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries [38, 42, 49–51]. On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation [35, 46]. Between 9/11 and the start of the Iraq War, for example, when US nationalism soared,\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthe US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets [53]. On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.\nSo just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-$n$ datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto [33] explains, these data limitations have “crippled efforts to study … cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.\nThe third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.\nFor researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas [54–56], but for this reason the study of cyber proxies faces a special set of challenges.\n## 1.1 Observational Equivalence in Existing Data\nThe crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing\nElectronic copy available at: https://ssrn.com/abstract=3611582\ndoesn't convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.\nTo illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.[8]\nOne reasonable expectation might be that states are likelier to delegate certain tasks to proxies – for example, less sophisticated or less sensitive operations. We can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.[10] However, it only tracks proxy relationship onset.[11] As a strictly cumulative measure, it cannot be used to measure whether outsourcing has declined. Instead, we can use it to observe the rate at which states have continued to outsource to new groups in recent years.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 1: Comparisons of trends over time from three datasets [33, 57, 58]. The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade.\nFigure 1 compares observations from all three datasets. The  $Y$ -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction.[12] Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nWe can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.\nThese trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto [33] explains that in order for the onset of a proxy relationship to appear in the dataset, \"there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government\" (emphasis mine). Akoto [33] continues: \"It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.\" Data collection is scoped on proxies which are already known to work for the state. Conclusion in the dataset is therefore inversely related the plausibility of a sponsor's deniability.\nWhat this means is that the large-$n$ information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.\nDirect measurements of outsourcing in available data cannot distinguish between these\n Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].\nElectronic copy available at: https://ssrn.com/abstract=3611582\ncompeting accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn't plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.\n## 2 The Illogic of Plausible Deniability\nIt has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true.\nIn the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its \"most difficult problem\" [61]. The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible [12, 13, 64]. Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns [65].\nEven if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose [33]. States are often sensitive about divulging how they know what they know [66]. Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on\nElectronic copy available at: https://ssrn.com/abstract=3611582\na direct command role can be held responsible for the actions of their proxies [36, 67].\nThese barriers are what make outsourcing so attractive, according to conventional wisdom [35]. But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal [33, 68]? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers [33, 69]. A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal [71] described plans to adopt a model reminiscent of US Cyber Command.\nFrom 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support [28]. Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000 [24], however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang [73] catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets [75]. Since then, the Chinese government has relied more on specialized units at the Ministry of State Security [35, 71]. Attacks\nThe International Law Commission (ILC)'s 2001 Draft Articles is perhaps the clearest articulation of the law on state responsibility (though often cited, it is actually a nonbinding source). In the ILC's view, a host state can only be held responsible if it directly conducts or oversees the offending operation at the operational level (see International Law Commission (ILC) Draft Articles on State Responsibility, 2001, http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf). International courts have held variously that the relationship must be one of \"effective control\" (Nicaragua v. United States), \"overall control\" plus the commission of specific acts (Prosecutor v. Dusko Tadic (1999)), or \"complete dependence\" (Bosnia and Herzegovina v. Serbia and Montenegro (1996)) – all very strict standards that elide the possibility of measures short of command or operational involvement. And in more than 4,700 claims proceedings, all but one tribunal (Dames &amp; Moore v. Iran) found that the burden of proof for wrongdoing rests with the defender (see Iran Claims Tribunal, https://www.state.gov/iran-u-s-claims-tribunal/).\nElectronic copy available at: https://ssrn.com/abstract=3611582\noriginating from that country reveal a more direct government hand [76]. If proxies pay for the reasons we usually suspect, then this behavior is puzzling.\nRarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect [12, 13, 77, 78]. Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.\nIn particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment [79]. Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices [80] – a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” [79].\n For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nIt is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.” In a separate piece, Carlin [43] explains that the Criminal and National Security Divisions at DOJ \"increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases),\" including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.\nThis level of cooperation gives the government specially enhanced attribution capabilities. Carlin [43] describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are” [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak [13].\nEspecially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin [43] admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: \"the government must demonstrate, among other things, that the ‘target ... is a foreign power or an agent of a foreign power’” if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.\nIndictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement [85–87]. To my knowledge, there is no institutional\n [for a detailed exposition in this journal, see 78].\n “The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].\nElectronic copy available at: https://ssrn.com/abstract=3611582\nrequirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” [89], they now seem more willing to punish sponsors for the activities of their proxies.\nAfter all, why wouldn't victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate [90]. States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.\nRaising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.\n## 2.1 A Model of Outsourcing\nHow can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology\n Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nfor checking and comparing a theory's internal validity this way. Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev [91], I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work \"under the hood\" in cases where data are questionable or unavailable.\nEvery theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large- $n$  data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes [92].\nIn the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims' beliefs and the level of investment. Under this framework, the sponsor's deniability is a function of its involvement and the target state's independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.\nThe model shows how a sponsor's concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthis holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship [8]. The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability's role in decisions about whether to outsource.\n## 2.2 Model setup\nA host government $(G)$ oversees a pool of non-state hackers $(H)$. The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as $\\varphi \\in [0,1]$, where $\\varphi &gt; 0$ is some positive degree of outsourcing. One can imagine that low levels of $\\varphi$ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at $\\varphi = 0$, for instance by implementing and enforcing laws against hacking foreign targets. In the game, $G$'s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.\nThe government's return on investment is given as $\\hat{u} x$, where $x$ is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker's level of sophistication, $\\psi_{i}$. The probability of a successful campaign is $\\psi_{i}$. I assume that individual operations are scalable, and thus the government obtains either full benefit $\\hat{u} x$ from a successful campaign $(\\psi = 1)$ or no benefit at all $(1 - \\psi)$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nConsistent with default explanations, $G$ faces principal-agent problems vis-a-vis $H$. The degree of agent drift – a function of $H$'s operational discipline and its ideological sympathy with government objectives – is written as $\\theta$. The government's level of investment $x$, and thus its expected payoffs, are penalized increasing in $\\theta$. In other words, the less reliable the agent $(\\theta \\uparrow)$, the less useful its efforts.\nFinally, $G$ gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, $f(\\varphi)$, and that the attacker faces penalties increasing in attack scale, $x$. This would be modeled as $x \\times \\varphi$: the less centralized, the more deniability when scale is held constant. The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target's right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.\n|  Term | Description | Range | Type  |\n| --- | --- | --- | --- |\n|  φ | Extent of outsourcing strategy | ∈ [0,1] | G’s Strategy  |\n|  ψ | Operational sophistication (probability of success) | ∈ [0,1] | Exogenous  |\n|  u | Return on scale of investment | ∈ R>0 | Exogenous  |\n|  x | Campaign investment | ∈ R>0 | Exogenous  |\n|  θ | Distance between principal / agent ideal points | ∈ R>0 | Exogenous  |\n|  γ | Fixed cost of centralization | ∈ R>0 | Exogenous  |\n|  c | Penalty of being caught & attributed | ∈ R>0 | Exogenous  |\n|  τ | Target’s ability to attribute (technical attrib.) | ∈ [0,1] | Exogenous  |\n|  α | Target’s willingness to accuse (political attrib.) | ∈ R>0 | Exogenous  |\nTable 1: Parameter Guide\nDeparting from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted $\\tau$, and political attribution, $\\alpha$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nAttribution $\\tau_v$ is simply the probability of detection, determined by the target state's capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, $\\alpha_v &gt; 1$, is determined by the target state's tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state's capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence.\nThe government's payoff can be modeled as\n$$\nU_G(\\varphi) = \\psi \\hat{u} x (2 - \\varphi) - \\theta \\varphi x - \\gamma (1 - \\varphi) - \\tau_v c \\left(\\alpha_v(\\varphi) + x (1 - \\varphi)\\right)\n$$\nIn plain terms, $G$'s expected benefit is given by the balance of participation, $\\hat{u}(2 - \\varphi)$, times the probability the campaign is successful ($\\psi$), and the amount of material investment required ($x$). If the campaign is successful, $G$'s investment yields a return of $\\hat{u}x$. $G$ has a choice whether to outsource ($\\varphi &gt; 0$) or centralize the campaign ($\\varphi = 0$). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment ($\\theta x$). Centralization may also involve investment of some fixed downpayment $\\gamma$. For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, $G$ incurs some penalty based on the target's ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes $\\varphi$ given the parameters.\nAs a stricter test of the theory, eliminate any agent drift $\\theta$ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that $H$'s\nElectronic copy available at: https://ssrn.com/abstract=3611582\nskill is equivalent to $G$'s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in $\\varphi$ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, $G$'s decision hinges on $\\alpha$.\nFor simplicity, assume the return on investment is linearly increasing in average attack scale $(\\hat{u} = 1)$. Also equalize the $\\theta$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal. Like the model employed by Lindsay [13], this setup allows us to locate the optimal attack scale. Since I regard $x$ as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, $\\psi$, as a constant. Set $\\psi = 1$ for the most interesting case. As a final simplification, assume technical attribution is certain whenever $G$ attacks $(\\tau = 1)$, and that the penalty $c$ is linearly increasing in scale as a function of the cumulative evidence left behind $x$. This implies a one-to-one increase in the target's ability to implicate the host state if the host state runs the campaign directly, since in this case \"responsibility\" can be proven through technical means alone. Set $x, c = 1$.\nThis set of assumptions simplifies the equation to $U_{G}(\\varphi) = x(2 - \\varphi) - c(\\alpha_{\\varphi}(\\varphi) + x(1 - \\varphi))$. In order to constitute an equilibrium where $G$ outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies\n$$\n\\varphi &gt; \\frac{1}{a}\n$$\nwhich illustrates the general relationship between outsourcing $(\\varphi)$ and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us\n I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\nU _ {G} (\\varphi) = x (2 - \\varphi) - (\\alpha_ {v} (\\varphi) + (1 - \\varphi))\n$$\nwhere expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and $\\varphi$ in Theorem 1.\nTheorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter's borders $(\\alpha)$, the lower the host state's incentive to outsource $(\\varphi)$.\nProof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of $\\varphi$ via straightforward optimization. The proof is concise enough to show in the body of the paper.\nWith no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: $(\\alpha_v(\\varphi) + (1 - \\varphi))^2$, which gives us the transformation\n$$\n\\max U _ {G} (\\varphi) = x (2 - \\varphi) - \\tau (\\alpha_ {v} (\\varphi) + (1 - \\varphi)) ^ {2}\n$$\nThe first order condition (FOC) must isolate at least one extremum in order to find a critical point at which $G$ will choose to switch between strategies. Differentiate the function with respect to $\\varphi$:\n$$\n\\frac {\\partial}{\\partial \\varphi} U _ {G} (\\cdot) = - (\\alpha + 1) (\\alpha \\varphi + \\varphi - 1) - x\n$$\nWe can then solve for the optimal level of $\\varphi$ by simply setting the derivative equal to zero and rearranging algebraically for $\\varphi$. This produces:\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\n\\varphi^ {*} = \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\text{ where } \\alpha \\geq 0 \\text{ by assumption} \\tag{1}\n$$\nThe second order condition (SOC) confirms that $\\varphi^{*}$ is indeed a global maximum:\n$$\n\\frac {\\partial^ {2}}{\\partial^ {2} \\varphi} U _ {G} (\\varphi) = - a ^ {2} - 2 a - 1 \\text{ which is } &lt; 0 \\tag{2}\n$$\nWe observe from Equation 2 that the slope is decreasing at $U_{G}^{\\prime \\prime}$, proving that $\\varphi^{*}$ maximizes $G$'s payoff function.\n## 2.3 Analysis\nWe wish to know how $U_{G}(\\varphi^{*})$ changes with $\\alpha, x$. Substituting $\\varphi^{*}$ into the original equation find calculate $G$'s expected utility, we obtain\n$$\nU _ {G} (\\varphi^ {*}) = x \\left[ 2 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\right] - x \\left[ \\alpha \\left(\\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) + \\left(1 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) \\right]\n$$\n$$\n\\text{which is equivalent to } U _ {G} \\left(\\varphi^ {*}\\right) = \\frac {\\alpha x ^ {2} + \\alpha x + x}{\\alpha^ {2} + 2 \\alpha + 1} \\tag{3}\n$$\nEquation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility $G$ can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between $\\alpha$ and $x$, neither Equation 1 nor Equation 3 is immediately intuitive. The relationship becomes more apparent when $\\alpha$ is $\\varphi^{*}$ is plotted. Figure 2 (right)\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim's propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their \"plausible deniability\" appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able).\nshows the utility gained for different levels of  $\\varphi$ . Outsourcing becomes less advantageous as  $\\alpha$  increases. In this model, the target state's  $\\alpha$  is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal  $\\varphi^{*}$ . As  $\\alpha$  increases, the expected gains of centralization  $(\\varphi^{*} \\downarrow)$  begin to exceed the gains from outsourcing  $(\\varphi^{*} \\uparrow)$ . The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay [13]'s findings on deterrence. Imputing values can help give us more precise point estimates.\nExample 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence  $(\\alpha = 0)$ . Then the optimal level of outsourcing is  $\\varphi^{*} = x$  and  $G$  would receive  $U_{G}(\\varphi^{*}) = \\tilde{u} x$  for any level of  $x$ . The value of  $x$  that maximizes this relationship is 1, so  $\\varphi^{*} = 1$ . In other\nElectronic copy available at: https://ssrn.com/abstract=3611582\nwords, $G$ gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming $\\hat{u} &gt; 1$) that $G$ would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom.\nExample 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. $\\alpha = 10$. Then $\\varphi^{*} = (10x^{2} + 11x) / 121$, and the calculation becomes more complex. Fixing $\\varphi^{*} = 0.148$, $x^{*} = 0.895$ at their optima (see previous footnote), $G$ can expect to receive $0.148\\hat{u}$. Note that $G$'s maximum payoff is strictly (and significantly) lower when $\\alpha = 1$ no matter what its strategy. Payoffs diminish further as $\\alpha$ increases or return on investment $\\hat{u}$ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.\n## 2.4 Discussion\nIn nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states' increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.\nIn practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however,\n In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthat unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions [55] as opposed to decentralized strategies, such as outsourcing.\nPursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay [13] argues compellingly that a target’s willingness to assign blame and/or retaliate could be positively related to the scale of the attack. If true, the results may even underestimate the influence of $\\alpha$, and therefore overstate the rate of outsourcing. Operations that are serious enough to be of interest to the attacking state would likely invite in-kind retaliation even if the evidence were extremely flimsy. As technical attribution capabilities continue to improve and norms become more conducive as a consequence of emerging state practice, political attributions will only become more common.\n# 3 Empirical Strategy\nResearchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?\nThere is no dataset that tracks negative variation in proxy relationships over time. As mentioned,\nElectronic copy available at: https://ssrn.com/abstract=3611582\n|  EVIDENCE | VALUE |   | SUSPICIOUS TARGET  |\n| --- | --- | --- | --- |\n|  Uniformed Personnel | (5) | Direct proof | Implausibly deniable  |\n|  Agency/Contractor | (4) | Strong proof | Implausibly deniable  |\n|  IoCs: Known Group | (3) | Technical proof | Questionably deniable  |\n|  IoCs: Location | (2) | Technical proof | Plausibly deniable  |\n|  Cui bono | (1) | Circumstantial proof | Plausibly deniable  |\n|  No evidence | (0) | No proof | Plausibly deniable  |\nTable 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a  $\\{0:5\\}$  scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).\nAkoto [33] tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.\nEach observation in CFR's dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.[23] While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).\nFor information on victim responses, I rely on Hinck and Maurer [99]'s data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer [99] dataset up to date (2022) by\nElectronic copy available at: https://ssrn.com/abstract=3611582\nsearching the DOJ's website for news and press releases under the category of cyber crime.\nUnsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive [100]. Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 [101]. Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step. This generates a daily count variable ranging from 1 to 4.\nThe data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.\nIn Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a\n https://www.justice.gov/news\n These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.\n It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time.\ngreater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof. Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.\n Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 3.1 Analysis\nTo explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsourcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn't actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.\nIn the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.\nFor tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, *more insourcing* should imply *less outsourcing*.\nNext, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country $i$ was implicated in year $j$. In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are\nElectronic copy available at: https://ssrn.com/abstract=3611582\nmeasuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.\nI include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony.\n|   | Dependent variables:  |   |   |   |\n| --- | --- | --- | --- | --- |\n|   | Observe Insourcing → Sponsor FE |   | Public Response  |   |\n|   | (1) | Two-Way FE | Sponsor FE | Two-Way FE  |\n|  Public Response (t-1) | 0.049*** (0.016) | 0.050*** (0.017) |  |   |\n|  Obs. Insourcing (t-1) |  |  | 0.028 (0.043) | 0.035 (0.042)  |\n|  Year (Control) | 0.015*** (0.005) |  | 0.013** (0.006) |   |\n|  Incident (Control) | 0.114*** (0.015) | 0.112*** (0.010) | 0.088*** (0.022) | 0.082*** (0.021)  |\n|  Observations | 186 | 186 | 186 | 186  |\n|  R2 | 0.450 | 0.304 | 0.355 | 0.207  |\n|  Adjusted R2 | 0.409 | 0.180 | 0.307 | 0.065  |\n|  Note: |  |  | *p<0.1; **p<0.05; ***p<0.01  |   |\nTable 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries' propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government's willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.\nTable 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects\nElectronic copy available at: https://ssrn.com/abstract=3611582\nare presented in the odd columns as a robustness check. Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insure operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.\nFirst examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t−1) are positively associated with decisions by other countries to insure in subsequent periods (p &lt; 0.01). Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods. Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.\nModels 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of\n Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.\n The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.\n Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\na sponsor's involvement and its willingness to respond publicly ($p = 0.35$). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.\nWhy might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.\nMoreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\" [104].\nThough caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal [105]. The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 4 Conclusion\nScholars have long been interested in the conditions under which new cyber norms can emerge and proliferate [106–109]. Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible [110, 111]. Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is *in fact* on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.\nOn the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a *true* decline, or a turn away from *ineffective* proxies in favor of even stealthier alternatives.\nThis potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their *own* operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected\nElectronic copy available at: https://ssrn.com/abstract=3611582\nattacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.\nAs opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.\nWithout plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts [112]. In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway [56, 58]. If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.\nIf not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes [26, 115]. And at times and in places where online nationalism\n It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nis elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own [20, 116], a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals [117], helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.\nFormalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets [118], Gorwa and Smeets [119], and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance [119]. Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.\nCyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-$n$ studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# Acknowledgements\nThe author is indebted to William Akoto, Jason Healey, Nadiya Kostyuk, Jon Lindsay, Mike Poznansky, Jack Snyder, Brandon Valeriano, JD Work, participants of the Digital Issues Discussion Group (DIDG), and four anonymous reviewers for helpful comments that improved this manuscript. This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484 (September 2021-November 2021) and 2021-2970 (November 2021 on).\nElectronic copy available at: https://ssrn.com/abstract=3611582",
  "citations": {
    "style": "superscript",
    "flat_text": "# Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay\nJustin Key Canfil\nJune 20, 2020\n## Abstract\nIt is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict.\nWord Count: 12,500\nKeywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.\nHow have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.\nScholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give\nElectronic copy available at: https://ssrn.com/abstract=3611582\nit even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.”\nIn this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14].\nThe proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in\nElectronic copy available at: https://ssrn.com/abstract=3611582\nresponse to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.\nThat is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.\n# 1 Cyber Proxies: What We Know\nWhether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict. For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident [24–27]. Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization [24, 30]. Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors [31].\nLong ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft [19]. Scholars have found that a majority of rebel groups since 1945 receive tacit state support [20] and this support has made these groups more powerful and influential [21]. They are observed most often between great power dyads [6, 22, 23], presumably because the risks associated with direct action are higher when targets can strike back.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nBut states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto [33] explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.” I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.\nThis of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting. More recent work by Florian Egloff [32] refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible [36].\nDetection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability [8, 35, 37–42]. Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.\nProxies \"may or may not be part of state security and intelligence agencies and may be criminal syndicates or private cybersecurity companies ... Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\" [33].\nMaurer [35] writes that state sponsors can actively fund or otherwise support non-state cyber actors with the expectation that these actors will accomplish some military, intelligence, or foreign policy objective on behalf of the state (what Maurer terms “orchestrating”). Alternatively, sponsors can simply permit offensive operations by non-state actors by turning a blind eye (“sanctioning”). At the opposite end, a sponsor can establish effective in-house command and control over the group (“delegating”).\nElectronic copy available at: https://ssrn.com/abstract=3611582\nVictim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors [43]. If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.\nSome non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998 [44]. Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors [8]. Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments [45] to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy's fidelity, and plausible deniability is strengthened.\nThis logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea [47] – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries [38, 42, 49–51]. On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation [35, 46]. Between 9/11 and the start of the Iraq War, for example, when US nationalism soared,\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthe US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets [53]. On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.\nSo just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-$n$ datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto [33] explains, these data limitations have “crippled efforts to study … cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.\nThe third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.\nFor researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas [54–56], but for this reason the study of cyber proxies faces a special set of challenges.\n## 1.1 Observational Equivalence in Existing Data\nThe crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing\nElectronic copy available at: https://ssrn.com/abstract=3611582\ndoesn't convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.\nTo illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.[8]\nOne reasonable expectation might be that states are likelier to delegate certain tasks to proxies – for example, less sophisticated or less sensitive operations. We can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.[10] However, it only tracks proxy relationship onset.[11] As a strictly cumulative measure, it cannot be used to measure whether outsourcing has declined. Instead, we can use it to observe the rate at which states have continued to outsource to new groups in recent years.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 1: Comparisons of trends over time from three datasets [33, 57, 58]. The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade.\nFigure 1 compares observations from all three datasets. The  $Y$ -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction.[12] Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nWe can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.\nThese trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto [33] explains that in order for the onset of a proxy relationship to appear in the dataset, \"there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government\" (emphasis mine). Akoto [33] continues: \"It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.\" Data collection is scoped on proxies which are already known to work for the state. Conclusion in the dataset is therefore inversely related the plausibility of a sponsor's deniability.\nWhat this means is that the large-$n$ information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.\nDirect measurements of outsourcing in available data cannot distinguish between these\n Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].\nElectronic copy available at: https://ssrn.com/abstract=3611582\ncompeting accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn't plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.\n## 2 The Illogic of Plausible Deniability\nIt has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true.\nIn the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its \"most difficult problem\" [61]. The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible [12, 13, 64]. Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns [65].\nEven if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose [33]. States are often sensitive about divulging how they know what they know [66]. Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on\nElectronic copy available at: https://ssrn.com/abstract=3611582\na direct command role can be held responsible for the actions of their proxies [36, 67].\nThese barriers are what make outsourcing so attractive, according to conventional wisdom [35]. But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal [33, 68]? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers [33, 69]. A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal [71] described plans to adopt a model reminiscent of US Cyber Command.\nFrom 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support [28]. Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000 [24], however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang [73] catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets [75]. Since then, the Chinese government has relied more on specialized units at the Ministry of State Security [35, 71]. Attacks\nThe International Law Commission (ILC)'s 2001 Draft Articles is perhaps the clearest articulation of the law on state responsibility (though often cited, it is actually a nonbinding source). In the ILC's view, a host state can only be held responsible if it directly conducts or oversees the offending operation at the operational level (see International Law Commission (ILC) Draft Articles on State Responsibility, 2001, http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf). International courts have held variously that the relationship must be one of \"effective control\" (Nicaragua v. United States), \"overall control\" plus the commission of specific acts (Prosecutor v. Dusko Tadic (1999)), or \"complete dependence\" (Bosnia and Herzegovina v. Serbia and Montenegro (1996)) – all very strict standards that elide the possibility of measures short of command or operational involvement. And in more than 4,700 claims proceedings, all but one tribunal (Dames &amp; Moore v. Iran) found that the burden of proof for wrongdoing rests with the defender (see Iran Claims Tribunal, https://www.state.gov/iran-u-s-claims-tribunal/).\nElectronic copy available at: https://ssrn.com/abstract=3611582\noriginating from that country reveal a more direct government hand [76]. If proxies pay for the reasons we usually suspect, then this behavior is puzzling.\nRarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect [12, 13, 77, 78]. Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.\nIn particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment [79]. Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices [80] – a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” [79].\n For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nIt is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.” In a separate piece, Carlin [43] explains that the Criminal and National Security Divisions at DOJ \"increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases),\" including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.\nThis level of cooperation gives the government specially enhanced attribution capabilities. Carlin [43] describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are” [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak [13].\nEspecially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin [43] admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: \"the government must demonstrate, among other things, that the ‘target ... is a foreign power or an agent of a foreign power’” if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.\nIndictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement [85–87]. To my knowledge, there is no institutional\n [for a detailed exposition in this journal, see 78].\n “The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].\nElectronic copy available at: https://ssrn.com/abstract=3611582\nrequirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” [89], they now seem more willing to punish sponsors for the activities of their proxies.\nAfter all, why wouldn't victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate [90]. States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.\nRaising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.\n## 2.1 A Model of Outsourcing\nHow can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology\n Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nfor checking and comparing a theory's internal validity this way. Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev [91], I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work \"under the hood\" in cases where data are questionable or unavailable.\nEvery theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large- $n$  data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes [92].\nIn the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims' beliefs and the level of investment. Under this framework, the sponsor's deniability is a function of its involvement and the target state's independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.\nThe model shows how a sponsor's concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthis holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship [8]. The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability's role in decisions about whether to outsource.\n## 2.2 Model setup\nA host government $(G)$ oversees a pool of non-state hackers $(H)$. The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as $\\varphi \\in [0,1]$, where $\\varphi &gt; 0$ is some positive degree of outsourcing. One can imagine that low levels of $\\varphi$ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at $\\varphi = 0$, for instance by implementing and enforcing laws against hacking foreign targets. In the game, $G$'s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.\nThe government's return on investment is given as $\\hat{u} x$, where $x$ is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker's level of sophistication, $\\psi_{i}$. The probability of a successful campaign is $\\psi_{i}$. I assume that individual operations are scalable, and thus the government obtains either full benefit $\\hat{u} x$ from a successful campaign $(\\psi = 1)$ or no benefit at all $(1 - \\psi)$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nConsistent with default explanations, $G$ faces principal-agent problems vis-a-vis $H$. The degree of agent drift – a function of $H$'s operational discipline and its ideological sympathy with government objectives – is written as $\\theta$. The government's level of investment $x$, and thus its expected payoffs, are penalized increasing in $\\theta$. In other words, the less reliable the agent $(\\theta \\uparrow)$, the less useful its efforts.\nFinally, $G$ gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, $f(\\varphi)$, and that the attacker faces penalties increasing in attack scale, $x$. This would be modeled as $x \\times \\varphi$: the less centralized, the more deniability when scale is held constant. The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target's right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.\n|  Term | Description | Range | Type  |\n| --- | --- | --- | --- |\n|  φ | Extent of outsourcing strategy | ∈ [0,1] | G’s Strategy  |\n|  ψ | Operational sophistication (probability of success) | ∈ [0,1] | Exogenous  |\n|  u | Return on scale of investment | ∈ R>0 | Exogenous  |\n|  x | Campaign investment | ∈ R>0 | Exogenous  |\n|  θ | Distance between principal / agent ideal points | ∈ R>0 | Exogenous  |\n|  γ | Fixed cost of centralization | ∈ R>0 | Exogenous  |\n|  c | Penalty of being caught & attributed | ∈ R>0 | Exogenous  |\n|  τ | Target’s ability to attribute (technical attrib.) | ∈ [0,1] | Exogenous  |\n|  α | Target’s willingness to accuse (political attrib.) | ∈ R>0 | Exogenous  |\nTable 1: Parameter Guide\nDeparting from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted $\\tau$, and political attribution, $\\alpha$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nAttribution $\\tau_v$ is simply the probability of detection, determined by the target state's capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, $\\alpha_v &gt; 1$, is determined by the target state's tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state's capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence.\nThe government's payoff can be modeled as\n$$\nU_G(\\varphi) = \\psi \\hat{u} x (2 - \\varphi) - \\theta \\varphi x - \\gamma (1 - \\varphi) - \\tau_v c \\left(\\alpha_v(\\varphi) + x (1 - \\varphi)\\right)\n$$\nIn plain terms, $G$'s expected benefit is given by the balance of participation, $\\hat{u}(2 - \\varphi)$, times the probability the campaign is successful ($\\psi$), and the amount of material investment required ($x$). If the campaign is successful, $G$'s investment yields a return of $\\hat{u}x$. $G$ has a choice whether to outsource ($\\varphi &gt; 0$) or centralize the campaign ($\\varphi = 0$). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment ($\\theta x$). Centralization may also involve investment of some fixed downpayment $\\gamma$. For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, $G$ incurs some penalty based on the target's ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes $\\varphi$ given the parameters.\nAs a stricter test of the theory, eliminate any agent drift $\\theta$ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that $H$'s\nElectronic copy available at: https://ssrn.com/abstract=3611582\nskill is equivalent to $G$'s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in $\\varphi$ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, $G$'s decision hinges on $\\alpha$.\nFor simplicity, assume the return on investment is linearly increasing in average attack scale $(\\hat{u} = 1)$. Also equalize the $\\theta$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal. Like the model employed by Lindsay [13], this setup allows us to locate the optimal attack scale. Since I regard $x$ as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, $\\psi$, as a constant. Set $\\psi = 1$ for the most interesting case. As a final simplification, assume technical attribution is certain whenever $G$ attacks $(\\tau = 1)$, and that the penalty $c$ is linearly increasing in scale as a function of the cumulative evidence left behind $x$. This implies a one-to-one increase in the target's ability to implicate the host state if the host state runs the campaign directly, since in this case \"responsibility\" can be proven through technical means alone. Set $x, c = 1$.\nThis set of assumptions simplifies the equation to $U_{G}(\\varphi) = x(2 - \\varphi) - c(\\alpha_{\\varphi}(\\varphi) + x(1 - \\varphi))$. In order to constitute an equilibrium where $G$ outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies\n$$\n\\varphi &gt; \\frac{1}{a}\n$$\nwhich illustrates the general relationship between outsourcing $(\\varphi)$ and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us\n I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\nU _ {G} (\\varphi) = x (2 - \\varphi) - (\\alpha_ {v} (\\varphi) + (1 - \\varphi))\n$$\nwhere expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and $\\varphi$ in Theorem 1.\nTheorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter's borders $(\\alpha)$, the lower the host state's incentive to outsource $(\\varphi)$.\nProof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of $\\varphi$ via straightforward optimization. The proof is concise enough to show in the body of the paper.\nWith no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: $(\\alpha_v(\\varphi) + (1 - \\varphi))^2$, which gives us the transformation\n$$\n\\max U _ {G} (\\varphi) = x (2 - \\varphi) - \\tau (\\alpha_ {v} (\\varphi) + (1 - \\varphi)) ^ {2}\n$$\nThe first order condition (FOC) must isolate at least one extremum in order to find a critical point at which $G$ will choose to switch between strategies. Differentiate the function with respect to $\\varphi$:\n$$\n\\frac {\\partial}{\\partial \\varphi} U _ {G} (\\cdot) = - (\\alpha + 1) (\\alpha \\varphi + \\varphi - 1) - x\n$$\nWe can then solve for the optimal level of $\\varphi$ by simply setting the derivative equal to zero and rearranging algebraically for $\\varphi$. This produces:\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\n\\varphi^ {*} = \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\text{ where } \\alpha \\geq 0 \\text{ by assumption} \\tag{1}\n$$\nThe second order condition (SOC) confirms that $\\varphi^{*}$ is indeed a global maximum:\n$$\n\\frac {\\partial^ {2}}{\\partial^ {2} \\varphi} U _ {G} (\\varphi) = - a ^ {2} - 2 a - 1 \\text{ which is } &lt; 0 \\tag{2}\n$$\nWe observe from Equation 2 that the slope is decreasing at $U_{G}^{\\prime \\prime}$, proving that $\\varphi^{*}$ maximizes $G$'s payoff function.\n## 2.3 Analysis\nWe wish to know how $U_{G}(\\varphi^{*})$ changes with $\\alpha, x$. Substituting $\\varphi^{*}$ into the original equation find calculate $G$'s expected utility, we obtain\n$$\nU _ {G} (\\varphi^ {*}) = x \\left[ 2 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\right] - x \\left[ \\alpha \\left(\\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) + \\left(1 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) \\right]\n$$\n$$\n\\text{which is equivalent to } U _ {G} \\left(\\varphi^ {*}\\right) = \\frac {\\alpha x ^ {2} + \\alpha x + x}{\\alpha^ {2} + 2 \\alpha + 1} \\tag{3}\n$$\nEquation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility $G$ can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between $\\alpha$ and $x$, neither Equation 1 nor Equation 3 is immediately intuitive. The relationship becomes more apparent when $\\alpha$ is $\\varphi^{*}$ is plotted. Figure 2 (right)\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim's propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their \"plausible deniability\" appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able).\nshows the utility gained for different levels of  $\\varphi$ . Outsourcing becomes less advantageous as  $\\alpha$  increases. In this model, the target state's  $\\alpha$  is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal  $\\varphi^{*}$ . As  $\\alpha$  increases, the expected gains of centralization  $(\\varphi^{*} \\downarrow)$  begin to exceed the gains from outsourcing  $(\\varphi^{*} \\uparrow)$ . The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay [13]'s findings on deterrence. Imputing values can help give us more precise point estimates.\nExample 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence  $(\\alpha = 0)$ . Then the optimal level of outsourcing is  $\\varphi^{*} = x$  and  $G$  would receive  $U_{G}(\\varphi^{*}) = \\tilde{u} x$  for any level of  $x$ . The value of  $x$  that maximizes this relationship is 1, so  $\\varphi^{*} = 1$ . In other\nElectronic copy available at: https://ssrn.com/abstract=3611582\nwords, $G$ gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming $\\hat{u} &gt; 1$) that $G$ would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom.\nExample 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. $\\alpha = 10$. Then $\\varphi^{*} = (10x^{2} + 11x) / 121$, and the calculation becomes more complex. Fixing $\\varphi^{*} = 0.148$, $x^{*} = 0.895$ at their optima (see previous footnote), $G$ can expect to receive $0.148\\hat{u}$. Note that $G$'s maximum payoff is strictly (and significantly) lower when $\\alpha = 1$ no matter what its strategy. Payoffs diminish further as $\\alpha$ increases or return on investment $\\hat{u}$ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.\n## 2.4 Discussion\nIn nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states' increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.\nIn practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however,\n In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthat unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions [55] as opposed to decentralized strategies, such as outsourcing.\nPursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay [13] argues compellingly that a target’s willingness to assign blame and/or retaliate could be positively related to the scale of the attack. If true, the results may even underestimate the influence of $\\alpha$, and therefore overstate the rate of outsourcing. Operations that are serious enough to be of interest to the attacking state would likely invite in-kind retaliation even if the evidence were extremely flimsy. As technical attribution capabilities continue to improve and norms become more conducive as a consequence of emerging state practice, political attributions will only become more common.\n# 3 Empirical Strategy\nResearchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?\nThere is no dataset that tracks negative variation in proxy relationships over time. As mentioned,\nElectronic copy available at: https://ssrn.com/abstract=3611582\n|  EVIDENCE | VALUE |   | SUSPICIOUS TARGET  |\n| --- | --- | --- | --- |\n|  Uniformed Personnel | (5) | Direct proof | Implausibly deniable  |\n|  Agency/Contractor | (4) | Strong proof | Implausibly deniable  |\n|  IoCs: Known Group | (3) | Technical proof | Questionably deniable  |\n|  IoCs: Location | (2) | Technical proof | Plausibly deniable  |\n|  Cui bono | (1) | Circumstantial proof | Plausibly deniable  |\n|  No evidence | (0) | No proof | Plausibly deniable  |\nTable 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a  $\\{0:5\\}$  scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).\nAkoto [33] tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.\nEach observation in CFR's dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.[23] While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).\nFor information on victim responses, I rely on Hinck and Maurer [99]'s data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer [99] dataset up to date (2022) by\nElectronic copy available at: https://ssrn.com/abstract=3611582\nsearching the DOJ's website for news and press releases under the category of cyber crime.\nUnsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive [100]. Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 [101]. Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step. This generates a daily count variable ranging from 1 to 4.\nThe data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.\nIn Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a\n https://www.justice.gov/news\n These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.\n It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time.\ngreater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof. Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.\n Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 3.1 Analysis\nTo explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsourcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn't actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.\nIn the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.\nFor tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, *more insourcing* should imply *less outsourcing*.\nNext, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country $i$ was implicated in year $j$. In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are\nElectronic copy available at: https://ssrn.com/abstract=3611582\nmeasuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.\nI include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony.\n|   | Dependent variables:  |   |   |   |\n| --- | --- | --- | --- | --- |\n|   | Observe Insourcing → Sponsor FE |   | Public Response  |   |\n|   | (1) | Two-Way FE | Sponsor FE | Two-Way FE  |\n|  Public Response (t-1) | 0.049*** (0.016) | 0.050*** (0.017) |  |   |\n|  Obs. Insourcing (t-1) |  |  | 0.028 (0.043) | 0.035 (0.042)  |\n|  Year (Control) | 0.015*** (0.005) |  | 0.013** (0.006) |   |\n|  Incident (Control) | 0.114*** (0.015) | 0.112*** (0.010) | 0.088*** (0.022) | 0.082*** (0.021)  |\n|  Observations | 186 | 186 | 186 | 186  |\n|  R2 | 0.450 | 0.304 | 0.355 | 0.207  |\n|  Adjusted R2 | 0.409 | 0.180 | 0.307 | 0.065  |\n|  Note: |  |  | *p<0.1; **p<0.05; ***p<0.01  |   |\nTable 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries' propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government's willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.\nTable 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects\nElectronic copy available at: https://ssrn.com/abstract=3611582\nare presented in the odd columns as a robustness check. Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insure operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.\nFirst examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t−1) are positively associated with decisions by other countries to insure in subsequent periods (p &lt; 0.01). Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods. Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.\nModels 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of\n Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.\n The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.\n Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\na sponsor's involvement and its willingness to respond publicly ($p = 0.35$). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.\nWhy might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.\nMoreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\" [104].\nThough caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal [105]. The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 4 Conclusion\nScholars have long been interested in the conditions under which new cyber norms can emerge and proliferate [106–109]. Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible [110, 111]. Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is *in fact* on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.\nOn the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a *true* decline, or a turn away from *ineffective* proxies in favor of even stealthier alternatives.\nThis potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their *own* operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected\nElectronic copy available at: https://ssrn.com/abstract=3611582\nattacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.\nAs opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.\nWithout plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts [112]. In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway [56, 58]. If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.\nIf not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes [26, 115]. And at times and in places where online nationalism\n It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nis elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own [20, 116], a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals [117], helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.\nFormalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets [118], Gorwa and Smeets [119], and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance [119]. Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.\nCyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-$n$ studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# Acknowledgements\nThe author is indebted to William Akoto, Jason Healey, Nadiya Kostyuk, Jon Lindsay, Mike Poznansky, Jack Snyder, Brandon Valeriano, JD Work, participants of the Digital Issues Discussion Group (DIDG), and four anonymous reviewers for helpful comments that improved this manuscript. This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484 (September 2021-November 2021) and 2021-2970 (November 2021 on).\nElectronic copy available at: https://ssrn.com/abstract=3611582",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 30,
        "success_occurrences": 30,
        "success_unique": 15,
        "bib_unique_total": 15,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 1.0,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "\"",
          "footnote": "Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].",
          "position": 20937
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "not distinguish between these\n",
          "footnote": "Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].",
          "position": 21686
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.",
          "position": 27406
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.",
          "position": 29517
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "”",
          "footnote": "[for a detailed exposition in this journal, see 78].",
          "position": 29861
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "“The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].",
          "position": 30376
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "ge, there is no institutional\n",
          "footnote": "[for a detailed exposition in this journal, see 78].",
          "position": 31927
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "“The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].",
          "position": 31983
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.",
          "position": 32751
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "re the appropriate technology\n",
          "footnote": "Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.",
          "position": 34230
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.",
          "position": 44352
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "This instead gives us",
          "footnote": "I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.",
          "position": 45802
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "",
          "footnote": "In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.",
          "position": 51981
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "The model shows, however,",
          "footnote": "In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.",
          "position": 53347
        },
        {
          "index": 24,
          "intext_citation": "²⁴",
          "preceding_text": "",
          "footnote": "https://www.justice.gov/news",
          "position": 58843
        },
        {
          "index": 25,
          "intext_citation": "²⁵",
          "preceding_text": "",
          "footnote": "These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.",
          "position": 59808
        },
        {
          "index": 26,
          "intext_citation": "²⁶",
          "preceding_text": "",
          "footnote": "It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.",
          "position": 59869
        },
        {
          "index": 24,
          "intext_citation": "²⁴",
          "preceding_text": "While a",
          "footnote": "https://www.justice.gov/news",
          "position": 60859
        },
        {
          "index": 25,
          "intext_citation": "²⁵",
          "preceding_text": "gov/news",
          "footnote": "These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.",
          "position": 60891
        },
        {
          "index": 26,
          "intext_citation": "²⁶",
          "preceding_text": "",
          "footnote": "It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.",
          "position": 61161
        },
        {
          "index": 27,
          "intext_citation": "²⁷",
          "preceding_text": "",
          "footnote": "Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).",
          "position": 61922
        },
        {
          "index": 27,
          "intext_citation": "²⁷",
          "preceding_text": "",
          "footnote": "Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).",
          "position": 62124
        },
        {
          "index": 28,
          "intext_citation": "²⁸",
          "preceding_text": "",
          "footnote": "Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.",
          "position": 68251
        },
        {
          "index": 29,
          "intext_citation": "²⁹",
          "preceding_text": "",
          "footnote": "The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.",
          "position": 69175
        },
        {
          "index": 30,
          "intext_citation": "³⁰",
          "preceding_text": "",
          "footnote": "Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.",
          "position": 69426
        },
        {
          "index": 28,
          "intext_citation": "²⁸",
          "preceding_text": "ained irrefutable evidence of\n",
          "footnote": "Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.",
          "position": 70034
        },
        {
          "index": 29,
          "intext_citation": "²⁹",
          "preceding_text": "",
          "footnote": "The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.",
          "position": 70512
        },
        {
          "index": 30,
          "intext_citation": "³⁰",
          "preceding_text": "",
          "footnote": "Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.",
          "position": 71081
        },
        {
          "index": 31,
          "intext_citation": "³¹",
          "preceding_text": "",
          "footnote": "It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.",
          "position": 77108
        },
        {
          "index": 31,
          "intext_citation": "³¹",
          "preceding_text": "aces where online nationalism\n",
          "footnote": "It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.",
          "position": 78352
        }
      ],
      "flat_text": "# Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay\nJustin Key Canfil\nJune 20, 2020\n## Abstract\nIt is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict.\nWord Count: 12,500\nKeywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.\nHow have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.\nScholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give\nElectronic copy available at: https://ssrn.com/abstract=3611582\nit even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.”\nIn this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14].\nThe proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in\nElectronic copy available at: https://ssrn.com/abstract=3611582\nresponse to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.\nThat is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.\n# 1 Cyber Proxies: What We Know\nWhether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict. For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident [24–27]. Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization [24, 30]. Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors [31].\nLong ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft [19]. Scholars have found that a majority of rebel groups since 1945 receive tacit state support [20] and this support has made these groups more powerful and influential [21]. They are observed most often between great power dyads [6, 22, 23], presumably because the risks associated with direct action are higher when targets can strike back.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nBut states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto [33] explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.” I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.\nThis of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting. More recent work by Florian Egloff [32] refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible [36].\nDetection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability [8, 35, 37–42]. Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.\nProxies \"may or may not be part of state security and intelligence agencies and may be criminal syndicates or private cybersecurity companies ... Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\" [33].\nMaurer [35] writes that state sponsors can actively fund or otherwise support non-state cyber actors with the expectation that these actors will accomplish some military, intelligence, or foreign policy objective on behalf of the state (what Maurer terms “orchestrating”). Alternatively, sponsors can simply permit offensive operations by non-state actors by turning a blind eye (“sanctioning”). At the opposite end, a sponsor can establish effective in-house command and control over the group (“delegating”).\nElectronic copy available at: https://ssrn.com/abstract=3611582\nVictim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors [43]. If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.\nSome non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998 [44]. Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors [8]. Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments [45] to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy's fidelity, and plausible deniability is strengthened.\nThis logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea [47] – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries [38, 42, 49–51]. On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation [35, 46]. Between 9/11 and the start of the Iraq War, for example, when US nationalism soared,\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthe US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets [53]. On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.\nSo just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-$n$ datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto [33] explains, these data limitations have “crippled efforts to study … cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.\nThe third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.\nFor researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas [54–56], but for this reason the study of cyber proxies faces a special set of challenges.\n## 1.1 Observational Equivalence in Existing Data\nThe crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing\nElectronic copy available at: https://ssrn.com/abstract=3611582\ndoesn't convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.\nTo illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.[8]\nOne reasonable expectation might be that states are likelier to delegate certain tasks to proxies – for example, less sophisticated or less sensitive operations. We can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.[10] However, it only tracks proxy relationship onset.[11] As a strictly cumulative measure, it cannot be used to measure whether outsourcing has declined. Instead, we can use it to observe the rate at which states have continued to outsource to new groups in recent years.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 1: Comparisons of trends over time from three datasets [33, 57, 58]. The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade.\nFigure 1 compares observations from all three datasets. The  $Y$ -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction.[12] Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nWe can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.\nThese trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto [33] explains that in order for the onset of a proxy relationship to appear in the dataset, \"there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government\" (emphasis mine). Akoto [33] continues: \"It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.\" Data collection is scoped on proxies which are already known to work for the state. Conclusion in the dataset is therefore inversely related the plausibility of a sponsor's deniability.\nWhat this means is that the large-$n$ information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.\nDirect measurements of outsourcing in available data cannot distinguish between these\n Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].\nElectronic copy available at: https://ssrn.com/abstract=3611582\ncompeting accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn't plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.\n## 2 The Illogic of Plausible Deniability\nIt has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true.\nIn the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its \"most difficult problem\" [61]. The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible [12, 13, 64]. Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns [65].\nEven if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose [33]. States are often sensitive about divulging how they know what they know [66]. Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on\nElectronic copy available at: https://ssrn.com/abstract=3611582\na direct command role can be held responsible for the actions of their proxies [36, 67].\nThese barriers are what make outsourcing so attractive, according to conventional wisdom [35]. But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal [33, 68]? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers [33, 69]. A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal [71] described plans to adopt a model reminiscent of US Cyber Command.\nFrom 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support [28]. Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000 [24], however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang [73] catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets [75]. Since then, the Chinese government has relied more on specialized units at the Ministry of State Security [35, 71]. Attacks\nThe International Law Commission (ILC)'s 2001 Draft Articles is perhaps the clearest articulation of the law on state responsibility (though often cited, it is actually a nonbinding source). In the ILC's view, a host state can only be held responsible if it directly conducts or oversees the offending operation at the operational level (see International Law Commission (ILC) Draft Articles on State Responsibility, 2001, http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf). International courts have held variously that the relationship must be one of \"effective control\" (Nicaragua v. United States), \"overall control\" plus the commission of specific acts (Prosecutor v. Dusko Tadic (1999)), or \"complete dependence\" (Bosnia and Herzegovina v. Serbia and Montenegro (1996)) – all very strict standards that elide the possibility of measures short of command or operational involvement. And in more than 4,700 claims proceedings, all but one tribunal (Dames &amp; Moore v. Iran) found that the burden of proof for wrongdoing rests with the defender (see Iran Claims Tribunal, https://www.state.gov/iran-u-s-claims-tribunal/).\nElectronic copy available at: https://ssrn.com/abstract=3611582\noriginating from that country reveal a more direct government hand [76]. If proxies pay for the reasons we usually suspect, then this behavior is puzzling.\nRarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect [12, 13, 77, 78]. Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.\nIn particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment [79]. Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices [80] – a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” [79].\n For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nIt is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.” In a separate piece, Carlin [43] explains that the Criminal and National Security Divisions at DOJ \"increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases),\" including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.\nThis level of cooperation gives the government specially enhanced attribution capabilities. Carlin [43] describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are” [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak [13].\nEspecially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin [43] admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: \"the government must demonstrate, among other things, that the ‘target ... is a foreign power or an agent of a foreign power’” if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.\nIndictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement [85–87]. To my knowledge, there is no institutional\n [for a detailed exposition in this journal, see 78].\n “The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].\nElectronic copy available at: https://ssrn.com/abstract=3611582\nrequirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” [89], they now seem more willing to punish sponsors for the activities of their proxies.\nAfter all, why wouldn't victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate [90]. States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.\nRaising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.\n## 2.1 A Model of Outsourcing\nHow can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology\n Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nfor checking and comparing a theory's internal validity this way. Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev [91], I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work \"under the hood\" in cases where data are questionable or unavailable.\nEvery theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large- $n$  data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes [92].\nIn the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims' beliefs and the level of investment. Under this framework, the sponsor's deniability is a function of its involvement and the target state's independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.\nThe model shows how a sponsor's concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthis holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship [8]. The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability's role in decisions about whether to outsource.\n## 2.2 Model setup\nA host government $(G)$ oversees a pool of non-state hackers $(H)$. The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as $\\varphi \\in [0,1]$, where $\\varphi &gt; 0$ is some positive degree of outsourcing. One can imagine that low levels of $\\varphi$ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at $\\varphi = 0$, for instance by implementing and enforcing laws against hacking foreign targets. In the game, $G$'s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.\nThe government's return on investment is given as $\\hat{u} x$, where $x$ is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker's level of sophistication, $\\psi_{i}$. The probability of a successful campaign is $\\psi_{i}$. I assume that individual operations are scalable, and thus the government obtains either full benefit $\\hat{u} x$ from a successful campaign $(\\psi = 1)$ or no benefit at all $(1 - \\psi)$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nConsistent with default explanations, $G$ faces principal-agent problems vis-a-vis $H$. The degree of agent drift – a function of $H$'s operational discipline and its ideological sympathy with government objectives – is written as $\\theta$. The government's level of investment $x$, and thus its expected payoffs, are penalized increasing in $\\theta$. In other words, the less reliable the agent $(\\theta \\uparrow)$, the less useful its efforts.\nFinally, $G$ gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, $f(\\varphi)$, and that the attacker faces penalties increasing in attack scale, $x$. This would be modeled as $x \\times \\varphi$: the less centralized, the more deniability when scale is held constant. The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target's right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.\n|  Term | Description | Range | Type  |\n| --- | --- | --- | --- |\n|  φ | Extent of outsourcing strategy | ∈ [0,1] | G’s Strategy  |\n|  ψ | Operational sophistication (probability of success) | ∈ [0,1] | Exogenous  |\n|  u | Return on scale of investment | ∈ R>0 | Exogenous  |\n|  x | Campaign investment | ∈ R>0 | Exogenous  |\n|  θ | Distance between principal / agent ideal points | ∈ R>0 | Exogenous  |\n|  γ | Fixed cost of centralization | ∈ R>0 | Exogenous  |\n|  c | Penalty of being caught & attributed | ∈ R>0 | Exogenous  |\n|  τ | Target’s ability to attribute (technical attrib.) | ∈ [0,1] | Exogenous  |\n|  α | Target’s willingness to accuse (political attrib.) | ∈ R>0 | Exogenous  |\nTable 1: Parameter Guide\nDeparting from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted $\\tau$, and political attribution, $\\alpha$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nAttribution $\\tau_v$ is simply the probability of detection, determined by the target state's capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, $\\alpha_v &gt; 1$, is determined by the target state's tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state's capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence.\nThe government's payoff can be modeled as\n$$\nU_G(\\varphi) = \\psi \\hat{u} x (2 - \\varphi) - \\theta \\varphi x - \\gamma (1 - \\varphi) - \\tau_v c \\left(\\alpha_v(\\varphi) + x (1 - \\varphi)\\right)\n$$\nIn plain terms, $G$'s expected benefit is given by the balance of participation, $\\hat{u}(2 - \\varphi)$, times the probability the campaign is successful ($\\psi$), and the amount of material investment required ($x$). If the campaign is successful, $G$'s investment yields a return of $\\hat{u}x$. $G$ has a choice whether to outsource ($\\varphi &gt; 0$) or centralize the campaign ($\\varphi = 0$). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment ($\\theta x$). Centralization may also involve investment of some fixed downpayment $\\gamma$. For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, $G$ incurs some penalty based on the target's ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes $\\varphi$ given the parameters.\nAs a stricter test of the theory, eliminate any agent drift $\\theta$ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that $H$'s\nElectronic copy available at: https://ssrn.com/abstract=3611582\nskill is equivalent to $G$'s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in $\\varphi$ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, $G$'s decision hinges on $\\alpha$.\nFor simplicity, assume the return on investment is linearly increasing in average attack scale $(\\hat{u} = 1)$. Also equalize the $\\theta$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal. Like the model employed by Lindsay [13], this setup allows us to locate the optimal attack scale. Since I regard $x$ as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, $\\psi$, as a constant. Set $\\psi = 1$ for the most interesting case. As a final simplification, assume technical attribution is certain whenever $G$ attacks $(\\tau = 1)$, and that the penalty $c$ is linearly increasing in scale as a function of the cumulative evidence left behind $x$. This implies a one-to-one increase in the target's ability to implicate the host state if the host state runs the campaign directly, since in this case \"responsibility\" can be proven through technical means alone. Set $x, c = 1$.\nThis set of assumptions simplifies the equation to $U_{G}(\\varphi) = x(2 - \\varphi) - c(\\alpha_{\\varphi}(\\varphi) + x(1 - \\varphi))$. In order to constitute an equilibrium where $G$ outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies\n$$\n\\varphi &gt; \\frac{1}{a}\n$$\nwhich illustrates the general relationship between outsourcing $(\\varphi)$ and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us\n I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\nU _ {G} (\\varphi) = x (2 - \\varphi) - (\\alpha_ {v} (\\varphi) + (1 - \\varphi))\n$$\nwhere expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and $\\varphi$ in Theorem 1.\nTheorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter's borders $(\\alpha)$, the lower the host state's incentive to outsource $(\\varphi)$.\nProof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of $\\varphi$ via straightforward optimization. The proof is concise enough to show in the body of the paper.\nWith no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: $(\\alpha_v(\\varphi) + (1 - \\varphi))^2$, which gives us the transformation\n$$\n\\max U _ {G} (\\varphi) = x (2 - \\varphi) - \\tau (\\alpha_ {v} (\\varphi) + (1 - \\varphi)) ^ {2}\n$$\nThe first order condition (FOC) must isolate at least one extremum in order to find a critical point at which $G$ will choose to switch between strategies. Differentiate the function with respect to $\\varphi$:\n$$\n\\frac {\\partial}{\\partial \\varphi} U _ {G} (\\cdot) = - (\\alpha + 1) (\\alpha \\varphi + \\varphi - 1) - x\n$$\nWe can then solve for the optimal level of $\\varphi$ by simply setting the derivative equal to zero and rearranging algebraically for $\\varphi$. This produces:\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\n\\varphi^ {*} = \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\text{ where } \\alpha \\geq 0 \\text{ by assumption} \\tag{1}\n$$\nThe second order condition (SOC) confirms that $\\varphi^{*}$ is indeed a global maximum:\n$$\n\\frac {\\partial^ {2}}{\\partial^ {2} \\varphi} U _ {G} (\\varphi) = - a ^ {2} - 2 a - 1 \\text{ which is } &lt; 0 \\tag{2}\n$$\nWe observe from Equation 2 that the slope is decreasing at $U_{G}^{\\prime \\prime}$, proving that $\\varphi^{*}$ maximizes $G$'s payoff function.\n## 2.3 Analysis\nWe wish to know how $U_{G}(\\varphi^{*})$ changes with $\\alpha, x$. Substituting $\\varphi^{*}$ into the original equation find calculate $G$'s expected utility, we obtain\n$$\nU _ {G} (\\varphi^ {*}) = x \\left[ 2 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\right] - x \\left[ \\alpha \\left(\\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) + \\left(1 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) \\right]\n$$\n$$\n\\text{which is equivalent to } U _ {G} \\left(\\varphi^ {*}\\right) = \\frac {\\alpha x ^ {2} + \\alpha x + x}{\\alpha^ {2} + 2 \\alpha + 1} \\tag{3}\n$$\nEquation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility $G$ can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between $\\alpha$ and $x$, neither Equation 1 nor Equation 3 is immediately intuitive. The relationship becomes more apparent when $\\alpha$ is $\\varphi^{*}$ is plotted. Figure 2 (right)\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim's propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their \"plausible deniability\" appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able).\nshows the utility gained for different levels of  $\\varphi$ . Outsourcing becomes less advantageous as  $\\alpha$  increases. In this model, the target state's  $\\alpha$  is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal  $\\varphi^{*}$ . As  $\\alpha$  increases, the expected gains of centralization  $(\\varphi^{*} \\downarrow)$  begin to exceed the gains from outsourcing  $(\\varphi^{*} \\uparrow)$ . The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay [13]'s findings on deterrence. Imputing values can help give us more precise point estimates.\nExample 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence  $(\\alpha = 0)$ . Then the optimal level of outsourcing is  $\\varphi^{*} = x$  and  $G$  would receive  $U_{G}(\\varphi^{*}) = \\tilde{u} x$  for any level of  $x$ . The value of  $x$  that maximizes this relationship is 1, so  $\\varphi^{*} = 1$ . In other\nElectronic copy available at: https://ssrn.com/abstract=3611582\nwords, $G$ gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming $\\hat{u} &gt; 1$) that $G$ would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom.\nExample 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. $\\alpha = 10$. Then $\\varphi^{*} = (10x^{2} + 11x) / 121$, and the calculation becomes more complex. Fixing $\\varphi^{*} = 0.148$, $x^{*} = 0.895$ at their optima (see previous footnote), $G$ can expect to receive $0.148\\hat{u}$. Note that $G$'s maximum payoff is strictly (and significantly) lower when $\\alpha = 1$ no matter what its strategy. Payoffs diminish further as $\\alpha$ increases or return on investment $\\hat{u}$ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.\n## 2.4 Discussion\nIn nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states' increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.\nIn practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however,\n In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthat unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions [55] as opposed to decentralized strategies, such as outsourcing.\nPursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay [13] argues compellingly that a target’s willingness to assign blame and/or retaliate could be positively related to the scale of the attack. If true, the results may even underestimate the influence of $\\alpha$, and therefore overstate the rate of outsourcing. Operations that are serious enough to be of interest to the attacking state would likely invite in-kind retaliation even if the evidence were extremely flimsy. As technical attribution capabilities continue to improve and norms become more conducive as a consequence of emerging state practice, political attributions will only become more common.\n# 3 Empirical Strategy\nResearchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?\nThere is no dataset that tracks negative variation in proxy relationships over time. As mentioned,\nElectronic copy available at: https://ssrn.com/abstract=3611582\n|  EVIDENCE | VALUE |   | SUSPICIOUS TARGET  |\n| --- | --- | --- | --- |\n|  Uniformed Personnel | (5) | Direct proof | Implausibly deniable  |\n|  Agency/Contractor | (4) | Strong proof | Implausibly deniable  |\n|  IoCs: Known Group | (3) | Technical proof | Questionably deniable  |\n|  IoCs: Location | (2) | Technical proof | Plausibly deniable  |\n|  Cui bono | (1) | Circumstantial proof | Plausibly deniable  |\n|  No evidence | (0) | No proof | Plausibly deniable  |\nTable 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a  $\\{0:5\\}$  scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).\nAkoto [33] tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.\nEach observation in CFR's dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.[23] While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).\nFor information on victim responses, I rely on Hinck and Maurer [99]'s data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer [99] dataset up to date (2022) by\nElectronic copy available at: https://ssrn.com/abstract=3611582\nsearching the DOJ's website for news and press releases under the category of cyber crime.\nUnsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive [100]. Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 [101]. Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step. This generates a daily count variable ranging from 1 to 4.\nThe data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.\nIn Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a\n https://www.justice.gov/news\n These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.\n It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time.\ngreater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof. Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.\n Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 3.1 Analysis\nTo explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsourcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn't actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.\nIn the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.\nFor tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, *more insourcing* should imply *less outsourcing*.\nNext, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country $i$ was implicated in year $j$. In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are\nElectronic copy available at: https://ssrn.com/abstract=3611582\nmeasuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.\nI include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony.\n|   | Dependent variables:  |   |   |   |\n| --- | --- | --- | --- | --- |\n|   | Observe Insourcing → Sponsor FE |   | Public Response  |   |\n|   | (1) | Two-Way FE | Sponsor FE | Two-Way FE  |\n|  Public Response (t-1) | 0.049*** (0.016) | 0.050*** (0.017) |  |   |\n|  Obs. Insourcing (t-1) |  |  | 0.028 (0.043) | 0.035 (0.042)  |\n|  Year (Control) | 0.015*** (0.005) |  | 0.013** (0.006) |   |\n|  Incident (Control) | 0.114*** (0.015) | 0.112*** (0.010) | 0.088*** (0.022) | 0.082*** (0.021)  |\n|  Observations | 186 | 186 | 186 | 186  |\n|  R2 | 0.450 | 0.304 | 0.355 | 0.207  |\n|  Adjusted R2 | 0.409 | 0.180 | 0.307 | 0.065  |\n|  Note: |  |  | *p<0.1; **p<0.05; ***p<0.01  |   |\nTable 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries' propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government's willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.\nTable 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects\nElectronic copy available at: https://ssrn.com/abstract=3611582\nare presented in the odd columns as a robustness check. Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insure operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.\nFirst examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t−1) are positively associated with decisions by other countries to insure in subsequent periods (p &lt; 0.01). Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods. Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.\nModels 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of\n Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.\n The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.\n Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\na sponsor's involvement and its willingness to respond publicly ($p = 0.35$). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.\nWhy might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.\nMoreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\" [104].\nThough caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal [105]. The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 4 Conclusion\nScholars have long been interested in the conditions under which new cyber norms can emerge and proliferate [106–109]. Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible [110, 111]. Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is *in fact* on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.\nOn the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a *true* decline, or a turn away from *ineffective* proxies in favor of even stealthier alternatives.\nThis potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their *own* operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected\nElectronic copy available at: https://ssrn.com/abstract=3611582\nattacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.\nAs opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.\nWithout plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts [112]. In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway [56, 58]. If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.\nIf not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes [26, 115]. And at times and in places where online nationalism\n It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nis elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own [20, 116], a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals [117], helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.\nFormalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets [118], Gorwa and Smeets [119], and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance [119]. Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.\nCyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-$n$ studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# Acknowledgements\nThe author is indebted to William Akoto, Jason Healey, Nadiya Kostyuk, Jon Lindsay, Mike Poznansky, Jack Snyder, Brandon Valeriano, JD Work, participants of the Digital Issues Discussion Group (DIDG), and four anonymous reviewers for helpful comments that improved this manuscript. This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484 (September 2021-November 2021) and 2021-2970 (November 2021 on).\nElectronic copy available at: https://ssrn.com/abstract=3611582"
    },
    "numeric": {
      "total": {
        "intext_total": 192,
        "success_occurrences": 192,
        "success_unique": 106,
        "bib_unique_total": 119,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.8907563025210085,
        "success_percentage": 100.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "1",
          "intext_citation": "[1]",
          "preceding_text": "Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world”",
          "footnote": "Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46."
        },
        {
          "index": "2",
          "intext_citation": "[2–4]",
          "preceding_text": "But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement",
          "footnote": "Borghard, Erica. “Friends with Benefits? Power and Influence in Proxy Warfare”. PhD thesis. Columbia University, 2014."
        },
        {
          "index": "3",
          "intext_citation": "[2–4]",
          "preceding_text": "But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement",
          "footnote": "Salehyan, Idean, Siroky, David, and Wood, Reed M. “External Rebel Sponsorship and Civilian Abuse: A Principal-Agent Analysis of Wartime Atrocities”. In: *International Organization* 68.3 (2014). Publisher: [The MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 633–661."
        },
        {
          "index": "4",
          "intext_citation": "[2–4]",
          "preceding_text": "But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement",
          "footnote": "Szekely, Ora. “A Friend in Need: The Impact of the Syrian Civil War on Syria’s Clients (A Principal-Agent Approach)”. In: *Foreign Policy Analysis* 12.3 (July 1, 2016). Publisher: Oxford Academic, pp. 450–468."
        },
        {
          "index": "5",
          "intext_citation": "[5]",
          "preceding_text": "Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage",
          "footnote": "Abbott, Kenneth W. *Economic Sanctions and International Terrorism*. SSRN Scholarly Paper ID 1402844. Rochester, NY: Social Science Research Network, 1987."
        },
        {
          "index": "1",
          "intext_citation": "[1, 6, 7]",
          "preceding_text": "Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation",
          "footnote": "Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46."
        },
        {
          "index": "6",
          "intext_citation": "[1, 6, 7]",
          "preceding_text": "Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation",
          "footnote": "Kirchner, Magdalena. “‘A good investment?’ State sponsorship of terrorism as an instrument of Iraqi foreign policy (1979–1991)”. In: *Cambridge Review of International Affairs* 27.3 (July 3, 2014). Publisher: Routledge _eprint: https://doi.org/10.1080/09557571.2013.839629, pp. 521–537."
        },
        {
          "index": "7",
          "intext_citation": "[1, 6, 7]",
          "preceding_text": "Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation",
          "footnote": "Byman, Daniel and Kreps, Sarah E. “Agents of Destruction? Applying Principal-Agent Analysis to State-Sponsored Terrorism”. In: *International Studies Perspectives* 11.1 (Feb. 1, 2010). Publisher: Oxford Academic, pp. 1–18."
        },
        {
          "index": "8",
          "intext_citation": "[8, 9]",
          "preceding_text": "This logic is widely assumed to hold in cyberspace, as well",
          "footnote": "Borghard, Erica D. and Lonergan, Shawn W. “Can States Calculate the Risks of Using Cyber Proxies?” In: *Orbis* 60.3 (Jan. 1, 2016), pp. 395–416. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "9",
          "intext_citation": "[8, 9]",
          "preceding_text": "This logic is widely assumed to hold in cyberspace, as well",
          "footnote": "Applegate, Scott. \"Cybermilitias and Political Hackers: Use of Irregular Forces in Cyberwarfare\". In: IEEE Security Privacy 9.5 (Sept. 2011). Conference Name: IEEE Security Privacy, pp. 16–22."
        },
        {
          "index": "10",
          "intext_citation": "[10]",
          "preceding_text": "Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit",
          "footnote": "Poznansky, Michael and Perkoski, Evan. \"Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\". In: Journal of Global Security Studies 3.4 (Oct. 1, 2018), pp. 402–416."
        },
        {
          "index": "11",
          "intext_citation": "[11]",
          "preceding_text": "Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself",
          "footnote": "Brown, Joseph M. and Fazal, Tanisha M. “#SorryNotSorry: Why states neither confirm nor deny responsibility for cyber operations”. In: European Journal of International Security (Aug. 28, 2021). Publisher: Cambridge University Press, pp. 1–17."
        },
        {
          "index": "12",
          "intext_citation": "[12, 13]",
          "preceding_text": "Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution",
          "footnote": "Baliga, Sandeep, Mesquita, Ethan Bueno de, and Wolitzky, Alexander. \"Deterrence with Imperfect Attribution\". In: American Political Science Review (2020)."
        },
        {
          "index": "13",
          "intext_citation": "[12, 13]",
          "preceding_text": "Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "14",
          "intext_citation": "[14]",
          "preceding_text": "Scholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich",
          "footnote": "Cormac, Rory and Aldrich, Richard J. \"Grey is the new black: covert action and implausible deniability\". In: International Affairs 94.3 (May 1, 2018), pp. 477–494."
        },
        {
          "index": "15",
          "intext_citation": "[15]",
          "preceding_text": "Similarly, Lin-Greenberg and Milonopoulos",
          "footnote": "Lin-Greenberg, Erik and Milonopoulos, Theo. \"Private Eyes in the Sky: Emerging Technology and the Political Consequences of Eroding Government Secrecy\". In: Journal of Conflict Resolution 65.6 (July 1, 2021). Publisher: SAGE Publications Inc, pp. 1067–1097."
        },
        {
          "index": "16",
          "intext_citation": "[16]",
          "preceding_text": "Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman",
          "footnote": "Vaynman, Jane. \"Better Monitoring and Better Spying: The Implications of Emerging Technology for Arms Control\". In: Texas National Security Review 4.4 (Sept. 23, 2021)."
        },
        {
          "index": "14",
          "intext_citation": "[14]",
          "preceding_text": "For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich",
          "footnote": "Cormac, Rory and Aldrich, Richard J. \"Grey is the new black: covert action and implausible deniability\". In: International Affairs 94.3 (May 1, 2018), pp. 477–494."
        },
        {
          "index": "10",
          "intext_citation": "[10, 11, 14]",
          "preceding_text": "These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict",
          "footnote": "Poznansky, Michael and Perkoski, Evan. \"Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\". In: Journal of Global Security Studies 3.4 (Oct. 1, 2018), pp. 402–416."
        },
        {
          "index": "11",
          "intext_citation": "[10, 11, 14]",
          "preceding_text": "These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict",
          "footnote": "Brown, Joseph M. and Fazal, Tanisha M. “#SorryNotSorry: Why states neither confirm nor deny responsibility for cyber operations”. In: European Journal of International Security (Aug. 28, 2021). Publisher: Cambridge University Press, pp. 1–17."
        },
        {
          "index": "14",
          "intext_citation": "[10, 11, 14]",
          "preceding_text": "These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict",
          "footnote": "Cormac, Rory and Aldrich, Richard J. \"Grey is the new black: covert action and implausible deniability\". In: International Affairs 94.3 (May 1, 2018), pp. 477–494."
        },
        {
          "index": "17",
          "intext_citation": "[17]",
          "preceding_text": "To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war",
          "footnote": "Pitrelli, Monica Buchanan. 'For the first time in history anyone can join a war': Volunteers join Russia-Ukraine cyber fight. CNBC. Section: Technology. Mar. 14, 2022. URL: https://www.cnbc.com/2022/03/14/volunteers-sign-up-to-help-in-cyberwars-between-russia-and-ukraine-.html. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "18",
          "intext_citation": "[18]",
          "preceding_text": "Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\"",
          "footnote": "Fedorov, Mykhailo. We are creating an IT army. We need digital talents. All operational tasks will be given here: https://t.me/itarmyofurraine. There will be tasks for everyone. We continue to fight on the cyber front. The first task is on the channel for cyber specialists. @FedorovMykhailo. Feb. 26, 2022. URL: https://twitter.com/FedorovMykhailo/status/1497642156076511233."
        },
        {
          "index": "24",
          "intext_citation": "[24–27]",
          "preceding_text": "phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident",
          "footnote": "Singer, P. W. and Friedman, Allan. Cybersecurity and Cyberwar: What Everyone Needs to Know®. Google-Books-ID: B88ZAgAAQBAJ. Oxford University Press, Dec. 4, 2013. 836 pp."
        },
        {
          "index": "25",
          "intext_citation": "[24–27]",
          "preceding_text": "phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident",
          "footnote": "Gries, Peter Hays. China’s New Nationalism. First edition. Berkeley Los Angeles London: University of California Press, July 5, 2005. 226 pp."
        },
        {
          "index": "26",
          "intext_citation": "[24–27]",
          "preceding_text": "phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident",
          "footnote": "Weiss, Jessica Chen. *Powerful Patriots: Nationalist Protest in China’s Foreign Relations*. 1 edition. New York, NY: Oxford University Press, Sept. 1, 2014. 360 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "27",
          "intext_citation": "[24–27]",
          "preceding_text": "phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident",
          "footnote": "Lemos, Robert. Defacements rise in China hacker war. CNET. Library Catalog: www.cnet.com. URL: https://www.cnet.com/news/defacements-rise-in-china-hacker-war/."
        },
        {
          "index": "28",
          "intext_citation": "[28]",
          "preceding_text": "Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year",
          "footnote": "Mulvenon, James C. et al. Chinese Responses to U.S. Military Transformation and Implications for the Department of Defense. Google-Books-ID: zHwnDNZNmdUC. Rand Corporation, Apr. 5, 2006. 187 pp."
        },
        {
          "index": "29",
          "intext_citation": "[29]",
          "preceding_text": "Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world's most notorious cyber conflict “wake-up call”",
          "footnote": "Bahovski, Erkki. Francis Maude: The Cyber-Attack against Estonia Was a Big Wake-Up Call for the World. Diplomaatria. Library Catalog: icds.ee. Aug. 2012. URL: https://icds.ee/francis-maude-the-cyber-attack-against-estonia-was-a-big-wake-up-call-for-the-world/."
        },
        {
          "index": "24",
          "intext_citation": "[24, 30]",
          "preceding_text": "Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization",
          "footnote": "Singer, P. W. and Friedman, Allan. Cybersecurity and Cyberwar: What Everyone Needs to Know®. Google-Books-ID: B88ZAgAAQBAJ. Oxford University Press, Dec. 4, 2013. 836 pp."
        },
        {
          "index": "30",
          "intext_citation": "[24, 30]",
          "preceding_text": "Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization",
          "footnote": "Shachtman, Noah. \"Kremlin Kids: We Launched the Estonian Cyber War\". In: Wired (Mar. 11, 2009)."
        },
        {
          "index": "31",
          "intext_citation": "[31]",
          "preceding_text": "Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors",
          "footnote": "Nye, Joseph S. \"Cyber Power\". In: *Belfer Center for Science and International Affairs* (May 2010)."
        },
        {
          "index": "19",
          "intext_citation": "[19]",
          "preceding_text": "¹Long ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft",
          "footnote": "Stephenson, Evan. “Does United Nations War Prevention Encourage State-Sponsorship of International Terrorism - An Economic Analysis”. In: Virginia Journal of International Law 44 (2003), p. 1197."
        },
        {
          "index": "20",
          "intext_citation": "[20]",
          "preceding_text": "Scholars have found that a majority of rebel groups since 1945 receive tacit state support",
          "footnote": "Salehyan, Idean, Gleditsch, Kristian Skrede, and Cunningham, David E. “Explaining External Support for Insurgent Groups”. In: International Organization 65.4 (2011). Publisher: [MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 709–744."
        },
        {
          "index": "21",
          "intext_citation": "[21]",
          "preceding_text": "Scholars have found that a majority of rebel groups since 1945 receive tacit state support [20] and this support has made these groups more powerful and influential",
          "footnote": "Hoffman, Bruce. Inside Terrorism. REV - Revised, 2. Columbia University Press, 2006."
        },
        {
          "index": "6",
          "intext_citation": "[6, 22, 23]",
          "preceding_text": "They are observed most often between great power dyads",
          "footnote": "Kirchner, Magdalena. “‘A good investment?’ State sponsorship of terrorism as an instrument of Iraqi foreign policy (1979–1991)”. In: *Cambridge Review of International Affairs* 27.3 (July 3, 2014). Publisher: Routledge _eprint: https://doi.org/10.1080/09557571.2013.839629, pp. 521–537."
        },
        {
          "index": "22",
          "intext_citation": "[6, 22, 23]",
          "preceding_text": "They are observed most often between great power dyads",
          "footnote": "Findley, Michael G., Piazza, James A., and Young, Joseph K. “Games Rivals Play: Terrorism in International Rivalries”. In: The Journal of Politics 74.1 (Jan. 1, 2012). Publisher: The University of Chicago Press, pp. 235–248."
        },
        {
          "index": "23",
          "intext_citation": "[6, 22, 23]",
          "preceding_text": "They are observed most often between great power dyads",
          "footnote": "Conrad, Justin. “Interstate Rivalry and Terrorism: An Unprobed Link”. In: Journal of Conflict Resolution 55.4 (Aug. 1, 2011). Publisher: SAGE Publications Inc, pp. 529–555."
        },
        {
          "index": "32",
          "intext_citation": "[32]",
          "preceding_text": "States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives",
          "footnote": "Egloff, Florian J. Semi-State Actors in Cybersecurity. Oxford University Press, Dec. 20, 2021. 294 pp."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "34",
          "intext_citation": "[34]",
          "preceding_text": "This of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey",
          "footnote": "Healey, Jason. \"The Spectrum of National Responsibility for Cyberattacks\". In: The Brown Journal of World Affairs 18.1 (2011). Publisher: Brown Journal of World Affairs, pp. 57–70."
        },
        {
          "index": "35",
          "intext_citation": "[35]",
          "preceding_text": "Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer",
          "footnote": "Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "32",
          "intext_citation": "[32]",
          "preceding_text": "Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting.³ More recent work by Florian Egloff",
          "footnote": "Egloff, Florian J. Semi-State Actors in Cybersecurity. Oxford University Press, Dec. 20, 2021. 294 pp."
        },
        {
          "index": "36",
          "intext_citation": "[36]",
          "preceding_text": "Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible",
          "footnote": "Damrosch, Lori and Murphy, Sean. International Law. 6 edition. St. Paul, MN: West Academic Publishing, July 8, 2014. 1250 pp."
        },
        {
          "index": "8",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Borghard, Erica D. and Lonergan, Shawn W. “Can States Calculate the Risks of Using Cyber Proxies?” In: *Orbis* 60.3 (Jan. 1, 2016), pp. 395–416. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "35",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "37",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Maurer, Tim. \"Cyber Proxies and Their Implications for Liberal Democracies\". In: The Washington Quarterly 41.2 (Apr. 3, 2018). Publisher: Routledge _eprint: https://doi.org/10.1080/0163660X.2018.1485332, pp. 171-188."
        },
        {
          "index": "38",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Schmoldt, Janine. The Rising Power of Cyber Proxies. Vol. Thaddeus Eze (ed.) Google-Books-ID: wCo4EAAAQBAJ. Conferences Proceedings of 20th European Conference on Cyber Warfare and Security, June 24, 2021. 646 pp."
        },
        {
          "index": "39",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Atwell, Kyle, Portzer, Joshua M., and McCurdy, Daphne. \"Negotiating [Im]plausible Deniability: Strategic Guidelines for U.S. Engagement in Modern Indirect Warfare\". In: PRISM 9.2 (2021). Publisher: Institute for National Strategic Security, National Defense University, pp. 112-121."
        },
        {
          "index": "40",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Feuer, Samantha V. From the Shadows to the Front Page: State Use of Proxies for Cyber Operations. Freeman Spogli Institute for International Studies, Stanford University, 2020."
        },
        {
          "index": "41",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Collier, Jamie. \"Proxy Actors in the Cyber Domain: Implications for State Strategy\". In: St Antony's International Review 13.1 (May 1, 2017), pp. 25-47."
        },
        {
          "index": "42",
          "intext_citation": "[8, 35, 37–42]",
          "preceding_text": "Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability",
          "footnote": "Maurer, Tim. Cyber Proxies and the Crisis in Ukraine. Vol. Cyber war in perspective: Russian aggression against Ukraine, Kenneth Geers (ed.) OCLC: 960393919. NATO Cooperative Cyber Defence Centre of Excellence, 2015."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\"",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "35",
          "intext_citation": "[35]",
          "preceding_text": "³Maurer",
          "footnote": "Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "43",
          "intext_citation": "[43]",
          "preceding_text": "ates may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors",
          "footnote": "Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436."
        },
        {
          "index": "44",
          "intext_citation": "[44]",
          "preceding_text": "Some non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998",
          "footnote": "Denning, Dorothy. \"Cyber Conflict as an Emergent Social Phenomenon\". In: Corporate Hacking and Technology-driven Crime, Thomas J. Holt and Bernadette Hlubik Schell (eds.) IGI Global, Jan. 1, 2011. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "8",
          "intext_citation": "[8]",
          "preceding_text": "e risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors",
          "footnote": "Borghard, Erica D. and Lonergan, Shawn W. “Can States Calculate the Risks of Using Cyber Proxies?” In: *Orbis* 60.3 (Jan. 1, 2016), pp. 395–416. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "45",
          "intext_citation": "[45]",
          "preceding_text": "Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments",
          "footnote": "Segal, Adam. Beware the Patriotic Geek: The Risk of Cyber Militias in Asia. Council on Foreign Relations. Library Catalog: www.cfr.org. Feb. 22, 2012. URL: https://www.cfr.org/blog/beware-patriotic-geek-risk-cyber-militias-asia."
        },
        {
          "index": "35",
          "intext_citation": "[35, 46]",
          "preceding_text": "This logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia",
          "footnote": "Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "46",
          "intext_citation": "[35, 46]",
          "preceding_text": "This logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia",
          "footnote": "Klimburg, Alexander. “Mobilising Cyber Power”. In: *Survival* 53.1 (Feb. 1, 2011). Publisher: Routledge _eprint: https://doi.org/10.1080/00396338.2011.555595, pp. 41–60."
        },
        {
          "index": "25",
          "intext_citation": "[25, 26]",
          "preceding_text": "This logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China",
          "footnote": "Gries, Peter Hays. China’s New Nationalism. First edition. Berkeley Los Angeles London: University of California Press, July 5, 2005. 226 pp."
        },
        {
          "index": "26",
          "intext_citation": "[25, 26]",
          "preceding_text": "This logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China",
          "footnote": "Weiss, Jessica Chen. *Powerful Patriots: Nationalist Protest in China’s Foreign Relations*. 1 edition. New York, NY: Oxford University Press, Sept. 1, 2014. 360 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "40",
          "intext_citation": "[40]",
          "preceding_text": "This logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran",
          "footnote": "Feuer, Samantha V. From the Shadows to the Front Page: State Use of Proxies for Cyber Operations. Freeman Spogli Institute for International Studies, Stanford University, 2020."
        },
        {
          "index": "47",
          "intext_citation": "[47]",
          "preceding_text": "This logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea",
          "footnote": "Trozzo, Eric. The Cyberdimension: A Political Theology of Cyberspace and Cybersecurity. Google-Books-ID: H0i6DwAAQBAJ. Wipf and Stock Publishers, Apr. 29, 2019. 293 pp."
        },
        {
          "index": "45",
          "intext_citation": "[45, 48]",
          "preceding_text": "Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia",
          "footnote": "Segal, Adam. Beware the Patriotic Geek: The Risk of Cyber Militias in Asia. Council on Foreign Relations. Library Catalog: www.cfr.org. Feb. 22, 2012. URL: https://www.cfr.org/blog/beware-patriotic-geek-risk-cyber-militias-asia."
        },
        {
          "index": "48",
          "intext_citation": "[45, 48]",
          "preceding_text": "Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia",
          "footnote": "Ottis, Rain. “From Pitch Forks to Laptops: Volunteers in Cyber Conflicts”. In: *Conference on Cyber Conflict Proceedings* (2010), pp. 97–109."
        },
        {
          "index": "38",
          "intext_citation": "[38, 42, 49–51]",
          "preceding_text": "Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries",
          "footnote": "Schmoldt, Janine. The Rising Power of Cyber Proxies. Vol. Thaddeus Eze (ed.) Google-Books-ID: wCo4EAAAQBAJ. Conferences Proceedings of 20th European Conference on Cyber Warfare and Security, June 24, 2021. 646 pp."
        },
        {
          "index": "42",
          "intext_citation": "[38, 42, 49–51]",
          "preceding_text": "Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries",
          "footnote": "Maurer, Tim. Cyber Proxies and the Crisis in Ukraine. Vol. Cyber war in perspective: Russian aggression against Ukraine, Kenneth Geers (ed.) OCLC: 960393919. NATO Cooperative Cyber Defence Centre of Excellence, 2015."
        },
        {
          "index": "49",
          "intext_citation": "[38, 42, 49–51]",
          "preceding_text": "Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries",
          "footnote": "Pagliery, Jose. Meet the vigilante who’s hacked jihadist websites for years. CNNMoney. Library Catalog: money.cnn.com. Jan. 16, 2015. URL: https://money.cnn.com/2015/01/16/technology/security/jester-hacker-vigilante/index.html."
        },
        {
          "index": "50",
          "intext_citation": "[38, 42, 49–51]",
          "preceding_text": "Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries",
          "footnote": "Thornburgh, Nathan. “The Invasion of the Chinese Cyberspies”. In: *Time* (Aug. 29, 2005)."
        },
        {
          "index": "51",
          "intext_citation": "[38, 42, 49–51]",
          "preceding_text": "Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries",
          "footnote": "Winter, Jana. Patriot hacker 'The Raptor' gains flock of followers after FoxNews.com report. Fox News. Last Modified: 2015-03-26T17:42:51-04:00 Library Catalog: www.foxnews.com Publisher: Fox News. Mar. 26, 2015. URL: https://www.foxnews.com/us/patriot-hacker-the-raptor-gains-flock-of-followers-after-foxnews-com-report."
        },
        {
          "index": "35",
          "intext_citation": "[35, 46]",
          "preceding_text": "On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation",
          "footnote": "Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "46",
          "intext_citation": "[35, 46]",
          "preceding_text": "On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation",
          "footnote": "Klimburg, Alexander. “Mobilising Cyber Power”. In: *Survival* 53.1 (Feb. 1, 2011). Publisher: Routledge _eprint: https://doi.org/10.1080/00396338.2011.555595, pp. 41–60."
        },
        {
          "index": "53",
          "intext_citation": "[53]",
          "preceding_text": "the US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets",
          "footnote": "NIPC Encourages Heightened Cyber Security as Iraq - US Tensions Increase. National Infrastructure Protection Center (NIPC) Advisory 03-002. Feb. 11, 2003. URL: https://www.2600.com/news/mirrors/www.nipc.gov/warnings/advisories/2003/03-002.htm. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "54",
          "intext_citation": "[54–56]",
          "preceding_text": "Scholars of cyber conflict have done excellent work to circumvent data problems in other areas",
          "footnote": "Kostyuk, Nadiya and Zhukov, Yuri M. \"Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\" In: Journal of Conflict Resolution 63.2 (Feb. 1, 2019). Publisher: SAGE Publications Inc, pp. 317-347."
        },
        {
          "index": "55",
          "intext_citation": "[54–56]",
          "preceding_text": "Scholars of cyber conflict have done excellent work to circumvent data problems in other areas",
          "footnote": "Kostyuk, Nadiya. \"Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\". In: International Studies Quarterly (sqab039 May 28, 2021)."
        },
        {
          "index": "56",
          "intext_citation": "[54–56]",
          "preceding_text": "Scholars of cyber conflict have done excellent work to circumvent data problems in other areas",
          "footnote": "Valeriano, Brandon. Cyber War versus Cyber Realities: Cyber Conflict in the International System. 1 edition. Oxford; New York: Oxford University Press, May 26, 2015. 288 pp."
        },
        {
          "index": "56",
          "intext_citation": "[56]",
          "preceding_text": "To illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano",
          "footnote": "Valeriano, Brandon. Cyber War versus Cyber Realities: Cyber Conflict in the International System. 1 edition. Oxford; New York: Oxford University Press, May 26, 2015. 288 pp."
        },
        {
          "index": "5",
          "intext_citation": "[5]",
          "preceding_text": "To illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");",
          "footnote": "Abbott, Kenneth W. *Economic Sanctions and International Terrorism*. SSRN Scholarly Paper ID 1402844. Rochester, NY: Social Science Research Network, 1987."
        },
        {
          "index": "57",
          "intext_citation": "[57]",
          "preceding_text": "lem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\")",
          "footnote": "Tracking State-Sponsored Cyberattacks Around the World. Council on Foreign Relations. 2021. URL: https://www.cfr.org/cyber-operations."
        },
        {
          "index": "6",
          "intext_citation": "[6]",
          "preceding_text": "f observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];",
          "footnote": "Kirchner, Magdalena. “‘A good investment?’ State sponsorship of terrorism as an instrument of Iraqi foreign policy (1979–1991)”. In: *Cambridge Review of International Affairs* 27.3 (July 3, 2014). Publisher: Routledge _eprint: https://doi.org/10.1080/09557571.2013.839629, pp. 521–537."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "l equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "7",
          "intext_citation": "[7]",
          "preceding_text": "s from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.",
          "footnote": "Byman, Daniel and Kreps, Sarah E. “Agents of Destruction? Applying Principal-Agent Analysis to State-Sponsored Terrorism”. In: *International Studies Perspectives* 11.1 (Feb. 1, 2010). Publisher: Oxford Academic, pp. 1–18."
        },
        {
          "index": "57",
          "intext_citation": "[57]",
          "preceding_text": "hree datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR",
          "footnote": "Tracking State-Sponsored Cyberattacks Around the World. Council on Foreign Relations. 2021. URL: https://www.cfr.org/cyber-operations."
        },
        {
          "index": "56",
          "intext_citation": "[56]",
          "preceding_text": ": Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM",
          "footnote": "Valeriano, Brandon. Cyber War versus Cyber Realities: Cyber Conflict in the International System. 1 edition. Oxford; New York: Oxford University Press, May 26, 2015. 288 pp."
        },
        {
          "index": "8",
          "intext_citation": "[8]",
          "preceding_text": "r (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.",
          "footnote": "Borghard, Erica D. and Lonergan, Shawn W. “Can States Calculate the Risks of Using Cyber Proxies?” In: *Orbis* 60.3 (Jan. 1, 2016), pp. 395–416. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "9",
          "intext_citation": "[9]",
          "preceding_text": "e can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.",
          "footnote": "Applegate, Scott. \"Cybermilitias and Political Hackers: Use of Irregular Forces in Cyberwarfare\". In: IEEE Security Privacy 9.5 (Sept. 2011). Conference Name: IEEE Security Privacy, pp. 16–22."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "o include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "10",
          "intext_citation": "[10]",
          "preceding_text": "Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.",
          "footnote": "Poznansky, Michael and Perkoski, Evan. \"Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\". In: Journal of Global Security Studies 3.4 (Oct. 1, 2018), pp. 402–416."
        },
        {
          "index": "11",
          "intext_citation": "[11]",
          "preceding_text": "much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.[10] However, it only tracks proxy relationship onset.",
          "footnote": "Brown, Joseph M. and Fazal, Tanisha M. “#SorryNotSorry: Why states neither confirm nor deny responsibility for cyber operations”. In: European Journal of International Security (Aug. 28, 2021). Publisher: Cambridge University Press, pp. 1–17."
        },
        {
          "index": "33",
          "intext_citation": "[33, 57, 58]",
          "preceding_text": "Figure 1: Comparisons of trends over time from three datasets",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "57",
          "intext_citation": "[33, 57, 58]",
          "preceding_text": "Figure 1: Comparisons of trends over time from three datasets",
          "footnote": "Tracking State-Sponsored Cyberattacks Around the World. Council on Foreign Relations. 2021. URL: https://www.cfr.org/cyber-operations."
        },
        {
          "index": "58",
          "intext_citation": "[33, 57, 58]",
          "preceding_text": "Figure 1: Comparisons of trends over time from three datasets",
          "footnote": "Valeriano, Brandon, Jensen, Benjamin, and Maness, Ryan C. Cyber Strategy: The Evolving Character of Power and Coercion. New York, NY: Oxford University Press, May 15, 2018. 320 pp."
        },
        {
          "index": "12",
          "intext_citation": "[12]",
          "preceding_text": "Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction.",
          "footnote": "Baliga, Sandeep, Mesquita, Ethan Bueno de, and Wolitzky, Alexander. \"Deterrence with Imperfect Attribution\". In: American Political Science Review (2020)."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "These trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "¹³ Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "59",
          "intext_citation": "[59, 60]",
          "preceding_text": "In the early days of cyber conflict, attack attribution",
          "footnote": "Franklin Kramer, Stuart H. Starr, and Larry Wentz, eds. Cyberpower and National Security. 1 edition. Washington, D.C: Potomac Books, Apr. 1, 2009. 664 pp."
        },
        {
          "index": "60",
          "intext_citation": "[59, 60]",
          "preceding_text": "In the early days of cyber conflict, attack attribution",
          "footnote": "Libicki, Martin C. Cyberdeterrence and Cyberwar. Google-Books-ID: MJX6jL6IeF0C. Rand Corporation, Sept. 22, 2009. 239 pp."
        },
        {
          "index": "61",
          "intext_citation": "[61]",
          "preceding_text": "In the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its \"most difficult problem\"",
          "footnote": "Betz, David and Stevens, Tim. Techniques for Cyber Attack Attribution. Institute for Defense Analyses, 2003. 82 pp."
        },
        {
          "index": "62",
          "intext_citation": "[62, 63]",
          "preceding_text": "The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic",
          "footnote": "Landau, Susan and Lubin, Asaf. \"Examining the Anomalies, Explaining the Value: Should the USA Freedom Act's Metadata Program Be Extended?\" In: Harvard National Security Journal 11.3 (2020), pp. 308-358."
        },
        {
          "index": "63",
          "intext_citation": "[62, 63]",
          "preceding_text": "The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic",
          "footnote": "Lin, Herbert. \"Attribution of Malicious Cyber Incidents: From Soup to Nuts\". In: Journal of International Affairs 70.1 (2016). Publisher: Journal of International Affairs Editorial Board, pp. 75-137. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "12",
          "intext_citation": "[12, 13, 64]",
          "preceding_text": "It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible",
          "footnote": "Baliga, Sandeep, Mesquita, Ethan Bueno de, and Wolitzky, Alexander. \"Deterrence with Imperfect Attribution\". In: American Political Science Review (2020)."
        },
        {
          "index": "13",
          "intext_citation": "[12, 13, 64]",
          "preceding_text": "It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "64",
          "intext_citation": "[12, 13, 64]",
          "preceding_text": "It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible",
          "footnote": "Rid, Thomas and Buchanan, Ben. “Attributing Cyber Attacks”. In: Journal of Strategic Studies 38.1 (Jan. 2, 2015). Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2014.977382, pp. 4–37."
        },
        {
          "index": "65",
          "intext_citation": "[65]",
          "preceding_text": "Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns",
          "footnote": "Canfil, Justin Key. Intelligence and Adversaries: What Do We Know? New York NY: Cyber Conflict Studies Association (CCSA), 2016."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "66",
          "intext_citation": "[66]",
          "preceding_text": "States are often sensitive about divulging how they know what they know",
          "footnote": "Carnegie, Allison and Carson, Austin. “The Disclosure Dilemma: Nuclear Intelligence and International Organizations”. In: American Journal of Political Science 63.2 (2019). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12426, pp. 269–285."
        },
        {
          "index": "36",
          "intext_citation": "[36, 67]",
          "preceding_text": "a direct command role can be held responsible for the actions of their proxies",
          "footnote": "Damrosch, Lori and Murphy, Sean. International Law. 6 edition. St. Paul, MN: West Academic Publishing, July 8, 2014. 1250 pp."
        },
        {
          "index": "67",
          "intext_citation": "[36, 67]",
          "preceding_text": "a direct command role can be held responsible for the actions of their proxies",
          "footnote": "Murphy, Sean D. Principles of International Law. Thomson/West, 2012. 575 pp."
        },
        {
          "index": "35",
          "intext_citation": "[35]",
          "preceding_text": "These barriers are what make outsourcing so attractive, according to conventional wisdom",
          "footnote": "Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "33",
          "intext_citation": "[33, 68]",
          "preceding_text": "But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "68",
          "intext_citation": "[33, 68]",
          "preceding_text": "But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal",
          "footnote": "Canfil, Justin Key. “A Framework for Assessing Foreign State Complicity: A Framework for Assessing Foreign State Complicity”. In: Journal of International Affairs 70.1 (2016). Publisher: Journal of International Affairs Editorial Board, pp. 217–226."
        },
        {
          "index": "33",
          "intext_citation": "[33, 69]",
          "preceding_text": "35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "69",
          "intext_citation": "[33, 69]",
          "preceding_text": "35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers",
          "footnote": "Weber, Valentin. “States and Their Proxies in Cyber Operations”. In: Lawfare (May 15, 2018)."
        },
        {
          "index": "55",
          "intext_citation": "[55]",
          "preceding_text": "Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions",
          "footnote": "Kostyuk, Nadiya. \"Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\". In: International Studies Quarterly (sqab039 May 28, 2021)."
        },
        {
          "index": "71",
          "intext_citation": "[71]",
          "preceding_text": "Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal",
          "footnote": "Segal, Adam. The Hacked World Order: How Nations Fight, Trade, Maneuver, and Manipulate in the Digital Age. 1 edition. New York: PublicAffairs, Feb. 23, 2016. 320 pp."
        },
        {
          "index": "28",
          "intext_citation": "[28]",
          "preceding_text": "From 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support",
          "footnote": "Mulvenon, James C. et al. Chinese Responses to U.S. Military Transformation and Implications for the Department of Defense. Google-Books-ID: zHwnDNZNmdUC. Rand Corporation, Apr. 5, 2006. 187 pp."
        },
        {
          "index": "72",
          "intext_citation": "[72]",
          "preceding_text": "Despite rising online nationalism in China",
          "footnote": "Wu, Xu. Chinese Cyber Nationalism: Evolution, Characteristics, and Implications: Evolution, Characteristics, and Implications. Lexington Books, Sept. 26, 2007. 280 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "24",
          "intext_citation": "[24]",
          "preceding_text": "Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000",
          "footnote": "Singer, P. W. and Friedman, Allan. Cybersecurity and Cyberwar: What Everyone Needs to Know®. Google-Books-ID: B88ZAgAAQBAJ. Oxford University Press, Dec. 4, 2013. 836 pp."
        },
        {
          "index": "73",
          "intext_citation": "[73]",
          "preceding_text": "For example, Hang",
          "footnote": "Hang, Ryan. Freedom for Authoritarianism: Patriotic Hackers and Chinese Nationalism. The Yale Review of International Studies. Library Catalog: yris.yira.org. Oct. 12, 2014. URL: http://yris.yira.org/essays/1447."
        },
        {
          "index": "75",
          "intext_citation": "[75]",
          "preceding_text": "r's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets",
          "footnote": "Fletcher, Owen. *Patriotic Chinese Hacking Group Reboots*. WSJ. ISSN: 0099-9660 Library Catalog: blogs.wsj.com Section: World. Oct. 5, 2011. URL: https://blogs.wsj.com/chinarealtime/2011/10/05/patriotic-chinese-hacking-group-reboots/."
        },
        {
          "index": "35",
          "intext_citation": "[35, 71]",
          "preceding_text": "Since then, the Chinese government has relied more on specialized units at the Ministry of State Security",
          "footnote": "Maurer, Tim. Cyber Mercenaries: The State, Hackers, and Power. Cambridge New York, NY: Port Melbourne New Delhi Singapore: Cambridge University Press, Jan. 18, 2018. 268 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "71",
          "intext_citation": "[35, 71]",
          "preceding_text": "Since then, the Chinese government has relied more on specialized units at the Ministry of State Security",
          "footnote": "Segal, Adam. The Hacked World Order: How Nations Fight, Trade, Maneuver, and Manipulate in the Digital Age. 1 edition. New York: PublicAffairs, Feb. 23, 2016. 320 pp."
        },
        {
          "index": "76",
          "intext_citation": "[76]",
          "preceding_text": "originating from that country reveal a more direct government hand",
          "footnote": "Newman, Lily Hay. \"China Escalates Hacks Against the US as Trade Tensions Rise\". In: Wired (June 22, 2018)."
        },
        {
          "index": "12",
          "intext_citation": "[12, 13, 77, 78]",
          "preceding_text": "Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect",
          "footnote": "Baliga, Sandeep, Mesquita, Ethan Bueno de, and Wolitzky, Alexander. \"Deterrence with Imperfect Attribution\". In: American Political Science Review (2020)."
        },
        {
          "index": "13",
          "intext_citation": "[12, 13, 77, 78]",
          "preceding_text": "Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "77",
          "intext_citation": "[12, 13, 77, 78]",
          "preceding_text": "Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect",
          "footnote": "Egloff, Florian J. and Smeets, Max. \"Publicly attributing cyber attacks: a framework\". In: Journal of Strategic Studies 0.0 (Mar. 10, 2021). Publisher: Routledge _eprint: https://doi.org/10.1080/01402390.2021.1895117, pp. 1-32."
        },
        {
          "index": "78",
          "intext_citation": "[12, 13, 77, 78]",
          "preceding_text": "Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect",
          "footnote": "Egloff, Florian J. \"Public attribution of cyber intrusions\". In: Journal of Cybersecurity 6.1 (Jan. 1, 2020)."
        },
        {
          "index": "43",
          "intext_citation": "[43]",
          "preceding_text": "In particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts",
          "footnote": "Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436."
        },
        {
          "index": "79",
          "intext_citation": "[79]",
          "preceding_text": "rts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment",
          "footnote": "DOJ Press Release: U.S. Charges Five Chinese Military Hackers for Cyber Espionage Against U.S. Corporations and a Labor Organization for Commercial Advantage. Department of Justice Office of Public Affairs, May 19, 2014."
        },
        {
          "index": "80",
          "intext_citation": "[80]",
          "preceding_text": "Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices",
          "footnote": "Berghel, Hal. \"The Equifax Hack Revisited and Repurposed\". In: Computer 53.5 (May 1, 2020). Publisher: IEEE Computer Society, pp. 85-90."
        },
        {
          "index": "79",
          "intext_citation": "[79]",
          "preceding_text": "–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable”",
          "footnote": "DOJ Press Release: U.S. Charges Five Chinese Military Hackers for Cyber Espionage Against U.S. Corporations and a Labor Organization for Commercial Advantage. Department of Justice Office of Public Affairs, May 19, 2014."
        },
        {
          "index": "43",
          "intext_citation": "[43]",
          "preceding_text": "It is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.”¹⁶ In a separate piece, Carlin",
          "footnote": "Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436."
        },
        {
          "index": "43",
          "intext_citation": "[43]",
          "preceding_text": "Carlin",
          "footnote": "Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436."
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "43",
          "intext_citation": "[43]",
          "preceding_text": "DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin",
          "footnote": "Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436."
        },
        {
          "index": "85",
          "intext_citation": "[85–87]",
          "preceding_text": "But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement",
          "footnote": "Nakashima, Ellen and Lynch, David J. U. S. charges Chinese hackers in alleged theft of vast trove of confidential data in 12 countries. Washington Post. Dec. 21, 2018. URL: https://www.washingtonpost.com/world/national-security/us-and-more-than-a-dozen-allies-to-condemn-china-for-economic-espionage/2018/12/20/cdfd0338-0455-11e9-b5df-5d3874f1ac36_story.html."
        },
        {
          "index": "86",
          "intext_citation": "[85–87]",
          "preceding_text": "But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement",
          "footnote": "Harknett, Richard and Fischerkeller, Michael. Persistent Engagement and Tacit Bargaining: A Path Toward Constructing Norms in Cyberspace. Lawfare. Nov. 9, 2018. URL: https://www.lawfareblog.com/persistent-engagement-and-tacit-bargaining-path-toward-constructing-norms-cyberspace."
        },
        {
          "index": "87",
          "intext_citation": "[85–87]",
          "preceding_text": "But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement",
          "footnote": "Miller, James N. and Pollard, Neal A. Persistent Engagement, Agreed Competition and Deterrence in Cyberspace. Lawfare. Apr. 30, 2019. URL: https://www.lawfareblog.com/persistent-engagement-agreed-competition-and-deterrence-cyberspace."
        },
        {
          "index": "43",
          "intext_citation": "[43]",
          "preceding_text": "¹⁷ “The most sophisticated threats we investigate are associated with nation-state actors or their proxies”",
          "footnote": "Carlin, John P. \"Detect, Disrupt, Deter: A Whole-of-Government Approach to National Security Cyber Threats\". In: Harvard National Security Journal 7.2 (2015), pp. 391-436."
        },
        {
          "index": "89",
          "intext_citation": "[89]",
          "preceding_text": "Where once victim states like the US exhibited “restrained responses”",
          "footnote": "Kaminska, Monica. \"Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks\". In: Journal of Cybersecurity 7.1 (Jan. 1, 2021), tyab008. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "90",
          "intext_citation": "[90]",
          "preceding_text": "proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate",
          "footnote": "Egloff, Florian J and Dunn Cavelty, Myriam. \"Attribution and Knowledge Creation Assemblages in Cybersecurity Politics\". In: Journal of Cybersecurity 7.1 (Jan. 1, 2021), tyab002."
        },
        {
          "index": "89",
          "intext_citation": "[89]",
          "preceding_text": "¹⁸ Note that Kaminska",
          "footnote": "Kaminska, Monica. \"Restraint under conditions of uncertainty: Why the United States tolerates cyberattacks\". In: Journal of Cybersecurity 7.1 (Jan. 1, 2021), tyab008. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "12",
          "intext_citation": "[12]",
          "preceding_text": "Following Baliga, Mesquita, and Wolitzky",
          "footnote": "Baliga, Sandeep, Mesquita, Ethan Bueno de, and Wolitzky, Alexander. \"Deterrence with Imperfect Attribution\". In: American Political Science Review (2020)."
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "Following Baliga, Mesquita, and Wolitzky [12], Lindsay",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "91",
          "intext_citation": "[91]",
          "preceding_text": "Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev",
          "footnote": "Axelrod, Robert and Iliev, Rumen. \"Timing of cyber conflict\". In: Proceedings of the National Academy of Sciences 111.4 (Jan. 28, 2014). Publisher: National Academy of Sciences Section: Physical Sciences, pp. 1298–1303."
        },
        {
          "index": "92",
          "intext_citation": "[92]",
          "preceding_text": "Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes",
          "footnote": "Gailmard, Sean and Patty, John W. “Preventing Prevention”. In: American Journal of Political Science 63.2 (2019). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12411, pp. 342–352."
        },
        {
          "index": "8",
          "intext_citation": "[8]",
          "preceding_text": "In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship",
          "footnote": "Borghard, Erica D. and Lonergan, Shawn W. “Can States Calculate the Risks of Using Cyber Proxies?” In: *Orbis* 60.3 (Jan. 1, 2016), pp. 395–416. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "1",
          "intext_citation": "[0,1]$",
          "preceding_text": "Define this decision as $\\varphi \\in",
          "footnote": "Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46."
        },
        {
          "index": "1",
          "intext_citation": "[0,1]",
          "preceding_text": "|  φ | Extent of outsourcing strategy | ∈",
          "footnote": "Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46."
        },
        {
          "index": "1",
          "intext_citation": "[0,1]",
          "preceding_text": "|  ψ | Operational sophistication (probability of success) | ∈",
          "footnote": "Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46."
        },
        {
          "index": "1",
          "intext_citation": "[0,1]",
          "preceding_text": "|  τ | Target’s ability to attribute (technical attrib.) | ∈",
          "footnote": "Mumford, Andrew. “Proxy Warfare and the Future of Conflict”. In: *The RUSI Journal* 158.2 (Apr. 1, 2013). Publisher: Routledge _eprint: https://doi.org/10.1080/03071847.2013.787733, pp. 40–46."
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "a$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal.²¹ Like the model employed by Lindsay",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "cing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "55",
          "intext_citation": "[55]",
          "preceding_text": "Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions",
          "footnote": "Kostyuk, Nadiya. \"Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\". In: International Studies Quarterly (sqab039 May 28, 2021)."
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "Pursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay",
          "footnote": "Lindsay, Jon R. \"Tipping the scales: the attribution problem and the feasibility of deterrence against cyberattack\". In: Journal of Cybersecurity 1.1 (Sept. 1, 2015). Publisher: Oxford Academic, pp. 53–67."
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "Akoto",
          "footnote": "Akoto, William. \"Accountability and cyber conflict: examining institutional constraints on the use of cyber proxies\". In: Conflict Management and Peace Science (Nov. 15, 2021). Publisher: SAGE Publications Ltd, p. 07388942211051264."
        },
        {
          "index": "23",
          "intext_citation": "[23]",
          "preceding_text": "In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.",
          "footnote": "Conrad, Justin. “Interstate Rivalry and Terrorism: An Unprobed Link”. In: Journal of Conflict Resolution 55.4 (Aug. 1, 2011). Publisher: SAGE Publications Inc, pp. 529–555."
        },
        {
          "index": "99",
          "intext_citation": "[99]",
          "preceding_text": "For information on victim responses, I rely on Hinck and Maurer",
          "footnote": "Hinck, Garrett and Maurer, Tim. \"Persistent Enforcement: Criminal Charges as a Response to Nation-State Malicious Cyber Activity\". In: *Journal of National Security Law and Policy* 10.3 (2019), pp. 525–562."
        },
        {
          "index": "99",
          "intext_citation": "[99]",
          "preceding_text": "The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer",
          "footnote": "Hinck, Garrett and Maurer, Tim. \"Persistent Enforcement: Criminal Charges as a Response to Nation-State Malicious Cyber Activity\". In: *Journal of National Security Law and Policy* 10.3 (2019), pp. 525–562."
        },
        {
          "index": "100",
          "intext_citation": "[100]",
          "preceding_text": "Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive",
          "footnote": "Gomez, Miguel Alberto and Whyte, Christopher. \"Unpacking Strategic Behavior in Cyberspace: A Schema-Driven Approach\". In: *Journal of Cybersecurity* (2022). forthcoming, pp. 1–16."
        },
        {
          "index": "101",
          "intext_citation": "[101]",
          "preceding_text": "The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014",
          "footnote": "Franceschi-Bicchierai, Lorenzo. *Chinese Cybersecurity Company Doxes Apparent NSA Hacking Operation*. Vice. Feb. 23, 2022. URL: https://www.vice.com/en/article/v7dxg3/chinese-cybersecurity-company-doxes-apparent-nsa-hacking-operation."
        },
        {
          "index": "99",
          "intext_citation": "[99]",
          "preceding_text": "²⁶ It stands to reason that, if anything, the Hinck and Maurer",
          "footnote": "Hinck, Garrett and Maurer, Tim. \"Persistent Enforcement: Criminal Charges as a Response to Nation-State Malicious Cyber Activity\". In: *Journal of National Security Law and Policy* 10.3 (2019), pp. 525–562."
        },
        {
          "index": "102",
          "intext_citation": "[102]",
          "preceding_text": "²⁸ Recent research has strongly recommended one-way fixed effects models over two-way specifications",
          "footnote": "Kropko, Jonathan and Kubinec, Robert. \"Interpretation and identification of within-unit and cross-sectional variation in panel data models\". In: *PLOS ONE* 15.4 (Apr. 21, 2020). Publisher: Public Library of Science, e0231349."
        },
        {
          "index": "103",
          "intext_citation": "[103]",
          "preceding_text": "Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise)",
          "footnote": "Hanson, Bruce E. “A Modern Gauss-Markov Theorem”. In: *Econometrica* (Dec. 1, 2021)."
        },
        {
          "index": "104",
          "intext_citation": "[104]",
          "preceding_text": "The difficulty in making substantive comparisons between units is a principal downside of fixed effects",
          "footnote": "Mummolo, Jonathan and Peterson, Erik. \"Improving the Interpretation of Fixed Effects Regression Results\". In: *Political Science Research and Methods* 6.4 (Oct. 2018). Publisher: Cambridge University Press, pp. 829–835."
        },
        {
          "index": "104",
          "intext_citation": "[104]",
          "preceding_text": "Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\"",
          "footnote": "Mummolo, Jonathan and Peterson, Erik. \"Improving the Interpretation of Fixed Effects Regression Results\". In: *Political Science Research and Methods* 6.4 (Oct. 2018). Publisher: Cambridge University Press, pp. 829–835."
        },
        {
          "index": "105",
          "intext_citation": "[105]",
          "preceding_text": "The US is far from the only cyber victim, but it is among the most vocal",
          "footnote": "Healey, Jason. *China Is a Cyber Victim, Too*. Foreign Policy. Apr. 16, 2013. URL: https://foreignpolicy.com/2013/04/16/china-is-a-cyber-victim-too/."
        },
        {
          "index": "106",
          "intext_citation": "[106–109]",
          "preceding_text": "Scholars have long been interested in the conditions under which new cyber norms can emerge and proliferate",
          "footnote": "Hollis, Duncan B. *Why States Need an International Law for Information Operations*. SSRN Scholarly Paper ID 1083889. Rochester, NY: Social Science Research Network, Jan. 17, 2008. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "107",
          "intext_citation": "[106–109]",
          "preceding_text": "Scholars have long been interested in the conditions under which new cyber norms can emerge and proliferate",
          "footnote": "Healey, Jason and Maurer, Tim. \"What it'll take to forge peace in cyberspace\". In: Christian Science Monitor (Mar. 20, 2017)."
        },
        {
          "index": "108",
          "intext_citation": "[106–109]",
          "preceding_text": "Scholars have long been interested in the conditions under which new cyber norms can emerge and proliferate",
          "footnote": "Finnemore, Martha and Hollis, Duncan B. \"Constructing Norms for Global Cybersecurity\". In: American Journal of International Law 110.3 (July 2016). Publisher: Cambridge University Press, pp. 425–479."
        },
        {
          "index": "109",
          "intext_citation": "[106–109]",
          "preceding_text": "Scholars have long been interested in the conditions under which new cyber norms can emerge and proliferate",
          "footnote": "Maurer, Tim. \"Cyber Norm Emergence at the United Nations—An Analysis of the UN's Activities Regarding Cyber-security\". In: Science, Technology, and Public Policy Program, Belfer Center (2011)."
        },
        {
          "index": "110",
          "intext_citation": "[110, 111]",
          "preceding_text": "states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible",
          "footnote": "Hare, Forrest B. \"Privateering in Cyberspace: Should Patriotic Hacking Be Promoted as National Policy?\" In: *Asian Security* 15.2 (May 4, 2019). Publisher: Routledge _eprint: https://doi.org/10.1080/14799855.2017.1414803, pp. 93–102."
        },
        {
          "index": "111",
          "intext_citation": "[110, 111]",
          "preceding_text": "states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible",
          "footnote": "Egloff, Florian J. \"Cybersecurity and non-state actors: a historical analogy with mercantile companies, privateers, and pirates\". http://purl.org/dc/dcmitype/Text. University of Oxford, 2018."
        },
        {
          "index": "20",
          "intext_citation": "[20]",
          "preceding_text": "In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage",
          "footnote": "Salehyan, Idean, Gleditsch, Kristian Skrede, and Cunningham, David E. “Explaining External Support for Insurgent Groups”. In: International Organization 65.4 (2011). Publisher: [MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 709–744."
        },
        {
          "index": "112",
          "intext_citation": "[112]",
          "preceding_text": "In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts",
          "footnote": "Sandler, Todd and Siqueira, Kevin. \"Global terrorism: deterrence versus pre-emption\". In: Canadian Journal of Economics/Revue canadienne d'économique 39.4 (2006). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-5982.2006.00393.x, pp. 1370–1387."
        },
        {
          "index": "56",
          "intext_citation": "[56, 58]",
          "preceding_text": "Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway",
          "footnote": "Valeriano, Brandon. Cyber War versus Cyber Realities: Cyber Conflict in the International System. 1 edition. Oxford; New York: Oxford University Press, May 26, 2015. 288 pp."
        },
        {
          "index": "58",
          "intext_citation": "[56, 58]",
          "preceding_text": "Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway",
          "footnote": "Valeriano, Brandon, Jensen, Benjamin, and Maness, Ryan C. Cyber Strategy: The Evolving Character of Power and Coercion. New York, NY: Oxford University Press, May 15, 2018. 320 pp."
        },
        {
          "index": "73",
          "intext_citation": "[73, 113, 114]",
          "preceding_text": "If not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion",
          "footnote": "Hang, Ryan. Freedom for Authoritarianism: Patriotic Hackers and Chinese Nationalism. The Yale Review of International Studies. Library Catalog: yris.yira.org. Oct. 12, 2014. URL: http://yris.yira.org/essays/1447."
        },
        {
          "index": "113",
          "intext_citation": "[73, 113, 114]",
          "preceding_text": "If not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion",
          "footnote": "Crosston, Matthew. \"Virtual Patriots and a New American Cyber Strategy: Changing the Zero-Sum Game\". In: Strategic Studies Quarterly 6.4 (2012). Publisher: Air University Press, pp. 100–118."
        },
        {
          "index": "114",
          "intext_citation": "[73, 113, 114]",
          "preceding_text": "If not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion",
          "footnote": "MacKinnon, Rebecca. \"China's Networked Authoritarianism\". In: \"Journal of Democracy 22.2 (2011), pp. 32–46. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "26",
          "intext_citation": "[26, 115]",
          "preceding_text": "It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes",
          "footnote": "Weiss, Jessica Chen. *Powerful Patriots: Nationalist Protest in China’s Foreign Relations*. 1 edition. New York, NY: Oxford University Press, Sept. 1, 2014. 360 pp. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "115",
          "intext_citation": "[26, 115]",
          "preceding_text": "It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes",
          "footnote": "Hjortdal, Magnus. “China’s Use of Cyber Warfare: Espionage Meets Strategic Deterrence”. In: *Journal of Strategic Security* 4.2 (2011). Publisher: University of South Florida Board of Trustees, pp. 1–24."
        },
        {
          "index": "93",
          "intext_citation": "[93]",
          "preceding_text": "25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives",
          "footnote": "Byman, Daniel et al. \"Iraq, Afghanistan and the War on Terror\". In: Middle East Policy 12.1 (2005). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1061-1924.2005.00183.x, pp. 1–24."
        },
        {
          "index": "20",
          "intext_citation": "[20, 116]",
          "preceding_text": "When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own",
          "footnote": "Salehyan, Idean, Gleditsch, Kristian Skrede, and Cunningham, David E. “Explaining External Support for Insurgent Groups”. In: International Organization 65.4 (2011). Publisher: [MIT Press, University of Wisconsin Press, Cambridge University Press, International Organization Foundation], pp. 709–744."
        },
        {
          "index": "116",
          "intext_citation": "[20, 116]",
          "preceding_text": "When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own",
          "footnote": "Freeman, Michael. “The Sources of Terrorist Financing: Theory and Typology”. In: *Studies in Conflict &amp; Terrorism* 34.6 (June 1, 2011). Publisher: Routledge _eprint: https://doi.org/10.1080/1057610X.2011.571193, pp. 461–475."
        },
        {
          "index": "117",
          "intext_citation": "[117]",
          "preceding_text": "In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals",
          "footnote": "DeVore, Marc R. “Exploring the Iran-Hezbollah Relationship: A Case Study of how State Sponsorship affects Terrorist Group Decision-Making”. In: *Perspectives on Terrorism* 6.4 (2012). Publisher: Terrorism Research Institute, pp. 85–107."
        },
        {
          "index": "118",
          "intext_citation": "[118]",
          "preceding_text": "Herr, Laudrain, and Smeets",
          "footnote": "Herr, Trey, Laudrain, Arthur P. B., and Smeets, Max. “Mapping the Known Unknowns of Cybersecurity Education: A Review of Syllabi on Cyber Conflict and Security”. In: *Journal of Political Science Education* 0.0 (Feb. 28, 2020). Publisher: Routledge _eprint: https://doi.org/10.1080/15512169.2020.1729166, pp. 1–17."
        },
        {
          "index": "119",
          "intext_citation": "[119]",
          "preceding_text": "Herr, Laudrain, and Smeets [118], Gorwa and Smeets",
          "footnote": "Gorwa, Robert and Smeets, Max. *Cyber Conflict in Political Science: A Review of Methods and Literature*. 2019 ISA Working Paper. July 25, 2019. Electronic copy available at: https://ssrn.com/abstract=3611582"
        },
        {
          "index": "119",
          "intext_citation": "[119]",
          "preceding_text": "Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance",
          "footnote": "Gorwa, Robert and Smeets, Max. *Cyber Conflict in Political Science: A Review of Methods and Literature*. 2019 ISA Working Paper. July 25, 2019. Electronic copy available at: https://ssrn.com/abstract=3611582"
        }
      ],
      "flat_text": "# Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay\nJustin Key Canfil\nJune 20, 2020\n## Abstract\nIt is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict.\nWord Count: 12,500\nKeywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” . But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement . By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage  to armed escalation . This logic is widely assumed to hold in cyberspace, as well . And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.\nHow have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit , undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself . Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution , attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.\nScholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich  argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give\nElectronic copy available at: https://ssrn.com/abstract=3611582\nit even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos  and Vaynman  have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich  explain, “we live in an era of implausible deniability.”\nIn this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict .\nThe proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in\nElectronic copy available at: https://ssrn.com/abstract=3611582\nresponse to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.\nThat is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war . Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" . By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.\n# 1 Cyber Proxies: What We Know\nWhether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident . Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year . Even the world's most notorious cyber conflict “wake-up call” , the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization . Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors .\n¹Long ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft . Scholars have found that a majority of rebel groups since 1945 receive tacit state support  and this support has made these groups more powerful and influential . They are observed most often between great power dyads , presumably because the risks associated with direct action are higher when targets can strike back.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nBut states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives . As Akoto  explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.”² I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.\nThis of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey  identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer  distills this into three core managerial strategies: delegating, funding, tacitly permitting.³ More recent work by Florian Egloff  refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible .\nDetection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability . Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.\n²Proxies \"may or may not be part of state security and intelligence agencies and may be criminal syndicates or private cybersecurity companies ... Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\" .\n³Maurer  writes that state sponsors can actively fund or otherwise support non-state cyber actors with the expectation that these actors will accomplish some military, intelligence, or foreign policy objective on behalf of the state (what Maurer terms “orchestrating”). Alternatively, sponsors can simply permit offensive operations by non-state actors by turning a blind eye (“sanctioning”). At the opposite end, a sponsor can establish effective in-house command and control over the group (“delegating”).\nElectronic copy available at: https://ssrn.com/abstract=3611582\nVictim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors . If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.\nSome non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998 . Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors . Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments  to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy's fidelity, and plausible deniability is strengthened.\nThis logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia , China , Iran , and North Korea  – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia , and (allegedly) employed by several Western countries . On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation . Between 9/11 and the start of the Iraq War, for example, when US nationalism soared,\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthe US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets . On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.\nSo just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-$n$ datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto  explains, these data limitations have “crippled efforts to study … cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.\nThe third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.\nFor researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas , but for this reason the study of cyber proxies faces a special set of challenges.\n## 1.1 Observational Equivalence in Existing Data\nThe crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing\nElectronic copy available at: https://ssrn.com/abstract=3611582\ndoesn't convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.\nTo illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano 's Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\"); the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") ; and Akoto 's dataset on cyber proxy onset. CFR  and VJM  track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.\nOne reasonable expectation might be that states are likelier to delegate certain tasks to proxies – for example, less sophisticated or less sensitive operations. We can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies. A third dataset by Akoto  contains an extensive survey of known proxy groups. However, it only tracks proxy relationship onset. As a strictly cumulative measure, it cannot be used to measure whether outsourcing has declined. Instead, we can use it to observe the rate at which states have continued to outsource to new groups in recent years.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 1: Comparisons of trends over time from three datasets . The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade.\nFigure 1 compares observations from all three datasets. The  $Y$ -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction. Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nWe can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.\nThese trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto  explains that in order for the onset of a proxy relationship to appear in the dataset, \"there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government\" (emphasis mine). Akoto  continues: \"It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.\"¹³ Data collection is scoped on proxies which are already known to work for the state. Conclusion in the dataset is therefore inversely related the plausibility of a sponsor's deniability.\nWhat this means is that the large-$n$ information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.\nDirect measurements of outsourcing in available data cannot distinguish between these\n¹³ Akoto  also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].\nElectronic copy available at: https://ssrn.com/abstract=3611582\ncompeting accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn't plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.\n## 2 The Illogic of Plausible Deniability\nIt has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true.\nIn the early days of cyber conflict, attack attribution  was widely regarded as its \"most difficult problem\" . The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic . Attribution may be onerous and complicated, but it is technically possible . Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns .\nEven if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose . States are often sensitive about divulging how they know what they know . Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on\nElectronic copy available at: https://ssrn.com/abstract=3611582\na direct command role can be held responsible for the actions of their proxies .¹⁴\nThese barriers are what make outsourcing so attractive, according to conventional wisdom . But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal ? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers . A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions , and in 2016 Segal  described plans to adopt a model reminiscent of US Cyber Command.\nFrom 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support . Despite rising online nationalism in China  and an army of cyber privateers that once purportedly numbered almost 200,000 , however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang  catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets . Since then, the Chinese government has relied more on specialized units at the Ministry of State Security . Attacks\n¹⁴The International Law Commission (ILC)'s 2001 Draft Articles is perhaps the clearest articulation of the law on state responsibility (though often cited, it is actually a nonbinding source). In the ILC's view, a host state can only be held responsible if it directly conducts or oversees the offending operation at the operational level (see International Law Commission (ILC) Draft Articles on State Responsibility, 2001, http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf). International courts have held variously that the relationship must be one of \"effective control\" (Nicaragua v. United States), \"overall control\" plus the commission of specific acts (Prosecutor v. Dusko Tadic (1999)), or \"complete dependence\" (Bosnia and Herzegovina v. Serbia and Montenegro (1996)) – all very strict standards that elide the possibility of measures short of command or operational involvement. And in more than 4,700 claims proceedings, all but one tribunal (Dames &amp; Moore v. Iran) found that the burden of proof for wrongdoing rests with the defender (see Iran Claims Tribunal, https://www.state.gov/iran-u-s-claims-tribunal/).\nElectronic copy available at: https://ssrn.com/abstract=3611582\noriginating from that country reveal a more direct government hand .¹⁵ If proxies pay for the reasons we usually suspect, then this behavior is puzzling.\nRarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect . Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.\nIn particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts . In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment . Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices  – a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” .\n¹⁵ For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nIt is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.”¹⁶ In a separate piece, Carlin  explains that the Criminal and National Security Divisions at DOJ \"increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases),\" including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.¹⁷\nThis level of cooperation gives the government specially enhanced attribution capabilities. Carlin  describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are” [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak .\nEspecially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin  admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: \"the government must demonstrate, among other things, that the ‘target ... is a foreign power or an agent of a foreign power’” if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.\nIndictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement . To my knowledge, there is no institutional\n¹⁶ [for a detailed exposition in this journal, see 78].\n¹⁷ “The most sophisticated threats we investigate are associated with nation-state actors or their proxies” .\nElectronic copy available at: https://ssrn.com/abstract=3611582\nrequirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” , they now seem more willing to punish sponsors for the activities of their proxies.¹⁸\nAfter all, why wouldn't victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate . States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.\nRaising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.\n## 2.1 A Model of Outsourcing\nHow can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology\n¹⁸ Note that Kaminska ’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nfor checking and comparing a theory's internal validity this way. Following Baliga, Mesquita, and Wolitzky , Lindsay , and Axelrod and Iliev , I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work \"under the hood\" in cases where data are questionable or unavailable.\nEvery theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large- $n$  data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes .\nIn the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims' beliefs and the level of investment. Under this framework, the sponsor's deniability is a function of its involvement and the target state's independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.\nThe model shows how a sponsor's concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthis holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship . The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability's role in decisions about whether to outsource.\n## 2.2 Model setup\nA host government $(G)$ oversees a pool of non-state hackers $(H)$. The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as $\\varphi \\in , where $\\varphi &gt; 0$ is some positive degree of outsourcing. One can imagine that low levels of $\\varphi$ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at $\\varphi = 0$, for instance by implementing and enforcing laws against hacking foreign targets. In the game, $G$'s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.\nThe government's return on investment is given as $\\hat{u} x$, where $x$ is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker's level of sophistication, $\\psi_{i}$. The probability of a successful campaign is $\\psi_{i}$. I assume that individual operations are scalable, and thus the government obtains either full benefit $\\hat{u} x$ from a successful campaign $(\\psi = 1)$ or no benefit at all $(1 - \\psi)$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nConsistent with default explanations, $G$ faces principal-agent problems vis-a-vis $H$. The degree of agent drift – a function of $H$'s operational discipline and its ideological sympathy with government objectives – is written as $\\theta$. The government's level of investment $x$, and thus its expected payoffs, are penalized increasing in $\\theta$. In other words, the less reliable the agent $(\\theta \\uparrow)$, the less useful its efforts.\nFinally, $G$ gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, $f(\\varphi)$, and that the attacker faces penalties increasing in attack scale, $x$. This would be modeled as $x \\times \\varphi$: the less centralized, the more deniability when scale is held constant.²⁰ The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target's right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.\n|  Term | Description | Range | Type  |\n| --- | --- | --- | --- |\n|  φ | Extent of outsourcing strategy | ∈  | G’s Strategy  |\n|  ψ | Operational sophistication (probability of success) | ∈  | Exogenous  |\n|  u | Return on scale of investment | ∈ R>0 | Exogenous  |\n|  x | Campaign investment | ∈ R>0 | Exogenous  |\n|  θ | Distance between principal / agent ideal points | ∈ R>0 | Exogenous  |\n|  γ | Fixed cost of centralization | ∈ R>0 | Exogenous  |\n|  c | Penalty of being caught & attributed | ∈ R>0 | Exogenous  |\n|  τ | Target’s ability to attribute (technical attrib.) | ∈  | Exogenous  |\n|  α | Target’s willingness to accuse (political attrib.) | ∈ R>0 | Exogenous  |\nTable 1: Parameter Guide\nDeparting from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted $\\tau$, and political attribution, $\\alpha$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nAttribution $\\tau_v$ is simply the probability of detection, determined by the target state's capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, $\\alpha_v &gt; 1$, is determined by the target state's tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state's capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence.\nThe government's payoff can be modeled as\n$$\nU_G(\\varphi) = \\psi \\hat{u} x (2 - \\varphi) - \\theta \\varphi x - \\gamma (1 - \\varphi) - \\tau_v c \\left(\\alpha_v(\\varphi) + x (1 - \\varphi)\\right)\n$$\nIn plain terms, $G$'s expected benefit is given by the balance of participation, $\\hat{u}(2 - \\varphi)$, times the probability the campaign is successful ($\\psi$), and the amount of material investment required ($x$). If the campaign is successful, $G$'s investment yields a return of $\\hat{u}x$. $G$ has a choice whether to outsource ($\\varphi &gt; 0$) or centralize the campaign ($\\varphi = 0$). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment ($\\theta x$). Centralization may also involve investment of some fixed downpayment $\\gamma$. For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, $G$ incurs some penalty based on the target's ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes $\\varphi$ given the parameters.\nAs a stricter test of the theory, eliminate any agent drift $\\theta$ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that $H$'s\nElectronic copy available at: https://ssrn.com/abstract=3611582\nskill is equivalent to $G$'s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in $\\varphi$ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, $G$'s decision hinges on $\\alpha$.\nFor simplicity, assume the return on investment is linearly increasing in average attack scale $(\\hat{u} = 1)$. Also equalize the $\\theta$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal.²¹ Like the model employed by Lindsay , this setup allows us to locate the optimal attack scale. Since I regard $x$ as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, $\\psi$, as a constant. Set $\\psi = 1$ for the most interesting case. As a final simplification, assume technical attribution is certain whenever $G$ attacks $(\\tau = 1)$, and that the penalty $c$ is linearly increasing in scale as a function of the cumulative evidence left behind $x$. This implies a one-to-one increase in the target's ability to implicate the host state if the host state runs the campaign directly, since in this case \"responsibility\" can be proven through technical means alone. Set $x, c = 1$.\nThis set of assumptions simplifies the equation to $U_{G}(\\varphi) = x(2 - \\varphi) - c(\\alpha_{\\varphi}(\\varphi) + x(1 - \\varphi))$. In order to constitute an equilibrium where $G$ outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies\n$$\n\\varphi &gt; \\frac{1}{a}\n$$\nwhich illustrates the general relationship between outsourcing $(\\varphi)$ and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us\n²¹ I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\nU _ {G} (\\varphi) = x (2 - \\varphi) - (\\alpha_ {v} (\\varphi) + (1 - \\varphi))\n$$\nwhere expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and $\\varphi$ in Theorem 1.\nTheorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter's borders $(\\alpha)$, the lower the host state's incentive to outsource $(\\varphi)$.\nProof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of $\\varphi$ via straightforward optimization. The proof is concise enough to show in the body of the paper.\nWith no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: $(\\alpha_v(\\varphi) + (1 - \\varphi))^2$, which gives us the transformation\n$$\n\\max U _ {G} (\\varphi) = x (2 - \\varphi) - \\tau (\\alpha_ {v} (\\varphi) + (1 - \\varphi)) ^ {2}\n$$\nThe first order condition (FOC) must isolate at least one extremum in order to find a critical point at which $G$ will choose to switch between strategies. Differentiate the function with respect to $\\varphi$:\n$$\n\\frac {\\partial}{\\partial \\varphi} U _ {G} (\\cdot) = - (\\alpha + 1) (\\alpha \\varphi + \\varphi - 1) - x\n$$\nWe can then solve for the optimal level of $\\varphi$ by simply setting the derivative equal to zero and rearranging algebraically for $\\varphi$. This produces:\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\n\\varphi^ {*} = \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\text{ where } \\alpha \\geq 0 \\text{ by assumption} \\tag{1}\n$$\nThe second order condition (SOC) confirms that $\\varphi^{*}$ is indeed a global maximum:\n$$\n\\frac {\\partial^ {2}}{\\partial^ {2} \\varphi} U _ {G} (\\varphi) = - a ^ {2} - 2 a - 1 \\text{ which is } &lt; 0 \\tag{2}\n$$\nWe observe from Equation 2 that the slope is decreasing at $U_{G}^{\\prime \\prime}$, proving that $\\varphi^{*}$ maximizes $G$'s payoff function.\n## 2.3 Analysis\nWe wish to know how $U_{G}(\\varphi^{*})$ changes with $\\alpha, x$. Substituting $\\varphi^{*}$ into the original equation find calculate $G$'s expected utility, we obtain\n$$\nU _ {G} (\\varphi^ {*}) = x \\left[ 2 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\right] - x \\left[ \\alpha \\left(\\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) + \\left(1 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) \\right]\n$$\n$$\n\\text{which is equivalent to } U _ {G} \\left(\\varphi^ {*}\\right) = \\frac {\\alpha x ^ {2} + \\alpha x + x}{\\alpha^ {2} + 2 \\alpha + 1} \\tag{3}\n$$\nEquation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility $G$ can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between $\\alpha$ and $x$, neither Equation 1 nor Equation 3 is immediately intuitive. The relationship becomes more apparent when $\\alpha$ is $\\varphi^{*}$ is plotted. Figure 2 (right)\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim's propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their \"plausible deniability\" appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able).\nshows the utility gained for different levels of  $\\varphi$ . Outsourcing becomes less advantageous as  $\\alpha$  increases. In this model, the target state's  $\\alpha$  is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal  $\\varphi^{*}$ . As  $\\alpha$  increases, the expected gains of centralization  $(\\varphi^{*} \\downarrow)$  begin to exceed the gains from outsourcing  $(\\varphi^{*} \\uparrow)$ . The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay 's findings on deterrence. Imputing values can help give us more precise point estimates.\nExample 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence  $(\\alpha = 0)$ . Then the optimal level of outsourcing is  $\\varphi^{*} = x$  and  $G$  would receive  $U_{G}(\\varphi^{*}) = \\tilde{u} x$  for any level of  $x$ . The value of  $x$  that maximizes this relationship is 1, so  $\\varphi^{*} = 1$ . In other\nElectronic copy available at: https://ssrn.com/abstract=3611582\nwords, $G$ gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming $\\hat{u} &gt; 1$) that $G$ would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom.\nExample 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. $\\alpha = 10$. Then $\\varphi^{*} = (10x^{2} + 11x) / 121$, and the calculation becomes more complex.²² Fixing $\\varphi^{*} = 0.148$, $x^{*} = 0.895$ at their optima (see previous footnote), $G$ can expect to receive $0.148\\hat{u}$. Note that $G$'s maximum payoff is strictly (and significantly) lower when $\\alpha = 1$ no matter what its strategy. Payoffs diminish further as $\\alpha$ increases or return on investment $\\hat{u}$ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.\n## 2.4 Discussion\nIn nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states' increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.\nIn practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however,\n²² In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthat unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions  as opposed to decentralized strategies, such as outsourcing.\nPursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay  argues compellingly that a target’s willingness to assign blame and/or retaliate could be positively related to the scale of the attack. If true, the results may even underestimate the influence of $\\alpha$, and therefore overstate the rate of outsourcing. Operations that are serious enough to be of interest to the attacking state would likely invite in-kind retaliation even if the evidence were extremely flimsy. As technical attribution capabilities continue to improve and norms become more conducive as a consequence of emerging state practice, political attributions will only become more common.\n# 3 Empirical Strategy\nResearchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?\nThere is no dataset that tracks negative variation in proxy relationships over time. As mentioned,\nElectronic copy available at: https://ssrn.com/abstract=3611582\n|  EVIDENCE | VALUE |   | SUSPICIOUS TARGET  |\n| --- | --- | --- | --- |\n|  Uniformed Personnel | (5) | Direct proof | Implausibly deniable  |\n|  Agency/Contractor | (4) | Strong proof | Implausibly deniable  |\n|  IoCs: Known Group | (3) | Technical proof | Questionably deniable  |\n|  IoCs: Location | (2) | Technical proof | Plausibly deniable  |\n|  Cui bono | (1) | Circumstantial proof | Plausibly deniable  |\n|  No evidence | (0) | No proof | Plausibly deniable  |\nTable 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a  $\\{0:5\\}$  scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).\nAkoto  tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.\nEach observation in CFR's dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme. While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).\nFor information on victim responses, I rely on Hinck and Maurer 's data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer  dataset up to date (2022) by\nElectronic copy available at: https://ssrn.com/abstract=3611582\nsearching the DOJ's website for news and press releases under the category of cyber crime.²⁴\nUnsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive . Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 . Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step.²⁵ This generates a daily count variable ranging from 1 to 4.²⁶\nThe data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.\nIn Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a\n²⁴ https://www.justice.gov/news\n²⁵ These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.\n²⁶ It stands to reason that, if anything, the Hinck and Maurer  data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time.\ngreater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof.²⁷ Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.\n²⁷ Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 3.1 Analysis\nTo explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsourcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn't actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.\nIn the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.\nFor tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, *more insourcing* should imply *less outsourcing*.\nNext, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country $i$ was implicated in year $j$. In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are\nElectronic copy available at: https://ssrn.com/abstract=3611582\nmeasuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.\nI include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony.\n|   | Dependent variables:  |   |   |   |\n| --- | --- | --- | --- | --- |\n|   | Observe Insourcing → Sponsor FE |   | Public Response  |   |\n|   | (1) | Two-Way FE | Sponsor FE | Two-Way FE  |\n|  Public Response (t-1) | 0.049*** (0.016) | 0.050*** (0.017) |  |   |\n|  Obs. Insourcing (t-1) |  |  | 0.028 (0.043) | 0.035 (0.042)  |\n|  Year (Control) | 0.015*** (0.005) |  | 0.013** (0.006) |   |\n|  Incident (Control) | 0.114*** (0.015) | 0.112*** (0.010) | 0.088*** (0.022) | 0.082*** (0.021)  |\n|  Observations | 186 | 186 | 186 | 186  |\n|  R2 | 0.450 | 0.304 | 0.355 | 0.207  |\n|  Adjusted R2 | 0.409 | 0.180 | 0.307 | 0.065  |\n|  Note: |  |  | *p<0.1; **p<0.05; ***p<0.01  |   |\nTable 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries' propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government's willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.\nTable 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects\nElectronic copy available at: https://ssrn.com/abstract=3611582\nare presented in the odd columns as a robustness check.²⁸ Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insure operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.\nFirst examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t−1) are positively associated with decisions by other countries to insure in subsequent periods (p &lt; 0.01).²⁹ Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods.³⁰ Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.\nModels 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of\n²⁸ Recent research has strongly recommended one-way fixed effects models over two-way specifications . Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) . Linear coefficients are also more easily interpreted.\n²⁹ The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.\n³⁰ Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects . The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\na sponsor's involvement and its willingness to respond publicly ($p = 0.35$). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.\nWhy might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.\nMoreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\" .\nThough caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal . The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 4 Conclusion\nScholars have long been interested in the conditions under which new cyber norms can emerge and proliferate . Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible . Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is *in fact* on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.\nOn the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a *true* decline, or a turn away from *ineffective* proxies in favor of even stealthier alternatives.\nThis potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their *own* operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected\nElectronic copy available at: https://ssrn.com/abstract=3611582\nattacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.\nAs opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.³¹\nWithout plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage , whereas state control minimizes these byproducts . In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway . If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.\nIf not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion  or external signaling purposes . And at times and in places where online nationalism\n³¹ It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nis elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives , or when the host state lacks capacity to conduct covert operations of its own , a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals , helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.\nFormalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets , Gorwa and Smeets , and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance . Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.\nCyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-$n$ studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# Acknowledgements\nThe author is indebted to William Akoto, Jason Healey, Nadiya Kostyuk, Jon Lindsay, Mike Poznansky, Jack Snyder, Brandon Valeriano, JD Work, participants of the Digital Issues Discussion Group (DIDG), and four anonymous reviewers for helpful comments that improved this manuscript. This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484 (September 2021-November 2021) and 2021-2970 (November 2021 on).\nElectronic copy available at: https://ssrn.com/abstract=3611582"
    },
    "author_year": {
      "total": {
        "intext_total": 1,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 303,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [
        {
          "index": "2021-november|2021",
          "intext_citation": "(September 2021-November 2021)",
          "preceding_text": "This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484",
          "footnote": null
        }
      ],
      "flat_text": "# Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay\nJustin Key Canfil\nJune 20, 2020\n## Abstract\nIt is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict.\nWord Count: 12,500\nKeywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.\nHow have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.\nScholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give\nElectronic copy available at: https://ssrn.com/abstract=3611582\nit even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.”\nIn this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14].\nThe proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in\nElectronic copy available at: https://ssrn.com/abstract=3611582\nresponse to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.\nThat is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.\n# 1 Cyber Proxies: What We Know\nWhether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict.¹ For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident [24–27]. Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world's most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization [24, 30]. Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors [31].\n¹Long ago common in naval warfare, proxy conflict once again became prevalent in the latter half of the 20th century as armed attack and conquest became less accepted as legitimate instruments of statecraft [19]. Scholars have found that a majority of rebel groups since 1945 receive tacit state support [20] and this support has made these groups more powerful and influential [21]. They are observed most often between great power dyads [6, 22, 23], presumably because the risks associated with direct action are higher when targets can strike back.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nBut states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto [33] explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.”² I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.\nThis of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting.³ More recent work by Florian Egloff [32] refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible [36].\nDetection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability [8, 35, 37–42]. Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.\n²Proxies \"may or may not be part of state security and intelligence agencies and may be criminal syndicates or private cybersecurity companies ... Some groups may start off as private hacker collectives and are then absorbed into state security agencies or vice versa\" [33].\n³Maurer [35] writes that state sponsors can actively fund or otherwise support non-state cyber actors with the expectation that these actors will accomplish some military, intelligence, or foreign policy objective on behalf of the state (what Maurer terms “orchestrating”). Alternatively, sponsors can simply permit offensive operations by non-state actors by turning a blind eye (“sanctioning”). At the opposite end, a sponsor can establish effective in-house command and control over the group (“delegating”).\nElectronic copy available at: https://ssrn.com/abstract=3611582\nVictim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors [43]. If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.\nSome non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called \"patriotic hackers\" first appeared as early as 1998 [44]. Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a \"Promethean dilemma\" if those proxies later use their newfound capabilities against their sponsors [8]. Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments [45] to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy's fidelity, and plausible deniability is strengthened.\nThis logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea [47] – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries [38, 42, 49–51]. On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation [35, 46]. Between 9/11 and the start of the Iraq War, for example, when US nationalism soared,\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthe US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets [53]. On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.\nSo just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-$n$ datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto [33] explains, these data limitations have “crippled efforts to study … cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.\nThe third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.\nFor researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas [54–56], but for this reason the study of cyber proxies faces a special set of challenges.\n## 1.1 Observational Equivalence in Existing Data\nThe crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing\nElectronic copy available at: https://ssrn.com/abstract=3611582\ndoesn't convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.\nTo illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]'s Dyadic Cyber Incident and Dispute Dataset 1.5 (\"VJM\");[5] the Council on Foreign Relations' Cyber Operations Tracker (\"CFR\") [57];[6] and Akoto [33]'s dataset on cyber proxy onset.[7] CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.[8]\nOne reasonable expectation might be that states are likelier to delegate certain tasks to proxies – for example, less sophisticated or less sensitive operations. We can subset these datasets to include only attacks other than espionage and Advanced Persistent Threats (APTs), respectively, to infer how much of this activity is driven by nation state operatives versus their proxies.[9] A third dataset by Akoto [33] contains an extensive survey of known proxy groups.[10] However, it only tracks proxy relationship onset.[11] As a strictly cumulative measure, it cannot be used to measure whether outsourcing has declined. Instead, we can use it to observe the rate at which states have continued to outsource to new groups in recent years.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 1: Comparisons of trends over time from three datasets [33, 57, 58]. The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade.\nFigure 1 compares observations from all three datasets. The  $Y$ -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in  $Y$  values over time, sorted by country faction.[12] Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nWe can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.\nThese trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto [33] explains that in order for the onset of a proxy relationship to appear in the dataset, \"there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government\" (emphasis mine). Akoto [33] continues: \"It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.\"¹³ Data collection is scoped on proxies which are already known to work for the state. Conclusion in the dataset is therefore inversely related the plausibility of a sponsor's deniability.\nWhat this means is that the large-$n$ information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.\nDirect measurements of outsourcing in available data cannot distinguish between these\n¹³ Akoto [33] also explicitly excludes \"flash\" groups – groups that emerge organically to conduct operations. This would seem to eliminate virtually all patriotic hackers, the type of proxy with the most deniability [see 34].\nElectronic copy available at: https://ssrn.com/abstract=3611582\ncompeting accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn't plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.\n## 2 The Illogic of Plausible Deniability\nIt has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true.\nIn the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its \"most difficult problem\" [61]. The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible [12, 13, 64]. Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns [65].\nEven if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose [33]. States are often sensitive about divulging how they know what they know [66]. Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on\nElectronic copy available at: https://ssrn.com/abstract=3611582\na direct command role can be held responsible for the actions of their proxies [36, 67].¹⁴\nThese barriers are what make outsourcing so attractive, according to conventional wisdom [35]. But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal [33, 68]? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers [33, 69]. A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal [71] described plans to adopt a model reminiscent of US Cyber Command.\nFrom 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support [28]. Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000 [24], however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang [73] catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker's Union (中国红客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they \"probably won't\" be permitted by the government to continue attacking foreign targets [75]. Since then, the Chinese government has relied more on specialized units at the Ministry of State Security [35, 71]. Attacks\n¹⁴The International Law Commission (ILC)'s 2001 Draft Articles is perhaps the clearest articulation of the law on state responsibility (though often cited, it is actually a nonbinding source). In the ILC's view, a host state can only be held responsible if it directly conducts or oversees the offending operation at the operational level (see International Law Commission (ILC) Draft Articles on State Responsibility, 2001, http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf). International courts have held variously that the relationship must be one of \"effective control\" (Nicaragua v. United States), \"overall control\" plus the commission of specific acts (Prosecutor v. Dusko Tadic (1999)), or \"complete dependence\" (Bosnia and Herzegovina v. Serbia and Montenegro (1996)) – all very strict standards that elide the possibility of measures short of command or operational involvement. And in more than 4,700 claims proceedings, all but one tribunal (Dames &amp; Moore v. Iran) found that the burden of proof for wrongdoing rests with the defender (see Iran Claims Tribunal, https://www.state.gov/iran-u-s-claims-tribunal/).\nElectronic copy available at: https://ssrn.com/abstract=3611582\noriginating from that country reveal a more direct government hand [76].¹⁵ If proxies pay for the reasons we usually suspect, then this behavior is puzzling.\nRarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect [12, 13, 77, 78]. Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.\nIn particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment [79]. Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices [80] – a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” [79].\n¹⁵ For another example, see a 2019 CERT-EU memo: https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nIt is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.”¹⁶ In a separate piece, Carlin [43] explains that the Criminal and National Security Divisions at DOJ \"increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases),\" including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.¹⁷\nThis level of cooperation gives the government specially enhanced attribution capabilities. Carlin [43] describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are” [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak [13].\nEspecially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin [43] admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: \"the government must demonstrate, among other things, that the ‘target ... is a foreign power or an agent of a foreign power’” if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.\nIndictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement [85–87]. To my knowledge, there is no institutional\n¹⁶ [for a detailed exposition in this journal, see 78].\n¹⁷ “The most sophisticated threats we investigate are associated with nation-state actors or their proxies” [43].\nElectronic copy available at: https://ssrn.com/abstract=3611582\nrequirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” [89], they now seem more willing to punish sponsors for the activities of their proxies.¹⁸\nAfter all, why wouldn't victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths’” for victims with the means to retaliate [90]. States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.\nRaising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.\n## 2.1 A Model of Outsourcing\nHow can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology\n¹⁸ Note that Kaminska [89]’s argument in this journal is that US hesitancy to respond “stem[med] from a desire to avoid risk,” not uncertainty about the identity of the culprit.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nfor checking and comparing a theory's internal validity this way. Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev [91], I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work \"under the hood\" in cases where data are questionable or unavailable.\nEvery theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large- $n$  data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes [92].\nIn the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims' beliefs and the level of investment. Under this framework, the sponsor's deniability is a function of its involvement and the target state's independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.\nThe model shows how a sponsor's concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthis holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship [8]. The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability's role in decisions about whether to outsource.\n## 2.2 Model setup\nA host government $(G)$ oversees a pool of non-state hackers $(H)$. The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as $\\varphi \\in [0,1]$, where $\\varphi &gt; 0$ is some positive degree of outsourcing. One can imagine that low levels of $\\varphi$ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at $\\varphi = 0$, for instance by implementing and enforcing laws against hacking foreign targets. In the game, $G$'s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.\nThe government's return on investment is given as $\\hat{u} x$, where $x$ is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker's level of sophistication, $\\psi_{i}$. The probability of a successful campaign is $\\psi_{i}$. I assume that individual operations are scalable, and thus the government obtains either full benefit $\\hat{u} x$ from a successful campaign $(\\psi = 1)$ or no benefit at all $(1 - \\psi)$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nConsistent with default explanations, $G$ faces principal-agent problems vis-a-vis $H$. The degree of agent drift – a function of $H$'s operational discipline and its ideological sympathy with government objectives – is written as $\\theta$. The government's level of investment $x$, and thus its expected payoffs, are penalized increasing in $\\theta$. In other words, the less reliable the agent $(\\theta \\uparrow)$, the less useful its efforts.\nFinally, $G$ gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, $f(\\varphi)$, and that the attacker faces penalties increasing in attack scale, $x$. This would be modeled as $x \\times \\varphi$: the less centralized, the more deniability when scale is held constant.²⁰ The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target's right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.\n|  Term | Description | Range | Type  |\n| --- | --- | --- | --- |\n|  φ | Extent of outsourcing strategy | ∈ [0,1] | G’s Strategy  |\n|  ψ | Operational sophistication (probability of success) | ∈ [0,1] | Exogenous  |\n|  u | Return on scale of investment | ∈ R>0 | Exogenous  |\n|  x | Campaign investment | ∈ R>0 | Exogenous  |\n|  θ | Distance between principal / agent ideal points | ∈ R>0 | Exogenous  |\n|  γ | Fixed cost of centralization | ∈ R>0 | Exogenous  |\n|  c | Penalty of being caught & attributed | ∈ R>0 | Exogenous  |\n|  τ | Target’s ability to attribute (technical attrib.) | ∈ [0,1] | Exogenous  |\n|  α | Target’s willingness to accuse (political attrib.) | ∈ R>0 | Exogenous  |\nTable 1: Parameter Guide\nDeparting from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted $\\tau$, and political attribution, $\\alpha$.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nAttribution $\\tau_v$ is simply the probability of detection, determined by the target state's capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, $\\alpha_v &gt; 1$, is determined by the target state's tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state's capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence.\nThe government's payoff can be modeled as\n$$\nU_G(\\varphi) = \\psi \\hat{u} x (2 - \\varphi) - \\theta \\varphi x - \\gamma (1 - \\varphi) - \\tau_v c \\left(\\alpha_v(\\varphi) + x (1 - \\varphi)\\right)\n$$\nIn plain terms, $G$'s expected benefit is given by the balance of participation, $\\hat{u}(2 - \\varphi)$, times the probability the campaign is successful ($\\psi$), and the amount of material investment required ($x$). If the campaign is successful, $G$'s investment yields a return of $\\hat{u}x$. $G$ has a choice whether to outsource ($\\varphi &gt; 0$) or centralize the campaign ($\\varphi = 0$). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment ($\\theta x$). Centralization may also involve investment of some fixed downpayment $\\gamma$. For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, $G$ incurs some penalty based on the target's ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes $\\varphi$ given the parameters.\nAs a stricter test of the theory, eliminate any agent drift $\\theta$ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that $H$'s\nElectronic copy available at: https://ssrn.com/abstract=3611582\nskill is equivalent to $G$'s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in $\\varphi$ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, $G$'s decision hinges on $\\alpha$.\nFor simplicity, assume the return on investment is linearly increasing in average attack scale $(\\hat{u} = 1)$. Also equalize the $\\theta$ assumption by also assuming centralization costs are trivial for high-capacity governments $(\\gamma \\downarrow 0)$, since these types have substantial resources at their disposal.²¹ Like the model employed by Lindsay [13], this setup allows us to locate the optimal attack scale. Since I regard $x$ as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, $\\psi$, as a constant. Set $\\psi = 1$ for the most interesting case. As a final simplification, assume technical attribution is certain whenever $G$ attacks $(\\tau = 1)$, and that the penalty $c$ is linearly increasing in scale as a function of the cumulative evidence left behind $x$. This implies a one-to-one increase in the target's ability to implicate the host state if the host state runs the campaign directly, since in this case \"responsibility\" can be proven through technical means alone. Set $x, c = 1$.\nThis set of assumptions simplifies the equation to $U_{G}(\\varphi) = x(2 - \\varphi) - c(\\alpha_{\\varphi}(\\varphi) + x(1 - \\varphi))$. In order to constitute an equilibrium where $G$ outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies\n$$\n\\varphi &gt; \\frac{1}{a}\n$$\nwhich illustrates the general relationship between outsourcing $(\\varphi)$ and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us\n²¹ I presume a very small fixed cost $\\gamma = \\epsilon$ to eliminate the potential for mixed strategy equilibria. If the decisionmaker is ever indifferent between outsourcing/not, she will choose to outsource. This makes the test slightly more stringent.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\nU _ {G} (\\varphi) = x (2 - \\varphi) - (\\alpha_ {v} (\\varphi) + (1 - \\varphi))\n$$\nwhere expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and $\\varphi$ in Theorem 1.\nTheorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter's borders $(\\alpha)$, the lower the host state's incentive to outsource $(\\varphi)$.\nProof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of $\\varphi$ via straightforward optimization. The proof is concise enough to show in the body of the paper.\nWith no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: $(\\alpha_v(\\varphi) + (1 - \\varphi))^2$, which gives us the transformation\n$$\n\\max U _ {G} (\\varphi) = x (2 - \\varphi) - \\tau (\\alpha_ {v} (\\varphi) + (1 - \\varphi)) ^ {2}\n$$\nThe first order condition (FOC) must isolate at least one extremum in order to find a critical point at which $G$ will choose to switch between strategies. Differentiate the function with respect to $\\varphi$:\n$$\n\\frac {\\partial}{\\partial \\varphi} U _ {G} (\\cdot) = - (\\alpha + 1) (\\alpha \\varphi + \\varphi - 1) - x\n$$\nWe can then solve for the optimal level of $\\varphi$ by simply setting the derivative equal to zero and rearranging algebraically for $\\varphi$. This produces:\nElectronic copy available at: https://ssrn.com/abstract=3611582\n$$\n\\varphi^ {*} = \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\text{ where } \\alpha \\geq 0 \\text{ by assumption} \\tag{1}\n$$\nThe second order condition (SOC) confirms that $\\varphi^{*}$ is indeed a global maximum:\n$$\n\\frac {\\partial^ {2}}{\\partial^ {2} \\varphi} U _ {G} (\\varphi) = - a ^ {2} - 2 a - 1 \\text{ which is } &lt; 0 \\tag{2}\n$$\nWe observe from Equation 2 that the slope is decreasing at $U_{G}^{\\prime \\prime}$, proving that $\\varphi^{*}$ maximizes $G$'s payoff function.\n## 2.3 Analysis\nWe wish to know how $U_{G}(\\varphi^{*})$ changes with $\\alpha, x$. Substituting $\\varphi^{*}$ into the original equation find calculate $G$'s expected utility, we obtain\n$$\nU _ {G} (\\varphi^ {*}) = x \\left[ 2 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}} \\right] - x \\left[ \\alpha \\left(\\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) + \\left(1 - \\frac {\\alpha - x + 1}{(\\alpha + 1) ^ {2}}\\right) \\right]\n$$\n$$\n\\text{which is equivalent to } U _ {G} \\left(\\varphi^ {*}\\right) = \\frac {\\alpha x ^ {2} + \\alpha x + x}{\\alpha^ {2} + 2 \\alpha + 1} \\tag{3}\n$$\nEquation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility $G$ can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between $\\alpha$ and $x$, neither Equation 1 nor Equation 3 is immediately intuitive. The relationship becomes more apparent when $\\alpha$ is $\\varphi^{*}$ is plotted. Figure 2 (right)\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim's propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their \"plausible deniability\" appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able).\nshows the utility gained for different levels of  $\\varphi$ . Outsourcing becomes less advantageous as  $\\alpha$  increases. In this model, the target state's  $\\alpha$  is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal  $\\varphi^{*}$ . As  $\\alpha$  increases, the expected gains of centralization  $(\\varphi^{*} \\downarrow)$  begin to exceed the gains from outsourcing  $(\\varphi^{*} \\uparrow)$ . The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given  $\\tau \\times \\alpha$ , consistent with Lindsay [13]'s findings on deterrence. Imputing values can help give us more precise point estimates.\nExample 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence  $(\\alpha = 0)$ . Then the optimal level of outsourcing is  $\\varphi^{*} = x$  and  $G$  would receive  $U_{G}(\\varphi^{*}) = \\tilde{u} x$  for any level of  $x$ . The value of  $x$  that maximizes this relationship is 1, so  $\\varphi^{*} = 1$ . In other\nElectronic copy available at: https://ssrn.com/abstract=3611582\nwords, $G$ gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming $\\hat{u} &gt; 1$) that $G$ would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom.\nExample 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. $\\alpha = 10$. Then $\\varphi^{*} = (10x^{2} + 11x) / 121$, and the calculation becomes more complex.²² Fixing $\\varphi^{*} = 0.148$, $x^{*} = 0.895$ at their optima (see previous footnote), $G$ can expect to receive $0.148\\hat{u}$. Note that $G$'s maximum payoff is strictly (and significantly) lower when $\\alpha = 1$ no matter what its strategy. Payoffs diminish further as $\\alpha$ increases or return on investment $\\hat{u}$ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.\n## 2.4 Discussion\nIn nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states' increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.\nIn practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however,\n²² In this situation, $G$ expects to receive the (rather hideous) payoff amount $\\hat{u}x((-0.0826x - 0.0909)x + 2) + x(x((-0.413x - 0.909)x + 0.409) + 1) - 0.5$, which maximizes at $x \\approx 0.895$. Suppose $G$ has control over $x$, or at least has the power to increase or decrease $x$ by permitting or restricting $H$ from acting unilaterally. Substituting 0.895 into Equation 3, $G$ maximizes utility by outsourcing at 0.148, or less than 15 percent capacity.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nthat unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions [55] as opposed to decentralized strategies, such as outsourcing.\nPursuant to the specification used in Example 2, host states outsource only about 15 percent of the time. However, Lindsay [13] argues compellingly that a target’s willingness to assign blame and/or retaliate could be positively related to the scale of the attack. If true, the results may even underestimate the influence of $\\alpha$, and therefore overstate the rate of outsourcing. Operations that are serious enough to be of interest to the attacking state would likely invite in-kind retaliation even if the evidence were extremely flimsy. As technical attribution capabilities continue to improve and norms become more conducive as a consequence of emerging state practice, political attributions will only become more common.\n# 3 Empirical Strategy\nResearchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?\nThere is no dataset that tracks negative variation in proxy relationships over time. As mentioned,\nElectronic copy available at: https://ssrn.com/abstract=3611582\n|  EVIDENCE | VALUE |   | SUSPICIOUS TARGET  |\n| --- | --- | --- | --- |\n|  Uniformed Personnel | (5) | Direct proof | Implausibly deniable  |\n|  Agency/Contractor | (4) | Strong proof | Implausibly deniable  |\n|  IoCs: Known Group | (3) | Technical proof | Questionably deniable  |\n|  IoCs: Location | (2) | Technical proof | Plausibly deniable  |\n|  Cui bono | (1) | Circumstantial proof | Plausibly deniable  |\n|  No evidence | (0) | No proof | Plausibly deniable  |\nTable 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a  $\\{0:5\\}$  scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).\nAkoto [33] tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.\nEach observation in CFR's dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.[23] While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).\nFor information on victim responses, I rely on Hinck and Maurer [99]'s data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer [99] dataset up to date (2022) by\nElectronic copy available at: https://ssrn.com/abstract=3611582\nsearching the DOJ's website for news and press releases under the category of cyber crime.²⁴\nUnsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive [100]. Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 [101]. Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step.²⁵ This generates a daily count variable ranging from 1 to 4.²⁶\nThe data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.\nIn Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a\n²⁴ https://www.justice.gov/news\n²⁵ These include whether the source of the attack/incident was taken down; whether sanctions were levied; whether the suspects were placed on the “Most Wanted” list or a reward was offered for their capture; and whether they were extradited, arrested, and/or sentenced.\n²⁶ It stands to reason that, if anything, the Hinck and Maurer [99] data might understate the intensity of the US response. One can imagine that many if not most US government hackbacks are undisclosed to the public.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nFigure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time.\ngreater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof.²⁷ Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.\n²⁷ Two important caveats should be discussed. First, it is possible that state personnel were always this involved, that the US has always known this, and it is simply more willing to disclose it since 2014. This is a shortcoming that is impossible to address because the political processes contributing to disclosures are unobserved. If true, the observed increase in evidence since 2014 is a function of victim confidence rather than actual changes in activity. However, given that 100 percent of attributed incidents were insourced in the last year of the dataset, insourcing as a proportion at least cannot have declined. A second possibility, that attribution technology itself has improved, so the US, even if always in theory willing, is now more able to attribute. This is less of a concern. Attribution has certainly improved over time, but that should mostly inflate the number of observed 3s (IoCs) as lower levels of evidence (0-2) become provable. Here we are principally concerned with whether the US is more likely to observe and respond to direct (&gt; 4) or indirect evidence (&lt; 4).\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 3.1 Analysis\nTo explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsourcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn't actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.\nIn the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.\nFor tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, *more insourcing* should imply *less outsourcing*.\nNext, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country $i$ was implicated in year $j$. In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are\nElectronic copy available at: https://ssrn.com/abstract=3611582\nmeasuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.\nI include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony.\n|   | Dependent variables:  |   |   |   |\n| --- | --- | --- | --- | --- |\n|   | Observe Insourcing → Sponsor FE |   | Public Response  |   |\n|   | (1) | Two-Way FE | Sponsor FE | Two-Way FE  |\n|  Public Response (t-1) | 0.049*** (0.016) | 0.050*** (0.017) |  |   |\n|  Obs. Insourcing (t-1) |  |  | 0.028 (0.043) | 0.035 (0.042)  |\n|  Year (Control) | 0.015*** (0.005) |  | 0.013** (0.006) |   |\n|  Incident (Control) | 0.114*** (0.015) | 0.112*** (0.010) | 0.088*** (0.022) | 0.082*** (0.021)  |\n|  Observations | 186 | 186 | 186 | 186  |\n|  R2 | 0.450 | 0.304 | 0.355 | 0.207  |\n|  Adjusted R2 | 0.409 | 0.180 | 0.307 | 0.065  |\n|  Note: |  |  | *p<0.1; **p<0.05; ***p<0.01  |   |\nTable 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries' propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government's willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.\nTable 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects\nElectronic copy available at: https://ssrn.com/abstract=3611582\nare presented in the odd columns as a robustness check.²⁸ Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insure operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.\nFirst examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t−1) are positively associated with decisions by other countries to insure in subsequent periods (p &lt; 0.01).²⁹ Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods.³⁰ Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.\nModels 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of\n²⁸ Recent research has strongly recommended one-way fixed effects models over two-way specifications [102]. Because two-way specifications remain popular in political science, I include both in Table 3 to demonstrate robustness. Although a logistic model could also be appropriate for binary outcomes, OLS is preferable in this case. It is now understood that OLS is the best unbiased estimator (linear or otherwise) [103]. Linear coefficients are also more easily interpreted.\n²⁹ The reliability of this estimate assumes that the US was equally likely to acknowledge any evidence it had of direct involvement across time. This is an unavoidable shortcoming in reporting-based data given the level of secrecy surrounding internal public attribution decisions. On the upside, because the dependent variable was dichotomized before being summed and normalized by year, it does not assume that the US was any more or less likely to disclose indirect or piecemeal evidence, such as IoCs. The first assumption is probably less tenuous than the latter.\n³⁰ Caution should be used in this interpretation, since fixed effects limit the number of comparisons. The difficulty in making substantive comparisons between units is a principal downside of fixed effects [104]. The need to compensate for the strong possibility of selection bias outweighs limitations in interpretation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\na sponsor's involvement and its willingness to respond publicly ($p = 0.35$). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.\nWhy might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.\nMoreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it \"reduces concerns that omitted variables drive any associations between dependent and independent variable\" [104].\nThough caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal [105]. The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# 4 Conclusion\nScholars have long been interested in the conditions under which new cyber norms can emerge and proliferate [106–109]. Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible [110, 111]. Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is *in fact* on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.\nOn the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a *true* decline, or a turn away from *ineffective* proxies in favor of even stealthier alternatives.\nThis potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their *own* operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected\nElectronic copy available at: https://ssrn.com/abstract=3611582\nattacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.\nAs opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.³¹\nWithout plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts [112]. In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway [56, 58]. If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.\nIf not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes [26, 115]. And at times and in places where online nationalism\n³¹ It is conceivable that outsourcing and insourcing are both increasing, and that outsourcing to plausibly deniable actors is increasing at a faster clip. This would undermine the results. Cyber operations have been consistently attractive to governments over the past decade. Thus, while possible, this alternative seems unlikely.\nElectronic copy available at: https://ssrn.com/abstract=3611582\nis elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state's objectives [93], or when the host state lacks capacity to conduct covert operations of its own [20, 116], a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group's goals [117], helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.\nFormalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets [118], Gorwa and Smeets [119], and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance [119]. Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.\nCyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-$n$ studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.\nElectronic copy available at: https://ssrn.com/abstract=3611582\n# Acknowledgements\nThe author is indebted to William Akoto, Jason Healey, Nadiya Kostyuk, Jon Lindsay, Mike Poznansky, Jack Snyder, Brandon Valeriano, JD Work, participants of the Digital Issues Discussion Group (DIDG), and four anonymous reviewers for helpful comments that improved this manuscript. This research was supported in part by funding from the William and Flora Hewlett Foundation under grants 2020-1484  and 2021-2970 .\nElectronic copy available at: https://ssrn.com/abstract=3611582"
    }
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 30.0,
      "success_occurrences": 30.0,
      "success_unique": 15.0,
      "bib_unique_total": 15.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 1.0,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 30.0,
        "success_occurrences": 30.0,
        "success_unique": 15.0,
        "bib_unique_total": 15.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 1.0,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 192.0,
        "success_occurrences": 192.0,
        "success_unique": 106.0,
        "bib_unique_total": 119.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.8907563025210085,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 1.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 303.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "Outsourcing Cyber Power: Why Proxy Conflict in Cyberspace May No Longer Pay",
    "subtitle": "June 20, 2020",
    "document_type": "unknown",
    "venue": "",
    "publication_year": 2020,
    "authors": [
      "Justin Key Canfil"
    ],
    "affiliations": [],
    "emails": [],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "It is believed that states can achieve military and foreign policy objectives “on the cheap” by outsourcing cyber operations to willing proxy actors, be they cyber mercenaries, patriotic zealots, pranksters, or simply allies of convenience. By outsourcing, this logic goes, a host government can claim plausible deniability while cashing in on strategic gains. Puzzlingly, proxy-associated behavior across three datasets appears to show that activity associated with outsourcing has flagged. Do cyber proxies still pay? A formal model is used to hypothesize about how new norms of attribution (specifically, the willingness of victims to make accusations on the basis of circumstantial evidence) are developing. Sponsors who learn that they will take the heat regardless have fewer incentives to rely on proxies. Empirical evidence drawn from two cyber incident datasets offers support for this proposition. This should decrease our confidence that plausible deniability is the primary reason why states outsource their cyber operations to non-state hackers. The paper joins an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict. Word Count: 12,500 Keywords: cyber conflict, cyber proxies, state-sponsored, attribution, cyber norms, plausible deniability Electronic copy available at: https://ssrn.com/abstract=3611582 FORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives. How have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster. Scholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give Electronic copy available at: https://ssrn.com/abstract=3611582 it even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.” In this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful as an extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14]. The proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in Electronic copy available at: https://ssrn.com/abstract=3611582 response to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover. That is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine's Minister of Digital Transformation even tweeted an open invitation to join his \"IT army\" and to \"fight on the cyber front\" [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.",
    "keywords": [
      "cyber conflict",
      "cyber proxies",
      "state-sponsored",
      "attribution",
      "cyber norms",
      "plausible deniability"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1080/03071847.2013.787733",
        "10.1080/09557571.2013.839629",
        "10.1080/0163660X.2018.1485332",
        "10.1080/00396338.2011.555595",
        "10.1080/01402390.2014.977382",
        "10.1111/ajps.12426",
        "10.1080/01402390.2021.1895117",
        "10.1111/ajps.12411",
        "10.1111/j.1061-1924.2005.00183.x",
        "10.1080/10576100290101197",
        "10.1080/09546559308427227",
        "10.1080/0966284042000279027",
        "10.1080/14799855.2017.1414803",
        "10.1111/j.1540-5982.2006.00393.x",
        "10.1080/1057610X.2011.571193",
        "10.1080/15512169.2020.1729166"
      ],
      "issn": [
        "ISSN: 0099-9660"
      ],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "https://ssrn.com/abstract=3611582",
        "http://legal.un.org/ilc/texts/instruments/english/commentaries/9_6_2001.pdf",
        "https://www.state.gov/iran-u-s-claims-tribunal",
        "https://media.cert.europa.eu/static/MEMO/2019/TLP-WHITE-CERT-EU-MEMO-190729-1.pdf"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 119,
    "heading_count": 14,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 30,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.36666666666666664,
      "footnote_coverage": 1.0,
      "unique_index_count": 15
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 39,
        "superscript_definition_lines": 15,
        "numeric_bracket_hits": 137,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 15.0,
      "dominant_bib_coverage_rate": 1.0,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 14,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 6,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": false,
        "emails": false,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": false,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 1,
        "affiliations": 0,
        "emails": 0,
        "orcids": 0,
        "keywords": 6,
        "doi": 16,
        "issn": 1,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 4
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [],
        "toc_dot_lines": 0
      },
      "flags": []
    },
    "flags": [
      "missing_preceding_text",
      "heading_numbering_parent_violation"
    ]
  },
  "updated_at_utc": "2026-02-14T08:28:36.638773+00:00"
}