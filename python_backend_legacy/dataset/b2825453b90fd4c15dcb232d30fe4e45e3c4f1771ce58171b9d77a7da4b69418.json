{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\ZL7835UD\\Poznansky and Perkoski - 2018 - Rethinking secrecy in cyberspace the politics of voluntary attribution.pdf",
  "custom_id": "521",
  "response": {
    "id": "batch-b6235e9e-522-465eee34-887c-4688-b5b5-3b7092237509",
    "custom_id": "521",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "Journal of Global Security Studies, 3(4), 2018, 402-416\n\ndoi: 10.1093/jogss/ogy022\n\nResearch Article\n\nOXFORD\n\n# Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\n\nMichael Poznansky¹ and Evan Perkoski²\n\n¹University of Pittsburgh and ²University of Connecticut\n\n## Abstract\n\nCyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain.\n\nKeywords: cyber warfare, secrecy, coercion, nonstate actors\n\n## Introduction\n\nSecrecy is a defining feature of cyberspace. Cyber intruders can frequently disrupt networks, steal financial assets, and conduct espionage without ever revealing their identities. Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence (Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017) to its influence on the dynamics of conflict and escalation (Gartzke 2013; Buchanan 2017). Yet, while cyber intruders have ample opportunities to keep their sponsorship a secret, not all choose to take advantage. To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions (Smith 2016). They are not alone; SOBH Cyber Jihad, based in Iran, claimed credit for hacking into the control system of a dam in New York (Gosk, Winter, and\n\nConnor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015 (Vinton 2015).\n\nWhy do some actors claim responsibility for cyber operations while others opt for anonymity? To answer this question, we explore the logic of credit-claiming for two key sets of actors in cyberspace: states and politically motivated nonstate actors (hereafter, nonstate actors).¹\n\nWe argue that credit-claiming, including the manner in which culpability is communicated, depends on what the intruder wants to accomplish. For states, credit-claiming is most appealing during operations that require target compliance, otherwise known as cyber coercion. When states choose to make their identities known to coerce targets, they are more likely to do so privately since public credit-claiming raises the odds of escalation. Anonymity is most attractive during operations where\n\n¹ We bracket nonstate actors without political motivations.\n\nPoznansky, Michael, and Evan Perkoski. (2018) Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution. Journal of Global Security Studies, doi: 10.1093/jogss/ogy022\n\n© The Author(s) (2018). Published by Oxford University Press on behalf of the International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 1,
            "markdown": "MICHAEL POZNANSKY AND EVAN PERKOSKI\n403\n\nsuccess can be achieved without target compliance—cyber espionage and sabotage offer two such examples. Nonstate actors operate according to a different logic. Drawing on insights from studies of armed and unarmed resistance, we argue that nonstate actors in cyberspace regularly claim credit for their intrusions in visible ways to signal credibility, influence public opinion, and grow their ranks. Owing to their relative weakness and obscurity, nonstate actors must first prove their capability before doing anything else.\n\nThis argument requires a conceptual shift in how we think about secrecy in cyberspace. Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations (Kibbe 2007). The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise (Axelrod 1979; Slantchev 2010). The latter involves the use of secrecy to conceal the sponsor of an operation (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson 2016). Importing this distinction to the cyber domain helps clarify when secrecy is an operational imperative and when it is a choice that actors make. In brief, the advantages afforded to targets who learn of imminent or ongoing operations means that cyber intrusions will almost always be conducted clandestinely. Once an operation is complete, however, intruders are free to choose whether to claim responsibility. Put differently, cyber operations are almost always clandestine but not necessarily covert. The failure to recognize this distinction partly contributes to the widespread assumption that anonymity is an immutable feature of cyberspace rather than something actors select into.\n\nRigorously testing these claims would require access to the internal deliberations of state and nonstate actors to understand how decisions about credit-claiming are made. At present, this is a nearly impossible task (Buchanan 2017, 12). We are perhaps decades away from gaining access to the types of declassified documents necessary to evaluate the deliberations of states; the problem is even more acute for nonstate actors. As a second-best option, we leverage a range of sources—secondary materials, news reports, official government statements, and interviews—to assess the plausibility of our argument. Our study is closer to an exercise in theory construction than theory testing (Mahoney 2015, 201).\n\nThis article makes several contributions. First, it joins together a burgeoning literature centered on the dynamics of secrecy in world politics and another focused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation (Carson 2016), and the relationship between democratic peace theory and covert regime change (Downes and Lilley 2010; Poznansky 2015). These studies are tied together by an overarching focus on how actors use secrecy to pursue their political goals. Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike (Gartzke 2013; Gartzke and Lindsay 2015; Lindsay 2015; Rid and Buchanan 2015; Buchanan 2017; Nye 2017) but have largely neglected the determinants of secrecy at the stage where sponsors can (dis)claim ownership of an operation.² We address this issue directly.\n\nSecond, this study is among the first of which we are aware that considers the goals and constraints of the two most important actors operating in cyberspace—states and nonstate actors. Existing research tends to focus on the former (Gartzke 2013; Buchanan 2017; Borghard and Lonergan 2017; Nye 2017). But nonstate actors conduct cyberattacks at high rates and often in very visible ways. Moreover, their attack capabilities are growing and in some cases they \"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\" (Stoller 2017). Ignoring nonstate actors or assuming that their strategic logic mirrors that of states is insufficient. Our approach is thus to ask the same questions for both sets of actors, reducing barriers that inhibit a more complete understanding of cyberattacks.\n\n## The Problem of Secrecy\n\nThe conventional view of a cyber operation is an intruder quietly penetrating a target's network to collect information or cause damage, whether virtual or physical, without betraying their identity.³ This narrative—which assumes secrecy from start to finish—colors how the literature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant (Slayton 2017). Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks (Rid and Buchanan 2015; Nye 2017, 49–52). According to Lindsay (2013), “[f]orensics takes months, whereas the anonymous attack can present\n\n2 For important exceptions, see Betz and Stevens (2011), Borghard and Lonergan (2017), and Libicki (2009).\n3 See Buchanan (2017) for a summary.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 2,
            "markdown": "Rethinking Secrecy in Cyberspace\n\nitself and perhaps complete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity (Lindsay 2015, 58).\n\nThe pervasiveness of secrecy in this domain also poses challenges for cyber coercion (Valeriano and Maness 2014; 2015, 79; Nye 2017, 55-56). Coercion requires victims to know who is making demands and what they are being asked to do (Schelling 1966). Anonymity is antithetical to this enterprise. As Gartzke (2013) once put it, \"How does one surrender to no one in particular?\" (47). Some scholars point out that perpetrators can enhance the credibility of coercive threats by making their identities known, a point we develop more fully below. But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace (Borghard and Lonergan 2017, 457-59; Libicki 2009, 50-51).\n\nWhile all of these studies seem to address the same basic phenomenon—secrecy—there are meaningful differences when it comes to what is being concealed during an operation and for what purpose. The next section explores these differences.\n\n## Disaggregating Secrecy\n\nThe US military and intelligence communities distinguish between two types of secret operations. The first are clandestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise (Axelrod 1979; Slantchev 2010). As an example, consider Operation Neptune Spear, the US Special Forces' raid on Osama bin Laden's compound in Abbottabad, Pakistan. While the raid itself was shrouded in secrecy, President Obama's remarks to the nation afterward suggest that the purpose of secrecy was tactical, not political.\n\nThe second type of secret operation is covert action, defined as \"[a]n operation that is so planned and\n\n![img-0.jpeg](img-0.jpeg)\nFigure 1. Clandestine and covert operations\n\nexecuted as to conceal the identity of or permit plausible denial by the sponsor.\"6 While covert operations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\" (Gross 2009, 12). There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns (Brown 2014; Carson 2016) and avoiding hostile reactions from domestic and international observers (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson and Yarhi-Milo 2017; Joseph and Poznansky 2017). A classic covert operation is the Bay of Pigs. Training fifteen hundred exiles to storm the shores of Cuba to overthrow Fidel Castro was a highly visible act; the sponsor, the United States, was supposed to remain hidden.\n\nFigure 1 presents four different combinations of secret operations with illustrative examples.7 Cases in the northwest quadrant include cyber intrusions that are planned and executed clandestinely and denied by the sponsor. These are what observers typically have in mind when discussing the attribution problem in cyberspace. The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases (Betz and Stevens 2011, 95). Examples in the northeast quadrant are covert because the sponsor denied complicity but are not clandestine since the activities themselves, typically performed by third parties, are not hidden. Examples in the southeast corner include large-scale wars.\n\n4 Betz and Stevens (2011, 95) mention that claiming may be necessary but do not explain why.\nThis is taken from the Department of Defense's Dictionary of Military and Associated Terms, available at http://www.dtic.mil/doctrine/dod/dictionary/. Although this definition is focused on government entities, the same logic applies broadly.\n\n6 This is also taken from the Department of Defense's Dictionary of Military and Associated Terms.\n7 The very existence of this two-by-two signifies that the main variants of secrecy may be used in combination with one another or separately. Covert and clandestine action are cousins, not synonyms.",
            "images": [
              {
                "id": "img-0.jpeg",
                "top_left_x": 712,
                "top_left_y": 180,
                "bottom_right_x": 1265,
                "bottom_right_y": 494,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 3,
            "markdown": "MICHAEL POZNANSKY AND EVAN PERKOSKI\n405\n\n![img-1.jpeg](img-1.jpeg)\nFigure 2. The logic of secrecy in cyberspace\n\nThese are neither covert (the sponsor was known) nor clandestine (the wars were announced in advance).\n\n## Secrecy in Cyberspace\n\nStudents of cyber warfare rarely distinguish between clandestine and covert forms of secrecy. As such, most studies do not explicitly address where secrecy is a de facto requirement rather than a choice in the course of a cyberattack. Figure 2 portrays a stylized schematic of cyber intrusions, capturing two of the key inflection points where actors make decisions about secrecy.\n\nAt  $\\mathrm{T_0}$ , perpetrators decide whether to announce to the target that an attack is imminent or whether they will conceal the operational details as in a clandestine operation. In almost all cases, perpetrators will choose the latter. Doing otherwise is counterproductive since publicizing even the most basic details of a pending operation affords the target an opportunity to enact countermeasures. Announcing that \"[you] will attack this network with this effect unless [the target] refrain[s] from X\" would be \"self-defeating\" (Lindsay 2015, 55). Acting clandestinely raises the likelihood of success by denying victims the chance to take steps that might blunt the efficacy of the attack such as patching a vulnerability or cutting access to servers. This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim.[8] Even when the perpetrator is not relying on zero days,\n\nthey still will not want to announce the exact vector by which the intrusion will occur to avoid jeopardizing the operation.\n\nActors have the most agency when it comes to secrecy and deception after an attack occurs at time  $\\mathrm{T}_{1}$ . Here, perpetrators must decide whether to proceed in a manner consistent with covert action (denying their role) or not (claiming it). Should a perpetrator choose to forgo plausible deniability, they must then decide how to communicate complicity. The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity (Libicki 2009, 50-51; Nye 2017, 51). Perpetrators can do this by leaving clues in the course of the attack—for example, leveraging a vector they have been known to use before, reusing code from a previous intrusion, or otherwise leaving signatures in the source code of malware. Or they might communicate through discrete diplomatic channels with a foreign counterpart (Borghard and Lonergan 2017, 459).\n\nThe second means of communicating complicity, public acknowledgment, refers to a situation where the perpetrator openly pronounces their identity to a much wider audience following an attack. They might make a public statement or alert the media of their culpability. Explaining why some actors intentionally dispense with anonymity—and, for those that do, whether they will credit-claim publicly or privately—is the focus of the next two sections. For now, it will suffice to point out that the attribution problem ceases to exist in cases where the perpetrator willingly makes their identity known.\n\nActors can, and often do, opt to act both clandestinely and covertly in the course of a single operation (Betz and Stevens 2011, 88). Our rationale for distinguishing between the two is to make clear that while clandestinity is a technical requirement of almost all cyber operations the decision to act covertly is something perpetrators consciously select into. In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.[9]\n\nIn what follows, we use these distinctions to address our original puzzle regarding why some actors claim responsibility for operations while others choose to remain anonymous. The next section discusses the politics of credit-claiming for states. We then turn to nonstate actors, a neglected but important player in the cyberspace arena.\n\n8 For a discussion, see Lin (2010, 65n7).\n\n9 Getting caught is still a real possibility, especially for larger operations (Lindsay 2015, 58).",
            "images": [
              {
                "id": "img-1.jpeg",
                "top_left_x": 108,
                "top_left_y": 178,
                "bottom_right_x": 650,
                "bottom_right_y": 730,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 4,
            "markdown": "Rethinking Secrecy in Cyberspace\n\n# States and the Politics of Voluntary Attribution\n\nWhether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion.[10] If success is possible without the target consciously acceding to some demand, states will act covertly and hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission.[11] In terms of how they eventually reveal complicity, we argue that states are most likely to use private channels and discrete communication.\n\n# When States Come Clean\n\nWhen the success of state-sponsored cyber operations does not require target compliance, voluntary credit-claiming is unnecessary at best and counterproductive at worst. In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage.[12] Like any intelligence gathering effort, voluntary attribution would be disadvantageous. Should a perpetrator announce that they have penetrated an adversary's network, they will jeopardize both their intrusion method and continued access without reaping any obvious benefit in return. Preserving anonymity is thus the preferred option for states interested in stealing secrets in cyberspace.\n\nAnother class of cyber operations, political action and sabotage, is also best served by perpetual anonymity. Examples include operations to influence elections through disinformation campaigns, vote manipulation, and the destruction of physical equipment and critical infrastructure. Because the success or failure of these operations does not depend on the target consciously responding to specified incentives, the motivations for states to voluntarily claim credit should be correspondingly low.\n\nThe calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful (Schelling 1966). When operations require that the\n\n10 This distinction is similar to the one Schelling (1966) draws between brute force and coercion. On how qualitatively different types of cyber operations have been conflated, see Betz and Stevens (2011, 81).\n11 The need for target compliance is not the only factor underlying this decision. Whether the action itself violates longstanding norms, would trigger escalation, and the like may factor in as well.\n12 These qualify as computer network exploitation, or CNE (Nye 2017, 47).\n\ntarget accede to a set of demands—either to do something (change the status quo) or to refrain from doing something (preserve the status quo)—states are likely to shun anonymity and engage in voluntary attribution. The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim (Carson and Yarhi-Milo 2017). Remaining anonymous does little to advance these aims. As Liff (2012) notes, “[u]nder most circumstances, any would-be aggressor who does not identify itself forfeits the ability to coerce its adversary” (414). Anonymity makes it hard for targets to evaluate the credibility of a threat and the sender’s resolve. Credit-claiming is thus critical if cyber coercion is to have any chance of succeeding. Betz and Stevens (2011) hint at this: “[W]hen states use military cyber-power against other states for the purposes of compelling them to do their will, they still have to declare what it is (even after the event). There is no sneaky way around this fact” (95). It is worth reiterating, however, that this can only feasibly be done after the attack has ended. As discussed earlier, providing details beforehand could undermine the mission and render the coercive threat impotent.\n\nForgoing anonymity permits states to more effectively make coercive threats by demonstrating credibility and resolve in at least two ways. First, a claimed attack can function as a costly signal by showing the threatening party's willingness to expend valuable resources in the hopes of gaining compliance from the target. According to Borghard and Lonergan (2017), \"[t]he greater the cost to the initiating state of producing a given signal, ceteris paribus, the more effective the signal is as an indication of the initiating state's resolve\" (467).\n\nSecond, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power.[13] Prestige and power, though related, are not the same. The latter refers strictly to capabilities, which can never be fully observed in cyberspace owing to the premium placed on keeping these tools shrouded in secrecy. The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\" (Gilpin 1981, 31).[14] States who cultivate a reputation for cyber power may be able to\n\n13 This is a play on Gilpin (1981, 31).\n14 Interestingly, even if actors do not willingly come clean, successful attribution can still bolster prestige. Consider the Stuxnet worm, allegedly manufactured by US and Israeli operatives and how it reflects on their cyber potential. As one Symantec director noted, \"[i]t seems pretty reasonable to think that there are things out there today that we haven't seen that are much more advanced [than Stuxnet]\" (Szoldra 2016).",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 5,
            "markdown": "MICHAEL POZNANSKY AND EVAN PERKOSKI\n407\n\npersuade adversaries that their threats are credible even if they do not specifically outline the vector they intend to exploit or the zero day they plan to deploy if demands go unmet. A history of successful cyberattacks can offset the invisibility of a state's arsenal.\n\nIt is worth briefly outlining how the dynamics of cyber prestige and coercion could operate in practice. When the goal is to compel a target to alter their behavior, perpetrators may take offensive action in cyberspace, claim credit for it, and threaten future punishment should the target fail to comply. When the goal is to deter some action, perpetrators may similarly be able to take offensive cyber action, claim credit for it, and threaten future punishment should the target act in ways deemed undesirable by the sender. A more plausible situation in the case of cyber deterrence might entail the victim of a recent attack retaliating against the perpetrator, voluntarily claiming credit, and threatening future harm should there be any further attacks against them. In each of these scenarios, cyber coercion is possible to the extent that the target believes the sender's promises of future pain are credible and that the threatener is resolved as a result of having claimed past attacks. It is \"the threat of . . . more damage,\" or the \"expectation of more violence,\" that may induce a target to give in (Schelling 1966, 3; emphasis in original).\n\nThere is obviously no guarantee that claiming credit for past attacks will generate the credibility necessary for coercion. If the target does not believe that the challenger has the ability or willingness to repeat similar or more painful attacks, issuing deterrent or compellent threats after claiming an intrusion with the promise of \"more where that came from\" won't work. Nevertheless, we are skeptical that observers never update their beliefs about an actor's capabilities and resolve, and opt instead to treat every attack as an isolated event. While Russia is unlikely to easily hack the Democratic National Committee again, for example, few observers doubt their capacity to carry out similar attacks in the future. Whether credible coercive threats will actually suffice to achieve concessions, while important in its own right, is a separate matter and depends on a complex cost-benefit calculation.\n\n## Escalation and the Means of Communication\n\nThis section focuses on the right-hand side of Figure 2, after an actor chooses to forgo plausible deniability $(\\mathrm{T}_1)$ and decides whether to claim responsibility publicly or privately. We argue that the unique dynamics of politically motivated, state-on-state cyber activity make public acknowledgment less attractive than private acknowledgment. There are several reasons for this.\n\nAs a general matter, opportunities for retaliation are higher when the actors involved are states. Unlike non-state actors, states are stationary, immobile entities with numerous targets available to hit. Concern about attacks against a state's critical infrastructure have been likened to a potential \"cyber 9/11\" (Maxey 2017).¹⁵ Moreover, perpetrators that publicly announce sponsorship of a cyberattack put the victim—in many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige (Carson and Yarhi-Milo 2017, 135).\n\nBecause the victims of publicly claimed, state-sponsored cyberattacks typically have both the opportunity to retaliate as well as strong domestic-level pressures to do so, nation-states interested in cyber coercion face powerful incentives to quietly claim their actions using private channels. While credit-claiming in private lacks the broader prestige benefits associated with publicity and limits the audience observing an operation's (physical) costly signals, it may nonetheless afford states an opportunity to engage in coercive diplomacy at reduced risk. Recent scholarship shows that states often face powerful incentives to collude with one another in acts of secrecy. For example, Carson (2016) argues that states may opt not to publicize the covert military actions of their rivals even when they are targeted as a way of keeping conflicts limited and contained. A similar logic should apply to discrete attempts at coercion in cyberspace.\n\nOne risk of private acknowledgment is that the victim will \"out\" the perpetrator by publicly announcing the occurrence of an intrusion and offering proof that the attacker sought to privately attribute themselves. While this is always a possibility, such concerns may not wholly disincentivize states from pursuing private acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them (Rid 2012, 28–29). This, in turn, can motivate perpetrators to quietly come clean with little fear of being exposed by the victim. Second, when victims have the capacity to out a state\n\n¹⁵ For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 6,
            "markdown": "Rethinking Secrecy in Cyberspace\n\npursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases.¹⁶ This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity (Yarhi-Milo 2013, 407).\n\n# Nonstate Actors and the Politics of Voluntary Attribution\n\nThe discussion so far has focused on the conditions under which states will claim credit for cyberattacks and why they are more likely to do so privately. This is important for obvious reasons.¹⁷ However, nonstate actors dominate the empirical record of credit-claiming in cyberspace. In what follows, we explain why nonstate actors commonly claim attacks and why they tend to do so publicly.\n\nDrawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means (Nye 2010; Asal et al. 2016). Regardless of their method of contention, nonstate actors are agents of change operating in a structural environment in which they are severely disadvantaged. These groups wield significantly fewer resources than states—financial, material, and otherwise—and their capabilities are consequently more constrained and more uncertain. In addition, what few capabilities nonstate actors do possess are in large part a function of the number of participants they can organize. This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well (Asal and Rethemeyer 2008; Chenoweth and Stephan 2011). The same basic logic extends to nonstate actors operating in cyberspace. One of the most common tools in a group's cyber arsenal, the distributed denial of service (DDoS) attack, grows stronger with every additional user.¹⁸\n\nOur primary claim is that nonstate actors are more likely than states to brazenly claim cyberattacks. Not\n\n¹⁶ See also Carson and Yarhi-Milo (2017, 135).\n¹⁷ On the importance of states for Internet politics, see Rovner and Moore (2017).\n¹⁸ To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.\n\nonly does this help showcase their capabilities, but the media attention can help attract new members to the cause. Additionally, since it is often difficult to bring these groups to justice, organizations like Anonymous, Lulzsec, and others face reduced incentives to keep quiet about their operations.¹⁹ In sum, complicity is a critical component of nonstate actors' strategic logic and they commonly announce sponsorship of cyberattacks as a result.\n\n# The Appeal of Credit-Claiming\n\nNonstate actors typically have coercive objectives. As Schelling wrote in 1973, \"[p]olitical violence, like political nonviolence, usually has as its purpose making somebody do something or not do something or stop doing something. The aim is to influence behavior.\"²⁰ In a broad sense, their goals are comparable to those of states seeking to alter the behavior of their adversaries.\n\nAbove, we argue that a key component of coercion is credibility: can actors issuing coercive threats make good on their promises of more pain if the target resists? This is especially difficult for nonstate actors (Hoffman and McCormick 2004; Kydd and Walter 2006; Dannenbaum 2011). They cannot put on military parades to show off their latest weaponry,²¹ do not have the means to finance modern military forces,²² and lack the resources—territorial, bureaucratic, and financial—of states. It is easy to dismiss the demands of nonstate actors as inconsequential chatter.\n\nGiven these deficits, the issue of how to boost credibility features centrally in the strategic logic of politically motivated nonstate actors. As with states, one way to demonstrate capabilities and resolve is to take action perceived as a costly signal. According to Kydd and Walter (2006), \"[b]ecause it is hard for weak actors to make credible threats, terrorists are forced to display publicly just how far they are willing to go to obtain their desired results\" (50). Similarly, Abrahms (2013) writes that \"[t]errorism . . . adds credibility to threats by showing that nonstate challengers possess the power to hurt\" (661).\n\nFor nonstate cyber warriors, sending costly signals to bolster credibility may include defacing government websites, launching distributed denial of service attacks,\n\n¹⁹ To the extent that they run the risk of capture, however, the credibility of their signals goes up.\n²⁰ Quoted in Sharp and Finkelstein (1973, xx).\n²¹ Doing so might expose their position and invite unwanted risk.\n²² One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 7,
            "markdown": "MICHAEL POZNANSKY AND EVAN PERKOSKI\n409\n\nand so forth. In other words, they are likely to take actions that prove their ability to cause pain or at least disrupt and inconvenience their targets. Although temporarily compromising access to a website will not pack the same symbolic punch as a terrorist attack, employing increasingly sophisticated cyber operations and exploiting consequential vulnerabilities helps nonstate groups elevate the costliness of their signals and more readily demonstrate credibility and resolve (Borghard and Lonergan 2017, 466–67).\n\nA history of successful attacks by a nonstate group can also help cultivate their prestige in much the same way it does for states. As such, nonstate actors stand to lose by not identifying their organization as responsible for an attack. Failing to communicate culpability negates an operation’s objectives and precludes nonstate actors from reaping signaling and reputational benefits that are critical to successful coercion. Without knowing who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities.²³ It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own (Bloom 2005, 78–79).²⁴\n\n## Maximizing Publicity\n\nThe notion that nonstate actors are more likely to claim attacks to showcase their capabilities and resolve mirrors a similar motivation among states interested in cyber coercion. Where the two diverge is in the preferred method of claiming. Several factors make nonstate actors more likely to choose public rather than private acknowledgment.\n\nOne reason nonstate cyber warriors crave the limelight hinges on the audiences they seek to influence. These\n\n²³ It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.\n\n²⁴ Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).\n\ngroups are often interested in sending a message not just to adversarial governments but to their populations as well. The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance (Schmid 2004). As Crenshaw (1981) notes in a related context, “[t]he victims or objects of terrorist attack have little intrinsic value to the terrorist group but represent a larger human audience whose reaction the terrorists seek” (379).\n\nUltimately, terrorists target the public since they are too weak to confront the state head-on. The same should be true of nonstate actors in cyberspace since these groups face comparable disadvantages. For such a strategy to work, however, communication cannot be private; it must be visible, clearly attributed, and widely known to the government and public alike.\n\nA second reason nonstate actors in cyberspace prefer public methods of claiming credit turns on their desire to attract new recruits. Like their traditional counterparts, these actors are interested in survival and growth. According to Pape (2005), “terrorism has two purposes—to gain supporters and to coerce opponents. Most terrorist campaigns seek both goals to some extent, often aiming to change the target state’s policies while simultaneously mobilizing support and recruits for the terrorists’ cause” (7). Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization (Abrahms 2008, 379) and augment their coercive ability. It is well established that the power of civil resistance flows from mobilization numbers, and the same goes for organizations in cyberspace. When it comes to their operating methods, these groups favor tactics that grow more powerful with additional bots and active supporters. The strength of DDoS operations, for instance, is linked to the number of machines involved (Ghosemajumder 2016).²⁵ The Low Orbit Internet Cannon (LOIC) and related variants draw strength from those who download the application and flood a server. With more members at their disposal, groups are able to launch increasingly formidable cyber operations.²⁶\n\n²⁵ On the determinants of DDoS attacks, see Asal et al. (2016).\n\n²⁶ It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 8,
            "markdown": "Rethinking Secrecy in Cyberspace\n\n# Plausibility Probes\n\nA lack of readily-accessible decision-making documents complicates rigorous empirical tests of our argument. If we are right that state-sponsored cyber operations involving espionage and sabotage are prime candidates for secrecy before, during, and after execution, it might be decades or longer before relevant materials are declassified.27 While coercive cyber operations are more likely to involve credit-claiming, the advantages of claiming attacks privately also impede observation. In fact, outsiders might be unable to discern differences between victims who are truly ignorant of their attacker's identity and those that feign ignorance while privately communicating with their attackers.\n\nAs a second-best strategy, we examine publicly available sources including news reports and a range of secondary materials to provide a preliminary test of our argument. We also conduct two interviews: one with a former Defense Department official involved in cyber policy and one with a former member of Anonymous. These helped corroborate what we found in the public record.\n\n# States\n\nWe were unable to find a single case of a state claiming credit for a cyber espionage operation, either openly or privately. Rather, the cases that have inadvertently come to light underscore the vigor with which states seek to avoid being named. China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative (Nakashima 2015). In the aftermath of the intrusion, Chinese officials denied complicity, placing blame on criminal hackers. They even went so far as to claim that they had arrested individuals who were connected with the hack (Chalfant 2017).28 Another example is Russia's alleged interference in the 2016 US election. The \"theft of research and emails from the Democratic National Committee\" for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government (Sanger 2016).29\n\n27 This is especially true when it comes to documents pertaining to intelligence activities, which may stay classified for longer owing to concerns about sources and methods.\n\n28 See also Yan (2015). While it is technically possible that Chinese officials privately communicated complicity to the United States, this is unlikely since it serves no real strategic purpose.\n\n29 One might reasonably categorize this episode as political action wherein the Russians disseminated stolen\n\nWhen asked in March 2017 about whether Russia was behind the efforts to discredit Hillary Clinton, Putin responded with \"Read my lips: No\" (Lister, Ilyushka, and Gigova 2017). When it comes to cyber espionage, there is no benefit to be had from credit-claiming.\n\nStuxnet provides a useful illustration of why decision-makers sometimes cling to anonymity and, more interestingly, the conditions under which they might be willing to voluntarily claim credit.30 Stuxnet, formally known as \"Olympic Games,\" was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant (Farwell and Rohozinski 2011). The aim was to make the Iranians believe their centrifuges were failing for reasons other than foreign interference. Sanger (2012) writes the following: \"When the centrifuges first began crashing in 2008 at the Natanz enrichment center, the crown jewel of the Iranian nuclear program, the engineers inside the plant had no clue they were under attack. That was exactly what the designers of the world's most sophisticated cyberweapon had planned.\" He continues that \"[t]he idea, hatched in Washington and Jerusalem, was to make the first breakdowns seem like random accidents and small ones at that\" (188).\n\nSanger's interviews with government officials confirm that the operation was supposed to leave no trace of US fingerprints: \"The most elegant cyber weapons are a lot like the most elegant bank frauds. . . . They work best when the victim doesn't even know he's been robbed\" (190-91). It is clear from this account that the United States kept both the operation and their sponsorship intentionally hidden, as our argument predicts. The success or failure of the operation did not depend on Iran changing their behavior, but simply hinged on the quiet destruction of centrifuges.\n\nInterestingly, though, some US operatives contemplated quietly alerting the Iranians that the United States was responsible for the attack. Their apparent rationale conforms to our theoretical expectation. Ostensibly, the goal would have been to send a message to Tehran that the United States had the ability to keep targeting their systems, presumably as a way of achieving concessions on the nuclear program. According to Sanger (2012), \"[a]t both the Pentagon and inside the intelligence agencies some of the creators of the bug believed that it might be\n\ninformation to relevant entities who could use it to discredit Hillary Clinton. Even if so, this type of action would qualify as a classic covert operation, and thus we would still expect Russian denials.\n\n30 For a full-length treatment of the dynamics underlying the operation, see Lindsay (2013) and Rid (2012).",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 9,
            "markdown": "MICHAEL POZNANSKY AND EVAN PERKOSKI\n411\n\neven more valuable if the source of the attacks became known, because the Iranians would get the message that Washington could pierce its systems repeatedly.\" One official directly involved in decision-making noted, \"[w]e had to be ready to work in an environment where the Iranians knew exactly who was doing this to them, to make the point that we could come back and do it again\" (203). In short, some policymakers believed they could more easily alter the Iranian regime's behavior by embracing responsibility and proving that they could bring more pain to bear should they continue down the path of nuclearization.[31]\n\nMore recent examples suggest that states are thinking hard about voluntarily claiming credit for their cyber operations in the service of coercion. In late September 2017, it came to light that the Trump administration authorized US Cyber Command to carry out a range of limited cyberattacks against North Korea's Reconnaissance General Bureau intended to interfere with Internet access (DeYoung, Nakashima, and Rauhala 2017). Most importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy.[32] Panda (2017) argues that the United States had \"take[n] the cyber equivalent of a shot across North Korea's bow, presumably signaling that it has the requisite access to North Korean networks to deliver considerably more significant damage in wartime.\" Since North Korea is not wanting for enemies, it seemed to serve US objectives to let their complicity be known, thereby reducing ambiguity about what behavioral changes were expected from the Kim regime.\n\nFurther evidence for our theory comes from recent statements by Shawn Turskey, the executive director of US Cyber Command. His comments from 2016 indicate that the United States government is contemplating ways to leverage cyber capabilities for coercive purposes,\n\n31 One interesting avenue for future research is to explore how the desire to claim credit for certain operations, especially sabotage, may be driven in part by which agency is responsible for conducting the attack. We might expect, for example, the military to more readily embrace complicity and the intelligence community to do the opposite.\n\n32 The White House and Cyber Command declined to comment, but a senior administration official told the Washington Post that \"[w]hat I can tell you is that North Korea has itself been guilty of cyberattacks, and we are going to take appropriate measures to defend our networks and systems\" (DeYoung et al. 2017).\n\nspecifically through intentional credit-claiming. Turskey declared the following:\n\nIn the intelligence community you never want to be caught, you want [to] be low and slow, you never really want to be attributed. . . . But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know. (Bing 2016, emphasis added)\n\nThese remarks are noteworthy for several reasons.[33] Chief among them is the prospect of the world's lone superpower developing an arsenal of cyber weapons with a return address. The fact that loud, attributable weapons are being discussed at all is at odds with the typical portrayal of cyberspace as a domain defined by secrecy and anonymity. Yet, it is easier to understand why Turskey is contemplating this shift once we come to terms with the mechanics of cyber coercion. Leveraging cyber assets for coercive purposes, rather than espionage or sabotage—which fits more readily within the purview of the military as opposed to the intelligence community—requires credible self-attribution. Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal (Lin 2016).\n\nMichael Sulmeyer, the former director for Plans and Operations for Cyber Policy in the Office of the Secretary of Defense, affirmed this sentiment in an interview for this article. Echoing the idea that cyber weapons can and should be embraced for more traditional purposes, he highlights the following:\n\nIt is important for the United States to invest in capabilities that not only help it improve its espionage activities against adversaries, but also that help it prevail in the event of hostilities with adversaries. When operating in the realm of the second objective, it can be beneficial for the United States to take responsibility for its actions publicly—not to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.[34]\n\nTaking responsibility, as Sulmeyer suggests, provides America's adversaries the chance to understand the extent of their cyber power. Similar to Turskey, Sulmeyer anticipates that more voluntary credit-claiming may be on the horizon:\n\n33 For a discussion of these comments, see Lin (2016).\n34 Interview with authors, October 26, 2017.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 10,
            "markdown": "Rethinking Secrecy in Cyberspace\n\nTo be sure, this signal could be missed or dismissed—and a mere tap on the digital shoulder clearly would not suffice for such a signal to be internalized. But why go through all the effort to hide every action every time in this context? That's an unnecessary additional burden in a war fight. If there are a suite of capabilities that can help our forces be more agile during hostilities, I would hope they are on the table for our commanders and leaders in the future.³⁵\n\n## Nonstate Actors\n\nThe empirical pattern of cyberattacks by nonstate actors differs from what we observed for states. These actors frequently claim credit for their cyberattacks in very public ways. Much like terrorist attacks, these operations almost always entail a political message intended to alter public opinion, change government policies, and the like. A cyberattack carried out by the Syrian Electronic Army against the US Army's website showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion (Vinton 2015). Quietly alerting the US Army that the Syrian Electronic Army was behind the attacks would have undermined the strategic motivations underlying the entire operation, namely bolstering their reputation as a group that deserves respect and sending a clear message with the intention of affecting public opinion and altering policy. The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list (Temperton 2016).\n\nFor a more complete picture of the decision-making process for nonstate actors in cyberspace, we briefly examine one of the most well-known organizations: Anonymous. Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article (Olson 2012; Coleman 2014). Anonymous’ behavior following this shift, though, sheds light on the group’s political strategy and how publicity and attention serve their goals.\n\nA cursory overview of Anonymous’ exploits over the years shows that the group commonly claims credit publicly for its operations. In late March 2016, Anonymous targeted roughly twenty Angolan government websites in response to the arrest of several activists. Prior to carrying out the attack, they posted details about the websites\n\nthey intended to target (British Broadcasting Company 2016). In one of their biggest and best-known campaigns, Operation Tunisia, the group first put out a press release via YouTube³⁶ before a launching series of DDoS attacks that took down numerous government-linked websites. This was part of a broader operation intended to assist protesters and weaken the government of Ben Ali. Most relevant for our purposes, the group issued a clear coercive threat: “This is a warning to the Tunisian government: attacks at the freedom of speech and information of its citizens will not be tolerated. . . . Free the net, and the attacks will cease, keep on that attitude and this will just be the beginning”³⁷ In another high-profile incident, Anonymous targeted the Church of Scientology. As before, the attack began with a YouTube press release³⁸ and proceeded with a series of DDoS attacks, doxing, and more press releases and media statements. In line with our expectations, the IT company hired by the Church of Scientology implored them to simply ignore the attacks: “Don’t issue warnings or threats to the attackers via the media; this will only keep the issue alive, raise tempers, and greatly increase the possibility of another assault. Most DDoS attackers seek publicity, so don’t hand it to them on a silver platter.”³⁹ Their solution was to deprive Anonymous of what it wanted most, namely attention.\n\nThis strategy of pursuing highly visible, self-attributed missions served at least three functions. First, Anonymous used these operations to ensure that they were taken seriously and that their coercive threats were not ignored. Establishing their capabilities, resolve, and credibility by conducting attacks with clear attribution contributed to this effort. This was explicit in their internal conversations during the operation against the Church of Scientology. As one member put it, “I think it’s time for [us] to do something big. People need to understand not to f*** with [Anonymous].”⁴⁰ These and other attacks proved somewhat successful. Outside observers came to understand that they should not dismiss the group’s threats. Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility” (Olson 2012, 177).\n\nSecond, Anonymous recognized that part of their strategy revolved around the public. During Operation Payback in 2010, which aimed to promote Internet privacy by targeting antipiracy groups, members of\n\n³⁵ See https://www.youtube.com/watch?v=BFLaBRk9wY0.\n³⁶ Quoted in Coleman (2014, 149).\n³⁷ See https://www.youtube.com/watch?v=JCbKv9yiLiQ.\n³⁸ Quoted in Olson (2012, 89).\n³⁹ Quoted in Olson (2012, 2).\n\nInterview with authors, October 26, 2017.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 11,
            "markdown": "MICHAEL POZNANSKY AND EVAN PERKOSKI\n\nAnonymous ardently debated this component of their strategy. Support eventually developed for one member who claimed that “... these attacks are less about hurting the business than drawing attention and forcing the media to cover the story. . . . The point for me is that this is the technological way of mass protesting that’s actually effective.”41 Getting their message out to the public to garner attention became a core objective.\n\nAnonymous’ operations often did more than just influence the public indirectly via messaging; sometimes the public was the direct target of attacks. Anonymous, like most terrorist groups, eventually had to reconcile with the fact that targeting innocent civilians might be useful for achieving their aims. This issue came to a head during Operation BART (Bay Area Rapid Transit), when members leaked information on individual passengers, including credit card numbers and other details from the company’s website. When asked about the incident by a reporter, a senior member replied, “[h]ow else do you get the world to respond and secure your information? How else do you get these companies and these big governments to keep your information, the information you give them voluntarily, safe? I think we got our message across, and I’ll bet you one thing: I’ll bet you they fix that.”42 Anonymous’ symbolic, essentially random targeting was part of a broader campaign to influence public opinion and achieve political change. Their cyberattacks were acts of coercion that bore a striking resemblance to the strategic logic of militant organizations.\n\nFinally, Anonymous’ cyber behavior was often geared toward generating new members and deepening support among their base. In an interview conducted for this article, we asked Hector Monsegur, a former leader of Anonymous known as Sabu, why the group was so eager to publicly claim their operations. As he put it,\n\nAt the time of its height (not so much now) Anonymous had gained huge successes in publicizing its protests, hacks, and engagements. They were masterful in the distribution of content, and the media truly ate it up for several reasons:\n\nIt was neatly packaged and ready for distribution, the hackers were willing to give interviews, and of course the mystery element. The whole thing about the mask and shadowy figures really “sells” the concept. As Anonymous grew in action, it also grew in numbers and support . . .\n\nThe truth of the matter is that Anonymous needed the media to grow, and this explains why many of the\n\nthings we did were really attention-grabbing. It served a purpose. It’s very similar to branding and how companies slip in their products into film, or events in general, even if each engagement or hack had different motivations.43\n\nIn her research on Anonymous, Coleman (2014) expands on this point: “[W]ithout the appearance of a critical mass, the operation would have likely lacked moral gravitas and authority. In this case, strength in numbers conveyed a potent message” (138). Expanding their membership didn’t just provide Anonymous legitimacy; it provided additional capability as well. While many of Anonymous’ DDoS campaigns relied on botnets to create their desired effect, individual users sustained those attacks that used the freeware LOIC, a staple of the group’s earlier activity. This required the group to invest time in assisting new members with the software. Olson (2012) points out that the group felt it was worth it to take the time “getting the [new members] on board to create an army” (65).\n\nUltimately, it was in Anonymous’ interest to take credit for their cyber operations through highly visible, public means of communication. Doing so rewarded their efforts significantly and was instrumental to their strategic logic. Whether the target was the Tunisian government or the Church of Scientology, the attention they received bolstered their particular brand of coercion. This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance (Coleman 2014, 107).\n\n## Cybercrime and Cyber Blackmail\n\nBefore concluding, it is worth flagging two types of cyber operations perpetrated by state and nonstate actors alike that are unlikely candidates for voluntary attribution. The first are operations involving theft of financial or intellectual assets. These are among the most common kind of cyberattack and are ill-served by credit-claiming. Malicious actors that leverage cyber assets for criminal purposes, such as stealing money from banking institutions, have little incentive to self-attribute. Doing so would provide little benefit and expose them to potential prosecution. While nonstate actors most commonly conduct these kinds of attacks, states may as well. For example, North Korea was identified as the responsible party in a cyber heist against Bangladesh’s central bank. Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million (Finkle 2017).\n\n41 Quoted in Coleman (2014, 132).\n\n42 Quoted in Coleman (2014, 307).\n\n43 Interview with authors, October 30, 2017.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 12,
            "markdown": "Rethinking Secrecy in Cyberspace\n\nA second unlikely candidate for voluntary attribution is what we might call “cyber blackmail,” or operations in which the perpetrator leverages stolen assets, embarrassing secrets, and the like to achieve compliance from the victim without having to reveal their true identity.⁴⁴ These operations are particularly interesting in that success requires target compliance—which we argue should lead to credit-claiming—but the perpetrator can remain behind a mask. By selectively releasing compromised information and assets to the victim publicly or privately (Lindsay 2015, 57), the perpetrator may be able to force compliance while remaining anonymous or hiding behind front groups.\n\nThis dynamic approximates what might have happened during the Sony hack, in which the “Guardians of Peace” (#GOP) issued an explicit compellent threat against Sony in an attempt to prevent the company from releasing The Interview, a comedy satirizing North Korea’s leader Kim Jong Un. In the event that Sony failed to comply with #GOP’s demands, the group threatened to release propriety information and potentially embarrassing e-mail correspondences between high-level employees. Although North Korea was widely suspected of sponsoring the attack, the regime denied any involvement. Nonetheless, the attack partially succeeded in coercing Sony without the government having to explicitly take credit.⁴⁵ We believe that the attack was partially successful as a result of Sony’s understanding that certain assets (personal e-mails, financial records) had indeed been compromised and would be released should they fail to comply.\n\n## Conclusion\n\nThis article draws on existing theory to develop an explanation for why states and politically motivated non-state actors might voluntarily claim credit for their attacks. We argue that the goals of an operation as well as the characteristics of the perpetrator drive both the decision to claim credit as well as the manner in which culpability is communicated. This research has several important implications. First, we show how states and nonstate actors share a common set of choices with regards to secrecy in cyberspace. Both face the same decisions at the same points in the life cycle of a cyberattack, yet the characteristics of each can cause their strategies to diverge, particularly when it comes to the optics of credit-claiming. Future research should continue to investigate how the characteristics and operational and strategic goals of cyber actors influence the look and feel of their cyber actions.\n\nSecond, existing research often treats cyber operations as distinct from more traditional elements of state power. Although there are differences, the framework developed here suggests that states may be able to leverage cyber assets to achieve many of the same goals most frequently pursued with conventional forces. Scholars have pushed back against this idea for a variety of reasons, one being the attributional difficulties of cyber operations. But states need not conceal their complicity in perpetuity. By relaxing this assumption, we can more easily see how these operations fit into a state’s coercive toolkit. One area ripe for future research is the efficacy of coercion in cyberspace, both on its own and in comparison to more conventional methods.\n\nFinally, while inferring intentions from behavior is problematic, actors’ decisions to privately or publicly acknowledge sponsorship of an attack may provide crucial information about motives and identity. Clinging to covert forms of secrecy after the completion of an attack might highlight a set of plausible underlying motivations for the initial intrusion, including espionage, cybercrime, and the like. Conversely, if the actor does come clean, it might be appropriate to infer that credibility, prestige, or coercion was the true goal. In the information-starved domain that is cyberspace, these clues may be all there is when designing policies and crafting responses.\n\n## Acknowledgements\n\nThis is one of several collaborative projects by the authors, and the ordering of names follows a principle of rotation. We are grateful to Joseph Brown, Ben Buchanan, Ryan Evans, Robert Jervis, Joseph LaPalombara, Herb Lin, Jon Lindsay, Joseph Nye, Joshua Rovner, and Michael Sulmeyer for helpful comments, suggestions, and insights. An earlier version of the argument presented here appeared in War on the Rocks.\n\n## References\n\nAbrahms, Max. 2008. “What Terrorists Really Want: Terrorist Motives and Counterterrorism Strategy.” *International Security* 32 (4): 78–105.\n\nA related tactic that might incentivize target compliance without voluntary attribution involves the use of ransomware. A recent example of this was the WannaCry attack in May 2017 (Perlroth and Sanger 2017).\n\n⁴⁴ A related tactic that might incentivize target compliance without voluntary attribution involves the use of ransomware. A recent example of this was the WannaCry attack in May 2017 (Perlroth and Sanger 2017).\n\n⁴⁵ We refer to this as a partial success since Sony ultimately released The Interview after initially delaying in immediate aftermath of the hack.\n\n⁴⁶ 2013. “The Credibility Paradox: Violence as a Double-Edged Sword in International Politics.” *International Studies Quarterly* 57 (4): 660–71.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 13,
            "markdown": "MICHAEL POZNANSKY AND EVAN PERKOSKI\n415\n\nAbrahms, Max, and Justin Conrad. 2017. \"The Strategic Logic of Credit Claiming: A New Theory for Anonymous Terrorist Attacks.\" *Security Studies* 26 (2): 279–304.\n\nAsal, Victor, Jacob Mauslein, Amanda Murdie, Joseph Young, Ken Cousins, and Chris Bronk. 2016. \"Repression, Education, and Politically Motivated Cyberattacks.\" *Journal of Global Security Studies* 1 (3): 235–47.\n\nAsal, Victor, and R. Karl Rethemeyer. 2008. \"The Nature of the Beast: Organizational Structures and the Lethality of Terrorist Attacks.\" *Journal of Politics* 70 (2): 437–49.\n\nAxelrod, Robert. 1979. \"The Rational Timing of Surprise.\" *World Politics* 31 (2): 228–46.\n\nBaum, Matthew. 2004. \"Going Private: Public Opinion, Presidential Rhetoric, and the Domestic Politics of Audience Costs in U.S. Foreign Policy Crises.\" *Journal of Conflict Resolution* 48 (5): 603–31.\n\nBetz, David J., and Tim Stevens. 2011. *Cyberspace and the State: Toward a Strategy for Cyber Power*. New York: Routledge.\n\nBing, Chris. 2016. \"U.S. Cyber Command Director: We Want 'Loud,' Offensive Cyber Tools.\" *FedScoop August* 30.\n\nBloom, Mia. 2005. *Dying to Kill: The Allure of Suicide Terror*. New York: Columbia University Press. https://www.fedscoop.com/us-cyber-command-offensive-cybersecurity-nsa-august-2016/.\n\nBorghard, Erica D., and Shawn W. Lonergan. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452–81.\n\nBritish Broadcasting Company. 2016. \"Anonymous' Hackers Cyber-Attack Angolan Government.\" *BBC News*, March 30. https://www.bbc.com/news/world-africa-35927474.\n\nBrown, Jonathan N. 2014. \"The Sound of Silence: Power, Secrecy, and International Audiences in US Military Basing Negotiations.\" *Conflict Management and Peace Science* 31 (4): 406–31.\n\nBuchanan, Ben. 2017. *The Cybersecurity Dilemma: Hacking, Trust, and Fear Between Nations*. Oxford and New York: Oxford University Press.\n\nCarson, Austin. 2016. \"Facing Off and Saving Face: Covert Intervention and Escalation Management in the Korean War.\" *International Organization* 70 (1): 103–31.\n\nCarson, Austin, and Keren Yarhi-Milo. 2017. \"Covert Communication: The Intelligibility and Credibility of Signaling in Secret.\" *Security Studies* 26 (1): 124–56.\n\nChalfant, Morgan. 2017. \"FBI Arrests Chinese National Linked to OPM Hack Malware.\" *The Hill*, August 24. http://thehill.com/policy/cybersecurity/347897-fbi-arrestschinese-national-linked-to-opm-hack-malware-report.\n\nChenoweth, Erica, and Maria J. Stephan. 2011. *Why Civil Resistance Works The Strategic Logic of Nonviolent Conflict*. New York: Columbia University Press.\n\nColeman, Gabriella. 2014. *Hacker, Hoaxer, Whistleblower, Spy: The Many Faces of Anonymous*. London: Verso.\n\nCrenshaw, Martha. 1981. \"The Causes of Terrorism.\" *Comparative Politics* 13 (4): 379–99.\n\nDannenbaum, Tom. 2011. \"Bombs, Ballots, and Coercion: The Madrid Bombings, Electoral Politics, and Terrorist Strategy.\" *Security Studies* 20 (3): 303–49.\n\nDeYoung, Karen, Ellen Nakashima, and Emily Rauhala. 2017. \"Trump Signed Presidential Directive Ordering Actions to Pressure North Korea.\" *Washington Post*, September 30. https://www.washingtonpost.com/world/national-security/trump-signed-presidential-directive-ordering-actions-to-pressure-north-korea/2017/09/30/97c6722a-a620-11e7-b14f-f41773cd5a14_story.html.\n\nDownes, Alexander B., and Mary L. Lilley. 2010. \"Overt Peace, Covert War?: Covert Intervention and the Democratic Peace.\" *Security Studies* 19 (2): 266–306.\n\nFarwell, James P., and Rafal Rohozinski. 2011. \"Stuxnet and the Future of Cyber Warfare.\" *Survival: Global Politics and Strategy* 53 (1): 23–40.\n\nFinkle, Jim. 2017. \"Cyber Security Firm: More Evidence North Korea Linked to Bangladesh Heist.\" *Reuters*, April 3. https://www.reuters.com/article/us-cyber-heist-bangladesh-northkorea/cyber-security-firm-more-evidence-north-korea-linked-to-bangladesh-heist-idUSKBN1752I4.\n\nForsythe, David P. 1992. \"Democracy, War, and Covert Action.\" *Journal of Peace Research* 29 (4): 385–95.\n\nGartzke, Erik. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.\" *International Security* 38 (2): 41–73.\n\nGartzke, Erik, and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" *Security Studies* 24(2): 316–48.\n\nGhosemajumder, Shuman. 2016. \"Here's Why Massive Website Outages Will Continue Happening.\" *Recode*, October 24. https://www.recode.net/2016/10/24/13393922/ddos-attack-denial-service-cybercriminals-hackers.\n\nGibbs, David N. 1995. \"Secrecy and International Relations.\" *Journal of Peace Research* 32 (2): 213–28.\n\nGilpin, Robert. 1981. *War and Change in World Politics*. Princeton, NJ: Princeton University Press.\n\nGosk, Stephanie, Tom Winter, and Tracy Connor. 2015. \"Iranian Hackers Claim Responsibility for Cyberattack on New York Dam.\" *NBC*, December 23. https://www.nbcnews.com/news/us-news/iranian-hackers-claim-cyber-attack-new-york-dam-n484611.\n\nGross, Richard C. 2009. \"Different Worlds: Unacknowledged Special Operations and Covert Action.\" Technical report, Strategy Research Project, US Army War College.\n\nHoffman, Bruce, and Gordon H. McCormick. 2004. \"Terrorism, Signaling, and Suicide Attack.\" *Studies in Conflict and Terrorism* 27 (4): 243–81.\n\nJoseph, Michael F., and Michael Poznansky. 2018. \"Media Technology, Covert Action, and the Politics of Exposure.\" *Journal of Peace Research* 53(3): 320–335.\n\nKibbe, Jennifer D. 2007. \"Covert Action and the Pentagon.\" *Intelligence and National Security* 22 (1): 57–74.\n\nKydd, Andrew H., and Barbara F. Walter. 2006. \"The Strategies of Terrorism.\" *International Security* 31 (1): 49–80.\n\nLibicki, Martin C. 2009. *Cyberdeterrence and Cyberwar*. Santa Monica, CA: RAND Corporation.\n\nLiff, Adam P. 2012. \"Cyberwar: A New Absolute Weapon? The Proliferation of Cyberwarfare Capabilities and Interstate War.\" *Journal of Strategic Studies* 35 (3): 401–28.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          },
          {
            "index": 14,
            "markdown": "Rethinking Secrecy in Cyberspace\n\nLin, Herb. 2010. \"Offensive Cyber Operations and the Use of Force.\" Journal of National Security Law and Policy 4 (63): 63-86.\n—. 2016. \"Developing 'Loud' Cyber Weapons.\" Lawfare, September 1. https://www.lawfareblog.com/developing-loud-cyber-weapons.\nLindsay, Jon R.. 2013. \"Stuxnet and the Limits of Cyber Warfare.\" Security Studies 22 (3): 365-404.\n—. 2015. \"Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence Against Cyberattack.\" Journal of Cybersecurity 1 (1): 53-67.\nLister, Tim, Mary Ilyushka, and Radina Gigova. 2017. \"Putin Slams US Election Meddling Claim As 'Lies.'\" CNN, March 30. https://www.cnn.com/2017/03/30/politics/putin-russia-us-election-denial/index.html.\nMahoney, James. 2015. \"Process Tracing As Historical Explanation.\" Security Studies 24 (2): 200-18.\nMaxey, Levi. 2017. \"Homeland Security Council Urges Action Before Cyber 9/11 Strikes.\" *Cipher Brief*, August 27. https://www.thecipherbrief.com/homeland-security-council-urges-action-cyber-911-strikes.\nNakashima, Ellen. 2015. \"Hacks of OPM Databases Compromised 22.1 Million People, Federal Authorities Say.\" Washington Post, July 9. https://www.washingtonpost.com/news/federal-eye/wp/2015/07/09/hack-of-security-clearances-system-affected-21-5-million-people-federal-authorities-say/.\nNye, Joseph S. 2010. Cyber Power. Cambridge, MA: Belfer Center for Science and International Affairs, Harvard Kennedy School.\n—. 2017. \"Deterrence and Dissuasion in Cyberspace.\" International Security 41 (3): 44-71.\nOlson, Parmy. 2012. We Are Anonymous: Inside the Hacker World of LulzSec, Anonymous, and the Global Cyber Insurgency. New York: Back Bay Books.\nPanda, Ankit. 2017. \"How to Make Sense of Offensive US Cyber Operations Against North Korean Military Intelligence.\" Diplomat, October 2. https://thediplomat.com/2017/10/how-to-make-sense-of-offensive-us-cyber-operations-against-north-korean-military-intelligence/.\nPape, Robert A. 2005. Dying to Win: The Strategic Logic of Suicide Terrorism. New York: Random House Trade Paperbacks.\nPerlroth, Nicole, and David E. Sanger 2017. \"Hacks Raise Fear Over N.S.A.'s Hold on Cyberweapons.\" New York Times, June 28. https://www.nytimes.com/2017/06/28/technology/ransomware-nsa-hacking-tools.html.\nPoznansky, Michael. 2015. \"Stasis Or Decay? Reconciling Covert War and the Democratic Peace.\" International Studies Quarterly 59 (4): 815-26.\nRid, Thomas. 2012. \"Cyber War Will Not Take Place.\" Journal of Strategic Studies 35 (1): 5-32.\nRid, Thomas, and Ben Buchanan. 2015. \"Attributing Cyberattacks.\" Journal of Strategic Studies 38 (1-2): 4-37.\nRovner, Joshua, and Tyler Moore. 2017. \"Does the Internet Need a Hegemon?\" Journal of Global Security Studies 2 (3): 184-203.\n\nSanger, David E. 2012. Confront and Conceal: Obama's Secret Wars and Surprising Use of American Power. New York: Broadway Paperbacks.\n—. 2016. \"U.S. Wrestles with How to Fight Back Against Cyberattacks.\" New York Times, July 30. https://www.nytimes.com/2016/07/31/us/politics/us-wrestles-with-how-to-fight-back-against-cyberattacks.html.\nSanger, David E., David D. Kirkpatrick, and Nicole Perlroth. 2017. \"The World Once Laughed At North Korean Cyberpower. No More.\" New York Times October 15. https://www.nytimes.com/2017/10/15/world/asia/north-korea-hacking-cyber-sony.html.\nSchelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale University Press.\nSchmid, Alex P. 2004. \"Frameworks for Conceptualizing Terrorism.\" *Terrorism and Political Violence* 16 (2): 197-221.\nSharp, Gene, and Marina Finkelstein. 1973. Dynamics of Nonviolent Action. 3rd ed. Boston, MA: P. Sargent Publisher.\nSlantchev, Branislav L. 2010. \"Feigning Weakness.\" International Organization 64 (3): 357-88.\nSlayton, Rebecca. 2017. \"What Is the Cyber Offense-Defense Balance? Conceptions, Causes, and Assessment.\" International Security 41 (3): 72-109.\nSmith, Candace. 2016. \"Anonymous Claims to Hack Donald Trump.\" ABC News, March 17. https://abcnews.go.com/US/anonymous-claims-hack-donald-trump/story?id=37730049.\nStoller, Daniel R. 2017. \"Cybercriminals Taking the Reins from Nation-State Adversaries.\" *Bloomberg Law: Privacy and Data Security Blog* December 8. https://www.bna.com/cybercriminals-taking-reins-b73014472953/.\nSzoldra, Paul. 2016. \"A New Film Gives a Frightening Look at How the US Used Cyberwarfare to Destroy Nukes.\" Business Insider, July 7. https://www.businessinsider.com/zero-days-stuxnet-cyber-weapon-2016-7.\nTemperton, James. 2016. \"FBI Adds Syrian Electronic Army Hackers to Most Wanted List.\" Wired, March 23. https://www.wired.co.uk/article/syrian-electronic-army-fbi-most-wanted.\nValeriano, Brandon, and Ryan C. Maness 2014. \"The Dynamics of Cyber Conflict Between Rival Antagonists, 2001-11.\" Journal of Peace Research 51 (3): 347-60.\n—. 2015. Cyber War Versus Cyber Realities: Cyber Conflict in the International System. Oxford and New York: Oxford University Press.\nVinton, Kate. 2015. \"Syrian Electronic Army Claims Responsibility For Hacking U.S. Army Website.\" Forbes, June 8. https://www.forbes.com/sites/katevinton/2015/06/08/syrian-electronic-army-claims-responsibility-for-hacking-army-website/.\nYan, Sophia. 2015. \"China Blames Criminals for U.S. Government Hack.\" CNN, December 2. https://money.cnn.com/2015/12/02/technology/china-hack-denial/index.html.\nYarhi-Milo, Keren. 2013. \"Tying Hands Behind Closed Doors: The Logic and Practice of Secret Reassurance.\" Security Studies 22: 405-35.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2000,
              "width": 1375
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 15,
          "doc_size_bytes": 397901
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "Journal of Global Security Studies, 3(4), 2018, 402-416\ndoi: 10.1093/jogss/ogy022\nResearch Article\nOXFORD\n# Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\nMichael Poznansky¹ and Evan Perkoski²\n¹University of Pittsburgh and ²University of Connecticut\n## Abstract\nCyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain.\nKeywords: cyber warfare, secrecy, coercion, nonstate actors\n## Introduction\nSecrecy is a defining feature of cyberspace. Cyber intruders can frequently disrupt networks, steal financial assets, and conduct espionage without ever revealing their identities. Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence (Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017) to its influence on the dynamics of conflict and escalation (Gartzke 2013; Buchanan 2017). Yet, while cyber intruders have ample opportunities to keep their sponsorship a secret, not all choose to take advantage. To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions (Smith 2016). They are not alone; SOBH Cyber Jihad, based in Iran, claimed credit for hacking into the control system of a dam in New York (Gosk, Winter, and\nConnor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015 (Vinton 2015).\nWhy do some actors claim responsibility for cyber operations while others opt for anonymity? To answer this question, we explore the logic of credit-claiming for two key sets of actors in cyberspace: states and politically motivated nonstate actors (hereafter, nonstate actors).¹\nWe argue that credit-claiming, including the manner in which culpability is communicated, depends on what the intruder wants to accomplish. For states, credit-claiming is most appealing during operations that require target compliance, otherwise known as cyber coercion. When states choose to make their identities known to coerce targets, they are more likely to do so privately since public credit-claiming raises the odds of escalation. Anonymity is most attractive during operations where\n¹ We bracket nonstate actors without political motivations.\nPoznansky, Michael, and Evan Perkoski. (2018) Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution. Journal of Global Security Studies, doi: 10.1093/jogss/ogy022\n© The Author(s) (2018). Published by Oxford University Press on behalf of the International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n403\nsuccess can be achieved without target compliance—cyber espionage and sabotage offer two such examples. Nonstate actors operate according to a different logic. Drawing on insights from studies of armed and unarmed resistance, we argue that nonstate actors in cyberspace regularly claim credit for their intrusions in visible ways to signal credibility, influence public opinion, and grow their ranks. Owing to their relative weakness and obscurity, nonstate actors must first prove their capability before doing anything else.\nThis argument requires a conceptual shift in how we think about secrecy in cyberspace. Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations (Kibbe 2007). The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise (Axelrod 1979; Slantchev 2010). The latter involves the use of secrecy to conceal the sponsor of an operation (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson 2016). Importing this distinction to the cyber domain helps clarify when secrecy is an operational imperative and when it is a choice that actors make. In brief, the advantages afforded to targets who learn of imminent or ongoing operations means that cyber intrusions will almost always be conducted clandestinely. Once an operation is complete, however, intruders are free to choose whether to claim responsibility. Put differently, cyber operations are almost always clandestine but not necessarily covert. The failure to recognize this distinction partly contributes to the widespread assumption that anonymity is an immutable feature of cyberspace rather than something actors select into.\nRigorously testing these claims would require access to the internal deliberations of state and nonstate actors to understand how decisions about credit-claiming are made. At present, this is a nearly impossible task (Buchanan 2017, 12). We are perhaps decades away from gaining access to the types of declassified documents necessary to evaluate the deliberations of states; the problem is even more acute for nonstate actors. As a second-best option, we leverage a range of sources—secondary materials, news reports, official government statements, and interviews—to assess the plausibility of our argument. Our study is closer to an exercise in theory construction than theory testing (Mahoney 2015, 201).\nThis article makes several contributions. First, it joins together a burgeoning literature centered on the dynamics of secrecy in world politics and another focused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation (Carson 2016), and the relationship between democratic peace theory and covert regime change (Downes and Lilley 2010; Poznansky 2015). These studies are tied together by an overarching focus on how actors use secrecy to pursue their political goals. Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike (Gartzke 2013; Gartzke and Lindsay 2015; Lindsay 2015; Rid and Buchanan 2015; Buchanan 2017; Nye 2017) but have largely neglected the determinants of secrecy at the stage where sponsors can (dis)claim ownership of an operation.² We address this issue directly.\nSecond, this study is among the first of which we are aware that considers the goals and constraints of the two most important actors operating in cyberspace—states and nonstate actors. Existing research tends to focus on the former (Gartzke 2013; Buchanan 2017; Borghard and Lonergan 2017; Nye 2017). But nonstate actors conduct cyberattacks at high rates and often in very visible ways. Moreover, their attack capabilities are growing and in some cases they \"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\" (Stoller 2017). Ignoring nonstate actors or assuming that their strategic logic mirrors that of states is insufficient. Our approach is thus to ask the same questions for both sets of actors, reducing barriers that inhibit a more complete understanding of cyberattacks.\n## The Problem of Secrecy\nThe conventional view of a cyber operation is an intruder quietly penetrating a target's network to collect information or cause damage, whether virtual or physical, without betraying their identity.³ This narrative—which assumes secrecy from start to finish—colors how the literature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant (Slayton 2017). Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks (Rid and Buchanan 2015; Nye 2017, 49–52). According to Lindsay (2013), “[f]orensics takes months, whereas the anonymous attack can present\n2 For important exceptions, see Betz and Stevens (2011), Borghard and Lonergan (2017), and Libicki (2009).\n3 See Buchanan (2017) for a summary.\nRethinking Secrecy in Cyberspace\nitself and perhaps complete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity (Lindsay 2015, 58).\nThe pervasiveness of secrecy in this domain also poses challenges for cyber coercion (Valeriano and Maness 2014; 2015, 79; Nye 2017, 55-56). Coercion requires victims to know who is making demands and what they are being asked to do (Schelling 1966). Anonymity is antithetical to this enterprise. As Gartzke (2013) once put it, \"How does one surrender to no one in particular?\" (47). Some scholars point out that perpetrators can enhance the credibility of coercive threats by making their identities known, a point we develop more fully below. But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace (Borghard and Lonergan 2017, 457-59; Libicki 2009, 50-51).\nWhile all of these studies seem to address the same basic phenomenon—secrecy—there are meaningful differences when it comes to what is being concealed during an operation and for what purpose. The next section explores these differences.\n## Disaggregating Secrecy\nThe US military and intelligence communities distinguish between two types of secret operations. The first are clandestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise (Axelrod 1979; Slantchev 2010). As an example, consider Operation Neptune Spear, the US Special Forces' raid on Osama bin Laden's compound in Abbottabad, Pakistan. While the raid itself was shrouded in secrecy, President Obama's remarks to the nation afterward suggest that the purpose of secrecy was tactical, not political.\nThe second type of secret operation is covert action, defined as \"[a]n operation that is so planned and\nFigure 1. Clandestine and covert operations\nexecuted as to conceal the identity of or permit plausible denial by the sponsor.\"6 While covert operations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\" (Gross 2009, 12). There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns (Brown 2014; Carson 2016) and avoiding hostile reactions from domestic and international observers (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson and Yarhi-Milo 2017; Joseph and Poznansky 2017). A classic covert operation is the Bay of Pigs. Training fifteen hundred exiles to storm the shores of Cuba to overthrow Fidel Castro was a highly visible act; the sponsor, the United States, was supposed to remain hidden.\nFigure 1 presents four different combinations of secret operations with illustrative examples.7 Cases in the northwest quadrant include cyber intrusions that are planned and executed clandestinely and denied by the sponsor. These are what observers typically have in mind when discussing the attribution problem in cyberspace. The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases (Betz and Stevens 2011, 95). Examples in the northeast quadrant are covert because the sponsor denied complicity but are not clandestine since the activities themselves, typically performed by third parties, are not hidden. Examples in the southeast corner include large-scale wars.\n4 Betz and Stevens (2011, 95) mention that claiming may be necessary but do not explain why.\nThis is taken from the Department of Defense's Dictionary of Military and Associated Terms, available at http://www.dtic.mil/doctrine/dod/dictionary/. Although this definition is focused on government entities, the same logic applies broadly.\n6 This is also taken from the Department of Defense's Dictionary of Military and Associated Terms.\n7 The very existence of this two-by-two signifies that the main variants of secrecy may be used in combination with one another or separately. Covert and clandestine action are cousins, not synonyms.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n405\nFigure 2. The logic of secrecy in cyberspace\nThese are neither covert (the sponsor was known) nor clandestine (the wars were announced in advance).\n## Secrecy in Cyberspace\nStudents of cyber warfare rarely distinguish between clandestine and covert forms of secrecy. As such, most studies do not explicitly address where secrecy is a de facto requirement rather than a choice in the course of a cyberattack. Figure 2 portrays a stylized schematic of cyber intrusions, capturing two of the key inflection points where actors make decisions about secrecy.\nAt  $\\mathrm{T_0}$ , perpetrators decide whether to announce to the target that an attack is imminent or whether they will conceal the operational details as in a clandestine operation. In almost all cases, perpetrators will choose the latter. Doing otherwise is counterproductive since publicizing even the most basic details of a pending operation affords the target an opportunity to enact countermeasures. Announcing that \"[you] will attack this network with this effect unless [the target] refrain[s] from X\" would be \"self-defeating\" (Lindsay 2015, 55). Acting clandestinely raises the likelihood of success by denying victims the chance to take steps that might blunt the efficacy of the attack such as patching a vulnerability or cutting access to servers. This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim.[8] Even when the perpetrator is not relying on zero days,\nthey still will not want to announce the exact vector by which the intrusion will occur to avoid jeopardizing the operation.\nActors have the most agency when it comes to secrecy and deception after an attack occurs at time  $\\mathrm{T}_{1}$ . Here, perpetrators must decide whether to proceed in a manner consistent with covert action (denying their role) or not (claiming it). Should a perpetrator choose to forgo plausible deniability, they must then decide how to communicate complicity. The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity (Libicki 2009, 50-51; Nye 2017, 51). Perpetrators can do this by leaving clues in the course of the attack—for example, leveraging a vector they have been known to use before, reusing code from a previous intrusion, or otherwise leaving signatures in the source code of malware. Or they might communicate through discrete diplomatic channels with a foreign counterpart (Borghard and Lonergan 2017, 459).\nThe second means of communicating complicity, public acknowledgment, refers to a situation where the perpetrator openly pronounces their identity to a much wider audience following an attack. They might make a public statement or alert the media of their culpability. Explaining why some actors intentionally dispense with anonymity—and, for those that do, whether they will credit-claim publicly or privately—is the focus of the next two sections. For now, it will suffice to point out that the attribution problem ceases to exist in cases where the perpetrator willingly makes their identity known.\nActors can, and often do, opt to act both clandestinely and covertly in the course of a single operation (Betz and Stevens 2011, 88). Our rationale for distinguishing between the two is to make clear that while clandestinity is a technical requirement of almost all cyber operations the decision to act covertly is something perpetrators consciously select into. In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.[9]\nIn what follows, we use these distinctions to address our original puzzle regarding why some actors claim responsibility for operations while others choose to remain anonymous. The next section discusses the politics of credit-claiming for states. We then turn to nonstate actors, a neglected but important player in the cyberspace arena.\n8 For a discussion, see Lin (2010, 65n7).\n9 Getting caught is still a real possibility, especially for larger operations (Lindsay 2015, 58).\nRethinking Secrecy in Cyberspace\n# States and the Politics of Voluntary Attribution\nWhether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion.[10] If success is possible without the target consciously acceding to some demand, states will act covertly and hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission.[11] In terms of how they eventually reveal complicity, we argue that states are most likely to use private channels and discrete communication.\n# When States Come Clean\nWhen the success of state-sponsored cyber operations does not require target compliance, voluntary credit-claiming is unnecessary at best and counterproductive at worst. In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage.[12] Like any intelligence gathering effort, voluntary attribution would be disadvantageous. Should a perpetrator announce that they have penetrated an adversary's network, they will jeopardize both their intrusion method and continued access without reaping any obvious benefit in return. Preserving anonymity is thus the preferred option for states interested in stealing secrets in cyberspace.\nAnother class of cyber operations, political action and sabotage, is also best served by perpetual anonymity. Examples include operations to influence elections through disinformation campaigns, vote manipulation, and the destruction of physical equipment and critical infrastructure. Because the success or failure of these operations does not depend on the target consciously responding to specified incentives, the motivations for states to voluntarily claim credit should be correspondingly low.\nThe calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful (Schelling 1966). When operations require that the\n10 This distinction is similar to the one Schelling (1966) draws between brute force and coercion. On how qualitatively different types of cyber operations have been conflated, see Betz and Stevens (2011, 81).\n11 The need for target compliance is not the only factor underlying this decision. Whether the action itself violates longstanding norms, would trigger escalation, and the like may factor in as well.\n12 These qualify as computer network exploitation, or CNE (Nye 2017, 47).\ntarget accede to a set of demands—either to do something (change the status quo) or to refrain from doing something (preserve the status quo)—states are likely to shun anonymity and engage in voluntary attribution. The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim (Carson and Yarhi-Milo 2017). Remaining anonymous does little to advance these aims. As Liff (2012) notes, “[u]nder most circumstances, any would-be aggressor who does not identify itself forfeits the ability to coerce its adversary” (414). Anonymity makes it hard for targets to evaluate the credibility of a threat and the sender’s resolve. Credit-claiming is thus critical if cyber coercion is to have any chance of succeeding. Betz and Stevens (2011) hint at this: “[W]hen states use military cyber-power against other states for the purposes of compelling them to do their will, they still have to declare what it is (even after the event). There is no sneaky way around this fact” (95). It is worth reiterating, however, that this can only feasibly be done after the attack has ended. As discussed earlier, providing details beforehand could undermine the mission and render the coercive threat impotent.\nForgoing anonymity permits states to more effectively make coercive threats by demonstrating credibility and resolve in at least two ways. First, a claimed attack can function as a costly signal by showing the threatening party's willingness to expend valuable resources in the hopes of gaining compliance from the target. According to Borghard and Lonergan (2017), \"[t]he greater the cost to the initiating state of producing a given signal, ceteris paribus, the more effective the signal is as an indication of the initiating state's resolve\" (467).\nSecond, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power.[13] Prestige and power, though related, are not the same. The latter refers strictly to capabilities, which can never be fully observed in cyberspace owing to the premium placed on keeping these tools shrouded in secrecy. The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\" (Gilpin 1981, 31).[14] States who cultivate a reputation for cyber power may be able to\n13 This is a play on Gilpin (1981, 31).\n14 Interestingly, even if actors do not willingly come clean, successful attribution can still bolster prestige. Consider the Stuxnet worm, allegedly manufactured by US and Israeli operatives and how it reflects on their cyber potential. As one Symantec director noted, \"[i]t seems pretty reasonable to think that there are things out there today that we haven't seen that are much more advanced [than Stuxnet]\" (Szoldra 2016).\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n407\npersuade adversaries that their threats are credible even if they do not specifically outline the vector they intend to exploit or the zero day they plan to deploy if demands go unmet. A history of successful cyberattacks can offset the invisibility of a state's arsenal.\nIt is worth briefly outlining how the dynamics of cyber prestige and coercion could operate in practice. When the goal is to compel a target to alter their behavior, perpetrators may take offensive action in cyberspace, claim credit for it, and threaten future punishment should the target fail to comply. When the goal is to deter some action, perpetrators may similarly be able to take offensive cyber action, claim credit for it, and threaten future punishment should the target act in ways deemed undesirable by the sender. A more plausible situation in the case of cyber deterrence might entail the victim of a recent attack retaliating against the perpetrator, voluntarily claiming credit, and threatening future harm should there be any further attacks against them. In each of these scenarios, cyber coercion is possible to the extent that the target believes the sender's promises of future pain are credible and that the threatener is resolved as a result of having claimed past attacks. It is \"the threat of . . . more damage,\" or the \"expectation of more violence,\" that may induce a target to give in (Schelling 1966, 3; emphasis in original).\nThere is obviously no guarantee that claiming credit for past attacks will generate the credibility necessary for coercion. If the target does not believe that the challenger has the ability or willingness to repeat similar or more painful attacks, issuing deterrent or compellent threats after claiming an intrusion with the promise of \"more where that came from\" won't work. Nevertheless, we are skeptical that observers never update their beliefs about an actor's capabilities and resolve, and opt instead to treat every attack as an isolated event. While Russia is unlikely to easily hack the Democratic National Committee again, for example, few observers doubt their capacity to carry out similar attacks in the future. Whether credible coercive threats will actually suffice to achieve concessions, while important in its own right, is a separate matter and depends on a complex cost-benefit calculation.\n## Escalation and the Means of Communication\nThis section focuses on the right-hand side of Figure 2, after an actor chooses to forgo plausible deniability $(\\mathrm{T}_1)$ and decides whether to claim responsibility publicly or privately. We argue that the unique dynamics of politically motivated, state-on-state cyber activity make public acknowledgment less attractive than private acknowledgment. There are several reasons for this.\nAs a general matter, opportunities for retaliation are higher when the actors involved are states. Unlike non-state actors, states are stationary, immobile entities with numerous targets available to hit. Concern about attacks against a state's critical infrastructure have been likened to a potential \"cyber 9/11\" (Maxey 2017).¹⁵ Moreover, perpetrators that publicly announce sponsorship of a cyberattack put the victim—in many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige (Carson and Yarhi-Milo 2017, 135).\nBecause the victims of publicly claimed, state-sponsored cyberattacks typically have both the opportunity to retaliate as well as strong domestic-level pressures to do so, nation-states interested in cyber coercion face powerful incentives to quietly claim their actions using private channels. While credit-claiming in private lacks the broader prestige benefits associated with publicity and limits the audience observing an operation's (physical) costly signals, it may nonetheless afford states an opportunity to engage in coercive diplomacy at reduced risk. Recent scholarship shows that states often face powerful incentives to collude with one another in acts of secrecy. For example, Carson (2016) argues that states may opt not to publicize the covert military actions of their rivals even when they are targeted as a way of keeping conflicts limited and contained. A similar logic should apply to discrete attempts at coercion in cyberspace.\nOne risk of private acknowledgment is that the victim will \"out\" the perpetrator by publicly announcing the occurrence of an intrusion and offering proof that the attacker sought to privately attribute themselves. While this is always a possibility, such concerns may not wholly disincentivize states from pursuing private acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them (Rid 2012, 28–29). This, in turn, can motivate perpetrators to quietly come clean with little fear of being exposed by the victim. Second, when victims have the capacity to out a state\n¹⁵ For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).\nRethinking Secrecy in Cyberspace\npursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases.¹⁶ This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity (Yarhi-Milo 2013, 407).\n# Nonstate Actors and the Politics of Voluntary Attribution\nThe discussion so far has focused on the conditions under which states will claim credit for cyberattacks and why they are more likely to do so privately. This is important for obvious reasons.¹⁷ However, nonstate actors dominate the empirical record of credit-claiming in cyberspace. In what follows, we explain why nonstate actors commonly claim attacks and why they tend to do so publicly.\nDrawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means (Nye 2010; Asal et al. 2016). Regardless of their method of contention, nonstate actors are agents of change operating in a structural environment in which they are severely disadvantaged. These groups wield significantly fewer resources than states—financial, material, and otherwise—and their capabilities are consequently more constrained and more uncertain. In addition, what few capabilities nonstate actors do possess are in large part a function of the number of participants they can organize. This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well (Asal and Rethemeyer 2008; Chenoweth and Stephan 2011). The same basic logic extends to nonstate actors operating in cyberspace. One of the most common tools in a group's cyber arsenal, the distributed denial of service (DDoS) attack, grows stronger with every additional user.¹⁸\nOur primary claim is that nonstate actors are more likely than states to brazenly claim cyberattacks. Not\n¹⁶ See also Carson and Yarhi-Milo (2017, 135).\n¹⁷ On the importance of states for Internet politics, see Rovner and Moore (2017).\n¹⁸ To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.\nonly does this help showcase their capabilities, but the media attention can help attract new members to the cause. Additionally, since it is often difficult to bring these groups to justice, organizations like Anonymous, Lulzsec, and others face reduced incentives to keep quiet about their operations.¹⁹ In sum, complicity is a critical component of nonstate actors' strategic logic and they commonly announce sponsorship of cyberattacks as a result.\n# The Appeal of Credit-Claiming\nNonstate actors typically have coercive objectives. As Schelling wrote in 1973, \"[p]olitical violence, like political nonviolence, usually has as its purpose making somebody do something or not do something or stop doing something. The aim is to influence behavior.\"²⁰ In a broad sense, their goals are comparable to those of states seeking to alter the behavior of their adversaries.\nAbove, we argue that a key component of coercion is credibility: can actors issuing coercive threats make good on their promises of more pain if the target resists? This is especially difficult for nonstate actors (Hoffman and McCormick 2004; Kydd and Walter 2006; Dannenbaum 2011). They cannot put on military parades to show off their latest weaponry,²¹ do not have the means to finance modern military forces,²² and lack the resources—territorial, bureaucratic, and financial—of states. It is easy to dismiss the demands of nonstate actors as inconsequential chatter.\nGiven these deficits, the issue of how to boost credibility features centrally in the strategic logic of politically motivated nonstate actors. As with states, one way to demonstrate capabilities and resolve is to take action perceived as a costly signal. According to Kydd and Walter (2006), \"[b]ecause it is hard for weak actors to make credible threats, terrorists are forced to display publicly just how far they are willing to go to obtain their desired results\" (50). Similarly, Abrahms (2013) writes that \"[t]errorism . . . adds credibility to threats by showing that nonstate challengers possess the power to hurt\" (661).\nFor nonstate cyber warriors, sending costly signals to bolster credibility may include defacing government websites, launching distributed denial of service attacks,\n¹⁹ To the extent that they run the risk of capture, however, the credibility of their signals goes up.\n²⁰ Quoted in Sharp and Finkelstein (1973, xx).\n²¹ Doing so might expose their position and invite unwanted risk.\n²² One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n409\nand so forth. In other words, they are likely to take actions that prove their ability to cause pain or at least disrupt and inconvenience their targets. Although temporarily compromising access to a website will not pack the same symbolic punch as a terrorist attack, employing increasingly sophisticated cyber operations and exploiting consequential vulnerabilities helps nonstate groups elevate the costliness of their signals and more readily demonstrate credibility and resolve (Borghard and Lonergan 2017, 466–67).\nA history of successful attacks by a nonstate group can also help cultivate their prestige in much the same way it does for states. As such, nonstate actors stand to lose by not identifying their organization as responsible for an attack. Failing to communicate culpability negates an operation’s objectives and precludes nonstate actors from reaping signaling and reputational benefits that are critical to successful coercion. Without knowing who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities.²³ It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own (Bloom 2005, 78–79).²⁴\n## Maximizing Publicity\nThe notion that nonstate actors are more likely to claim attacks to showcase their capabilities and resolve mirrors a similar motivation among states interested in cyber coercion. Where the two diverge is in the preferred method of claiming. Several factors make nonstate actors more likely to choose public rather than private acknowledgment.\nOne reason nonstate cyber warriors crave the limelight hinges on the audiences they seek to influence. These\n²³ It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.\n²⁴ Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).\ngroups are often interested in sending a message not just to adversarial governments but to their populations as well. The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance (Schmid 2004). As Crenshaw (1981) notes in a related context, “[t]he victims or objects of terrorist attack have little intrinsic value to the terrorist group but represent a larger human audience whose reaction the terrorists seek” (379).\nUltimately, terrorists target the public since they are too weak to confront the state head-on. The same should be true of nonstate actors in cyberspace since these groups face comparable disadvantages. For such a strategy to work, however, communication cannot be private; it must be visible, clearly attributed, and widely known to the government and public alike.\nA second reason nonstate actors in cyberspace prefer public methods of claiming credit turns on their desire to attract new recruits. Like their traditional counterparts, these actors are interested in survival and growth. According to Pape (2005), “terrorism has two purposes—to gain supporters and to coerce opponents. Most terrorist campaigns seek both goals to some extent, often aiming to change the target state’s policies while simultaneously mobilizing support and recruits for the terrorists’ cause” (7). Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization (Abrahms 2008, 379) and augment their coercive ability. It is well established that the power of civil resistance flows from mobilization numbers, and the same goes for organizations in cyberspace. When it comes to their operating methods, these groups favor tactics that grow more powerful with additional bots and active supporters. The strength of DDoS operations, for instance, is linked to the number of machines involved (Ghosemajumder 2016).²⁵ The Low Orbit Internet Cannon (LOIC) and related variants draw strength from those who download the application and flood a server. With more members at their disposal, groups are able to launch increasingly formidable cyber operations.²⁶\n²⁵ On the determinants of DDoS attacks, see Asal et al. (2016).\n²⁶ It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.\nRethinking Secrecy in Cyberspace\n# Plausibility Probes\nA lack of readily-accessible decision-making documents complicates rigorous empirical tests of our argument. If we are right that state-sponsored cyber operations involving espionage and sabotage are prime candidates for secrecy before, during, and after execution, it might be decades or longer before relevant materials are declassified.27 While coercive cyber operations are more likely to involve credit-claiming, the advantages of claiming attacks privately also impede observation. In fact, outsiders might be unable to discern differences between victims who are truly ignorant of their attacker's identity and those that feign ignorance while privately communicating with their attackers.\nAs a second-best strategy, we examine publicly available sources including news reports and a range of secondary materials to provide a preliminary test of our argument. We also conduct two interviews: one with a former Defense Department official involved in cyber policy and one with a former member of Anonymous. These helped corroborate what we found in the public record.\n# States\nWe were unable to find a single case of a state claiming credit for a cyber espionage operation, either openly or privately. Rather, the cases that have inadvertently come to light underscore the vigor with which states seek to avoid being named. China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative (Nakashima 2015). In the aftermath of the intrusion, Chinese officials denied complicity, placing blame on criminal hackers. They even went so far as to claim that they had arrested individuals who were connected with the hack (Chalfant 2017).28 Another example is Russia's alleged interference in the 2016 US election. The \"theft of research and emails from the Democratic National Committee\" for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government (Sanger 2016).29\n27 This is especially true when it comes to documents pertaining to intelligence activities, which may stay classified for longer owing to concerns about sources and methods.\n28 See also Yan (2015). While it is technically possible that Chinese officials privately communicated complicity to the United States, this is unlikely since it serves no real strategic purpose.\n29 One might reasonably categorize this episode as political action wherein the Russians disseminated stolen\nWhen asked in March 2017 about whether Russia was behind the efforts to discredit Hillary Clinton, Putin responded with \"Read my lips: No\" (Lister, Ilyushka, and Gigova 2017). When it comes to cyber espionage, there is no benefit to be had from credit-claiming.\nStuxnet provides a useful illustration of why decision-makers sometimes cling to anonymity and, more interestingly, the conditions under which they might be willing to voluntarily claim credit.30 Stuxnet, formally known as \"Olympic Games,\" was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant (Farwell and Rohozinski 2011). The aim was to make the Iranians believe their centrifuges were failing for reasons other than foreign interference. Sanger (2012) writes the following: \"When the centrifuges first began crashing in 2008 at the Natanz enrichment center, the crown jewel of the Iranian nuclear program, the engineers inside the plant had no clue they were under attack. That was exactly what the designers of the world's most sophisticated cyberweapon had planned.\" He continues that \"[t]he idea, hatched in Washington and Jerusalem, was to make the first breakdowns seem like random accidents and small ones at that\" (188).\nSanger's interviews with government officials confirm that the operation was supposed to leave no trace of US fingerprints: \"The most elegant cyber weapons are a lot like the most elegant bank frauds. . . . They work best when the victim doesn't even know he's been robbed\" (190-91). It is clear from this account that the United States kept both the operation and their sponsorship intentionally hidden, as our argument predicts. The success or failure of the operation did not depend on Iran changing their behavior, but simply hinged on the quiet destruction of centrifuges.\nInterestingly, though, some US operatives contemplated quietly alerting the Iranians that the United States was responsible for the attack. Their apparent rationale conforms to our theoretical expectation. Ostensibly, the goal would have been to send a message to Tehran that the United States had the ability to keep targeting their systems, presumably as a way of achieving concessions on the nuclear program. According to Sanger (2012), \"[a]t both the Pentagon and inside the intelligence agencies some of the creators of the bug believed that it might be\ninformation to relevant entities who could use it to discredit Hillary Clinton. Even if so, this type of action would qualify as a classic covert operation, and thus we would still expect Russian denials.\n30 For a full-length treatment of the dynamics underlying the operation, see Lindsay (2013) and Rid (2012).\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n411\neven more valuable if the source of the attacks became known, because the Iranians would get the message that Washington could pierce its systems repeatedly.\" One official directly involved in decision-making noted, \"[w]e had to be ready to work in an environment where the Iranians knew exactly who was doing this to them, to make the point that we could come back and do it again\" (203). In short, some policymakers believed they could more easily alter the Iranian regime's behavior by embracing responsibility and proving that they could bring more pain to bear should they continue down the path of nuclearization.[31]\nMore recent examples suggest that states are thinking hard about voluntarily claiming credit for their cyber operations in the service of coercion. In late September 2017, it came to light that the Trump administration authorized US Cyber Command to carry out a range of limited cyberattacks against North Korea's Reconnaissance General Bureau intended to interfere with Internet access (DeYoung, Nakashima, and Rauhala 2017). Most importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy.[32] Panda (2017) argues that the United States had \"take[n] the cyber equivalent of a shot across North Korea's bow, presumably signaling that it has the requisite access to North Korean networks to deliver considerably more significant damage in wartime.\" Since North Korea is not wanting for enemies, it seemed to serve US objectives to let their complicity be known, thereby reducing ambiguity about what behavioral changes were expected from the Kim regime.\nFurther evidence for our theory comes from recent statements by Shawn Turskey, the executive director of US Cyber Command. His comments from 2016 indicate that the United States government is contemplating ways to leverage cyber capabilities for coercive purposes,\n31 One interesting avenue for future research is to explore how the desire to claim credit for certain operations, especially sabotage, may be driven in part by which agency is responsible for conducting the attack. We might expect, for example, the military to more readily embrace complicity and the intelligence community to do the opposite.\n32 The White House and Cyber Command declined to comment, but a senior administration official told the Washington Post that \"[w]hat I can tell you is that North Korea has itself been guilty of cyberattacks, and we are going to take appropriate measures to defend our networks and systems\" (DeYoung et al. 2017).\nspecifically through intentional credit-claiming. Turskey declared the following:\nIn the intelligence community you never want to be caught, you want [to] be low and slow, you never really want to be attributed. . . . But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know. (Bing 2016, emphasis added)\nThese remarks are noteworthy for several reasons.[33] Chief among them is the prospect of the world's lone superpower developing an arsenal of cyber weapons with a return address. The fact that loud, attributable weapons are being discussed at all is at odds with the typical portrayal of cyberspace as a domain defined by secrecy and anonymity. Yet, it is easier to understand why Turskey is contemplating this shift once we come to terms with the mechanics of cyber coercion. Leveraging cyber assets for coercive purposes, rather than espionage or sabotage—which fits more readily within the purview of the military as opposed to the intelligence community—requires credible self-attribution. Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal (Lin 2016).\nMichael Sulmeyer, the former director for Plans and Operations for Cyber Policy in the Office of the Secretary of Defense, affirmed this sentiment in an interview for this article. Echoing the idea that cyber weapons can and should be embraced for more traditional purposes, he highlights the following:\nIt is important for the United States to invest in capabilities that not only help it improve its espionage activities against adversaries, but also that help it prevail in the event of hostilities with adversaries. When operating in the realm of the second objective, it can be beneficial for the United States to take responsibility for its actions publicly—not to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.[34]\nTaking responsibility, as Sulmeyer suggests, provides America's adversaries the chance to understand the extent of their cyber power. Similar to Turskey, Sulmeyer anticipates that more voluntary credit-claiming may be on the horizon:\n33 For a discussion of these comments, see Lin (2016).\n34 Interview with authors, October 26, 2017.\nRethinking Secrecy in Cyberspace\nTo be sure, this signal could be missed or dismissed—and a mere tap on the digital shoulder clearly would not suffice for such a signal to be internalized. But why go through all the effort to hide every action every time in this context? That's an unnecessary additional burden in a war fight. If there are a suite of capabilities that can help our forces be more agile during hostilities, I would hope they are on the table for our commanders and leaders in the future.³⁵\n## Nonstate Actors\nThe empirical pattern of cyberattacks by nonstate actors differs from what we observed for states. These actors frequently claim credit for their cyberattacks in very public ways. Much like terrorist attacks, these operations almost always entail a political message intended to alter public opinion, change government policies, and the like. A cyberattack carried out by the Syrian Electronic Army against the US Army's website showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion (Vinton 2015). Quietly alerting the US Army that the Syrian Electronic Army was behind the attacks would have undermined the strategic motivations underlying the entire operation, namely bolstering their reputation as a group that deserves respect and sending a clear message with the intention of affecting public opinion and altering policy. The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list (Temperton 2016).\nFor a more complete picture of the decision-making process for nonstate actors in cyberspace, we briefly examine one of the most well-known organizations: Anonymous. Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article (Olson 2012; Coleman 2014). Anonymous’ behavior following this shift, though, sheds light on the group’s political strategy and how publicity and attention serve their goals.\nA cursory overview of Anonymous’ exploits over the years shows that the group commonly claims credit publicly for its operations. In late March 2016, Anonymous targeted roughly twenty Angolan government websites in response to the arrest of several activists. Prior to carrying out the attack, they posted details about the websites\nthey intended to target (British Broadcasting Company 2016). In one of their biggest and best-known campaigns, Operation Tunisia, the group first put out a press release via YouTube³⁶ before a launching series of DDoS attacks that took down numerous government-linked websites. This was part of a broader operation intended to assist protesters and weaken the government of Ben Ali. Most relevant for our purposes, the group issued a clear coercive threat: “This is a warning to the Tunisian government: attacks at the freedom of speech and information of its citizens will not be tolerated. . . . Free the net, and the attacks will cease, keep on that attitude and this will just be the beginning”³⁷ In another high-profile incident, Anonymous targeted the Church of Scientology. As before, the attack began with a YouTube press release³⁸ and proceeded with a series of DDoS attacks, doxing, and more press releases and media statements. In line with our expectations, the IT company hired by the Church of Scientology implored them to simply ignore the attacks: “Don’t issue warnings or threats to the attackers via the media; this will only keep the issue alive, raise tempers, and greatly increase the possibility of another assault. Most DDoS attackers seek publicity, so don’t hand it to them on a silver platter.”³⁹ Their solution was to deprive Anonymous of what it wanted most, namely attention.\nThis strategy of pursuing highly visible, self-attributed missions served at least three functions. First, Anonymous used these operations to ensure that they were taken seriously and that their coercive threats were not ignored. Establishing their capabilities, resolve, and credibility by conducting attacks with clear attribution contributed to this effort. This was explicit in their internal conversations during the operation against the Church of Scientology. As one member put it, “I think it’s time for [us] to do something big. People need to understand not to f*** with [Anonymous].”⁴⁰ These and other attacks proved somewhat successful. Outside observers came to understand that they should not dismiss the group’s threats. Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility” (Olson 2012, 177).\nSecond, Anonymous recognized that part of their strategy revolved around the public. During Operation Payback in 2010, which aimed to promote Internet privacy by targeting antipiracy groups, members of\n³⁵ See https://www.youtube.com/watch?v=BFLaBRk9wY0.\n³⁶ Quoted in Coleman (2014, 149).\n³⁷ See https://www.youtube.com/watch?v=JCbKv9yiLiQ.\n³⁸ Quoted in Olson (2012, 89).\n³⁹ Quoted in Olson (2012, 2).\nInterview with authors, October 26, 2017.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\nAnonymous ardently debated this component of their strategy. Support eventually developed for one member who claimed that “... these attacks are less about hurting the business than drawing attention and forcing the media to cover the story. . . . The point for me is that this is the technological way of mass protesting that’s actually effective.”41 Getting their message out to the public to garner attention became a core objective.\nAnonymous’ operations often did more than just influence the public indirectly via messaging; sometimes the public was the direct target of attacks. Anonymous, like most terrorist groups, eventually had to reconcile with the fact that targeting innocent civilians might be useful for achieving their aims. This issue came to a head during Operation BART (Bay Area Rapid Transit), when members leaked information on individual passengers, including credit card numbers and other details from the company’s website. When asked about the incident by a reporter, a senior member replied, “[h]ow else do you get the world to respond and secure your information? How else do you get these companies and these big governments to keep your information, the information you give them voluntarily, safe? I think we got our message across, and I’ll bet you one thing: I’ll bet you they fix that.”42 Anonymous’ symbolic, essentially random targeting was part of a broader campaign to influence public opinion and achieve political change. Their cyberattacks were acts of coercion that bore a striking resemblance to the strategic logic of militant organizations.\nFinally, Anonymous’ cyber behavior was often geared toward generating new members and deepening support among their base. In an interview conducted for this article, we asked Hector Monsegur, a former leader of Anonymous known as Sabu, why the group was so eager to publicly claim their operations. As he put it,\nAt the time of its height (not so much now) Anonymous had gained huge successes in publicizing its protests, hacks, and engagements. They were masterful in the distribution of content, and the media truly ate it up for several reasons:\nIt was neatly packaged and ready for distribution, the hackers were willing to give interviews, and of course the mystery element. The whole thing about the mask and shadowy figures really “sells” the concept. As Anonymous grew in action, it also grew in numbers and support . . .\nThe truth of the matter is that Anonymous needed the media to grow, and this explains why many of the\nthings we did were really attention-grabbing. It served a purpose. It’s very similar to branding and how companies slip in their products into film, or events in general, even if each engagement or hack had different motivations.43\nIn her research on Anonymous, Coleman (2014) expands on this point: “[W]ithout the appearance of a critical mass, the operation would have likely lacked moral gravitas and authority. In this case, strength in numbers conveyed a potent message” (138). Expanding their membership didn’t just provide Anonymous legitimacy; it provided additional capability as well. While many of Anonymous’ DDoS campaigns relied on botnets to create their desired effect, individual users sustained those attacks that used the freeware LOIC, a staple of the group’s earlier activity. This required the group to invest time in assisting new members with the software. Olson (2012) points out that the group felt it was worth it to take the time “getting the [new members] on board to create an army” (65).\nUltimately, it was in Anonymous’ interest to take credit for their cyber operations through highly visible, public means of communication. Doing so rewarded their efforts significantly and was instrumental to their strategic logic. Whether the target was the Tunisian government or the Church of Scientology, the attention they received bolstered their particular brand of coercion. This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance (Coleman 2014, 107).\n## Cybercrime and Cyber Blackmail\nBefore concluding, it is worth flagging two types of cyber operations perpetrated by state and nonstate actors alike that are unlikely candidates for voluntary attribution. The first are operations involving theft of financial or intellectual assets. These are among the most common kind of cyberattack and are ill-served by credit-claiming. Malicious actors that leverage cyber assets for criminal purposes, such as stealing money from banking institutions, have little incentive to self-attribute. Doing so would provide little benefit and expose them to potential prosecution. While nonstate actors most commonly conduct these kinds of attacks, states may as well. For example, North Korea was identified as the responsible party in a cyber heist against Bangladesh’s central bank. Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million (Finkle 2017).\n41 Quoted in Coleman (2014, 132).\n42 Quoted in Coleman (2014, 307).\n43 Interview with authors, October 30, 2017.\nRethinking Secrecy in Cyberspace\nA second unlikely candidate for voluntary attribution is what we might call “cyber blackmail,” or operations in which the perpetrator leverages stolen assets, embarrassing secrets, and the like to achieve compliance from the victim without having to reveal their true identity.⁴⁴ These operations are particularly interesting in that success requires target compliance—which we argue should lead to credit-claiming—but the perpetrator can remain behind a mask. By selectively releasing compromised information and assets to the victim publicly or privately (Lindsay 2015, 57), the perpetrator may be able to force compliance while remaining anonymous or hiding behind front groups.\nThis dynamic approximates what might have happened during the Sony hack, in which the “Guardians of Peace” (#GOP) issued an explicit compellent threat against Sony in an attempt to prevent the company from releasing The Interview, a comedy satirizing North Korea’s leader Kim Jong Un. In the event that Sony failed to comply with #GOP’s demands, the group threatened to release propriety information and potentially embarrassing e-mail correspondences between high-level employees. Although North Korea was widely suspected of sponsoring the attack, the regime denied any involvement. Nonetheless, the attack partially succeeded in coercing Sony without the government having to explicitly take credit.⁴⁵ We believe that the attack was partially successful as a result of Sony’s understanding that certain assets (personal e-mails, financial records) had indeed been compromised and would be released should they fail to comply.\n## Conclusion\nThis article draws on existing theory to develop an explanation for why states and politically motivated non-state actors might voluntarily claim credit for their attacks. We argue that the goals of an operation as well as the characteristics of the perpetrator drive both the decision to claim credit as well as the manner in which culpability is communicated. This research has several important implications. First, we show how states and nonstate actors share a common set of choices with regards to secrecy in cyberspace. Both face the same decisions at the same points in the life cycle of a cyberattack, yet the characteristics of each can cause their strategies to diverge, particularly when it comes to the optics of credit-claiming. Future research should continue to investigate how the characteristics and operational and strategic goals of cyber actors influence the look and feel of their cyber actions.\nSecond, existing research often treats cyber operations as distinct from more traditional elements of state power. Although there are differences, the framework developed here suggests that states may be able to leverage cyber assets to achieve many of the same goals most frequently pursued with conventional forces. Scholars have pushed back against this idea for a variety of reasons, one being the attributional difficulties of cyber operations. But states need not conceal their complicity in perpetuity. By relaxing this assumption, we can more easily see how these operations fit into a state’s coercive toolkit. One area ripe for future research is the efficacy of coercion in cyberspace, both on its own and in comparison to more conventional methods.\nFinally, while inferring intentions from behavior is problematic, actors’ decisions to privately or publicly acknowledge sponsorship of an attack may provide crucial information about motives and identity. Clinging to covert forms of secrecy after the completion of an attack might highlight a set of plausible underlying motivations for the initial intrusion, including espionage, cybercrime, and the like. Conversely, if the actor does come clean, it might be appropriate to infer that credibility, prestige, or coercion was the true goal. In the information-starved domain that is cyberspace, these clues may be all there is when designing policies and crafting responses.\n## Acknowledgements\nThis is one of several collaborative projects by the authors, and the ordering of names follows a principle of rotation. We are grateful to Joseph Brown, Ben Buchanan, Ryan Evans, Robert Jervis, Joseph LaPalombara, Herb Lin, Jon Lindsay, Joseph Nye, Joshua Rovner, and Michael Sulmeyer for helpful comments, suggestions, and insights. An earlier version of the argument presented here appeared in War on the Rocks.",
  "references": [
    "## References\nAbrahms, Max. 2008. “What Terrorists Really Want: Terrorist Motives and Counterterrorism Strategy.” *International Security* 32 (4): 78–105.\nA related tactic that might incentivize target compliance without voluntary attribution involves the use of ransomware. A recent example of this was the WannaCry attack in May 2017 (Perlroth and Sanger 2017).\n⁴⁴ A related tactic that might incentivize target compliance without voluntary attribution involves the use of ransomware. A recent example of this was the WannaCry attack in May 2017 (Perlroth and Sanger 2017).\n⁴⁵ We refer to this as a partial success since Sony ultimately released The Interview after initially delaying in immediate aftermath of the hack.\n⁴⁶ 2013. “The Credibility Paradox: Violence as a Double-Edged Sword in International Politics.” *International Studies Quarterly* 57 (4): 660–71.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n415\nAbrahms, Max, and Justin Conrad. 2017. \"The Strategic Logic of Credit Claiming: A New Theory for Anonymous Terrorist Attacks.\" *Security Studies* 26 (2): 279–304.\nAsal, Victor, Jacob Mauslein, Amanda Murdie, Joseph Young, Ken Cousins, and Chris Bronk. 2016. \"Repression, Education, and Politically Motivated Cyberattacks.\" *Journal of Global Security Studies* 1 (3): 235–47.\nAsal, Victor, and R. Karl Rethemeyer. 2008. \"The Nature of the Beast: Organizational Structures and the Lethality of Terrorist Attacks.\" *Journal of Politics* 70 (2): 437–49.\nAxelrod, Robert. 1979. \"The Rational Timing of Surprise.\" *World Politics* 31 (2): 228–46.\nBaum, Matthew. 2004. \"Going Private: Public Opinion, Presidential Rhetoric, and the Domestic Politics of Audience Costs in U.S. Foreign Policy Crises.\" *Journal of Conflict Resolution* 48 (5): 603–31.\nBetz, David J., and Tim Stevens. 2011. *Cyberspace and the State: Toward a Strategy for Cyber Power*. New York: Routledge.\nBing, Chris. 2016. \"U.S. Cyber Command Director: We Want 'Loud,' Offensive Cyber Tools.\" *FedScoop August* 30.\nBloom, Mia. 2005. *Dying to Kill: The Allure of Suicide Terror*. New York: Columbia University Press. https://www.fedscoop.com/us-cyber-command-offensive-cybersecurity-nsa-august-2016/.\nBorghard, Erica D., and Shawn W. Lonergan. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452–81.\nBritish Broadcasting Company. 2016. \"Anonymous' Hackers Cyber-Attack Angolan Government.\" *BBC News*, March 30. https://www.bbc.com/news/world-africa-35927474.\nBrown, Jonathan N. 2014. \"The Sound of Silence: Power, Secrecy, and International Audiences in US Military Basing Negotiations.\" *Conflict Management and Peace Science* 31 (4): 406–31.\nBuchanan, Ben. 2017. *The Cybersecurity Dilemma: Hacking, Trust, and Fear Between Nations*. Oxford and New York: Oxford University Press.\nCarson, Austin. 2016. \"Facing Off and Saving Face: Covert Intervention and Escalation Management in the Korean War.\" *International Organization* 70 (1): 103–31.\nCarson, Austin, and Keren Yarhi-Milo. 2017. \"Covert Communication: The Intelligibility and Credibility of Signaling in Secret.\" *Security Studies* 26 (1): 124–56.\nChalfant, Morgan. 2017. \"FBI Arrests Chinese National Linked to OPM Hack Malware.\" *The Hill*, August 24. http://thehill.com/policy/cybersecurity/347897-fbi-arrestschinese-national-linked-to-opm-hack-malware-report.\nChenoweth, Erica, and Maria J. Stephan. 2011. *Why Civil Resistance Works The Strategic Logic of Nonviolent Conflict*. New York: Columbia University Press.\nColeman, Gabriella. 2014. *Hacker, Hoaxer, Whistleblower, Spy: The Many Faces of Anonymous*. London: Verso.\nCrenshaw, Martha. 1981. \"The Causes of Terrorism.\" *Comparative Politics* 13 (4): 379–99.\nDannenbaum, Tom. 2011. \"Bombs, Ballots, and Coercion: The Madrid Bombings, Electoral Politics, and Terrorist Strategy.\" *Security Studies* 20 (3): 303–49.\nDeYoung, Karen, Ellen Nakashima, and Emily Rauhala. 2017. \"Trump Signed Presidential Directive Ordering Actions to Pressure North Korea.\" *Washington Post*, September 30. https://www.washingtonpost.com/world/national-security/trump-signed-presidential-directive-ordering-actions-to-pressure-north-korea/2017/09/30/97c6722a-a620-11e7-b14f-f41773cd5a14_story.html.\nDownes, Alexander B., and Mary L. Lilley. 2010. \"Overt Peace, Covert War?: Covert Intervention and the Democratic Peace.\" *Security Studies* 19 (2): 266–306.\nFarwell, James P., and Rafal Rohozinski. 2011. \"Stuxnet and the Future of Cyber Warfare.\" *Survival: Global Politics and Strategy* 53 (1): 23–40.\nFinkle, Jim. 2017. \"Cyber Security Firm: More Evidence North Korea Linked to Bangladesh Heist.\" *Reuters*, April 3. https://www.reuters.com/article/us-cyber-heist-bangladesh-northkorea/cyber-security-firm-more-evidence-north-korea-linked-to-bangladesh-heist-idUSKBN1752I4.\nForsythe, David P. 1992. \"Democracy, War, and Covert Action.\" *Journal of Peace Research* 29 (4): 385–95.\nGartzke, Erik. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.\" *International Security* 38 (2): 41–73.\nGartzke, Erik, and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" *Security Studies* 24(2): 316–48.\nGhosemajumder, Shuman. 2016. \"Here's Why Massive Website Outages Will Continue Happening.\" *Recode*, October 24. https://www.recode.net/2016/10/24/13393922/ddos-attack-denial-service-cybercriminals-hackers.\nGibbs, David N. 1995. \"Secrecy and International Relations.\" *Journal of Peace Research* 32 (2): 213–28.\nGilpin, Robert. 1981. *War and Change in World Politics*. Princeton, NJ: Princeton University Press.\nGosk, Stephanie, Tom Winter, and Tracy Connor. 2015. \"Iranian Hackers Claim Responsibility for Cyberattack on New York Dam.\" *NBC*, December 23. https://www.nbcnews.com/news/us-news/iranian-hackers-claim-cyber-attack-new-york-dam-n484611.\nGross, Richard C. 2009. \"Different Worlds: Unacknowledged Special Operations and Covert Action.\" Technical report, Strategy Research Project, US Army War College.\nHoffman, Bruce, and Gordon H. McCormick. 2004. \"Terrorism, Signaling, and Suicide Attack.\" *Studies in Conflict and Terrorism* 27 (4): 243–81.\nJoseph, Michael F., and Michael Poznansky. 2018. \"Media Technology, Covert Action, and the Politics of Exposure.\" *Journal of Peace Research* 53(3): 320–335.\nKibbe, Jennifer D. 2007. \"Covert Action and the Pentagon.\" *Intelligence and National Security* 22 (1): 57–74.\nKydd, Andrew H., and Barbara F. Walter. 2006. \"The Strategies of Terrorism.\" *International Security* 31 (1): 49–80.\nLibicki, Martin C. 2009. *Cyberdeterrence and Cyberwar*. Santa Monica, CA: RAND Corporation.\nLiff, Adam P. 2012. \"Cyberwar: A New Absolute Weapon? The Proliferation of Cyberwarfare Capabilities and Interstate War.\" *Journal of Strategic Studies* 35 (3): 401–28.\nRethinking Secrecy in Cyberspace\nLin, Herb. 2010. \"Offensive Cyber Operations and the Use of Force.\" Journal of National Security Law and Policy 4 (63): 63-86.\n—. 2016. \"Developing 'Loud' Cyber Weapons.\" Lawfare, September 1. https://www.lawfareblog.com/developing-loud-cyber-weapons.\nLindsay, Jon R.. 2013. \"Stuxnet and the Limits of Cyber Warfare.\" Security Studies 22 (3): 365-404.\n—. 2015. \"Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence Against Cyberattack.\" Journal of Cybersecurity 1 (1): 53-67.\nLister, Tim, Mary Ilyushka, and Radina Gigova. 2017. \"Putin Slams US Election Meddling Claim As 'Lies.'\" CNN, March 30. https://www.cnn.com/2017/03/30/politics/putin-russia-us-election-denial/index.html.\nMahoney, James. 2015. \"Process Tracing As Historical Explanation.\" Security Studies 24 (2): 200-18.\nMaxey, Levi. 2017. \"Homeland Security Council Urges Action Before Cyber 9/11 Strikes.\" *Cipher Brief*, August 27. https://www.thecipherbrief.com/homeland-security-council-urges-action-cyber-911-strikes.\nNakashima, Ellen. 2015. \"Hacks of OPM Databases Compromised 22.1 Million People, Federal Authorities Say.\" Washington Post, July 9. https://www.washingtonpost.com/news/federal-eye/wp/2015/07/09/hack-of-security-clearances-system-affected-21-5-million-people-federal-authorities-say/.\nNye, Joseph S. 2010. Cyber Power. Cambridge, MA: Belfer Center for Science and International Affairs, Harvard Kennedy School.\n—. 2017. \"Deterrence and Dissuasion in Cyberspace.\" International Security 41 (3): 44-71.\nOlson, Parmy. 2012. We Are Anonymous: Inside the Hacker World of LulzSec, Anonymous, and the Global Cyber Insurgency. New York: Back Bay Books.\nPanda, Ankit. 2017. \"How to Make Sense of Offensive US Cyber Operations Against North Korean Military Intelligence.\" Diplomat, October 2. https://thediplomat.com/2017/10/how-to-make-sense-of-offensive-us-cyber-operations-against-north-korean-military-intelligence/.\nPape, Robert A. 2005. Dying to Win: The Strategic Logic of Suicide Terrorism. New York: Random House Trade Paperbacks.\nPerlroth, Nicole, and David E. Sanger 2017. \"Hacks Raise Fear Over N.S.A.'s Hold on Cyberweapons.\" New York Times, June 28. https://www.nytimes.com/2017/06/28/technology/ransomware-nsa-hacking-tools.html.\nPoznansky, Michael. 2015. \"Stasis Or Decay? Reconciling Covert War and the Democratic Peace.\" International Studies Quarterly 59 (4): 815-26.\nRid, Thomas. 2012. \"Cyber War Will Not Take Place.\" Journal of Strategic Studies 35 (1): 5-32.\nRid, Thomas, and Ben Buchanan. 2015. \"Attributing Cyberattacks.\" Journal of Strategic Studies 38 (1-2): 4-37.\nRovner, Joshua, and Tyler Moore. 2017. \"Does the Internet Need a Hegemon?\" Journal of Global Security Studies 2 (3): 184-203.\nSanger, David E. 2012. Confront and Conceal: Obama's Secret Wars and Surprising Use of American Power. New York: Broadway Paperbacks.\n—. 2016. \"U.S. Wrestles with How to Fight Back Against Cyberattacks.\" New York Times, July 30. https://www.nytimes.com/2016/07/31/us/politics/us-wrestles-with-how-to-fight-back-against-cyberattacks.html.\nSanger, David E., David D. Kirkpatrick, and Nicole Perlroth. 2017. \"The World Once Laughed At North Korean Cyberpower. No More.\" New York Times October 15. https://www.nytimes.com/2017/10/15/world/asia/north-korea-hacking-cyber-sony.html.\nSchelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale University Press.\nSchmid, Alex P. 2004. \"Frameworks for Conceptualizing Terrorism.\" *Terrorism and Political Violence* 16 (2): 197-221.\nSharp, Gene, and Marina Finkelstein. 1973. Dynamics of Nonviolent Action. 3rd ed. Boston, MA: P. Sargent Publisher.\nSlantchev, Branislav L. 2010. \"Feigning Weakness.\" International Organization 64 (3): 357-88.\nSlayton, Rebecca. 2017. \"What Is the Cyber Offense-Defense Balance? Conceptions, Causes, and Assessment.\" International Security 41 (3): 72-109.\nSmith, Candace. 2016. \"Anonymous Claims to Hack Donald Trump.\" ABC News, March 17. https://abcnews.go.com/US/anonymous-claims-hack-donald-trump/story?id=37730049.\nStoller, Daniel R. 2017. \"Cybercriminals Taking the Reins from Nation-State Adversaries.\" *Bloomberg Law: Privacy and Data Security Blog* December 8. https://www.bna.com/cybercriminals-taking-reins-b73014472953/.\nSzoldra, Paul. 2016. \"A New Film Gives a Frightening Look at How the US Used Cyberwarfare to Destroy Nukes.\" Business Insider, July 7. https://www.businessinsider.com/zero-days-stuxnet-cyber-weapon-2016-7.\nTemperton, James. 2016. \"FBI Adds Syrian Electronic Army Hackers to Most Wanted List.\" Wired, March 23. https://www.wired.co.uk/article/syrian-electronic-army-fbi-most-wanted.\nValeriano, Brandon, and Ryan C. Maness 2014. \"The Dynamics of Cyber Conflict Between Rival Antagonists, 2001-11.\" Journal of Peace Research 51 (3): 347-60.\n—. 2015. Cyber War Versus Cyber Realities: Cyber Conflict in the International System. Oxford and New York: Oxford University Press.\nVinton, Kate. 2015. \"Syrian Electronic Army Claims Responsibility For Hacking U.S. Army Website.\" Forbes, June 8. https://www.forbes.com/sites/katevinton/2015/06/08/syrian-electronic-army-claims-responsibility-for-hacking-army-website/.\nYan, Sophia. 2015. \"China Blames Criminals for U.S. Government Hack.\" CNN, December 2. https://money.cnn.com/2015/12/02/technology/china-hack-denial/index.html.\nYarhi-Milo, Keren. 2013. \"Tying Hands Behind Closed Doors: The Logic and Practice of Secret Reassurance.\" Security Studies 22: 405-35."
  ],
  "flat_text": "Journal of Global Security Studies, 3(4), 2018, 402-416\ndoi: 10.1093/jogss/ogy022\nResearch Article\nOXFORD\n# Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\nMichael Poznansky and Evan Perkoski\nUniversity of Pittsburgh and University of Connecticut\n## Abstract\nCyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain.\nKeywords: cyber warfare, secrecy, coercion, nonstate actors\n## Introduction\nSecrecy is a defining feature of cyberspace. Cyber intruders can frequently disrupt networks, steal financial assets, and conduct espionage without ever revealing their identities. Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence (Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017) to its influence on the dynamics of conflict and escalation (Gartzke 2013; Buchanan 2017). Yet, while cyber intruders have ample opportunities to keep their sponsorship a secret, not all choose to take advantage. To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions (Smith 2016). They are not alone; SOBH Cyber Jihad, based in Iran, claimed credit for hacking into the control system of a dam in New York (Gosk, Winter, and\nConnor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015 (Vinton 2015).\nWhy do some actors claim responsibility for cyber operations while others opt for anonymity? To answer this question, we explore the logic of credit-claiming for two key sets of actors in cyberspace: states and politically motivated nonstate actors (hereafter, nonstate actors).\nWe argue that credit-claiming, including the manner in which culpability is communicated, depends on what the intruder wants to accomplish. For states, credit-claiming is most appealing during operations that require target compliance, otherwise known as cyber coercion. When states choose to make their identities known to coerce targets, they are more likely to do so privately since public credit-claiming raises the odds of escalation. Anonymity is most attractive during operations where\n We bracket nonstate actors without political motivations.\nPoznansky, Michael, and Evan Perkoski. (2018) Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution. Journal of Global Security Studies, doi: 10.1093/jogss/ogy022\n© The Author(s) (2018). Published by Oxford University Press on behalf of the International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nThis argument requires a conceptual shift in how we think about secrecy in cyberspace. Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations (Kibbe 2007). The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise (Axelrod 1979; Slantchev 2010). The latter involves the use of secrecy to conceal the sponsor of an operation (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson 2016). Importing this distinction to the cyber domain helps clarify when secrecy is an operational imperative and when it is a choice that actors make. In brief, the advantages afforded to targets who learn of imminent or ongoing operations means that cyber intrusions will almost always be conducted clandestinely. Once an operation is complete, however, intruders are free to choose whether to claim responsibility. Put differently, cyber operations are almost always clandestine but not necessarily covert. The failure to recognize this distinction partly contributes to the widespread assumption that anonymity is an immutable feature of cyberspace rather than something actors select into.\nRigorously testing these claims would require access to the internal deliberations of state and nonstate actors to understand how decisions about credit-claiming are made. At present, this is a nearly impossible task (Buchanan 2017, 12). We are perhaps decades away from gaining access to the types of declassified documents necessary to evaluate the deliberations of states; the problem is even more acute for nonstate actors. As a second-best option, we leverage a range of sources—secondary materials, news reports, official government statements, and interviews—to assess the plausibility of our argument. Our study is closer to an exercise in theory construction than theory testing (Mahoney 2015, 201).\nThis article makes several contributions. First, it joins together a burgeoning literature centered on the dynamics of secrecy in world politics and another focused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation (Carson 2016), and the relationship between democratic peace theory and covert regime change (Downes and Lilley 2010; Poznansky 2015). These studies are tied together by an overarching focus on how actors use secrecy to pursue their political goals. Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike (Gartzke 2013; Gartzke and Lindsay 2015; Lindsay 2015; Rid and Buchanan 2015; Buchanan 2017; Nye 2017) but have largely neglected the determinants of secrecy at the stage where sponsors can (dis)claim ownership of an operation. We address this issue directly.\nSecond, this study is among the first of which we are aware that considers the goals and constraints of the two most important actors operating in cyberspace—states and nonstate actors. Existing research tends to focus on the former (Gartzke 2013; Buchanan 2017; Borghard and Lonergan 2017; Nye 2017). But nonstate actors conduct cyberattacks at high rates and often in very visible ways. Moreover, their attack capabilities are growing and in some cases they \"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\" (Stoller 2017). Ignoring nonstate actors or assuming that their strategic logic mirrors that of states is insufficient. Our approach is thus to ask the same questions for both sets of actors, reducing barriers that inhibit a more complete understanding of cyberattacks.\n## The Problem of Secrecy\nThe conventional view of a cyber operation is an intruder quietly penetrating a target's network to collect information or cause damage, whether virtual or physical, without betraying their identity. This narrative—which assumes secrecy from start to finish—colors how the literature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant (Slayton 2017). Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks (Rid and Buchanan 2015; Nye 2017, 49–52). According to Lindsay (2013), “[f]orensics takes months, whereas the anonymous attack can present\n\nRethinking Secrecy in Cyberspace\nitself and perhaps complete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity (Lindsay 2015, 58).\nThe pervasiveness of secrecy in this domain also poses challenges for cyber coercion (Valeriano and Maness 2014; 2015, 79; Nye 2017, 55-56). Coercion requires victims to know who is making demands and what they are being asked to do (Schelling 1966). Anonymity is antithetical to this enterprise. As Gartzke (2013) once put it, \"How does one surrender to no one in particular?\" (47). Some scholars point out that perpetrators can enhance the credibility of coercive threats by making their identities known, a point we develop more fully below. But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace (Borghard and Lonergan 2017, 457-59; Libicki 2009, 50-51).\nWhile all of these studies seem to address the same basic phenomenon—secrecy—there are meaningful differences when it comes to what is being concealed during an operation and for what purpose. The next section explores these differences.\n## Disaggregating Secrecy\nThe US military and intelligence communities distinguish between two types of secret operations. The first are clandestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise (Axelrod 1979; Slantchev 2010). As an example, consider Operation Neptune Spear, the US Special Forces' raid on Osama bin Laden's compound in Abbottabad, Pakistan. While the raid itself was shrouded in secrecy, President Obama's remarks to the nation afterward suggest that the purpose of secrecy was tactical, not political.\nThe second type of secret operation is covert action, defined as \"[a]n operation that is so planned and\nFigure 1. Clandestine and covert operations\nexecuted as to conceal the identity of or permit plausible denial by the sponsor.\"6 While covert operations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\" (Gross 2009, 12). There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns (Brown 2014; Carson 2016) and avoiding hostile reactions from domestic and international observers (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson and Yarhi-Milo 2017; Joseph and Poznansky 2017). A classic covert operation is the Bay of Pigs. Training fifteen hundred exiles to storm the shores of Cuba to overthrow Fidel Castro was a highly visible act; the sponsor, the United States, was supposed to remain hidden.\nFigure 1 presents four different combinations of secret operations with illustrative examples.7 Cases in the northwest quadrant include cyber intrusions that are planned and executed clandestinely and denied by the sponsor. These are what observers typically have in mind when discussing the attribution problem in cyberspace. The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases (Betz and Stevens 2011, 95). Examples in the northeast quadrant are covert because the sponsor denied complicity but are not clandestine since the activities themselves, typically performed by third parties, are not hidden. Examples in the southeast corner include large-scale wars.\n\nThis is taken from the Department of Defense's Dictionary of Military and Associated Terms, available at http://www.dtic.mil/doctrine/dod/dictionary/. Although this definition is focused on government entities, the same logic applies broadly.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nThese are neither covert (the sponsor was known) nor clandestine (the wars were announced in advance).\n## Secrecy in Cyberspace\nStudents of cyber warfare rarely distinguish between clandestine and covert forms of secrecy. As such, most studies do not explicitly address where secrecy is a de facto requirement rather than a choice in the course of a cyberattack. Figure 2 portrays a stylized schematic of cyber intrusions, capturing two of the key inflection points where actors make decisions about secrecy.\nAt  $\\mathrm{T_0}$ , perpetrators decide whether to announce to the target that an attack is imminent or whether they will conceal the operational details as in a clandestine operation. In almost all cases, perpetrators will choose the latter. Doing otherwise is counterproductive since publicizing even the most basic details of a pending operation affords the target an opportunity to enact countermeasures. Announcing that \"[you] will attack this network with this effect unless [the target] refrain[s] from X\" would be \"self-defeating\" (Lindsay 2015, 55). Acting clandestinely raises the likelihood of success by denying victims the chance to take steps that might blunt the efficacy of the attack such as patching a vulnerability or cutting access to servers. This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim.[8] Even when the perpetrator is not relying on zero days,\nthey still will not want to announce the exact vector by which the intrusion will occur to avoid jeopardizing the operation.\nActors have the most agency when it comes to secrecy and deception after an attack occurs at time  $\\mathrm{T}_{1}$ . Here, perpetrators must decide whether to proceed in a manner consistent with covert action (denying their role) or not (claiming it). Should a perpetrator choose to forgo plausible deniability, they must then decide how to communicate complicity. The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity (Libicki 2009, 50-51; Nye 2017, 51). Perpetrators can do this by leaving clues in the course of the attack—for example, leveraging a vector they have been known to use before, reusing code from a previous intrusion, or otherwise leaving signatures in the source code of malware. Or they might communicate through discrete diplomatic channels with a foreign counterpart (Borghard and Lonergan 2017, 459).\nThe second means of communicating complicity, public acknowledgment, refers to a situation where the perpetrator openly pronounces their identity to a much wider audience following an attack. They might make a public statement or alert the media of their culpability. Explaining why some actors intentionally dispense with anonymity—and, for those that do, whether they will credit-claim publicly or privately—is the focus of the next two sections. For now, it will suffice to point out that the attribution problem ceases to exist in cases where the perpetrator willingly makes their identity known.\nActors can, and often do, opt to act both clandestinely and covertly in the course of a single operation (Betz and Stevens 2011, 88). Our rationale for distinguishing between the two is to make clear that while clandestinity is a technical requirement of almost all cyber operations the decision to act covertly is something perpetrators consciously select into. In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.[9]\nIn what follows, we use these distinctions to address our original puzzle regarding why some actors claim responsibility for operations while others choose to remain anonymous. The next section discusses the politics of credit-claiming for states. We then turn to nonstate actors, a neglected but important player in the cyberspace arena.\n\nRethinking Secrecy in Cyberspace\n# States and the Politics of Voluntary Attribution\nWhether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion.[10] If success is possible without the target consciously acceding to some demand, states will act covertly and hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission.[11] In terms of how they eventually reveal complicity, we argue that states are most likely to use private channels and discrete communication.\n# When States Come Clean\nWhen the success of state-sponsored cyber operations does not require target compliance, voluntary credit-claiming is unnecessary at best and counterproductive at worst. In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage.[12] Like any intelligence gathering effort, voluntary attribution would be disadvantageous. Should a perpetrator announce that they have penetrated an adversary's network, they will jeopardize both their intrusion method and continued access without reaping any obvious benefit in return. Preserving anonymity is thus the preferred option for states interested in stealing secrets in cyberspace.\nAnother class of cyber operations, political action and sabotage, is also best served by perpetual anonymity. Examples include operations to influence elections through disinformation campaigns, vote manipulation, and the destruction of physical equipment and critical infrastructure. Because the success or failure of these operations does not depend on the target consciously responding to specified incentives, the motivations for states to voluntarily claim credit should be correspondingly low.\nThe calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful (Schelling 1966). When operations require that the\n\ntarget accede to a set of demands—either to do something (change the status quo) or to refrain from doing something (preserve the status quo)—states are likely to shun anonymity and engage in voluntary attribution. The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim (Carson and Yarhi-Milo 2017). Remaining anonymous does little to advance these aims. As Liff (2012) notes, “[u]nder most circumstances, any would-be aggressor who does not identify itself forfeits the ability to coerce its adversary” (414). Anonymity makes it hard for targets to evaluate the credibility of a threat and the sender’s resolve. Credit-claiming is thus critical if cyber coercion is to have any chance of succeeding. Betz and Stevens (2011) hint at this: “[W]hen states use military cyber-power against other states for the purposes of compelling them to do their will, they still have to declare what it is (even after the event). There is no sneaky way around this fact” (95). It is worth reiterating, however, that this can only feasibly be done after the attack has ended. As discussed earlier, providing details beforehand could undermine the mission and render the coercive threat impotent.\nForgoing anonymity permits states to more effectively make coercive threats by demonstrating credibility and resolve in at least two ways. First, a claimed attack can function as a costly signal by showing the threatening party's willingness to expend valuable resources in the hopes of gaining compliance from the target. According to Borghard and Lonergan (2017), \"[t]he greater the cost to the initiating state of producing a given signal, ceteris paribus, the more effective the signal is as an indication of the initiating state's resolve\" (467).\nSecond, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power.[13] Prestige and power, though related, are not the same. The latter refers strictly to capabilities, which can never be fully observed in cyberspace owing to the premium placed on keeping these tools shrouded in secrecy. The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\" (Gilpin 1981, 31).[14] States who cultivate a reputation for cyber power may be able to\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nIt is worth briefly outlining how the dynamics of cyber prestige and coercion could operate in practice. When the goal is to compel a target to alter their behavior, perpetrators may take offensive action in cyberspace, claim credit for it, and threaten future punishment should the target fail to comply. When the goal is to deter some action, perpetrators may similarly be able to take offensive cyber action, claim credit for it, and threaten future punishment should the target act in ways deemed undesirable by the sender. A more plausible situation in the case of cyber deterrence might entail the victim of a recent attack retaliating against the perpetrator, voluntarily claiming credit, and threatening future harm should there be any further attacks against them. In each of these scenarios, cyber coercion is possible to the extent that the target believes the sender's promises of future pain are credible and that the threatener is resolved as a result of having claimed past attacks. It is \"the threat of . . . more damage,\" or the \"expectation of more violence,\" that may induce a target to give in (Schelling 1966, 3; emphasis in original).\nThere is obviously no guarantee that claiming credit for past attacks will generate the credibility necessary for coercion. If the target does not believe that the challenger has the ability or willingness to repeat similar or more painful attacks, issuing deterrent or compellent threats after claiming an intrusion with the promise of \"more where that came from\" won't work. Nevertheless, we are skeptical that observers never update their beliefs about an actor's capabilities and resolve, and opt instead to treat every attack as an isolated event. While Russia is unlikely to easily hack the Democratic National Committee again, for example, few observers doubt their capacity to carry out similar attacks in the future. Whether credible coercive threats will actually suffice to achieve concessions, while important in its own right, is a separate matter and depends on a complex cost-benefit calculation.\n## Escalation and the Means of Communication\nThis section focuses on the right-hand side of Figure 2, after an actor chooses to forgo plausible deniability $(\\mathrm{T}_1)$ and decides whether to claim responsibility publicly or privately. We argue that the unique dynamics of politically motivated, state-on-state cyber activity make public acknowledgment less attractive than private acknowledgment. There are several reasons for this.\nAs a general matter, opportunities for retaliation are higher when the actors involved are states. Unlike non-state actors, states are stationary, immobile entities with numerous targets available to hit. Concern about attacks against a state's critical infrastructure have been likened to a potential \"cyber 9/11\" (Maxey 2017). Moreover, perpetrators that publicly announce sponsorship of a cyberattack put the victim—in many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige (Carson and Yarhi-Milo 2017, 135).\nBecause the victims of publicly claimed, state-sponsored cyberattacks typically have both the opportunity to retaliate as well as strong domestic-level pressures to do so, nation-states interested in cyber coercion face powerful incentives to quietly claim their actions using private channels. While credit-claiming in private lacks the broader prestige benefits associated with publicity and limits the audience observing an operation's (physical) costly signals, it may nonetheless afford states an opportunity to engage in coercive diplomacy at reduced risk. Recent scholarship shows that states often face powerful incentives to collude with one another in acts of secrecy. For example, Carson (2016) argues that states may opt not to publicize the covert military actions of their rivals even when they are targeted as a way of keeping conflicts limited and contained. A similar logic should apply to discrete attempts at coercion in cyberspace.\nOne risk of private acknowledgment is that the victim will \"out\" the perpetrator by publicly announcing the occurrence of an intrusion and offering proof that the attacker sought to privately attribute themselves. While this is always a possibility, such concerns may not wholly disincentivize states from pursuing private acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them (Rid 2012, 28–29). This, in turn, can motivate perpetrators to quietly come clean with little fear of being exposed by the victim. Second, when victims have the capacity to out a state\n For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).\nRethinking Secrecy in Cyberspace\npursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases. This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity (Yarhi-Milo 2013, 407).\n# Nonstate Actors and the Politics of Voluntary Attribution\nThe discussion so far has focused on the conditions under which states will claim credit for cyberattacks and why they are more likely to do so privately. This is important for obvious reasons. However, nonstate actors dominate the empirical record of credit-claiming in cyberspace. In what follows, we explain why nonstate actors commonly claim attacks and why they tend to do so publicly.\nDrawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means (Nye 2010; Asal et al. 2016). Regardless of their method of contention, nonstate actors are agents of change operating in a structural environment in which they are severely disadvantaged. These groups wield significantly fewer resources than states—financial, material, and otherwise—and their capabilities are consequently more constrained and more uncertain. In addition, what few capabilities nonstate actors do possess are in large part a function of the number of participants they can organize. This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well (Asal and Rethemeyer 2008; Chenoweth and Stephan 2011). The same basic logic extends to nonstate actors operating in cyberspace. One of the most common tools in a group's cyber arsenal, the distributed denial of service (DDoS) attack, grows stronger with every additional user.\nOur primary claim is that nonstate actors are more likely than states to brazenly claim cyberattacks. Not\n See also Carson and Yarhi-Milo (2017, 135).\n On the importance of states for Internet politics, see Rovner and Moore (2017).\n To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.\nonly does this help showcase their capabilities, but the media attention can help attract new members to the cause. Additionally, since it is often difficult to bring these groups to justice, organizations like Anonymous, Lulzsec, and others face reduced incentives to keep quiet about their operations. In sum, complicity is a critical component of nonstate actors' strategic logic and they commonly announce sponsorship of cyberattacks as a result.\n# The Appeal of Credit-Claiming\nNonstate actors typically have coercive objectives. As Schelling wrote in 1973, \"[p]olitical violence, like political nonviolence, usually has as its purpose making somebody do something or not do something or stop doing something. The aim is to influence behavior.\" In a broad sense, their goals are comparable to those of states seeking to alter the behavior of their adversaries.\nAbove, we argue that a key component of coercion is credibility: can actors issuing coercive threats make good on their promises of more pain if the target resists? This is especially difficult for nonstate actors (Hoffman and McCormick 2004; Kydd and Walter 2006; Dannenbaum 2011). They cannot put on military parades to show off their latest weaponry, do not have the means to finance modern military forces, and lack the resources—territorial, bureaucratic, and financial—of states. It is easy to dismiss the demands of nonstate actors as inconsequential chatter.\nGiven these deficits, the issue of how to boost credibility features centrally in the strategic logic of politically motivated nonstate actors. As with states, one way to demonstrate capabilities and resolve is to take action perceived as a costly signal. According to Kydd and Walter (2006), \"[b]ecause it is hard for weak actors to make credible threats, terrorists are forced to display publicly just how far they are willing to go to obtain their desired results\" (50). Similarly, Abrahms (2013) writes that \"[t]errorism . . . adds credibility to threats by showing that nonstate challengers possess the power to hurt\" (661).\nFor nonstate cyber warriors, sending costly signals to bolster credibility may include defacing government websites, launching distributed denial of service attacks,\n To the extent that they run the risk of capture, however, the credibility of their signals goes up.\n Quoted in Sharp and Finkelstein (1973, xx).\n Doing so might expose their position and invite unwanted risk.\n One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nA history of successful attacks by a nonstate group can also help cultivate their prestige in much the same way it does for states. As such, nonstate actors stand to lose by not identifying their organization as responsible for an attack. Failing to communicate culpability negates an operation’s objectives and precludes nonstate actors from reaping signaling and reputational benefits that are critical to successful coercion. Without knowing who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities. It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own (Bloom 2005, 78–79).\n## Maximizing Publicity\nThe notion that nonstate actors are more likely to claim attacks to showcase their capabilities and resolve mirrors a similar motivation among states interested in cyber coercion. Where the two diverge is in the preferred method of claiming. Several factors make nonstate actors more likely to choose public rather than private acknowledgment.\nOne reason nonstate cyber warriors crave the limelight hinges on the audiences they seek to influence. These\n It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.\n Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).\ngroups are often interested in sending a message not just to adversarial governments but to their populations as well. The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance (Schmid 2004). As Crenshaw (1981) notes in a related context, “[t]he victims or objects of terrorist attack have little intrinsic value to the terrorist group but represent a larger human audience whose reaction the terrorists seek” (379).\nUltimately, terrorists target the public since they are too weak to confront the state head-on. The same should be true of nonstate actors in cyberspace since these groups face comparable disadvantages. For such a strategy to work, however, communication cannot be private; it must be visible, clearly attributed, and widely known to the government and public alike.\nA second reason nonstate actors in cyberspace prefer public methods of claiming credit turns on their desire to attract new recruits. Like their traditional counterparts, these actors are interested in survival and growth. According to Pape (2005), “terrorism has two purposes—to gain supporters and to coerce opponents. Most terrorist campaigns seek both goals to some extent, often aiming to change the target state’s policies while simultaneously mobilizing support and recruits for the terrorists’ cause” (7). Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization (Abrahms 2008, 379) and augment their coercive ability. It is well established that the power of civil resistance flows from mobilization numbers, and the same goes for organizations in cyberspace. When it comes to their operating methods, these groups favor tactics that grow more powerful with additional bots and active supporters. The strength of DDoS operations, for instance, is linked to the number of machines involved (Ghosemajumder 2016). The Low Orbit Internet Cannon (LOIC) and related variants draw strength from those who download the application and flood a server. With more members at their disposal, groups are able to launch increasingly formidable cyber operations.\n On the determinants of DDoS attacks, see Asal et al. (2016).\n It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.\nRethinking Secrecy in Cyberspace\n# Plausibility Probes\nA lack of readily-accessible decision-making documents complicates rigorous empirical tests of our argument. If we are right that state-sponsored cyber operations involving espionage and sabotage are prime candidates for secrecy before, during, and after execution, it might be decades or longer before relevant materials are declassified.27 While coercive cyber operations are more likely to involve credit-claiming, the advantages of claiming attacks privately also impede observation. In fact, outsiders might be unable to discern differences between victims who are truly ignorant of their attacker's identity and those that feign ignorance while privately communicating with their attackers.\nAs a second-best strategy, we examine publicly available sources including news reports and a range of secondary materials to provide a preliminary test of our argument. We also conduct two interviews: one with a former Defense Department official involved in cyber policy and one with a former member of Anonymous. These helped corroborate what we found in the public record.\n# States\nWe were unable to find a single case of a state claiming credit for a cyber espionage operation, either openly or privately. Rather, the cases that have inadvertently come to light underscore the vigor with which states seek to avoid being named. China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative (Nakashima 2015). In the aftermath of the intrusion, Chinese officials denied complicity, placing blame on criminal hackers. They even went so far as to claim that they had arrested individuals who were connected with the hack (Chalfant 2017).28 Another example is Russia's alleged interference in the 2016 US election. The \"theft of research and emails from the Democratic National Committee\" for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government (Sanger 2016).29\n\nWhen asked in March 2017 about whether Russia was behind the efforts to discredit Hillary Clinton, Putin responded with \"Read my lips: No\" (Lister, Ilyushka, and Gigova 2017). When it comes to cyber espionage, there is no benefit to be had from credit-claiming.\nStuxnet provides a useful illustration of why decision-makers sometimes cling to anonymity and, more interestingly, the conditions under which they might be willing to voluntarily claim credit.30 Stuxnet, formally known as \"Olympic Games,\" was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant (Farwell and Rohozinski 2011). The aim was to make the Iranians believe their centrifuges were failing for reasons other than foreign interference. Sanger (2012) writes the following: \"When the centrifuges first began crashing in 2008 at the Natanz enrichment center, the crown jewel of the Iranian nuclear program, the engineers inside the plant had no clue they were under attack. That was exactly what the designers of the world's most sophisticated cyberweapon had planned.\" He continues that \"[t]he idea, hatched in Washington and Jerusalem, was to make the first breakdowns seem like random accidents and small ones at that\" (188).\nSanger's interviews with government officials confirm that the operation was supposed to leave no trace of US fingerprints: \"The most elegant cyber weapons are a lot like the most elegant bank frauds. . . . They work best when the victim doesn't even know he's been robbed\" (190-91). It is clear from this account that the United States kept both the operation and their sponsorship intentionally hidden, as our argument predicts. The success or failure of the operation did not depend on Iran changing their behavior, but simply hinged on the quiet destruction of centrifuges.\nInterestingly, though, some US operatives contemplated quietly alerting the Iranians that the United States was responsible for the attack. Their apparent rationale conforms to our theoretical expectation. Ostensibly, the goal would have been to send a message to Tehran that the United States had the ability to keep targeting their systems, presumably as a way of achieving concessions on the nuclear program. According to Sanger (2012), \"[a]t both the Pentagon and inside the intelligence agencies some of the creators of the bug believed that it might be\ninformation to relevant entities who could use it to discredit Hillary Clinton. Even if so, this type of action would qualify as a classic covert operation, and thus we would still expect Russian denials.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nMore recent examples suggest that states are thinking hard about voluntarily claiming credit for their cyber operations in the service of coercion. In late September 2017, it came to light that the Trump administration authorized US Cyber Command to carry out a range of limited cyberattacks against North Korea's Reconnaissance General Bureau intended to interfere with Internet access (DeYoung, Nakashima, and Rauhala 2017). Most importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy.[32] Panda (2017) argues that the United States had \"take[n] the cyber equivalent of a shot across North Korea's bow, presumably signaling that it has the requisite access to North Korean networks to deliver considerably more significant damage in wartime.\" Since North Korea is not wanting for enemies, it seemed to serve US objectives to let their complicity be known, thereby reducing ambiguity about what behavioral changes were expected from the Kim regime.\nFurther evidence for our theory comes from recent statements by Shawn Turskey, the executive director of US Cyber Command. His comments from 2016 indicate that the United States government is contemplating ways to leverage cyber capabilities for coercive purposes,\n\nspecifically through intentional credit-claiming. Turskey declared the following:\nIn the intelligence community you never want to be caught, you want [to] be low and slow, you never really want to be attributed. . . . But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know. (Bing 2016, emphasis added)\nThese remarks are noteworthy for several reasons.[33] Chief among them is the prospect of the world's lone superpower developing an arsenal of cyber weapons with a return address. The fact that loud, attributable weapons are being discussed at all is at odds with the typical portrayal of cyberspace as a domain defined by secrecy and anonymity. Yet, it is easier to understand why Turskey is contemplating this shift once we come to terms with the mechanics of cyber coercion. Leveraging cyber assets for coercive purposes, rather than espionage or sabotage—which fits more readily within the purview of the military as opposed to the intelligence community—requires credible self-attribution. Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal (Lin 2016).\nMichael Sulmeyer, the former director for Plans and Operations for Cyber Policy in the Office of the Secretary of Defense, affirmed this sentiment in an interview for this article. Echoing the idea that cyber weapons can and should be embraced for more traditional purposes, he highlights the following:\nIt is important for the United States to invest in capabilities that not only help it improve its espionage activities against adversaries, but also that help it prevail in the event of hostilities with adversaries. When operating in the realm of the second objective, it can be beneficial for the United States to take responsibility for its actions publicly—not to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.[34]\nTaking responsibility, as Sulmeyer suggests, provides America's adversaries the chance to understand the extent of their cyber power. Similar to Turskey, Sulmeyer anticipates that more voluntary credit-claiming may be on the horizon:\n\nRethinking Secrecy in Cyberspace\nTo be sure, this signal could be missed or dismissed—and a mere tap on the digital shoulder clearly would not suffice for such a signal to be internalized. But why go through all the effort to hide every action every time in this context? That's an unnecessary additional burden in a war fight. If there are a suite of capabilities that can help our forces be more agile during hostilities, I would hope they are on the table for our commanders and leaders in the future.\n## Nonstate Actors\nThe empirical pattern of cyberattacks by nonstate actors differs from what we observed for states. These actors frequently claim credit for their cyberattacks in very public ways. Much like terrorist attacks, these operations almost always entail a political message intended to alter public opinion, change government policies, and the like. A cyberattack carried out by the Syrian Electronic Army against the US Army's website showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion (Vinton 2015). Quietly alerting the US Army that the Syrian Electronic Army was behind the attacks would have undermined the strategic motivations underlying the entire operation, namely bolstering their reputation as a group that deserves respect and sending a clear message with the intention of affecting public opinion and altering policy. The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list (Temperton 2016).\nFor a more complete picture of the decision-making process for nonstate actors in cyberspace, we briefly examine one of the most well-known organizations: Anonymous. Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article (Olson 2012; Coleman 2014). Anonymous’ behavior following this shift, though, sheds light on the group’s political strategy and how publicity and attention serve their goals.\nA cursory overview of Anonymous’ exploits over the years shows that the group commonly claims credit publicly for its operations. In late March 2016, Anonymous targeted roughly twenty Angolan government websites in response to the arrest of several activists. Prior to carrying out the attack, they posted details about the websites\nthey intended to target (British Broadcasting Company 2016). In one of their biggest and best-known campaigns, Operation Tunisia, the group first put out a press release via YouTube before a launching series of DDoS attacks that took down numerous government-linked websites. This was part of a broader operation intended to assist protesters and weaken the government of Ben Ali. Most relevant for our purposes, the group issued a clear coercive threat: “This is a warning to the Tunisian government: attacks at the freedom of speech and information of its citizens will not be tolerated. . . . Free the net, and the attacks will cease, keep on that attitude and this will just be the beginning” In another high-profile incident, Anonymous targeted the Church of Scientology. As before, the attack began with a YouTube press release and proceeded with a series of DDoS attacks, doxing, and more press releases and media statements. In line with our expectations, the IT company hired by the Church of Scientology implored them to simply ignore the attacks: “Don’t issue warnings or threats to the attackers via the media; this will only keep the issue alive, raise tempers, and greatly increase the possibility of another assault. Most DDoS attackers seek publicity, so don’t hand it to them on a silver platter.” Their solution was to deprive Anonymous of what it wanted most, namely attention.\nThis strategy of pursuing highly visible, self-attributed missions served at least three functions. First, Anonymous used these operations to ensure that they were taken seriously and that their coercive threats were not ignored. Establishing their capabilities, resolve, and credibility by conducting attacks with clear attribution contributed to this effort. This was explicit in their internal conversations during the operation against the Church of Scientology. As one member put it, “I think it’s time for [us] to do something big. People need to understand not to f*** with [Anonymous].” These and other attacks proved somewhat successful. Outside observers came to understand that they should not dismiss the group’s threats. Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility” (Olson 2012, 177).\nSecond, Anonymous recognized that part of their strategy revolved around the public. During Operation Payback in 2010, which aimed to promote Internet privacy by targeting antipiracy groups, members of\n See https://www.youtube.com/watch?v=BFLaBRk9wY0.\n Quoted in Coleman (2014, 149).\n See https://www.youtube.com/watch?v=JCbKv9yiLiQ.\n Quoted in Olson (2012, 89).\n Quoted in Olson (2012, 2).\nInterview with authors, October 26, 2017.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\nAnonymous ardently debated this component of their strategy. Support eventually developed for one member who claimed that “... these attacks are less about hurting the business than drawing attention and forcing the media to cover the story. . . . The point for me is that this is the technological way of mass protesting that’s actually effective.”41 Getting their message out to the public to garner attention became a core objective.\nAnonymous’ operations often did more than just influence the public indirectly via messaging; sometimes the public was the direct target of attacks. Anonymous, like most terrorist groups, eventually had to reconcile with the fact that targeting innocent civilians might be useful for achieving their aims. This issue came to a head during Operation BART (Bay Area Rapid Transit), when members leaked information on individual passengers, including credit card numbers and other details from the company’s website. When asked about the incident by a reporter, a senior member replied, “[h]ow else do you get the world to respond and secure your information? How else do you get these companies and these big governments to keep your information, the information you give them voluntarily, safe? I think we got our message across, and I’ll bet you one thing: I’ll bet you they fix that.”42 Anonymous’ symbolic, essentially random targeting was part of a broader campaign to influence public opinion and achieve political change. Their cyberattacks were acts of coercion that bore a striking resemblance to the strategic logic of militant organizations.\nFinally, Anonymous’ cyber behavior was often geared toward generating new members and deepening support among their base. In an interview conducted for this article, we asked Hector Monsegur, a former leader of Anonymous known as Sabu, why the group was so eager to publicly claim their operations. As he put it,\nAt the time of its height (not so much now) Anonymous had gained huge successes in publicizing its protests, hacks, and engagements. They were masterful in the distribution of content, and the media truly ate it up for several reasons:\nIt was neatly packaged and ready for distribution, the hackers were willing to give interviews, and of course the mystery element. The whole thing about the mask and shadowy figures really “sells” the concept. As Anonymous grew in action, it also grew in numbers and support . . .\nThe truth of the matter is that Anonymous needed the media to grow, and this explains why many of the\nthings we did were really attention-grabbing. It served a purpose. It’s very similar to branding and how companies slip in their products into film, or events in general, even if each engagement or hack had different motivations.43\nIn her research on Anonymous, Coleman (2014) expands on this point: “[W]ithout the appearance of a critical mass, the operation would have likely lacked moral gravitas and authority. In this case, strength in numbers conveyed a potent message” (138). Expanding their membership didn’t just provide Anonymous legitimacy; it provided additional capability as well. While many of Anonymous’ DDoS campaigns relied on botnets to create their desired effect, individual users sustained those attacks that used the freeware LOIC, a staple of the group’s earlier activity. This required the group to invest time in assisting new members with the software. Olson (2012) points out that the group felt it was worth it to take the time “getting the [new members] on board to create an army” (65).\nUltimately, it was in Anonymous’ interest to take credit for their cyber operations through highly visible, public means of communication. Doing so rewarded their efforts significantly and was instrumental to their strategic logic. Whether the target was the Tunisian government or the Church of Scientology, the attention they received bolstered their particular brand of coercion. This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance (Coleman 2014, 107).\n## Cybercrime and Cyber Blackmail\nBefore concluding, it is worth flagging two types of cyber operations perpetrated by state and nonstate actors alike that are unlikely candidates for voluntary attribution. The first are operations involving theft of financial or intellectual assets. These are among the most common kind of cyberattack and are ill-served by credit-claiming. Malicious actors that leverage cyber assets for criminal purposes, such as stealing money from banking institutions, have little incentive to self-attribute. Doing so would provide little benefit and expose them to potential prosecution. While nonstate actors most commonly conduct these kinds of attacks, states may as well. For example, North Korea was identified as the responsible party in a cyber heist against Bangladesh’s central bank. Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million (Finkle 2017).\n\nRethinking Secrecy in Cyberspace\nA second unlikely candidate for voluntary attribution is what we might call “cyber blackmail,” or operations in which the perpetrator leverages stolen assets, embarrassing secrets, and the like to achieve compliance from the victim without having to reveal their true identity. These operations are particularly interesting in that success requires target compliance—which we argue should lead to credit-claiming—but the perpetrator can remain behind a mask. By selectively releasing compromised information and assets to the victim publicly or privately (Lindsay 2015, 57), the perpetrator may be able to force compliance while remaining anonymous or hiding behind front groups.\nThis dynamic approximates what might have happened during the Sony hack, in which the “Guardians of Peace” (#GOP) issued an explicit compellent threat against Sony in an attempt to prevent the company from releasing The Interview, a comedy satirizing North Korea’s leader Kim Jong Un. In the event that Sony failed to comply with #GOP’s demands, the group threatened to release propriety information and potentially embarrassing e-mail correspondences between high-level employees. Although North Korea was widely suspected of sponsoring the attack, the regime denied any involvement. Nonetheless, the attack partially succeeded in coercing Sony without the government having to explicitly take credit. We believe that the attack was partially successful as a result of Sony’s understanding that certain assets (personal e-mails, financial records) had indeed been compromised and would be released should they fail to comply.\n## Conclusion\nThis article draws on existing theory to develop an explanation for why states and politically motivated non-state actors might voluntarily claim credit for their attacks. We argue that the goals of an operation as well as the characteristics of the perpetrator drive both the decision to claim credit as well as the manner in which culpability is communicated. This research has several important implications. First, we show how states and nonstate actors share a common set of choices with regards to secrecy in cyberspace. Both face the same decisions at the same points in the life cycle of a cyberattack, yet the characteristics of each can cause their strategies to diverge, particularly when it comes to the optics of credit-claiming. Future research should continue to investigate how the characteristics and operational and strategic goals of cyber actors influence the look and feel of their cyber actions.\nSecond, existing research often treats cyber operations as distinct from more traditional elements of state power. Although there are differences, the framework developed here suggests that states may be able to leverage cyber assets to achieve many of the same goals most frequently pursued with conventional forces. Scholars have pushed back against this idea for a variety of reasons, one being the attributional difficulties of cyber operations. But states need not conceal their complicity in perpetuity. By relaxing this assumption, we can more easily see how these operations fit into a state’s coercive toolkit. One area ripe for future research is the efficacy of coercion in cyberspace, both on its own and in comparison to more conventional methods.\nFinally, while inferring intentions from behavior is problematic, actors’ decisions to privately or publicly acknowledge sponsorship of an attack may provide crucial information about motives and identity. Clinging to covert forms of secrecy after the completion of an attack might highlight a set of plausible underlying motivations for the initial intrusion, including espionage, cybercrime, and the like. Conversely, if the actor does come clean, it might be appropriate to infer that credibility, prestige, or coercion was the true goal. In the information-starved domain that is cyberspace, these clues may be all there is when designing policies and crafting responses.\n## Acknowledgements\nThis is one of several collaborative projects by the authors, and the ordering of names follows a principle of rotation. We are grateful to Joseph Brown, Ben Buchanan, Ryan Evans, Robert Jervis, Joseph LaPalombara, Herb Lin, Jon Lindsay, Joseph Nye, Joshua Rovner, and Michael Sulmeyer for helpful comments, suggestions, and insights. An earlier version of the argument presented here appeared in War on the Rocks.",
  "citations": {
    "style": "superscript",
    "flat_text": "Journal of Global Security Studies, 3(4), 2018, 402-416\ndoi: 10.1093/jogss/ogy022\nResearch Article\nOXFORD\n# Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\nMichael Poznansky and Evan Perkoski\nUniversity of Pittsburgh and University of Connecticut\n## Abstract\nCyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain.\nKeywords: cyber warfare, secrecy, coercion, nonstate actors\n## Introduction\nSecrecy is a defining feature of cyberspace. Cyber intruders can frequently disrupt networks, steal financial assets, and conduct espionage without ever revealing their identities. Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence (Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017) to its influence on the dynamics of conflict and escalation (Gartzke 2013; Buchanan 2017). Yet, while cyber intruders have ample opportunities to keep their sponsorship a secret, not all choose to take advantage. To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions (Smith 2016). They are not alone; SOBH Cyber Jihad, based in Iran, claimed credit for hacking into the control system of a dam in New York (Gosk, Winter, and\nConnor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015 (Vinton 2015).\nWhy do some actors claim responsibility for cyber operations while others opt for anonymity? To answer this question, we explore the logic of credit-claiming for two key sets of actors in cyberspace: states and politically motivated nonstate actors (hereafter, nonstate actors).\nWe argue that credit-claiming, including the manner in which culpability is communicated, depends on what the intruder wants to accomplish. For states, credit-claiming is most appealing during operations that require target compliance, otherwise known as cyber coercion. When states choose to make their identities known to coerce targets, they are more likely to do so privately since public credit-claiming raises the odds of escalation. Anonymity is most attractive during operations where\n We bracket nonstate actors without political motivations.\nPoznansky, Michael, and Evan Perkoski. (2018) Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution. Journal of Global Security Studies, doi: 10.1093/jogss/ogy022\n© The Author(s) (2018). Published by Oxford University Press on behalf of the International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nThis argument requires a conceptual shift in how we think about secrecy in cyberspace. Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations (Kibbe 2007). The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise (Axelrod 1979; Slantchev 2010). The latter involves the use of secrecy to conceal the sponsor of an operation (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson 2016). Importing this distinction to the cyber domain helps clarify when secrecy is an operational imperative and when it is a choice that actors make. In brief, the advantages afforded to targets who learn of imminent or ongoing operations means that cyber intrusions will almost always be conducted clandestinely. Once an operation is complete, however, intruders are free to choose whether to claim responsibility. Put differently, cyber operations are almost always clandestine but not necessarily covert. The failure to recognize this distinction partly contributes to the widespread assumption that anonymity is an immutable feature of cyberspace rather than something actors select into.\nRigorously testing these claims would require access to the internal deliberations of state and nonstate actors to understand how decisions about credit-claiming are made. At present, this is a nearly impossible task (Buchanan 2017, 12). We are perhaps decades away from gaining access to the types of declassified documents necessary to evaluate the deliberations of states; the problem is even more acute for nonstate actors. As a second-best option, we leverage a range of sources—secondary materials, news reports, official government statements, and interviews—to assess the plausibility of our argument. Our study is closer to an exercise in theory construction than theory testing (Mahoney 2015, 201).\nThis article makes several contributions. First, it joins together a burgeoning literature centered on the dynamics of secrecy in world politics and another focused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation (Carson 2016), and the relationship between democratic peace theory and covert regime change (Downes and Lilley 2010; Poznansky 2015). These studies are tied together by an overarching focus on how actors use secrecy to pursue their political goals. Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike (Gartzke 2013; Gartzke and Lindsay 2015; Lindsay 2015; Rid and Buchanan 2015; Buchanan 2017; Nye 2017) but have largely neglected the determinants of secrecy at the stage where sponsors can (dis)claim ownership of an operation. We address this issue directly.\nSecond, this study is among the first of which we are aware that considers the goals and constraints of the two most important actors operating in cyberspace—states and nonstate actors. Existing research tends to focus on the former (Gartzke 2013; Buchanan 2017; Borghard and Lonergan 2017; Nye 2017). But nonstate actors conduct cyberattacks at high rates and often in very visible ways. Moreover, their attack capabilities are growing and in some cases they \"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\" (Stoller 2017). Ignoring nonstate actors or assuming that their strategic logic mirrors that of states is insufficient. Our approach is thus to ask the same questions for both sets of actors, reducing barriers that inhibit a more complete understanding of cyberattacks.\n## The Problem of Secrecy\nThe conventional view of a cyber operation is an intruder quietly penetrating a target's network to collect information or cause damage, whether virtual or physical, without betraying their identity. This narrative—which assumes secrecy from start to finish—colors how the literature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant (Slayton 2017). Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks (Rid and Buchanan 2015; Nye 2017, 49–52). According to Lindsay (2013), “[f]orensics takes months, whereas the anonymous attack can present\n\nRethinking Secrecy in Cyberspace\nitself and perhaps complete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity (Lindsay 2015, 58).\nThe pervasiveness of secrecy in this domain also poses challenges for cyber coercion (Valeriano and Maness 2014; 2015, 79; Nye 2017, 55-56). Coercion requires victims to know who is making demands and what they are being asked to do (Schelling 1966). Anonymity is antithetical to this enterprise. As Gartzke (2013) once put it, \"How does one surrender to no one in particular?\" (47). Some scholars point out that perpetrators can enhance the credibility of coercive threats by making their identities known, a point we develop more fully below. But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace (Borghard and Lonergan 2017, 457-59; Libicki 2009, 50-51).\nWhile all of these studies seem to address the same basic phenomenon—secrecy—there are meaningful differences when it comes to what is being concealed during an operation and for what purpose. The next section explores these differences.\n## Disaggregating Secrecy\nThe US military and intelligence communities distinguish between two types of secret operations. The first are clandestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise (Axelrod 1979; Slantchev 2010). As an example, consider Operation Neptune Spear, the US Special Forces' raid on Osama bin Laden's compound in Abbottabad, Pakistan. While the raid itself was shrouded in secrecy, President Obama's remarks to the nation afterward suggest that the purpose of secrecy was tactical, not political.\nThe second type of secret operation is covert action, defined as \"[a]n operation that is so planned and\nFigure 1. Clandestine and covert operations\nexecuted as to conceal the identity of or permit plausible denial by the sponsor.\"6 While covert operations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\" (Gross 2009, 12). There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns (Brown 2014; Carson 2016) and avoiding hostile reactions from domestic and international observers (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson and Yarhi-Milo 2017; Joseph and Poznansky 2017). A classic covert operation is the Bay of Pigs. Training fifteen hundred exiles to storm the shores of Cuba to overthrow Fidel Castro was a highly visible act; the sponsor, the United States, was supposed to remain hidden.\nFigure 1 presents four different combinations of secret operations with illustrative examples.7 Cases in the northwest quadrant include cyber intrusions that are planned and executed clandestinely and denied by the sponsor. These are what observers typically have in mind when discussing the attribution problem in cyberspace. The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases (Betz and Stevens 2011, 95). Examples in the northeast quadrant are covert because the sponsor denied complicity but are not clandestine since the activities themselves, typically performed by third parties, are not hidden. Examples in the southeast corner include large-scale wars.\n\nThis is taken from the Department of Defense's Dictionary of Military and Associated Terms, available at http://www.dtic.mil/doctrine/dod/dictionary/. Although this definition is focused on government entities, the same logic applies broadly.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nThese are neither covert (the sponsor was known) nor clandestine (the wars were announced in advance).\n## Secrecy in Cyberspace\nStudents of cyber warfare rarely distinguish between clandestine and covert forms of secrecy. As such, most studies do not explicitly address where secrecy is a de facto requirement rather than a choice in the course of a cyberattack. Figure 2 portrays a stylized schematic of cyber intrusions, capturing two of the key inflection points where actors make decisions about secrecy.\nAt  $\\mathrm{T_0}$ , perpetrators decide whether to announce to the target that an attack is imminent or whether they will conceal the operational details as in a clandestine operation. In almost all cases, perpetrators will choose the latter. Doing otherwise is counterproductive since publicizing even the most basic details of a pending operation affords the target an opportunity to enact countermeasures. Announcing that \"[you] will attack this network with this effect unless [the target] refrain[s] from X\" would be \"self-defeating\" (Lindsay 2015, 55). Acting clandestinely raises the likelihood of success by denying victims the chance to take steps that might blunt the efficacy of the attack such as patching a vulnerability or cutting access to servers. This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim.[8] Even when the perpetrator is not relying on zero days,\nthey still will not want to announce the exact vector by which the intrusion will occur to avoid jeopardizing the operation.\nActors have the most agency when it comes to secrecy and deception after an attack occurs at time  $\\mathrm{T}_{1}$ . Here, perpetrators must decide whether to proceed in a manner consistent with covert action (denying their role) or not (claiming it). Should a perpetrator choose to forgo plausible deniability, they must then decide how to communicate complicity. The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity (Libicki 2009, 50-51; Nye 2017, 51). Perpetrators can do this by leaving clues in the course of the attack—for example, leveraging a vector they have been known to use before, reusing code from a previous intrusion, or otherwise leaving signatures in the source code of malware. Or they might communicate through discrete diplomatic channels with a foreign counterpart (Borghard and Lonergan 2017, 459).\nThe second means of communicating complicity, public acknowledgment, refers to a situation where the perpetrator openly pronounces their identity to a much wider audience following an attack. They might make a public statement or alert the media of their culpability. Explaining why some actors intentionally dispense with anonymity—and, for those that do, whether they will credit-claim publicly or privately—is the focus of the next two sections. For now, it will suffice to point out that the attribution problem ceases to exist in cases where the perpetrator willingly makes their identity known.\nActors can, and often do, opt to act both clandestinely and covertly in the course of a single operation (Betz and Stevens 2011, 88). Our rationale for distinguishing between the two is to make clear that while clandestinity is a technical requirement of almost all cyber operations the decision to act covertly is something perpetrators consciously select into. In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.[9]\nIn what follows, we use these distinctions to address our original puzzle regarding why some actors claim responsibility for operations while others choose to remain anonymous. The next section discusses the politics of credit-claiming for states. We then turn to nonstate actors, a neglected but important player in the cyberspace arena.\n\nRethinking Secrecy in Cyberspace\n# States and the Politics of Voluntary Attribution\nWhether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion.[10] If success is possible without the target consciously acceding to some demand, states will act covertly and hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission.[11] In terms of how they eventually reveal complicity, we argue that states are most likely to use private channels and discrete communication.\n# When States Come Clean\nWhen the success of state-sponsored cyber operations does not require target compliance, voluntary credit-claiming is unnecessary at best and counterproductive at worst. In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage.[12] Like any intelligence gathering effort, voluntary attribution would be disadvantageous. Should a perpetrator announce that they have penetrated an adversary's network, they will jeopardize both their intrusion method and continued access without reaping any obvious benefit in return. Preserving anonymity is thus the preferred option for states interested in stealing secrets in cyberspace.\nAnother class of cyber operations, political action and sabotage, is also best served by perpetual anonymity. Examples include operations to influence elections through disinformation campaigns, vote manipulation, and the destruction of physical equipment and critical infrastructure. Because the success or failure of these operations does not depend on the target consciously responding to specified incentives, the motivations for states to voluntarily claim credit should be correspondingly low.\nThe calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful (Schelling 1966). When operations require that the\n\ntarget accede to a set of demands—either to do something (change the status quo) or to refrain from doing something (preserve the status quo)—states are likely to shun anonymity and engage in voluntary attribution. The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim (Carson and Yarhi-Milo 2017). Remaining anonymous does little to advance these aims. As Liff (2012) notes, “[u]nder most circumstances, any would-be aggressor who does not identify itself forfeits the ability to coerce its adversary” (414). Anonymity makes it hard for targets to evaluate the credibility of a threat and the sender’s resolve. Credit-claiming is thus critical if cyber coercion is to have any chance of succeeding. Betz and Stevens (2011) hint at this: “[W]hen states use military cyber-power against other states for the purposes of compelling them to do their will, they still have to declare what it is (even after the event). There is no sneaky way around this fact” (95). It is worth reiterating, however, that this can only feasibly be done after the attack has ended. As discussed earlier, providing details beforehand could undermine the mission and render the coercive threat impotent.\nForgoing anonymity permits states to more effectively make coercive threats by demonstrating credibility and resolve in at least two ways. First, a claimed attack can function as a costly signal by showing the threatening party's willingness to expend valuable resources in the hopes of gaining compliance from the target. According to Borghard and Lonergan (2017), \"[t]he greater the cost to the initiating state of producing a given signal, ceteris paribus, the more effective the signal is as an indication of the initiating state's resolve\" (467).\nSecond, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power.[13] Prestige and power, though related, are not the same. The latter refers strictly to capabilities, which can never be fully observed in cyberspace owing to the premium placed on keeping these tools shrouded in secrecy. The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\" (Gilpin 1981, 31).[14] States who cultivate a reputation for cyber power may be able to\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nIt is worth briefly outlining how the dynamics of cyber prestige and coercion could operate in practice. When the goal is to compel a target to alter their behavior, perpetrators may take offensive action in cyberspace, claim credit for it, and threaten future punishment should the target fail to comply. When the goal is to deter some action, perpetrators may similarly be able to take offensive cyber action, claim credit for it, and threaten future punishment should the target act in ways deemed undesirable by the sender. A more plausible situation in the case of cyber deterrence might entail the victim of a recent attack retaliating against the perpetrator, voluntarily claiming credit, and threatening future harm should there be any further attacks against them. In each of these scenarios, cyber coercion is possible to the extent that the target believes the sender's promises of future pain are credible and that the threatener is resolved as a result of having claimed past attacks. It is \"the threat of . . . more damage,\" or the \"expectation of more violence,\" that may induce a target to give in (Schelling 1966, 3; emphasis in original).\nThere is obviously no guarantee that claiming credit for past attacks will generate the credibility necessary for coercion. If the target does not believe that the challenger has the ability or willingness to repeat similar or more painful attacks, issuing deterrent or compellent threats after claiming an intrusion with the promise of \"more where that came from\" won't work. Nevertheless, we are skeptical that observers never update their beliefs about an actor's capabilities and resolve, and opt instead to treat every attack as an isolated event. While Russia is unlikely to easily hack the Democratic National Committee again, for example, few observers doubt their capacity to carry out similar attacks in the future. Whether credible coercive threats will actually suffice to achieve concessions, while important in its own right, is a separate matter and depends on a complex cost-benefit calculation.\n## Escalation and the Means of Communication\nThis section focuses on the right-hand side of Figure 2, after an actor chooses to forgo plausible deniability $(\\mathrm{T}_1)$ and decides whether to claim responsibility publicly or privately. We argue that the unique dynamics of politically motivated, state-on-state cyber activity make public acknowledgment less attractive than private acknowledgment. There are several reasons for this.\nAs a general matter, opportunities for retaliation are higher when the actors involved are states. Unlike non-state actors, states are stationary, immobile entities with numerous targets available to hit. Concern about attacks against a state's critical infrastructure have been likened to a potential \"cyber 9/11\" (Maxey 2017). Moreover, perpetrators that publicly announce sponsorship of a cyberattack put the victim—in many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige (Carson and Yarhi-Milo 2017, 135).\nBecause the victims of publicly claimed, state-sponsored cyberattacks typically have both the opportunity to retaliate as well as strong domestic-level pressures to do so, nation-states interested in cyber coercion face powerful incentives to quietly claim their actions using private channels. While credit-claiming in private lacks the broader prestige benefits associated with publicity and limits the audience observing an operation's (physical) costly signals, it may nonetheless afford states an opportunity to engage in coercive diplomacy at reduced risk. Recent scholarship shows that states often face powerful incentives to collude with one another in acts of secrecy. For example, Carson (2016) argues that states may opt not to publicize the covert military actions of their rivals even when they are targeted as a way of keeping conflicts limited and contained. A similar logic should apply to discrete attempts at coercion in cyberspace.\nOne risk of private acknowledgment is that the victim will \"out\" the perpetrator by publicly announcing the occurrence of an intrusion and offering proof that the attacker sought to privately attribute themselves. While this is always a possibility, such concerns may not wholly disincentivize states from pursuing private acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them (Rid 2012, 28–29). This, in turn, can motivate perpetrators to quietly come clean with little fear of being exposed by the victim. Second, when victims have the capacity to out a state\n For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).\nRethinking Secrecy in Cyberspace\npursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases. This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity (Yarhi-Milo 2013, 407).\n# Nonstate Actors and the Politics of Voluntary Attribution\nThe discussion so far has focused on the conditions under which states will claim credit for cyberattacks and why they are more likely to do so privately. This is important for obvious reasons. However, nonstate actors dominate the empirical record of credit-claiming in cyberspace. In what follows, we explain why nonstate actors commonly claim attacks and why they tend to do so publicly.\nDrawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means (Nye 2010; Asal et al. 2016). Regardless of their method of contention, nonstate actors are agents of change operating in a structural environment in which they are severely disadvantaged. These groups wield significantly fewer resources than states—financial, material, and otherwise—and their capabilities are consequently more constrained and more uncertain. In addition, what few capabilities nonstate actors do possess are in large part a function of the number of participants they can organize. This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well (Asal and Rethemeyer 2008; Chenoweth and Stephan 2011). The same basic logic extends to nonstate actors operating in cyberspace. One of the most common tools in a group's cyber arsenal, the distributed denial of service (DDoS) attack, grows stronger with every additional user.\nOur primary claim is that nonstate actors are more likely than states to brazenly claim cyberattacks. Not\n See also Carson and Yarhi-Milo (2017, 135).\n On the importance of states for Internet politics, see Rovner and Moore (2017).\n To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.\nonly does this help showcase their capabilities, but the media attention can help attract new members to the cause. Additionally, since it is often difficult to bring these groups to justice, organizations like Anonymous, Lulzsec, and others face reduced incentives to keep quiet about their operations. In sum, complicity is a critical component of nonstate actors' strategic logic and they commonly announce sponsorship of cyberattacks as a result.\n# The Appeal of Credit-Claiming\nNonstate actors typically have coercive objectives. As Schelling wrote in 1973, \"[p]olitical violence, like political nonviolence, usually has as its purpose making somebody do something or not do something or stop doing something. The aim is to influence behavior.\" In a broad sense, their goals are comparable to those of states seeking to alter the behavior of their adversaries.\nAbove, we argue that a key component of coercion is credibility: can actors issuing coercive threats make good on their promises of more pain if the target resists? This is especially difficult for nonstate actors (Hoffman and McCormick 2004; Kydd and Walter 2006; Dannenbaum 2011). They cannot put on military parades to show off their latest weaponry, do not have the means to finance modern military forces, and lack the resources—territorial, bureaucratic, and financial—of states. It is easy to dismiss the demands of nonstate actors as inconsequential chatter.\nGiven these deficits, the issue of how to boost credibility features centrally in the strategic logic of politically motivated nonstate actors. As with states, one way to demonstrate capabilities and resolve is to take action perceived as a costly signal. According to Kydd and Walter (2006), \"[b]ecause it is hard for weak actors to make credible threats, terrorists are forced to display publicly just how far they are willing to go to obtain their desired results\" (50). Similarly, Abrahms (2013) writes that \"[t]errorism . . . adds credibility to threats by showing that nonstate challengers possess the power to hurt\" (661).\nFor nonstate cyber warriors, sending costly signals to bolster credibility may include defacing government websites, launching distributed denial of service attacks,\n To the extent that they run the risk of capture, however, the credibility of their signals goes up.\n Quoted in Sharp and Finkelstein (1973, xx).\n Doing so might expose their position and invite unwanted risk.\n One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nA history of successful attacks by a nonstate group can also help cultivate their prestige in much the same way it does for states. As such, nonstate actors stand to lose by not identifying their organization as responsible for an attack. Failing to communicate culpability negates an operation’s objectives and precludes nonstate actors from reaping signaling and reputational benefits that are critical to successful coercion. Without knowing who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities. It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own (Bloom 2005, 78–79).\n## Maximizing Publicity\nThe notion that nonstate actors are more likely to claim attacks to showcase their capabilities and resolve mirrors a similar motivation among states interested in cyber coercion. Where the two diverge is in the preferred method of claiming. Several factors make nonstate actors more likely to choose public rather than private acknowledgment.\nOne reason nonstate cyber warriors crave the limelight hinges on the audiences they seek to influence. These\n It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.\n Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).\ngroups are often interested in sending a message not just to adversarial governments but to their populations as well. The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance (Schmid 2004). As Crenshaw (1981) notes in a related context, “[t]he victims or objects of terrorist attack have little intrinsic value to the terrorist group but represent a larger human audience whose reaction the terrorists seek” (379).\nUltimately, terrorists target the public since they are too weak to confront the state head-on. The same should be true of nonstate actors in cyberspace since these groups face comparable disadvantages. For such a strategy to work, however, communication cannot be private; it must be visible, clearly attributed, and widely known to the government and public alike.\nA second reason nonstate actors in cyberspace prefer public methods of claiming credit turns on their desire to attract new recruits. Like their traditional counterparts, these actors are interested in survival and growth. According to Pape (2005), “terrorism has two purposes—to gain supporters and to coerce opponents. Most terrorist campaigns seek both goals to some extent, often aiming to change the target state’s policies while simultaneously mobilizing support and recruits for the terrorists’ cause” (7). Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization (Abrahms 2008, 379) and augment their coercive ability. It is well established that the power of civil resistance flows from mobilization numbers, and the same goes for organizations in cyberspace. When it comes to their operating methods, these groups favor tactics that grow more powerful with additional bots and active supporters. The strength of DDoS operations, for instance, is linked to the number of machines involved (Ghosemajumder 2016). The Low Orbit Internet Cannon (LOIC) and related variants draw strength from those who download the application and flood a server. With more members at their disposal, groups are able to launch increasingly formidable cyber operations.\n On the determinants of DDoS attacks, see Asal et al. (2016).\n It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.\nRethinking Secrecy in Cyberspace\n# Plausibility Probes\nA lack of readily-accessible decision-making documents complicates rigorous empirical tests of our argument. If we are right that state-sponsored cyber operations involving espionage and sabotage are prime candidates for secrecy before, during, and after execution, it might be decades or longer before relevant materials are declassified.27 While coercive cyber operations are more likely to involve credit-claiming, the advantages of claiming attacks privately also impede observation. In fact, outsiders might be unable to discern differences between victims who are truly ignorant of their attacker's identity and those that feign ignorance while privately communicating with their attackers.\nAs a second-best strategy, we examine publicly available sources including news reports and a range of secondary materials to provide a preliminary test of our argument. We also conduct two interviews: one with a former Defense Department official involved in cyber policy and one with a former member of Anonymous. These helped corroborate what we found in the public record.\n# States\nWe were unable to find a single case of a state claiming credit for a cyber espionage operation, either openly or privately. Rather, the cases that have inadvertently come to light underscore the vigor with which states seek to avoid being named. China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative (Nakashima 2015). In the aftermath of the intrusion, Chinese officials denied complicity, placing blame on criminal hackers. They even went so far as to claim that they had arrested individuals who were connected with the hack (Chalfant 2017).28 Another example is Russia's alleged interference in the 2016 US election. The \"theft of research and emails from the Democratic National Committee\" for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government (Sanger 2016).29\n\nWhen asked in March 2017 about whether Russia was behind the efforts to discredit Hillary Clinton, Putin responded with \"Read my lips: No\" (Lister, Ilyushka, and Gigova 2017). When it comes to cyber espionage, there is no benefit to be had from credit-claiming.\nStuxnet provides a useful illustration of why decision-makers sometimes cling to anonymity and, more interestingly, the conditions under which they might be willing to voluntarily claim credit.30 Stuxnet, formally known as \"Olympic Games,\" was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant (Farwell and Rohozinski 2011). The aim was to make the Iranians believe their centrifuges were failing for reasons other than foreign interference. Sanger (2012) writes the following: \"When the centrifuges first began crashing in 2008 at the Natanz enrichment center, the crown jewel of the Iranian nuclear program, the engineers inside the plant had no clue they were under attack. That was exactly what the designers of the world's most sophisticated cyberweapon had planned.\" He continues that \"[t]he idea, hatched in Washington and Jerusalem, was to make the first breakdowns seem like random accidents and small ones at that\" (188).\nSanger's interviews with government officials confirm that the operation was supposed to leave no trace of US fingerprints: \"The most elegant cyber weapons are a lot like the most elegant bank frauds. . . . They work best when the victim doesn't even know he's been robbed\" (190-91). It is clear from this account that the United States kept both the operation and their sponsorship intentionally hidden, as our argument predicts. The success or failure of the operation did not depend on Iran changing their behavior, but simply hinged on the quiet destruction of centrifuges.\nInterestingly, though, some US operatives contemplated quietly alerting the Iranians that the United States was responsible for the attack. Their apparent rationale conforms to our theoretical expectation. Ostensibly, the goal would have been to send a message to Tehran that the United States had the ability to keep targeting their systems, presumably as a way of achieving concessions on the nuclear program. According to Sanger (2012), \"[a]t both the Pentagon and inside the intelligence agencies some of the creators of the bug believed that it might be\ninformation to relevant entities who could use it to discredit Hillary Clinton. Even if so, this type of action would qualify as a classic covert operation, and thus we would still expect Russian denials.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nMore recent examples suggest that states are thinking hard about voluntarily claiming credit for their cyber operations in the service of coercion. In late September 2017, it came to light that the Trump administration authorized US Cyber Command to carry out a range of limited cyberattacks against North Korea's Reconnaissance General Bureau intended to interfere with Internet access (DeYoung, Nakashima, and Rauhala 2017). Most importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy.[32] Panda (2017) argues that the United States had \"take[n] the cyber equivalent of a shot across North Korea's bow, presumably signaling that it has the requisite access to North Korean networks to deliver considerably more significant damage in wartime.\" Since North Korea is not wanting for enemies, it seemed to serve US objectives to let their complicity be known, thereby reducing ambiguity about what behavioral changes were expected from the Kim regime.\nFurther evidence for our theory comes from recent statements by Shawn Turskey, the executive director of US Cyber Command. His comments from 2016 indicate that the United States government is contemplating ways to leverage cyber capabilities for coercive purposes,\n\nspecifically through intentional credit-claiming. Turskey declared the following:\nIn the intelligence community you never want to be caught, you want [to] be low and slow, you never really want to be attributed. . . . But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know. (Bing 2016, emphasis added)\nThese remarks are noteworthy for several reasons.[33] Chief among them is the prospect of the world's lone superpower developing an arsenal of cyber weapons with a return address. The fact that loud, attributable weapons are being discussed at all is at odds with the typical portrayal of cyberspace as a domain defined by secrecy and anonymity. Yet, it is easier to understand why Turskey is contemplating this shift once we come to terms with the mechanics of cyber coercion. Leveraging cyber assets for coercive purposes, rather than espionage or sabotage—which fits more readily within the purview of the military as opposed to the intelligence community—requires credible self-attribution. Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal (Lin 2016).\nMichael Sulmeyer, the former director for Plans and Operations for Cyber Policy in the Office of the Secretary of Defense, affirmed this sentiment in an interview for this article. Echoing the idea that cyber weapons can and should be embraced for more traditional purposes, he highlights the following:\nIt is important for the United States to invest in capabilities that not only help it improve its espionage activities against adversaries, but also that help it prevail in the event of hostilities with adversaries. When operating in the realm of the second objective, it can be beneficial for the United States to take responsibility for its actions publicly—not to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.[34]\nTaking responsibility, as Sulmeyer suggests, provides America's adversaries the chance to understand the extent of their cyber power. Similar to Turskey, Sulmeyer anticipates that more voluntary credit-claiming may be on the horizon:\n\nRethinking Secrecy in Cyberspace\nTo be sure, this signal could be missed or dismissed—and a mere tap on the digital shoulder clearly would not suffice for such a signal to be internalized. But why go through all the effort to hide every action every time in this context? That's an unnecessary additional burden in a war fight. If there are a suite of capabilities that can help our forces be more agile during hostilities, I would hope they are on the table for our commanders and leaders in the future.\n## Nonstate Actors\nThe empirical pattern of cyberattacks by nonstate actors differs from what we observed for states. These actors frequently claim credit for their cyberattacks in very public ways. Much like terrorist attacks, these operations almost always entail a political message intended to alter public opinion, change government policies, and the like. A cyberattack carried out by the Syrian Electronic Army against the US Army's website showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion (Vinton 2015). Quietly alerting the US Army that the Syrian Electronic Army was behind the attacks would have undermined the strategic motivations underlying the entire operation, namely bolstering their reputation as a group that deserves respect and sending a clear message with the intention of affecting public opinion and altering policy. The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list (Temperton 2016).\nFor a more complete picture of the decision-making process for nonstate actors in cyberspace, we briefly examine one of the most well-known organizations: Anonymous. Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article (Olson 2012; Coleman 2014). Anonymous’ behavior following this shift, though, sheds light on the group’s political strategy and how publicity and attention serve their goals.\nA cursory overview of Anonymous’ exploits over the years shows that the group commonly claims credit publicly for its operations. In late March 2016, Anonymous targeted roughly twenty Angolan government websites in response to the arrest of several activists. Prior to carrying out the attack, they posted details about the websites\nthey intended to target (British Broadcasting Company 2016). In one of their biggest and best-known campaigns, Operation Tunisia, the group first put out a press release via YouTube before a launching series of DDoS attacks that took down numerous government-linked websites. This was part of a broader operation intended to assist protesters and weaken the government of Ben Ali. Most relevant for our purposes, the group issued a clear coercive threat: “This is a warning to the Tunisian government: attacks at the freedom of speech and information of its citizens will not be tolerated. . . . Free the net, and the attacks will cease, keep on that attitude and this will just be the beginning” In another high-profile incident, Anonymous targeted the Church of Scientology. As before, the attack began with a YouTube press release and proceeded with a series of DDoS attacks, doxing, and more press releases and media statements. In line with our expectations, the IT company hired by the Church of Scientology implored them to simply ignore the attacks: “Don’t issue warnings or threats to the attackers via the media; this will only keep the issue alive, raise tempers, and greatly increase the possibility of another assault. Most DDoS attackers seek publicity, so don’t hand it to them on a silver platter.” Their solution was to deprive Anonymous of what it wanted most, namely attention.\nThis strategy of pursuing highly visible, self-attributed missions served at least three functions. First, Anonymous used these operations to ensure that they were taken seriously and that their coercive threats were not ignored. Establishing their capabilities, resolve, and credibility by conducting attacks with clear attribution contributed to this effort. This was explicit in their internal conversations during the operation against the Church of Scientology. As one member put it, “I think it’s time for [us] to do something big. People need to understand not to f*** with [Anonymous].” These and other attacks proved somewhat successful. Outside observers came to understand that they should not dismiss the group’s threats. Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility” (Olson 2012, 177).\nSecond, Anonymous recognized that part of their strategy revolved around the public. During Operation Payback in 2010, which aimed to promote Internet privacy by targeting antipiracy groups, members of\n See https://www.youtube.com/watch?v=BFLaBRk9wY0.\n Quoted in Coleman (2014, 149).\n See https://www.youtube.com/watch?v=JCbKv9yiLiQ.\n Quoted in Olson (2012, 89).\n Quoted in Olson (2012, 2).\nInterview with authors, October 26, 2017.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\nAnonymous ardently debated this component of their strategy. Support eventually developed for one member who claimed that “... these attacks are less about hurting the business than drawing attention and forcing the media to cover the story. . . . The point for me is that this is the technological way of mass protesting that’s actually effective.”41 Getting their message out to the public to garner attention became a core objective.\nAnonymous’ operations often did more than just influence the public indirectly via messaging; sometimes the public was the direct target of attacks. Anonymous, like most terrorist groups, eventually had to reconcile with the fact that targeting innocent civilians might be useful for achieving their aims. This issue came to a head during Operation BART (Bay Area Rapid Transit), when members leaked information on individual passengers, including credit card numbers and other details from the company’s website. When asked about the incident by a reporter, a senior member replied, “[h]ow else do you get the world to respond and secure your information? How else do you get these companies and these big governments to keep your information, the information you give them voluntarily, safe? I think we got our message across, and I’ll bet you one thing: I’ll bet you they fix that.”42 Anonymous’ symbolic, essentially random targeting was part of a broader campaign to influence public opinion and achieve political change. Their cyberattacks were acts of coercion that bore a striking resemblance to the strategic logic of militant organizations.\nFinally, Anonymous’ cyber behavior was often geared toward generating new members and deepening support among their base. In an interview conducted for this article, we asked Hector Monsegur, a former leader of Anonymous known as Sabu, why the group was so eager to publicly claim their operations. As he put it,\nAt the time of its height (not so much now) Anonymous had gained huge successes in publicizing its protests, hacks, and engagements. They were masterful in the distribution of content, and the media truly ate it up for several reasons:\nIt was neatly packaged and ready for distribution, the hackers were willing to give interviews, and of course the mystery element. The whole thing about the mask and shadowy figures really “sells” the concept. As Anonymous grew in action, it also grew in numbers and support . . .\nThe truth of the matter is that Anonymous needed the media to grow, and this explains why many of the\nthings we did were really attention-grabbing. It served a purpose. It’s very similar to branding and how companies slip in their products into film, or events in general, even if each engagement or hack had different motivations.43\nIn her research on Anonymous, Coleman (2014) expands on this point: “[W]ithout the appearance of a critical mass, the operation would have likely lacked moral gravitas and authority. In this case, strength in numbers conveyed a potent message” (138). Expanding their membership didn’t just provide Anonymous legitimacy; it provided additional capability as well. While many of Anonymous’ DDoS campaigns relied on botnets to create their desired effect, individual users sustained those attacks that used the freeware LOIC, a staple of the group’s earlier activity. This required the group to invest time in assisting new members with the software. Olson (2012) points out that the group felt it was worth it to take the time “getting the [new members] on board to create an army” (65).\nUltimately, it was in Anonymous’ interest to take credit for their cyber operations through highly visible, public means of communication. Doing so rewarded their efforts significantly and was instrumental to their strategic logic. Whether the target was the Tunisian government or the Church of Scientology, the attention they received bolstered their particular brand of coercion. This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance (Coleman 2014, 107).\n## Cybercrime and Cyber Blackmail\nBefore concluding, it is worth flagging two types of cyber operations perpetrated by state and nonstate actors alike that are unlikely candidates for voluntary attribution. The first are operations involving theft of financial or intellectual assets. These are among the most common kind of cyberattack and are ill-served by credit-claiming. Malicious actors that leverage cyber assets for criminal purposes, such as stealing money from banking institutions, have little incentive to self-attribute. Doing so would provide little benefit and expose them to potential prosecution. While nonstate actors most commonly conduct these kinds of attacks, states may as well. For example, North Korea was identified as the responsible party in a cyber heist against Bangladesh’s central bank. Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million (Finkle 2017).\n\nRethinking Secrecy in Cyberspace\nA second unlikely candidate for voluntary attribution is what we might call “cyber blackmail,” or operations in which the perpetrator leverages stolen assets, embarrassing secrets, and the like to achieve compliance from the victim without having to reveal their true identity. These operations are particularly interesting in that success requires target compliance—which we argue should lead to credit-claiming—but the perpetrator can remain behind a mask. By selectively releasing compromised information and assets to the victim publicly or privately (Lindsay 2015, 57), the perpetrator may be able to force compliance while remaining anonymous or hiding behind front groups.\nThis dynamic approximates what might have happened during the Sony hack, in which the “Guardians of Peace” (#GOP) issued an explicit compellent threat against Sony in an attempt to prevent the company from releasing The Interview, a comedy satirizing North Korea’s leader Kim Jong Un. In the event that Sony failed to comply with #GOP’s demands, the group threatened to release propriety information and potentially embarrassing e-mail correspondences between high-level employees. Although North Korea was widely suspected of sponsoring the attack, the regime denied any involvement. Nonetheless, the attack partially succeeded in coercing Sony without the government having to explicitly take credit. We believe that the attack was partially successful as a result of Sony’s understanding that certain assets (personal e-mails, financial records) had indeed been compromised and would be released should they fail to comply.\n## Conclusion\nThis article draws on existing theory to develop an explanation for why states and politically motivated non-state actors might voluntarily claim credit for their attacks. We argue that the goals of an operation as well as the characteristics of the perpetrator drive both the decision to claim credit as well as the manner in which culpability is communicated. This research has several important implications. First, we show how states and nonstate actors share a common set of choices with regards to secrecy in cyberspace. Both face the same decisions at the same points in the life cycle of a cyberattack, yet the characteristics of each can cause their strategies to diverge, particularly when it comes to the optics of credit-claiming. Future research should continue to investigate how the characteristics and operational and strategic goals of cyber actors influence the look and feel of their cyber actions.\nSecond, existing research often treats cyber operations as distinct from more traditional elements of state power. Although there are differences, the framework developed here suggests that states may be able to leverage cyber assets to achieve many of the same goals most frequently pursued with conventional forces. Scholars have pushed back against this idea for a variety of reasons, one being the attributional difficulties of cyber operations. But states need not conceal their complicity in perpetuity. By relaxing this assumption, we can more easily see how these operations fit into a state’s coercive toolkit. One area ripe for future research is the efficacy of coercion in cyberspace, both on its own and in comparison to more conventional methods.\nFinally, while inferring intentions from behavior is problematic, actors’ decisions to privately or publicly acknowledge sponsorship of an attack may provide crucial information about motives and identity. Clinging to covert forms of secrecy after the completion of an attack might highlight a set of plausible underlying motivations for the initial intrusion, including espionage, cybercrime, and the like. Conversely, if the actor does come clean, it might be appropriate to infer that credibility, prestige, or coercion was the true goal. In the information-starved domain that is cyberspace, these clues may be all there is when designing policies and crafting responses.\n## Acknowledgements\nThis is one of several collaborative projects by the authors, and the ordering of names follows a principle of rotation. We are grateful to Joseph Brown, Ben Buchanan, Ryan Evans, Robert Jervis, Joseph LaPalombara, Herb Lin, Jon Lindsay, Joseph Nye, Joshua Rovner, and Michael Sulmeyer for helpful comments, suggestions, and insights. An earlier version of the argument presented here appeared in War on the Rocks.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 42,
        "success_occurrences": 42,
        "success_unique": 20,
        "bib_unique_total": 46,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.43478260869565216,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": " Attribution\nMichael Poznansky",
          "footnote": "We bracket nonstate actors without political motivations.",
          "position": 197
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "l Poznansky¹ and Evan Perkoski",
          "footnote": "For important exceptions, see Betz and Stevens (2011), Borghard and Lonergan (2017), and Libicki (2009).",
          "position": 216
        },
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "Poznansky¹ and Evan Perkoski²\n",
          "footnote": "We bracket nonstate actors without political motivations.",
          "position": 218
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "¹University of Pittsburgh and ",
          "footnote": "For important exceptions, see Betz and Stevens (2011), Borghard and Lonergan (2017), and Libicki (2009).",
          "position": 248
        },
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "",
          "footnote": "We bracket nonstate actors without political motivations.",
          "position": 2810
        },
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "ctive during operations where\n",
          "footnote": "We bracket nonstate actors without political motivations.",
          "position": 3305
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "For important exceptions, see Betz and Stevens (2011), Borghard and Lonergan (2017), and Libicki (2009).",
          "position": 7354
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "",
          "footnote": "See Buchanan (2017) for a summary.",
          "position": 8436
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).",
          "position": 26544
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "e the capacity to out a state\n",
          "footnote": "For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).",
          "position": 28650
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "See also Carson and Yarhi-Milo (2017, 135).",
          "position": 29173
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "On the importance of states for Internet politics, see Rovner and Moore (2017).",
          "position": 29571
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.",
          "position": 30967
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "Not",
          "footnote": "See also Carson and Yarhi-Milo (2017, 135).",
          "position": 31076
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "On the importance of states for Internet politics, see Rovner and Moore (2017).",
          "position": 31123
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.",
          "position": 31206
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "",
          "footnote": "To the extent that they run the risk of capture, however, the credibility of their signals goes up.",
          "position": 31889
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "\"",
          "footnote": "Quoted in Sharp and Finkelstein (1973, xx).",
          "position": 32337
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "how off their latest weaponry,",
          "footnote": "Doing so might expose their position and invite unwanted risk.",
          "position": 32809
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "inance modern military forces,",
          "footnote": "One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.",
          "position": 32868
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "ed denial of service attacks,\n",
          "footnote": "To the extent that they run the risk of capture, however, the credibility of their signals goes up.",
          "position": 33823
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "",
          "footnote": "Quoted in Sharp and Finkelstein (1973, xx).",
          "position": 33926
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "Doing so might expose their position and invite unwanted risk.",
          "position": 33973
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "",
          "footnote": "One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.",
          "position": 34039
        },
        {
          "index": 23,
          "intext_citation": "²³",
          "preceding_text": "",
          "footnote": "It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.",
          "position": 35321
        },
        {
          "index": 24,
          "intext_citation": "²⁴",
          "preceding_text": "",
          "footnote": "Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).",
          "position": 35476
        },
        {
          "index": 23,
          "intext_citation": "²³",
          "preceding_text": "These",
          "footnote": "It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.",
          "position": 35956
        },
        {
          "index": 24,
          "intext_citation": "²⁴",
          "preceding_text": "",
          "footnote": "Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).",
          "position": 36154
        },
        {
          "index": 25,
          "intext_citation": "²⁵",
          "preceding_text": "",
          "footnote": "On the determinants of DDoS attacks, see Asal et al. (2016).",
          "position": 38752
        },
        {
          "index": 26,
          "intext_citation": "²⁶",
          "preceding_text": "",
          "footnote": "It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.",
          "position": 38991
        },
        {
          "index": 25,
          "intext_citation": "²⁵",
          "preceding_text": "²⁶",
          "footnote": "On the determinants of DDoS attacks, see Asal et al. (2016).",
          "position": 38994
        },
        {
          "index": 26,
          "intext_citation": "²⁶",
          "preceding_text": "",
          "footnote": "It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.",
          "position": 39058
        },
        {
          "index": 35,
          "intext_citation": "³⁵",
          "preceding_text": "",
          "footnote": "See https://www.youtube.com/watch?v=BFLaBRk9wY0.",
          "position": 50413
        },
        {
          "index": 36,
          "intext_citation": "³⁶",
          "preceding_text": "ut a press release via YouTube",
          "footnote": "Quoted in Coleman (2014, 149).",
          "position": 52654
        },
        {
          "index": 37,
          "intext_citation": "³⁷",
          "preceding_text": "is will just be the beginning”",
          "footnote": "See https://www.youtube.com/watch?v=JCbKv9yiLiQ.",
          "position": 53171
        },
        {
          "index": 38,
          "intext_citation": "³⁸",
          "preceding_text": "n with a YouTube press release",
          "footnote": "Quoted in Olson (2012, 89).",
          "position": 53310
        },
        {
          "index": 39,
          "intext_citation": "³⁹",
          "preceding_text": "”",
          "footnote": "Quoted in Olson (2012, 2).",
          "position": 53793
        },
        {
          "index": 35,
          "intext_citation": "³⁵",
          "preceding_text": "antipiracy groups, members of\n",
          "footnote": "See https://www.youtube.com/watch?v=BFLaBRk9wY0.",
          "position": 54981
        },
        {
          "index": 36,
          "intext_citation": "³⁶",
          "preceding_text": "",
          "footnote": "Quoted in Coleman (2014, 149).",
          "position": 55033
        },
        {
          "index": 37,
          "intext_citation": "³⁷",
          "preceding_text": "",
          "footnote": "See https://www.youtube.com/watch?v=JCbKv9yiLiQ.",
          "position": 55067
        },
        {
          "index": 38,
          "intext_citation": "³⁸",
          "preceding_text": "",
          "footnote": "Quoted in Olson (2012, 89).",
          "position": 55119
        },
        {
          "index": 39,
          "intext_citation": "³⁹",
          "preceding_text": "",
          "footnote": "Quoted in Olson (2012, 2).",
          "position": 55150
        }
      ],
      "flat_text": "Journal of Global Security Studies, 3(4), 2018, 402-416\ndoi: 10.1093/jogss/ogy022\nResearch Article\nOXFORD\n# Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\nMichael Poznansky and Evan Perkoski\nUniversity of Pittsburgh and University of Connecticut\n## Abstract\nCyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain.\nKeywords: cyber warfare, secrecy, coercion, nonstate actors\n## Introduction\nSecrecy is a defining feature of cyberspace. Cyber intruders can frequently disrupt networks, steal financial assets, and conduct espionage without ever revealing their identities. Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence (Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017) to its influence on the dynamics of conflict and escalation (Gartzke 2013; Buchanan 2017). Yet, while cyber intruders have ample opportunities to keep their sponsorship a secret, not all choose to take advantage. To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions (Smith 2016). They are not alone; SOBH Cyber Jihad, based in Iran, claimed credit for hacking into the control system of a dam in New York (Gosk, Winter, and\nConnor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015 (Vinton 2015).\nWhy do some actors claim responsibility for cyber operations while others opt for anonymity? To answer this question, we explore the logic of credit-claiming for two key sets of actors in cyberspace: states and politically motivated nonstate actors (hereafter, nonstate actors).\nWe argue that credit-claiming, including the manner in which culpability is communicated, depends on what the intruder wants to accomplish. For states, credit-claiming is most appealing during operations that require target compliance, otherwise known as cyber coercion. When states choose to make their identities known to coerce targets, they are more likely to do so privately since public credit-claiming raises the odds of escalation. Anonymity is most attractive during operations where\n We bracket nonstate actors without political motivations.\nPoznansky, Michael, and Evan Perkoski. (2018) Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution. Journal of Global Security Studies, doi: 10.1093/jogss/ogy022\n© The Author(s) (2018). Published by Oxford University Press on behalf of the International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nThis argument requires a conceptual shift in how we think about secrecy in cyberspace. Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations (Kibbe 2007). The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise (Axelrod 1979; Slantchev 2010). The latter involves the use of secrecy to conceal the sponsor of an operation (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson 2016). Importing this distinction to the cyber domain helps clarify when secrecy is an operational imperative and when it is a choice that actors make. In brief, the advantages afforded to targets who learn of imminent or ongoing operations means that cyber intrusions will almost always be conducted clandestinely. Once an operation is complete, however, intruders are free to choose whether to claim responsibility. Put differently, cyber operations are almost always clandestine but not necessarily covert. The failure to recognize this distinction partly contributes to the widespread assumption that anonymity is an immutable feature of cyberspace rather than something actors select into.\nRigorously testing these claims would require access to the internal deliberations of state and nonstate actors to understand how decisions about credit-claiming are made. At present, this is a nearly impossible task (Buchanan 2017, 12). We are perhaps decades away from gaining access to the types of declassified documents necessary to evaluate the deliberations of states; the problem is even more acute for nonstate actors. As a second-best option, we leverage a range of sources—secondary materials, news reports, official government statements, and interviews—to assess the plausibility of our argument. Our study is closer to an exercise in theory construction than theory testing (Mahoney 2015, 201).\nThis article makes several contributions. First, it joins together a burgeoning literature centered on the dynamics of secrecy in world politics and another focused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation (Carson 2016), and the relationship between democratic peace theory and covert regime change (Downes and Lilley 2010; Poznansky 2015). These studies are tied together by an overarching focus on how actors use secrecy to pursue their political goals. Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike (Gartzke 2013; Gartzke and Lindsay 2015; Lindsay 2015; Rid and Buchanan 2015; Buchanan 2017; Nye 2017) but have largely neglected the determinants of secrecy at the stage where sponsors can (dis)claim ownership of an operation. We address this issue directly.\nSecond, this study is among the first of which we are aware that considers the goals and constraints of the two most important actors operating in cyberspace—states and nonstate actors. Existing research tends to focus on the former (Gartzke 2013; Buchanan 2017; Borghard and Lonergan 2017; Nye 2017). But nonstate actors conduct cyberattacks at high rates and often in very visible ways. Moreover, their attack capabilities are growing and in some cases they \"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\" (Stoller 2017). Ignoring nonstate actors or assuming that their strategic logic mirrors that of states is insufficient. Our approach is thus to ask the same questions for both sets of actors, reducing barriers that inhibit a more complete understanding of cyberattacks.\n## The Problem of Secrecy\nThe conventional view of a cyber operation is an intruder quietly penetrating a target's network to collect information or cause damage, whether virtual or physical, without betraying their identity. This narrative—which assumes secrecy from start to finish—colors how the literature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant (Slayton 2017). Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks (Rid and Buchanan 2015; Nye 2017, 49–52). According to Lindsay (2013), “[f]orensics takes months, whereas the anonymous attack can present\n\nRethinking Secrecy in Cyberspace\nitself and perhaps complete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity (Lindsay 2015, 58).\nThe pervasiveness of secrecy in this domain also poses challenges for cyber coercion (Valeriano and Maness 2014; 2015, 79; Nye 2017, 55-56). Coercion requires victims to know who is making demands and what they are being asked to do (Schelling 1966). Anonymity is antithetical to this enterprise. As Gartzke (2013) once put it, \"How does one surrender to no one in particular?\" (47). Some scholars point out that perpetrators can enhance the credibility of coercive threats by making their identities known, a point we develop more fully below. But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace (Borghard and Lonergan 2017, 457-59; Libicki 2009, 50-51).\nWhile all of these studies seem to address the same basic phenomenon—secrecy—there are meaningful differences when it comes to what is being concealed during an operation and for what purpose. The next section explores these differences.\n## Disaggregating Secrecy\nThe US military and intelligence communities distinguish between two types of secret operations. The first are clandestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise (Axelrod 1979; Slantchev 2010). As an example, consider Operation Neptune Spear, the US Special Forces' raid on Osama bin Laden's compound in Abbottabad, Pakistan. While the raid itself was shrouded in secrecy, President Obama's remarks to the nation afterward suggest that the purpose of secrecy was tactical, not political.\nThe second type of secret operation is covert action, defined as \"[a]n operation that is so planned and\nFigure 1. Clandestine and covert operations\nexecuted as to conceal the identity of or permit plausible denial by the sponsor.\"6 While covert operations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\" (Gross 2009, 12). There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns (Brown 2014; Carson 2016) and avoiding hostile reactions from domestic and international observers (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson and Yarhi-Milo 2017; Joseph and Poznansky 2017). A classic covert operation is the Bay of Pigs. Training fifteen hundred exiles to storm the shores of Cuba to overthrow Fidel Castro was a highly visible act; the sponsor, the United States, was supposed to remain hidden.\nFigure 1 presents four different combinations of secret operations with illustrative examples.7 Cases in the northwest quadrant include cyber intrusions that are planned and executed clandestinely and denied by the sponsor. These are what observers typically have in mind when discussing the attribution problem in cyberspace. The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases (Betz and Stevens 2011, 95). Examples in the northeast quadrant are covert because the sponsor denied complicity but are not clandestine since the activities themselves, typically performed by third parties, are not hidden. Examples in the southeast corner include large-scale wars.\n\nThis is taken from the Department of Defense's Dictionary of Military and Associated Terms, available at http://www.dtic.mil/doctrine/dod/dictionary/. Although this definition is focused on government entities, the same logic applies broadly.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nThese are neither covert (the sponsor was known) nor clandestine (the wars were announced in advance).\n## Secrecy in Cyberspace\nStudents of cyber warfare rarely distinguish between clandestine and covert forms of secrecy. As such, most studies do not explicitly address where secrecy is a de facto requirement rather than a choice in the course of a cyberattack. Figure 2 portrays a stylized schematic of cyber intrusions, capturing two of the key inflection points where actors make decisions about secrecy.\nAt  $\\mathrm{T_0}$ , perpetrators decide whether to announce to the target that an attack is imminent or whether they will conceal the operational details as in a clandestine operation. In almost all cases, perpetrators will choose the latter. Doing otherwise is counterproductive since publicizing even the most basic details of a pending operation affords the target an opportunity to enact countermeasures. Announcing that \"[you] will attack this network with this effect unless [the target] refrain[s] from X\" would be \"self-defeating\" (Lindsay 2015, 55). Acting clandestinely raises the likelihood of success by denying victims the chance to take steps that might blunt the efficacy of the attack such as patching a vulnerability or cutting access to servers. This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim.[8] Even when the perpetrator is not relying on zero days,\nthey still will not want to announce the exact vector by which the intrusion will occur to avoid jeopardizing the operation.\nActors have the most agency when it comes to secrecy and deception after an attack occurs at time  $\\mathrm{T}_{1}$ . Here, perpetrators must decide whether to proceed in a manner consistent with covert action (denying their role) or not (claiming it). Should a perpetrator choose to forgo plausible deniability, they must then decide how to communicate complicity. The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity (Libicki 2009, 50-51; Nye 2017, 51). Perpetrators can do this by leaving clues in the course of the attack—for example, leveraging a vector they have been known to use before, reusing code from a previous intrusion, or otherwise leaving signatures in the source code of malware. Or they might communicate through discrete diplomatic channels with a foreign counterpart (Borghard and Lonergan 2017, 459).\nThe second means of communicating complicity, public acknowledgment, refers to a situation where the perpetrator openly pronounces their identity to a much wider audience following an attack. They might make a public statement or alert the media of their culpability. Explaining why some actors intentionally dispense with anonymity—and, for those that do, whether they will credit-claim publicly or privately—is the focus of the next two sections. For now, it will suffice to point out that the attribution problem ceases to exist in cases where the perpetrator willingly makes their identity known.\nActors can, and often do, opt to act both clandestinely and covertly in the course of a single operation (Betz and Stevens 2011, 88). Our rationale for distinguishing between the two is to make clear that while clandestinity is a technical requirement of almost all cyber operations the decision to act covertly is something perpetrators consciously select into. In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.[9]\nIn what follows, we use these distinctions to address our original puzzle regarding why some actors claim responsibility for operations while others choose to remain anonymous. The next section discusses the politics of credit-claiming for states. We then turn to nonstate actors, a neglected but important player in the cyberspace arena.\n\nRethinking Secrecy in Cyberspace\n# States and the Politics of Voluntary Attribution\nWhether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion.[10] If success is possible without the target consciously acceding to some demand, states will act covertly and hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission.[11] In terms of how they eventually reveal complicity, we argue that states are most likely to use private channels and discrete communication.\n# When States Come Clean\nWhen the success of state-sponsored cyber operations does not require target compliance, voluntary credit-claiming is unnecessary at best and counterproductive at worst. In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage.[12] Like any intelligence gathering effort, voluntary attribution would be disadvantageous. Should a perpetrator announce that they have penetrated an adversary's network, they will jeopardize both their intrusion method and continued access without reaping any obvious benefit in return. Preserving anonymity is thus the preferred option for states interested in stealing secrets in cyberspace.\nAnother class of cyber operations, political action and sabotage, is also best served by perpetual anonymity. Examples include operations to influence elections through disinformation campaigns, vote manipulation, and the destruction of physical equipment and critical infrastructure. Because the success or failure of these operations does not depend on the target consciously responding to specified incentives, the motivations for states to voluntarily claim credit should be correspondingly low.\nThe calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful (Schelling 1966). When operations require that the\n\ntarget accede to a set of demands—either to do something (change the status quo) or to refrain from doing something (preserve the status quo)—states are likely to shun anonymity and engage in voluntary attribution. The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim (Carson and Yarhi-Milo 2017). Remaining anonymous does little to advance these aims. As Liff (2012) notes, “[u]nder most circumstances, any would-be aggressor who does not identify itself forfeits the ability to coerce its adversary” (414). Anonymity makes it hard for targets to evaluate the credibility of a threat and the sender’s resolve. Credit-claiming is thus critical if cyber coercion is to have any chance of succeeding. Betz and Stevens (2011) hint at this: “[W]hen states use military cyber-power against other states for the purposes of compelling them to do their will, they still have to declare what it is (even after the event). There is no sneaky way around this fact” (95). It is worth reiterating, however, that this can only feasibly be done after the attack has ended. As discussed earlier, providing details beforehand could undermine the mission and render the coercive threat impotent.\nForgoing anonymity permits states to more effectively make coercive threats by demonstrating credibility and resolve in at least two ways. First, a claimed attack can function as a costly signal by showing the threatening party's willingness to expend valuable resources in the hopes of gaining compliance from the target. According to Borghard and Lonergan (2017), \"[t]he greater the cost to the initiating state of producing a given signal, ceteris paribus, the more effective the signal is as an indication of the initiating state's resolve\" (467).\nSecond, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power.[13] Prestige and power, though related, are not the same. The latter refers strictly to capabilities, which can never be fully observed in cyberspace owing to the premium placed on keeping these tools shrouded in secrecy. The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\" (Gilpin 1981, 31).[14] States who cultivate a reputation for cyber power may be able to\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nIt is worth briefly outlining how the dynamics of cyber prestige and coercion could operate in practice. When the goal is to compel a target to alter their behavior, perpetrators may take offensive action in cyberspace, claim credit for it, and threaten future punishment should the target fail to comply. When the goal is to deter some action, perpetrators may similarly be able to take offensive cyber action, claim credit for it, and threaten future punishment should the target act in ways deemed undesirable by the sender. A more plausible situation in the case of cyber deterrence might entail the victim of a recent attack retaliating against the perpetrator, voluntarily claiming credit, and threatening future harm should there be any further attacks against them. In each of these scenarios, cyber coercion is possible to the extent that the target believes the sender's promises of future pain are credible and that the threatener is resolved as a result of having claimed past attacks. It is \"the threat of . . . more damage,\" or the \"expectation of more violence,\" that may induce a target to give in (Schelling 1966, 3; emphasis in original).\nThere is obviously no guarantee that claiming credit for past attacks will generate the credibility necessary for coercion. If the target does not believe that the challenger has the ability or willingness to repeat similar or more painful attacks, issuing deterrent or compellent threats after claiming an intrusion with the promise of \"more where that came from\" won't work. Nevertheless, we are skeptical that observers never update their beliefs about an actor's capabilities and resolve, and opt instead to treat every attack as an isolated event. While Russia is unlikely to easily hack the Democratic National Committee again, for example, few observers doubt their capacity to carry out similar attacks in the future. Whether credible coercive threats will actually suffice to achieve concessions, while important in its own right, is a separate matter and depends on a complex cost-benefit calculation.\n## Escalation and the Means of Communication\nThis section focuses on the right-hand side of Figure 2, after an actor chooses to forgo plausible deniability $(\\mathrm{T}_1)$ and decides whether to claim responsibility publicly or privately. We argue that the unique dynamics of politically motivated, state-on-state cyber activity make public acknowledgment less attractive than private acknowledgment. There are several reasons for this.\nAs a general matter, opportunities for retaliation are higher when the actors involved are states. Unlike non-state actors, states are stationary, immobile entities with numerous targets available to hit. Concern about attacks against a state's critical infrastructure have been likened to a potential \"cyber 9/11\" (Maxey 2017). Moreover, perpetrators that publicly announce sponsorship of a cyberattack put the victim—in many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige (Carson and Yarhi-Milo 2017, 135).\nBecause the victims of publicly claimed, state-sponsored cyberattacks typically have both the opportunity to retaliate as well as strong domestic-level pressures to do so, nation-states interested in cyber coercion face powerful incentives to quietly claim their actions using private channels. While credit-claiming in private lacks the broader prestige benefits associated with publicity and limits the audience observing an operation's (physical) costly signals, it may nonetheless afford states an opportunity to engage in coercive diplomacy at reduced risk. Recent scholarship shows that states often face powerful incentives to collude with one another in acts of secrecy. For example, Carson (2016) argues that states may opt not to publicize the covert military actions of their rivals even when they are targeted as a way of keeping conflicts limited and contained. A similar logic should apply to discrete attempts at coercion in cyberspace.\nOne risk of private acknowledgment is that the victim will \"out\" the perpetrator by publicly announcing the occurrence of an intrusion and offering proof that the attacker sought to privately attribute themselves. While this is always a possibility, such concerns may not wholly disincentivize states from pursuing private acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them (Rid 2012, 28–29). This, in turn, can motivate perpetrators to quietly come clean with little fear of being exposed by the victim. Second, when victims have the capacity to out a state\n For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).\nRethinking Secrecy in Cyberspace\npursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases. This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity (Yarhi-Milo 2013, 407).\n# Nonstate Actors and the Politics of Voluntary Attribution\nThe discussion so far has focused on the conditions under which states will claim credit for cyberattacks and why they are more likely to do so privately. This is important for obvious reasons. However, nonstate actors dominate the empirical record of credit-claiming in cyberspace. In what follows, we explain why nonstate actors commonly claim attacks and why they tend to do so publicly.\nDrawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means (Nye 2010; Asal et al. 2016). Regardless of their method of contention, nonstate actors are agents of change operating in a structural environment in which they are severely disadvantaged. These groups wield significantly fewer resources than states—financial, material, and otherwise—and their capabilities are consequently more constrained and more uncertain. In addition, what few capabilities nonstate actors do possess are in large part a function of the number of participants they can organize. This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well (Asal and Rethemeyer 2008; Chenoweth and Stephan 2011). The same basic logic extends to nonstate actors operating in cyberspace. One of the most common tools in a group's cyber arsenal, the distributed denial of service (DDoS) attack, grows stronger with every additional user.\nOur primary claim is that nonstate actors are more likely than states to brazenly claim cyberattacks. Not\n See also Carson and Yarhi-Milo (2017, 135).\n On the importance of states for Internet politics, see Rovner and Moore (2017).\n To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.\nonly does this help showcase their capabilities, but the media attention can help attract new members to the cause. Additionally, since it is often difficult to bring these groups to justice, organizations like Anonymous, Lulzsec, and others face reduced incentives to keep quiet about their operations. In sum, complicity is a critical component of nonstate actors' strategic logic and they commonly announce sponsorship of cyberattacks as a result.\n# The Appeal of Credit-Claiming\nNonstate actors typically have coercive objectives. As Schelling wrote in 1973, \"[p]olitical violence, like political nonviolence, usually has as its purpose making somebody do something or not do something or stop doing something. The aim is to influence behavior.\" In a broad sense, their goals are comparable to those of states seeking to alter the behavior of their adversaries.\nAbove, we argue that a key component of coercion is credibility: can actors issuing coercive threats make good on their promises of more pain if the target resists? This is especially difficult for nonstate actors (Hoffman and McCormick 2004; Kydd and Walter 2006; Dannenbaum 2011). They cannot put on military parades to show off their latest weaponry, do not have the means to finance modern military forces, and lack the resources—territorial, bureaucratic, and financial—of states. It is easy to dismiss the demands of nonstate actors as inconsequential chatter.\nGiven these deficits, the issue of how to boost credibility features centrally in the strategic logic of politically motivated nonstate actors. As with states, one way to demonstrate capabilities and resolve is to take action perceived as a costly signal. According to Kydd and Walter (2006), \"[b]ecause it is hard for weak actors to make credible threats, terrorists are forced to display publicly just how far they are willing to go to obtain their desired results\" (50). Similarly, Abrahms (2013) writes that \"[t]errorism . . . adds credibility to threats by showing that nonstate challengers possess the power to hurt\" (661).\nFor nonstate cyber warriors, sending costly signals to bolster credibility may include defacing government websites, launching distributed denial of service attacks,\n To the extent that they run the risk of capture, however, the credibility of their signals goes up.\n Quoted in Sharp and Finkelstein (1973, xx).\n Doing so might expose their position and invite unwanted risk.\n One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nA history of successful attacks by a nonstate group can also help cultivate their prestige in much the same way it does for states. As such, nonstate actors stand to lose by not identifying their organization as responsible for an attack. Failing to communicate culpability negates an operation’s objectives and precludes nonstate actors from reaping signaling and reputational benefits that are critical to successful coercion. Without knowing who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities. It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own (Bloom 2005, 78–79).\n## Maximizing Publicity\nThe notion that nonstate actors are more likely to claim attacks to showcase their capabilities and resolve mirrors a similar motivation among states interested in cyber coercion. Where the two diverge is in the preferred method of claiming. Several factors make nonstate actors more likely to choose public rather than private acknowledgment.\nOne reason nonstate cyber warriors crave the limelight hinges on the audiences they seek to influence. These\n It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.\n Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).\ngroups are often interested in sending a message not just to adversarial governments but to their populations as well. The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance (Schmid 2004). As Crenshaw (1981) notes in a related context, “[t]he victims or objects of terrorist attack have little intrinsic value to the terrorist group but represent a larger human audience whose reaction the terrorists seek” (379).\nUltimately, terrorists target the public since they are too weak to confront the state head-on. The same should be true of nonstate actors in cyberspace since these groups face comparable disadvantages. For such a strategy to work, however, communication cannot be private; it must be visible, clearly attributed, and widely known to the government and public alike.\nA second reason nonstate actors in cyberspace prefer public methods of claiming credit turns on their desire to attract new recruits. Like their traditional counterparts, these actors are interested in survival and growth. According to Pape (2005), “terrorism has two purposes—to gain supporters and to coerce opponents. Most terrorist campaigns seek both goals to some extent, often aiming to change the target state’s policies while simultaneously mobilizing support and recruits for the terrorists’ cause” (7). Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization (Abrahms 2008, 379) and augment their coercive ability. It is well established that the power of civil resistance flows from mobilization numbers, and the same goes for organizations in cyberspace. When it comes to their operating methods, these groups favor tactics that grow more powerful with additional bots and active supporters. The strength of DDoS operations, for instance, is linked to the number of machines involved (Ghosemajumder 2016). The Low Orbit Internet Cannon (LOIC) and related variants draw strength from those who download the application and flood a server. With more members at their disposal, groups are able to launch increasingly formidable cyber operations.\n On the determinants of DDoS attacks, see Asal et al. (2016).\n It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.\nRethinking Secrecy in Cyberspace\n# Plausibility Probes\nA lack of readily-accessible decision-making documents complicates rigorous empirical tests of our argument. If we are right that state-sponsored cyber operations involving espionage and sabotage are prime candidates for secrecy before, during, and after execution, it might be decades or longer before relevant materials are declassified.27 While coercive cyber operations are more likely to involve credit-claiming, the advantages of claiming attacks privately also impede observation. In fact, outsiders might be unable to discern differences between victims who are truly ignorant of their attacker's identity and those that feign ignorance while privately communicating with their attackers.\nAs a second-best strategy, we examine publicly available sources including news reports and a range of secondary materials to provide a preliminary test of our argument. We also conduct two interviews: one with a former Defense Department official involved in cyber policy and one with a former member of Anonymous. These helped corroborate what we found in the public record.\n# States\nWe were unable to find a single case of a state claiming credit for a cyber espionage operation, either openly or privately. Rather, the cases that have inadvertently come to light underscore the vigor with which states seek to avoid being named. China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative (Nakashima 2015). In the aftermath of the intrusion, Chinese officials denied complicity, placing blame on criminal hackers. They even went so far as to claim that they had arrested individuals who were connected with the hack (Chalfant 2017).28 Another example is Russia's alleged interference in the 2016 US election. The \"theft of research and emails from the Democratic National Committee\" for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government (Sanger 2016).29\n\nWhen asked in March 2017 about whether Russia was behind the efforts to discredit Hillary Clinton, Putin responded with \"Read my lips: No\" (Lister, Ilyushka, and Gigova 2017). When it comes to cyber espionage, there is no benefit to be had from credit-claiming.\nStuxnet provides a useful illustration of why decision-makers sometimes cling to anonymity and, more interestingly, the conditions under which they might be willing to voluntarily claim credit.30 Stuxnet, formally known as \"Olympic Games,\" was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant (Farwell and Rohozinski 2011). The aim was to make the Iranians believe their centrifuges were failing for reasons other than foreign interference. Sanger (2012) writes the following: \"When the centrifuges first began crashing in 2008 at the Natanz enrichment center, the crown jewel of the Iranian nuclear program, the engineers inside the plant had no clue they were under attack. That was exactly what the designers of the world's most sophisticated cyberweapon had planned.\" He continues that \"[t]he idea, hatched in Washington and Jerusalem, was to make the first breakdowns seem like random accidents and small ones at that\" (188).\nSanger's interviews with government officials confirm that the operation was supposed to leave no trace of US fingerprints: \"The most elegant cyber weapons are a lot like the most elegant bank frauds. . . . They work best when the victim doesn't even know he's been robbed\" (190-91). It is clear from this account that the United States kept both the operation and their sponsorship intentionally hidden, as our argument predicts. The success or failure of the operation did not depend on Iran changing their behavior, but simply hinged on the quiet destruction of centrifuges.\nInterestingly, though, some US operatives contemplated quietly alerting the Iranians that the United States was responsible for the attack. Their apparent rationale conforms to our theoretical expectation. Ostensibly, the goal would have been to send a message to Tehran that the United States had the ability to keep targeting their systems, presumably as a way of achieving concessions on the nuclear program. According to Sanger (2012), \"[a]t both the Pentagon and inside the intelligence agencies some of the creators of the bug believed that it might be\ninformation to relevant entities who could use it to discredit Hillary Clinton. Even if so, this type of action would qualify as a classic covert operation, and thus we would still expect Russian denials.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nMore recent examples suggest that states are thinking hard about voluntarily claiming credit for their cyber operations in the service of coercion. In late September 2017, it came to light that the Trump administration authorized US Cyber Command to carry out a range of limited cyberattacks against North Korea's Reconnaissance General Bureau intended to interfere with Internet access (DeYoung, Nakashima, and Rauhala 2017). Most importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy.[32] Panda (2017) argues that the United States had \"take[n] the cyber equivalent of a shot across North Korea's bow, presumably signaling that it has the requisite access to North Korean networks to deliver considerably more significant damage in wartime.\" Since North Korea is not wanting for enemies, it seemed to serve US objectives to let their complicity be known, thereby reducing ambiguity about what behavioral changes were expected from the Kim regime.\nFurther evidence for our theory comes from recent statements by Shawn Turskey, the executive director of US Cyber Command. His comments from 2016 indicate that the United States government is contemplating ways to leverage cyber capabilities for coercive purposes,\n\nspecifically through intentional credit-claiming. Turskey declared the following:\nIn the intelligence community you never want to be caught, you want [to] be low and slow, you never really want to be attributed. . . . But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know. (Bing 2016, emphasis added)\nThese remarks are noteworthy for several reasons.[33] Chief among them is the prospect of the world's lone superpower developing an arsenal of cyber weapons with a return address. The fact that loud, attributable weapons are being discussed at all is at odds with the typical portrayal of cyberspace as a domain defined by secrecy and anonymity. Yet, it is easier to understand why Turskey is contemplating this shift once we come to terms with the mechanics of cyber coercion. Leveraging cyber assets for coercive purposes, rather than espionage or sabotage—which fits more readily within the purview of the military as opposed to the intelligence community—requires credible self-attribution. Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal (Lin 2016).\nMichael Sulmeyer, the former director for Plans and Operations for Cyber Policy in the Office of the Secretary of Defense, affirmed this sentiment in an interview for this article. Echoing the idea that cyber weapons can and should be embraced for more traditional purposes, he highlights the following:\nIt is important for the United States to invest in capabilities that not only help it improve its espionage activities against adversaries, but also that help it prevail in the event of hostilities with adversaries. When operating in the realm of the second objective, it can be beneficial for the United States to take responsibility for its actions publicly—not to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.[34]\nTaking responsibility, as Sulmeyer suggests, provides America's adversaries the chance to understand the extent of their cyber power. Similar to Turskey, Sulmeyer anticipates that more voluntary credit-claiming may be on the horizon:\n\nRethinking Secrecy in Cyberspace\nTo be sure, this signal could be missed or dismissed—and a mere tap on the digital shoulder clearly would not suffice for such a signal to be internalized. But why go through all the effort to hide every action every time in this context? That's an unnecessary additional burden in a war fight. If there are a suite of capabilities that can help our forces be more agile during hostilities, I would hope they are on the table for our commanders and leaders in the future.\n## Nonstate Actors\nThe empirical pattern of cyberattacks by nonstate actors differs from what we observed for states. These actors frequently claim credit for their cyberattacks in very public ways. Much like terrorist attacks, these operations almost always entail a political message intended to alter public opinion, change government policies, and the like. A cyberattack carried out by the Syrian Electronic Army against the US Army's website showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion (Vinton 2015). Quietly alerting the US Army that the Syrian Electronic Army was behind the attacks would have undermined the strategic motivations underlying the entire operation, namely bolstering their reputation as a group that deserves respect and sending a clear message with the intention of affecting public opinion and altering policy. The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list (Temperton 2016).\nFor a more complete picture of the decision-making process for nonstate actors in cyberspace, we briefly examine one of the most well-known organizations: Anonymous. Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article (Olson 2012; Coleman 2014). Anonymous’ behavior following this shift, though, sheds light on the group’s political strategy and how publicity and attention serve their goals.\nA cursory overview of Anonymous’ exploits over the years shows that the group commonly claims credit publicly for its operations. In late March 2016, Anonymous targeted roughly twenty Angolan government websites in response to the arrest of several activists. Prior to carrying out the attack, they posted details about the websites\nthey intended to target (British Broadcasting Company 2016). In one of their biggest and best-known campaigns, Operation Tunisia, the group first put out a press release via YouTube before a launching series of DDoS attacks that took down numerous government-linked websites. This was part of a broader operation intended to assist protesters and weaken the government of Ben Ali. Most relevant for our purposes, the group issued a clear coercive threat: “This is a warning to the Tunisian government: attacks at the freedom of speech and information of its citizens will not be tolerated. . . . Free the net, and the attacks will cease, keep on that attitude and this will just be the beginning” In another high-profile incident, Anonymous targeted the Church of Scientology. As before, the attack began with a YouTube press release and proceeded with a series of DDoS attacks, doxing, and more press releases and media statements. In line with our expectations, the IT company hired by the Church of Scientology implored them to simply ignore the attacks: “Don’t issue warnings or threats to the attackers via the media; this will only keep the issue alive, raise tempers, and greatly increase the possibility of another assault. Most DDoS attackers seek publicity, so don’t hand it to them on a silver platter.” Their solution was to deprive Anonymous of what it wanted most, namely attention.\nThis strategy of pursuing highly visible, self-attributed missions served at least three functions. First, Anonymous used these operations to ensure that they were taken seriously and that their coercive threats were not ignored. Establishing their capabilities, resolve, and credibility by conducting attacks with clear attribution contributed to this effort. This was explicit in their internal conversations during the operation against the Church of Scientology. As one member put it, “I think it’s time for [us] to do something big. People need to understand not to f*** with [Anonymous].” These and other attacks proved somewhat successful. Outside observers came to understand that they should not dismiss the group’s threats. Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility” (Olson 2012, 177).\nSecond, Anonymous recognized that part of their strategy revolved around the public. During Operation Payback in 2010, which aimed to promote Internet privacy by targeting antipiracy groups, members of\n See https://www.youtube.com/watch?v=BFLaBRk9wY0.\n Quoted in Coleman (2014, 149).\n See https://www.youtube.com/watch?v=JCbKv9yiLiQ.\n Quoted in Olson (2012, 89).\n Quoted in Olson (2012, 2).\nInterview with authors, October 26, 2017.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\nAnonymous ardently debated this component of their strategy. Support eventually developed for one member who claimed that “... these attacks are less about hurting the business than drawing attention and forcing the media to cover the story. . . . The point for me is that this is the technological way of mass protesting that’s actually effective.”41 Getting their message out to the public to garner attention became a core objective.\nAnonymous’ operations often did more than just influence the public indirectly via messaging; sometimes the public was the direct target of attacks. Anonymous, like most terrorist groups, eventually had to reconcile with the fact that targeting innocent civilians might be useful for achieving their aims. This issue came to a head during Operation BART (Bay Area Rapid Transit), when members leaked information on individual passengers, including credit card numbers and other details from the company’s website. When asked about the incident by a reporter, a senior member replied, “[h]ow else do you get the world to respond and secure your information? How else do you get these companies and these big governments to keep your information, the information you give them voluntarily, safe? I think we got our message across, and I’ll bet you one thing: I’ll bet you they fix that.”42 Anonymous’ symbolic, essentially random targeting was part of a broader campaign to influence public opinion and achieve political change. Their cyberattacks were acts of coercion that bore a striking resemblance to the strategic logic of militant organizations.\nFinally, Anonymous’ cyber behavior was often geared toward generating new members and deepening support among their base. In an interview conducted for this article, we asked Hector Monsegur, a former leader of Anonymous known as Sabu, why the group was so eager to publicly claim their operations. As he put it,\nAt the time of its height (not so much now) Anonymous had gained huge successes in publicizing its protests, hacks, and engagements. They were masterful in the distribution of content, and the media truly ate it up for several reasons:\nIt was neatly packaged and ready for distribution, the hackers were willing to give interviews, and of course the mystery element. The whole thing about the mask and shadowy figures really “sells” the concept. As Anonymous grew in action, it also grew in numbers and support . . .\nThe truth of the matter is that Anonymous needed the media to grow, and this explains why many of the\nthings we did were really attention-grabbing. It served a purpose. It’s very similar to branding and how companies slip in their products into film, or events in general, even if each engagement or hack had different motivations.43\nIn her research on Anonymous, Coleman (2014) expands on this point: “[W]ithout the appearance of a critical mass, the operation would have likely lacked moral gravitas and authority. In this case, strength in numbers conveyed a potent message” (138). Expanding their membership didn’t just provide Anonymous legitimacy; it provided additional capability as well. While many of Anonymous’ DDoS campaigns relied on botnets to create their desired effect, individual users sustained those attacks that used the freeware LOIC, a staple of the group’s earlier activity. This required the group to invest time in assisting new members with the software. Olson (2012) points out that the group felt it was worth it to take the time “getting the [new members] on board to create an army” (65).\nUltimately, it was in Anonymous’ interest to take credit for their cyber operations through highly visible, public means of communication. Doing so rewarded their efforts significantly and was instrumental to their strategic logic. Whether the target was the Tunisian government or the Church of Scientology, the attention they received bolstered their particular brand of coercion. This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance (Coleman 2014, 107).\n## Cybercrime and Cyber Blackmail\nBefore concluding, it is worth flagging two types of cyber operations perpetrated by state and nonstate actors alike that are unlikely candidates for voluntary attribution. The first are operations involving theft of financial or intellectual assets. These are among the most common kind of cyberattack and are ill-served by credit-claiming. Malicious actors that leverage cyber assets for criminal purposes, such as stealing money from banking institutions, have little incentive to self-attribute. Doing so would provide little benefit and expose them to potential prosecution. While nonstate actors most commonly conduct these kinds of attacks, states may as well. For example, North Korea was identified as the responsible party in a cyber heist against Bangladesh’s central bank. Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million (Finkle 2017).\n\nRethinking Secrecy in Cyberspace\nA second unlikely candidate for voluntary attribution is what we might call “cyber blackmail,” or operations in which the perpetrator leverages stolen assets, embarrassing secrets, and the like to achieve compliance from the victim without having to reveal their true identity. These operations are particularly interesting in that success requires target compliance—which we argue should lead to credit-claiming—but the perpetrator can remain behind a mask. By selectively releasing compromised information and assets to the victim publicly or privately (Lindsay 2015, 57), the perpetrator may be able to force compliance while remaining anonymous or hiding behind front groups.\nThis dynamic approximates what might have happened during the Sony hack, in which the “Guardians of Peace” (#GOP) issued an explicit compellent threat against Sony in an attempt to prevent the company from releasing The Interview, a comedy satirizing North Korea’s leader Kim Jong Un. In the event that Sony failed to comply with #GOP’s demands, the group threatened to release propriety information and potentially embarrassing e-mail correspondences between high-level employees. Although North Korea was widely suspected of sponsoring the attack, the regime denied any involvement. Nonetheless, the attack partially succeeded in coercing Sony without the government having to explicitly take credit. We believe that the attack was partially successful as a result of Sony’s understanding that certain assets (personal e-mails, financial records) had indeed been compromised and would be released should they fail to comply.\n## Conclusion\nThis article draws on existing theory to develop an explanation for why states and politically motivated non-state actors might voluntarily claim credit for their attacks. We argue that the goals of an operation as well as the characteristics of the perpetrator drive both the decision to claim credit as well as the manner in which culpability is communicated. This research has several important implications. First, we show how states and nonstate actors share a common set of choices with regards to secrecy in cyberspace. Both face the same decisions at the same points in the life cycle of a cyberattack, yet the characteristics of each can cause their strategies to diverge, particularly when it comes to the optics of credit-claiming. Future research should continue to investigate how the characteristics and operational and strategic goals of cyber actors influence the look and feel of their cyber actions.\nSecond, existing research often treats cyber operations as distinct from more traditional elements of state power. Although there are differences, the framework developed here suggests that states may be able to leverage cyber assets to achieve many of the same goals most frequently pursued with conventional forces. Scholars have pushed back against this idea for a variety of reasons, one being the attributional difficulties of cyber operations. But states need not conceal their complicity in perpetuity. By relaxing this assumption, we can more easily see how these operations fit into a state’s coercive toolkit. One area ripe for future research is the efficacy of coercion in cyberspace, both on its own and in comparison to more conventional methods.\nFinally, while inferring intentions from behavior is problematic, actors’ decisions to privately or publicly acknowledge sponsorship of an attack may provide crucial information about motives and identity. Clinging to covert forms of secrecy after the completion of an attack might highlight a set of plausible underlying motivations for the initial intrusion, including espionage, cybercrime, and the like. Conversely, if the actor does come clean, it might be appropriate to infer that credibility, prestige, or coercion was the true goal. In the information-starved domain that is cyberspace, these clues may be all there is when designing policies and crafting responses.\n## Acknowledgements\nThis is one of several collaborative projects by the authors, and the ordering of names follows a principle of rotation. We are grateful to Joseph Brown, Ben Buchanan, Ryan Evans, Robert Jervis, Joseph LaPalombara, Herb Lin, Jon Lindsay, Joseph Nye, Joshua Rovner, and Michael Sulmeyer for helpful comments, suggestions, and insights. An earlier version of the argument presented here appeared in War on the Rocks."
    },
    "numeric": {
      "total": {
        "intext_total": 11,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "8",
          "intext_citation": "[8]",
          "preceding_text": "This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim.",
          "footnote": null
        },
        {
          "index": "9",
          "intext_citation": "[9]",
          "preceding_text": "In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.",
          "footnote": null
        },
        {
          "index": "10",
          "intext_citation": "[10]",
          "preceding_text": "Whether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion.",
          "footnote": null
        },
        {
          "index": "11",
          "intext_citation": "[11]",
          "preceding_text": "hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission.",
          "footnote": null
        },
        {
          "index": "12",
          "intext_citation": "[12]",
          "preceding_text": "In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage.",
          "footnote": null
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "Second, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power.",
          "footnote": null
        },
        {
          "index": "14",
          "intext_citation": "[14]",
          "preceding_text": "The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\" (Gilpin 1981, 31).",
          "footnote": null
        },
        {
          "index": "31",
          "intext_citation": "[31]",
          "preceding_text": "some policymakers believed they could more easily alter the Iranian regime's behavior by embracing responsibility and proving that they could bring more pain to bear should they continue down the path of nuclearization.",
          "footnote": null
        },
        {
          "index": "32",
          "intext_citation": "[32]",
          "preceding_text": "importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy.",
          "footnote": null
        },
        {
          "index": "33",
          "intext_citation": "[33]",
          "preceding_text": "These remarks are noteworthy for several reasons.",
          "footnote": null
        },
        {
          "index": "34",
          "intext_citation": "[34]",
          "preceding_text": "t to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.",
          "footnote": null
        }
      ],
      "flat_text": "Journal of Global Security Studies, 3(4), 2018, 402-416\ndoi: 10.1093/jogss/ogy022\nResearch Article\nOXFORD\n# Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution\nMichael Poznansky¹ and Evan Perkoski²\n¹University of Pittsburgh and ²University of Connecticut\n## Abstract\nCyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain.\nKeywords: cyber warfare, secrecy, coercion, nonstate actors\n## Introduction\nSecrecy is a defining feature of cyberspace. Cyber intruders can frequently disrupt networks, steal financial assets, and conduct espionage without ever revealing their identities. Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence (Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017) to its influence on the dynamics of conflict and escalation (Gartzke 2013; Buchanan 2017). Yet, while cyber intruders have ample opportunities to keep their sponsorship a secret, not all choose to take advantage. To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions (Smith 2016). They are not alone; SOBH Cyber Jihad, based in Iran, claimed credit for hacking into the control system of a dam in New York (Gosk, Winter, and\nConnor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015 (Vinton 2015).\nWhy do some actors claim responsibility for cyber operations while others opt for anonymity? To answer this question, we explore the logic of credit-claiming for two key sets of actors in cyberspace: states and politically motivated nonstate actors (hereafter, nonstate actors).¹\nWe argue that credit-claiming, including the manner in which culpability is communicated, depends on what the intruder wants to accomplish. For states, credit-claiming is most appealing during operations that require target compliance, otherwise known as cyber coercion. When states choose to make their identities known to coerce targets, they are more likely to do so privately since public credit-claiming raises the odds of escalation. Anonymity is most attractive during operations where\n¹ We bracket nonstate actors without political motivations.\nPoznansky, Michael, and Evan Perkoski. (2018) Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution. Journal of Global Security Studies, doi: 10.1093/jogss/ogy022\n© The Author(s) (2018). Published by Oxford University Press on behalf of the International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n403\nsuccess can be achieved without target compliance—cyber espionage and sabotage offer two such examples. Nonstate actors operate according to a different logic. Drawing on insights from studies of armed and unarmed resistance, we argue that nonstate actors in cyberspace regularly claim credit for their intrusions in visible ways to signal credibility, influence public opinion, and grow their ranks. Owing to their relative weakness and obscurity, nonstate actors must first prove their capability before doing anything else.\nThis argument requires a conceptual shift in how we think about secrecy in cyberspace. Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations (Kibbe 2007). The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise (Axelrod 1979; Slantchev 2010). The latter involves the use of secrecy to conceal the sponsor of an operation (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson 2016). Importing this distinction to the cyber domain helps clarify when secrecy is an operational imperative and when it is a choice that actors make. In brief, the advantages afforded to targets who learn of imminent or ongoing operations means that cyber intrusions will almost always be conducted clandestinely. Once an operation is complete, however, intruders are free to choose whether to claim responsibility. Put differently, cyber operations are almost always clandestine but not necessarily covert. The failure to recognize this distinction partly contributes to the widespread assumption that anonymity is an immutable feature of cyberspace rather than something actors select into.\nRigorously testing these claims would require access to the internal deliberations of state and nonstate actors to understand how decisions about credit-claiming are made. At present, this is a nearly impossible task (Buchanan 2017, 12). We are perhaps decades away from gaining access to the types of declassified documents necessary to evaluate the deliberations of states; the problem is even more acute for nonstate actors. As a second-best option, we leverage a range of sources—secondary materials, news reports, official government statements, and interviews—to assess the plausibility of our argument. Our study is closer to an exercise in theory construction than theory testing (Mahoney 2015, 201).\nThis article makes several contributions. First, it joins together a burgeoning literature centered on the dynamics of secrecy in world politics and another focused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation (Carson 2016), and the relationship between democratic peace theory and covert regime change (Downes and Lilley 2010; Poznansky 2015). These studies are tied together by an overarching focus on how actors use secrecy to pursue their political goals. Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike (Gartzke 2013; Gartzke and Lindsay 2015; Lindsay 2015; Rid and Buchanan 2015; Buchanan 2017; Nye 2017) but have largely neglected the determinants of secrecy at the stage where sponsors can (dis)claim ownership of an operation.² We address this issue directly.\nSecond, this study is among the first of which we are aware that considers the goals and constraints of the two most important actors operating in cyberspace—states and nonstate actors. Existing research tends to focus on the former (Gartzke 2013; Buchanan 2017; Borghard and Lonergan 2017; Nye 2017). But nonstate actors conduct cyberattacks at high rates and often in very visible ways. Moreover, their attack capabilities are growing and in some cases they \"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\" (Stoller 2017). Ignoring nonstate actors or assuming that their strategic logic mirrors that of states is insufficient. Our approach is thus to ask the same questions for both sets of actors, reducing barriers that inhibit a more complete understanding of cyberattacks.\n## The Problem of Secrecy\nThe conventional view of a cyber operation is an intruder quietly penetrating a target's network to collect information or cause damage, whether virtual or physical, without betraying their identity.³ This narrative—which assumes secrecy from start to finish—colors how the literature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant (Slayton 2017). Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks (Rid and Buchanan 2015; Nye 2017, 49–52). According to Lindsay (2013), “[f]orensics takes months, whereas the anonymous attack can present\n2 For important exceptions, see Betz and Stevens (2011), Borghard and Lonergan (2017), and Libicki (2009).\n3 See Buchanan (2017) for a summary.\nRethinking Secrecy in Cyberspace\nitself and perhaps complete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity (Lindsay 2015, 58).\nThe pervasiveness of secrecy in this domain also poses challenges for cyber coercion (Valeriano and Maness 2014; 2015, 79; Nye 2017, 55-56). Coercion requires victims to know who is making demands and what they are being asked to do (Schelling 1966). Anonymity is antithetical to this enterprise. As Gartzke (2013) once put it, \"How does one surrender to no one in particular?\" (47). Some scholars point out that perpetrators can enhance the credibility of coercive threats by making their identities known, a point we develop more fully below. But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace (Borghard and Lonergan 2017, 457-59; Libicki 2009, 50-51).\nWhile all of these studies seem to address the same basic phenomenon—secrecy—there are meaningful differences when it comes to what is being concealed during an operation and for what purpose. The next section explores these differences.\n## Disaggregating Secrecy\nThe US military and intelligence communities distinguish between two types of secret operations. The first are clandestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise (Axelrod 1979; Slantchev 2010). As an example, consider Operation Neptune Spear, the US Special Forces' raid on Osama bin Laden's compound in Abbottabad, Pakistan. While the raid itself was shrouded in secrecy, President Obama's remarks to the nation afterward suggest that the purpose of secrecy was tactical, not political.\nThe second type of secret operation is covert action, defined as \"[a]n operation that is so planned and\nFigure 1. Clandestine and covert operations\nexecuted as to conceal the identity of or permit plausible denial by the sponsor.\"6 While covert operations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\" (Gross 2009, 12). There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns (Brown 2014; Carson 2016) and avoiding hostile reactions from domestic and international observers (Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson and Yarhi-Milo 2017; Joseph and Poznansky 2017). A classic covert operation is the Bay of Pigs. Training fifteen hundred exiles to storm the shores of Cuba to overthrow Fidel Castro was a highly visible act; the sponsor, the United States, was supposed to remain hidden.\nFigure 1 presents four different combinations of secret operations with illustrative examples.7 Cases in the northwest quadrant include cyber intrusions that are planned and executed clandestinely and denied by the sponsor. These are what observers typically have in mind when discussing the attribution problem in cyberspace. The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases (Betz and Stevens 2011, 95). Examples in the northeast quadrant are covert because the sponsor denied complicity but are not clandestine since the activities themselves, typically performed by third parties, are not hidden. Examples in the southeast corner include large-scale wars.\n4 Betz and Stevens (2011, 95) mention that claiming may be necessary but do not explain why.\nThis is taken from the Department of Defense's Dictionary of Military and Associated Terms, available at http://www.dtic.mil/doctrine/dod/dictionary/. Although this definition is focused on government entities, the same logic applies broadly.\n6 This is also taken from the Department of Defense's Dictionary of Military and Associated Terms.\n7 The very existence of this two-by-two signifies that the main variants of secrecy may be used in combination with one another or separately. Covert and clandestine action are cousins, not synonyms.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n405\nFigure 2. The logic of secrecy in cyberspace\nThese are neither covert (the sponsor was known) nor clandestine (the wars were announced in advance).\n## Secrecy in Cyberspace\nStudents of cyber warfare rarely distinguish between clandestine and covert forms of secrecy. As such, most studies do not explicitly address where secrecy is a de facto requirement rather than a choice in the course of a cyberattack. Figure 2 portrays a stylized schematic of cyber intrusions, capturing two of the key inflection points where actors make decisions about secrecy.\nAt  $\\mathrm{T_0}$ , perpetrators decide whether to announce to the target that an attack is imminent or whether they will conceal the operational details as in a clandestine operation. In almost all cases, perpetrators will choose the latter. Doing otherwise is counterproductive since publicizing even the most basic details of a pending operation affords the target an opportunity to enact countermeasures. Announcing that \"[you] will attack this network with this effect unless [the target] refrain[s] from X\" would be \"self-defeating\" (Lindsay 2015, 55). Acting clandestinely raises the likelihood of success by denying victims the chance to take steps that might blunt the efficacy of the attack such as patching a vulnerability or cutting access to servers. This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim. Even when the perpetrator is not relying on zero days,\nthey still will not want to announce the exact vector by which the intrusion will occur to avoid jeopardizing the operation.\nActors have the most agency when it comes to secrecy and deception after an attack occurs at time  $\\mathrm{T}_{1}$ . Here, perpetrators must decide whether to proceed in a manner consistent with covert action (denying their role) or not (claiming it). Should a perpetrator choose to forgo plausible deniability, they must then decide how to communicate complicity. The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity (Libicki 2009, 50-51; Nye 2017, 51). Perpetrators can do this by leaving clues in the course of the attack—for example, leveraging a vector they have been known to use before, reusing code from a previous intrusion, or otherwise leaving signatures in the source code of malware. Or they might communicate through discrete diplomatic channels with a foreign counterpart (Borghard and Lonergan 2017, 459).\nThe second means of communicating complicity, public acknowledgment, refers to a situation where the perpetrator openly pronounces their identity to a much wider audience following an attack. They might make a public statement or alert the media of their culpability. Explaining why some actors intentionally dispense with anonymity—and, for those that do, whether they will credit-claim publicly or privately—is the focus of the next two sections. For now, it will suffice to point out that the attribution problem ceases to exist in cases where the perpetrator willingly makes their identity known.\nActors can, and often do, opt to act both clandestinely and covertly in the course of a single operation (Betz and Stevens 2011, 88). Our rationale for distinguishing between the two is to make clear that while clandestinity is a technical requirement of almost all cyber operations the decision to act covertly is something perpetrators consciously select into. In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.\nIn what follows, we use these distinctions to address our original puzzle regarding why some actors claim responsibility for operations while others choose to remain anonymous. The next section discusses the politics of credit-claiming for states. We then turn to nonstate actors, a neglected but important player in the cyberspace arena.\n8 For a discussion, see Lin (2010, 65n7).\n9 Getting caught is still a real possibility, especially for larger operations (Lindsay 2015, 58).\nRethinking Secrecy in Cyberspace\n# States and the Politics of Voluntary Attribution\nWhether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion. If success is possible without the target consciously acceding to some demand, states will act covertly and hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission. In terms of how they eventually reveal complicity, we argue that states are most likely to use private channels and discrete communication.\n# When States Come Clean\nWhen the success of state-sponsored cyber operations does not require target compliance, voluntary credit-claiming is unnecessary at best and counterproductive at worst. In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage. Like any intelligence gathering effort, voluntary attribution would be disadvantageous. Should a perpetrator announce that they have penetrated an adversary's network, they will jeopardize both their intrusion method and continued access without reaping any obvious benefit in return. Preserving anonymity is thus the preferred option for states interested in stealing secrets in cyberspace.\nAnother class of cyber operations, political action and sabotage, is also best served by perpetual anonymity. Examples include operations to influence elections through disinformation campaigns, vote manipulation, and the destruction of physical equipment and critical infrastructure. Because the success or failure of these operations does not depend on the target consciously responding to specified incentives, the motivations for states to voluntarily claim credit should be correspondingly low.\nThe calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful (Schelling 1966). When operations require that the\n10 This distinction is similar to the one Schelling (1966) draws between brute force and coercion. On how qualitatively different types of cyber operations have been conflated, see Betz and Stevens (2011, 81).\n11 The need for target compliance is not the only factor underlying this decision. Whether the action itself violates longstanding norms, would trigger escalation, and the like may factor in as well.\n12 These qualify as computer network exploitation, or CNE (Nye 2017, 47).\ntarget accede to a set of demands—either to do something (change the status quo) or to refrain from doing something (preserve the status quo)—states are likely to shun anonymity and engage in voluntary attribution. The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim (Carson and Yarhi-Milo 2017). Remaining anonymous does little to advance these aims. As Liff (2012) notes, “[u]nder most circumstances, any would-be aggressor who does not identify itself forfeits the ability to coerce its adversary” (414). Anonymity makes it hard for targets to evaluate the credibility of a threat and the sender’s resolve. Credit-claiming is thus critical if cyber coercion is to have any chance of succeeding. Betz and Stevens (2011) hint at this: “[W]hen states use military cyber-power against other states for the purposes of compelling them to do their will, they still have to declare what it is (even after the event). There is no sneaky way around this fact” (95). It is worth reiterating, however, that this can only feasibly be done after the attack has ended. As discussed earlier, providing details beforehand could undermine the mission and render the coercive threat impotent.\nForgoing anonymity permits states to more effectively make coercive threats by demonstrating credibility and resolve in at least two ways. First, a claimed attack can function as a costly signal by showing the threatening party's willingness to expend valuable resources in the hopes of gaining compliance from the target. According to Borghard and Lonergan (2017), \"[t]he greater the cost to the initiating state of producing a given signal, ceteris paribus, the more effective the signal is as an indication of the initiating state's resolve\" (467).\nSecond, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power. Prestige and power, though related, are not the same. The latter refers strictly to capabilities, which can never be fully observed in cyberspace owing to the premium placed on keeping these tools shrouded in secrecy. The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\" (Gilpin 1981, 31). States who cultivate a reputation for cyber power may be able to\n13 This is a play on Gilpin (1981, 31).\n14 Interestingly, even if actors do not willingly come clean, successful attribution can still bolster prestige. Consider the Stuxnet worm, allegedly manufactured by US and Israeli operatives and how it reflects on their cyber potential. As one Symantec director noted, \"[i]t seems pretty reasonable to think that there are things out there today that we haven't seen that are much more advanced [than Stuxnet]\" (Szoldra 2016).\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n407\npersuade adversaries that their threats are credible even if they do not specifically outline the vector they intend to exploit or the zero day they plan to deploy if demands go unmet. A history of successful cyberattacks can offset the invisibility of a state's arsenal.\nIt is worth briefly outlining how the dynamics of cyber prestige and coercion could operate in practice. When the goal is to compel a target to alter their behavior, perpetrators may take offensive action in cyberspace, claim credit for it, and threaten future punishment should the target fail to comply. When the goal is to deter some action, perpetrators may similarly be able to take offensive cyber action, claim credit for it, and threaten future punishment should the target act in ways deemed undesirable by the sender. A more plausible situation in the case of cyber deterrence might entail the victim of a recent attack retaliating against the perpetrator, voluntarily claiming credit, and threatening future harm should there be any further attacks against them. In each of these scenarios, cyber coercion is possible to the extent that the target believes the sender's promises of future pain are credible and that the threatener is resolved as a result of having claimed past attacks. It is \"the threat of . . . more damage,\" or the \"expectation of more violence,\" that may induce a target to give in (Schelling 1966, 3; emphasis in original).\nThere is obviously no guarantee that claiming credit for past attacks will generate the credibility necessary for coercion. If the target does not believe that the challenger has the ability or willingness to repeat similar or more painful attacks, issuing deterrent or compellent threats after claiming an intrusion with the promise of \"more where that came from\" won't work. Nevertheless, we are skeptical that observers never update their beliefs about an actor's capabilities and resolve, and opt instead to treat every attack as an isolated event. While Russia is unlikely to easily hack the Democratic National Committee again, for example, few observers doubt their capacity to carry out similar attacks in the future. Whether credible coercive threats will actually suffice to achieve concessions, while important in its own right, is a separate matter and depends on a complex cost-benefit calculation.\n## Escalation and the Means of Communication\nThis section focuses on the right-hand side of Figure 2, after an actor chooses to forgo plausible deniability $(\\mathrm{T}_1)$ and decides whether to claim responsibility publicly or privately. We argue that the unique dynamics of politically motivated, state-on-state cyber activity make public acknowledgment less attractive than private acknowledgment. There are several reasons for this.\nAs a general matter, opportunities for retaliation are higher when the actors involved are states. Unlike non-state actors, states are stationary, immobile entities with numerous targets available to hit. Concern about attacks against a state's critical infrastructure have been likened to a potential \"cyber 9/11\" (Maxey 2017).¹⁵ Moreover, perpetrators that publicly announce sponsorship of a cyberattack put the victim—in many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige (Carson and Yarhi-Milo 2017, 135).\nBecause the victims of publicly claimed, state-sponsored cyberattacks typically have both the opportunity to retaliate as well as strong domestic-level pressures to do so, nation-states interested in cyber coercion face powerful incentives to quietly claim their actions using private channels. While credit-claiming in private lacks the broader prestige benefits associated with publicity and limits the audience observing an operation's (physical) costly signals, it may nonetheless afford states an opportunity to engage in coercive diplomacy at reduced risk. Recent scholarship shows that states often face powerful incentives to collude with one another in acts of secrecy. For example, Carson (2016) argues that states may opt not to publicize the covert military actions of their rivals even when they are targeted as a way of keeping conflicts limited and contained. A similar logic should apply to discrete attempts at coercion in cyberspace.\nOne risk of private acknowledgment is that the victim will \"out\" the perpetrator by publicly announcing the occurrence of an intrusion and offering proof that the attacker sought to privately attribute themselves. While this is always a possibility, such concerns may not wholly disincentivize states from pursuing private acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them (Rid 2012, 28–29). This, in turn, can motivate perpetrators to quietly come clean with little fear of being exposed by the victim. Second, when victims have the capacity to out a state\n¹⁵ For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).\nRethinking Secrecy in Cyberspace\npursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases.¹⁶ This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity (Yarhi-Milo 2013, 407).\n# Nonstate Actors and the Politics of Voluntary Attribution\nThe discussion so far has focused on the conditions under which states will claim credit for cyberattacks and why they are more likely to do so privately. This is important for obvious reasons.¹⁷ However, nonstate actors dominate the empirical record of credit-claiming in cyberspace. In what follows, we explain why nonstate actors commonly claim attacks and why they tend to do so publicly.\nDrawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means (Nye 2010; Asal et al. 2016). Regardless of their method of contention, nonstate actors are agents of change operating in a structural environment in which they are severely disadvantaged. These groups wield significantly fewer resources than states—financial, material, and otherwise—and their capabilities are consequently more constrained and more uncertain. In addition, what few capabilities nonstate actors do possess are in large part a function of the number of participants they can organize. This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well (Asal and Rethemeyer 2008; Chenoweth and Stephan 2011). The same basic logic extends to nonstate actors operating in cyberspace. One of the most common tools in a group's cyber arsenal, the distributed denial of service (DDoS) attack, grows stronger with every additional user.¹⁸\nOur primary claim is that nonstate actors are more likely than states to brazenly claim cyberattacks. Not\n¹⁶ See also Carson and Yarhi-Milo (2017, 135).\n¹⁷ On the importance of states for Internet politics, see Rovner and Moore (2017).\n¹⁸ To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.\nonly does this help showcase their capabilities, but the media attention can help attract new members to the cause. Additionally, since it is often difficult to bring these groups to justice, organizations like Anonymous, Lulzsec, and others face reduced incentives to keep quiet about their operations.¹⁹ In sum, complicity is a critical component of nonstate actors' strategic logic and they commonly announce sponsorship of cyberattacks as a result.\n# The Appeal of Credit-Claiming\nNonstate actors typically have coercive objectives. As Schelling wrote in 1973, \"[p]olitical violence, like political nonviolence, usually has as its purpose making somebody do something or not do something or stop doing something. The aim is to influence behavior.\"²⁰ In a broad sense, their goals are comparable to those of states seeking to alter the behavior of their adversaries.\nAbove, we argue that a key component of coercion is credibility: can actors issuing coercive threats make good on their promises of more pain if the target resists? This is especially difficult for nonstate actors (Hoffman and McCormick 2004; Kydd and Walter 2006; Dannenbaum 2011). They cannot put on military parades to show off their latest weaponry,²¹ do not have the means to finance modern military forces,²² and lack the resources—territorial, bureaucratic, and financial—of states. It is easy to dismiss the demands of nonstate actors as inconsequential chatter.\nGiven these deficits, the issue of how to boost credibility features centrally in the strategic logic of politically motivated nonstate actors. As with states, one way to demonstrate capabilities and resolve is to take action perceived as a costly signal. According to Kydd and Walter (2006), \"[b]ecause it is hard for weak actors to make credible threats, terrorists are forced to display publicly just how far they are willing to go to obtain their desired results\" (50). Similarly, Abrahms (2013) writes that \"[t]errorism . . . adds credibility to threats by showing that nonstate challengers possess the power to hurt\" (661).\nFor nonstate cyber warriors, sending costly signals to bolster credibility may include defacing government websites, launching distributed denial of service attacks,\n¹⁹ To the extent that they run the risk of capture, however, the credibility of their signals goes up.\n²⁰ Quoted in Sharp and Finkelstein (1973, xx).\n²¹ Doing so might expose their position and invite unwanted risk.\n²² One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n409\nand so forth. In other words, they are likely to take actions that prove their ability to cause pain or at least disrupt and inconvenience their targets. Although temporarily compromising access to a website will not pack the same symbolic punch as a terrorist attack, employing increasingly sophisticated cyber operations and exploiting consequential vulnerabilities helps nonstate groups elevate the costliness of their signals and more readily demonstrate credibility and resolve (Borghard and Lonergan 2017, 466–67).\nA history of successful attacks by a nonstate group can also help cultivate their prestige in much the same way it does for states. As such, nonstate actors stand to lose by not identifying their organization as responsible for an attack. Failing to communicate culpability negates an operation’s objectives and precludes nonstate actors from reaping signaling and reputational benefits that are critical to successful coercion. Without knowing who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities.²³ It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own (Bloom 2005, 78–79).²⁴\n## Maximizing Publicity\nThe notion that nonstate actors are more likely to claim attacks to showcase their capabilities and resolve mirrors a similar motivation among states interested in cyber coercion. Where the two diverge is in the preferred method of claiming. Several factors make nonstate actors more likely to choose public rather than private acknowledgment.\nOne reason nonstate cyber warriors crave the limelight hinges on the audiences they seek to influence. These\n²³ It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.\n²⁴ Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).\ngroups are often interested in sending a message not just to adversarial governments but to their populations as well. The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance (Schmid 2004). As Crenshaw (1981) notes in a related context, “[t]he victims or objects of terrorist attack have little intrinsic value to the terrorist group but represent a larger human audience whose reaction the terrorists seek” (379).\nUltimately, terrorists target the public since they are too weak to confront the state head-on. The same should be true of nonstate actors in cyberspace since these groups face comparable disadvantages. For such a strategy to work, however, communication cannot be private; it must be visible, clearly attributed, and widely known to the government and public alike.\nA second reason nonstate actors in cyberspace prefer public methods of claiming credit turns on their desire to attract new recruits. Like their traditional counterparts, these actors are interested in survival and growth. According to Pape (2005), “terrorism has two purposes—to gain supporters and to coerce opponents. Most terrorist campaigns seek both goals to some extent, often aiming to change the target state’s policies while simultaneously mobilizing support and recruits for the terrorists’ cause” (7). Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization (Abrahms 2008, 379) and augment their coercive ability. It is well established that the power of civil resistance flows from mobilization numbers, and the same goes for organizations in cyberspace. When it comes to their operating methods, these groups favor tactics that grow more powerful with additional bots and active supporters. The strength of DDoS operations, for instance, is linked to the number of machines involved (Ghosemajumder 2016).²⁵ The Low Orbit Internet Cannon (LOIC) and related variants draw strength from those who download the application and flood a server. With more members at their disposal, groups are able to launch increasingly formidable cyber operations.²⁶\n²⁵ On the determinants of DDoS attacks, see Asal et al. (2016).\n²⁶ It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.\nRethinking Secrecy in Cyberspace\n# Plausibility Probes\nA lack of readily-accessible decision-making documents complicates rigorous empirical tests of our argument. If we are right that state-sponsored cyber operations involving espionage and sabotage are prime candidates for secrecy before, during, and after execution, it might be decades or longer before relevant materials are declassified.27 While coercive cyber operations are more likely to involve credit-claiming, the advantages of claiming attacks privately also impede observation. In fact, outsiders might be unable to discern differences between victims who are truly ignorant of their attacker's identity and those that feign ignorance while privately communicating with their attackers.\nAs a second-best strategy, we examine publicly available sources including news reports and a range of secondary materials to provide a preliminary test of our argument. We also conduct two interviews: one with a former Defense Department official involved in cyber policy and one with a former member of Anonymous. These helped corroborate what we found in the public record.\n# States\nWe were unable to find a single case of a state claiming credit for a cyber espionage operation, either openly or privately. Rather, the cases that have inadvertently come to light underscore the vigor with which states seek to avoid being named. China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative (Nakashima 2015). In the aftermath of the intrusion, Chinese officials denied complicity, placing blame on criminal hackers. They even went so far as to claim that they had arrested individuals who were connected with the hack (Chalfant 2017).28 Another example is Russia's alleged interference in the 2016 US election. The \"theft of research and emails from the Democratic National Committee\" for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government (Sanger 2016).29\n27 This is especially true when it comes to documents pertaining to intelligence activities, which may stay classified for longer owing to concerns about sources and methods.\n28 See also Yan (2015). While it is technically possible that Chinese officials privately communicated complicity to the United States, this is unlikely since it serves no real strategic purpose.\n29 One might reasonably categorize this episode as political action wherein the Russians disseminated stolen\nWhen asked in March 2017 about whether Russia was behind the efforts to discredit Hillary Clinton, Putin responded with \"Read my lips: No\" (Lister, Ilyushka, and Gigova 2017). When it comes to cyber espionage, there is no benefit to be had from credit-claiming.\nStuxnet provides a useful illustration of why decision-makers sometimes cling to anonymity and, more interestingly, the conditions under which they might be willing to voluntarily claim credit.30 Stuxnet, formally known as \"Olympic Games,\" was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant (Farwell and Rohozinski 2011). The aim was to make the Iranians believe their centrifuges were failing for reasons other than foreign interference. Sanger (2012) writes the following: \"When the centrifuges first began crashing in 2008 at the Natanz enrichment center, the crown jewel of the Iranian nuclear program, the engineers inside the plant had no clue they were under attack. That was exactly what the designers of the world's most sophisticated cyberweapon had planned.\" He continues that \"[t]he idea, hatched in Washington and Jerusalem, was to make the first breakdowns seem like random accidents and small ones at that\" (188).\nSanger's interviews with government officials confirm that the operation was supposed to leave no trace of US fingerprints: \"The most elegant cyber weapons are a lot like the most elegant bank frauds. . . . They work best when the victim doesn't even know he's been robbed\" (190-91). It is clear from this account that the United States kept both the operation and their sponsorship intentionally hidden, as our argument predicts. The success or failure of the operation did not depend on Iran changing their behavior, but simply hinged on the quiet destruction of centrifuges.\nInterestingly, though, some US operatives contemplated quietly alerting the Iranians that the United States was responsible for the attack. Their apparent rationale conforms to our theoretical expectation. Ostensibly, the goal would have been to send a message to Tehran that the United States had the ability to keep targeting their systems, presumably as a way of achieving concessions on the nuclear program. According to Sanger (2012), \"[a]t both the Pentagon and inside the intelligence agencies some of the creators of the bug believed that it might be\ninformation to relevant entities who could use it to discredit Hillary Clinton. Even if so, this type of action would qualify as a classic covert operation, and thus we would still expect Russian denials.\n30 For a full-length treatment of the dynamics underlying the operation, see Lindsay (2013) and Rid (2012).\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n411\neven more valuable if the source of the attacks became known, because the Iranians would get the message that Washington could pierce its systems repeatedly.\" One official directly involved in decision-making noted, \"[w]e had to be ready to work in an environment where the Iranians knew exactly who was doing this to them, to make the point that we could come back and do it again\" (203). In short, some policymakers believed they could more easily alter the Iranian regime's behavior by embracing responsibility and proving that they could bring more pain to bear should they continue down the path of nuclearization.\nMore recent examples suggest that states are thinking hard about voluntarily claiming credit for their cyber operations in the service of coercion. In late September 2017, it came to light that the Trump administration authorized US Cyber Command to carry out a range of limited cyberattacks against North Korea's Reconnaissance General Bureau intended to interfere with Internet access (DeYoung, Nakashima, and Rauhala 2017). Most importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy. Panda (2017) argues that the United States had \"take[n] the cyber equivalent of a shot across North Korea's bow, presumably signaling that it has the requisite access to North Korean networks to deliver considerably more significant damage in wartime.\" Since North Korea is not wanting for enemies, it seemed to serve US objectives to let their complicity be known, thereby reducing ambiguity about what behavioral changes were expected from the Kim regime.\nFurther evidence for our theory comes from recent statements by Shawn Turskey, the executive director of US Cyber Command. His comments from 2016 indicate that the United States government is contemplating ways to leverage cyber capabilities for coercive purposes,\n31 One interesting avenue for future research is to explore how the desire to claim credit for certain operations, especially sabotage, may be driven in part by which agency is responsible for conducting the attack. We might expect, for example, the military to more readily embrace complicity and the intelligence community to do the opposite.\n32 The White House and Cyber Command declined to comment, but a senior administration official told the Washington Post that \"[w]hat I can tell you is that North Korea has itself been guilty of cyberattacks, and we are going to take appropriate measures to defend our networks and systems\" (DeYoung et al. 2017).\nspecifically through intentional credit-claiming. Turskey declared the following:\nIn the intelligence community you never want to be caught, you want [to] be low and slow, you never really want to be attributed. . . . But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know. (Bing 2016, emphasis added)\nThese remarks are noteworthy for several reasons. Chief among them is the prospect of the world's lone superpower developing an arsenal of cyber weapons with a return address. The fact that loud, attributable weapons are being discussed at all is at odds with the typical portrayal of cyberspace as a domain defined by secrecy and anonymity. Yet, it is easier to understand why Turskey is contemplating this shift once we come to terms with the mechanics of cyber coercion. Leveraging cyber assets for coercive purposes, rather than espionage or sabotage—which fits more readily within the purview of the military as opposed to the intelligence community—requires credible self-attribution. Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal (Lin 2016).\nMichael Sulmeyer, the former director for Plans and Operations for Cyber Policy in the Office of the Secretary of Defense, affirmed this sentiment in an interview for this article. Echoing the idea that cyber weapons can and should be embraced for more traditional purposes, he highlights the following:\nIt is important for the United States to invest in capabilities that not only help it improve its espionage activities against adversaries, but also that help it prevail in the event of hostilities with adversaries. When operating in the realm of the second objective, it can be beneficial for the United States to take responsibility for its actions publicly—not to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.\nTaking responsibility, as Sulmeyer suggests, provides America's adversaries the chance to understand the extent of their cyber power. Similar to Turskey, Sulmeyer anticipates that more voluntary credit-claiming may be on the horizon:\n33 For a discussion of these comments, see Lin (2016).\n34 Interview with authors, October 26, 2017.\nRethinking Secrecy in Cyberspace\nTo be sure, this signal could be missed or dismissed—and a mere tap on the digital shoulder clearly would not suffice for such a signal to be internalized. But why go through all the effort to hide every action every time in this context? That's an unnecessary additional burden in a war fight. If there are a suite of capabilities that can help our forces be more agile during hostilities, I would hope they are on the table for our commanders and leaders in the future.³⁵\n## Nonstate Actors\nThe empirical pattern of cyberattacks by nonstate actors differs from what we observed for states. These actors frequently claim credit for their cyberattacks in very public ways. Much like terrorist attacks, these operations almost always entail a political message intended to alter public opinion, change government policies, and the like. A cyberattack carried out by the Syrian Electronic Army against the US Army's website showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion (Vinton 2015). Quietly alerting the US Army that the Syrian Electronic Army was behind the attacks would have undermined the strategic motivations underlying the entire operation, namely bolstering their reputation as a group that deserves respect and sending a clear message with the intention of affecting public opinion and altering policy. The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list (Temperton 2016).\nFor a more complete picture of the decision-making process for nonstate actors in cyberspace, we briefly examine one of the most well-known organizations: Anonymous. Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article (Olson 2012; Coleman 2014). Anonymous’ behavior following this shift, though, sheds light on the group’s political strategy and how publicity and attention serve their goals.\nA cursory overview of Anonymous’ exploits over the years shows that the group commonly claims credit publicly for its operations. In late March 2016, Anonymous targeted roughly twenty Angolan government websites in response to the arrest of several activists. Prior to carrying out the attack, they posted details about the websites\nthey intended to target (British Broadcasting Company 2016). In one of their biggest and best-known campaigns, Operation Tunisia, the group first put out a press release via YouTube³⁶ before a launching series of DDoS attacks that took down numerous government-linked websites. This was part of a broader operation intended to assist protesters and weaken the government of Ben Ali. Most relevant for our purposes, the group issued a clear coercive threat: “This is a warning to the Tunisian government: attacks at the freedom of speech and information of its citizens will not be tolerated. . . . Free the net, and the attacks will cease, keep on that attitude and this will just be the beginning”³⁷ In another high-profile incident, Anonymous targeted the Church of Scientology. As before, the attack began with a YouTube press release³⁸ and proceeded with a series of DDoS attacks, doxing, and more press releases and media statements. In line with our expectations, the IT company hired by the Church of Scientology implored them to simply ignore the attacks: “Don’t issue warnings or threats to the attackers via the media; this will only keep the issue alive, raise tempers, and greatly increase the possibility of another assault. Most DDoS attackers seek publicity, so don’t hand it to them on a silver platter.”³⁹ Their solution was to deprive Anonymous of what it wanted most, namely attention.\nThis strategy of pursuing highly visible, self-attributed missions served at least three functions. First, Anonymous used these operations to ensure that they were taken seriously and that their coercive threats were not ignored. Establishing their capabilities, resolve, and credibility by conducting attacks with clear attribution contributed to this effort. This was explicit in their internal conversations during the operation against the Church of Scientology. As one member put it, “I think it’s time for [us] to do something big. People need to understand not to f*** with [Anonymous].”⁴⁰ These and other attacks proved somewhat successful. Outside observers came to understand that they should not dismiss the group’s threats. Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility” (Olson 2012, 177).\nSecond, Anonymous recognized that part of their strategy revolved around the public. During Operation Payback in 2010, which aimed to promote Internet privacy by targeting antipiracy groups, members of\n³⁵ See https://www.youtube.com/watch?v=BFLaBRk9wY0.\n³⁶ Quoted in Coleman (2014, 149).\n³⁷ See https://www.youtube.com/watch?v=JCbKv9yiLiQ.\n³⁸ Quoted in Olson (2012, 89).\n³⁹ Quoted in Olson (2012, 2).\nInterview with authors, October 26, 2017.\nMICHAEL POZNANSKY AND EVAN PERKOSKI\nAnonymous ardently debated this component of their strategy. Support eventually developed for one member who claimed that “... these attacks are less about hurting the business than drawing attention and forcing the media to cover the story. . . . The point for me is that this is the technological way of mass protesting that’s actually effective.”41 Getting their message out to the public to garner attention became a core objective.\nAnonymous’ operations often did more than just influence the public indirectly via messaging; sometimes the public was the direct target of attacks. Anonymous, like most terrorist groups, eventually had to reconcile with the fact that targeting innocent civilians might be useful for achieving their aims. This issue came to a head during Operation BART (Bay Area Rapid Transit), when members leaked information on individual passengers, including credit card numbers and other details from the company’s website. When asked about the incident by a reporter, a senior member replied, “[h]ow else do you get the world to respond and secure your information? How else do you get these companies and these big governments to keep your information, the information you give them voluntarily, safe? I think we got our message across, and I’ll bet you one thing: I’ll bet you they fix that.”42 Anonymous’ symbolic, essentially random targeting was part of a broader campaign to influence public opinion and achieve political change. Their cyberattacks were acts of coercion that bore a striking resemblance to the strategic logic of militant organizations.\nFinally, Anonymous’ cyber behavior was often geared toward generating new members and deepening support among their base. In an interview conducted for this article, we asked Hector Monsegur, a former leader of Anonymous known as Sabu, why the group was so eager to publicly claim their operations. As he put it,\nAt the time of its height (not so much now) Anonymous had gained huge successes in publicizing its protests, hacks, and engagements. They were masterful in the distribution of content, and the media truly ate it up for several reasons:\nIt was neatly packaged and ready for distribution, the hackers were willing to give interviews, and of course the mystery element. The whole thing about the mask and shadowy figures really “sells” the concept. As Anonymous grew in action, it also grew in numbers and support . . .\nThe truth of the matter is that Anonymous needed the media to grow, and this explains why many of the\nthings we did were really attention-grabbing. It served a purpose. It’s very similar to branding and how companies slip in their products into film, or events in general, even if each engagement or hack had different motivations.43\nIn her research on Anonymous, Coleman (2014) expands on this point: “[W]ithout the appearance of a critical mass, the operation would have likely lacked moral gravitas and authority. In this case, strength in numbers conveyed a potent message” (138). Expanding their membership didn’t just provide Anonymous legitimacy; it provided additional capability as well. While many of Anonymous’ DDoS campaigns relied on botnets to create their desired effect, individual users sustained those attacks that used the freeware LOIC, a staple of the group’s earlier activity. This required the group to invest time in assisting new members with the software. Olson (2012) points out that the group felt it was worth it to take the time “getting the [new members] on board to create an army” (65).\nUltimately, it was in Anonymous’ interest to take credit for their cyber operations through highly visible, public means of communication. Doing so rewarded their efforts significantly and was instrumental to their strategic logic. Whether the target was the Tunisian government or the Church of Scientology, the attention they received bolstered their particular brand of coercion. This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance (Coleman 2014, 107).\n## Cybercrime and Cyber Blackmail\nBefore concluding, it is worth flagging two types of cyber operations perpetrated by state and nonstate actors alike that are unlikely candidates for voluntary attribution. The first are operations involving theft of financial or intellectual assets. These are among the most common kind of cyberattack and are ill-served by credit-claiming. Malicious actors that leverage cyber assets for criminal purposes, such as stealing money from banking institutions, have little incentive to self-attribute. Doing so would provide little benefit and expose them to potential prosecution. While nonstate actors most commonly conduct these kinds of attacks, states may as well. For example, North Korea was identified as the responsible party in a cyber heist against Bangladesh’s central bank. Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million (Finkle 2017).\n41 Quoted in Coleman (2014, 132).\n42 Quoted in Coleman (2014, 307).\n43 Interview with authors, October 30, 2017.\nRethinking Secrecy in Cyberspace\nA second unlikely candidate for voluntary attribution is what we might call “cyber blackmail,” or operations in which the perpetrator leverages stolen assets, embarrassing secrets, and the like to achieve compliance from the victim without having to reveal their true identity.⁴⁴ These operations are particularly interesting in that success requires target compliance—which we argue should lead to credit-claiming—but the perpetrator can remain behind a mask. By selectively releasing compromised information and assets to the victim publicly or privately (Lindsay 2015, 57), the perpetrator may be able to force compliance while remaining anonymous or hiding behind front groups.\nThis dynamic approximates what might have happened during the Sony hack, in which the “Guardians of Peace” (#GOP) issued an explicit compellent threat against Sony in an attempt to prevent the company from releasing The Interview, a comedy satirizing North Korea’s leader Kim Jong Un. In the event that Sony failed to comply with #GOP’s demands, the group threatened to release propriety information and potentially embarrassing e-mail correspondences between high-level employees. Although North Korea was widely suspected of sponsoring the attack, the regime denied any involvement. Nonetheless, the attack partially succeeded in coercing Sony without the government having to explicitly take credit.⁴⁵ We believe that the attack was partially successful as a result of Sony’s understanding that certain assets (personal e-mails, financial records) had indeed been compromised and would be released should they fail to comply.\n## Conclusion\nThis article draws on existing theory to develop an explanation for why states and politically motivated non-state actors might voluntarily claim credit for their attacks. We argue that the goals of an operation as well as the characteristics of the perpetrator drive both the decision to claim credit as well as the manner in which culpability is communicated. This research has several important implications. First, we show how states and nonstate actors share a common set of choices with regards to secrecy in cyberspace. Both face the same decisions at the same points in the life cycle of a cyberattack, yet the characteristics of each can cause their strategies to diverge, particularly when it comes to the optics of credit-claiming. Future research should continue to investigate how the characteristics and operational and strategic goals of cyber actors influence the look and feel of their cyber actions.\nSecond, existing research often treats cyber operations as distinct from more traditional elements of state power. Although there are differences, the framework developed here suggests that states may be able to leverage cyber assets to achieve many of the same goals most frequently pursued with conventional forces. Scholars have pushed back against this idea for a variety of reasons, one being the attributional difficulties of cyber operations. But states need not conceal their complicity in perpetuity. By relaxing this assumption, we can more easily see how these operations fit into a state’s coercive toolkit. One area ripe for future research is the efficacy of coercion in cyberspace, both on its own and in comparison to more conventional methods.\nFinally, while inferring intentions from behavior is problematic, actors’ decisions to privately or publicly acknowledge sponsorship of an attack may provide crucial information about motives and identity. Clinging to covert forms of secrecy after the completion of an attack might highlight a set of plausible underlying motivations for the initial intrusion, including espionage, cybercrime, and the like. Conversely, if the actor does come clean, it might be appropriate to infer that credibility, prestige, or coercion was the true goal. In the information-starved domain that is cyberspace, these clues may be all there is when designing policies and crafting responses.\n## Acknowledgements\nThis is one of several collaborative projects by the authors, and the ordering of names follows a principle of rotation. We are grateful to Joseph Brown, Ben Buchanan, Ryan Evans, Robert Jervis, Joseph LaPalombara, Herb Lin, Jon Lindsay, Joseph Nye, Joshua Rovner, and Michael Sulmeyer for helpful comments, suggestions, and insights. An earlier version of the argument presented here appeared in War on the Rocks."
    },
    "author_year": {
      "total": {
        "intext_total": 63,
        "success_occurrences": 60,
        "success_unique": 45,
        "bib_unique_total": 94,
        "occurrence_match_rate": 0.9523809523809523,
        "bib_coverage_rate": 0.4787234042553192,
        "success_percentage": 95.24,
        "style": "author_year"
      },
      "results": [
        {
          "index": "gartzke|2015",
          "intext_citation": "(Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017)",
          "preceding_text": "Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence",
          "footnote": "Gartzke, Erik, and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" *Security Studies* 24(2): 316–48."
        },
        {
          "index": "gartzke|2013",
          "intext_citation": "(Gartzke 2013; Buchanan 2017)",
          "preceding_text": "ining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence (Gartzke and Lindsay 2015; Lindsay 2015; Borghard and Lonergan 2017; Nye 2017) to its influence on the dynamics of conflict and escalation",
          "footnote": "Gartzke, Erik. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.\" *International Security* 38 (2): 41–73."
        },
        {
          "index": "smith|2016",
          "intext_citation": "(Smith 2016)",
          "preceding_text": "To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions",
          "footnote": "Smith, Candace. 2016. \"Anonymous Claims to Hack Donald Trump.\" ABC News, March 17. https://abcnews.go.com/US/anonymous-claims-hack-donald-trump/story?id=37730049."
        },
        {
          "index": "vinton|2015",
          "intext_citation": "(Vinton 2015)",
          "preceding_text": "Connor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015",
          "footnote": "Vinton, Kate. 2015. \"Syrian Electronic Army Claims Responsibility For Hacking U.S. Army Website.\" Forbes, June 8. https://www.forbes.com/sites/katevinton/2015/06/08/syrian-electronic-army-claims-responsibility-for-hacking-army-website/."
        },
        {
          "index": "kibbe|2007",
          "intext_citation": "(Kibbe 2007)",
          "preceding_text": "Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations",
          "footnote": "Kibbe, Jennifer D. 2007. \"Covert Action and the Pentagon.\" *Intelligence and National Security* 22 (1): 57–74."
        },
        {
          "index": "axelrod|1979",
          "intext_citation": "(Axelrod 1979; Slantchev 2010)",
          "preceding_text": "The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise",
          "footnote": "Axelrod, Robert. 1979. \"The Rational Timing of Surprise.\" *World Politics* 31 (2): 228–46."
        },
        {
          "index": "forsythe|1992",
          "intext_citation": "(Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson 2016)",
          "preceding_text": "The latter involves the use of secrecy to conceal the sponsor of an operation",
          "footnote": "Forsythe, David P. 1992. \"Democracy, War, and Covert Action.\" *Journal of Peace Research* 29 (4): 385–95."
        },
        {
          "index": "buchanan|2017",
          "intext_citation": "(Buchanan 2017, 12)",
          "preceding_text": "At present, this is a nearly impossible task",
          "footnote": "Buchanan, Ben. 2017. *The Cybersecurity Dilemma: Hacking, Trust, and Fear Between Nations*. Oxford and New York: Oxford University Press."
        },
        {
          "index": "mahoney|2015",
          "intext_citation": "(Mahoney 2015, 201)",
          "preceding_text": "Our study is closer to an exercise in theory construction than theory testing",
          "footnote": "Mahoney, James. 2015. \"Process Tracing As Historical Explanation.\" Security Studies 24 (2): 200-18."
        },
        {
          "index": "baum|2004",
          "intext_citation": "(Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017)",
          "preceding_text": "In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining",
          "footnote": "Baum, Matthew. 2004. \"Going Private: Public Opinion, Presidential Rhetoric, and the Domestic Politics of Audience Costs in U.S. Foreign Policy Crises.\" *Journal of Conflict Resolution* 48 (5): 603–31."
        },
        {
          "index": "carson|2016",
          "intext_citation": "(Carson 2016)",
          "preceding_text": "cused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation",
          "footnote": "Carson, Austin. 2016. \"Facing Off and Saving Face: Covert Intervention and Escalation Management in the Korean War.\" *International Organization* 70 (1): 103–31."
        },
        {
          "index": "downes|2010",
          "intext_citation": "(Downes and Lilley 2010; Poznansky 2015)",
          "preceding_text": "vate diplomacy during crisis bargaining (Baum 2004; Yarhi-Milo 2013; Brown 2014; Carson and Yarhi-Milo 2017), the role that covert action plays in managing escalation (Carson 2016), and the relationship between democratic peace theory and covert regime change",
          "footnote": "Downes, Alexander B., and Mary L. Lilley. 2010. \"Overt Peace, Covert War?: Covert Intervention and the Democratic Peace.\" *Security Studies* 19 (2): 266–306."
        },
        {
          "index": "gartzke|2013",
          "intext_citation": "(Gartzke 2013; Gartzke and Lindsay 2015; Lindsay 2015; Rid and Buchanan 2015; Buchanan 2017; Nye 2017)",
          "preceding_text": "Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike",
          "footnote": "Gartzke, Erik. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.\" *International Security* 38 (2): 41–73."
        },
        {
          "index": "gartzke|2013",
          "intext_citation": "(Gartzke 2013; Buchanan 2017; Borghard and Lonergan 2017; Nye 2017)",
          "preceding_text": "Existing research tends to focus on the former",
          "footnote": "Gartzke, Erik. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.\" *International Security* 38 (2): 41–73."
        },
        {
          "index": "stoller|2017",
          "intext_citation": "(Stoller 2017)",
          "preceding_text": "Moreover, their attack capabilities are growing and in some cases they \"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\"",
          "footnote": "Stoller, Daniel R. 2017. \"Cybercriminals Taking the Reins from Nation-State Adversaries.\" *Bloomberg Law: Privacy and Data Security Blog* December 8. https://www.bna.com/cybercriminals-taking-reins-b73014472953/."
        },
        {
          "index": "slayton|2017",
          "intext_citation": "(Slayton 2017)",
          "preceding_text": "terature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant",
          "footnote": "Slayton, Rebecca. 2017. \"What Is the Cyber Offense-Defense Balance? Conceptions, Causes, and Assessment.\" International Security 41 (3): 72-109."
        },
        {
          "index": "rid|2015",
          "intext_citation": "(Rid and Buchanan 2015; Nye 2017, 49–52)",
          "preceding_text": "Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks",
          "footnote": "Rid, Thomas, and Ben Buchanan. 2015. \"Attributing Cyberattacks.\" Journal of Strategic Studies 38 (1-2): 4-37."
        },
        {
          "index": "lindsay|2015",
          "intext_citation": "(Lindsay 2015, 58)",
          "preceding_text": "omplete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity",
          "footnote": "Gartzke, Erik, and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" *Security Studies* 24(2): 316–48."
        },
        {
          "index": "valeriano|2014",
          "intext_citation": "(Valeriano and Maness 2014; 2015, 79; Nye 2017, 55-56)",
          "preceding_text": "The pervasiveness of secrecy in this domain also poses challenges for cyber coercion",
          "footnote": "Valeriano, Brandon, and Ryan C. Maness 2014. \"The Dynamics of Cyber Conflict Between Rival Antagonists, 2001-11.\" Journal of Peace Research 51 (3): 347-60."
        },
        {
          "index": "schelling|1966",
          "intext_citation": "(Schelling 1966)",
          "preceding_text": "Coercion requires victims to know who is making demands and what they are being asked to do",
          "footnote": "Schelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale University Press."
        },
        {
          "index": "borghard|2017",
          "intext_citation": "(Borghard and Lonergan 2017, 457-59; Libicki 2009, 50-51)",
          "preceding_text": "But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace",
          "footnote": "Borghard, Erica D., and Shawn W. Lonergan. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452–81."
        },
        {
          "index": "axelrod|1979",
          "intext_citation": "(Axelrod 1979; Slantchev 2010)",
          "preceding_text": "andestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise",
          "footnote": "Axelrod, Robert. 1979. \"The Rational Timing of Surprise.\" *World Politics* 31 (2): 228–46."
        },
        {
          "index": "gross|2009",
          "intext_citation": "(Gross 2009, 12)",
          "preceding_text": "rations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\"",
          "footnote": "Gross, Richard C. 2009. \"Different Worlds: Unacknowledged Special Operations and Covert Action.\" Technical report, Strategy Research Project, US Army War College."
        },
        {
          "index": "brown|2014",
          "intext_citation": "(Brown 2014; Carson 2016)",
          "preceding_text": "There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns",
          "footnote": "Brown, Jonathan N. 2014. \"The Sound of Silence: Power, Secrecy, and International Audiences in US Military Basing Negotiations.\" *Conflict Management and Peace Science* 31 (4): 406–31."
        },
        {
          "index": "forsythe|1992",
          "intext_citation": "(Forsythe 1992; Gibbs 1995; Downes and Lilley 2010; Poznansky 2015; Carson and Yarhi-Milo 2017; Joseph and Poznansky 2017)",
          "preceding_text": "ncealment of the operation\" (Gross 2009, 12). There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns (Brown 2014; Carson 2016) and avoiding hostile reactions from domestic and international observers",
          "footnote": "Forsythe, David P. 1992. \"Democracy, War, and Covert Action.\" *Journal of Peace Research* 29 (4): 385–95."
        },
        {
          "index": "betz|2011",
          "intext_citation": "(Betz and Stevens 2011, 95)",
          "preceding_text": "The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases",
          "footnote": "Betz, David J., and Tim Stevens. 2011. *Cyberspace and the State: Toward a Strategy for Cyber Power*. New York: Routledge."
        },
        {
          "index": "lindsay|2015",
          "intext_citation": "(Lindsay 2015, 55)",
          "preceding_text": "Announcing that \"[you] will attack this network with this effect unless [the target] refrain[s] from X\" would be \"self-defeating\"",
          "footnote": "Gartzke, Erik, and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" *Security Studies* 24(2): 316–48."
        },
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009, 50-51; Nye 2017, 51)",
          "preceding_text": "The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity",
          "footnote": "Libicki, Martin C. 2009. *Cyberdeterrence and Cyberwar*. Santa Monica, CA: RAND Corporation."
        },
        {
          "index": "borghard|2017",
          "intext_citation": "(Borghard and Lonergan 2017, 459)",
          "preceding_text": "Or they might communicate through discrete diplomatic channels with a foreign counterpart",
          "footnote": "Borghard, Erica D., and Shawn W. Lonergan. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452–81."
        },
        {
          "index": "betz|2011",
          "intext_citation": "(Betz and Stevens 2011, 88)",
          "preceding_text": "Actors can, and often do, opt to act both clandestinely and covertly in the course of a single operation",
          "footnote": "Betz, David J., and Tim Stevens. 2011. *Cyberspace and the State: Toward a Strategy for Cyber Power*. New York: Routledge."
        },
        {
          "index": "lindsay|2015",
          "intext_citation": "(Lindsay 2015, 58)",
          "preceding_text": "9 Getting caught is still a real possibility, especially for larger operations",
          "footnote": "Gartzke, Erik, and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" *Security Studies* 24(2): 316–48."
        },
        {
          "index": "schelling|1966",
          "intext_citation": "(Schelling 1966)",
          "preceding_text": "The calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful",
          "footnote": "Schelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale University Press."
        },
        {
          "index": "nye|2017",
          "intext_citation": "(Nye 2017, 47)",
          "preceding_text": "12 These qualify as computer network exploitation, or CNE",
          "footnote": null
        },
        {
          "index": "carson|2017",
          "intext_citation": "(Carson and Yarhi-Milo 2017)",
          "preceding_text": "The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim",
          "footnote": "Carson, Austin, and Keren Yarhi-Milo. 2017. \"Covert Communication: The Intelligibility and Credibility of Signaling in Secret.\" *Security Studies* 26 (1): 124–56."
        },
        {
          "index": "gilpin|1981",
          "intext_citation": "(Gilpin 1981, 31)",
          "preceding_text": "The former \"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\"",
          "footnote": "Gilpin, Robert. 1981. *War and Change in World Politics*. Princeton, NJ: Princeton University Press."
        },
        {
          "index": "szoldra|2016",
          "intext_citation": "(Szoldra 2016)",
          "preceding_text": "As one Symantec director noted, \"[i]t seems pretty reasonable to think that there are things out there today that we haven't seen that are much more advanced [than Stuxnet]\"",
          "footnote": "Szoldra, Paul. 2016. \"A New Film Gives a Frightening Look at How the US Used Cyberwarfare to Destroy Nukes.\" Business Insider, July 7. https://www.businessinsider.com/zero-days-stuxnet-cyber-weapon-2016-7."
        },
        {
          "index": "schelling|1966",
          "intext_citation": "(Schelling 1966, 3; emphasis in original)",
          "preceding_text": "It is \"the threat of . . . more damage,\" or the \"expectation of more violence,\" that may induce a target to give in",
          "footnote": "Schelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale University Press."
        },
        {
          "index": "maxey|2017",
          "intext_citation": "(Maxey 2017)",
          "preceding_text": "Concern about attacks against a state's critical infrastructure have been likened to a potential \"cyber 9/11\"",
          "footnote": "Maxey, Levi. 2017. \"Homeland Security Council Urges Action Before Cyber 9/11 Strikes.\" *Cipher Brief*, August 27. https://www.thecipherbrief.com/homeland-security-council-urges-action-cyber-911-strikes."
        },
        {
          "index": "carson|2017",
          "intext_citation": "(Carson and Yarhi-Milo 2017, 135)",
          "preceding_text": "many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige",
          "footnote": "Carson, Austin, and Keren Yarhi-Milo. 2017. \"Covert Communication: The Intelligibility and Credibility of Signaling in Secret.\" *Security Studies* 26 (1): 124–56."
        },
        {
          "index": "rid|2012",
          "intext_citation": "(Rid 2012, 28–29)",
          "preceding_text": "vate acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them",
          "footnote": "Rid, Thomas. 2012. \"Cyber War Will Not Take Place.\" Journal of Strategic Studies 35 (1): 5-32."
        },
        {
          "index": "yarhi-milo|2013",
          "intext_citation": "(Yarhi-Milo 2013, 407)",
          "preceding_text": "pursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases.¹⁶ This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity",
          "footnote": "Yarhi-Milo, Keren. 2013. \"Tying Hands Behind Closed Doors: The Logic and Practice of Secret Reassurance.\" Security Studies 22: 405-35."
        },
        {
          "index": "nye|2010",
          "intext_citation": "(Nye 2010; Asal et al. 2016)",
          "preceding_text": "Drawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means",
          "footnote": "Nye, Joseph S. 2010. Cyber Power. Cambridge, MA: Belfer Center for Science and International Affairs, Harvard Kennedy School."
        },
        {
          "index": "asal|2008",
          "intext_citation": "(Asal and Rethemeyer 2008; Chenoweth and Stephan 2011)",
          "preceding_text": "This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well",
          "footnote": "Asal, Victor, and R. Karl Rethemeyer. 2008. \"The Nature of the Beast: Organizational Structures and the Lethality of Terrorist Attacks.\" *Journal of Politics* 70 (2): 437–49."
        },
        {
          "index": "hoffman|2004",
          "intext_citation": "(Hoffman and McCormick 2004; Kydd and Walter 2006; Dannenbaum 2011)",
          "preceding_text": "This is especially difficult for nonstate actors",
          "footnote": "Hoffman, Bruce, and Gordon H. McCormick. 2004. \"Terrorism, Signaling, and Suicide Attack.\" *Studies in Conflict and Terrorism* 27 (4): 243–81."
        },
        {
          "index": "borghard|2017",
          "intext_citation": "(Borghard and Lonergan 2017, 466–67)",
          "preceding_text": "he same symbolic punch as a terrorist attack, employing increasingly sophisticated cyber operations and exploiting consequential vulnerabilities helps nonstate groups elevate the costliness of their signals and more readily demonstrate credibility and resolve",
          "footnote": "Borghard, Erica D., and Shawn W. Lonergan. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452–81."
        },
        {
          "index": "bloom|2005",
          "intext_citation": "(Bloom 2005, 78–79)",
          "preceding_text": "g who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities.²³ It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own",
          "footnote": "Bloom, Mia. 2005. *Dying to Kill: The Allure of Suicide Terror*. New York: Columbia University Press. https://www.fedscoop.com/us-cyber-command-offensive-cybersecurity-nsa-august-2016/."
        },
        {
          "index": "schmid|2004",
          "intext_citation": "(Schmid 2004)",
          "preceding_text": "The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance",
          "footnote": "Schmid, Alex P. 2004. \"Frameworks for Conceptualizing Terrorism.\" *Terrorism and Political Violence* 16 (2): 197-221."
        },
        {
          "index": "abrahms|2008",
          "intext_citation": "(Abrahms 2008, 379)",
          "preceding_text": "Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization",
          "footnote": "Abrahms, Max. 2008. “What Terrorists Really Want: Terrorist Motives and Counterterrorism Strategy.” *International Security* 32 (4): 78–105."
        },
        {
          "index": "ghosemajumder|2016",
          "intext_citation": "(Ghosemajumder 2016)",
          "preceding_text": "The strength of DDoS operations, for instance, is linked to the number of machines involved",
          "footnote": "Ghosemajumder, Shuman. 2016. \"Here's Why Massive Website Outages Will Continue Happening.\" *Recode*, October 24. https://www.recode.net/2016/10/24/13393922/ddos-attack-denial-service-cybercriminals-hackers."
        },
        {
          "index": "nakashima|2015",
          "intext_citation": "(Nakashima 2015)",
          "preceding_text": "China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative",
          "footnote": "Nakashima, Ellen. 2015. \"Hacks of OPM Databases Compromised 22.1 Million People, Federal Authorities Say.\" Washington Post, July 9. https://www.washingtonpost.com/news/federal-eye/wp/2015/07/09/hack-of-security-clearances-system-affected-21-5-million-people-federal-authorities-say/."
        },
        {
          "index": "chalfant|2017",
          "intext_citation": "(Chalfant 2017)",
          "preceding_text": "They even went so far as to claim that they had arrested individuals who were connected with the hack",
          "footnote": "Chalfant, Morgan. 2017. \"FBI Arrests Chinese National Linked to OPM Hack Malware.\" *The Hill*, August 24. http://thehill.com/policy/cybersecurity/347897-fbi-arrestschinese-national-linked-to-opm-hack-malware-report."
        },
        {
          "index": "sanger|2016",
          "intext_citation": "(Sanger 2016)",
          "preceding_text": "ion. The \"theft of research and emails from the Democratic National Committee\" for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government",
          "footnote": null
        },
        {
          "index": "farwell|2011",
          "intext_citation": "(Farwell and Rohozinski 2011)",
          "preceding_text": "ght be willing to voluntarily claim credit.30 Stuxnet, formally known as \"Olympic Games,\" was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant",
          "footnote": "Farwell, James P., and Rafal Rohozinski. 2011. \"Stuxnet and the Future of Cyber Warfare.\" *Survival: Global Politics and Strategy* 53 (1): 23–40."
        },
        {
          "index": "deyoung|2017",
          "intext_citation": "(DeYoung et al. 2017)",
          "preceding_text": "ommand declined to comment, but a senior administration official told the Washington Post that \"[w]hat I can tell you is that North Korea has itself been guilty of cyberattacks, and we are going to take appropriate measures to defend our networks and systems\"",
          "footnote": "DeYoung, Karen, Ellen Nakashima, and Emily Rauhala. 2017. \"Trump Signed Presidential Directive Ordering Actions to Pressure North Korea.\" *Washington Post*, September 30. https://www.washingtonpost.com/world/national-security/trump-signed-presidential-directive-ordering-actions-to-pressure-north-korea/2017/09/30/97c6722a-a620-11e7-b14f-f41773cd5a14_story.html."
        },
        {
          "index": "bing|2016",
          "intext_citation": "(Bing 2016, emphasis added)",
          "preceding_text": ". . . But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know.",
          "footnote": "Bing, Chris. 2016. \"U.S. Cyber Command Director: We Want 'Loud,' Offensive Cyber Tools.\" *FedScoop August* 30."
        },
        {
          "index": "lin|2016",
          "intext_citation": "(Lin 2016)",
          "preceding_text": "Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal",
          "footnote": null
        },
        {
          "index": "vinton|2015",
          "intext_citation": "(Vinton 2015)",
          "preceding_text": "ebsite showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion",
          "footnote": "Vinton, Kate. 2015. \"Syrian Electronic Army Claims Responsibility For Hacking U.S. Army Website.\" Forbes, June 8. https://www.forbes.com/sites/katevinton/2015/06/08/syrian-electronic-army-claims-responsibility-for-hacking-army-website/."
        },
        {
          "index": "temperton|2016",
          "intext_citation": "(Temperton 2016)",
          "preceding_text": "The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list",
          "footnote": "Temperton, James. 2016. \"FBI Adds Syrian Electronic Army Hackers to Most Wanted List.\" Wired, March 23. https://www.wired.co.uk/article/syrian-electronic-army-fbi-most-wanted."
        },
        {
          "index": "olson|2012",
          "intext_citation": "(Olson 2012; Coleman 2014)",
          "preceding_text": "Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article",
          "footnote": "Olson, Parmy. 2012. We Are Anonymous: Inside the Hacker World of LulzSec, Anonymous, and the Global Cyber Insurgency. New York: Back Bay Books."
        },
        {
          "index": "olson|2012",
          "intext_citation": "(Olson 2012, 177)",
          "preceding_text": "Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility”",
          "footnote": "Olson, Parmy. 2012. We Are Anonymous: Inside the Hacker World of LulzSec, Anonymous, and the Global Cyber Insurgency. New York: Back Bay Books."
        },
        {
          "index": "coleman|2014",
          "intext_citation": "(Coleman 2014, 107)",
          "preceding_text": "This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance",
          "footnote": "Coleman, Gabriella. 2014. *Hacker, Hoaxer, Whistleblower, Spy: The Many Faces of Anonymous*. London: Verso."
        },
        {
          "index": "finkle|2017",
          "intext_citation": "(Finkle 2017)",
          "preceding_text": "Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million",
          "footnote": "Finkle, Jim. 2017. \"Cyber Security Firm: More Evidence North Korea Linked to Bangladesh Heist.\" *Reuters*, April 3. https://www.reuters.com/article/us-cyber-heist-bangladesh-northkorea/cyber-security-firm-more-evidence-north-korea-linked-to-bangladesh-heist-idUSKBN1752I4."
        },
        {
          "index": "lindsay|2015",
          "intext_citation": "(Lindsay 2015, 57)",
          "preceding_text": "By selectively releasing compromised information and assets to the victim publicly or privately",
          "footnote": "Gartzke, Erik, and Jon R. Lindsay. 2015. \"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace.\" *Security Studies* 24(2): 316–48."
        }
      ],
      "flat_text": "Journal of Global Security Studies, 3(4), 2018, 402-416 doi: 10.1093/jogss/ogy022 Research Article OXFORD # Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution Michael Poznansky¹ and Evan Perkoski² ¹University of Pittsburgh and ²University of Connecticut ## Abstract Cyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain.\nKeywords: cyber warfare, secrecy, coercion, nonstate actors ## Introduction Secrecy is a defining feature of cyberspace. Cyber intruders can frequently disrupt networks, steal financial assets, and conduct espionage without ever revealing their identities. Recent scholarship goes a long way toward explaining the consequences of rampant secrecy and deception in cyberspace, from the way it affects competence and deterrence to its influence on the dynamics of conflict and escalation. Yet, while cyber intruders have ample opportunities to keep their sponsorship a secret, not all choose to take advantage. To the contrary, some willingly claim credit for their handiwork. For example, the group Anonymous frequently rebrands websites with personal logos after intrusions. They are not alone; SOBH Cyber Jihad, based in Iran, claimed credit for hacking into the control system of a dam in New York (Gosk, Winter, and Connor 2015), and the Syrian Electronic Army left behind a brazen message when they compromised the US Army's public website in June 2015.\nWhy do some actors claim responsibility for cyber operations while others opt for anonymity? To answer this question, we explore the logic of credit-claiming for two key sets of actors in cyberspace: states and politically motivated nonstate actors (hereafter, nonstate actors).¹ We argue that credit-claiming, including the manner in which culpability is communicated, depends on what the intruder wants to accomplish. For states, credit-claiming is most appealing during operations that require target compliance, otherwise known as cyber coercion. When states choose to make their identities known to coerce targets, they are more likely to do so privately since public credit-claiming raises the odds of escalation. Anonymity is most attractive during operations where ¹ We bracket nonstate actors without political motivations.\nPoznansky, Michael, and Evan Perkoski. (2018) Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution. Journal of Global Security Studies, doi: 10.1093/jogss/ogy022 © The Author(s) (2018). Published by Oxford University Press on behalf of the International Studies Association. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com MICHAEL POZNANSKY AND EVAN PERKOSKI This argument requires a conceptual shift in how we think about secrecy in cyberspace. Existing research typically treats secrecy as monolithic, but there are important distinctions worth bearing in mind. Perhaps most relevant is the difference between clandestine and covert operations. The former refers to missions where secrecy and deception are employed to preserve the strategic advantages afforded by surprise. The latter involves the use of secrecy to conceal the sponsor of an operation. Importing this distinction to the cyber domain helps clarify when secrecy is an operational imperative and when it is a choice that actors make. In brief, the advantages afforded to targets who learn of imminent or ongoing operations means that cyber intrusions will almost always be conducted clandestinely. Once an operation is complete, however, intruders are free to choose whether to claim responsibility. Put differently, cyber operations are almost always clandestine but not necessarily covert. The failure to recognize this distinction partly contributes to the widespread assumption that anonymity is an immutable feature of cyberspace rather than something actors select into.\nRigorously testing these claims would require access to the internal deliberations of state and nonstate actors to understand how decisions about credit-claiming are made. At present, this is a nearly impossible task. We are perhaps decades away from gaining access to the types of declassified documents necessary to evaluate the deliberations of states; the problem is even more acute for nonstate actors. As a second-best option, we leverage a range of sources—secondary materials, news reports, official government statements, and interviews—to assess the plausibility of our argument. Our study is closer to an exercise in theory construction than theory testing.\nThis article makes several contributions. First, it joins together a burgeoning literature centered on the dynamics of secrecy in world politics and another focused on cyber warfare. In the past, scholars have examined the importance of secrecy and private diplomacy during crisis bargaining, the role that covert action plays in managing escalation, and the relationship between democratic peace theory and covert regime change. These studies are tied together by an overarching focus on how actors use secrecy to pursue their political goals. Students of cyber warfare have done a commendable job analyzing the many challenges secrecy poses for perpetrator and victim alike but have largely neglected the determinants of secrecy at the stage where sponsors can (dis)claim ownership of an operation.² We address this issue directly.\nSecond, this study is among the first of which we are aware that considers the goals and constraints of the two most important actors operating in cyberspace—states and nonstate actors. Existing research tends to focus on the former. But nonstate actors conduct cyberattacks at high rates and often in very visible ways. Moreover, their attack capabilities are growing and in some cases they\"tak[e] tools and tricks from nation-states and unleash them on companies and organizations\". Ignoring nonstate actors or assuming that their strategic logic mirrors that of states is insufficient. Our approach is thus to ask the same questions for both sets of actors, reducing barriers that inhibit a more complete understanding of cyberattacks.\n## The Problem of Secrecy The conventional view of a cyber operation is an intruder quietly penetrating a target's network to collect information or cause damage, whether virtual or physical, without betraying their identity.³ This narrative—which assumes secrecy from start to finish—colors how the literature describes the challenges cyber operations pose. The relative ease with which perpetrators can surreptitiously penetrate networks and the difficulty of anticipating and defending against attacks underlies the notion that cyberspace is offense-dominant. Moreover, intruders' ability to mask their identities makes it hard for victims to confidently attribute responsibility for cyberattacks. According to Lindsay (2013), “[f]orensics takes months, whereas the anonymous attack can present\n\nRethinking Secrecy in Cyberspace\nitself and perhaps complete in milliseconds\" (377). Although attribution techniques are constantly advancing and may be easier for high-scale, high-value attacks, assigning responsibility remains challenging and often requires using nontechnical clues like motive and opportunity .\nThe pervasiveness of secrecy in this domain also poses challenges for cyber coercion . Coercion requires victims to know who is making demands and what they are being asked to do . Anonymity is antithetical to this enterprise. As Gartzke (2013) once put it, \"How does one surrender to no one in particular?\" (47). Some scholars point out that perpetrators can enhance the credibility of coercive threats by making their identities known, a point we develop more fully below. But it remains unclear where in the course of an attack such pronouncements must be made (i.e., before, during, or after) and how that fits with what we know about secrecy requirements in cyberspace .\nWhile all of these studies seem to address the same basic phenomenon—secrecy—there are meaningful differences when it comes to what is being concealed during an operation and for what purpose. The next section explores these differences.\n## Disaggregating Secrecy\nThe US military and intelligence communities distinguish between two types of secret operations. The first are clandestine operations, or actions that are \"sponsored or conducted by governmental departments or agencies in such a way as to assure secrecy or concealment.\"5 Actors operate clandestinely when they wish to gain tactical advantages from the element of surprise . As an example, consider Operation Neptune Spear, the US Special Forces' raid on Osama bin Laden's compound in Abbottabad, Pakistan. While the raid itself was shrouded in secrecy, President Obama's remarks to the nation afterward suggest that the purpose of secrecy was tactical, not political.\nThe second type of secret operation is covert action, defined as \"[a]n operation that is so planned and\nFigure 1. Clandestine and covert operations\nexecuted as to conceal the identity of or permit plausible denial by the sponsor.\"6 While covert operations, like clandestine operations, rely on deception, the rationale is different: \"A covert operation differs from a clandestine operation in that emphasis is placed on concealment of the identity of the sponsor rather than on concealment of the operation\" . There are numerous reasons why actors might want to hide their role in an operation, including escalation concerns  and avoiding hostile reactions from domestic and international observers . A classic covert operation is the Bay of Pigs. Training fifteen hundred exiles to storm the shores of Cuba to overthrow Fidel Castro was a highly visible act; the sponsor, the United States, was supposed to remain hidden.\nFigure 1 presents four different combinations of secret operations with illustrative examples.7 Cases in the northwest quadrant include cyber intrusions that are planned and executed clandestinely and denied by the sponsor. These are what observers typically have in mind when discussing the attribution problem in cyberspace. The examples in the southwest quadrant are planned and executed in secret but claimed by the sponsor afterward. The attribution problem fails to materialize in these cases . Examples in the northeast quadrant are covert because the sponsor denied complicity but are not clandestine since the activities themselves, typically performed by third parties, are not hidden. Examples in the southeast corner include large-scale wars.\n\nThis is taken from the Department of Defense's Dictionary of Military and Associated Terms, available at http://www.dtic.mil/doctrine/dod/dictionary/. Although this definition is focused on government entities, the same logic applies broadly.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nThese are neither covert (the sponsor was known) nor clandestine (the wars were announced in advance).\n## Secrecy in Cyberspace Students of cyber warfare rarely distinguish between clandestine and covert forms of secrecy. As such, most studies do not explicitly address where secrecy is a de facto requirement rather than a choice in the course of a cyberattack. Figure 2 portrays a stylized schematic of cyber intrusions, capturing two of the key inflection points where actors make decisions about secrecy.\nAt $\\mathrm{T_0}$, perpetrators decide whether to announce to the target that an attack is imminent or whether they will conceal the operational details as in a clandestine operation. In almost all cases, perpetrators will choose the latter. Doing otherwise is counterproductive since publicizing even the most basic details of a pending operation affords the target an opportunity to enact countermeasures. Announcing that\"[you] will attack this network with this effect unless [the target] refrain[s] from X\"would be\"self-defeating\". Acting clandestinely raises the likelihood of success by denying victims the chance to take steps that might blunt the efficacy of the attack such as patching a vulnerability or cutting access to servers. This is perhaps most salient for zero day exploits that leverage a vulnerability currently unknown to the victim.[8] Even when the perpetrator is not relying on zero days, they still will not want to announce the exact vector by which the intrusion will occur to avoid jeopardizing the operation.\nActors have the most agency when it comes to secrecy and deception after an attack occurs at time $\\mathrm{T}_{1}$. Here, perpetrators must decide whether to proceed in a manner consistent with covert action (denying their role) or not (claiming it). Should a perpetrator choose to forgo plausible deniability, they must then decide how to communicate complicity. The first option, private acknowledgment, refers to a scenario in which an actor quietly alerts the victim of their identity. Perpetrators can do this by leaving clues in the course of the attack—for example, leveraging a vector they have been known to use before, reusing code from a previous intrusion, or otherwise leaving signatures in the source code of malware. Or they might communicate through discrete diplomatic channels with a foreign counterpart.\nThe second means of communicating complicity, public acknowledgment, refers to a situation where the perpetrator openly pronounces their identity to a much wider audience following an attack. They might make a public statement or alert the media of their culpability. Explaining why some actors intentionally dispense with anonymity—and, for those that do, whether they will credit-claim publicly or privately—is the focus of the next two sections. For now, it will suffice to point out that the attribution problem ceases to exist in cases where the perpetrator willingly makes their identity known.\nActors can, and often do, opt to act both clandestinely and covertly in the course of a single operation. Our rationale for distinguishing between the two is to make clear that while clandestinity is a technical requirement of almost all cyber operations the decision to act covertly is something perpetrators consciously select into. In other words, it is a political decision. This process has been ill-theorized owing to the failure to recognize that there are two different types of secrecy in cyberspace.[9] In what follows, we use these distinctions to address our original puzzle regarding why some actors claim responsibility for operations while others choose to remain anonymous. The next section discusses the politics of credit-claiming for states. We then turn to nonstate actors, a neglected but important player in the cyberspace arena.\n\nRethinking Secrecy in Cyberspace # States and the Politics of Voluntary Attribution Whether states are able to achieve their objectives without target compliance helps explain the decision to deny or embrace sponsorship of a cyber intrusion.[10] If success is possible without the target consciously acceding to some demand, states will act covertly and hence anonymously. If the mission requires compliance of some kind, as is the case with coercion, states are more likely to make their identities known voluntarily; doing so may be critical to the success of the mission.[11] In terms of how they eventually reveal complicity, we argue that states are most likely to use private channels and discrete communication.\n# When States Come Clean When the success of state-sponsored cyber operations does not require target compliance, voluntary credit-claiming is unnecessary at best and counterproductive at worst. In these cases, we expect governments to preserve anonymity and avoid attribution if possible. Consider cyber espionage.[12] Like any intelligence gathering effort, voluntary attribution would be disadvantageous. Should a perpetrator announce that they have penetrated an adversary's network, they will jeopardize both their intrusion method and continued access without reaping any obvious benefit in return. Preserving anonymity is thus the preferred option for states interested in stealing secrets in cyberspace.\nAnother class of cyber operations, political action and sabotage, is also best served by perpetual anonymity. Examples include operations to influence elections through disinformation campaigns, vote manipulation, and the destruction of physical equipment and critical infrastructure. Because the success or failure of these operations does not depend on the target consciously responding to specified incentives, the motivations for states to voluntarily claim credit should be correspondingly low.\nThe calculus changes when a cyber operation involves coercion, which requires victim compliance to be successful. When operations require that the target accede to a set of demands—either to do something (change the status quo) or to refrain from doing something (preserve the status quo)—states are likely to shun anonymity and engage in voluntary attribution. The success of coercive threats boils down to whether and how the sender can showcase credibility and resolve to a witting victim. Remaining anonymous does little to advance these aims. As Liff (2012) notes, “[u]nder most circumstances, any would-be aggressor who does not identify itself forfeits the ability to coerce its adversary” (414). Anonymity makes it hard for targets to evaluate the credibility of a threat and the sender’s resolve. Credit-claiming is thus critical if cyber coercion is to have any chance of succeeding. Betz and Stevens (2011) hint at this: “[W]hen states use military cyber-power against other states for the purposes of compelling them to do their will, they still have to declare what it is (even after the event). There is no sneaky way around this fact” (95). It is worth reiterating, however, that this can only feasibly be done after the attack has ended. As discussed earlier, providing details beforehand could undermine the mission and render the coercive threat impotent.\nForgoing anonymity permits states to more effectively make coercive threats by demonstrating credibility and resolve in at least two ways. First, a claimed attack can function as a costly signal by showing the threatening party's willingness to expend valuable resources in the hopes of gaining compliance from the target. According to Borghard and Lonergan (2017),\"[t]he greater the cost to the initiating state of producing a given signal, ceteris paribus, the more effective the signal is as an indication of the initiating state's resolve\"(467).\nSecond, claiming credit for cyberattacks can build prestige, which we define as a reputation for cyber power.[13] Prestige and power, though related, are not the same. The latter refers strictly to capabilities, which can never be fully observed in cyberspace owing to the premium placed on keeping these tools shrouded in secrecy. The former\"refers primarily to the perceptions of other states with respect to a state's capacity and willingness to exercise its power\".[14] States who cultivate a reputation for cyber power may be able to\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nIt is worth briefly outlining how the dynamics of cyber prestige and coercion could operate in practice. When the goal is to compel a target to alter their behavior, perpetrators may take offensive action in cyberspace, claim credit for it, and threaten future punishment should the target fail to comply. When the goal is to deter some action, perpetrators may similarly be able to take offensive cyber action, claim credit for it, and threaten future punishment should the target act in ways deemed undesirable by the sender. A more plausible situation in the case of cyber deterrence might entail the victim of a recent attack retaliating against the perpetrator, voluntarily claiming credit, and threatening future harm should there be any further attacks against them. In each of these scenarios, cyber coercion is possible to the extent that the target believes the sender's promises of future pain are credible and that the threatener is resolved as a result of having claimed past attacks. It is\"the threat of... more damage,\"or the\"expectation of more violence,\"that may induce a target to give in.\nThere is obviously no guarantee that claiming credit for past attacks will generate the credibility necessary for coercion. If the target does not believe that the challenger has the ability or willingness to repeat similar or more painful attacks, issuing deterrent or compellent threats after claiming an intrusion with the promise of\"more where that came from\"won't work. Nevertheless, we are skeptical that observers never update their beliefs about an actor's capabilities and resolve, and opt instead to treat every attack as an isolated event. While Russia is unlikely to easily hack the Democratic National Committee again, for example, few observers doubt their capacity to carry out similar attacks in the future. Whether credible coercive threats will actually suffice to achieve concessions, while important in its own right, is a separate matter and depends on a complex cost-benefit calculation.\n## Escalation and the Means of Communication This section focuses on the right-hand side of Figure 2, after an actor chooses to forgo plausible deniability $(\\mathrm{T}_1)$ and decides whether to claim responsibility publicly or privately. We argue that the unique dynamics of politically motivated, state-on-state cyber activity make public acknowledgment less attractive than private acknowledgment. There are several reasons for this.\nAs a general matter, opportunities for retaliation are higher when the actors involved are states. Unlike non-state actors, states are stationary, immobile entities with numerous targets available to hit. Concern about attacks against a state's critical infrastructure have been likened to a potential\"cyber 9/11\".¹⁵ Moreover, perpetrators that publicly announce sponsorship of a cyberattack put the victim—in many cases, a fellow state—in an unenviable position. Even if officials within the target government prefer not to respond, they may face pressure from various domestic constituencies to retaliate in kind against challenges to their state's honor and prestige.\nBecause the victims of publicly claimed, state-sponsored cyberattacks typically have both the opportunity to retaliate as well as strong domestic-level pressures to do so, nation-states interested in cyber coercion face powerful incentives to quietly claim their actions using private channels. While credit-claiming in private lacks the broader prestige benefits associated with publicity and limits the audience observing an operation's (physical) costly signals, it may nonetheless afford states an opportunity to engage in coercive diplomacy at reduced risk. Recent scholarship shows that states often face powerful incentives to collude with one another in acts of secrecy. For example, Carson (2016) argues that states may opt not to publicize the covert military actions of their rivals even when they are targeted as a way of keeping conflicts limited and contained. A similar logic should apply to discrete attempts at coercion in cyberspace.\nOne risk of private acknowledgment is that the victim will\"out\"the perpetrator by publicly announcing the occurrence of an intrusion and offering proof that the attacker sought to privately attribute themselves. While this is always a possibility, such concerns may not wholly disincentivize states from pursuing private acknowledgment. First, admitting that networks have been compromised can be embarrassing for victims, creating incentives for the aggrieved to maintain the fiction that they have not been attacked or, short of that, to deny knowledge of who attacked them. This, in turn, can motivate perpetrators to quietly come clean with little fear of being exposed by the victim. Second, when victims have the capacity to out a state ¹⁵ For further discussion, see Betz and Stevens (2011, 91–94). Some states are obviously less vulnerable than others. For instance, North Korea relies on little shared infrastructure and presents few high-value cyber targets, making it possible for them to operate with a greater chance of impunity, at least on the cyber side (Sanger, Kirkpatrick, and Perlroth 2017).\nRethinking Secrecy in Cyberspace pursuing private diplomacy, the credibility of the sender's threats and the prospects for concessions actually increases.¹⁶ This dynamic depends on several conditions, in particular the costs of exposure outweighing the benefits of duplicity.\n# Nonstate Actors and the Politics of Voluntary Attribution The discussion so far has focused on the conditions under which states will claim credit for cyberattacks and why they are more likely to do so privately. This is important for obvious reasons.¹⁷ However, nonstate actors dominate the empirical record of credit-claiming in cyberspace. In what follows, we explain why nonstate actors commonly claim attacks and why they tend to do so publicly.\nDrawing on insights from the study of armed and unarmed resistance, we hold that nonstate actors in cyberspace share a host of similarities with other nonstate organizations that seek to affect political change through violent and nonviolent means. Regardless of their method of contention, nonstate actors are agents of change operating in a structural environment in which they are severely disadvantaged. These groups wield significantly fewer resources than states—financial, material, and otherwise—and their capabilities are consequently more constrained and more uncertain. In addition, what few capabilities nonstate actors do possess are in large part a function of the number of participants they can organize. This is especially true for nonviolent groups whose strength is most directly correlated with participation, though similar dynamics apply to violent resistance as well. The same basic logic extends to nonstate actors operating in cyberspace. One of the most common tools in a group's cyber arsenal, the distributed denial of service (DDoS) attack, grows stronger with every additional user.¹⁸ Our primary claim is that nonstate actors are more likely than states to brazenly claim cyberattacks. Not ¹⁶ See also Carson and Yarhi-Milo (2017, 135).\n¹⁷ On the importance of states for Internet politics, see Rovner and Moore (2017).\n¹⁸ To be sure, there are notable differences as well. We have yet to see cyber warriors espouse goals similar to their counterparts in more conventional domains (e.g., goals like secession and religious dominance). Cyber warriors also rarely risk their lives, though it would be wrong to say their activities are risk-free. Indeed, they might trade bodily injury for prison time.\nonly does this help showcase their capabilities, but the media attention can help attract new members to the cause. Additionally, since it is often difficult to bring these groups to justice, organizations like Anonymous, Lulzsec, and others face reduced incentives to keep quiet about their operations.¹⁹ In sum, complicity is a critical component of nonstate actors' strategic logic and they commonly announce sponsorship of cyberattacks as a result.\n# The Appeal of Credit-Claiming Nonstate actors typically have coercive objectives. As Schelling wrote in 1973,\"[p]olitical violence, like political nonviolence, usually has as its purpose making somebody do something or not do something or stop doing something. The aim is to influence behavior.\"²⁰ In a broad sense, their goals are comparable to those of states seeking to alter the behavior of their adversaries.\nAbove, we argue that a key component of coercion is credibility: can actors issuing coercive threats make good on their promises of more pain if the target resists? This is especially difficult for nonstate actors. They cannot put on military parades to show off their latest weaponry,²¹ do not have the means to finance modern military forces,²² and lack the resources—territorial, bureaucratic, and financial—of states. It is easy to dismiss the demands of nonstate actors as inconsequential chatter.\nGiven these deficits, the issue of how to boost credibility features centrally in the strategic logic of politically motivated nonstate actors. As with states, one way to demonstrate capabilities and resolve is to take action perceived as a costly signal. According to Kydd and Walter (2006),\"[b]ecause it is hard for weak actors to make credible threats, terrorists are forced to display publicly just how far they are willing to go to obtain their desired results\"(50). Similarly, Abrahms (2013) writes that\"[t]errorism... adds credibility to threats by showing that nonstate challengers possess the power to hurt\"(661).\nFor nonstate cyber warriors, sending costly signals to bolster credibility may include defacing government websites, launching distributed denial of service attacks, ¹⁹ To the extent that they run the risk of capture, however, the credibility of their signals goes up.\n²⁰ Quoted in Sharp and Finkelstein (1973, xx).\n²¹ Doing so might expose their position and invite unwanted risk.\n²² One of the only known nonstate armed groups with any semblance of an air force or navy is the LTTE in Sri Lanka, although even then it was primitive.\nMICHAEL POZNANSKY AND EVAN PERKOSKI A history of successful attacks by a nonstate group can also help cultivate their prestige in much the same way it does for states. As such, nonstate actors stand to lose by not identifying their organization as responsible for an attack. Failing to communicate culpability negates an operation’s objectives and precludes nonstate actors from reaping signaling and reputational benefits that are critical to successful coercion. Without knowing who to blame, states and their populations cannot update their beliefs about an organization’s intentions and capabilities.²³ It should therefore come as no surprise that nonstate actors often rush to claim attacks, even claiming some that are not their own.²⁴ ## Maximizing Publicity The notion that nonstate actors are more likely to claim attacks to showcase their capabilities and resolve mirrors a similar motivation among states interested in cyber coercion. Where the two diverge is in the preferred method of claiming. Several factors make nonstate actors more likely to choose public rather than private acknowledgment.\nOne reason nonstate cyber warriors crave the limelight hinges on the audiences they seek to influence. These ²³ It is worth noting, however, that these groups may still exploit clandestinity in the lead up to a violent attack. The 9/11 attacks, which were clandestine but not covert, illustrate this point.\n²⁴ Recent research suggests that, contrary to conventional wisdom, terrorists groups do sometimes face incentives to forgo credit-claiming. Abrahms and Conrad (2017) argue that this is particularly likely when lower-level operatives conduct indiscriminate attacks that might generate tension with local populations. Since local support is inconsequential to cyber operatives, who are by and large unconnected to civilian populations, we do not expect this dynamic to translate to cyberspace. Rather, we expect nonstate actors to not only claim their attacks, but to do so loudly and publicly as well (see next section).\ngroups are often interested in sending a message not just to adversarial governments but to their populations as well. The target of an attack may be symbolic, if not altogether random, while the physical (or digital) action aims to scare, intimidate, punish, and coerce a broader audience into compliance. As Crenshaw (1981) notes in a related context, “[t]he victims or objects of terrorist attack have little intrinsic value to the terrorist group but represent a larger human audience whose reaction the terrorists seek” (379).\nUltimately, terrorists target the public since they are too weak to confront the state head-on. The same should be true of nonstate actors in cyberspace since these groups face comparable disadvantages. For such a strategy to work, however, communication cannot be private; it must be visible, clearly attributed, and widely known to the government and public alike.\nA second reason nonstate actors in cyberspace prefer public methods of claiming credit turns on their desire to attract new recruits. Like their traditional counterparts, these actors are interested in survival and growth. According to Pape (2005), “terrorism has two purposes—to gain supporters and to coerce opponents. Most terrorist campaigns seek both goals to some extent, often aiming to change the target state’s policies while simultaneously mobilizing support and recruits for the terrorists’ cause” (7). Nonstate actors in cyberspace also aim to attract new members as a way to propagate their organization and augment their coercive ability. It is well established that the power of civil resistance flows from mobilization numbers, and the same goes for organizations in cyberspace. When it comes to their operating methods, these groups favor tactics that grow more powerful with additional bots and active supporters. The strength of DDoS operations, for instance, is linked to the number of machines involved.²⁵ The Low Orbit Internet Cannon (LOIC) and related variants draw strength from those who download the application and flood a server. With more members at their disposal, groups are able to launch increasingly formidable cyber operations.²⁶ ²⁵ On the determinants of DDoS attacks, see Asal et al. (2016).\n²⁶ It is true that many intrusion methods are largely unconnected to participation. Stuxnet comes to mind as an operation where a small team of sophisticated operatives was critical, rather than a large network of supporters. So far, however, politically motivated nonstate actors have tended to embrace less sophisticated operations.\nRethinking Secrecy in Cyberspace # Plausibility Probes A lack of readily-accessible decision-making documents complicates rigorous empirical tests of our argument. If we are right that state-sponsored cyber operations involving espionage and sabotage are prime candidates for secrecy before, during, and after execution, it might be decades or longer before relevant materials are declassified.27 While coercive cyber operations are more likely to involve credit-claiming, the advantages of claiming attacks privately also impede observation. In fact, outsiders might be unable to discern differences between victims who are truly ignorant of their attacker's identity and those that feign ignorance while privately communicating with their attackers.\nAs a second-best strategy, we examine publicly available sources including news reports and a range of secondary materials to provide a preliminary test of our argument. We also conduct two interviews: one with a former Defense Department official involved in cyber policy and one with a former member of Anonymous. These helped corroborate what we found in the public record.\n# States We were unable to find a single case of a state claiming credit for a cyber espionage operation, either openly or privately. Rather, the cases that have inadvertently come to light underscore the vigor with which states seek to avoid being named. China's hack into the Office of Personnel and Management's database wherein the records of millions of federal US employees were stolen is illustrative. In the aftermath of the intrusion, Chinese officials denied complicity, placing blame on criminal hackers. They even went so far as to claim that they had arrested individuals who were connected with the hack.28 Another example is Russia's alleged interference in the 2016 US election. The\"theft of research and emails from the Democratic National Committee\"for the purposes of embarrassing the Democratic Party and Hillary Clinton—the heart of Russia's disinformation campaign—was, like China's OPM hack, denied by the Russian government.29 When asked in March 2017 about whether Russia was behind the efforts to discredit Hillary Clinton, Putin responded with\"Read my lips: No\"(Lister, Ilyushka, and Gigova 2017). When it comes to cyber espionage, there is no benefit to be had from credit-claiming.\nStuxnet provides a useful illustration of why decision-makers sometimes cling to anonymity and, more interestingly, the conditions under which they might be willing to voluntarily claim credit.30 Stuxnet, formally known as\"Olympic Games,\"was an operation allegedly carried out by the United States and Israel to disrupt and degrade Iran's nuclear program by destroying centrifuges at Natanz enrichment plant. The aim was to make the Iranians believe their centrifuges were failing for reasons other than foreign interference. Sanger (2012) writes the following:\"When the centrifuges first began crashing in 2008 at the Natanz enrichment center, the crown jewel of the Iranian nuclear program, the engineers inside the plant had no clue they were under attack. That was exactly what the designers of the world's most sophisticated cyberweapon had planned.\"He continues that\"[t]he idea, hatched in Washington and Jerusalem, was to make the first breakdowns seem like random accidents and small ones at that\"(188).\nSanger's interviews with government officials confirm that the operation was supposed to leave no trace of US fingerprints:\"The most elegant cyber weapons are a lot like the most elegant bank frauds.... They work best when the victim doesn't even know he's been robbed\"(190-91). It is clear from this account that the United States kept both the operation and their sponsorship intentionally hidden, as our argument predicts. The success or failure of the operation did not depend on Iran changing their behavior, but simply hinged on the quiet destruction of centrifuges.\nInterestingly, though, some US operatives contemplated quietly alerting the Iranians that the United States was responsible for the attack. Their apparent rationale conforms to our theoretical expectation. Ostensibly, the goal would have been to send a message to Tehran that the United States had the ability to keep targeting their systems, presumably as a way of achieving concessions on the nuclear program. According to Sanger (2012),\"[a]t both the Pentagon and inside the intelligence agencies some of the creators of the bug believed that it might be information to relevant entities who could use it to discredit Hillary Clinton. Even if so, this type of action would qualify as a classic covert operation, and thus we would still expect Russian denials.\n\nMICHAEL POZNANSKY AND EVAN PERKOSKI\n\nMore recent examples suggest that states are thinking hard about voluntarily claiming credit for their cyber operations in the service of coercion. In late September 2017, it came to light that the Trump administration authorized US Cyber Command to carry out a range of limited cyberattacks against North Korea's Reconnaissance General Bureau intended to interfere with Internet access (DeYoung, Nakashima, and Rauhala 2017). Most importantly, the cyber operation involved alerting the North Koreans that the United States was behind the attacks to convey a more muscular US posture and perhaps to persuade Kim Jong Un to moderate his foreign policy.[32] Panda (2017) argues that the United States had\"take[n] the cyber equivalent of a shot across North Korea's bow, presumably signaling that it has the requisite access to North Korean networks to deliver considerably more significant damage in wartime.\"Since North Korea is not wanting for enemies, it seemed to serve US objectives to let their complicity be known, thereby reducing ambiguity about what behavioral changes were expected from the Kim regime.\nFurther evidence for our theory comes from recent statements by Shawn Turskey, the executive director of US Cyber Command. His comments from 2016 indicate that the United States government is contemplating ways to leverage cyber capabilities for coercive purposes, specifically through intentional credit-claiming. Turskey declared the following: In the intelligence community you never want to be caught, you want [to] be low and slow, you never really want to be attributed.... But there's another space over here, where maybe you definitely want to be louder, where attribution is important to you and you actually want the adversary to know. These remarks are noteworthy for several reasons.[33] Chief among them is the prospect of the world's lone superpower developing an arsenal of cyber weapons with a return address. The fact that loud, attributable weapons are being discussed at all is at odds with the typical portrayal of cyberspace as a domain defined by secrecy and anonymity. Yet, it is easier to understand why Turskey is contemplating this shift once we come to terms with the mechanics of cyber coercion. Leveraging cyber assets for coercive purposes, rather than espionage or sabotage—which fits more readily within the purview of the military as opposed to the intelligence community—requires credible self-attribution. Developing tools that erase doubt about who conducted a particular intrusion contributes to this goal.\nMichael Sulmeyer, the former director for Plans and Operations for Cyber Policy in the Office of the Secretary of Defense, affirmed this sentiment in an interview for this article. Echoing the idea that cyber weapons can and should be embraced for more traditional purposes, he highlights the following: It is important for the United States to invest in capabilities that not only help it improve its espionage activities against adversaries, but also that help it prevail in the event of hostilities with adversaries. When operating in the realm of the second objective, it can be beneficial for the United States to take responsibility for its actions publicly—not to advance tactical, technical objectives but to intimidate and signal that the actions being experienced are being delivered courtesy of the USA, and that the adversary should expect more to follow unless it complies.[34] Taking responsibility, as Sulmeyer suggests, provides America's adversaries the chance to understand the extent of their cyber power. Similar to Turskey, Sulmeyer anticipates that more voluntary credit-claiming may be on the horizon: Rethinking Secrecy in Cyberspace To be sure, this signal could be missed or dismissed—and a mere tap on the digital shoulder clearly would not suffice for such a signal to be internalized. But why go through all the effort to hide every action every time in this context? That's an unnecessary additional burden in a war fight. If there are a suite of capabilities that can help our forces be more agile during hostilities, I would hope they are on the table for our commanders and leaders in the future.³⁵ ## Nonstate Actors The empirical pattern of cyberattacks by nonstate actors differs from what we observed for states. These actors frequently claim credit for their cyberattacks in very public ways. Much like terrorist attacks, these operations almost always entail a political message intended to alter public opinion, change government policies, and the like. A cyberattack carried out by the Syrian Electronic Army against the US Army's website showcases these dynamics. After posting a political message on the website stating “Your commanders admit they are training the people they have sent you to die fighting,” the hackers posted messages on Twitter claiming responsibility for the intrusion. Quietly alerting the US Army that the Syrian Electronic Army was behind the attacks would have undermined the strategic motivations underlying the entire operation, namely bolstering their reputation as a group that deserves respect and sending a clear message with the intention of affecting public opinion and altering policy. The attack was not cost-free either; several hackers from the Syrian Electronic Army were identified and eventually placed on the FBI’s most-wanted list.\nFor a more complete picture of the decision-making process for nonstate actors in cyberspace, we briefly examine one of the most well-known organizations: Anonymous. Its evolution from an organization that conducted cyber operations simply for the “lulz” to one that engaged in political activism is beyond the scope of this article. Anonymous’ behavior following this shift, though, sheds light on the group’s political strategy and how publicity and attention serve their goals.\nA cursory overview of Anonymous’ exploits over the years shows that the group commonly claims credit publicly for its operations. In late March 2016, Anonymous targeted roughly twenty Angolan government websites in response to the arrest of several activists. Prior to carrying out the attack, they posted details about the websites they intended to target (British Broadcasting Company 2016). In one of their biggest and best-known campaigns, Operation Tunisia, the group first put out a press release via YouTube³⁶ before a launching series of DDoS attacks that took down numerous government-linked websites. This was part of a broader operation intended to assist protesters and weaken the government of Ben Ali. Most relevant for our purposes, the group issued a clear coercive threat: “This is a warning to the Tunisian government: attacks at the freedom of speech and information of its citizens will not be tolerated.... Free the net, and the attacks will cease, keep on that attitude and this will just be the beginning”³⁷ In another high-profile incident, Anonymous targeted the Church of Scientology. As before, the attack began with a YouTube press release³⁸ and proceeded with a series of DDoS attacks, doxing, and more press releases and media statements. In line with our expectations, the IT company hired by the Church of Scientology implored them to simply ignore the attacks: “Don’t issue warnings or threats to the attackers via the media; this will only keep the issue alive, raise tempers, and greatly increase the possibility of another assault. Most DDoS attackers seek publicity, so don’t hand it to them on a silver platter.”³⁹ Their solution was to deprive Anonymous of what it wanted most, namely attention.\nThis strategy of pursuing highly visible, self-attributed missions served at least three functions. First, Anonymous used these operations to ensure that they were taken seriously and that their coercive threats were not ignored. Establishing their capabilities, resolve, and credibility by conducting attacks with clear attribution contributed to this effort. This was explicit in their internal conversations during the operation against the Church of Scientology. As one member put it, “I think it’s time for [us] to do something big. People need to understand not to f*** with [Anonymous].”⁴⁰ These and other attacks proved somewhat successful. Outside observers came to understand that they should not dismiss the group’s threats. Eventually, “[t]he attack on HBGary had excited news reporters so much that any hint of an Anonymous threat suddenly had a veneer of credibility”.\nSecond, Anonymous recognized that part of their strategy revolved around the public. During Operation Payback in 2010, which aimed to promote Internet privacy by targeting antipiracy groups, members of ³⁵ See https://www.youtube.com/watch?v=BFLaBRk9wY0.\n³⁶ Quoted in Coleman (2014, 149).\n³⁷ See https://www.youtube.com/watch?v=JCbKv9yiLiQ.\n³⁸ Quoted in Olson (2012, 89).\n³⁹ Quoted in Olson (2012, 2).\nInterview with authors, October 26, 2017.\nMICHAEL POZNANSKY AND EVAN PERKOSKI Anonymous ardently debated this component of their strategy. Support eventually developed for one member who claimed that “... these attacks are less about hurting the business than drawing attention and forcing the media to cover the story.... The point for me is that this is the technological way of mass protesting that’s actually effective.”41 Getting their message out to the public to garner attention became a core objective.\nAnonymous’ operations often did more than just influence the public indirectly via messaging; sometimes the public was the direct target of attacks. Anonymous, like most terrorist groups, eventually had to reconcile with the fact that targeting innocent civilians might be useful for achieving their aims. This issue came to a head during Operation BART (Bay Area Rapid Transit), when members leaked information on individual passengers, including credit card numbers and other details from the company’s website. When asked about the incident by a reporter, a senior member replied, “[h]ow else do you get the world to respond and secure your information? How else do you get these companies and these big governments to keep your information, the information you give them voluntarily, safe? I think we got our message across, and I’ll bet you one thing: I’ll bet you they fix that.”42 Anonymous’ symbolic, essentially random targeting was part of a broader campaign to influence public opinion and achieve political change. Their cyberattacks were acts of coercion that bore a striking resemblance to the strategic logic of militant organizations.\nFinally, Anonymous’ cyber behavior was often geared toward generating new members and deepening support among their base. In an interview conducted for this article, we asked Hector Monsegur, a former leader of Anonymous known as Sabu, why the group was so eager to publicly claim their operations. As he put it, At the time of its height (not so much now) Anonymous had gained huge successes in publicizing its protests, hacks, and engagements. They were masterful in the distribution of content, and the media truly ate it up for several reasons: It was neatly packaged and ready for distribution, the hackers were willing to give interviews, and of course the mystery element. The whole thing about the mask and shadowy figures really “sells” the concept. As Anonymous grew in action, it also grew in numbers and support...\nThe truth of the matter is that Anonymous needed the media to grow, and this explains why many of the things we did were really attention-grabbing. It served a purpose. It’s very similar to branding and how companies slip in their products into film, or events in general, even if each engagement or hack had different motivations.43 In her research on Anonymous, Coleman (2014) expands on this point: “[W]ithout the appearance of a critical mass, the operation would have likely lacked moral gravitas and authority. In this case, strength in numbers conveyed a potent message” (138). Expanding their membership didn’t just provide Anonymous legitimacy; it provided additional capability as well. While many of Anonymous’ DDoS campaigns relied on botnets to create their desired effect, individual users sustained those attacks that used the freeware LOIC, a staple of the group’s earlier activity. This required the group to invest time in assisting new members with the software. Olson (2012) points out that the group felt it was worth it to take the time “getting the [new members] on board to create an army” (65).\nUltimately, it was in Anonymous’ interest to take credit for their cyber operations through highly visible, public means of communication. Doing so rewarded their efforts significantly and was instrumental to their strategic logic. Whether the target was the Tunisian government or the Church of Scientology, the attention they received bolstered their particular brand of coercion. This strategy resembles the brands of coercion of online actors using “weapons of the geek” and of groups using violent and nonviolent tactics of resistance.\n## Cybercrime and Cyber Blackmail Before concluding, it is worth flagging two types of cyber operations perpetrated by state and nonstate actors alike that are unlikely candidates for voluntary attribution. The first are operations involving theft of financial or intellectual assets. These are among the most common kind of cyberattack and are ill-served by credit-claiming. Malicious actors that leverage cyber assets for criminal purposes, such as stealing money from banking institutions, have little incentive to self-attribute. Doing so would provide little benefit and expose them to potential prosecution. While nonstate actors most commonly conduct these kinds of attacks, states may as well. For example, North Korea was identified as the responsible party in a cyber heist against Bangladesh’s central bank. Unsurprisingly, Pyongyang has denied any involvement in the theft of roughly US$81 million.\n\nRethinking Secrecy in Cyberspace A second unlikely candidate for voluntary attribution is what we might call “cyber blackmail,” or operations in which the perpetrator leverages stolen assets, embarrassing secrets, and the like to achieve compliance from the victim without having to reveal their true identity.⁴⁴ These operations are particularly interesting in that success requires target compliance—which we argue should lead to credit-claiming—but the perpetrator can remain behind a mask. By selectively releasing compromised information and assets to the victim publicly or privately, the perpetrator may be able to force compliance while remaining anonymous or hiding behind front groups.\nThis dynamic approximates what might have happened during the Sony hack, in which the “Guardians of Peace” (#GOP) issued an explicit compellent threat against Sony in an attempt to prevent the company from releasing The Interview, a comedy satirizing North Korea’s leader Kim Jong Un. In the event that Sony failed to comply with #GOP’s demands, the group threatened to release propriety information and potentially embarrassing e-mail correspondences between high-level employees. Although North Korea was widely suspected of sponsoring the attack, the regime denied any involvement. Nonetheless, the attack partially succeeded in coercing Sony without the government having to explicitly take credit.⁴⁵ We believe that the attack was partially successful as a result of Sony’s understanding that certain assets (personal e-mails, financial records) had indeed been compromised and would be released should they fail to comply.\n## Conclusion This article draws on existing theory to develop an explanation for why states and politically motivated non-state actors might voluntarily claim credit for their attacks. We argue that the goals of an operation as well as the characteristics of the perpetrator drive both the decision to claim credit as well as the manner in which culpability is communicated. This research has several important implications. First, we show how states and nonstate actors share a common set of choices with regards to secrecy in cyberspace. Both face the same decisions at the same points in the life cycle of a cyberattack, yet the characteristics of each can cause their strategies to diverge, particularly when it comes to the optics of credit-claiming. Future research should continue to investigate how the characteristics and operational and strategic goals of cyber actors influence the look and feel of their cyber actions.\nSecond, existing research often treats cyber operations as distinct from more traditional elements of state power. Although there are differences, the framework developed here suggests that states may be able to leverage cyber assets to achieve many of the same goals most frequently pursued with conventional forces. Scholars have pushed back against this idea for a variety of reasons, one being the attributional difficulties of cyber operations. But states need not conceal their complicity in perpetuity. By relaxing this assumption, we can more easily see how these operations fit into a state’s coercive toolkit. One area ripe for future research is the efficacy of coercion in cyberspace, both on its own and in comparison to more conventional methods.\nFinally, while inferring intentions from behavior is problematic, actors’ decisions to privately or publicly acknowledge sponsorship of an attack may provide crucial information about motives and identity. Clinging to covert forms of secrecy after the completion of an attack might highlight a set of plausible underlying motivations for the initial intrusion, including espionage, cybercrime, and the like. Conversely, if the actor does come clean, it might be appropriate to infer that credibility, prestige, or coercion was the true goal. In the information-starved domain that is cyberspace, these clues may be all there is when designing policies and crafting responses.\n## Acknowledgements This is one of several collaborative projects by the authors, and the ordering of names follows a principle of rotation. We are grateful to Joseph Brown, Ben Buchanan, Ryan Evans, Robert Jervis, Joseph LaPalombara, Herb Lin, Jon Lindsay, Joseph Nye, Joshua Rovner, and Michael Sulmeyer for helpful comments, suggestions, and insights. An earlier version of the argument presented here appeared in War on the Rocks."
    }
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 42.0,
      "success_occurrences": 42.0,
      "success_unique": 20.0,
      "bib_unique_total": 46.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.43478260869565216,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 42.0,
        "success_occurrences": 42.0,
        "success_unique": 20.0,
        "bib_unique_total": 46.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.43478260869565216,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 11.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 63.0,
        "success_occurrences": 60.0,
        "success_unique": 45.0,
        "bib_unique_total": 94.0,
        "occurrence_match_rate": 0.9523809523809523,
        "bib_coverage_rate": 0.4787234042553192,
        "success_percentage": 95.24,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "Rethinking Secrecy in Cyberspace: The Politics of Voluntary Attribution",
    "subtitle": "¹University of Pittsburgh and ²University of Connecticut",
    "document_type": "journal_article",
    "venue": "Journal of Global Security Studies, 3(4), 2018, 402-416",
    "publication_year": 2018,
    "authors": [
      "Michael Poznansky",
      "Evan Perkoski"
    ],
    "affiliations": [
      "¹University of Pittsburgh and ²University of Connecticut"
    ],
    "emails": [
      "journals.permissions@oup.com"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "Cyberspace affords actors unprecedented opportunities to carry out operations under a cloak of anonymity. Why do perpetrators sometimes forgo these opportunities and willingly claim credit for attacks? To date, the literature has done little to explain this variation. This article explores the motivations behind voluntary credit-claiming for the two main actors in cyberspace: states and politically motivated nonstate actors. We argue that states are most likely to claim credit for their operations and to do so privately when the goal is to coerce an opponent. Nonstate actors tend to publicly claim credit for their attacks in order to showcase their capabilities, influence public opinion, and grow their ranks. We use case narratives to assess the plausibility of our argument and find strong support. This article places cyberspace operations in conversation with the larger literature on secrecy in international relations and advances a common framework for understanding how both states and nonstate actors operate in this evolving domain. Keywords: cyber warfare, secrecy, coercion, nonstate actors",
    "keywords": [
      "cyber warfare",
      "secrecy",
      "coercion",
      "nonstate actors"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1093/jogss/ogy022"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "http://www.dtic.mil/doctrine/dod/dictionary"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 67,
    "heading_count": 19,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 42,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.42857142857142855,
      "footnote_coverage": 1.0,
      "unique_index_count": 20
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 45,
        "superscript_definition_lines": 18,
        "numeric_bracket_hits": 11,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 46.0,
      "dominant_bib_coverage_rate": 0.43478260869565216,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 19,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": true,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 2,
        "affiliations": 1,
        "emails": 1,
        "orcids": 0,
        "keywords": 4,
        "doi": 1,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 1
      },
      "coverage": {
        "core_coverage": 1.0,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "missing_preceding_text",
      "low_bib_coverage",
      "meta_low_email_author_link_rate"
    ]
  },
  "updated_at_utc": "2026-02-14T08:28:27.131010+00:00"
}