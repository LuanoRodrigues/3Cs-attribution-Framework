{
  "full_text": "Foreign Policy Analysis (2022), orac003\n# RESEARCH NOTE\n# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months (Rid and Buchanan 2015). The attribution problem complicates both compellence and deterrence (Borghard and Lonergan 2017). Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution (Lynn 2010; Clark and Landau 2011; Harknett and Nye Jr 2017).\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government (Schulzke 2018). As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized (Rovner 2011). To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support (Egloff 2019).\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics (Saunders and Abramowitz 2008; Mason 2018) and US foreign policy (Guisinger and Saunders 2017; Cavari and Freedman 2019). A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance (Gaines et al. 2007; Jerit and Barabas 2012; Ansolabehere, Meredith and Snowberg 2013; Bullock et al. 2015). Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences (Gaines et al. 2007; Jerit and Barabas 2012; Peterson and Iyengar 2021). Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans (Gerber and Huber 2009). Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture (Musgrave 2019). On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information (Robbett and Matthews 2018).\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones (Gomez and Whyte 2021).\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce (Lee 2019). On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so (Ipsos 2018).\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion (Foyle 2017). Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n## Exploring US Public Opinion regarding Cybersecurity\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond (Zaller 1992). Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering (Gaines et al. 2007; Gerber and Huber 2009) or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party (Petrocik 2009). Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace\n# OLS Coefficients\nFigure 1. Partisanship and cyber threat perception.\nagencies (Egloff 2019). Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang (Fritz 2018). As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic (Edwards et al. 2017), we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n## Experiment 1: Iran Treatment\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey (November 2018; $n = 874$), the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\n2018 CCES Experiment; Multinomial logistic regression\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy (Clary and Siddiqui 2021; Escriba-Folch, Muradova, and Rodon 2021), enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents (Bansak et al. 2018, 2019). These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\n8 The multi-wave design allowed us to mitigate pre-treatment bias, ensure respondent quality by screening for consistency across waves on answers to questions such as educational attainment and age, and ask more questions than would have been possible in a single questionnaire.\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States (Gartner 2008) and the identity and motivation of the attacker (Huff and Kertzer 2018).\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\n7 A small number of implausible scenarios were excluded; see the online appendix for details.\n8 Shanahan was recognized by only 10 percent of respondents in a poll fielded soon after our experiment, compared to 47 percent name recognition for Secretary of State Michael Pompeo (Relman and Hickey 2019).\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.\n# Discussion and Conclusion\nThe public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and\nCheerleading in Cyberspace\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem.",
  "flat_text": "Foreign Policy Analysis (2022), orac003\n# RESEARCH NOTE\n# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months . The attribution problem complicates both compellence and deterrence . Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution .\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government . As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized . To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support .\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics  and US foreign policy . A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance . Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences . Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans . Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture . On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information .\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones .\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce . On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so .\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion . Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n## Exploring US Public Opinion regarding Cybersecurity\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond . Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering  or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party . Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace\n# OLS Coefficients\nFigure 1. Partisanship and cyber threat perception.\nagencies . Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang . As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic , we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n## Experiment 1: Iran Treatment\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey , the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\n\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy , enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents . These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\n\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States  and the identity and motivation of the attacker .\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\n\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.\n# Discussion and Conclusion\nThe public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and\nCheerleading in Cyberspace\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem.",
  "toc": [
    [
      1,
      "__preamble__"
    ],
    [
      1,
      "# RESEARCH NOTE"
    ],
    [
      1,
      "# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks"
    ],
    [
      1,
      "# OLS Coefficients"
    ],
    [
      1,
      "# Discussion and Conclusion"
    ]
  ],
  "sections": {
    "__preamble__": "Foreign Policy Analysis (2022), orac003",
    "# RESEARCH NOTE": "",
    "# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks": "MARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months . The attribution problem complicates both compellence and deterrence . Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution .\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government . As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized . To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support .\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics  and US foreign policy . A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance . Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences . Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans . Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture . On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information .\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones .\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce . On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so .\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion . Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n## Exploring US Public Opinion regarding Cybersecurity\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond . Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering  or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party . Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace",
    "# OLS Coefficients": "Figure 1. Partisanship and cyber threat perception.\nagencies . Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang . As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic , we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n## Experiment 1: Iran Treatment\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey , the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy , enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents . These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States  and the identity and motivation of the attacker .\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.",
    "# Discussion and Conclusion": "The public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and\nCheerleading in Cyberspace\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem."
  },
  "process_log": {
    "scheme": "markdown",
    "numeric_check": {
      "first_num": null,
      "raw_count": 0,
      "raw_examples": [],
      "filtered_count": 0,
      "filtered_examples": [],
      "seq_score": 0.0
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0
    },
    "toc_count": 4,
    "section_count": 5
  },
  "word_count": 5789,
  "references": [
    "# References\nANSOLABEHERE, STEPHEN, MARC MEREDITH, AND ERIK SNOWBERG. 2013. \"Asking about Numbers: Why and How.\" Political Analysis 21 (1): 48-69.\nBANSAK, KIRK, JENS HAINMUELLER, DANIEL J. HOPKINS, AND TEPEI YAMAMOTO. 2018. \"The Number of Choice Tasks and Survey Satisficing in Conjoint Experiments.\" Political Analysis 26 (1): 112-19.\n——. 2019. \"Beyond the Breaking Point? Survey Satisficing in Conjoint Experiments.\" Political Science Research and Methods 9 (1): 53-71.\nBORGHARD, ERICA D., AND SHOWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" Security Studies 26 (3): 452-81.\nBULLOCK, JOHN G., ALAN S. GERBER, SETH J. HILL, AND GREGORY A. HUBER. 2015. \"Partisan Bias in Factual Beliefs about Politics.\" Quarterly Journal of Political Science 10 (4): 519-78.\nBULLOCK, JOHN G., AND GABRIEL LENZ. 2019. \"Partisan Bias in Surveys.\" Annual Review of Political Science 22 (1): 325-42.\nCAVARI, AMNON, AND GUY FREEDMAN. 2019. \"Partisan Cues and Opinion Formation on Foreign Policy.\" American Politics Research 47 (1): 29-57.\nCLARK, DAVID D., AND SUSAN LANDAU. 2011. \"Untangling Attribution.\" Harvard National Security Law Journal 2: 323.\nCLARY, CHRISTOPHER, AND NILOUFER SIDDIQUI. 2021. \"Voters and Foreign Policy: Evidence from a Conjoint Experiment in Pakistan.\" Foreign Policy Analysis 17 (2): orab001.\nEDWARDS, BENJAMIN, ALEXANDER FURNAS, STEPHANIE FORREST, AND ROBERT AXELROD. 2017. \"Strategic Aspects of Cyberattack, Attribution, and Blame.\" Proceedings of the National Academy of Sciences 114 (11): 2825-30.\nEGLOFF, FLORIAN J. 2019. \"Contested Public Attributions of Cyber Incidents and the Role of Academia.\" Contemporary Security Policy 41 (1): 55-81.\nESCRIBA-FOLCH, ABEL, LALA H. MURADOVA, AND TONI RODON. 2021. \"The Effects of Autocratic Characteristics on Public Opinion toward Democracy Promotion Policies: A Conjoint Analysis.\" Foreign Policy Analysis 17 (1): oraa016.\nEVERS, MILES M., ALEKSANDR FISHER, AND STEVEN D. SCHAAF. 2019. \"Is There a Trump Effect? An Experiment on Political Polarization and Audience Costs.\" Perspectives on Politics 17 (2): 433-52.\nFOYLE, DOUGLAS. 2017. \"Public Opinion and Foreign Policy.\" Oxford Research Encyclopedia of Politics. 22 Aug. 2017; Accessed January 29, 2022. https://oxfordre.com/politics/view/10.1093/acrefore/9780190228637.001.0001/acrefore-9780190228637-e-472.\nFRITZ, BEN. 2018. The Big Picture: The Fight for the Future of Movies. Boston, MA: Houghton Mifflin Harcourt.\nGAINES, BRIAN J., JAMES H. KUKLINSKI, PAUL J. QUIRK, BUDDY PEYTON, AND JAY VERKUILEN. 2007. \"Same Facts, Different Interpretations: Partisan Motivation and Opinion on Iraq.\" The Journal of Politics 69 (4): 957-74.\nGARTNER, SCOTT SIGMUND. 2008. \"The Multiple Effects of Casualties on Public Support for War: An Experimental Approach.\" American Political Science Review 102 (1): 95-106.\nMARCELO LEAL AND PAUL MUSGRAVE\nGERBER, ALAN S., AND GREGORY A. HUBER. 2009. \"Partisanship and Economic Behavior: Do Partisan Differences in Economic Forecasts Predict Real Economic Behavior?\" American Political Science Review 103 (3): 407-26.\nGOMEZ, MIGUEL ALBERTO, AND CHRISTOPHER WHITE. 2021. \"Breaking the Myth of Cyber Doom: Securitization and Normalization of Novel Threats.\" International Studies Quarterly 65 (4): 1137-1150.\nGROSS, MICHAEL L., DAPHNA CANETTI, AND DANA R. VASHIDI. 2017. \"Cyberterrorism: Its Effects on Psychological Well-Being, Public Confidence and Political Attitudes.\" Journal of Cybersecurity 3 (1): 49-58.\nGUISINGER, ALEXANDRA, AND ELIZABETH N. SAUNDERS. 2017. \"Mapping the Boundaries of Elite Cues: How Elites Shape Mass Opinion across International Issues.\" International Studies Quarterly 61 (2): 425-41.\nHAINHUELLER, JENS, DOMINIK HANGARTNER, AND TEPEI YAMAMOTO. 2015. \"Validating Vignette and Conjoint Survey Experiments against Real-World Behavior.\" Proceedings of the National Academy of Sciences 112 (8): 2395-2400.\n——. 2014. \"Causal Inference in Conjoint Analysis: Understanding Multidimensional Choices via Stated Preference Experiments.\" Political Analysis 22 (1): 1-30.\nHARKNETT, RICHARD J., AND JOSEPH S. NYE, JR. 2017. \"Is Deterrence Possible in Cyberspace?\" International Security 42 (2): 196-99.\nHUFF, CONNOR, AND JOSHUA D. KERTZER. 2018. \"How the Public Defines Terrorism.\" American Journal of Political Science 62 (1): 55-71.\nIPSOS. 2018. \"Ipsos/Reuters Poll Data about Russian Interference from 7/18/2018.\" Ipsos. Accessed January 28, 2022. https://www.ipsos.com/sites/default/files/ct/news/documents/2018-07/2018_reuters_tracking_rusia_7_18_2018.pdf.\nJENSEN, BENJAMIN M., AND BRANDON VALERIANO. 2019. \"What Do We Know about Cyber Escalation? Observations from Simulations and Surveys.\" Atlantic Council, Washington, DC. Accessed January 28, 2022. https://www.atlanticcouncil.org/in-depth-research-reports/issue-brief/what-do-we-know-about-cyber-escalation-observations-from-simulations-and-surveys/.\nJERIT, JENNIFER, AND JASON BARABAS. 2012. \"Partisan Perceptual Bias and the Information Environment.\" The Journal of Politics 74 (3): 672-84.\nKOSTYUK, NADIYA, AND CARLY WHINE. 2021. \"The Microfoundations of State Cybersecurity: Cyber Risk Perceptions and the Mass Public.\" Journal of Global Security Studies 6 (2): ogz077.\nKREPS, SARAH, AND DEBAK DAS. 2017. \"Warring from the Virtual to the Real: Assessing the Public's Threshold for War over Cyber Security.\" Research &amp; Politics 4 (2): 205316801771593. Accessed January 28, 2022. https://doi.org/10.1177/2053168017715930.\nKREPS, SARAH, AND JACQUELYN SCHNEIDER. 2019. \"Escalation Firebreaks in the Cyber, Conventional, and Nuclear Domains: Moving beyond Effects-Based Logics.\" Journal of Cybersecurity 5 (1): tyz007.\nLEE, MARY. 2019. \"Trump's Cyber Workforce Order Gets Bipartisan Praise.\" *Politico*, May 3, 2019. Accessed January 28, 2022. https://politi.co/2DMj8MN.\nLINDSAY, JON R. 2015. \"Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence against Cyberattack.\" Journal of Cybersecurity 1 (1): 53-67.\nLIN-GREENBERG, ERIK. 2021. \"Soldiers, Pollsters, and International Crises: Public Opinion and the Military's Advice on the Use of Force.\" Foreign Policy Analysis 17 (3): orab009.\nLYNN, WILLIAM F. 2010. \"Defending a New Domain-the Pentagon's Cyberstrategy.\" Foreign Affairs 89: 97.\nMASON, LILLIANA. 2018. Uncivil Agreement: How Politics Became Our Identity. Chicago, IL: University of Chicago Press.\nMUSGRAVE, PAUL. 2019. \"International Hegemony Meets Domestic Politics: Why Liberals Can Be Pessimists.\" Security Studies 28 (3): 451-478.\nPETERSON, ERIK, AND SHANTO IYENGAR. 2021. \"Partisan Gaps in Political Information and Information-Seeking Behavior: Motivated Reasoning or Cheerleading?\" American Journal of Political Science 65 (1): 133-47.\nPETROCIK, JOHN RICHARD. 2009. \"Measuring Party Support: Leaners Are Not Independents.\" *Electoral Studies* 28 (4): 562-72.\nPRIOR, MARKUS, GAURAV SOOD, AND KABIR KHANNA. 2015. \"You Cannot be Serious: The Impact of Accuracy Incentives on Partisan Bias in Reports of Economic Perceptions.\" Quarterly Journal of Political Science 10: 489-518.\nRELMAN, ELIZA, AND WALT HICKEY. 2019. \"Alexandria Ocasio-Cortez More Famous Than Top Republicans, Trump Cabinet.\" Business Insider, March 12, 2019. Accessed January 28, 2022. https://www.businessinsider.com/alexandria-ocasio-cortez-more-famous-than-top-republicans-trump-cabinet-2019-3.\nRID, THOMAS, AND BEN BUCHANAN. 2015. \"Attributing Cyber Attacks.\" Journal of Strategic Studies 38 (1-2): 4-37.\nROBBETT, ANDREA, AND PETER HANS MATTHEWS. 2018. \"Partisan Bias and Expressive Voting.\" Journal of Public Economics 157: 107-20.\nCheerleading in Cyberspace\nRovner, Joshua. 2011. Fixing the Facts: National Security and the Politics of Intelligence. New York: Cornell University Press.\nSaunders, Kyle L., and Alan I. Abramowitz. 2008. \"Is Polarization a Myth?\" The Journal of Politics 70: 542–55.\nSchulzke, Marcus. 2018. \"The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty.\" Perspectives on Politics 16 (4): 954–68.\nTomz, Michael, Jessica LP Weeks, and Keren Yarhi-Milo. 2020. \"Public Opinion and Decisions about Military Force in Democracies.\" International Organization 74 (1): 119–43.\nZaller, John R. 1992. The Nature and Origins of Mass Opinion. Cambridge: Cambridge University Press."
  ],
  "citations": {
    "style": "author_year",
    "flat_text": "Foreign Policy Analysis (2022), orac003\n# RESEARCH NOTE\n# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months . The attribution problem complicates both compellence and deterrence . Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution .\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government . As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized . To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support .\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics  and US foreign policy . A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance . Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences . Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans . Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture . On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information .\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones .\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce . On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so .\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion . Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n## Exploring US Public Opinion regarding Cybersecurity\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond . Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering  or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party . Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace\n# OLS Coefficients\nFigure 1. Partisanship and cyber threat perception.\nagencies . Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang . As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic , we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n## Experiment 1: Iran Treatment\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey , the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\n\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy , enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents . These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\n\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States  and the identity and motivation of the attacker .\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\n\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.\n# Discussion and Conclusion\nThe public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and\nCheerleading in Cyberspace\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Foreign Policy Analysis (2022), orac003\n# RESEARCH NOTE\n# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months (Rid and Buchanan 2015). The attribution problem complicates both compellence and deterrence (Borghard and Lonergan 2017). Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution (Lynn 2010; Clark and Landau 2011; Harknett and Nye Jr 2017).\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government (Schulzke 2018). As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized (Rovner 2011). To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support (Egloff 2019).\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics (Saunders and Abramowitz 2008; Mason 2018) and US foreign policy (Guisinger and Saunders 2017; Cavari and Freedman 2019). A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance (Gaines et al. 2007; Jerit and Barabas 2012; Ansolabehere, Meredith and Snowberg 2013; Bullock et al. 2015). Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences (Gaines et al. 2007; Jerit and Barabas 2012; Peterson and Iyengar 2021). Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans (Gerber and Huber 2009). Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture (Musgrave 2019). On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information (Robbett and Matthews 2018).\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones (Gomez and Whyte 2021).\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce (Lee 2019). On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so (Ipsos 2018).\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion (Foyle 2017). Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n## Exploring US Public Opinion regarding Cybersecurity\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond (Zaller 1992). Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering (Gaines et al. 2007; Gerber and Huber 2009) or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party (Petrocik 2009). Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace\n# OLS Coefficients\nFigure 1. Partisanship and cyber threat perception.\nagencies (Egloff 2019). Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang (Fritz 2018). As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic (Edwards et al. 2017), we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n## Experiment 1: Iran Treatment\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey (November 2018; $n = 874$), the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\n2018 CCES Experiment; Multinomial logistic regression\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy (Clary and Siddiqui 2021; Escriba-Folch, Muradova, and Rodon 2021), enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents (Bansak et al. 2018, 2019). These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\n8 The multi-wave design allowed us to mitigate pre-treatment bias, ensure respondent quality by screening for consistency across waves on answers to questions such as educational attainment and age, and ask more questions than would have been possible in a single questionnaire.\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States (Gartner 2008) and the identity and motivation of the attacker (Huff and Kertzer 2018).\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\n7 A small number of implausible scenarios were excluded; see the online appendix for details.\n8 Shanahan was recognized by only 10 percent of respondents in a poll fielded soon after our experiment, compared to 47 percent name recognition for Secretary of State Michael Pompeo (Relman and Hickey 2019).\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.\n# Discussion and Conclusion\nThe public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and\nCheerleading in Cyberspace\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem."
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Foreign Policy Analysis (2022), orac003\n# RESEARCH NOTE\n# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months (Rid and Buchanan 2015). The attribution problem complicates both compellence and deterrence (Borghard and Lonergan 2017). Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution (Lynn 2010; Clark and Landau 2011; Harknett and Nye Jr 2017).\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government (Schulzke 2018). As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized (Rovner 2011). To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support (Egloff 2019).\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics (Saunders and Abramowitz 2008; Mason 2018) and US foreign policy (Guisinger and Saunders 2017; Cavari and Freedman 2019). A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance (Gaines et al. 2007; Jerit and Barabas 2012; Ansolabehere, Meredith and Snowberg 2013; Bullock et al. 2015). Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences (Gaines et al. 2007; Jerit and Barabas 2012; Peterson and Iyengar 2021). Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans (Gerber and Huber 2009). Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture (Musgrave 2019). On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information (Robbett and Matthews 2018).\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones (Gomez and Whyte 2021).\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce (Lee 2019). On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so (Ipsos 2018).\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion (Foyle 2017). Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n## Exploring US Public Opinion regarding Cybersecurity\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond (Zaller 1992). Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering (Gaines et al. 2007; Gerber and Huber 2009) or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party (Petrocik 2009). Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace\n# OLS Coefficients\nFigure 1. Partisanship and cyber threat perception.\nagencies (Egloff 2019). Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang (Fritz 2018). As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic (Edwards et al. 2017), we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n## Experiment 1: Iran Treatment\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey (November 2018; $n = 874$), the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\n2018 CCES Experiment; Multinomial logistic regression\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy (Clary and Siddiqui 2021; Escriba-Folch, Muradova, and Rodon 2021), enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents (Bansak et al. 2018, 2019). These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\n8 The multi-wave design allowed us to mitigate pre-treatment bias, ensure respondent quality by screening for consistency across waves on answers to questions such as educational attainment and age, and ask more questions than would have been possible in a single questionnaire.\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States (Gartner 2008) and the identity and motivation of the attacker (Huff and Kertzer 2018).\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\n7 A small number of implausible scenarios were excluded; see the online appendix for details.\n8 Shanahan was recognized by only 10 percent of respondents in a poll fielded soon after our experiment, compared to 47 percent name recognition for Secretary of State Michael Pompeo (Relman and Hickey 2019).\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.\n# Discussion and Conclusion\nThe public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and\nCheerleading in Cyberspace\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem."
    },
    "author_year": {
      "total": {
        "intext_total": 28,
        "success_occurrences": 28,
        "success_unique": 25,
        "bib_unique_total": 91,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.27472527472527475,
        "success_percentage": 100.0,
        "style": "author_year"
      },
      "results": [
        {
          "index": "rid|2015",
          "intext_citation": "(Rid and Buchanan 2015)",
          "preceding_text": "Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months",
          "footnote": "RID, THOMAS, AND BEN BUCHANAN. 2015. \"Attributing Cyber Attacks.\" Journal of Strategic Studies 38 (1-2): 4-37."
        },
        {
          "index": "borghard|2017",
          "intext_citation": "(Borghard and Lonergan 2017)",
          "preceding_text": "The attribution problem complicates both compellence and deterrence",
          "footnote": "BORGHARD, ERICA D., AND SHOWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" Security Studies 26 (3): 452-81."
        },
        {
          "index": "lynn|2010",
          "intext_citation": "(Lynn 2010; Clark and Landau 2011; Harknett and Nye Jr 2017)",
          "preceding_text": "Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution",
          "footnote": "LYNN, WILLIAM F. 2010. \"Defending a New Domain-the Pentagon's Cyberstrategy.\" Foreign Affairs 89: 97."
        },
        {
          "index": "schulzke|2018",
          "intext_citation": "(Schulzke 2018)",
          "preceding_text": "This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government",
          "footnote": "Schulzke, Marcus. 2018. \"The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty.\" Perspectives on Politics 16 (4): 954–68."
        },
        {
          "index": "rovner|2011",
          "intext_citation": "(Rovner 2011)",
          "preceding_text": "Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized",
          "footnote": "Rovner, Joshua. 2011. Fixing the Facts: National Security and the Politics of Intelligence. New York: Cornell University Press."
        },
        {
          "index": "egloff|2019",
          "intext_citation": "(Egloff 2019)",
          "preceding_text": "Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support",
          "footnote": "EGLOFF, FLORIAN J. 2019. \"Contested Public Attributions of Cyber Incidents and the Role of Academia.\" Contemporary Security Policy 41 (1): 55-81."
        },
        {
          "index": "saunders|2008",
          "intext_citation": "(Saunders and Abramowitz 2008; Mason 2018)",
          "preceding_text": "Political polarization affects much of US politics",
          "footnote": "Saunders, Kyle L., and Alan I. Abramowitz. 2008. \"Is Polarization a Myth?\" The Journal of Politics 70: 542–55."
        },
        {
          "index": "guisinger|2017",
          "intext_citation": "(Guisinger and Saunders 2017; Cavari and Freedman 2019)",
          "preceding_text": "Political polarization affects much of US politics (Saunders and Abramowitz 2008; Mason 2018) and US foreign policy",
          "footnote": "GUISINGER, ALEXANDRA, AND ELIZABETH N. SAUNDERS. 2017. \"Mapping the Boundaries of Elite Cues: How Elites Shape Mass Opinion across International Issues.\" International Studies Quarterly 61 (2): 425-41."
        },
        {
          "index": "gaines|2007",
          "intext_citation": "(Gaines et al. 2007; Jerit and Barabas 2012; Ansolabehere, Meredith and Snowberg 2013; Bullock et al. 2015)",
          "preceding_text": "Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance",
          "footnote": "GAINES, BRIAN J., JAMES H. KUKLINSKI, PAUL J. QUIRK, BUDDY PEYTON, AND JAY VERKUILEN. 2007. \"Same Facts, Different Interpretations: Partisan Motivation and Opinion on Iraq.\" The Journal of Politics 69 (4): 957-74."
        },
        {
          "index": "gaines|2007",
          "intext_citation": "(Gaines et al. 2007; Jerit and Barabas 2012; Peterson and Iyengar 2021)",
          "preceding_text": "Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences",
          "footnote": "GAINES, BRIAN J., JAMES H. KUKLINSKI, PAUL J. QUIRK, BUDDY PEYTON, AND JAY VERKUILEN. 2007. \"Same Facts, Different Interpretations: Partisan Motivation and Opinion on Iraq.\" The Journal of Politics 69 (4): 957-74."
        },
        {
          "index": "gerber|2009",
          "intext_citation": "(Gerber and Huber 2009)",
          "preceding_text": "and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans",
          "footnote": "GERBER, ALAN S., AND GREGORY A. HUBER. 2009. \"Partisanship and Economic Behavior: Do Partisan Differences in Economic Forecasts Predict Real Economic Behavior?\" American Political Science Review 103 (3): 407-26."
        },
        {
          "index": "musgrave|2019",
          "intext_citation": "(Musgrave 2019)",
          "preceding_text": "partisans (Gerber and Huber 2009). Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture",
          "footnote": "MUSGRAVE, PAUL. 2019. \"International Hegemony Meets Domestic Politics: Why Liberals Can Be Pessimists.\" Security Studies 28 (3): 451-478."
        },
        {
          "index": "robbett|2018",
          "intext_citation": "(Robbett and Matthews 2018)",
          "preceding_text": "ans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information",
          "footnote": "ROBBETT, ANDREA, AND PETER HANS MATTHEWS. 2018. \"Partisan Bias and Expressive Voting.\" Journal of Public Economics 157: 107-20."
        },
        {
          "index": "gomez|2021",
          "intext_citation": "(Gomez and Whyte 2021)",
          "preceding_text": "interested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones",
          "footnote": "GOMEZ, MIGUEL ALBERTO, AND CHRISTOPHER WHITE. 2021. \"Breaking the Myth of Cyber Doom: Securitization and Normalization of Novel Threats.\" International Studies Quarterly 65 (4): 1137-1150."
        },
        {
          "index": "lee|2019",
          "intext_citation": "(Lee 2019)",
          "preceding_text": "either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce",
          "footnote": "LEE, MARY. 2019. \"Trump's Cyber Workforce Order Gets Bipartisan Praise.\" *Politico*, May 3, 2019. Accessed January 28, 2022. https://politi.co/2DMj8MN."
        },
        {
          "index": "ipsos|2018",
          "intext_citation": "(Ipsos 2018)",
          "preceding_text": "A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so",
          "footnote": "IPSOS. 2018. \"Ipsos/Reuters Poll Data about Russian Interference from 7/18/2018.\" Ipsos. Accessed January 28, 2022. https://www.ipsos.com/sites/default/files/ct/news/documents/2018-07/2018_reuters_tracking_rusia_7_18_2018.pdf."
        },
        {
          "index": "foyle|2017",
          "intext_citation": "(Foyle 2017)",
          "preceding_text": "Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion",
          "footnote": "FOYLE, DOUGLAS. 2017. \"Public Opinion and Foreign Policy.\" Oxford Research Encyclopedia of Politics. 22 Aug. 2017; Accessed January 29, 2022. https://oxfordre.com/politics/view/10.1093/acrefore/9780190228637.001.0001/acrefore-9780190228637-e-472."
        },
        {
          "index": "zaller|1992",
          "intext_citation": "(Zaller 1992)",
          "preceding_text": "We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond",
          "footnote": "Zaller, John R. 1992. The Nature and Origins of Mass Opinion. Cambridge: Cambridge University Press."
        },
        {
          "index": "gaines|2007",
          "intext_citation": "(Gaines et al. 2007; Gerber and Huber 2009)",
          "preceding_text": "Observational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering",
          "footnote": "GAINES, BRIAN J., JAMES H. KUKLINSKI, PAUL J. QUIRK, BUDDY PEYTON, AND JAY VERKUILEN. 2007. \"Same Facts, Different Interpretations: Partisan Motivation and Opinion on Iraq.\" The Journal of Politics 69 (4): 957-74."
        },
        {
          "index": "petrocik|2009",
          "intext_citation": "(Petrocik 2009)",
          "preceding_text": "² Throughout, we count independents who lean toward one party as belonging to that party",
          "footnote": "PETROCIK, JOHN RICHARD. 2009. \"Measuring Party Support: Leaners Are Not Independents.\" *Electoral Studies* 28 (4): 562-72."
        },
        {
          "index": "egloff|2019",
          "intext_citation": "(Egloff 2019)",
          "preceding_text": "agencies",
          "footnote": "EGLOFF, FLORIAN J. 2019. \"Contested Public Attributions of Cyber Incidents and the Role of Academia.\" Contemporary Security Policy 41 (1): 55-81."
        },
        {
          "index": "fritz|2018",
          "intext_citation": "(Fritz 2018)",
          "preceding_text": "agencies (Egloff 2019). Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang",
          "footnote": "FRITZ, BEN. 2018. The Big Picture: The Fight for the Future of Movies. Boston, MA: Houghton Mifflin Harcourt."
        },
        {
          "index": "edwards|2017",
          "intext_citation": "(Edwards et al. 2017)",
          "preceding_text": "Even though a government's choice of when to publicly attribute an attack may be strategic",
          "footnote": "EDWARDS, BENJAMIN, ALEXANDER FURNAS, STEPHANIE FORREST, AND ROBERT AXELROD. 2017. \"Strategic Aspects of Cyberattack, Attribution, and Blame.\" Proceedings of the National Academy of Sciences 114 (11): 2825-30."
        },
        {
          "index": "clary|2021",
          "intext_citation": "(Clary and Siddiqui 2021; Escriba-Folch, Muradova, and Rodon 2021)",
          "preceding_text": "Conjoint experiments, increasingly popular in studies of foreign policy",
          "footnote": "CLARY, CHRISTOPHER, AND NILOUFER SIDDIQUI. 2021. \"Voters and Foreign Policy: Evidence from a Conjoint Experiment in Pakistan.\" Foreign Policy Analysis 17 (2): orab001."
        },
        {
          "index": "bansak|2018",
          "intext_citation": "(Bansak et al. 2018, 2019)",
          "preceding_text": "Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents",
          "footnote": "BANSAK, KIRK, JENS HAINMUELLER, DANIEL J. HOPKINS, AND TEPEI YAMAMOTO. 2018. \"The Number of Choice Tasks and Survey Satisficing in Conjoint Experiments.\" Political Analysis 26 (1): 112-19."
        },
        {
          "index": "gartner|2008",
          "intext_citation": "(Gartner 2008)",
          "preceding_text": "These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States",
          "footnote": "GARTNER, SCOTT SIGMUND. 2008. \"The Multiple Effects of Casualties on Public Support for War: An Experimental Approach.\" American Political Science Review 102 (1): 95-106."
        },
        {
          "index": "huff|2018",
          "intext_citation": "(Huff and Kertzer 2018)",
          "preceding_text": ". These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States (Gartner 2008) and the identity and motivation of the attacker",
          "footnote": "HUFF, CONNOR, AND JOSHUA D. KERTZER. 2018. \"How the Public Defines Terrorism.\" American Journal of Political Science 62 (1): 55-71."
        },
        {
          "index": "relman|2019",
          "intext_citation": "(Relman and Hickey 2019)",
          "preceding_text": "8 Shanahan was recognized by only 10 percent of respondents in a poll fielded soon after our experiment, compared to 47 percent name recognition for Secretary of State Michael Pompeo",
          "footnote": "RELMAN, ELIZA, AND WALT HICKEY. 2019. \"Alexandria Ocasio-Cortez More Famous Than Top Republicans, Trump Cabinet.\" Business Insider, March 12, 2019. Accessed January 28, 2022. https://www.businessinsider.com/alexandria-ocasio-cortez-more-famous-than-top-republicans-trump-cabinet-2019-3."
        }
      ],
      "flat_text": "Foreign Policy Analysis (2022), orac003\n# RESEARCH NOTE\n# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months . The attribution problem complicates both compellence and deterrence . Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution .\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government . As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized . To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support .\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics  and US foreign policy . A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance . Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences . Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans . Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture . On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information .\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones .\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce . On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so .\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion . Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n## Exploring US Public Opinion regarding Cybersecurity\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond . Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering  or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party . Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace\n# OLS Coefficients\nFigure 1. Partisanship and cyber threat perception.\nagencies . Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang . As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic , we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n## Experiment 1: Iran Treatment\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey , the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\n\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy , enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents . These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\n\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States  and the identity and motivation of the attacker .\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\n\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.\n# Discussion and Conclusion\nThe public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and\nCheerleading in Cyberspace\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem."
    }
  },
  "summary": {
    "full_text": {
      "words": 6021,
      "tokens": 7703
    },
    "flat_text": {
      "words": 5789,
      "tokens": 7246
    }
  },
  "payload": "## # Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\n\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nCheerleading in Cyberspace\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months . The attribution problem complicates both compellence and deterrence . Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution .\nAttribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government . As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized . To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support .\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics  and US foreign policy . A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance . Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences . Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans . Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture . On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information .\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more\ninterested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones .\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce . On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so .\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion . Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n## Descriptive Survey Data\nWe begin by establishing that partisan polarization matters for cybersecurity.\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,\nMARCELO LEAL AND PAUL MUSGRAVE\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond . Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering  or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n## Hypotheses\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n² Throughout, we count independents who lean toward one party as belonging to that party . Reclassifying leaners as independents does not affect our substantive findings.\nCheerleading in Cyberspace\n\n---\n\n## # OLS Coefficients\n\nFigure 1. Partisanship and cyber threat perception.\nagencies . Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang . As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.\nMARCELO LEAL AND PAUL MUSGRAVE\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic , we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey , the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.\nCheerleading in Cyberspace\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 3. Predicted support for retaliation by party and outcome variable.\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".\nCheerleading in Cyberspace\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n## Experiment 2: Conjoint Experiment\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\nConjoint experiments, increasingly popular in studies of foreign policy , enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents . These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\nMARCELO LEAL AND PAUL MUSGRAVE\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States  and the identity and motivation of the attacker .\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\nCheerleading in Cyberspace\nFigure 4. OLS coefficients for respondents' confidence in attribution.\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was\nMARCELO LEAL AND PAUL MUSGRAVE\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:SUCCESS\nsections_raw:5\nsections_clean:4\nintro:FOUND\nconclusion:FOUND\npredefined_sections:# Discussion and Conclusion\nextra_sections:None\npayload_tokens_before:7262\npayload_tokens_after:7262\ndropped_section:None\nadded_section:None\n---LOG_SUMMARY_END---",
  "pages_text": [
    "Foreign Policy Analysis (2022), orac003\n\n# RESEARCH NOTE\n\n# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks\n\nMARCELO LEAL AND PAUL MUSGRAVE\nUniversity of Massachusetts Amherst, USA\n\nHow does the US public evaluate claims attributing responsibility for a cyberattack? It seems plausible that political factors complicate how the US public judges attribution claims. In this article, we collect original survey data and use two survey experiments to explore this subject. Specifically, we analyze how cues and endorsements from partisan, intelligence, and independent non-governmental actors affect public confidence in attribution claims regarding the identity of cyberaggressors and support for retribution. We find evidence of polarization, particularly regarding perceptions of Russia's threat in cyberspace. To uncover whether this polarization results from partisan cheerleading or more sincere motivations, we conduct two experiments regarding political factors and attribution claims. In the first experiment, we find that respondents respond similarly to independent observers' endorsements of attribution claims but that Democrats appear to respond strategically in a test of the link between attribution and retribution rather than endorse a proposal by then-President Trump. In the second experiment, we find that partisans respond similarly to intelligence and independent experts' evaluations of attribution claims, and that both respond much more favorably to independent experts than the intelligence community. Superficial polarization thus turns out to look more like partisan cheerleading.\n\n¿Cómo evalúa el público estadounidense las declaraciones que atribuyen la responsabilidad de un ciberataque? Resulta plausible que los factores políticos compliquen la forma en que el público estadounidense juzga las declaraciones de atribución. En este artículo, se recopilan datos de encuestas originales y se utilizan dos experimentos de encuestas para explorar este tema. Específicamente, analizamos la forma en que las señales y los apoyos de los actores partidistas, no gubernamentales independientes y de los servicios de inteligencia afectan la confianza pública en las declaraciones de atribución sobre la identidad de los ciberagresores y el apoyo a la represalia. Brindamos pruebas de la polarización, especialmente en lo que respecta a la percepción de la amenaza de Rusia en el ciberespacio. Para\n\nMarcelo Leal is a PhD student in Political Science at the University of Massachusetts Amherst and a Research Fellow at the National Center for Digital Government. His research lies at the intersection of cybersecurity, foreign policy, and public opinion. In his doctoral research, he explores why states pursue specific cybersecurity policies. In some of his recent works, he has also explored how the maintenance and control of infrastructure affect states' cyber strategies and how the U.S. public evaluates competing narratives about cybersecurity incidents.\n\nPaul Musgrave is an Assistant Professor of Political Science at the University of Massachusetts Amherst. He studies US foreign policy, international relations theory, and how oil and politics mix. His research has appeared in International Organization, International Studies Quarterly, Security Studies, Presidential Studies Quarterly, and Comparative Political Studies, and he has written for The Washington Post, Foreign Policy, and other outlets. He holds a PhD in Government with a focus on international relations from Georgetown University.\n\nLeal, Marcelo, and Paul Musgrave. (2022) Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks. Foreign Policy Analysis, https://doi.org/10.1093/fpa/orac003\n\n© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.\n\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com",
    "Cheerleading in Cyberspace\n\ndescubrir si esta polarización es el resultado de la propaganda partidista o de motivaciones más genuinas, llevamos a cabo dos experimentos sobre los factores políticos y las declaraciones de atribución. En el primer experimento, se observa que los encuestados responden de forma similar a los apoyos de observadores independientes sobre las declaraciones de atribución, pero que los demócratas parecen responder estratégicamente en una prueba del vínculo entre atribución y represalia en lugar de respaldar una propuesta del entonces presidente Trump. En el segundo experimento, descubrimos que los partidistas responden de forma similar a las evaluaciones de los servicios de inteligencia y de los expertos independientes sobre las declaraciones de atribución, y que ambos responden mucho más favorablemente a los expertos independientes que a la comunidad de servicios de inteligencia. Así, la polarización superficial resulta parecerse más a la propaganda partidista.\n\nComment le public américain évalue-t-il les déclarations attribuant la responsabilité d'une cyberattaque? Il semble plausible que des facteurs politiques compliquent la façon dont le public américain juge les déclarations d'attribution. Pour cet article, nous avons recueilli des données d'enquêtes originales et nous nous appuyons sur deux expériences d'enquête pour explorer ce sujet. Plus précisément, nous analysons la manière dont les signaux et approbations des acteurs partisans, des acteurs des services de renseignement et des acteurs non gouvernementaux indépendants affectent la confiance que le public accorde aux déclarations d'attribution d'identité aux cyberagresseurs ainsi que le soutien qu'il prête aux représailles. Nous prouvons qu'il existe une polarisation, en particulier concernant les perceptions de la menace russe dans le cyberespace. Nous avons mené deux expériences concernant les facteurs politiques et les déclarations d'attribution pour découvrir si cette polarisation résultait d'un soutien partisan ou plutôt de motivations plus sincères. Dans la première expérience, nous avons constaté que les participants réagissaient d'une manière similaire aux approbations d'attribution des observateurs indépendants, mais que les démocrates semblaient réagir de manière stratégique lorsqu'il s'agissait d'analyser le lien entre attribution et représailles plutôt que d'approuver une proposition du président Trump de l'époque. Dans la deuxième expérience, nous avons constaté que les partisans réagissaient d'une manière similaire aux évaluations des déclarations d'attribution par les services de renseignement et les experts indépendants et que les démocrates tout comme les républicains réagissaient beaucoup plus favorablement aux évaluations des experts indépendants qu'à celles de la communauté du renseignement. La polarisation superficielle s'avère donc plutôt liée à un soutien partisan.\n\nAttribution, the process of establishing responsibility for a cyberattack, forms a major part of the theory and practice of cybersecurity. Attributing responsibility for a cyberattack involves difficult technical and interpretive tasks. These include comparing code samples to find elements that have been re-used from other attacks, tracing entry into secured systems, or otherwise using intelligence sources. Consequently, cyber attribution may be far more difficult than determining which country carried out an airstrike, given that a cyber intrusion may not even be detected for weeks or months (Rid and Buchanan 2015). The attribution problem complicates both compellence and deterrence (Borghard and Lonergan 2017). Deterrence by punishment, in particular, has been deemed challenging or even impossible without attribution (Lynn 2010; Clark and Landau 2011; Harknett and Nye Jr 2017).",
    "Attribution grows even more complicated when we consider its public phase: convincing the public that a given entity has carried out an attack. This process involves the acceptance or rejection of such claims by nontechnical audiences inside and beyond the government (Schulzke 2018). As Lindsay (2015) writes, there are special challenges in making attribution cases public: “An attribution case that depends on secret sources and methods ... cannot be publicly revealed without jeopardizing those sources.” If the public is unpersuaded, Lindsay argues, an unconvincing case for attribution may undermine the legitimacy of a retaliatory act. Skepticism may be difficult to surmount if the public mistrusts intelligence agencies' attribution claims, perhaps because it believes those agencies have been politicized (Rovner 2011). To the extent that public support is necessary for overt reprisals, the factors involved in generating public confidence in such claims matter greatly. Some have suggested that independent experts, such as academics, could verify intelligence claims to overcome such problems, but this remains a supposition without empirical support (Egloff 2019).\n\nPolitical polarization—the process of dividing public opinion and practice toward politics along partisan lines—may further complicate the task of securing public confidence in an attribution claim in the United States. Political polarization affects much of US politics (Saunders and Abramowitz 2008; Mason 2018) and US foreign policy (Guisinger and Saunders 2017; Cavari and Freedman 2019). A key question concerns the relationship between polarization and how the public forms judgments. Specialists in American politics have long argued that partisanship colors how partisans respond to questions regarding even factual information, such as economic performance (Gaines et al. 2007; Jerit and Barabas 2012; Ansolabehere, Meredith and Snowberg 2013; Bullock et al. 2015). Some argue these divisions result from fundamental differences in how partisans see the world—that a partisan lens distorts partisans' interpretations of political facts, causes, and consequences (Gaines et al. 2007; Jerit and Barabas 2012; Peterson and Iyengar 2021). Others argue that such concerns are overblown and that divergences in partisan responses reflect a simpler process whereby partisans express sentiments that favor their party's position but retain a more accurate model of the world (Ansolabehere, Meredith, and Snowberg 2013; Bullock et al. 2015).\n\nThe stakes of this debate matter tremendously. If party differences result from fundamental divisions, as Jerit and Barabas (2012) write, public learning and judgment would be dominated by “a selective pattern of learning” in which partisans learn only facts that favor their side and discard those that challenge their position. There is evidence that partisans evaluate the economy as doing better than it is when their co-partisan occupies the White House, for example, thus leading to higher levels of consumer spending by co-partisans (Gerber and Huber 2009). Such a mechanism would undermine the process for generating bipartisan policymaking in cybersecurity, as like other instances in which partisan division led to difficulties in establishing a consistent foreign policy posture (Musgrave 2019). On the other hand, if the public's judgments about cyber attribution claims are only superficially driven by partisanship, then policymakers may act with greater confidence that the same facts presented to different partisans will generate relatively similar responses. Expressive behavior has sometimes been tamed by incentives to respond correctly (such as a small monetary reward for accurate guesses about economic growth) or even the provision of free and accurate information (Robbett and Matthews 2018).\n\nDespite the importance of attribution and the role of the public in evaluating attribution claims, however, the field knows little about what influences the public's acceptance of attribution, particularly whether polarization matters in cybersecurity. To be sure, recent work in the cybersecurity literature has made advances in understanding public opinion and cyber operations generally (Gross, Canetti, and Vashdi 2017; Kreps and Das 2017; Jensen and Valeriano 2019; Kreps and Schneider 2019; Kostyuk and Wayne 2021). Yet these studies tend to be more",
    "interested in processes other than attribution, such as how the public adapts to new types of threats in light of existing ones (Gomez and Whyte 2021).\n\nAt first glance, it appears plausible that the public's views of cybersecurity could be either nonpolitical or driven by partisanship. Cybersecurity discussions in the United States often feature bipartisan action, as when legislators of both parties united behind President Trump's executive order to enhance the national cybersecurity workforce (Lee 2019). On the other hand, Russia's involvement in the 2016 US elections and debates over the extent and effects of such meddling—itself an instance of an attribution dispute—have been polarizing. A 2018 poll shows that only 32 percent of Republicans believe that Russia had interfered in the American elections in favor of President Donald Trump, while 81 percent of Democrats thought it did so (Ipsos 2018).\n\nResolving the question of how the American public evaluates attribution claims would thus address key debates in foreign policy and American politics. The importance of this topic goes beyond an academic interest in understanding public opinion. Despite longstanding claims that public opinion matters comparatively little to the shaping of foreign policy, recent research suggests that elites may be more sensitive to public opinion (Foyle 2017). Tomz, Weeks, and Yarhi-Milo (2020) find that elected officials are more willing to express support for the use of force when informed there is public support. Lin-Greenberg (2021) demonstrates a similar effect among military officers, who are more likely to recommend the use of force if they are informed there is public support for that option.\n\nIn this research note, we contribute to this debate by reporting original survey data and the results of experiments to explore US public opinion regarding attribution in cybersecurity, with particular attention given to partisan polarization. Our survey data reveal a large partisan division regarding evaluations of which cyber adversaries pose a major threat to the United States and which sectors are most vulnerable to attack. Yet our experiments demonstrate evidence consistent with the interpretation that this division may be superficial and driven as much or more by partisan cheerleading than by partisan filtering.\n\n## Exploring US Public Opinion regarding Cybersecurity\n\nDespite substantial progress, many dimensions of public opinion regarding cyberspace remain underexplored. We advance this literature in three ways. First, we provide original data regarding public opinion on core cybersecurity issues taken from a representative sample of Americans via the 2018 Cooperative Congressional Election Survey (CCES). Second, we present the results of a survey experiment with CCES respondents about a hypothetical Iranian government cyberattack to explore what factors affect Americans' confidence in official attribution claims and, by extension, their support for retributive actions. Third, we conduct a separate conjoint experiment to explore how contextual and specific factors of hypothetical cyberattacks influence confidence in attribution claims.\n\n## Descriptive Survey Data\n\nWe begin by establishing that partisan polarization matters for cybersecurity.\n\nAs part of the 2018 CCES survey, we asked a nationally representative sample of respondents about their attitudes toward cybersecurity (n = 1,000, September/October 2018). In particular, we asked respondents to rate on a 0--100 scale how much of a threat selected countries or organizations posed to the cybersecurity of the United States: Russia, China, Iran, North Korea, international criminals,",
    "MARCELO LEAL AND PAUL MUSGRAVE\n\nCanada, and international terrorists.¹ Responses displayed substantial variation by party identification in their ranking of threats, especially regarding Russia.² To test if these relationships hold controlling for more factors, we turn to regression analysis. The dependent variable is an adjusted threat perception rating generated by subtracting respondents' individual mean threat rating from their rating for each adversary. We control for standard demographics and party identification as well as whether respondents had broadband, dial-up, or no Internet access at home as a proxy for familiarity with the Internet. We also measure self-reported interest in how often respondents followed the news, coded as a four-point variable ranging from \"Hardly at all\" to \"Most of the time\". We interact news interest with party identification as a test of receptivity to cues about how partisans \"should\" respond (Zaller 1992). Finally, we adjust each respondent's rating of the threat posed by each potential adversary by subtracting their overall arithmetic mean threat rating from each individual threat rating, enabling us to focus on whether respondents view an adversary as more or less threatening than their average perception.\n\nFigure 1 presents ordinary least squares (OLS) regression estimates of how the key explanatory variables, partisanship, and news interest predict respondents' evaluations of the threat posed by different countries. (Full results are available in the online appendix.) After controlling for other factors, we find that partisanship and news interest do not affect evaluations of different threats, except for Russia. Notably, and in keeping with the uniquely polarized role of Russia in cybersecurity at the time, Republicans grew less likely to evaluate Russia as a threat as their self-reported news interest increased, a pattern not visible for any other country.\n\nWe found a similar pattern in responses to a question asking respondents to evaluate the vulnerability of different categories of targets. In ordinal logistic regressions of each sector's vulnerability reported in the online appendix, self-reported news interest proves a significant predictor of a belief that voting machines are vulnerable for Democrats, but not for Republicans or Independents. Indeed, the strongest relationship between News Interest and evaluation of a sectoral vulnerability comes among Democrats who report taking an interest in the news \"most of the time\" (the highest level of self-reported interest) evaluating the vulnerability of voting machines. This supports the view that partisans most attuned to cues more reliably express the \"correct\" opinion by partisan lights.\n\nObservational data do not allow us to discern whether this partisan polarization regarding cyberspace reflects partisan filtering (Gaines et al. 2007; Gerber and Huber 2009) or partisan cheerleading (Prior, Sood, and Khanna 2015; Bullock and Lenz 2019). Perhaps Democrats believed that voting machines would be hacked or perhaps they exaggerated such risks given widespread rumors about the 2016 election. Similarly, perhaps Republicans believed that Russia is less of a threat or perhaps more sophisticated Republicans downplayed Russian cyber capabilities to defend their \"team\" against Democratic attacks. Determining the mechanisms producing such polarization can therefore help illuminate the depth and significance of that polarization.\n\n## Hypotheses\n\nWe test several hypotheses to explore what mechanisms affect attribution, produce polarization, and link attribution and support for retaliation.\n\nThe first hypothesis concerns the role of independent endorsers. Real-world debates over attributions feature fierce disagreements among experts and intelligence\n\n¹ Canada was included as a check against straightlining or other forms of inattentiveness or malicious responses, although it is possible some respondents view its latent power with alarm.\n\n² Throughout, we count independents who lean toward one party as belonging to that party (Petrocik 2009). Reclassifying leaners as independents does not affect our substantive findings.",
    "Cheerleading in Cyberspace\n\n# OLS Coefficients\n\n![img-0.jpeg](img-0.jpeg)\n\n![img-1.jpeg](img-1.jpeg)\n\n![img-2.jpeg](img-2.jpeg)\nFigure 1. Partisanship and cyber threat perception.\n\n![img-3.jpeg](img-3.jpeg)\n\nagencies (Egloff 2019). Although the US government named the North Korean government as responsible for hacking Sony studios, for example, many experts long considered plausible an alternative theory that blamed disgruntled employees rather than Pyongyang (Fritz 2018). As Guisinger and Saunders (2017) argue, on issues in which the public is not already polarized, endorsements from independent experts should result in attitudinal shifts toward an agreement with experts regardless of the partisan affiliation of respondents.\n\nHypothesis 1: Independent endorsements of attribution claims will increase public confidence in such claims.\n\nOut-partisans may be skeptical of endorsements from any actor tied to a political party, including intelligence agencies, in which case we would expect treatment heterogeneity depending on partisan affinity and cue giver identity.\n\nHypothesis 2: Democrats will be persuaded more by evaluations provided by nonpartisan sources than by evaluations provided by Republican political figures.",
    "MARCELO LEAL AND PAUL MUSGRAVE\n\nOur next hypothesis concerns the relationship between attribution and retribution. It seems intuitive that willingness to support a retaliatory action would depend upon confidence in assessments of attribution for responsibility, which we formalize as:\n\nHypothesis 3: Endorsements of attribution claims will increase support for retaliatory strikes.\n\nHypothesis 3a: Democrats will support retaliation more when a Republican figure's attribution claim is backed up by a nonpartisan source.\n\nBecause intelligence agencies play a major role in attribution, we test factors related to their role through our second hypothesis. Even though a government's choice of when to publicly attribute an attack may be strategic (Edwards et al. 2017), we are interested in the consequences of such an attribution once it has been made. In particular, we seek to ascertain whether claims made by intelligence agencies affect public opinion and whether they do so more or less strongly than independent experts. Because we are interested in the public's evaluation, we state this hypothesis as being conditional on an intelligence agency already having been called upon to publicly state its belief, leading to Hypothesis 4:\n\nHypothesis 4: Increasing levels of certainty in intelligence agencies' evaluation of attribution claims will increase public confidence.\n\n## Experiment 1: Iran Treatment\n\nTo discern what mechanism or mechanisms are producing these patterns of polarization, and to explore the mechanisms at work producing public opinion more broadly, we turn to experimental methods. In the post-election CCES survey (November 2018; $n = 874$), the same respondents who answered the pre-election wave questions (minus attrition) read a vignette about a hypothetical attack on US critical infrastructure:\n\nAs you may know, cyberattacks are attacks on computer systems using software and the Internet. Imagine that a severe cyberattack on US power companies has caused billions of dollars in losses to the US economy. President Trump has asserted that the attack was carried out by the government of Iran. [TREATMENT 1] [TREATMENT 2] the president's assessment that the government of Iran was involved.³\n\nFor half of the respondents, Treatment 1—the identity of the cue givers—was randomly provided as \"US intelligence officials in the CIA and National Security Agency\"; for the other half, the cue givers were identified as \"independent cybersecurity experts\". We varied the strength of the cue in Treatment 2. For half of the respondents, Treatment 2 was assigned to be \"agree with\"; for the other half, it was \"are divided over whether\". This treatment reflects a more direct test of the effect of endorsements than earlier work. Kreps and Das (2017), for example, test how confidence in assessments affects respondents' willingness to carry out retributive strikes. Their treatment, however, was limited to varying whether the alleged culprit was \"probably\" or \"almost certainly\" responsible. Varying the identity of cue givers and presenting a wider range in the level of confidence allows us to examine these factors more directly.\n\nRespondents rated how confident they were of Iran's responsibility from 0 (\"certainly not involved\") to 10 (\"certainly involved\") and 598 respondents completed the experiment. Figure 2 presents coefficient estimates from OLS regressions of core factors regarding confidence in attribution. (Full results are available in the\n\n³Given the polarized nature of US contemporary politics, we believe that stating the president's name rather than leaving it unspecified provides firmer external validity for the time period in which the experiment was administered. Some evidence suggests these worries are overblown (Evers, Fisher, and Schaaf 2019), but erring on the side of specificity seemed wiser to ensure treatment consistency.",
    "Cheerleading in Cyberspace\n\n![img-4.jpeg](img-4.jpeg)\nFigure 2. Factors influencing confidence in attribution of cyberattack to Iran.\n\nonline appendix.) The core test here concerns Hypothesis 1 and the role of independent endorsers. Respondents of all partisan affiliations responded similarly to a supportive endorsement of Trump's claims, while there were no significant differences based upon the cue giver identity. In line with Guisinger and Saunders's (2017) argument, this suggests lower levels of polarization as partisans responded similarly to the treatment. Because responses do not significantly differ according to cue giver identity (intelligence or independent), there is no evidence in these results consistent with Hypothesis 2, regarding partisan differences in evaluations of cue giver source.\n\nTo test Hypothesis 3, the attribution-retribution link, respondents were then informed that Trump proposed that the United States should carry out retaliatory cyberattacks against the electrical power grid in Iran, a response exactly proportional to the original (putatively) Iranian cyberattack. Respondents were asked if they supported, did not support, or were unsure if they supported such strikes. Examining the raw data revealed that the most significant changes in responses came not from between-subjects changes in the frequency of respondents selecting approve/don't approve but from among \"approve\", \"don't approve\", and \"don't know\". Accordingly, modeling responses as trichotomous rather than dichotomous seemed appropriate, and so we model responses using multinomial logistic regression.\n\nFigure 3 displays the core results of the experiment. Because multinomial logistic results can be difficult to interpret, we display our results as predicted support for respondents choosing to support or to express \"don't know\" (the base outcome category is \"does not support\") based upon treatment category. Overall, as the top three figures demonstrate, support increases for retaliation by about 5 percentage points in the supportive treatment, while opposition falls by about 8.6 percentage points. The percentage of respondents predicted to respond \"don't know\", however, increases by about 3.8 percentage points in the supportive compared to the divided treatments.\n\nThe story becomes more complicated when we examine results by partisan affiliation. As might be intuitive, Independents respond to the supportive treatment",
    "MARCELO LEAL AND PAUL MUSGRAVE\n\n![img-5.jpeg](img-5.jpeg)\n2018 CCES Experiment; Multinomial logistic regression\n\n![img-6.jpeg](img-6.jpeg)\n\n![img-7.jpeg](img-7.jpeg)\n\n![img-8.jpeg](img-8.jpeg)\n\n![img-9.jpeg](img-9.jpeg)\n\n![img-10.jpeg](img-10.jpeg)\n\n![img-11.jpeg](img-11.jpeg)\n\n![img-12.jpeg](img-12.jpeg)\n\n![img-13.jpeg](img-13.jpeg)\n\n![img-14.jpeg](img-14.jpeg)\nFigure 3. Predicted support for retaliation by party and outcome variable.\n\n![img-15.jpeg](img-15.jpeg)\n\n![img-16.jpeg](img-16.jpeg)\n\ncategory by substantially increasing support for retaliation. Republicans remain unchanged regardless of the treatment category. Democrats, perhaps surprisingly, respond to the presence of a supportive endorsement of Trump's attribution claims by shifting from \"would not support\" to \"don't know\".",
    "Cheerleading in Cyberspace\n\nThis finding has complex implications. Hypothesis 3 predicts that endorsements of attribution claims will increase support for retaliation. Although this was true in the aggregate, the pattern of partisan responses suggests that non-independent partisans responded in ways consonant with partisan cheerleading, leading us to conclude that a more complicated mechanism was at work in this part of the experiment than in the first half. Strictly speaking, we disconfirm Hypothesis 3a (that Democrats would support retaliation more when supported by an independent endorsement), but our findings suggest that Democrats are, nevertheless, changing their minds. Bearing in mind Bullock and Lenz's (2019) admonition that partisan cheerleading can be difficult to measure, Democrats, essentially, choose to hide behind \"don't know\" rather than support a Trump policy proposal. Our findings further suggest that tests of the attribution-retaliation link must consider the possibility that direct measurements may be biased by partisan cheerleading, which would require more explicit testing to fully explain.\n\nThese results point to several conclusions. First, we confirm that attribution is political, as Schulzke (2018) and others have argued. Focusing on technical aspects oversimplifies this challenge. Second, our evidence supports claims that endorsements can bolster public confidence, even among Democrats and Independents asked to evaluate a claim by President Trump. Third, attribution confidence seems more elastic than support for retribution. These results are too ambiguous to warrant throwing out the link between attribution and retaliation, but they do suggest that the link may not be intuitively straightforward and that measurements might be biased by other mechanisms, including cheerleading.\n\nThis effect may be limited to the Trump presidency. Future work can establish whether there was something unique about the Trump administration that generated these partisan dynamics. However, we should hesitate before ascribing all of this effect to the 45th president. A \"credibility gap\" is hardly new—consider Lyndon Johnson and Vietnam. Polarization antedates Trump as well. If mistrust of out-party presidents is an enduring feature of polarized politics, then such doubts will play an enduring role in evaluations of claims that rest on credence.\n\n## Experiment 2: Conjoint Experiment\n\nExperiment 1 has many advantages over existing work, but any vignette experiment suffers from limitations, not least from restrictions on the number of factors that can be varied. To test our hypotheses more fully, we turn to an alternative experimental design: conjoint analysis.\n\nConjoint experiments, increasingly popular in studies of foreign policy (Clary and Siddiqui 2021; Escriba-Folch, Muradova, and Rodon 2021), enable the simultaneous manipulation of many factors in a manner that more closely resembles real-world tasks (Hainmueller, Hopkins, and Yamamoto 2014). Real-world validation suggests that conjoint experiments also perform well in predicting respondents' real-world choices (Hainmueller, Hangartner, and Yamamoto 2015). Furthermore, conjoint experiments perform well even when many tasks and factors are presented to respondents (Bansak et al. 2018, 2019). These advantages allowed us to incorporate many additional factors that would be relevant to the public's judgment of hypothetical scenarios that could have been included in experiments such as the one we fielded on CCES.\n\nWe fielded a paired-rating conjoint experiment to investigate how the public judges attribution on Amazon's Mechanical Turk platform in two waves between March 24 and April 20, 2019. Wave 1 measured demographics and baseline\n\n8 The multi-wave design allowed us to mitigate pre-treatment bias, ensure respondent quality by screening for consistency across waves on answers to questions such as educational attainment and age, and ask more questions than would have been possible in a single questionnaire.",
    "MARCELO LEAL AND PAUL MUSGRAVE\n\nattitudes, including threats and vulnerabilities as measured in the CCES. There were 2,031 respondents for this wave, for which respondents were compensated $0.75. We recruited 1,354 respondents from the first wave to complete the second wave, which contained the experiment and for which respondents were compensated $1. A total of 1,233 respondents who passed data integrity checks completed ratings of 10 profiles each for a total N of 12,330 completed tasks.\n\nAfter completing a pair of nonrandomized training scenarios, respondents were presented with conjoint profiles. Each profile described a hypothetical cyberattack. Among the treatments was an intelligence community assessment of the identity of the perpetrator of the cyberattack. Respondents were asked to evaluate how confident they were in the intelligence community's assessment of responsibility for each attack on a 0-100 scale. (The online appendix contains the full list of conjoint factors and levels as well as a sample conjoint profile.) We included many factors to ensure that respondents did not make varying judgments about what our core factors of interest implied about the scenario. Other factors included manipulations of the severity of the attacks, the motivation, and the identity of the attacker. Our interest in studying attribution with respect to these issues was to explore whether there is a substantively significant link between such characteristics and attribution claims.\n\nWe are most interested in the factors relating to how external endorsers and political factors affect respondents' assessments of attribution claims. These included many factors that have been found relevant in judging the use of force, a closely related topic, including losses (particularly the level of deaths) sustained by the United States (Gartner 2008) and the identity and motivation of the attacker (Huff and Kertzer 2018).\n\nThe first of these key factors is the effects of endorsements by independent computer security experts, which range from agreement to rejection—a wider range than either our previous experiment or experiments such as Kreps and Das (2017). Doing so allows us to more finely test Hypothesis 1. We also test Hypothesis 2 more directly by varying whether a nonpolitical figure (Secretary of Defense Patrick Shanahan, the then-incumbent Pentagon chief—a relatively nonpolitical, even unknown figure) or President Trump is named as the government cue giver. The conjoint methodology thereby allows us to more finely disaggregate intelligence, independent, and official sources, going far beyond earlier works' tests of cue giver identities. We also allow officials and experts to not only endorse but to reject such claims, again going beyond earlier work. Finally, we test Hypothesis 4 related to the intelligence community's confidence level. By design, this experiment required the intelligence community to present an attribution claim, compared with the first experiment, in which the intelligence community evaluated a presidential attribution claim. Thus, this factor ranges from \"unanimously confident\" to \"highly confident but not certain\" to \"somewhat certain\", as it seemed unrealistic to have the intelligence community issue an assessment that they were not confident in.\n\nFigure 4 displays the core results of the overall conjoint analysis. Independent endorsements of attribution claims are statistically and substantively meaningful, in line with the expectations of Hypothesis 1. A shift from experts disputing the intelligence community's assessment to having mixed views produces an increase of 7.4 points, almost as large an effect as the maximum shift in the intelligence community's confidence. When independent experts mostly agree with the intelligence community's assessment (the maximum level of confidence), there is a further 8.2 point increase in confidence—a total shift of 15.6 points. If the Defense Secretary is included as an independent (in the political sense) endorsement by\n\n7 A small number of implausible scenarios were excluded; see the online appendix for details.\n\n8 Shanahan was recognized by only 10 percent of respondents in a poll fielded soon after our experiment, compared to 47 percent name recognition for Secretary of State Michael Pompeo (Relman and Hickey 2019).",
    "Cheerleading in Cyberspace\n\n![img-17.jpeg](img-17.jpeg)\nFigure 4. OLS coefficients for respondents' confidence in attribution.\n\ncomparison with the president, it is notable that there is a smaller but significant increase of about 3.7 points for an endorsement from Secretary of Defense Shanahan (compared to disputing the intelligence community's claim) and only 1.5 points for President Trump's endorsement (again, compared to disputing it).\n\nSimilarly, Hypothesis 4 receives support, as a movement in the intelligence community's expressed confidence from somewhat confident to unanimously confident produced an increase in confidence of 8.9 points on the 100-point scale.\n\nTo test Hypothesis 2, we disaggregate results by party in Figure 5. Increasing intelligence community confidence has a larger effect on Democrats than on Republicans, although supporters of both parties respond similarly to independent computer security experts' shifts in confidence. Furthermore, whereas an endorsement from Shanahan or Trump produces a 3.7 point increase for Republicans' confidence, an endorsement from Shanahan increases Democratic confidence by 3.6 points, while one from Trump increases Democrats' confidence by only 1 point when the interaction term between cue giver identity and endorsement is taken into account.\n\nNotably, some factors not obviously associated with attribution proved to be statistically significant. Increased severity of attacks—in either dollars or deaths—was",
    "MARCELO LEAL AND PAUL MUSGRAVE\n\n![img-18.jpeg](img-18.jpeg)\nFigure 5. OLS coefficients for respondents' confidence in attribution, by party ID.\n\nassociated with increased confidence in attribution assessments. The effect sizes are small, but they are consistent: all else equal, respondents were slightly more likely to believe the intelligence community's assessment when the losses were higher. This is an unexpected mechanism, albeit potentially consistent with the model in Lindsay (2015) that suggests that it is easier to deter major cyberattacks than minor ones.\n\nThe conjoint experiment puts our earlier findings into higher resolution. Respondents' confidence in attribution findings is influenced by the intelligence community's own confidence but even more so by the views of independent computer security experts. The effect of intelligence community and other nonpartisan endorsers was generally greater for Democrats than for Republicans. The scale of these effects tends to fall in line with the comparable findings in our earlier experiment, and the differences between the two are explainable by the much larger  $N$  and greater sensitivity of the second experiment. Furthermore, the second experiment suggests that, although partisan cheerleading is present (as with the results on the Trump endorsements), respondents are nevertheless willing to abandon cheerleading when given other evidence.\n\n# Discussion and Conclusion\n\nThe public's confidence in attribution claims depends upon who sends the message, who endorses it, and the beliefs of those who receive it. In particular, independent experts influence the public's confidence in attribution to a much greater degree than current theorizing might suggest. Theories of attribution and",
    "Cheerleading in Cyberspace\n\nretaliation should consider who is sending what signals about attribution claims, and what that might entail for the credibility of deterrent effects or how to convince key audiences of the details of an attribution claim.\n\nPartisanship, however, may do less to shape opinions about attribution at a fundamental level than the conventional wisdom might suggest. Our results suggest that superficial polarization may reflect instead expressive behavior—cheerleading, rather than filtering. Finding that public opinion regarding cyberattack attribution is not hopelessly polarized is good news. Trusted outsiders and government agencies may be able to correct for partisan biases in public opinion.\n\nDespite this potentially optimistic note, we must note reasons for caution. Our survey data demonstrate that partisan splits exist in the real world, even if they are focused on particular issues. That suggests that de-polarizing mechanisms are either not at work in the world or that they are being overwhelmed by polarizing mechanisms. Perhaps the substantive import of our findings will prove limited to the Trump era. Perhaps not. These ambivalent findings lead us to conclude that more research may be necessary to understand the problem. Yet given the nature of the split being investigated, we should also acknowledge that knowing what mechanisms are at work may not guarantee the ability to solve the problem.\n\n# References\n\nANSOLABEHERE, STEPHEN, MARC MEREDITH, AND ERIK SNOWBERG. 2013. \"Asking about Numbers: Why and How.\" Political Analysis 21 (1): 48-69.\nBANSAK, KIRK, JENS HAINMUELLER, DANIEL J. HOPKINS, AND TEPEI YAMAMOTO. 2018. \"The Number of Choice Tasks and Survey Satisficing in Conjoint Experiments.\" Political Analysis 26 (1): 112-19.\n——. 2019. \"Beyond the Breaking Point? Survey Satisficing in Conjoint Experiments.\" Political Science Research and Methods 9 (1): 53-71.\nBORGHARD, ERICA D., AND SHOWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" Security Studies 26 (3): 452-81.\nBULLOCK, JOHN G., ALAN S. GERBER, SETH J. HILL, AND GREGORY A. HUBER. 2015. \"Partisan Bias in Factual Beliefs about Politics.\" Quarterly Journal of Political Science 10 (4): 519-78.\nBULLOCK, JOHN G., AND GABRIEL LENZ. 2019. \"Partisan Bias in Surveys.\" Annual Review of Political Science 22 (1): 325-42.\nCAVARI, AMNON, AND GUY FREEDMAN. 2019. \"Partisan Cues and Opinion Formation on Foreign Policy.\" American Politics Research 47 (1): 29-57.\nCLARK, DAVID D., AND SUSAN LANDAU. 2011. \"Untangling Attribution.\" Harvard National Security Law Journal 2: 323.\nCLARY, CHRISTOPHER, AND NILOUFER SIDDIQUI. 2021. \"Voters and Foreign Policy: Evidence from a Conjoint Experiment in Pakistan.\" Foreign Policy Analysis 17 (2): orab001.\nEDWARDS, BENJAMIN, ALEXANDER FURNAS, STEPHANIE FORREST, AND ROBERT AXELROD. 2017. \"Strategic Aspects of Cyberattack, Attribution, and Blame.\" Proceedings of the National Academy of Sciences 114 (11): 2825-30.\nEGLOFF, FLORIAN J. 2019. \"Contested Public Attributions of Cyber Incidents and the Role of Academia.\" Contemporary Security Policy 41 (1): 55-81.\nESCRIBA-FOLCH, ABEL, LALA H. MURADOVA, AND TONI RODON. 2021. \"The Effects of Autocratic Characteristics on Public Opinion toward Democracy Promotion Policies: A Conjoint Analysis.\" Foreign Policy Analysis 17 (1): oraa016.\nEVERS, MILES M., ALEKSANDR FISHER, AND STEVEN D. SCHAAF. 2019. \"Is There a Trump Effect? An Experiment on Political Polarization and Audience Costs.\" Perspectives on Politics 17 (2): 433-52.\nFOYLE, DOUGLAS. 2017. \"Public Opinion and Foreign Policy.\" Oxford Research Encyclopedia of Politics. 22 Aug. 2017; Accessed January 29, 2022. https://oxfordre.com/politics/view/10.1093/acrefore/9780190228637.001.0001/acrefore-9780190228637-e-472.\nFRITZ, BEN. 2018. The Big Picture: The Fight for the Future of Movies. Boston, MA: Houghton Mifflin Harcourt.\nGAINES, BRIAN J., JAMES H. KUKLINSKI, PAUL J. QUIRK, BUDDY PEYTON, AND JAY VERKUILEN. 2007. \"Same Facts, Different Interpretations: Partisan Motivation and Opinion on Iraq.\" The Journal of Politics 69 (4): 957-74.\nGARTNER, SCOTT SIGMUND. 2008. \"The Multiple Effects of Casualties on Public Support for War: An Experimental Approach.\" American Political Science Review 102 (1): 95-106.",
    "MARCELO LEAL AND PAUL MUSGRAVE\n\nGERBER, ALAN S., AND GREGORY A. HUBER. 2009. \"Partisanship and Economic Behavior: Do Partisan Differences in Economic Forecasts Predict Real Economic Behavior?\" American Political Science Review 103 (3): 407-26.\n\nGOMEZ, MIGUEL ALBERTO, AND CHRISTOPHER WHITE. 2021. \"Breaking the Myth of Cyber Doom: Securitization and Normalization of Novel Threats.\" International Studies Quarterly 65 (4): 1137-1150.\n\nGROSS, MICHAEL L., DAPHNA CANETTI, AND DANA R. VASHIDI. 2017. \"Cyberterrorism: Its Effects on Psychological Well-Being, Public Confidence and Political Attitudes.\" Journal of Cybersecurity 3 (1): 49-58.\n\nGUISINGER, ALEXANDRA, AND ELIZABETH N. SAUNDERS. 2017. \"Mapping the Boundaries of Elite Cues: How Elites Shape Mass Opinion across International Issues.\" International Studies Quarterly 61 (2): 425-41.\n\nHAINHUELLER, JENS, DOMINIK HANGARTNER, AND TEPEI YAMAMOTO. 2015. \"Validating Vignette and Conjoint Survey Experiments against Real-World Behavior.\" Proceedings of the National Academy of Sciences 112 (8): 2395-2400.\n\n——. 2014. \"Causal Inference in Conjoint Analysis: Understanding Multidimensional Choices via Stated Preference Experiments.\" Political Analysis 22 (1): 1-30.\n\nHARKNETT, RICHARD J., AND JOSEPH S. NYE, JR. 2017. \"Is Deterrence Possible in Cyberspace?\" International Security 42 (2): 196-99.\n\nHUFF, CONNOR, AND JOSHUA D. KERTZER. 2018. \"How the Public Defines Terrorism.\" American Journal of Political Science 62 (1): 55-71.\n\nIPSOS. 2018. \"Ipsos/Reuters Poll Data about Russian Interference from 7/18/2018.\" Ipsos. Accessed January 28, 2022. https://www.ipsos.com/sites/default/files/ct/news/documents/2018-07/2018_reuters_tracking_rusia_7_18_2018.pdf.\n\nJENSEN, BENJAMIN M., AND BRANDON VALERIANO. 2019. \"What Do We Know about Cyber Escalation? Observations from Simulations and Surveys.\" Atlantic Council, Washington, DC. Accessed January 28, 2022. https://www.atlanticcouncil.org/in-depth-research-reports/issue-brief/what-do-we-know-about-cyber-escalation-observations-from-simulations-and-surveys/.\n\nJERIT, JENNIFER, AND JASON BARABAS. 2012. \"Partisan Perceptual Bias and the Information Environment.\" The Journal of Politics 74 (3): 672-84.\n\nKOSTYUK, NADIYA, AND CARLY WHINE. 2021. \"The Microfoundations of State Cybersecurity: Cyber Risk Perceptions and the Mass Public.\" Journal of Global Security Studies 6 (2): ogz077.\n\nKREPS, SARAH, AND DEBAK DAS. 2017. \"Warring from the Virtual to the Real: Assessing the Public's Threshold for War over Cyber Security.\" Research &amp; Politics 4 (2): 205316801771593. Accessed January 28, 2022. https://doi.org/10.1177/2053168017715930.\n\nKREPS, SARAH, AND JACQUELYN SCHNEIDER. 2019. \"Escalation Firebreaks in the Cyber, Conventional, and Nuclear Domains: Moving beyond Effects-Based Logics.\" Journal of Cybersecurity 5 (1): tyz007.\n\nLEE, MARY. 2019. \"Trump's Cyber Workforce Order Gets Bipartisan Praise.\" *Politico*, May 3, 2019. Accessed January 28, 2022. https://politi.co/2DMj8MN.\n\nLINDSAY, JON R. 2015. \"Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence against Cyberattack.\" Journal of Cybersecurity 1 (1): 53-67.\n\nLIN-GREENBERG, ERIK. 2021. \"Soldiers, Pollsters, and International Crises: Public Opinion and the Military's Advice on the Use of Force.\" Foreign Policy Analysis 17 (3): orab009.\n\nLYNN, WILLIAM F. 2010. \"Defending a New Domain-the Pentagon's Cyberstrategy.\" Foreign Affairs 89: 97.\n\nMASON, LILLIANA. 2018. Uncivil Agreement: How Politics Became Our Identity. Chicago, IL: University of Chicago Press.\n\nMUSGRAVE, PAUL. 2019. \"International Hegemony Meets Domestic Politics: Why Liberals Can Be Pessimists.\" Security Studies 28 (3): 451-478.\n\nPETERSON, ERIK, AND SHANTO IYENGAR. 2021. \"Partisan Gaps in Political Information and Information-Seeking Behavior: Motivated Reasoning or Cheerleading?\" American Journal of Political Science 65 (1): 133-47.\n\nPETROCIK, JOHN RICHARD. 2009. \"Measuring Party Support: Leaners Are Not Independents.\" *Electoral Studies* 28 (4): 562-72.\n\nPRIOR, MARKUS, GAURAV SOOD, AND KABIR KHANNA. 2015. \"You Cannot be Serious: The Impact of Accuracy Incentives on Partisan Bias in Reports of Economic Perceptions.\" Quarterly Journal of Political Science 10: 489-518.\n\nRELMAN, ELIZA, AND WALT HICKEY. 2019. \"Alexandria Ocasio-Cortez More Famous Than Top Republicans, Trump Cabinet.\" Business Insider, March 12, 2019. Accessed January 28, 2022. https://www.businessinsider.com/alexandria-ocasio-cortez-more-famous-than-top-republicans-trump-cabinet-2019-3.\n\nRID, THOMAS, AND BEN BUCHANAN. 2015. \"Attributing Cyber Attacks.\" Journal of Strategic Studies 38 (1-2): 4-37.\n\nROBBETT, ANDREA, AND PETER HANS MATTHEWS. 2018. \"Partisan Bias and Expressive Voting.\" Journal of Public Economics 157: 107-20.",
    "Cheerleading in Cyberspace\n\nRovner, Joshua. 2011. Fixing the Facts: National Security and the Politics of Intelligence. New York: Cornell University Press.\nSaunders, Kyle L., and Alan I. Abramowitz. 2008. \"Is Polarization a Myth?\" The Journal of Politics 70: 542–55.\nSchulzke, Marcus. 2018. \"The Politics of Attributing Blame for Cyberattacks and the Costs of Uncertainty.\" Perspectives on Politics 16 (4): 954–68.\nTomz, Michael, Jessica LP Weeks, and Keren Yarhi-Milo. 2020. \"Public Opinion and Decisions about Military Force in Democracies.\" International Organization 74 (1): 119–43.\nZaller, John R. 1992. The Nature and Origins of Mass Opinion. Cambridge: Cambridge University Press."
  ],
  "metadata": {
    "title": "Foreign Policy Analysis (2022), orac003",
    "subtitle": "# Cheerleading in Cyberspace: How the American Public Judges Attribution Claims for Cyberattacks",
    "document_type": "journal_article",
    "venue": "© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association.",
    "publication_year": 2022,
    "authors": [
      "MARCELO LEAL",
      "PAUL MUSGRAVE",
      "Cheerleading in Cyberspace"
    ],
    "affiliations": [
      "University of Massachusetts Amherst, USA",
      "© The Author(s) (2022). Published by Oxford University Press on behalf of the International Studies Association."
    ],
    "emails": [
      "journals.permissions@oup.com"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1093/fpa/orac003",
        "10.1093/acrefore/9780190228637.001.0001/acrefore-9780190228637-e-472",
        "10.1177/2053168017715930"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "https://doi.org/10.1093/fpa/orac003"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 45,
    "heading_count": 10,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 28,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 1.0,
      "unique_index_count": 25
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "author_year",
      "recommended_style": "unknown",
      "aligned": true,
      "signals": {
        "superscript_hits": 6,
        "superscript_definition_lines": 2,
        "numeric_bracket_hits": 0,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 91.0,
      "dominant_bib_coverage_rate": 0.27472527472527475,
      "dominant_link_target": "bibliography",
      "dominant_unresolved_flag": "unresolved_reference_links"
    },
    "heading_validation": {
      "heading_count": 10,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": true,
        "orcids": false,
        "abstract": false,
        "keywords": false,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 3,
        "affiliations": 2,
        "emails": 1,
        "orcids": 0,
        "keywords": 0,
        "doi": 3,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 1
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_abstract_and_keywords",
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "low_bib_coverage",
      "meta_missing_abstract_and_keywords",
      "meta_low_email_author_link_rate"
    ]
  },
  "citation_summary": {
    "style": "author_year",
    "dominant_bucket": "author_year",
    "dominant": {
      "intext_total": 28.0,
      "success_occurrences": 28.0,
      "success_unique": 25.0,
      "bib_unique_total": 91.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.27472527472527475,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "author_year"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 28.0,
        "success_occurrences": 28.0,
        "success_unique": 25.0,
        "bib_unique_total": 91.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.27472527472527475,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:25:49.334445+00:00"
}