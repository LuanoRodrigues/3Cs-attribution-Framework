{
  "full_text": "Journal of Military Ethics\nIRRutledge Taylor &amp; Francis Group\nISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20\n# Ethics and Cyber Conflict: A Response to JME 12:1 (2013)\nGeorge R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012\nTo link to this article: https://doi.org/10.1080/15027570.2014.908012\nPublished online: 08 May 2014.\nSubmit your article to this journal ☐\nArticle views: 792\nView related articles ☐\nView Crossmark data ☐\nFull Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20\n# ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013)\nGeorge R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA\nThis article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense\n# Introduction\nContributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual' (Tallinn 2012), which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014\nVol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012\nThis work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group\nThe special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n## Prior Essays in JME on Ethics and Cyber War\nCyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\nLikewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)\nWith cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue (Cook 2010). There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and\nspace, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.\n## Recent Contributions to Ethics and Cyber Warfare\nMany of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing\nattack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424 (Lucas 2014), tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that\nETHICS AND CYBER CONFLICT\nthere is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations\nand even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy (DoD 2011) threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as\na deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable\nIranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago (Lucas 2011) that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a\nETHICS AND CYBER CONFLICT\ncyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays.",
  "flat_text": "Journal of Military Ethics IRRutledge Taylor &amp; Francis Group ISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20 # Ethics and Cyber Conflict: A Response to JME 12:1 (2013) George R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012 To link to this article: https://doi.org/10.1080/15027570.2014.908012 Published online: 08 May 2014.\nSubmit your article to this journal ☐ Article views: 792 View related articles ☐ View Crossmark data ☐ Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20 # ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013) George R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA This article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense # Introduction Contributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual', which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014 Vol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012 This work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group The special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n## Prior Essays in JME on Ethics and Cyber War Cyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\nLikewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)\nWith cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue. There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and space, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.\n## Recent Contributions to Ethics and Cyber Warfare Many of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing attack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424, tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that ETHICS AND CYBER CONFLICT there is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations and even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as a deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable Iranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a ETHICS AND CYBER CONFLICT cyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays.",
  "toc": [
    [
      1,
      "__preamble__"
    ],
    [
      1,
      "## Prior Essays in JME on Ethics and Cyber War Cyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war."
    ],
    [
      1,
      "## Recent Contributions to Ethics and Cyber Warfare Many of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict."
    ]
  ],
  "sections": {
    "__preamble__": "Journal of Military Ethics IRRutledge Taylor &amp; Francis Group ISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20 # Ethics and Cyber Conflict: A Response to JME 12:1 (2013) George R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012 To link to this article: https://doi.org/10.1080/15027570.2014.908012 Published online: 08 May 2014.\nSubmit your article to this journal ☐ Article views: 792 View related articles ☐ View Crossmark data ☐ Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20 # ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013) George R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA This article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense # Introduction Contributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual', which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014 Vol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012 This work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group The special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.",
    "## Prior Essays in JME on Ethics and Cyber War Cyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.": "Likewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)\nWith cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue. There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and space, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.",
    "## Recent Contributions to Ethics and Cyber Warfare Many of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.": "Two of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing attack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424, tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that ETHICS AND CYBER CONFLICT there is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations and even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as a deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable Iranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a ETHICS AND CYBER CONFLICT cyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays."
  },
  "process_log": {
    "scheme": "markdown",
    "numeric_check": {
      "first_num": null,
      "raw_count": 0,
      "raw_examples": [],
      "filtered_count": 0,
      "filtered_examples": [],
      "seq_score": 0.0
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0
    },
    "toc_count": 2,
    "section_count": 3
  },
  "word_count": 5581,
  "references": [
    "# REFERENCES\nArquilla, John. (1999) Ethics and Information Warfare, in: Z. Khalilzad, J. White &amp; A. Marshall (Eds), The Changing Role of Information in Warfare, pp. 379-401 (Santa Monica, CA: RAND Corporation).\nArquilla, John. (2010) Conflict, Security, and Computer Ethics, in: Luciano Floridi (Ed), Cambridge Handbook of Information and Computer Ethics, pp.133-149 (New York: Cambridge University Press).\nArquilla, John. (2012) Cyber War is Already upon Us, Foreign Policy, March-April; accessed 2 April 2014, available at: http://www.foreignpolicy.com/articles/2012/02/27/cyberwar_is_already_upon_us; Internet.\nArquilla, John &amp; Ronfeldt, David. (1993) Cyberwar is Coming!, Comparative Strategy, 12(2), pp. 141-165.\nCook, James. (2010) 'Cyberation' and Just War Doctrine: A Response to Randall Dipert, Journal of Military Ethics, 9(4), pp. 411-423.\nDipert, Randall R. (2010) The Ethics of Cyber Warfare, Journal of Military Ethics, 9(4), pp. 384-410.\nDipert, Randall R. (2013) The Essential Features for an Ontology for Cyberwarfare, in: Panayotis A. Yannakogeorgos &amp; Adam B. Lowther (Eds), Conflict and Cooperation in Cyberspace, pp. 35-48 (Boca Raton, FL: Taylor &amp; Francis).\nDipert, Randall R. (2014) The Ethics of Information Warfare, in: Luciano Floridi &amp; Mariarosaria Taddeo (Eds), Philosophy of Engineering and Technology: Proceedings of a UNESCO Conference on Ethics &amp; Cyber Security, pp. 25-37 (Amsterdam: Springer).\nDoD (Department of Defense). (2011) US Department of Defense Strategy for Operating in Cyber Space, accessed 2 April 2014, available at: http://www.defense.gov/news/d20110714cyber.pdf; Internet.\nDunlap, Charles J. (2011) Perspectives for Cyber Strategists on Law for Cyberwar, Strategic Studies Quarterly, 5 (Spring), pp. 81-99.\nGraham, David E. (2010) Cyber Threats and the Law of War, Journal of National Security Law, 4(1), pp. 87-102.\nLucas, George R. Jr. (2011) Permissible Preventive Cyberwar: Restricting Cyber Conflict to Justified Military Targets, opening address for a UNESCO-sponsored conference on Cyber War and Ethics at the University of Hertfordshire, 1 July, accessed 2 April 2014, available at: http://www.elac.ox.ac.uk/downloads/Permissible%20Preventive%20Cyberwar%20UNESCO%202011.pdf; Internet. (Also forthcoming in: Luciano Floridi &amp; Mariarosaria Taddeo (Eds), Philosophy of Engineering and Technology: Proceedings of a UNESCO Conference on Ethics &amp; Cyber Security (Amsterdam: Springer).)\nG.R. LUCAS\nLucas, George R. Jr. (2013a) Can There Be an Ethical Cyberwar?, in: A. Panayotis Yannakogeorgos &amp; Adam B. Lowther (Eds), Conflict and Cooperation in Cyberspace, pp. 195–210 (Boca Raton, FL: CRC Press / Taylor and Francis).\nLucas, George R. Jr. (2013b) *Jus in Silico: Moral Restrictions on the Use of Cyber Warfare*, in: Fritz Allhoff, Nicholas G. Evans &amp; Adam Henschke (Eds), *The Routledge Handbook of War and Ethics*, pp. 367–380 (Oxford: Routledge).\nLucas, George R. Jr. (2013c) Emerging Norms for Cyber Warfare. Keynote Address, Conference on Ethics &amp; Cyber Security, Center for Applied Philosophy &amp; Practical Ethics, Australian National and Charles Stuart Universities, Canberra, 5–6 August, accessed 2 April 2014, available at: http://philevents.org/event/show/11114; Internet.\nLucas, George R. Jr. (2013d) Navigation, Aviation, ‘Cyberation’: Developing New Rules of the Road for the Cyber Domain. Inaugural Public Security Lecture, National Security College, Australian National University, Canberra, 7 August, accessed 2 April 2014, available at: http://www.youtube.com/watch?v=cs7RXAPzG84; Internet.\nLucas, George R. Jr. (2014) NSA Management Directive # 424: Secrecy and Privacy in the Aftermath of Snowden, Ethics and International Affairs (6 February), accessed 9 April 2014, available at: http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=9207954; Internet.\nRid, Thomas. (2011) Cyber War Will Not Take Place, The Journal of Strategic Studies, 35(1), pp. 5–32.\nRid, Thomas C. (2012) Cyber War: Think Again, Foreign Policy Magazine, 26 February, pp. 58–61.\nRowe, Neil C. (2007) War Crimes from Cyberweapons, Journal of Information Warfare, 6(3), pp. 15–25.\nRowe, Neil C. (2008) Ethics of Cyber War Attacks, in: Lech J. Janczewski &amp; Andrew M. Colarik (Eds), Cyber Warfare and Cyber Terrorism, pp. 105–111 (Hershey, PA: Information Science Reference).\nRowe, Neil C. (2010) The Ethics of Cyberweapons in Warfare, Journal of Techoethics, 1(1), pp. 20–31.\nRowe, Neil C. (2011) Toward Reversible Cyber Attacks, in: Julie Ryan (Ed), Leading Issues in Information Warfare and Security Research, pp. 145–158 (Reading: Academic Publishing).\nSchmitt, Michael N. (1999) Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework, Columbia Journal of Transnational Law, 37, pp. 885–937.\nSchmitt, Michael N. (2002) Wired Warfare: Computer Network Attack and Jus in Bello, International Review of the Red Cross, 84(846), pp. 365–399.\nSchmitt, Michael N. (2011) Cyber Operations and the Jus in Bello: Key Issues, U.S. Naval War College International Law Studies, 87, pp. 89–110.\nSparrow, Robert. (2007) Killer Robots, Journal of Applied Philosophy, 24(1), pp. 62–67.\nSymantec. (2011) W32.Stuxnet Dossier, by Nicholas Falliere, Liam O. Murchu &amp; Eric Chien (February), accessed 2 April 2014, available at: http://www.symantec.com/content/en/us/enterprise/media/security_response/whitepapers/w32_stuxnet_dossier.pdf; Internet.\nTallinn. (2012) The Tallinn Manual on the International Law Applicable to Cyber Warfare, ed. Michael N. Schmitt (Tallinn: NATO Cooperative Cyber Defence Center of Excellence), accessed 2 April 2014, available at: https://www.ccdcoe.org/249.html; Internet.\nETHICS AND CYBER CONFLICT\nRecently retired from the Distinguished Chair in Ethics in the Vice Admiral James B. Stockdale Center for Ethical Leadership at the U.S. Naval Academy, George Lucas is currently a professor of ethics and public policy at the Graduate School of Public Policy at the Naval Postgraduate School in Monterey, California. His essay on Edward Snowden and NSA cyber surveillance was just published in *Ethics &amp; International Affairs* (28:1), and his book, \"Military Ethics: What Everyone Needs to Know\" is forthcoming from Oxford University Press in 2015, with a foreword by General John R. Allen, USMC (retired). Correspondence address: Naval Postgraduate School, 1 University Cir, Monterey, CA 93943, USA. Email Address: grlucas@nps.edu"
  ],
  "citations": {
    "style": "author_year",
    "flat_text": "Journal of Military Ethics IRRutledge Taylor &amp; Francis Group ISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20 # Ethics and Cyber Conflict: A Response to JME 12:1 (2013) George R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012 To link to this article: https://doi.org/10.1080/15027570.2014.908012 Published online: 08 May 2014.\nSubmit your article to this journal ☐ Article views: 792 View related articles ☐ View Crossmark data ☐ Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20 # ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013) George R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA This article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense # Introduction Contributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual', which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014 Vol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012 This work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group The special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n## Prior Essays in JME on Ethics and Cyber War Cyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\nLikewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)\nWith cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue. There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and space, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.\n## Recent Contributions to Ethics and Cyber Warfare Many of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing attack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424, tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that ETHICS AND CYBER CONFLICT there is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations and even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as a deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable Iranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a ETHICS AND CYBER CONFLICT cyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Journal of Military Ethics\nIRRutledge Taylor &amp; Francis Group\nISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20\n# Ethics and Cyber Conflict: A Response to JME 12:1 (2013)\nGeorge R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012\nTo link to this article: https://doi.org/10.1080/15027570.2014.908012\nPublished online: 08 May 2014.\nSubmit your article to this journal ☐\nArticle views: 792\nView related articles ☐\nView Crossmark data ☐\nFull Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20\n# ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013)\nGeorge R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA\nThis article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense\n# Introduction\nContributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual' (Tallinn 2012), which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014\nVol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012\nThis work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group\nThe special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n## Prior Essays in JME on Ethics and Cyber War\nCyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\nLikewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)\nWith cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue (Cook 2010). There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and\nspace, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.\n## Recent Contributions to Ethics and Cyber Warfare\nMany of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing\nattack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424 (Lucas 2014), tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that\nETHICS AND CYBER CONFLICT\nthere is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations\nand even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy (DoD 2011) threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as\na deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable\nIranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago (Lucas 2011) that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a\nETHICS AND CYBER CONFLICT\ncyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays."
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Journal of Military Ethics\nIRRutledge Taylor &amp; Francis Group\nISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20\n# Ethics and Cyber Conflict: A Response to JME 12:1 (2013)\nGeorge R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012\nTo link to this article: https://doi.org/10.1080/15027570.2014.908012\nPublished online: 08 May 2014.\nSubmit your article to this journal ☐\nArticle views: 792\nView related articles ☐\nView Crossmark data ☐\nFull Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20\n# ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013)\nGeorge R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA\nThis article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense\n# Introduction\nContributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual' (Tallinn 2012), which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014\nVol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012\nThis work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group\nThe special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n## Prior Essays in JME on Ethics and Cyber War\nCyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\nLikewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)\nWith cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue (Cook 2010). There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and\nspace, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.\n## Recent Contributions to Ethics and Cyber Warfare\nMany of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing\nattack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424 (Lucas 2014), tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that\nETHICS AND CYBER CONFLICT\nthere is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations\nand even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy (DoD 2011) threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as\na deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable\nIranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago (Lucas 2011) that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a\nETHICS AND CYBER CONFLICT\ncyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays."
    },
    "author_year": {
      "total": {
        "intext_total": 5,
        "success_occurrences": 5,
        "success_unique": 5,
        "bib_unique_total": 37,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.13513513513513514,
        "success_percentage": 100.0,
        "style": "author_year"
      },
      "results": [
        {
          "index": "tallinn|2012",
          "intext_citation": "(Tallinn 2012)",
          "preceding_text": "Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual'",
          "footnote": "Tallinn. (2012) The Tallinn Manual on the International Law Applicable to Cyber Warfare, ed. Michael N. Schmitt (Tallinn: NATO Cooperative Cyber Defence Center of Excellence), accessed 2 April 2014, available at: https://www.ccdcoe.org/249.html; Internet."
        },
        {
          "index": "cook|2010",
          "intext_citation": "(Cook 2010)",
          "preceding_text": "Col. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue",
          "footnote": "Cook, James. (2010) 'Cyberation' and Just War Doctrine: A Response to Randall Dipert, Journal of Military Ethics, 9(4), pp. 411-423."
        },
        {
          "index": "lucas|2014",
          "intext_citation": "(Lucas 2014)",
          "preceding_text": "But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424",
          "footnote": "Lucas, George R. Jr. (2014) NSA Management Directive # 424: Secrecy and Privacy in the Aftermath of Snowden, Ethics and International Affairs (6 February), accessed 9 April 2014, available at: http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=9207954; Internet."
        },
        {
          "index": "dod|2011",
          "intext_citation": "(DoD 2011)",
          "preceding_text": "This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy",
          "footnote": "DoD (Department of Defense). (2011) US Department of Defense Strategy for Operating in Cyber Space, accessed 2 April 2014, available at: http://www.defense.gov/news/d20110714cyber.pdf; Internet."
        },
        {
          "index": "lucas|2011",
          "intext_citation": "(Lucas 2011)",
          "preceding_text": "But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago",
          "footnote": "Lucas, George R. Jr. (2011) Permissible Preventive Cyberwar: Restricting Cyber Conflict to Justified Military Targets, opening address for a UNESCO-sponsored conference on Cyber War and Ethics at the University of Hertfordshire, 1 July, accessed 2 April 2014, available at: http://www.elac.ox.ac.uk/downloads/Permissible%20Preventive%20Cyberwar%20UNESCO%202011.pdf; Internet. (Also forthcoming in: Luciano Floridi &amp; Mariarosaria Taddeo (Eds), Philosophy of Engineering and Technology: Proceedings of a UNESCO Conference on Ethics &amp; Cyber Security (Amsterdam: Springer).)"
        }
      ],
      "flat_text": "Journal of Military Ethics IRRutledge Taylor &amp; Francis Group ISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20 # Ethics and Cyber Conflict: A Response to JME 12:1 (2013) George R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012 To link to this article: https://doi.org/10.1080/15027570.2014.908012 Published online: 08 May 2014.\nSubmit your article to this journal ☐ Article views: 792 View related articles ☐ View Crossmark data ☐ Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20 # ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013) George R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA This article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense # Introduction Contributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual', which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014 Vol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012 This work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group The special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n## Prior Essays in JME on Ethics and Cyber War Cyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\nLikewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)\nWith cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue. There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and space, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.\n## Recent Contributions to Ethics and Cyber Warfare Many of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing attack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424, tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that ETHICS AND CYBER CONFLICT there is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations and even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as a deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable Iranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a ETHICS AND CYBER CONFLICT cyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays."
    }
  },
  "summary": {
    "full_text": {
      "words": 5591,
      "tokens": 7122
    },
    "flat_text": {
      "words": 5581,
      "tokens": 7062
    }
  },
  "payload": "## __preamble__\n\nJournal of Military Ethics IRRutledge Taylor &amp; Francis Group ISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20 # Ethics and Cyber Conflict: A Response to JME 12:1 (2013) George R. Lucas Jr.\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012 To link to this article: https://doi.org/10.1080/15027570.2014.908012 Published online: 08 May 2014.\nSubmit your article to this journal ☐ Article views: 792 View related articles ☐ View Crossmark data ☐ Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20 # ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013) George R. Lucas, Jr.\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA This article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense # Introduction Contributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual', which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\nJournal of Military Ethics, 2014 Vol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012 This work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\nRoutledge Taylor &amp; Francis Group The special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n\n---\n\n## ## Recent Contributions to Ethics and Cyber Warfare Many of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\n\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing attack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424, tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that ETHICS AND CYBER CONFLICT there is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations and even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as a deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable Iranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a ETHICS AND CYBER CONFLICT cyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays.",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:PARTIAL_BODY\nsections_raw:3\nsections_clean:3\nintro:FOUND\nconclusion:FOUND\npredefined_sections:None\nextra_sections:None\npayload_tokens_before:7131\npayload_tokens_after:5560\ndropped_section:## Prior Essays in JME on Ethics and Cyber War Cyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\nadded_section:None\n---LOG_SUMMARY_END---",
  "pages_text": [
    "Journal of Military Ethics\nIRRutledge Taylor &amp; Francis Group\nISSN: 1502-7570 (Print) 1502-7589 (Online) Journal homepage: www.tandfonline.com/journals/smil20\n\n# Ethics and Cyber Conflict: A Response to JME 12:1 (2013)\n\nGeorge R. Lucas Jr.\n\nTo cite this article: George R. Lucas Jr. (2014) Ethics and Cyber Conflict: A Response to JME 12:1 (2013), Journal of Military Ethics, 13:1, 20-31, DOI: 10.1080/15027570.2014.908012\n\nTo link to this article: https://doi.org/10.1080/15027570.2014.908012\n\nPublished online: 08 May 2014.\n\nSubmit your article to this journal ☐\n\nArticle views: 792\n\nView related articles ☐\n\nView Crossmark data ☐\n\nFull Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=smil20",
    "# ETHICS AND CYBER CONFLICT A RESPONSE TO JME 12:1 (2013)\n\nGeorge R. Lucas, Jr.\n\nProfessor of Ethics &amp; Public Policy, Naval Postgraduate School, Monterey, California, USA\n\nThis article responds to several recent moral (as contrasted with legal) evaluations of cyber conflict appearing during the past several years. The principal (but not exclusive) focus is on articles recently published in this journal. Including those collected in a recent special issue of JME (12:1/ January 2013), guest edited by Bradley J. Strawser. The author distinguishes moral from legal issues in cyber conflict under current international law, and examines claims (like those of cyber expert, Randall Dipert) that neither international law nor just war tradition is any longer sufficient to govern the utterly unique objects and events taking place within a peculiar sort of domain that knows no boundaries, and where conventional constraints (like transparency and accountability) are wholly absent. Other issues covered include recent cyber conflicts, and whether the sort of harm suffered there, or likely to be inflicted during a broader cyberattack (including that resulting from long-term espionage and sabotage) would ever justify the use of conventional force in retaliation. While the JME special issue is not found to break any substantially new ground, taken in a wider context it charts the substantial progress that ethicists, moral philosophers and political theorists have made in catching up with the substantial legal analysis that have attended the advent of serious acts of malfeasance in the cyber domain during the past decade.\n\nKEY WORDS: Ethics, cyber conflict, sabotage, espionage, virtual harm, privacy, anonymity, Snowden, surveillance, retaliation, cyber security, preemptive self-defense\n\n# Introduction\n\nContributors to the recent special issue of JME (12:1) chose collectively to address perhaps the most vexed and ominous of the ongoing ethics debates over military technology: the prospects for cyber warfare. Of all the technologies recently surveyed and evaluated for the ethical challenges that they pose, the cyber warfare prospects are perhaps the most widespread and devastating on a human scale. Interestingly, although the issues presented by cyber warfare are in many ways the most representative of the common themes and ethical concerns pervading all other recently emergent military technologies combined, cyber conflict still remains the least thoroughly examined from the standpoint of ethics and governance. There is, to be sure, an enormous body of legal literature on the topic (e.g. Dunlap 2011, Graham 2010, Schmitt 2002, 2011). Much of this followed in the wake of the alleged Russian attack on Estonia in 2007, culminating in the 'Tallinn Manual' (Tallinn 2012), which attempts to apply existing statutes of international law to the cyber domain. But there is no equivalent effort to date from the community of practical and professional ethics (although several anthologies are in press at this writing).\n\nJournal of Military Ethics, 2014\n\nVol. 13, No. 1, 20–31, http://dx.doi.org/10.1080/15027570.2014.908012\n\nThis work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.\n\nRoutledge Taylor &amp; Francis Group",
    "The special issue of JME (12:1), published early in 2013, constitutes, to my knowledge, the first collective effort to address the ethical challenges of cyber warfare, and as such it deserves praise and also critical engagement. In order to do this more fully, however, I will also refer back to two earlier JME essays (one written by one of the contributors to the 2013 issue) so as to complete the comprehensive critical survey of ethical analyses of this subject to date.\n\n## Prior Essays in JME on Ethics and Cyber War\n\nCyber war and cyber weapons, just like all the other innovations in military technology considered in the JME over the past several years, invoke, in various ways, what we might label the ‘threshold' problem, the ‘accountability' problem and the ‘discrimination/ proportionality' problem. In distinctive and various ways, each new military technology has been criticized on one or more of these grounds as desensitizing the public to the true costs of war.\n\nLikewise, the first thread of concern running through these new essays is the ‘threshold' question: will increasing reliance on cyber weapons, or the resort to cyber war, lower the threshold for resorting to war? Inasmuch as cyber conflict allegedly involves only ‘virtual' harm, rather than genuine physical harm, and makes attribution and accountability for inflicting it difficult to ascertain, will this not encourage easy resort to such conflict directly, in lieu of seeking alternative means of conflict resolution?\n\nAt least, this is how critics of cyber technology have tended to assess this problem. War (presumably of any sort) is traditionally consigned to being the last (rather than the earliest) resort to conflict resolution with adversaries or competitors. Any technology, weapon or tactic that makes it inherently easier to resort to destructive uses of force in order to resolve disputes automatically constitutes a ground for concern on this criterion. Using robots cuts down on human casualties and costs, for example, while cyber war is ‘virtual' war, and may seem more like a game than reality. Thus, in both instances, we might more readily resort to war using these technologies when we should instead refrain or at least forebear in favor of alternative, non-militaristic approaches to conflict resolution.\n\nFurthermore, there is what we might term the jus in bello/Law of Armed Conflict (LOAC) question: will the advent of cyber conflict present increased risks of harm to civilians, or otherwise threaten disproportionate destruction and collateral damage in war? Is the very development of cyber technology itself a violation of international humanitarian law, owing to its tendency to be deliberately intended to do widespread harm to civilian infrastructure? These concerns (as I will show) tend to straddle the boundaries and blur the distinctions between the normally distinct realms of jus in bello and jus ad bellum.\n\nThis concern about the nature of cyber weapons themselves, for example, leads directly from in bello targeting questions to a related ad bellum question, in the following manner. One may interpret the so-called ‘Martens Clause' in international law as prohibiting the deliberate development of any weapons system for whose use or misuse military personnel or their governments cannot be held reasonably accountable under LOAC, since such accountability is, in all other contexts, a feature of custom and law as these pertain to existing weapons systems. (Robert Sparrow (2007) first raised this objection with respect to the lack of accountability for collateral harm done by unmanned systems.)",
    "With cyber warfare, however, what is generally regarded as a jus in bello issue of legal and moral accountability takes on a unique form that factors into ad bellum decisions regarding whether and how to retaliate to a cyberattack. Accountability for the use of cyber weapons is an enormous challenge, owing to the still-formidable difficulty of being certain beyond reasonable doubt of who has launched an attack, especially when the suspected attacker denies culpability. Virtually every contributor to JME 12:1 acknowledges this problem.\n\nThe moral debate over cyber strategy, however, has focused even more upon the indiscriminate (and sometimes also wildly disproportionate) properties of cyber weapons and tactics, whenever these are deliberately focused upon compromising civilian infrastructure. Computer science professor and cyber expert, Neil Rowe (2007, 2008, 2010, 2011), for example, has published several papers raising an alarm that the weapons and tactics frequently and (from the standpoint of ethics, at least) unreflectively envisioned as part of any routine preparation to wage or defend against cyber war are aimed at civilians, and that their use would cause widespread destruction of lives and property, and otherwise inflict surprisingly massive and terrible suffering among the civilian population of the target state. Such cyber strategy is thus, he argues, inherently a violation of LOAC.\n\nPhilosopher Randall Dipert (University of Buffalo) (2010, 2013, 2014) cited this work in the first of several seminal and path-breaking essays, yet another of which is included in this JME special issue. Dipert (in JME 12:1) offers careful consideration of Rowe's concerns in the course of offering what remains without doubt the most technically detailed, precise and comprehensive account of warfare, weapons, strategy and tactics in cyberspace -- all part of what Dipert sees as the puzzling and paradoxical ‘ontology of cyberspace'.\n\nMore broadly than Rowe's jus in bello analysis, however, Dipert's first essay (2010) attempted to evaluate both the strategic justification for cyber warfare (ad bellum), and the morality and legality of the tactics proposed for the conduct of such warfare (in bello), through the lens of classical just war doctrine. His earliest conclusion in 2010 was that both international law and just war doctrine are woefully deficient in providing reliable guidance for this novel and unique kind of futuristic warfare, and, in this initial essay, he originally proposed some guidelines that might help remedy these deficiencies in governance as the prospects for the conduct of such warfare grow ever more imminent. (His specific conclusions on the inapplicability of existing law and extant understandings of just war doctrine, however, are views against which I have subsequently argued strongly (e.g. Lucas 2011, 2013a, 2013b)).\n\nCol. James Cook, a philosopher at the US Air Force Academy, also adopted this line in response, arguing against Dipert in the same earlier issue (Cook 2010). There Cook argued that this appearance of deficiency in conventional just war doctrine is illusory. Cook specifically rejected what he termed ‘the argument from disanalogy' in Dipert's earlier account, and attempted to demonstrate in brief compass that the new dimensions of cyber war and cyber weapons can, or can be made to, fit well within the framework of guidance provided by conventional just war doctrine.\n\nIn an intriguing Heideggerian turn, Cook defined ‘cyberation' by analogy with the earlier derivation of ‘aviation' from ‘navigation', as the collective noun meant to encompass the ‘goings-on' of cyber ‘things' and ‘events' within cyberspace. As with aviation (as applied to the air), or navigation to the maritime domain, ‘cyberation' would include a central but by no means exclusive focus on military operations and considerations. As in air, sea and",
    "space, military activities in cyberspace take place alongside other operations and considerations that are decidedly non-military, with no obvious and immediate demarcation between or among them. In the end, however, and notwithstanding the initially confusing novelty of the medium and its activities, it should prove no less possible to encompass military operations in cyberspace (‘cyberation') within the framework of just war theory and international law than it was to adopt just war considerations within the wider domains of aviation and navigation, respectively. Rather, it takes a considerable degree of patience and judgment to sort out which things are which.\n\nCook's intriguing and original analogy has been adopted by other authors (e.g. Lucas 2013d), and has proved useful in helping situate our confusion over activities in the cyber domain in historical context, against which backdrop these current confusions are merely the latest episode in an ongoing drama of post facto social adjustment to technological transformations.\n\n## Recent Contributions to Ethics and Cyber Warfare\n\nMany of these same basic concerns that Dipert and Cook first raised in their initial exchange in 2010 are reiterated in the new essays on cyber warfare that comprise the second special issue of JME (for which the foregoing account was necessary in order to put the contributions in the current JME special issue (12:1) in proper context). As mentioned, the publication of this special issue itself testifies to a new awakening of interest in the topic of cyber conflict within the field of ethics, very much in the manner that two lengthy wars in the last decade re-awakened scholarly interest in just war doctrine itself, which had languished as a mainstream interest for decades after the Vietnam War. Prior to the appearance of this special issue (edited by B. J. Strawser), the topic of cyber conflict had received only scattered treatment by subject matter experts in ethics, especially in comparison with the voluminous body of interpretive scholarship generated by international lawyers in the aftermath of the Estonian conflict.\n\nTwo of these more recent essays stand out especially strongly for their contributions to the wider debate: the second essay by Dipert, and a summative essay at the end of the issue by John Arquilla. Despite both Cook and I having disagreed with some of Dipert's earlier findings regarding the relevance of just war doctrine, there is no question that Dipert is the single most knowledgeable and substantial contributor to the current, relatively nascent cyber ethics debate. Arquilla, for his part, is in many respects the founder or father of the entire field of cyber ethics (as his thoughtful reflections on some twenty years of this discussion, often including acknowledgement of his distinguished colleague, computer scientist Dorothy Denning, gently remind us: ref et passim below; see also Arquilla 1999, 2010, 2012).\n\nIn his essay for JME 12:1, Dipert reminds us that the cyber domain is not restricted to the internet itself, but includes a number of other important facets (what he terms ‘other-than-internet' or OTI attacks) that offer their own ethical challenges apart from those considered by the remaining contributors (who, like most of us, seem to equate ‘cyberspace' itself primarily with what transpires on the internet). Dipert concentrates, by contrast, on techniques like infecting thumb drives (the vector through which the Stuxnet worm may have been introduced to the otherwise-secure [‘air-gapped'] Iranian military internet system) and interfering with buried optical cables (which he surmises as the most likely manner of sabotaging Syrian air defense systems in advance of the Israeli bombing",
    "attack on the nuclear reactor under construction at Dayr-al Zawr). His account would have been much strengthened by considering the prospects revealed in the Snowden accounts of cell phone network hacking and even tapping into the Global Positioning System (GPS) system, both of which networks are connected to and interact with, but are physically distinct from the ‘internet' per se (far more so than thumb drives, which, like many of Dipert's other OTI examples, must eventually be introduced into devices that are connected to the internet itself in order to have any effect).\n\nIt is a helpful illustration to recall that the ubiquitous social networking site, Facebook, is an internet-based phenomenon that is struggling to gain a foothold in the cellular world, while its cellular counterpart, Twitter, was explicitly designed with the original limitations of the cellular network in mind, and is only now beginning to make a foray onto the internet. GPS navigational devices, in turn, operate on a frequency entirely separate from both. But all are part of the cyber domain, and the now-infamous ‘Enterprise Knowledge System' laid bare in Edward Snowden's release of NSA Management Directive #424 (Lucas 2014), tracks and correlates metadata from these distinct sources, along with conventional telephone networks (both copper and fiber optic cable), and local usage details (LUDs) as well. It is also the case that devices, like the unmanned systems used by the military, or like the elder care robots and robotic cars that loom on the near horizon, make use of a variety of these different dimensions of the cyber domain, and thus are, perforce, part of that domain as well.\n\nNotwithstanding this technical quibble over the great diversity of forms a genuine OTI attack might assume, Dipert's account of the severity and ethical conundrums of OTI-sourced attacks helpfully broadens the discussion to include threats less explicitly envisioned in the remaining essays (to which I will shortly turn in conclusion, below).\n\nArquilla's most recent critic and cyber-debating opponent has become the British international relations scholar, Thomas Rid. Contrary to all Arquilla's assertions and concerns regarding the threat of cyber conflict over the past two decades, Rid has forcefully denied that genuine cyber ‘warfare', involving death, harm and destruction equal to that of conventional warfare, could ever truly occur (e.g. Rid 2011, 2012). This (as I have repeatedly argued in Arquilla's defense, see Lucas 2013a, 2013b) is a far too stringent and unrealistic definition of ‘armed attack' or its equivalent, and Arquilla is right to continue to resist such an iconoclastic characterization of warfare.\n\nArquilla has made his own reputation through being something of a strategic contrarian, taking sharp issue with the received views of the defense establishment -- for example, by advocating, nearly two decades ago, increased reliance on special forces in response to the increase in number of ‘small wars', involving both humanitarian intervention and counterinsurgency. The military establishment during most of that period was instead bent on investing personnel and scarce resources to build overwhelming (and exorbitantly expensive) conventional superiority. In the midst of this sometimes-acrimonious debate, Arquilla (with colleague David Ronfeldt, see Arquilla & Ronfeldt 1993) literally coined the term ‘cyber war' to designate a form of conflict that, at the time (from 1992 until at least 1999), few took seriously.\n\nTime, we might observe, has proven Arquilla a remarkably prescient prognosticator. Yet he does err when he challenges Dipert's assertion that there are few, if any, historical precedents of military non-attribution that can be cited. Arquilla responds with earlier examples of unattributed cyberattacks, when what Dipert clearly intends instead is that",
    "ETHICS AND CYBER CONFLICT\n\nthere is a dearth of historical examples of unattributed conventional attacks, from which to draw conclusions by analogy on the limits of acceptable responses to the cyber cases (including those that Arquilla cites in response).\n\nThis is an unfortunate confusion, since a well-informed historian like Arquilla could have easily produced interesting counter-examples of instances in conventional warfare, such as the sinking of British merchant convey ships (allegedly) by Italian submarines early in the Second World War, and (perhaps even more apt to contemporary cyber attribution and response) the sinking of the US battleship Maine, just prior to the Spanish-American war of 1898. To this day, in the latter example, no one has been able to conclude definitively beyond a reasonable doubt who or what actually sunk the Maine, although suspicion, even from shortly after the event itself, was that it surely wasn't the Spanish government (which was nonetheless blamed for it). This instance provides a perfect analogue for the attribution problem in cyber space, and calls into question Dipert's contention that we do not have solid ground to stand on in evaluating how to proceed in the event of uncertainty. Of these, the Second World War instance seems even more definitive, inasmuch as, following Churchill's threats to retaliate by bombing targets in Italy, the mysterious submarine attacks on British convoys in the Mediterranean ceased entirely.\n\nBoth instances, and others like them, are instructive for cyber conflict in different ways. The sinking of the Maine produced what was likely a deliberately provoked and unjust war, lacking a genuine just cause, let alone right intention, on the part of the USA. In contrast, the cessation of submarine attacks following a threat of use of force against Italy strongly suggested, post facto, that the Italian suspects were indeed the guilty party (in which case, retaliation by the British for any subsequent attacks would have been morally justified).\n\nFollowing the leads of 'probable cause', and focusing suspicions on the most obvious beneficiaries of an 'unattributable' cyberattack (as Dipert has proposed in his earlier essays), is likely 'close enough for government work'. Hence, Dipert also suggests that the so-called 'attribution problem', while significant, need not be seen as an absolute obstacle to the prosecution of acceptable defense and retaliation against cyberattacks.\n\nThe remaining essays on cyber conflict in this special issue seem wholly occupied with the now well-studied properties for internet mischief, ignorant of the other forms of cyber vulnerability of which Dipert writes, even while they collectively fail in addition to distinguish carefully the important legal and moral boundaries between crime, vandalism, activism or 'hacktivism', corporate (criminal) espionage, state-sponsored espionage, covert action, sabotage, and the as-yet very few instances of outright cyber equivalents of kinetic armed attacks. Aside from this frustrating and systematic equivocation, however, these pieces raise a number of important and disturbing points.\n\nPerhaps most disturbingly, David and Joseph Danks offer a poignant analysis of the manner in which automated cyber response systems can go awry: for example, the 'death spiral' of cyber violence that might result from retaliation in the absence of definitive attribution, especially if autonomous retaliatory defense mechanisms are put in place, in a manner analogous to the fears of such unintended escalation during the age of 'nuclear deterrence'. This is indeed a grave concern, especially given the rapidity with which cyber events may unfold in time, as illustrated by the authors in the highly unstable computer securities trading systems, which have caused extreme oscillations",
    "and even unintended but grave ‘meltdowns' in securities markets in a matter of seconds. Automation, they aver, can produce some other unintended consequences, such as when a denial of service (DoS) attack provokes a blackout of the offending source. If it turns out the ‘zombie' is an unprotected hospital computer system, the counter-attack might produce unacceptable collateral damage in the form of denial of access to medical records needed in life-saving treatment. The problem's complexity is multiplied exponentially if an automated defense system is responding to a ‘distributed' DoS (DDoS) attack, as in Estonia, but instead launched from a botnet incorporating perhaps thousands of unsuspecting users or organizational systems who themselves have done nothing wrong, and are not legitimately the object of the counter-attack. Combined with the well-studied attribution problem, these authors conclude that factors in increasingly necessary automated defense systems have not been sufficiently studied, and the moral impact of their use remains unclear, especially if the best automated ‘defense' becomes an offensive or ‘preemptive' system.\n\nRyan Jenkins' article on Stuxnet attempts to bridge the gap between the virtual and the physical, and determine whether the use of a weapon of this sort might (as his opening quote from General Michael Hayden suggests) cross a line of significant demarcation between intention in the virtual world and genuine harm in the real world. Jenkins does not engage the highly debatable view put forth in a subsequent essay by Christopher Eberle, that ‘mere' destruction of property without loss of life can never constitute a just cause for war. In this case, the destruction of a military asset, just as in the case of the Israeli attacks on nuclear facilities in Iraq and Syria, regardless of loss of life, constitutes a use of armed force that would provide a just cause for war, should the victim of the attack choose to regard it as such. Jenkins' account of the ontology of cyberspace, of effects-based analysis of cyber weapons in determining the justification for a response, and of the details of Stuxnet in particular, especially regarding its extraordinary degree of discrimination, are all on point, and would provide a telling summary of this event, had every element of this account not already been exhaustively discussed in similar fashion in a rather considerable body of literature that the author does not cite (e.g. the Symantec security analysis of the structure and risks of Stuxnet in 2011, to cite but one instance). Still, this is a useful, accurate and informative account for those who may not have followed those earlier developments.\n\nIn distinguishing between types of cyberattacks that do, do not and might (or might not) constitute just causes for war, Christopher Eberle, in a subsequent essay, helpfully suggests that ‘right intention', in terms of the plan or purpose envisioned by the attacker in launching such an attack, plays a deciding role in such retaliation. This seems intuitively correct: before launching some sort of retaliation, especially kinetic retaliation, as the US Department of Defense cyber strategy (DoD 2011) threatens, one might wish to know not only who launched the cyberattack, but why, with what ‘purpose'. An inadvertent accident, for example, let alone the actions of cyber ‘rogues' or ‘patriotic hacktivists' within a nation's sovereign borders (as the Russian government characterized the unattributed attacks on Estonia launched from within its borders in 2007), might call for a different kind of retaliation than a deliberate attempt to do harm for reasons of state. In any event, Eberle finds that the very recourse to cyber weapons, which generally do less or even no ‘real' harm, would not generally provide a moral justification for the kind of kinetic retaliation that the USA has threatened (presumably as",
    "a deterrent to suffering such attacks). This seems unresolvable, however, absent a specific instance or context to analyze. I would think Eberle's constraint would hold (as it did, finally, hold) in the Estonian case, where virtual cyber mischief, even on a heretofore unprecedented scale, did not inflict the kind of permanent damage or harm that would justify kinetic retaliation. The ‘cyber-Armageddon' or ‘Pearl Harbor' that pundits like Richard Clarke predict, as Eberle acknowledges, would constitute a different matter altogether, were such an attack to be launched. The harm would perforce be substantial, and fully equivalent to the physical effects of a conventional attack. The recourse to cyber weapons, moreover, would not automatically signify, as Eberle seems to think, a desire to do little or no actual physical harm, but instead would simply represent the inability of the attacking state to resort effectively to a kinetic attack to achieve the damage easily wrought from afar by the use of cyber weapons.\n\nHere Eberle takes up one of the most recalcitrant of cyber threats, the planting of ‘trapdoors' and ‘logic bombs' by adversaries within a nation's vital infrastructure, presumably in anticipation of a future cyberattack. He likens these to nuclear missiles, aimed at a nation from its adversary's soil. Inasmuch as the existence and even the positioning of the latter do not constitute a just cause for war, neither, he suggests, would this form of systematic sabotage (since no actual harm has been inflicted).\n\nThe nuclear analogy, however, is tricky in this instance and can cut both ways (including against the point that Eberle is at pains to establish regarding the illegitimacy of preventive self-defense). The development of nuclear weapons capabilities by adversary governments, combined with the thinly veiled threat to use them, was indeed thought by a great many leaders in many countries to constitute a just cause for preventive war on several occasions: against the mounting Soviet nuclear threat in the 1950s; against the introduction of those same missiles in Cuba in the 1960s; and in the present day, in the nuclear weapons programs and accompanying public threats to use them, first by Iraq in 1981, then by Syria prior to 2007, and most recently by Iran. These are hardly uncontested examples of ‘just cause', but the controversy over them indicates that the matter is not easily resolved.\n\nIndependently, there seems something oddly dis-analogous between the nuclear and the cyber case. A better analogy would be the discovery of a group of enemy operatives systematically planting real bombs on real infrastructure, like highways, railroads and bridges. When noticed, it would seem a bit disingenuous for the organizing adversary to claim that these were merely preventive measures, that no actual harm had been done, and thus that no retaliation for these acts of (potential) sabotage was justified -- at least until the devices were detonated. Obviously, that is not a satisfactory threat assessment. At very least, mining an adversary's civilian infrastructure with logic bombs constitutes a massive crime, for which the host nation could be expected to cooperate in interdicting the guilty parties, and if not, under the Cybercrime Convention of 2001, the nation itself could be held accountable (whatever that would mean, see Lucas 2011, 2013b) for failing to put a halt to this cyber mischief.\n\nThis brings us full circle to Eberle's underlying concern with the adversary's plans, purposes and the just war criterion of ‘right intention'. In all these instances, both nuclear and cyber, it would help immensely to know what the intentions of the various actors truly were. Yet, whether discussing logic bombs planted by the Chinese cyber army or the development of nuclear capabilities by Saddam Hussein, Bashir al-Assad or the inscrutable",
    "Iranian leadership, we can never fully gauge intentionality apart from concrete actions. If the actions appear hostile and threatening, especially if accompanied by bellicose public rhetoric, we can hardly assume that the underlying intentions, whatever they may be, are benign.\n\nThis summary of the justification for the use of force would appear to dovetail nicely with the diplomatic statement of this principle by Col. Edward Barrett, whose overall driving vision this entire project on the ethics of cyber warfare originally was. And yet, somewhat akin to Eberle, he appears to waiver when the time for decisiveness arises, stating (in tepid defense of my point about anticipatory self-defense in the previous paragraph), that the acquisition and deployment of nuclear weapons or logic bombs is not itself a cause for war, and that any forcible response designed to prevent their use in some future attack could only occur if we, the potential victims of attack, possessed absolute clarity about an adversary's capabilities, intentions, preparations, and especially identity.\n\nThis waffling by both authors places the entire burden of proof upon the victim of an attack, without any residual accountability for the perpetrator. Granted, the principles of discrimination and proportionality, in both war and individual self-defense, do place a reasonable burden of proof on anyone who would employ deadly force to refrain from doing so if the situation (as judged by reasonably impartial third persons) would not clearly warrant it. A warning must be issued, an opportunity afforded for the invaders to surrender or flee. But it seems patently absurd, after a point, to deny the victim the right of defense of life and property if these conditions are met, even absent knowledge of who the intruders are, or what they intend (since their initial trespass, coupled with their unwillingness to surrender or attempt to flee when warned or ordered to do so, seems to constitute reasonable doubt about the benevolent nature of their intentions).\n\nIn like manner, if an adversary nation is busily engaged in stealing everything I own, and festooning my civilian infrastructure with devices of sabotage whose effect would prove devastating to life and limb, exactly how certain do I need to be of their genuine intent to use these weapons before putting a stop to the mischief? Forbearance in the face of such circumstances would unquestionably constitute a virtue, but one of supererogation, rather than a fundamental claim of morality. None of this mitigates the entirely separate concern for unintended spiraling escalation and harm that Danks and Danks caution against, in the case of wholly automated and unsupervised systems of cyber self-defense. But it does pose a limit of sound judgment upon the anxieties about discriminate and proportionate response to cyberattack. I argued a few years ago (Lucas 2011) that Stuxnet, on any reasonable account, represented a legal and morally justifiable response to criminal conspiracy in violation of international laws and regulations, especially because (as Eberle and Jenkins note) it managed to accomplish this without so much as ‘mussing the hair' of a bystander or conspirator. And this attack, to date, seems to have been the most physically destructive that we have witnessed, in terms of rendering physical damage on the nuclear centrifuges themselves. In general, we are discussing forms of virtual, not real harm, mighty inconvenience and loss, rather than death, destruction and devastation. If so, perhaps we are being too precious about the measures that we may reasonably undertake regarding cyber defense. If, as Eberle in particular seems to feel, no one and no thing is actually harmed or damaged in a",
    "ETHICS AND CYBER CONFLICT\n\ncyberattack, then the reverse would also be true as we, the victim, responded in kind, presuming we did only that, and not something more dire.\n\nIn that sense, I would defend the morality not only of Stuxnet, but also, properly understood, the morality of anticipatory self-defense inherent in National Security Agency's now much-maligned 'Enterprise Knowledge System'. The unjustifiable component was the secrecy and deception, not the institution of the wholly defensive measures. But that is an argument I have made at great length elsewhere (e.g. Lucas 2013c, 2013d, 2014), and in any case, would take us far afield from the limited purview of these interesting essays.\n\n# REFERENCES\n\nArquilla, John. (1999) Ethics and Information Warfare, in: Z. Khalilzad, J. White &amp; A. Marshall (Eds), The Changing Role of Information in Warfare, pp. 379-401 (Santa Monica, CA: RAND Corporation).\nArquilla, John. (2010) Conflict, Security, and Computer Ethics, in: Luciano Floridi (Ed), Cambridge Handbook of Information and Computer Ethics, pp.133-149 (New York: Cambridge University Press).\nArquilla, John. (2012) Cyber War is Already upon Us, Foreign Policy, March-April; accessed 2 April 2014, available at: http://www.foreignpolicy.com/articles/2012/02/27/cyberwar_is_already_upon_us; Internet.\nArquilla, John &amp; Ronfeldt, David. (1993) Cyberwar is Coming!, Comparative Strategy, 12(2), pp. 141-165.\nCook, James. (2010) 'Cyberation' and Just War Doctrine: A Response to Randall Dipert, Journal of Military Ethics, 9(4), pp. 411-423.\nDipert, Randall R. (2010) The Ethics of Cyber Warfare, Journal of Military Ethics, 9(4), pp. 384-410.\nDipert, Randall R. (2013) The Essential Features for an Ontology for Cyberwarfare, in: Panayotis A. Yannakogeorgos &amp; Adam B. Lowther (Eds), Conflict and Cooperation in Cyberspace, pp. 35-48 (Boca Raton, FL: Taylor &amp; Francis).\nDipert, Randall R. (2014) The Ethics of Information Warfare, in: Luciano Floridi &amp; Mariarosaria Taddeo (Eds), Philosophy of Engineering and Technology: Proceedings of a UNESCO Conference on Ethics &amp; Cyber Security, pp. 25-37 (Amsterdam: Springer).\nDoD (Department of Defense). (2011) US Department of Defense Strategy for Operating in Cyber Space, accessed 2 April 2014, available at: http://www.defense.gov/news/d20110714cyber.pdf; Internet.\nDunlap, Charles J. (2011) Perspectives for Cyber Strategists on Law for Cyberwar, Strategic Studies Quarterly, 5 (Spring), pp. 81-99.\nGraham, David E. (2010) Cyber Threats and the Law of War, Journal of National Security Law, 4(1), pp. 87-102.\nLucas, George R. Jr. (2011) Permissible Preventive Cyberwar: Restricting Cyber Conflict to Justified Military Targets, opening address for a UNESCO-sponsored conference on Cyber War and Ethics at the University of Hertfordshire, 1 July, accessed 2 April 2014, available at: http://www.elac.ox.ac.uk/downloads/Permissible%20Preventive%20Cyberwar%20UNESCO%202011.pdf; Internet. (Also forthcoming in: Luciano Floridi &amp; Mariarosaria Taddeo (Eds), Philosophy of Engineering and Technology: Proceedings of a UNESCO Conference on Ethics &amp; Cyber Security (Amsterdam: Springer).)",
    "G.R. LUCAS\n\nLucas, George R. Jr. (2013a) Can There Be an Ethical Cyberwar?, in: A. Panayotis Yannakogeorgos &amp; Adam B. Lowther (Eds), Conflict and Cooperation in Cyberspace, pp. 195–210 (Boca Raton, FL: CRC Press / Taylor and Francis).\n\nLucas, George R. Jr. (2013b) *Jus in Silico: Moral Restrictions on the Use of Cyber Warfare*, in: Fritz Allhoff, Nicholas G. Evans &amp; Adam Henschke (Eds), *The Routledge Handbook of War and Ethics*, pp. 367–380 (Oxford: Routledge).\n\nLucas, George R. Jr. (2013c) Emerging Norms for Cyber Warfare. Keynote Address, Conference on Ethics &amp; Cyber Security, Center for Applied Philosophy &amp; Practical Ethics, Australian National and Charles Stuart Universities, Canberra, 5–6 August, accessed 2 April 2014, available at: http://philevents.org/event/show/11114; Internet.\n\nLucas, George R. Jr. (2013d) Navigation, Aviation, ‘Cyberation’: Developing New Rules of the Road for the Cyber Domain. Inaugural Public Security Lecture, National Security College, Australian National University, Canberra, 7 August, accessed 2 April 2014, available at: http://www.youtube.com/watch?v=cs7RXAPzG84; Internet.\n\nLucas, George R. Jr. (2014) NSA Management Directive # 424: Secrecy and Privacy in the Aftermath of Snowden, Ethics and International Affairs (6 February), accessed 9 April 2014, available at: http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=9207954; Internet.\n\nRid, Thomas. (2011) Cyber War Will Not Take Place, The Journal of Strategic Studies, 35(1), pp. 5–32.\n\nRid, Thomas C. (2012) Cyber War: Think Again, Foreign Policy Magazine, 26 February, pp. 58–61.\n\nRowe, Neil C. (2007) War Crimes from Cyberweapons, Journal of Information Warfare, 6(3), pp. 15–25.\n\nRowe, Neil C. (2008) Ethics of Cyber War Attacks, in: Lech J. Janczewski &amp; Andrew M. Colarik (Eds), Cyber Warfare and Cyber Terrorism, pp. 105–111 (Hershey, PA: Information Science Reference).\n\nRowe, Neil C. (2010) The Ethics of Cyberweapons in Warfare, Journal of Techoethics, 1(1), pp. 20–31.\n\nRowe, Neil C. (2011) Toward Reversible Cyber Attacks, in: Julie Ryan (Ed), Leading Issues in Information Warfare and Security Research, pp. 145–158 (Reading: Academic Publishing).\n\nSchmitt, Michael N. (1999) Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework, Columbia Journal of Transnational Law, 37, pp. 885–937.\n\nSchmitt, Michael N. (2002) Wired Warfare: Computer Network Attack and Jus in Bello, International Review of the Red Cross, 84(846), pp. 365–399.\n\nSchmitt, Michael N. (2011) Cyber Operations and the Jus in Bello: Key Issues, U.S. Naval War College International Law Studies, 87, pp. 89–110.\n\nSparrow, Robert. (2007) Killer Robots, Journal of Applied Philosophy, 24(1), pp. 62–67.\n\nSymantec. (2011) W32.Stuxnet Dossier, by Nicholas Falliere, Liam O. Murchu &amp; Eric Chien (February), accessed 2 April 2014, available at: http://www.symantec.com/content/en/us/enterprise/media/security_response/whitepapers/w32_stuxnet_dossier.pdf; Internet.\n\nTallinn. (2012) The Tallinn Manual on the International Law Applicable to Cyber Warfare, ed. Michael N. Schmitt (Tallinn: NATO Cooperative Cyber Defence Center of Excellence), accessed 2 April 2014, available at: https://www.ccdcoe.org/249.html; Internet.",
    "ETHICS AND CYBER CONFLICT\n\nRecently retired from the Distinguished Chair in Ethics in the Vice Admiral James B. Stockdale Center for Ethical Leadership at the U.S. Naval Academy, George Lucas is currently a professor of ethics and public policy at the Graduate School of Public Policy at the Naval Postgraduate School in Monterey, California. His essay on Edward Snowden and NSA cyber surveillance was just published in *Ethics &amp; International Affairs* (28:1), and his book, \"Military Ethics: What Everyone Needs to Know\" is forthcoming from Oxford University Press in 2015, with a foreword by General John R. Allen, USMC (retired). Correspondence address: Naval Postgraduate School, 1 University Cir, Monterey, CA 93943, USA. Email Address: grlucas@nps.edu"
  ],
  "metadata": {
    "title": "Ethics and Cyber Conflict: A Response to JME 12:1 (2013)",
    "subtitle": "To link to this article: https://doi.org/10.1080/15027570.2014.908012",
    "document_type": "journal_article",
    "venue": "Journal of Military Ethics",
    "publication_year": 2013,
    "authors": [
      "IRRutledge Taylor",
      "Francis Group",
      "George R. Lucas Jr.",
      "George R. Lucas"
    ],
    "affiliations": [
      "Professor of Ethics & Public Policy, Naval Postgraduate School, Monterey, California, USA"
    ],
    "emails": [],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [
      "Ethics",
      "cyber conflict",
      "sabotage",
      "espionage",
      "virtual harm",
      "privacy",
      "anonymity",
      "Snowden",
      "surveillance",
      "retaliation",
      "cyber security",
      "preemptive self-defense"
    ],
    "publication_dates": {
      "published": "08 May 2014",
      "online": "08 May 2014"
    },
    "identifiers": {
      "doi": [
        "10.1080/15027570.2014.908012"
      ],
      "issn": [
        "ISSN: 1502-7570"
      ],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "www.tandfonline.com/journals/smil20",
        "https://doi.org/10.1080/15027570.2014.908012",
        "https://www.tandfonline.com/action/journalInformation?journalCode=smil20",
        "http://dx.doi.org/10.1080/15027570.2014.908012"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 26,
    "heading_count": 6,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 5,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 1.0,
      "unique_index_count": 5
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "author_year",
      "recommended_style": "unknown",
      "aligned": true,
      "signals": {
        "superscript_hits": 0,
        "superscript_definition_lines": 0,
        "numeric_bracket_hits": 0,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 37.0,
      "dominant_bib_coverage_rate": 0.13513513513513514,
      "dominant_link_target": "bibliography",
      "dominant_unresolved_flag": "unresolved_reference_links"
    },
    "heading_validation": {
      "heading_count": 6,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": false,
        "orcids": false,
        "abstract": false,
        "keywords": true,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 4,
        "affiliations": 1,
        "emails": 0,
        "orcids": 0,
        "keywords": 12,
        "doi": 1,
        "issn": 1,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 4
      },
      "coverage": {
        "core_coverage": 1.0,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": []
    },
    "flags": [
      "low_bib_coverage"
    ]
  },
  "citation_summary": {
    "style": "author_year",
    "dominant_bucket": "author_year",
    "dominant": {
      "intext_total": 5.0,
      "success_occurrences": 5.0,
      "success_unique": 5.0,
      "bib_unique_total": 37.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.13513513513513514,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "author_year"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 5.0,
        "success_occurrences": 5.0,
        "success_unique": 5.0,
        "bib_unique_total": 37.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.13513513513513514,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:25:22.449287+00:00"
}