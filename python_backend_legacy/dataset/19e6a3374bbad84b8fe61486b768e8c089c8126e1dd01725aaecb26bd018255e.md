{
  "full_text": "168\n# Usefulness of Cyber Attribution Indicators\nHenrik Karlzén\nSwedish Defence Research Agency, Linköping, Sweden\nhenrik.karlzen@foi.se\nDOI: 10.34190/EWS.20.074\nAbstract: Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.\nKeywords: cyberattack, attribution, cyber operation, APT, security, usefulness\n# 1. Introduction\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions (Davis et al., 2017), or by counter-attacking (Egloff, 2018). This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty (Porter, 2017)). These possibilities also mean that attribution can be a deterrent (Floyd, 2018). Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state (Illinois, 2018). Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action (Ahmed and Perlroth, 2019). Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR (Davis et al., 2017).\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks (Romanosky and Boudreaux, 2019). They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies (Bartholomew and Guerrero-Saade, 2016). On the other hand, intelligence agencies – that have good sources both in cyber and other domains (Malik, 2017; Symantec, 2018) – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor (Romanosky and Boudreaux, 2019). It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors (Davis et al., 2017), a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) (Neutze, 2016), or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n# 1.1 Related work\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds (DARPA, 2016a), and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods (DARPA, 2016b).\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n# 2. Method\nThe next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n# 2.1 Cyberattack databases\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)\nHenrik Karlzén\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks (Romanosky and Boudreaux, 2019), and is updated quarterly (CFR, 2019). It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers (CFR, 2019).\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\nTable 1: Sample attack in CFR (shortened).\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n# 2.2 Categorisations of attribution indicators\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |\nHenrik Karlzén\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).\n# 3. Attribution indicators in theory and practice\nThe CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that\nHenrik Karlzén\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\nTable 3: Attribution indicator categories and practical examples.\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible (Cherepanov, 2017)  |\n|  Entry | Spearphishing (Great, 2017)  |\n|   |  Supply-chain attack (Cherepanov, 2017)  |\n|  Targeting | Target fitting national interests (ThreatConnect, 2017a; O'Leary et al., 2017)  |\n|   |  Diverse targeting (Secureworks, 2017)  |\n|  Infrastructure | Nationality of DNS servers (O'Leary et al., 2017) and IP-addresses (Reaqta, 2017; Marczak et al., 2017)  |\n|   |  Spoofed domains (ThreatConnect, 2017b)  |\n|   |  C2 (PWC, 2017; Symantec, 2017)  |\n|   |  Links via legitimate websites to trick filters (ThreatConnect, 2017a)  |\n|  Modularity | Open source tools (Lancaster, 2017)  |\n|   |  Nationality of tools (O'Leary et al., 2017)  |\n|   |  Tool demonstration log files (Marczak et al., 2017)  |\n|   |  Code (Symantec, 2017)  |\n|  Language | System language settings (Reaqta, 2017; Atch and Neray, 2017)  |\n|   |  Artefacts in specific natural language (O'Leary et al., 2017; Secureworks, 2017)  |\n|   |  Poor or unusual use of natural language (Great, 2017)  |\n|  Personas | Recurring names in code (Symantec, 2017; O'Leary et al., 2017)  |\n|  Pattern-of-Life | Reduced attack activity during certain holidays (Secureworks, 2017; O'Leary et al., 2017)  |\n|   |  Compilation on certain countries' working hours (PWC, 2017)  |\n|  Stealth | Type of code obfuscation (Symantec, 2017)  |\n|   |  Type of crypto-mechanism (Hegel, 2018)  |\n|  Cluster | Similar process-trees (Reaqta, 2017)  |\n|  Functionality | Gather information (Goeij, 2017)  |\n|   |  Destroy data (Cherepanov, 2017)  |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch (Symantec, 2017)  |\n|  Mistakes | Mistakenly accessing without proxy (Hegel, 2018)  |\n|  Skills | Capability (Atch and Neray, 2017)  |\n|  Scope | Attacks to obtain code signing certificates for later attacks (Hegel, 2018)  |\n|  Stages | Several teams cooperating (PWC, 2017; Hegel, 2018)  |\n|  Evolution | First targeting diplomatic entities, then defence organisations (Great, 2017)  |\n|   |  Adapts and learns to evade detection (Hegel, 2018)  |\n|  Claims | Former team member admission (Reyes et al., 2017)  |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions (Hegel, 2018)  |\n|  Cost | Massive infrastructure to decrypt and analyse (Atch and Neray, 2017)  |\n|  Significance (for attacker) | Valuable (Secureworks, 2017)  |\n|  Context | Victim a certain country showed interest in (O'Leary et al., 2017; PWC, 2017  |\n|   |  Statements from officials (Goeij, 2017; Huetteman, 2017; Homewood, 2017)  |\n|  Benefit | A certain nation (Homewood, 2017)  |\n|  Consequences | Serious for a nation's security (Goeij, 2017)  |\n|   |  Intelligence gathering (Atch and Neray, 2017)  |\n# 4. Discussion\nThe following subsections discuss practical difficulties with attribution, and limitations of the empirical data.\nHenrik Karlzén\n## 4.1 Practical difficulties with attribution\nAttribution is slow and often requires weeks or months of analysis (ODNI, 2018). Attributing cyberattacks is also difficult (Keromytis, 2016), although the news media often overstate the problems in order to appear balanced in their reporting (Bartholomew and Guerrero-Saade, 2016).\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available (Bartholomew and Guerrero-Saade, 2016).\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware (Boot, 2019). Allegedly, more than half of Stuxnet development costs were for anti-attribution (Langner, 2013). The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings (Pahi and Skopik, 2019) or adding text in different languages (Bartholomew and Guerrero-Saade, 2016). Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet (Bartholomew and Guerrero-Saade, 2016).\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability (Floyd, 2018) and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" (Zetter, 2017).\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers (Nicholson et al., 2015). However, this would be difficult to accomplish (Cook et al., 2016), and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses (ODNI, 2018), as in Fokker and Beek (2019), using independent reviews (Davis et al., 2017), or public disagreements between analysts as in e.g. Lancaster (2017).\n## 4.2 Limitations of the empirical data\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods (Rid and Buchanan, 2015; Bartholomew and Guerrero-Saade, 2016). Attribution can also be harmful to one's reputation, or even dangerous (Romanosky and Boudreaux, 2019). Companies do not point fingers at nation-states as often as other nation-states do (Mueller et al., 2019), and US companies may hesitate to point fingers at the US government (Yadron, 2015; Romanosky and Boudreaux, 2019). Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation (Rid and Buchanan, 2015).\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law (Berghel, 2017). However, weaker evidence may lead to stronger evidence (Clark and Landau, 2010), or be sufficient for security decision-making (Tsagourias, 2012). There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments (Shakarian et al., 2015; Davis et al., 2017). Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale (Davis et al., 2017). Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) (Schmitt and Vihul, 2017), and obfuscate (when attacking). Furthermore,\nHenrik Karlzén\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).\n# 5. Conclusions\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute.",
  "flat_text": "Henrik Karlzén\nSwedish Defence Research Agency, Linköping, Sweden\nhenrik.karlzen@foi.se\nDOI: 10.34190/EWS.20.074\nAbstract: Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.\nKeywords: cyberattack, attribution, cyber operation, APT, security, usefulness\n# 1. Introduction\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions , or by counter-attacking . This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty ). These possibilities also mean that attribution can be a deterrent . Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state . Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action . Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR .\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks . They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies . On the other hand, intelligence agencies – that have good sources both in cyber and other domains  – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor . It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors , a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) , or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n# 1.1 Related work\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds , and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods .\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n# 2. Method\nThe next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n# 2.1 Cyberattack databases\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)\nHenrik Karlzén\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks , and is updated quarterly . It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers .\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\nTable 1: Sample attack in CFR (shortened).\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n# 2.2 Categorisations of attribution indicators\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |\nHenrik Karlzén\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).\n# 3. Attribution indicators in theory and practice\nThe CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that\nHenrik Karlzén\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\nTable 3: Attribution indicator categories and practical examples.\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible   |\n|  Entry | Spearphishing   |\n|   |  Supply-chain attack   |\n|  Targeting | Target fitting national interests   |\n|   |  Diverse targeting   |\n|  Infrastructure | Nationality of DNS servers  and IP-addresses   |\n|   |  Spoofed domains   |\n|   |  C2   |\n|   |  Links via legitimate websites to trick filters   |\n|  Modularity | Open source tools   |\n|   |  Nationality of tools   |\n|   |  Tool demonstration log files   |\n|   |  Code   |\n|  Language | System language settings   |\n|   |  Artefacts in specific natural language   |\n|   |  Poor or unusual use of natural language   |\n|  Personas | Recurring names in code   |\n|  Pattern-of-Life | Reduced attack activity during certain holidays   |\n|   |  Compilation on certain countries' working hours   |\n|  Stealth | Type of code obfuscation   |\n|   |  Type of crypto-mechanism   |\n|  Cluster | Similar process-trees   |\n|  Functionality | Gather information   |\n|   |  Destroy data   |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch   |\n|  Mistakes | Mistakenly accessing without proxy   |\n|  Skills | Capability   |\n|  Scope | Attacks to obtain code signing certificates for later attacks   |\n|  Stages | Several teams cooperating   |\n|  Evolution | First targeting diplomatic entities, then defence organisations   |\n|   |  Adapts and learns to evade detection   |\n|  Claims | Former team member admission   |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions   |\n|  Cost | Massive infrastructure to decrypt and analyse   |\n|  Significance (for attacker) | Valuable   |\n|  Context | Victim a certain country showed interest in   |\n|  Benefit | A certain nation   |\n|  Consequences | Serious for a nation's security   |\n|   |  Intelligence gathering   |\n# 4. Discussion\nThe following subsections discuss practical difficulties with attribution, and limitations of the empirical data.\nHenrik Karlzén\n## 4.1 Practical difficulties with attribution\nAttribution is slow and often requires weeks or months of analysis . Attributing cyberattacks is also difficult , although the news media often overstate the problems in order to appear balanced in their reporting .\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available .\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware . Allegedly, more than half of Stuxnet development costs were for anti-attribution . The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings  or adding text in different languages . Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet .\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability  and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" .\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers . However, this would be difficult to accomplish , and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses , as in Fokker and Beek (2019), using independent reviews , or public disagreements between analysts as in e.g. Lancaster (2017).\n## 4.2 Limitations of the empirical data\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods . Attribution can also be harmful to one's reputation, or even dangerous . Companies do not point fingers at nation-states as often as other nation-states do , and US companies may hesitate to point fingers at the US government . Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation .\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law . However, weaker evidence may lead to stronger evidence , or be sufficient for security decision-making . There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments . Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale . Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) , and obfuscate (when attacking). Furthermore,\nHenrik Karlzén\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).\n# 5. Conclusions\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute.",
  "toc": [
    [
      1,
      "# 1. Introduction"
    ],
    [
      1,
      "# 2. Method"
    ],
    [
      1,
      "# 3. Attribution indicators in theory and practice"
    ],
    [
      1,
      "# 4. Discussion"
    ],
    [
      1,
      "# 5. Conclusions"
    ]
  ],
  "sections": {
    "# 1. Introduction": "This paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions , or by counter-attacking . This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty ). These possibilities also mean that attribution can be a deterrent . Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state . Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action . Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR .\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks . They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies . On the other hand, intelligence agencies – that have good sources both in cyber and other domains  – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor . It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors , a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) , or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n# 1.1 Related work\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds , and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods .\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.",
    "# 2. Method": "The next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n# 2.1 Cyberattack databases\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)\nHenrik Karlzén\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks , and is updated quarterly . It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers .\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\nTable 1: Sample attack in CFR (shortened).\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n# 2.2 Categorisations of attribution indicators\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |\nHenrik Karlzén\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).",
    "# 3. Attribution indicators in theory and practice": "The CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that\nHenrik Karlzén\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\nTable 3: Attribution indicator categories and practical examples.\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible   |\n|  Entry | Spearphishing   |\n|   |  Supply-chain attack   |\n|  Targeting | Target fitting national interests   |\n|   |  Diverse targeting   |\n|  Infrastructure | Nationality of DNS servers  and IP-addresses   |\n|   |  Spoofed domains   |\n|   |  C2   |\n|   |  Links via legitimate websites to trick filters   |\n|  Modularity | Open source tools   |\n|   |  Nationality of tools   |\n|   |  Tool demonstration log files   |\n|   |  Code   |\n|  Language | System language settings   |\n|   |  Artefacts in specific natural language   |\n|   |  Poor or unusual use of natural language   |\n|  Personas | Recurring names in code   |\n|  Pattern-of-Life | Reduced attack activity during certain holidays   |\n|   |  Compilation on certain countries' working hours   |\n|  Stealth | Type of code obfuscation   |\n|   |  Type of crypto-mechanism   |\n|  Cluster | Similar process-trees   |\n|  Functionality | Gather information   |\n|   |  Destroy data   |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch   |\n|  Mistakes | Mistakenly accessing without proxy   |\n|  Skills | Capability   |\n|  Scope | Attacks to obtain code signing certificates for later attacks   |\n|  Stages | Several teams cooperating   |\n|  Evolution | First targeting diplomatic entities, then defence organisations   |\n|   |  Adapts and learns to evade detection   |\n|  Claims | Former team member admission   |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions   |\n|  Cost | Massive infrastructure to decrypt and analyse   |\n|  Significance (for attacker) | Valuable   |\n|  Context | Victim a certain country showed interest in   |\n|  Benefit | A certain nation   |\n|  Consequences | Serious for a nation's security   |\n|   |  Intelligence gathering   |",
    "# 4. Discussion": "The following subsections discuss practical difficulties with attribution, and limitations of the empirical data.\nHenrik Karlzén\n## 4.1 Practical difficulties with attribution\nAttribution is slow and often requires weeks or months of analysis . Attributing cyberattacks is also difficult , although the news media often overstate the problems in order to appear balanced in their reporting .\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available .\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware . Allegedly, more than half of Stuxnet development costs were for anti-attribution . The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings  or adding text in different languages . Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet .\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability  and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" .\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers . However, this would be difficult to accomplish , and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses , as in Fokker and Beek (2019), using independent reviews , or public disagreements between analysts as in e.g. Lancaster (2017).\n## 4.2 Limitations of the empirical data\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods . Attribution can also be harmful to one's reputation, or even dangerous . Companies do not point fingers at nation-states as often as other nation-states do , and US companies may hesitate to point fingers at the US government . Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation .\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law . However, weaker evidence may lead to stronger evidence , or be sufficient for security decision-making . There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments . Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale . Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) , and obfuscate (when attacking). Furthermore,\nHenrik Karlzén\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).",
    "# 5. Conclusions": "The focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute."
  },
  "process_log": {
    "scheme": "numeric_hint",
    "numeric_check": {
      "first_num": 1,
      "raw_count": 11,
      "raw_examples": [
        1,
        1,
        1,
        2,
        2,
        2,
        3,
        4
      ],
      "filtered_count": 11,
      "filtered_examples": [
        1,
        1,
        1,
        2,
        2,
        2,
        3,
        4
      ],
      "seq_score": 0.45454545454545453
    },
    "roman_check": {
      "raw_count": 0,
      "count": 0,
      "min": null,
      "examples": [],
      "best_run": 0,
      "seq_score": 0.0,
      "requires_from_I": true
    },
    "markdown_numeric_hint": {
      "raw_count": 11,
      "count": 5,
      "min": 1,
      "examples": [
        1,
        2,
        3,
        4,
        5
      ],
      "best_run": 5
    },
    "toc_count": 5,
    "section_count": 5
  },
  "word_count": 3738,
  "references": [
    "# References\nAhmed, B.A. and Perlroth, N. (2019) \"Using Texts as Lures, Government Spyware Targets Mexican Journalists and Their Families\", [online], New York Times, 19 June, www.nytimes.com/2017/06/19/world/americas/mexico-spyware-anticrime.html\nAtch, D. and Neray, P. (2017) \"Operation BugDrop: CyberX Discovers Large-Scale Cyber-Reconnaissance Operation Targeting Ukrainian Organizations\", [online], CyberX Labs, cyberx-labs.com/en/blog/operation-bugdrop-cyberx-discovers-large-scale-cyber-reconnaissance-operation/\nBartholomew, B. and Guerrero-Saade, J.A. (2016) \"Wave Your False Flags! Deception Tactics Muddying Attribution in Targeted Attacks\", Virus Bulletin, October.\nBerghel, H. (2017) \"On the Problem of (Cyber) Attribution\", Computer, Vol. 50, No. 3.\nBoot, C. (2019) \"Applying Supervised Learning on Malware Authorship Attribution\", M.Sc. thesis, Radboud University Nijmegen.\nCaltagirone, S., Pendergast, A. and Betz, C. (2013). The Diamond Model of Intrusion Analysis, Hanover, MD: Center for Cyber Threat Intelligence and Threat Research, 5 July.\nCherepanov, A. (2017) \"TeleBots are back: Supply-chain attacks against Ukraine\", [online], Eset, https://www.welivesecurity.com/2017/06/30/telebots-back-supply-chain-attacks-against-ukraine/\nChernenko, E., Demidov, O. and Lukyanov, F. (2018) \"Increasing international cooperation and cybersecurity and adapting cyber norms\", [online], Council on Foreign Relations, www.cfr.org/report/increasing-international-cooperation-cybersecurity-and-adapting-cyber-norms\nClark, D.D. and Landau, S. (2010) \"The Problem isn't Attribution; It's Multi-Stage Attacks\", ACM ReArch.\nCook, A., Nicholson, A., Janicke, H., Maglaras, L. and Smith, R. (2016) \"Attribution of Cyber Attacks on Industrial Control Systems\", EAI Endorsed Transactions on Industrial Networks and Intelligent Systems, Vol. 3, No. 7.\nDARPA. (2016a) \"DARPA-BAA-16-34, Enhanced Attribution, Frequently Asked Questions\", DARPA.\nDARPA. (2016b) \"Broad Agency Announcement Enhanced Attribution DARPA-BAA-16-34\", DARPA.\nDavis, J., Boudreaux, B., Welburn, J., Aguirre, J., Ogletree, C., McGovern, G. and Chase, M. (2017) \"Stateless Attribution: Toward International Accountability in Cyberspace\", RAND.\nEgloff, F.J. (2018) \"Cybersecurity and Non-State Actors\", Ph.D. thesis, University of Oxford.\nFloyd, G.S. (2018) \"Attribution and Operational Art: Implications for Competing in Time\", Strategic Studies Quarterly, Vol. 12, No. 2.\nFokker, J. and Beek, C. (2019) \"Ryuk Ransomware Attack: Rush to Attribution Misses the Point\", [online], McAfee Blogs, securingtomorrow.mcafee.com/other-blogs/mcafee-labs/ryuk-ransomware-attack-rush-to-attribution-misses-the-point/\nHenrik Karlzén\nGoeij, H.d. (2017) \"Czech Government Suspects Foreign Power in Hacking of Its Email\", [online], The New York Times, 31 January, www.nytimes.com/2017/01/31/world/europe/czech-government-suspects-foreign-power-in-hacking-of-its-email.html?_r=1%0A\nGreat. (2017) \"Introducing WhiteBear\", Securelist, [online], Kaspersky, securelist.com/introducing-whitebear/81638/%0A\nHegel, T. (2018) \"Burning Umbrella: An Intelligence Report on the Winnti Umbrella and Associated State-Sponsored Attackers\", [online], 401Trg, 401trg.pw/burning-umbrella/\nHomewood, B. (2017) \"IAAF says medical records compromised by Fancy Bear hacking group\", [online], Reuters, www.reuters.com/article/us-sport-doping-iaaf/iaaf-says-medical-records-compromised-by-fancy-bear-hacking-group-idUSKBN1750ZM\nHuetteman, E. (2017) \"Marco Rubio Says His Campaign Was a Target of Russian Cyberattacks\", [online], The New York Times, 30 March, www.nytimes.com/2017/03/30/us/politics/marco-rubio-russian-cyberattacks.html\nHunker, J., Hutchinson, B. and Margulies, J. (2008) \"Role and Challenges for Sufficient Cyber-Attack Attribution\", Dartmouth College\nHutchins, E., Cloppert, M. and Amin, R. (2011) Intelligence-driven computer network defense informed by analysis of adversary campaigns and intrusion kill chains, 6th International Conference on Information Warfare and Security, ICIW\nIllinois. (2018) \"2018 WL 4941760 (Ill.Cir.Ct.) (Trial Pleading). MONDELEZ INTERNATIONAL, INC., Plaintiff, v. ZURICH AMERICAN INSURANCE COMPANY, Defendant\", Circuit Court of Illinois.\nJolley, J.D. (2017) Attribution, State Responsibility, and the Duty to Prevent Malicious Cyber-Attacks in International Law, University of Glasgow\nKearns, E.M. (2019) \"When to Take Credit for Terrorism? A Cross-National Examination of Claims and Attributions\", Terrorism and Political Violence\nKeromytis, A. (2016) \"Enhanced Attribution\", [online], DARPA, www.enisa.europa.eu/events/cti-eu-event/cti-eu-event-presentations/enhanced-attribution\nLancaster, T. (2017) \"Muddying the Water: Targeted Attacks in the Middle East\", [online], Palo Alto Networks, researchcenter.paloaltonetworks.com/2017/11/unit42-muddying-the-water-targeted-attacks-in-the-middle-east\nLangner, R. (2013) To Kill a Centrifuge, The Langner Group.\nMalik, W. (2017) \"What are the benefits of attribution?\", [online], TrendMicro, 16 August, blog.trendmicro.com/what-are-the-benefits-of-attribution/\nMarczak, B. (2017) \"Champing at the Cyberbit\", [online], The Citizen Lab, citizenlab.ca/2017/12/champing-cyberbit-ethiopian-dissidents-targeted-commercial-spyware\nMateski, M., Trevino, C.M., Veitch, C.K., Michalski, J., Harris, J.M., Maruoka, S. and Frye, J. (2012) \"Cyber Threat Metrics\", SANDIA Report, SAND2012-2427, March.\nMinistry of Foreign Affairs of PRC. (2015) \"Foreign Ministry Spokesperson Hong Lei's Regular Press Conference\", Ministry of Foreign Affairs, the People's Republic of China, 5 June.\nMueller, M., Grindal, K., Kuerbis, B. and Badiei, F. (2019) \"Cyber Attribution\", The Cyber Defense Review, Vol. 4, No. 1.\nNeutze, J. (2016) \"The role of cybernorms in preventing digital warfare\", [online], Microsoft EU Policy Blog, blogs.microsoft.com/eupolicy/2016/07/08/the-role-of-cybernorms-in-preventing-digital-warfare/\nNicholson, A., Janicke, H., Watson, T. and Smith, R. (2015) \"Rolling the Dice - Deceptive authentication for attack attribution\", Proceedings of the 10th International Conference on Cyber Warfare and Security, ICCWS.\nO'Leary, J., Kimble, J., Vanderlee, K. and Fraser, N. (2017) \"Insights into Iranian Cyber Espionage: APT33 Targets Aerospace and Energy Sectors and has Ties to Destructive Malware\", [online], FireEye. www.fireeye.com/blog/threat-research/2017/09/apt33-insights-into-iranian-cyber-espionage.html\nODNI. (2018) A Guide to Cyber Attribution, Office of the director of national intelligence\nOttis, R. (2009) Theoretical Model for Creating a Nation-State Level Offensive Cyber Capability, European Conference on Information Warfare and Security\nPahi, T. and Skopik, F. (2019) Cyber Attribution 2.0: Capture the False Flag, European Conference on Cyber Warfare and Security.\nPorter, C. (2017) \"Private Sector Cyber Intelligence Could Be Key to Workable Cyber Arms Control Treaties\", [online], Lawfare www.lawfareblog.com/private-sector-cyber-intelligence-could-be-key-workable-cyber-arms-control-treaties\nPWC. (2017) \"Operation Cloud Hopper\", [online], PwC, www.pwc.co.uk/cyber%0Ahttps://www.pwc.co.uk/cyber-security/pdf/cloud-hopper-report-final-v4.pdf\nReaqta. (2017) \"A dive into MuddyWater APT targeting\", [online], Reaqta, reaqta.com/2017/11/muddywater-apt-targeting-middle-east\nReyes, G., Adams, D., Cooper, J. and Camacaro, D. (2017) \"EXCLUSIVE: Panama's expresident wiretapped Americans, according to court documents\", [online], Univision, 24 June, www.univision.com/univision-news/latin-america/exclusive-panamas-ex-president-wiretapped-americans-according-to-court-documents\nRid, T. and Buchanan, B. (2015) \"Attributing Cyber Attacks\", Journal of Strategic Studies, Vol. 38, No. 1-2.\nRomanosky, S. and Boudreaux, B. (2019) Private Sector Attribution of Cyber Incidents: Benefits and Risks to the U.S. Government, National Security Research Division. RAND, February.\nSchmitt, M. and Vihul, L. (2017) \"International Cyber Law Politicized: The UN GGE's Failure to Advance Cyber Norms\", [online], Just Security, www.justsecurity.org/42768/international-cyber-law-politicized-gges-failure-advance-cybernorms/\n175\nHenrik Karlzén\nSecureworks. (2017) \"BRONZE BUTLER Targets Japanese Enterprises\", [online], Secureworks, www.secureworks.com/research/bronze-butler-targets-japanese-businesses\nShakarian, P., Simari, G.I., Moores, G. and Parsons, S. (2015) \"Cyber attribution: An argumentation-based approach\", Advances in Information Security, Vol. 56.\nSymantec. (2017) \"WannaCry: Ransomware attacks show strong links to Lazarus group\", [online], Symantec, www.symantec.com/connect/blogs/wannacry-ransomware-attacks-show-strong-links-lazarus-group\nSymantec. (2018) \"The Cyber Security Whodunnit: Challenges in Attribution of Targeted Attacks\", [online], Symantec, www.symantec.com/blogs/expert-perspectives/cyber-security-whodunnit-challenges-attribution-targeted-attacks\nThreatConnect. (2017a) \"Fancy Bear Pens the Worst Blog Posts Ever\", [online], ThreatConnect, threatconnect.com/blog/fancy-bear-leverages-blogspot/\nThreatConnect. (2017b) \"Parlez-vous Fancy?\", [online], ThreatConnect, threatconnect.com/blog/activity-targeting-french-election/\nTsagourias, N. (2012) \"Cyber attacks, self-defence and the problem of attribution\", Journal of Conflict and Security Law, Vol. 17, No. 2.\nValeriano, B. and Maness, R. (2013) \"The Dynamics of Cyber Conflict between Rival Antagonists, 2001-2011\", Journal of Peace Research, February.\nWheeler, D.A., Larsen, G.N. and Leader, T. (2003) \"Techniques for cyber attack attribution\", [online], Institute for Defense Analyses, October, apps.dtic.mil/dtic/tr/fulltext/u2/a468859.pdf\nWikileaks. (2017a) \"Development Tradecraft DOs and DON'Ts\", [online], wikileaks.org/ciav7p1/cms/page_14587109.html\nWikileaks. (2017b) \"Vault 7: Projects\", [online], wikileaks.org/vault7\nWikileaks. (2017c) \"Vault 7: CIA Hacking Tools Revealed\", [online], wikileaks.org/ciav7p1\nYadron, D. (2015) \"When Cybersecurity Meets Geopolitics\", [online], Wall Street Journal, 23 March, blogs.wsj.com/digits/2015/03/23/when-cybersecurity-meets-geopolitics/\nZetter, K. (2017) \"Masquerading hackers are forcing a rethink of how attacks are traced\", [online], The Intercept, 4 October, theintercept.com/2017/10/04/masquerading-hackers-are-forcing-a-rethink-of-how-attacks-are-traced\n176\nPetri Jääskeläinen is a masters student from the Faculty of Information Technology and Communication Sciences in Tampere University. He also works as a freelance journalist specialized in radicalized movements, disinformation, conspiracy theories and technology.\nYahlieel Jafta a Software Developer and has been working professionally since 2012. Areas of interest include Software Design patterns and Test Driven Development with a keen interest in Domain Driven Development and Artificial Intelligence. He holds a BSc in Computer Science and is currently completing his Computer Science Honours degree at the University of the Western Cape.\nDr. Victor J Jaquire has been within the field of cyber and information security for over 20 years within government and private sector focusing on strategy, performance management and operations. He holds d PhD in Informatics from the University of Johannesburg - specialising in strategies for cyber counterintelligence maturity and the security of cyberspace. His professional certifications include CISSP, CISM and CCISO.\nJiri Jelinek Ph.D. (Czech Technical University in Prague). He worked a long time at the University of Economics, Prague. Since 2011 he is a professor assistant in the Institute of Applied Informatics of Faculty of Science at the University of South Bohemia in České Budějovice. Professional interests include distributed artificial intelligence, neural networks, multi-agent systems, social networks, and simulation models.\nJuozapavičius holds a PhD in theoretical physics from KTH Royal Institute of Technology, Sweden. He leads the Department of Defence Technologies at General Jonas Žemaitis Military Academy of Lithuania. His research interests are cybersecurity and computer modelling. He participates in EU-funded cybersecurity-related projects, and he is responsible for the cybersecurity specialisation of the study programs\nDr. Connie Justice has over 30 years' experience in cybersecurity, computer, and systems engineering. She designed courses in cybersecurity curriculum to NSA/DHS Center of Academic Excellence and NIST National Initiative for Cybersecurity Education standards. Research areas include: misinformation, industrial controls risk, experiential learning, information and security risk management, digital forensics.\nLt.Col Harry Kantola conducts research at the Finnish National Defence University, Helsinki. Also currently appointed to the Finnish Army Signal School as commandant.. He served in various capacities in the Finnish Navy, Armoured Signal Coy, and Armoured Brigade from 1991. Also served as a researcher at the NATO Cooperative Cyber Defence Centre of Excellence, Tallinn, Estonia and Chief of Cyber Division in C5 Agency.\nPhD Martti J Kari is university teacher of cyber security, hybrid threats and strategic intelligence in Jyväskylä University, Finland. He retired as colonel from Finnish Defense Intelligence in the end of year 2017. His last post in military was Assistant Chief of Defense Intelligence. He has MA in Russian language (1993) and literature, MA in cyber security (2017), and PhD in cyber security 2019 in Jyväskylä University. The topic of his PhD thesis was Russian cyber threat perception.\nMr. Antti Kariluoto is a data science and an artificial intelligence enthusiast who researches smart buildings, cybersecurity, and blockchain in the University of Jyväskylä.\nHenrik Karlzén is a researcher at the Swedish Defence Research Agency and got his master's in cyber security in 2009 at Chalmers University of Technology, Gothenburg, Sweden. His research focuses on cyberwar, risk management, culture and behaviour.\nDr. Kiviharju works as a principal scientist in the Finnish Defence Research Agency in Cyber Defence, for 16 years now. Kiviharju wrote his PhD in cryptography, and specializes in the technological aspects of the cyberspace.\nThorsten Kodalle LTC (General Staff) lectures on security policy (Command and Staff College of the German Armed Forces) with a particular focus on NATO, Critical Infrastructure and Cyber. A member of the NATO research task group \"Gamification of Cyber Defense/Resilience\", an experienced facilitator of manual wargaming on the operational level for courses of action analysis, for operational analysis, operations research, serious gaming and especially for matrix wargaming.\nxiv\nReproduced with permission of copyright owner. Further reproduction prohibited without permission."
  ],
  "citations": {
    "style": "author_year",
    "flat_text": "Henrik Karlzén\nSwedish Defence Research Agency, Linköping, Sweden\nhenrik.karlzen@foi.se\nDOI: 10.34190/EWS.20.074\nAbstract: Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.\nKeywords: cyberattack, attribution, cyber operation, APT, security, usefulness\n# 1. Introduction\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions , or by counter-attacking . This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty ). These possibilities also mean that attribution can be a deterrent . Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state . Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action . Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR .\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks . They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies . On the other hand, intelligence agencies – that have good sources both in cyber and other domains  – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor . It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors , a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) , or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n# 1.1 Related work\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds , and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods .\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n# 2. Method\nThe next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n# 2.1 Cyberattack databases\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)\nHenrik Karlzén\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks , and is updated quarterly . It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers .\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\nTable 1: Sample attack in CFR (shortened).\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n# 2.2 Categorisations of attribution indicators\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |\nHenrik Karlzén\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).\n# 3. Attribution indicators in theory and practice\nThe CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that\nHenrik Karlzén\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\nTable 3: Attribution indicator categories and practical examples.\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible   |\n|  Entry | Spearphishing   |\n|   |  Supply-chain attack   |\n|  Targeting | Target fitting national interests   |\n|   |  Diverse targeting   |\n|  Infrastructure | Nationality of DNS servers  and IP-addresses   |\n|   |  Spoofed domains   |\n|   |  C2   |\n|   |  Links via legitimate websites to trick filters   |\n|  Modularity | Open source tools   |\n|   |  Nationality of tools   |\n|   |  Tool demonstration log files   |\n|   |  Code   |\n|  Language | System language settings   |\n|   |  Artefacts in specific natural language   |\n|   |  Poor or unusual use of natural language   |\n|  Personas | Recurring names in code   |\n|  Pattern-of-Life | Reduced attack activity during certain holidays   |\n|   |  Compilation on certain countries' working hours   |\n|  Stealth | Type of code obfuscation   |\n|   |  Type of crypto-mechanism   |\n|  Cluster | Similar process-trees   |\n|  Functionality | Gather information   |\n|   |  Destroy data   |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch   |\n|  Mistakes | Mistakenly accessing without proxy   |\n|  Skills | Capability   |\n|  Scope | Attacks to obtain code signing certificates for later attacks   |\n|  Stages | Several teams cooperating   |\n|  Evolution | First targeting diplomatic entities, then defence organisations   |\n|   |  Adapts and learns to evade detection   |\n|  Claims | Former team member admission   |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions   |\n|  Cost | Massive infrastructure to decrypt and analyse   |\n|  Significance (for attacker) | Valuable   |\n|  Context | Victim a certain country showed interest in   |\n|  Benefit | A certain nation   |\n|  Consequences | Serious for a nation's security   |\n|   |  Intelligence gathering   |\n# 4. Discussion\nThe following subsections discuss practical difficulties with attribution, and limitations of the empirical data.\nHenrik Karlzén\n## 4.1 Practical difficulties with attribution\nAttribution is slow and often requires weeks or months of analysis . Attributing cyberattacks is also difficult , although the news media often overstate the problems in order to appear balanced in their reporting .\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available .\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware . Allegedly, more than half of Stuxnet development costs were for anti-attribution . The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings  or adding text in different languages . Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet .\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability  and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" .\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers . However, this would be difficult to accomplish , and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses , as in Fokker and Beek (2019), using independent reviews , or public disagreements between analysts as in e.g. Lancaster (2017).\n## 4.2 Limitations of the empirical data\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods . Attribution can also be harmful to one's reputation, or even dangerous . Companies do not point fingers at nation-states as often as other nation-states do , and US companies may hesitate to point fingers at the US government . Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation .\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law . However, weaker evidence may lead to stronger evidence , or be sufficient for security decision-making . There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments . Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale . Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) , and obfuscate (when attacking). Furthermore,\nHenrik Karlzén\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).\n# 5. Conclusions\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "168\n# Usefulness of Cyber Attribution Indicators\nHenrik Karlzén\nSwedish Defence Research Agency, Linköping, Sweden\nhenrik.karlzen@foi.se\nDOI: 10.34190/EWS.20.074\nAbstract: Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.\nKeywords: cyberattack, attribution, cyber operation, APT, security, usefulness\n# 1. Introduction\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions (Davis et al., 2017), or by counter-attacking (Egloff, 2018). This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty (Porter, 2017)). These possibilities also mean that attribution can be a deterrent (Floyd, 2018). Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state (Illinois, 2018). Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action (Ahmed and Perlroth, 2019). Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR (Davis et al., 2017).\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks (Romanosky and Boudreaux, 2019). They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies (Bartholomew and Guerrero-Saade, 2016). On the other hand, intelligence agencies – that have good sources both in cyber and other domains (Malik, 2017; Symantec, 2018) – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor (Romanosky and Boudreaux, 2019). It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors (Davis et al., 2017), a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) (Neutze, 2016), or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n# 1.1 Related work\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds (DARPA, 2016a), and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods (DARPA, 2016b).\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n# 2. Method\nThe next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n# 2.1 Cyberattack databases\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)\nHenrik Karlzén\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks (Romanosky and Boudreaux, 2019), and is updated quarterly (CFR, 2019). It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers (CFR, 2019).\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\nTable 1: Sample attack in CFR (shortened).\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n# 2.2 Categorisations of attribution indicators\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |\nHenrik Karlzén\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).\n# 3. Attribution indicators in theory and practice\nThe CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that\nHenrik Karlzén\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\nTable 3: Attribution indicator categories and practical examples.\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible (Cherepanov, 2017)  |\n|  Entry | Spearphishing (Great, 2017)  |\n|   |  Supply-chain attack (Cherepanov, 2017)  |\n|  Targeting | Target fitting national interests (ThreatConnect, 2017a; O'Leary et al., 2017)  |\n|   |  Diverse targeting (Secureworks, 2017)  |\n|  Infrastructure | Nationality of DNS servers (O'Leary et al., 2017) and IP-addresses (Reaqta, 2017; Marczak et al., 2017)  |\n|   |  Spoofed domains (ThreatConnect, 2017b)  |\n|   |  C2 (PWC, 2017; Symantec, 2017)  |\n|   |  Links via legitimate websites to trick filters (ThreatConnect, 2017a)  |\n|  Modularity | Open source tools (Lancaster, 2017)  |\n|   |  Nationality of tools (O'Leary et al., 2017)  |\n|   |  Tool demonstration log files (Marczak et al., 2017)  |\n|   |  Code (Symantec, 2017)  |\n|  Language | System language settings (Reaqta, 2017; Atch and Neray, 2017)  |\n|   |  Artefacts in specific natural language (O'Leary et al., 2017; Secureworks, 2017)  |\n|   |  Poor or unusual use of natural language (Great, 2017)  |\n|  Personas | Recurring names in code (Symantec, 2017; O'Leary et al., 2017)  |\n|  Pattern-of-Life | Reduced attack activity during certain holidays (Secureworks, 2017; O'Leary et al., 2017)  |\n|   |  Compilation on certain countries' working hours (PWC, 2017)  |\n|  Stealth | Type of code obfuscation (Symantec, 2017)  |\n|   |  Type of crypto-mechanism (Hegel, 2018)  |\n|  Cluster | Similar process-trees (Reaqta, 2017)  |\n|  Functionality | Gather information (Goeij, 2017)  |\n|   |  Destroy data (Cherepanov, 2017)  |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch (Symantec, 2017)  |\n|  Mistakes | Mistakenly accessing without proxy (Hegel, 2018)  |\n|  Skills | Capability (Atch and Neray, 2017)  |\n|  Scope | Attacks to obtain code signing certificates for later attacks (Hegel, 2018)  |\n|  Stages | Several teams cooperating (PWC, 2017; Hegel, 2018)  |\n|  Evolution | First targeting diplomatic entities, then defence organisations (Great, 2017)  |\n|   |  Adapts and learns to evade detection (Hegel, 2018)  |\n|  Claims | Former team member admission (Reyes et al., 2017)  |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions (Hegel, 2018)  |\n|  Cost | Massive infrastructure to decrypt and analyse (Atch and Neray, 2017)  |\n|  Significance (for attacker) | Valuable (Secureworks, 2017)  |\n|  Context | Victim a certain country showed interest in (O'Leary et al., 2017; PWC, 2017  |\n|   |  Statements from officials (Goeij, 2017; Huetteman, 2017; Homewood, 2017)  |\n|  Benefit | A certain nation (Homewood, 2017)  |\n|  Consequences | Serious for a nation's security (Goeij, 2017)  |\n|   |  Intelligence gathering (Atch and Neray, 2017)  |\n# 4. Discussion\nThe following subsections discuss practical difficulties with attribution, and limitations of the empirical data.\nHenrik Karlzén\n## 4.1 Practical difficulties with attribution\nAttribution is slow and often requires weeks or months of analysis (ODNI, 2018). Attributing cyberattacks is also difficult (Keromytis, 2016), although the news media often overstate the problems in order to appear balanced in their reporting (Bartholomew and Guerrero-Saade, 2016).\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available (Bartholomew and Guerrero-Saade, 2016).\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware (Boot, 2019). Allegedly, more than half of Stuxnet development costs were for anti-attribution (Langner, 2013). The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings (Pahi and Skopik, 2019) or adding text in different languages (Bartholomew and Guerrero-Saade, 2016). Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet (Bartholomew and Guerrero-Saade, 2016).\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability (Floyd, 2018) and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" (Zetter, 2017).\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers (Nicholson et al., 2015). However, this would be difficult to accomplish (Cook et al., 2016), and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses (ODNI, 2018), as in Fokker and Beek (2019), using independent reviews (Davis et al., 2017), or public disagreements between analysts as in e.g. Lancaster (2017).\n## 4.2 Limitations of the empirical data\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods (Rid and Buchanan, 2015; Bartholomew and Guerrero-Saade, 2016). Attribution can also be harmful to one's reputation, or even dangerous (Romanosky and Boudreaux, 2019). Companies do not point fingers at nation-states as often as other nation-states do (Mueller et al., 2019), and US companies may hesitate to point fingers at the US government (Yadron, 2015; Romanosky and Boudreaux, 2019). Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation (Rid and Buchanan, 2015).\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law (Berghel, 2017). However, weaker evidence may lead to stronger evidence (Clark and Landau, 2010), or be sufficient for security decision-making (Tsagourias, 2012). There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments (Shakarian et al., 2015; Davis et al., 2017). Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale (Davis et al., 2017). Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) (Schmitt and Vihul, 2017), and obfuscate (when attacking). Furthermore,\nHenrik Karlzén\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).\n# 5. Conclusions\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute."
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "168\n# Usefulness of Cyber Attribution Indicators\nHenrik Karlzén\nSwedish Defence Research Agency, Linköping, Sweden\nhenrik.karlzen@foi.se\nDOI: 10.34190/EWS.20.074\nAbstract: Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.\nKeywords: cyberattack, attribution, cyber operation, APT, security, usefulness\n# 1. Introduction\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions (Davis et al., 2017), or by counter-attacking (Egloff, 2018). This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty (Porter, 2017)). These possibilities also mean that attribution can be a deterrent (Floyd, 2018). Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state (Illinois, 2018). Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action (Ahmed and Perlroth, 2019). Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR (Davis et al., 2017).\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks (Romanosky and Boudreaux, 2019). They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies (Bartholomew and Guerrero-Saade, 2016). On the other hand, intelligence agencies – that have good sources both in cyber and other domains (Malik, 2017; Symantec, 2018) – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor (Romanosky and Boudreaux, 2019). It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors (Davis et al., 2017), a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) (Neutze, 2016), or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n# 1.1 Related work\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds (DARPA, 2016a), and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods (DARPA, 2016b).\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n# 2. Method\nThe next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n# 2.1 Cyberattack databases\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)\nHenrik Karlzén\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks (Romanosky and Boudreaux, 2019), and is updated quarterly (CFR, 2019). It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers (CFR, 2019).\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\nTable 1: Sample attack in CFR (shortened).\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n# 2.2 Categorisations of attribution indicators\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |\nHenrik Karlzén\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).\n# 3. Attribution indicators in theory and practice\nThe CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that\nHenrik Karlzén\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\nTable 3: Attribution indicator categories and practical examples.\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible (Cherepanov, 2017)  |\n|  Entry | Spearphishing (Great, 2017)  |\n|   |  Supply-chain attack (Cherepanov, 2017)  |\n|  Targeting | Target fitting national interests (ThreatConnect, 2017a; O'Leary et al., 2017)  |\n|   |  Diverse targeting (Secureworks, 2017)  |\n|  Infrastructure | Nationality of DNS servers (O'Leary et al., 2017) and IP-addresses (Reaqta, 2017; Marczak et al., 2017)  |\n|   |  Spoofed domains (ThreatConnect, 2017b)  |\n|   |  C2 (PWC, 2017; Symantec, 2017)  |\n|   |  Links via legitimate websites to trick filters (ThreatConnect, 2017a)  |\n|  Modularity | Open source tools (Lancaster, 2017)  |\n|   |  Nationality of tools (O'Leary et al., 2017)  |\n|   |  Tool demonstration log files (Marczak et al., 2017)  |\n|   |  Code (Symantec, 2017)  |\n|  Language | System language settings (Reaqta, 2017; Atch and Neray, 2017)  |\n|   |  Artefacts in specific natural language (O'Leary et al., 2017; Secureworks, 2017)  |\n|   |  Poor or unusual use of natural language (Great, 2017)  |\n|  Personas | Recurring names in code (Symantec, 2017; O'Leary et al., 2017)  |\n|  Pattern-of-Life | Reduced attack activity during certain holidays (Secureworks, 2017; O'Leary et al., 2017)  |\n|   |  Compilation on certain countries' working hours (PWC, 2017)  |\n|  Stealth | Type of code obfuscation (Symantec, 2017)  |\n|   |  Type of crypto-mechanism (Hegel, 2018)  |\n|  Cluster | Similar process-trees (Reaqta, 2017)  |\n|  Functionality | Gather information (Goeij, 2017)  |\n|   |  Destroy data (Cherepanov, 2017)  |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch (Symantec, 2017)  |\n|  Mistakes | Mistakenly accessing without proxy (Hegel, 2018)  |\n|  Skills | Capability (Atch and Neray, 2017)  |\n|  Scope | Attacks to obtain code signing certificates for later attacks (Hegel, 2018)  |\n|  Stages | Several teams cooperating (PWC, 2017; Hegel, 2018)  |\n|  Evolution | First targeting diplomatic entities, then defence organisations (Great, 2017)  |\n|   |  Adapts and learns to evade detection (Hegel, 2018)  |\n|  Claims | Former team member admission (Reyes et al., 2017)  |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions (Hegel, 2018)  |\n|  Cost | Massive infrastructure to decrypt and analyse (Atch and Neray, 2017)  |\n|  Significance (for attacker) | Valuable (Secureworks, 2017)  |\n|  Context | Victim a certain country showed interest in (O'Leary et al., 2017; PWC, 2017  |\n|   |  Statements from officials (Goeij, 2017; Huetteman, 2017; Homewood, 2017)  |\n|  Benefit | A certain nation (Homewood, 2017)  |\n|  Consequences | Serious for a nation's security (Goeij, 2017)  |\n|   |  Intelligence gathering (Atch and Neray, 2017)  |\n# 4. Discussion\nThe following subsections discuss practical difficulties with attribution, and limitations of the empirical data.\nHenrik Karlzén\n## 4.1 Practical difficulties with attribution\nAttribution is slow and often requires weeks or months of analysis (ODNI, 2018). Attributing cyberattacks is also difficult (Keromytis, 2016), although the news media often overstate the problems in order to appear balanced in their reporting (Bartholomew and Guerrero-Saade, 2016).\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available (Bartholomew and Guerrero-Saade, 2016).\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware (Boot, 2019). Allegedly, more than half of Stuxnet development costs were for anti-attribution (Langner, 2013). The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings (Pahi and Skopik, 2019) or adding text in different languages (Bartholomew and Guerrero-Saade, 2016). Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet (Bartholomew and Guerrero-Saade, 2016).\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability (Floyd, 2018) and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" (Zetter, 2017).\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers (Nicholson et al., 2015). However, this would be difficult to accomplish (Cook et al., 2016), and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses (ODNI, 2018), as in Fokker and Beek (2019), using independent reviews (Davis et al., 2017), or public disagreements between analysts as in e.g. Lancaster (2017).\n## 4.2 Limitations of the empirical data\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods (Rid and Buchanan, 2015; Bartholomew and Guerrero-Saade, 2016). Attribution can also be harmful to one's reputation, or even dangerous (Romanosky and Boudreaux, 2019). Companies do not point fingers at nation-states as often as other nation-states do (Mueller et al., 2019), and US companies may hesitate to point fingers at the US government (Yadron, 2015; Romanosky and Boudreaux, 2019). Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation (Rid and Buchanan, 2015).\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law (Berghel, 2017). However, weaker evidence may lead to stronger evidence (Clark and Landau, 2010), or be sufficient for security decision-making (Tsagourias, 2012). There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments (Shakarian et al., 2015; Davis et al., 2017). Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale (Davis et al., 2017). Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) (Schmitt and Vihul, 2017), and obfuscate (when attacking). Furthermore,\nHenrik Karlzén\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).\n# 5. Conclusions\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute."
    },
    "author_year": {
      "total": {
        "intext_total": 84,
        "success_occurrences": 82,
        "success_unique": 44,
        "bib_unique_total": 129,
        "occurrence_match_rate": 0.9761904761904762,
        "bib_coverage_rate": 0.34108527131782945,
        "success_percentage": 97.62,
        "style": "author_year"
      },
      "results": [
        {
          "index": "davis|2017",
          "intext_citation": "(Davis et al., 2017)",
          "preceding_text": "First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions",
          "footnote": "Davis, J., Boudreaux, B., Welburn, J., Aguirre, J., Ogletree, C., McGovern, G. and Chase, M. (2017) \"Stateless Attribution: Toward International Accountability in Cyberspace\", RAND."
        },
        {
          "index": "egloff|2018",
          "intext_citation": "(Egloff, 2018)",
          "preceding_text": "First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions (Davis et al., 2017), or by counter-attacking",
          "footnote": "Egloff, F.J. (2018) \"Cybersecurity and Non-State Actors\", Ph.D. thesis, University of Oxford."
        },
        {
          "index": "porter|2017",
          "intext_citation": "(Porter, 2017)",
          "preceding_text": "by using sanctions (Davis et al., 2017), or by counter-attacking (Egloff, 2018). This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty",
          "footnote": "Porter, C. (2017) \"Private Sector Cyber Intelligence Could Be Key to Workable Cyber Arms Control Treaties\", [online], Lawfare www.lawfareblog.com/private-sector-cyber-intelligence-could-be-key-workable-cyber-arms-control-treaties"
        },
        {
          "index": "floyd|2018",
          "intext_citation": "(Floyd, 2018)",
          "preceding_text": "This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty (Porter, 2017)). These possibilities also mean that attribution can be a deterrent",
          "footnote": "Floyd, G.S. (2018) \"Attribution and Operational Art: Implications for Competing in Time\", Strategic Studies Quarterly, Vol. 12, No. 2."
        },
        {
          "index": "illinois|2018",
          "intext_citation": "(Illinois, 2018)",
          "preceding_text": "ve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state",
          "footnote": "Illinois. (2018) \"2018 WL 4941760 (Ill.Cir.Ct.) (Trial Pleading). MONDELEZ INTERNATIONAL, INC., Plaintiff, v. ZURICH AMERICAN INSURANCE COMPANY, Defendant\", Circuit Court of Illinois."
        },
        {
          "index": "ahmed|2019",
          "intext_citation": "(Ahmed and Perlroth, 2019)",
          "preceding_text": "Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action",
          "footnote": "Ahmed, B.A. and Perlroth, N. (2019) \"Using Texts as Lures, Government Spyware Targets Mexican Journalists and Their Families\", [online], New York Times, 19 June, www.nytimes.com/2017/06/19/world/americas/mexico-spyware-anticrime.html"
        },
        {
          "index": "davis|2017",
          "intext_citation": "(Davis et al., 2017)",
          "preceding_text": "Fifth, cyber security companies can use attribution as a proof-of-concept or for PR",
          "footnote": "Davis, J., Boudreaux, B., Welburn, J., Aguirre, J., Ogletree, C., McGovern, G. and Chase, M. (2017) \"Stateless Attribution: Toward International Accountability in Cyberspace\", RAND."
        },
        {
          "index": "romanosky|2019",
          "intext_citation": "(Romanosky and Boudreaux, 2019)",
          "preceding_text": "Attribution is often conducted by multinational cyber security companies that provide good insight into networks",
          "footnote": "Romanosky, S. and Boudreaux, B. (2019) Private Sector Attribution of Cyber Incidents: Benefits and Risks to the U.S. Government, National Security Research Division. RAND, February."
        },
        {
          "index": "bartholomew|2016",
          "intext_citation": "(Bartholomew and Guerrero-Saade, 2016)",
          "preceding_text": "They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies",
          "footnote": "Bartholomew, B. and Guerrero-Saade, J.A. (2016) \"Wave Your False Flags! Deception Tactics Muddying Attribution in Targeted Attacks\", Virus Bulletin, October."
        },
        {
          "index": "malik|2017",
          "intext_citation": "(Malik, 2017; Symantec, 2018)",
          "preceding_text": "On the other hand, intelligence agencies – that have good sources both in cyber and other domains",
          "footnote": "Malik, W. (2017) \"What are the benefits of attribution?\", [online], TrendMicro, 16 August, blog.trendmicro.com/what-are-the-benefits-of-attribution/"
        },
        {
          "index": "romanosky|2019",
          "intext_citation": "(Romanosky and Boudreaux, 2019)",
          "preceding_text": "to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor",
          "footnote": "Romanosky, S. and Boudreaux, B. (2019) Private Sector Attribution of Cyber Incidents: Benefits and Risks to the U.S. Government, National Security Research Division. RAND, February."
        },
        {
          "index": "davis|2017",
          "intext_citation": "(Davis et al., 2017)",
          "preceding_text": "It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors",
          "footnote": "Davis, J., Boudreaux, B., Welburn, J., Aguirre, J., Ogletree, C., McGovern, G. and Chase, M. (2017) \"Stateless Attribution: Toward International Accountability in Cyberspace\", RAND."
        },
        {
          "index": "neutze|2016",
          "intext_citation": "(Neutze, 2016)",
          "preceding_text": "in a consortium of private actors (Davis et al., 2017), a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency)",
          "footnote": "Neutze, J. (2016) \"The role of cybernorms in preventing digital warfare\", [online], Microsoft EU Policy Blog, blogs.microsoft.com/eupolicy/2016/07/08/the-role-of-cybernorms-in-preventing-digital-warfare/"
        },
        {
          "index": "darpa|2016a",
          "intext_citation": "(DARPA, 2016a)",
          "preceding_text": "The program aims to decrease the time for attribution from months to hours or even seconds",
          "footnote": "DARPA. (2016a) \"DARPA-BAA-16-34, Enhanced Attribution, Frequently Asked Questions\", DARPA."
        },
        {
          "index": "darpa|2016b",
          "intext_citation": "(DARPA, 2016b)",
          "preceding_text": "vember 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds (DARPA, 2016a), and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods",
          "footnote": "DARPA. (2016b) \"Broad Agency Announcement Enhanced Attribution DARPA-BAA-16-34\", DARPA."
        },
        {
          "index": "romanosky|2019",
          "intext_citation": "(Romanosky and Boudreaux, 2019)",
          "preceding_text": "This is also the most complete database for state-sponsored cyberattacks",
          "footnote": "Romanosky, S. and Boudreaux, B. (2019) Private Sector Attribution of Cyber Incidents: Benefits and Risks to the U.S. Government, National Security Research Division. RAND, February."
        },
        {
          "index": "cfr|2019",
          "intext_citation": "(CFR, 2019)",
          "preceding_text": "This is also the most complete database for state-sponsored cyberattacks (Romanosky and Boudreaux, 2019), and is updated quarterly",
          "footnote": null
        },
        {
          "index": "cfr|2019",
          "intext_citation": "(CFR, 2019)",
          "preceding_text": "ersa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers",
          "footnote": null
        },
        {
          "index": "cherepanov|2017",
          "intext_citation": "(Cherepanov, 2017)",
          "preceding_text": "|  Indicators of compromise | Data inaccessible",
          "footnote": "Cherepanov, A. (2017) \"TeleBots are back: Supply-chain attacks against Ukraine\", [online], Eset, https://www.welivesecurity.com/2017/06/30/telebots-back-supply-chain-attacks-against-ukraine/"
        },
        {
          "index": "great|2017",
          "intext_citation": "(Great, 2017)",
          "preceding_text": "|  Entry | Spearphishing",
          "footnote": "Great. (2017) \"Introducing WhiteBear\", Securelist, [online], Kaspersky, securelist.com/introducing-whitebear/81638/%0A"
        },
        {
          "index": "cherepanov|2017",
          "intext_citation": "(Cherepanov, 2017)",
          "preceding_text": "|   |  Supply-chain attack",
          "footnote": "Cherepanov, A. (2017) \"TeleBots are back: Supply-chain attacks against Ukraine\", [online], Eset, https://www.welivesecurity.com/2017/06/30/telebots-back-supply-chain-attacks-against-ukraine/"
        },
        {
          "index": "threatconnect|2017a",
          "intext_citation": "(ThreatConnect, 2017a; O'Leary et al., 2017)",
          "preceding_text": "|  Targeting | Target fitting national interests",
          "footnote": "ThreatConnect. (2017a) \"Fancy Bear Pens the Worst Blog Posts Ever\", [online], ThreatConnect, threatconnect.com/blog/fancy-bear-leverages-blogspot/"
        },
        {
          "index": "secureworks|2017",
          "intext_citation": "(Secureworks, 2017)",
          "preceding_text": "|   |  Diverse targeting",
          "footnote": "Secureworks. (2017) \"BRONZE BUTLER Targets Japanese Enterprises\", [online], Secureworks, www.secureworks.com/research/bronze-butler-targets-japanese-businesses"
        },
        {
          "index": "oleary|2017",
          "intext_citation": "(O'Leary et al., 2017)",
          "preceding_text": "|  Infrastructure | Nationality of DNS servers",
          "footnote": "O'Leary, J., Kimble, J., Vanderlee, K. and Fraser, N. (2017) \"Insights into Iranian Cyber Espionage: APT33 Targets Aerospace and Energy Sectors and has Ties to Destructive Malware\", [online], FireEye. www.fireeye.com/blog/threat-research/2017/09/apt33-insights-into-iranian-cyber-espionage.html"
        },
        {
          "index": "reaqta|2017",
          "intext_citation": "(Reaqta, 2017; Marczak et al., 2017)",
          "preceding_text": "|  Infrastructure | Nationality of DNS servers (O'Leary et al., 2017) and IP-addresses",
          "footnote": "Reaqta. (2017) \"A dive into MuddyWater APT targeting\", [online], Reaqta, reaqta.com/2017/11/muddywater-apt-targeting-middle-east"
        },
        {
          "index": "threatconnect|2017b",
          "intext_citation": "(ThreatConnect, 2017b)",
          "preceding_text": "|   |  Spoofed domains",
          "footnote": "ThreatConnect. (2017b) \"Parlez-vous Fancy?\", [online], ThreatConnect, threatconnect.com/blog/activity-targeting-french-election/"
        },
        {
          "index": "pwc|2017",
          "intext_citation": "(PWC, 2017; Symantec, 2017)",
          "preceding_text": "|   |  C2",
          "footnote": "PWC. (2017) \"Operation Cloud Hopper\", [online], PwC, www.pwc.co.uk/cyber%0Ahttps://www.pwc.co.uk/cyber-security/pdf/cloud-hopper-report-final-v4.pdf"
        },
        {
          "index": "threatconnect|2017a",
          "intext_citation": "(ThreatConnect, 2017a)",
          "preceding_text": "|   |  Links via legitimate websites to trick filters",
          "footnote": "ThreatConnect. (2017a) \"Fancy Bear Pens the Worst Blog Posts Ever\", [online], ThreatConnect, threatconnect.com/blog/fancy-bear-leverages-blogspot/"
        },
        {
          "index": "lancaster|2017",
          "intext_citation": "(Lancaster, 2017)",
          "preceding_text": "|  Modularity | Open source tools",
          "footnote": "Lancaster, T. (2017) \"Muddying the Water: Targeted Attacks in the Middle East\", [online], Palo Alto Networks, researchcenter.paloaltonetworks.com/2017/11/unit42-muddying-the-water-targeted-attacks-in-the-middle-east"
        },
        {
          "index": "oleary|2017",
          "intext_citation": "(O'Leary et al., 2017)",
          "preceding_text": "|   |  Nationality of tools",
          "footnote": "O'Leary, J., Kimble, J., Vanderlee, K. and Fraser, N. (2017) \"Insights into Iranian Cyber Espionage: APT33 Targets Aerospace and Energy Sectors and has Ties to Destructive Malware\", [online], FireEye. www.fireeye.com/blog/threat-research/2017/09/apt33-insights-into-iranian-cyber-espionage.html"
        },
        {
          "index": "marczak|2017",
          "intext_citation": "(Marczak et al., 2017)",
          "preceding_text": "|   |  Tool demonstration log files",
          "footnote": "Marczak, B. (2017) \"Champing at the Cyberbit\", [online], The Citizen Lab, citizenlab.ca/2017/12/champing-cyberbit-ethiopian-dissidents-targeted-commercial-spyware"
        },
        {
          "index": "symantec|2017",
          "intext_citation": "(Symantec, 2017)",
          "preceding_text": "|   |  Code",
          "footnote": "Symantec. (2017) \"WannaCry: Ransomware attacks show strong links to Lazarus group\", [online], Symantec, www.symantec.com/connect/blogs/wannacry-ransomware-attacks-show-strong-links-lazarus-group"
        },
        {
          "index": "reaqta|2017",
          "intext_citation": "(Reaqta, 2017; Atch and Neray, 2017)",
          "preceding_text": "|  Language | System language settings",
          "footnote": "Reaqta. (2017) \"A dive into MuddyWater APT targeting\", [online], Reaqta, reaqta.com/2017/11/muddywater-apt-targeting-middle-east"
        },
        {
          "index": "oleary|2017",
          "intext_citation": "(O'Leary et al., 2017; Secureworks, 2017)",
          "preceding_text": "|   |  Artefacts in specific natural language",
          "footnote": "O'Leary, J., Kimble, J., Vanderlee, K. and Fraser, N. (2017) \"Insights into Iranian Cyber Espionage: APT33 Targets Aerospace and Energy Sectors and has Ties to Destructive Malware\", [online], FireEye. www.fireeye.com/blog/threat-research/2017/09/apt33-insights-into-iranian-cyber-espionage.html"
        },
        {
          "index": "great|2017",
          "intext_citation": "(Great, 2017)",
          "preceding_text": "|   |  Poor or unusual use of natural language",
          "footnote": "Great. (2017) \"Introducing WhiteBear\", Securelist, [online], Kaspersky, securelist.com/introducing-whitebear/81638/%0A"
        },
        {
          "index": "symantec|2017",
          "intext_citation": "(Symantec, 2017; O'Leary et al., 2017)",
          "preceding_text": "|  Personas | Recurring names in code",
          "footnote": "Symantec. (2017) \"WannaCry: Ransomware attacks show strong links to Lazarus group\", [online], Symantec, www.symantec.com/connect/blogs/wannacry-ransomware-attacks-show-strong-links-lazarus-group"
        },
        {
          "index": "secureworks|2017",
          "intext_citation": "(Secureworks, 2017; O'Leary et al., 2017)",
          "preceding_text": "|  Pattern-of-Life | Reduced attack activity during certain holidays",
          "footnote": "Secureworks. (2017) \"BRONZE BUTLER Targets Japanese Enterprises\", [online], Secureworks, www.secureworks.com/research/bronze-butler-targets-japanese-businesses"
        },
        {
          "index": "pwc|2017",
          "intext_citation": "(PWC, 2017)",
          "preceding_text": "|   |  Compilation on certain countries' working hours",
          "footnote": "PWC. (2017) \"Operation Cloud Hopper\", [online], PwC, www.pwc.co.uk/cyber%0Ahttps://www.pwc.co.uk/cyber-security/pdf/cloud-hopper-report-final-v4.pdf"
        },
        {
          "index": "symantec|2017",
          "intext_citation": "(Symantec, 2017)",
          "preceding_text": "|  Stealth | Type of code obfuscation",
          "footnote": "Symantec. (2017) \"WannaCry: Ransomware attacks show strong links to Lazarus group\", [online], Symantec, www.symantec.com/connect/blogs/wannacry-ransomware-attacks-show-strong-links-lazarus-group"
        },
        {
          "index": "hegel|2018",
          "intext_citation": "(Hegel, 2018)",
          "preceding_text": "|   |  Type of crypto-mechanism",
          "footnote": "Hegel, T. (2018) \"Burning Umbrella: An Intelligence Report on the Winnti Umbrella and Associated State-Sponsored Attackers\", [online], 401Trg, 401trg.pw/burning-umbrella/"
        },
        {
          "index": "reaqta|2017",
          "intext_citation": "(Reaqta, 2017)",
          "preceding_text": "|  Cluster | Similar process-trees",
          "footnote": "Reaqta. (2017) \"A dive into MuddyWater APT targeting\", [online], Reaqta, reaqta.com/2017/11/muddywater-apt-targeting-middle-east"
        },
        {
          "index": "goeij|2017",
          "intext_citation": "(Goeij, 2017)",
          "preceding_text": "|  Functionality | Gather information",
          "footnote": "Goeij, H.d. (2017) \"Czech Government Suspects Foreign Power in Hacking of Its Email\", [online], The New York Times, 31 January, www.nytimes.com/2017/01/31/world/europe/czech-government-suspects-foreign-power-in-hacking-of-its-email.html?_r=1%0A"
        },
        {
          "index": "cherepanov|2017",
          "intext_citation": "(Cherepanov, 2017)",
          "preceding_text": "|   |  Destroy data",
          "footnote": "Cherepanov, A. (2017) \"TeleBots are back: Supply-chain attacks against Ukraine\", [online], Eset, https://www.welivesecurity.com/2017/06/30/telebots-back-supply-chain-attacks-against-ukraine/"
        },
        {
          "index": "symantec|2017",
          "intext_citation": "(Symantec, 2017)",
          "preceding_text": "|   |  Existence of kill switch",
          "footnote": "Symantec. (2017) \"WannaCry: Ransomware attacks show strong links to Lazarus group\", [online], Symantec, www.symantec.com/connect/blogs/wannacry-ransomware-attacks-show-strong-links-lazarus-group"
        },
        {
          "index": "hegel|2018",
          "intext_citation": "(Hegel, 2018)",
          "preceding_text": "|  Mistakes | Mistakenly accessing without proxy",
          "footnote": "Hegel, T. (2018) \"Burning Umbrella: An Intelligence Report on the Winnti Umbrella and Associated State-Sponsored Attackers\", [online], 401Trg, 401trg.pw/burning-umbrella/"
        },
        {
          "index": "atch|2017",
          "intext_citation": "(Atch and Neray, 2017)",
          "preceding_text": "|  Skills | Capability",
          "footnote": "Atch, D. and Neray, P. (2017) \"Operation BugDrop: CyberX Discovers Large-Scale Cyber-Reconnaissance Operation Targeting Ukrainian Organizations\", [online], CyberX Labs, cyberx-labs.com/en/blog/operation-bugdrop-cyberx-discovers-large-scale-cyber-reconnaissance-operation/"
        },
        {
          "index": "hegel|2018",
          "intext_citation": "(Hegel, 2018)",
          "preceding_text": "|  Scope | Attacks to obtain code signing certificates for later attacks",
          "footnote": "Hegel, T. (2018) \"Burning Umbrella: An Intelligence Report on the Winnti Umbrella and Associated State-Sponsored Attackers\", [online], 401Trg, 401trg.pw/burning-umbrella/"
        },
        {
          "index": "pwc|2017",
          "intext_citation": "(PWC, 2017; Hegel, 2018)",
          "preceding_text": "|  Stages | Several teams cooperating",
          "footnote": "PWC. (2017) \"Operation Cloud Hopper\", [online], PwC, www.pwc.co.uk/cyber%0Ahttps://www.pwc.co.uk/cyber-security/pdf/cloud-hopper-report-final-v4.pdf"
        },
        {
          "index": "great|2017",
          "intext_citation": "(Great, 2017)",
          "preceding_text": "|  Evolution | First targeting diplomatic entities, then defence organisations",
          "footnote": "Great. (2017) \"Introducing WhiteBear\", Securelist, [online], Kaspersky, securelist.com/introducing-whitebear/81638/%0A"
        },
        {
          "index": "hegel|2018",
          "intext_citation": "(Hegel, 2018)",
          "preceding_text": "|   |  Adapts and learns to evade detection",
          "footnote": "Hegel, T. (2018) \"Burning Umbrella: An Intelligence Report on the Winnti Umbrella and Associated State-Sponsored Attackers\", [online], 401Trg, 401trg.pw/burning-umbrella/"
        },
        {
          "index": "reyes|2017",
          "intext_citation": "(Reyes et al., 2017)",
          "preceding_text": "|  Claims | Former team member admission",
          "footnote": "Reyes, G., Adams, D., Cooper, J. and Camacaro, D. (2017) \"EXCLUSIVE: Panama's expresident wiretapped Americans, according to court documents\", [online], Univision, 24 June, www.univision.com/univision-news/latin-america/exclusive-panamas-ex-president-wiretapped-americans-according-to-court-documents"
        },
        {
          "index": "hegel|2018",
          "intext_citation": "(Hegel, 2018)",
          "preceding_text": "|  Intelligence | Target's email solutions",
          "footnote": "Hegel, T. (2018) \"Burning Umbrella: An Intelligence Report on the Winnti Umbrella and Associated State-Sponsored Attackers\", [online], 401Trg, 401trg.pw/burning-umbrella/"
        },
        {
          "index": "atch|2017",
          "intext_citation": "(Atch and Neray, 2017)",
          "preceding_text": "|  Cost | Massive infrastructure to decrypt and analyse",
          "footnote": "Atch, D. and Neray, P. (2017) \"Operation BugDrop: CyberX Discovers Large-Scale Cyber-Reconnaissance Operation Targeting Ukrainian Organizations\", [online], CyberX Labs, cyberx-labs.com/en/blog/operation-bugdrop-cyberx-discovers-large-scale-cyber-reconnaissance-operation/"
        },
        {
          "index": "secureworks|2017",
          "intext_citation": "(Secureworks, 2017)",
          "preceding_text": "|  Significance (for attacker) | Valuable",
          "footnote": "Secureworks. (2017) \"BRONZE BUTLER Targets Japanese Enterprises\", [online], Secureworks, www.secureworks.com/research/bronze-butler-targets-japanese-businesses"
        },
        {
          "index": "oleary|2017",
          "intext_citation": "(O'Leary et al., 2017; PWC, 2017  |\n|   |  Statements from officials (Goeij, 2017; Huetteman, 2017; Homewood, 2017)",
          "preceding_text": "|  Context | Victim a certain country showed interest in",
          "footnote": "O'Leary, J., Kimble, J., Vanderlee, K. and Fraser, N. (2017) \"Insights into Iranian Cyber Espionage: APT33 Targets Aerospace and Energy Sectors and has Ties to Destructive Malware\", [online], FireEye. www.fireeye.com/blog/threat-research/2017/09/apt33-insights-into-iranian-cyber-espionage.html"
        },
        {
          "index": "homewood|2017",
          "intext_citation": "(Homewood, 2017)",
          "preceding_text": "|  Benefit | A certain nation",
          "footnote": "Homewood, B. (2017) \"IAAF says medical records compromised by Fancy Bear hacking group\", [online], Reuters, www.reuters.com/article/us-sport-doping-iaaf/iaaf-says-medical-records-compromised-by-fancy-bear-hacking-group-idUSKBN1750ZM"
        },
        {
          "index": "goeij|2017",
          "intext_citation": "(Goeij, 2017)",
          "preceding_text": "|  Consequences | Serious for a nation's security",
          "footnote": "Goeij, H.d. (2017) \"Czech Government Suspects Foreign Power in Hacking of Its Email\", [online], The New York Times, 31 January, www.nytimes.com/2017/01/31/world/europe/czech-government-suspects-foreign-power-in-hacking-of-its-email.html?_r=1%0A"
        },
        {
          "index": "atch|2017",
          "intext_citation": "(Atch and Neray, 2017)",
          "preceding_text": "|   |  Intelligence gathering",
          "footnote": "Atch, D. and Neray, P. (2017) \"Operation BugDrop: CyberX Discovers Large-Scale Cyber-Reconnaissance Operation Targeting Ukrainian Organizations\", [online], CyberX Labs, cyberx-labs.com/en/blog/operation-bugdrop-cyberx-discovers-large-scale-cyber-reconnaissance-operation/"
        },
        {
          "index": "odni|2018",
          "intext_citation": "(ODNI, 2018)",
          "preceding_text": "Attribution is slow and often requires weeks or months of analysis",
          "footnote": "ODNI. (2018) A Guide to Cyber Attribution, Office of the director of national intelligence"
        },
        {
          "index": "keromytis|2016",
          "intext_citation": "(Keromytis, 2016)",
          "preceding_text": "Attributing cyberattacks is also difficult",
          "footnote": "Keromytis, A. (2016) \"Enhanced Attribution\", [online], DARPA, www.enisa.europa.eu/events/cti-eu-event/cti-eu-event-presentations/enhanced-attribution"
        },
        {
          "index": "bartholomew|2016",
          "intext_citation": "(Bartholomew and Guerrero-Saade, 2016)",
          "preceding_text": "Attributing cyberattacks is also difficult (Keromytis, 2016), although the news media often overstate the problems in order to appear balanced in their reporting",
          "footnote": "Bartholomew, B. and Guerrero-Saade, J.A. (2016) \"Wave Your False Flags! Deception Tactics Muddying Attribution in Targeted Attacks\", Virus Bulletin, October."
        },
        {
          "index": "bartholomew|2016",
          "intext_citation": "(Bartholomew and Guerrero-Saade, 2016)",
          "preceding_text": "However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available",
          "footnote": "Bartholomew, B. and Guerrero-Saade, J.A. (2016) \"Wave Your False Flags! Deception Tactics Muddying Attribution in Targeted Attacks\", Virus Bulletin, October."
        },
        {
          "index": "boot|2019",
          "intext_citation": "(Boot, 2019)",
          "preceding_text": "Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware",
          "footnote": "Boot, C. (2019) \"Applying Supervised Learning on Malware Authorship Attribution\", M.Sc. thesis, Radboud University Nijmegen."
        },
        {
          "index": "langner|2013",
          "intext_citation": "(Langner, 2013)",
          "preceding_text": "by restricting execution of their malware (Boot, 2019). Allegedly, more than half of Stuxnet development costs were for anti-attribution",
          "footnote": "Langner, R. (2013) To Kill a Centrifuge, The Langner Group."
        },
        {
          "index": "pahi|2019",
          "intext_citation": "(Pahi and Skopik, 2019)",
          "preceding_text": "Attackers also mislead attribution efforts by planting false flags, e.g. changing language settings",
          "footnote": "Pahi, T. and Skopik, F. (2019) Cyber Attribution 2.0: Capture the False Flag, European Conference on Cyber Warfare and Security."
        },
        {
          "index": "bartholomew|2016",
          "intext_citation": "(Bartholomew and Guerrero-Saade, 2016)",
          "preceding_text": "Attackers also mislead attribution efforts by planting false flags, e.g. changing language settings (Pahi and Skopik, 2019) or adding text in different languages",
          "footnote": "Bartholomew, B. and Guerrero-Saade, J.A. (2016) \"Wave Your False Flags! Deception Tactics Muddying Attribution in Targeted Attacks\", Virus Bulletin, October."
        },
        {
          "index": "bartholomew|2016",
          "intext_citation": "(Bartholomew and Guerrero-Saade, 2016)",
          "preceding_text": "Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet",
          "footnote": "Bartholomew, B. and Guerrero-Saade, J.A. (2016) \"Wave Your False Flags! Deception Tactics Muddying Attribution in Targeted Attacks\", Virus Bulletin, October."
        },
        {
          "index": "floyd|2018",
          "intext_citation": "(Floyd, 2018)",
          "preceding_text": "However, some attackers may wish for attribution in order to claim responsibility, revealing their capability",
          "footnote": "Floyd, G.S. (2018) \"Attribution and Operational Art: Implications for Competing in Time\", Strategic Studies Quarterly, Vol. 12, No. 2."
        },
        {
          "index": "zetter|2017",
          "intext_citation": "(Zetter, 2017)",
          "preceding_text": "terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\"",
          "footnote": "Zetter, K. (2017) \"Masquerading hackers are forcing a rethink of how attacks are traced\", [online], The Intercept, 4 October, theintercept.com/2017/10/04/masquerading-hackers-are-forcing-a-rethink-of-how-attacks-are-traced"
        },
        {
          "index": "nicholson|2015",
          "intext_citation": "(Nicholson et al., 2015)",
          "preceding_text": "To facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers",
          "footnote": "Nicholson, A., Janicke, H., Watson, T. and Smith, R. (2015) \"Rolling the Dice - Deceptive authentication for attack attribution\", Proceedings of the 10th International Conference on Cyber Warfare and Security, ICCWS."
        },
        {
          "index": "cook|2016",
          "intext_citation": "(Cook et al., 2016)",
          "preceding_text": "However, this would be difficult to accomplish",
          "footnote": "Cook, A., Nicholson, A., Janicke, H., Maglaras, L. and Smith, R. (2016) \"Attribution of Cyber Attacks on Industrial Control Systems\", EAI Endorsed Transactions on Industrial Networks and Intelligent Systems, Vol. 3, No. 7."
        },
        {
          "index": "odni|2018",
          "intext_citation": "(ODNI, 2018)",
          "preceding_text": "Another option is to improve the attribution process by comparing different hypotheses",
          "footnote": "ODNI. (2018) A Guide to Cyber Attribution, Office of the director of national intelligence"
        },
        {
          "index": "davis|2017",
          "intext_citation": "(Davis et al., 2017)",
          "preceding_text": "Another option is to improve the attribution process by comparing different hypotheses (ODNI, 2018), as in Fokker and Beek (2019), using independent reviews",
          "footnote": "Davis, J., Boudreaux, B., Welburn, J., Aguirre, J., Ogletree, C., McGovern, G. and Chase, M. (2017) \"Stateless Attribution: Toward International Accountability in Cyberspace\", RAND."
        },
        {
          "index": "rid|2015",
          "intext_citation": "(Rid and Buchanan, 2015; Bartholomew and Guerrero-Saade, 2016)",
          "preceding_text": "There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods",
          "footnote": "Rid, T. and Buchanan, B. (2015) \"Attributing Cyber Attacks\", Journal of Strategic Studies, Vol. 38, No. 1-2."
        },
        {
          "index": "romanosky|2019",
          "intext_citation": "(Romanosky and Boudreaux, 2019)",
          "preceding_text": "Attribution can also be harmful to one's reputation, or even dangerous",
          "footnote": "Romanosky, S. and Boudreaux, B. (2019) Private Sector Attribution of Cyber Incidents: Benefits and Risks to the U.S. Government, National Security Research Division. RAND, February."
        },
        {
          "index": "mueller|2019",
          "intext_citation": "(Mueller et al., 2019)",
          "preceding_text": "Attribution can also be harmful to one's reputation, or even dangerous (Romanosky and Boudreaux, 2019). Companies do not point fingers at nation-states as often as other nation-states do",
          "footnote": "Mueller, M., Grindal, K., Kuerbis, B. and Badiei, F. (2019) \"Cyber Attribution\", The Cyber Defense Review, Vol. 4, No. 1."
        },
        {
          "index": "yadron|2015",
          "intext_citation": "(Yadron, 2015; Romanosky and Boudreaux, 2019)",
          "preceding_text": "Companies do not point fingers at nation-states as often as other nation-states do (Mueller et al., 2019), and US companies may hesitate to point fingers at the US government",
          "footnote": "Yadron, D. (2015) \"When Cybersecurity Meets Geopolitics\", [online], Wall Street Journal, 23 March, blogs.wsj.com/digits/2015/03/23/when-cybersecurity-meets-geopolitics/"
        },
        {
          "index": "rid|2015",
          "intext_citation": "(Rid and Buchanan, 2015)",
          "preceding_text": "Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation",
          "footnote": "Rid, T. and Buchanan, B. (2015) \"Attributing Cyber Attacks\", Journal of Strategic Studies, Vol. 38, No. 1-2."
        },
        {
          "index": "berghel|2017",
          "intext_citation": "(Berghel, 2017)",
          "preceding_text": "Another flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law",
          "footnote": "Berghel, H. (2017) \"On the Problem of (Cyber) Attribution\", Computer, Vol. 50, No. 3."
        },
        {
          "index": "clark|2010",
          "intext_citation": "(Clark and Landau, 2010)",
          "preceding_text": "However, weaker evidence may lead to stronger evidence",
          "footnote": "Clark, D.D. and Landau, S. (2010) \"The Problem isn't Attribution; It's Multi-Stage Attacks\", ACM ReArch."
        },
        {
          "index": "tsagourias|2012",
          "intext_citation": "(Tsagourias, 2012)",
          "preceding_text": "However, weaker evidence may lead to stronger evidence (Clark and Landau, 2010), or be sufficient for security decision-making",
          "footnote": "Tsagourias, N. (2012) \"Cyber attacks, self-defence and the problem of attribution\", Journal of Conflict and Security Law, Vol. 17, No. 2."
        },
        {
          "index": "shakarian|2015",
          "intext_citation": "(Shakarian et al., 2015; Davis et al., 2017)",
          "preceding_text": "There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments",
          "footnote": "Shakarian, P., Simari, G.I., Moores, G. and Parsons, S. (2015) \"Cyber attribution: An argumentation-based approach\", Advances in Information Security, Vol. 56."
        },
        {
          "index": "davis|2017",
          "intext_citation": "(Davis et al., 2017)",
          "preceding_text": "Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale",
          "footnote": "Davis, J., Boudreaux, B., Welburn, J., Aguirre, J., Ogletree, C., McGovern, G. and Chase, M. (2017) \"Stateless Attribution: Toward International Accountability in Cyberspace\", RAND."
        },
        {
          "index": "schmitt|2017",
          "intext_citation": "(Schmitt and Vihul, 2017)",
          "preceding_text": "Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing)",
          "footnote": "Schmitt, M. and Vihul, L. (2017) \"International Cyber Law Politicized: The UN GGE's Failure to Advance Cyber Norms\", [online], Just Security, www.justsecurity.org/42768/international-cyber-law-politicized-gges-failure-advance-cybernorms/"
        }
      ],
      "flat_text": "Henrik Karlzén\nSwedish Defence Research Agency, Linköping, Sweden\nhenrik.karlzen@foi.se\nDOI: 10.34190/EWS.20.074\nAbstract: Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.\nKeywords: cyberattack, attribution, cyber operation, APT, security, usefulness\n# 1. Introduction\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions , or by counter-attacking . This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty ). These possibilities also mean that attribution can be a deterrent . Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state . Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action . Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR .\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks . They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies . On the other hand, intelligence agencies – that have good sources both in cyber and other domains  – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor . It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors , a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) , or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n# 1.1 Related work\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds , and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods .\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n# 2. Method\nThe next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n# 2.1 Cyberattack databases\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)\nHenrik Karlzén\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks , and is updated quarterly . It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers .\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\nTable 1: Sample attack in CFR (shortened).\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n# 2.2 Categorisations of attribution indicators\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |\nHenrik Karlzén\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).\n# 3. Attribution indicators in theory and practice\nThe CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that\nHenrik Karlzén\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\nTable 3: Attribution indicator categories and practical examples.\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible   |\n|  Entry | Spearphishing   |\n|   |  Supply-chain attack   |\n|  Targeting | Target fitting national interests   |\n|   |  Diverse targeting   |\n|  Infrastructure | Nationality of DNS servers  and IP-addresses   |\n|   |  Spoofed domains   |\n|   |  C2   |\n|   |  Links via legitimate websites to trick filters   |\n|  Modularity | Open source tools   |\n|   |  Nationality of tools   |\n|   |  Tool demonstration log files   |\n|   |  Code   |\n|  Language | System language settings   |\n|   |  Artefacts in specific natural language   |\n|   |  Poor or unusual use of natural language   |\n|  Personas | Recurring names in code   |\n|  Pattern-of-Life | Reduced attack activity during certain holidays   |\n|   |  Compilation on certain countries' working hours   |\n|  Stealth | Type of code obfuscation   |\n|   |  Type of crypto-mechanism   |\n|  Cluster | Similar process-trees   |\n|  Functionality | Gather information   |\n|   |  Destroy data   |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch   |\n|  Mistakes | Mistakenly accessing without proxy   |\n|  Skills | Capability   |\n|  Scope | Attacks to obtain code signing certificates for later attacks   |\n|  Stages | Several teams cooperating   |\n|  Evolution | First targeting diplomatic entities, then defence organisations   |\n|   |  Adapts and learns to evade detection   |\n|  Claims | Former team member admission   |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions   |\n|  Cost | Massive infrastructure to decrypt and analyse   |\n|  Significance (for attacker) | Valuable   |\n|  Context | Victim a certain country showed interest in   |\n|  Benefit | A certain nation   |\n|  Consequences | Serious for a nation's security   |\n|   |  Intelligence gathering   |\n# 4. Discussion\nThe following subsections discuss practical difficulties with attribution, and limitations of the empirical data.\nHenrik Karlzén\n## 4.1 Practical difficulties with attribution\nAttribution is slow and often requires weeks or months of analysis . Attributing cyberattacks is also difficult , although the news media often overstate the problems in order to appear balanced in their reporting .\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available .\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware . Allegedly, more than half of Stuxnet development costs were for anti-attribution . The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings  or adding text in different languages . Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet .\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability  and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" .\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers . However, this would be difficult to accomplish , and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses , as in Fokker and Beek (2019), using independent reviews , or public disagreements between analysts as in e.g. Lancaster (2017).\n## 4.2 Limitations of the empirical data\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods . Attribution can also be harmful to one's reputation, or even dangerous . Companies do not point fingers at nation-states as often as other nation-states do , and US companies may hesitate to point fingers at the US government . Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation .\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law . However, weaker evidence may lead to stronger evidence , or be sufficient for security decision-making . There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments . Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale . Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) , and obfuscate (when attacking). Furthermore,\nHenrik Karlzén\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).\n# 5. Conclusions\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute."
    }
  },
  "summary": {
    "full_text": {
      "words": 4042,
      "tokens": 6368
    },
    "flat_text": {
      "words": 3738,
      "tokens": 5439
    }
  },
  "payload": "## # 1. Introduction\n\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions , or by counter-attacking . This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty ). These possibilities also mean that attribution can be a deterrent . Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state . Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action . Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR .\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks . They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies . On the other hand, intelligence agencies – that have good sources both in cyber and other domains  – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor . It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors , a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) , or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).\nHenrik Karlzén\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds , and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods .\n# 1.2 Paper structure\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n\n---\n\n## # 5. Conclusions\n\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute.",
  "summary_log": "---LOG_SUMMARY_START---\ndoc_status:SUCCESS\nsections_raw:5\nsections_clean:5\nintro:FOUND\nconclusion:FOUND\npredefined_sections:# 4. Discussion\nextra_sections:# 2. Method|# 3. Attribution indicators in theory and practice\npayload_tokens_before:4681\npayload_tokens_after:5445\ndropped_section:None\nadded_section:# 3. Attribution indicators in theory and practice\n---LOG_SUMMARY_END---",
  "pages_text": [
    "168\n\n# Usefulness of Cyber Attribution Indicators\n\nHenrik Karlzén\nSwedish Defence Research Agency, Linköping, Sweden\nhenrik.karlzen@foi.se\nDOI: 10.34190/EWS.20.074\n\nAbstract: Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.\n\nKeywords: cyberattack, attribution, cyber operation, APT, security, usefulness\n\n# 1. Introduction\n\nThis paper investigates attribution, i.e. determining who conducted a cyberattack. Attackers typically wish to remain anonymous when conducting cyberattacks while there are several reasons why others want to reveal a cyber-attacker's identity. First, the victim (and others) probably wants to change their relationship to the attacker, e.g. by using sanctions (Davis et al., 2017), or by counter-attacking (Egloff, 2018). This is arguably more important when the attacker acts out of character (e.g. attacking despite a peace treaty (Porter, 2017)). These possibilities also mean that attribution can be a deterrent (Floyd, 2018). Second, attacker identity might determine who should deal with the consequences of the attack. For instance, a nation-state attack may absolve an insurance company from paying damages to a victim. A case is currently being litigated in a US court, where the victim is claiming that the insurance company has denied payment without having proved that the attack was indeed conducted by a nation-state (Illinois, 2018). Third, a manufacturer of a cyberweapon might only sell the weapon to certain organisations, and if others use it the manufacturer may want to take action (Ahmed and Perlroth, 2019). Fourth, knowledge of the attacker enriches one's understanding, enabling better defence (Hunker, Hutchinson, and Margulies, 2008). Fifth, cyber security companies can use attribution as a proof-of-concept or for PR (Davis et al., 2017).\n\nAttribution is often conducted by multinational cyber security companies that provide good insight into networks (Romanosky and Boudreaux, 2019). They also have strong technical capabilities, but somewhat lack the analytical capability of intelligence agencies (Bartholomew and Guerrero-Saade, 2016). On the other hand, intelligence agencies – that have good sources both in cyber and other domains (Malik, 2017; Symantec, 2018) – cannot speak as openly about attribution, e.g. to protect methods and sources. Collaboration between organisations is limited, which is demonstrated by their confusing assignment of different names for the same threat actor (Romanosky and Boudreaux, 2019). It has been suggested that different attributing organisations work together, e.g. in a consortium of private actors (Davis et al., 2017), a cyber-IAEA (promoting peaceful cyber akin to the work of the International Atomic Energy Agency) (Neutze, 2016), or in an international court for cyber attribution (Chernenko, Demidov, and Lukyanov, 2018).",
    "Henrik Karlzén\n\nThis paper aims to better understand how attacks are attributed, as well as the obstacles to attribution and its publicising. More specifically the paper answers the following research question: how are attacks attributed in theory and practice?\n\n# 1.1 Related work\n\nAttribution is an interdisciplinary task, with research focusing on technical indicators as well as political implications and communication. For instance, Rid and Buchanan (2015) studied the less technical side of how to attribute and proposed the  $Q$  model for categorising attribution indicators. In contrast, Kaspersky researchers Bartholomew and Guerrero-Saade (2016) described more technical challenges as well as false flags used by attackers to mislead. Davis et al. (2017), published by the US think tank RAND, described that attribution methodologies vary and that a standardised and scientifically transparent methodology is missing. Another RAND paper, by Romanosky and Boudreaux (2019), studied the topic of publicly disclosing attribution conclusions. The Master thesis by Boot (2019) summarised one type of attribution indicators and how attackers conceal themselves. In the paper by Pahi and Skopik (2019), presented at the 2019 European Conference on Cyber Warfare and Security, the so-called Diamond model for attribution was elaborated in order to address the shortcomings of attribution methods and increase the resistance to false flags. The new Cyber attribution model structurally separated and then combined the how of an attack with the who (attacker).\n\nMost of the academic literature is theoretical in nature and few papers investigate larger numbers of empirical cases where attribution has occurred. As such, theories are not validated by empirical data, and the academic literature typically only investigates if a proposed model can be exemplified by a few cases rather than large collections of data. The paper by Valeriano and Maness (2014) is a rare exception; it formulated a theory on cyber conflict and evaluated the theory by collecting data on 110 cyber incidents and 45 cyber disputes between rival nations. The paper indicated that cyber combat is rarely used, causing mainly minor effects, and is primarily regional rather than global.\n\nThere is currently much interest in improving the possibilities of attribution, such as the new US Defense Advanced Research Projects Agency (DARPA) program Enhanced Attribution, running from 1 November 2016 to 1 May 2021. The program aims to decrease the time for attribution from months to hours or even seconds (DARPA, 2016a), and increase the government's capability to openly reveal its conclusions about an attack without harming sources and methods (DARPA, 2016b).\n\n# 1.2 Paper structure\n\nThe remainder of the present paper describes the research method, attribution indicators in theory and practice, discussions of the practical difficulties with attribution as well as limitations of the empirical data, and finally conclusions.\n\n# 2. Method\n\nThe next subsection details how cyberattack databases and cyberattacks were identified, followed by a subsection on how the empirical data was categorised.\n\n# 2.1 Cyberattack databases\n\nIn order to find information on conducted cyberattacks, an internet search for databases on such attacks was performed. Many databases with information on cyberattacks were found. To choose between the databases, several criteria were applied. Similar criteria had previously been established by this paper's author together with some colleagues. These criteria were (somewhat adjusted) as follows, with excluded databases based on each criterion: They focus on attacks rather than actors, etc. (7 excluded: e.g. ATT&amp;CK Groups, and APT Groups and Operations, which focused on actors; and 1 excluded: VirusTotal, which focused on malware.) They have references with more details for increased trustworthiness. (1 excluded: CSIS, which lacked references; and 1 excluded: Dyadic, which only had references in terms of names of news media.) They have details such as dates, modi operandi, attackers, and victims. (4 excluded: e.g. Security Without Borders.) They contain a large number of attacks rather than only a few. (1 excluded: Relevante Cybervorfälle.) Finally, they are trustworthy (with a described method and reliable authors). (2 excluded: Hackmageddon, which is authored by a private individual and has relatively few reliable sources, and VERIS which does not clearly describe its method for compilation.)",
    "Henrik Karlzén\n\nOnly one database was not excluded: Cyber Operations Tracker (CFR), composed of  $300+$  operations (attacks) from the year 2005 onwards, authored by the US think tank Council on Foreign Relations. This is also the most complete database for state-sponsored cyberattacks (Romanosky and Boudreaux, 2019), and is updated quarterly (CFR, 2019). It may be noted that several of the excluded databases are (partially) based on CFR (and vice versa). It may also be noted that CFR also has its flaws, such as commonly weak attribution evidence (that the attacks were state-sponsored), and it only contains open sources that are mostly in the English language with victims who are native English speakers (CFR, 2019).\n\nAn example of how CFR describes an attack is shown in Table 1. For each attack, CFR provides a title, date, victim, attacker, description of attack, and possible victim response. There are also links to one to three sources (per attack), where more information can be found. Over half the sources are news articles, with the most common news media being The New York Times, The Washington Post, Reuters, and Wired. A third of the sources are cyber security companies' reports, with the most common one being Kaspersky, FireEye, Symantec and Palo Alto Networks. There are also government reports (seven percent of sources), mostly from the USA, and other sources, e.g. documents from think tanks and research institutes.\n\nTable 1: Sample attack in CFR (shortened).\n\n|  Title | Date | Description  |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Compromise the North Korean nuclear program | 2017-03-04 | A threat actor, believed to be the United States, targeted computer networks and electronic components associated with the North Korean nuclear program to sabotage and slow its development.  |   |   |   |\n|  Response | Victims | Sponsor | Type | Category | Sources_1  |\n|  [blank] | North Korea | United States | Sabotage | Military | nytimes.com/...  |\n\nIn order to obtain a manageable amount of sources, only the 45 attacks from 2017 (fresh but also mature) were chosen. The CFR sources were read by this paper's author together with a colleague, and statements on attribution were noted and divided into categories (as described in section 3).\n\n# 2.2 Categorisations of attribution indicators\n\nThere are several categorisations of attribution indicators in the literature, such as the Diamond Model (Caltagirone, Pendergast, and Betz, 2013) that scientifically formalises the work of intrusion analysts. This model, where the diamond's four corners represent the adversary, capability, victim and infrastructure, was further developed by Pahi and Skopik (2019). A second categorisation is the Lockheed Martin Cyber Kill Chain (Hutchins, Cloppert, and Amin, 2010), which divides attacks into different stages. However, it was primarily developed to stop attacks. A third categorisation by Wheeler, Larsen, and Leader (2003) focuses on network communication indicators, with the goal to adjust systems, thus making attribution easier. A fourth categorisation by Cook et al. (2016) uses categories such as network communication, forensic analysis of client, analysis of malware, and non-technical methods, and is thus more useful for measurements. A fifth categorisation by ODNI (2018) describes the US intelligence agencies' categories for attribution, such as recurring modi operandi, infrastructure, malware, motivation, and indicators from external sources.\n\nThis paper uses a more detailed (semi-structured) categorisation developed by Rid and Buchanan (2015), called the Q model. The Q model includes, among other things, more than a hundred questions the answers to which may be considered attribution indicators. Most of the questions are divided into more specific categories provides the categories of indication used in the Q model, together with explanations and indicators mentioned by some other theoretical works on indicators. As illustrated in Table 2, the Q model fairly well covers the attribution indicators suggested elsewhere, although only if the categories are interpreted in a broad manner.\n\nTable 2: Attribution indicator categories (first column) from the Q model by Rid and Buchanan (2015). The categories are briefly explained in the second column. The third column shows indicators from some other theoretical works\n\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|  Indicators of compromise | Suspicious behaviour that triggers the attribution effort |   |\n|  Entry | Penetration techniques, vulnerabilities |   |\n|  Targeting | The target and its specificity | Target specificitya,b,e  |\n|  Infrastructure | Infrastructure such as software, | Infrastructuref  |",
    "Henrik Karlzén\n\n|  Category | Explanation | Indicators in the literature  |\n| --- | --- | --- |\n|   | command and control (C2) | Bandwidthd  |\n|   |   |  Compilerf  |\n|   |   |  Domaind  |\n|   |   |  IP-addressa,a,f  |\n|   |   |  Exfiltration methodf  |\n|  Modularity | Malware modularity, reused components, different teams | Tool procurementd  |\n|   |   |  Programming stylef,h  |\n|   |   |  Code blocks, function calls, multi-threading, binary similarity, etcf  |\n|  Language | System language settings, region-specific strings | System language settingsf,  |\n|   |   |  Region-specific stringsa  |\n|   |   |  Programming languagef  |\n|   |   |  Language skillsc  |\n|  Personas | Pseudonyms and names | Pseudonyms and namesc  |\n|  Pattern-of-Life | Time of attack, working hours | Time of attack, working hoursc  |\n|  Stealth | Detection evasion, anti-forensics | Anti-attribution methodf  |\n|   |   |  The password chosen to hide codef  |\n|   |   |  Crypto-mechanismf  |\n|  Cluster | Other attacks with similar methodologies |   |\n|  Functionality | Designed purpose (modify, interrupt, etc.) |   |\n|  Approval | Who approved it, target verification, collateral minimisation | Amount of collateral damagea,b  |\n|  Mistakes | Attacker mistakes |   |\n|  Skills | Skills required and their rarity | Technical sophisticationa  |\n|  Scope | E.g. as campaign | The attacker returns to the systemh  |\n|  Stages | E.g. preparatory, main, or follow-up; teams | Number of stepsa,h  |\n|  Evolution | Changes during attacking |   |\n|  Claims | Claims, announcements | Claimse  |\n|  Insider | Insider required and used |   |\n|  Intelligence | Target intelligence required | Target intelligence requiredg  |\n|  Cost | Cost and testing requirements | Testing requirementsg  |\n|  Significance | Significance for attacker |   |\n|  Context | Political and regional context, other events, other sources | Political and regional contexta  |\n|   |   |  Other eventsa,b  |\n|   |   |  Other sourcesa  |\n|   |   |  The judicial system makes no effort or has no successa,b  |\n|  Benefit | Who benefited? | Matching doctrinea  |\n|  Consequences | Damage, side-effects | Effectb  |\n|   |   |  Side-effectsa,b  |\n\nSources: a = Jolley (2017), b = Ottis (2009), c = Bartholomew and Guerrero-Saade (2016), d = Cook et al. (2016), e = Mateski et al. (2012), f = Boot (2019), g = Langner (2013), h = Nicholson et al. (2015).\n\n# 3. Attribution indicators in theory and practice\n\nThe CFR sources describe their attempts to attribute attacks in various detail. One example involved cyber security company FireEye attributing an attack to the Iranian government, based on a username in the code being the same as one used in a web forum with ties to the Iranian government. Furthermore, the code contained artefacts in Iranian language Farsi, the targets aligned with Iranian interests, and the time of attack aligned with the Iranian time zone and working week (Saturday-Wednesday). Similarities to code used in other attacks were also mentioned. News media usually provide fewer details and rely on claims from anonymous people or government officials who provide no evidence.\n\nTable 3 matches the Q model categories with practical attribution examples from the CFR database sources. The Q model covers quite well the indicators used in practice, with only insider requirements missing in this selection of empirical data. It is also clear that many practical examples were needed to cover the entire Q model, indicating that it is rare to use the entire Q model to attribute a single attack. Indeed, only a few indicators are mentioned in each case, with the indicators varying between cases, and indicators that",
    "Henrik Karlzén\n\nconstitute counter-evidence are ignored or even considered false flags (as in PWC (2017)). Furthermore, the chains of evidence are long, with one attribution building on the previous one.\n\nTable 3: Attribution indicator categories and practical examples.\n\n|  Category | Practical examples  |\n| --- | --- |\n|  Indicators of compromise | Data inaccessible (Cherepanov, 2017)  |\n|  Entry | Spearphishing (Great, 2017)  |\n|   |  Supply-chain attack (Cherepanov, 2017)  |\n|  Targeting | Target fitting national interests (ThreatConnect, 2017a; O'Leary et al., 2017)  |\n|   |  Diverse targeting (Secureworks, 2017)  |\n|  Infrastructure | Nationality of DNS servers (O'Leary et al., 2017) and IP-addresses (Reaqta, 2017; Marczak et al., 2017)  |\n|   |  Spoofed domains (ThreatConnect, 2017b)  |\n|   |  C2 (PWC, 2017; Symantec, 2017)  |\n|   |  Links via legitimate websites to trick filters (ThreatConnect, 2017a)  |\n|  Modularity | Open source tools (Lancaster, 2017)  |\n|   |  Nationality of tools (O'Leary et al., 2017)  |\n|   |  Tool demonstration log files (Marczak et al., 2017)  |\n|   |  Code (Symantec, 2017)  |\n|  Language | System language settings (Reaqta, 2017; Atch and Neray, 2017)  |\n|   |  Artefacts in specific natural language (O'Leary et al., 2017; Secureworks, 2017)  |\n|   |  Poor or unusual use of natural language (Great, 2017)  |\n|  Personas | Recurring names in code (Symantec, 2017; O'Leary et al., 2017)  |\n|  Pattern-of-Life | Reduced attack activity during certain holidays (Secureworks, 2017; O'Leary et al., 2017)  |\n|   |  Compilation on certain countries' working hours (PWC, 2017)  |\n|  Stealth | Type of code obfuscation (Symantec, 2017)  |\n|   |  Type of crypto-mechanism (Hegel, 2018)  |\n|  Cluster | Similar process-trees (Reaqta, 2017)  |\n|  Functionality | Gather information (Goeij, 2017)  |\n|   |  Destroy data (Cherepanov, 2017)  |\n|  Approval | Who ordered it (Reyes et al, 2017)  |\n|   |  Existence of kill switch (Symantec, 2017)  |\n|  Mistakes | Mistakenly accessing without proxy (Hegel, 2018)  |\n|  Skills | Capability (Atch and Neray, 2017)  |\n|  Scope | Attacks to obtain code signing certificates for later attacks (Hegel, 2018)  |\n|  Stages | Several teams cooperating (PWC, 2017; Hegel, 2018)  |\n|  Evolution | First targeting diplomatic entities, then defence organisations (Great, 2017)  |\n|   |  Adapts and learns to evade detection (Hegel, 2018)  |\n|  Claims | Former team member admission (Reyes et al., 2017)  |\n|  Insider | [not used]  |\n|  Intelligence | Target's email solutions (Hegel, 2018)  |\n|  Cost | Massive infrastructure to decrypt and analyse (Atch and Neray, 2017)  |\n|  Significance (for attacker) | Valuable (Secureworks, 2017)  |\n|  Context | Victim a certain country showed interest in (O'Leary et al., 2017; PWC, 2017  |\n|   |  Statements from officials (Goeij, 2017; Huetteman, 2017; Homewood, 2017)  |\n|  Benefit | A certain nation (Homewood, 2017)  |\n|  Consequences | Serious for a nation's security (Goeij, 2017)  |\n|   |  Intelligence gathering (Atch and Neray, 2017)  |\n\n# 4. Discussion\n\nThe following subsections discuss practical difficulties with attribution, and limitations of the empirical data.",
    "Henrik Karlzén\n\n## 4.1 Practical difficulties with attribution\n\nAttribution is slow and often requires weeks or months of analysis (ODNI, 2018). Attributing cyberattacks is also difficult (Keromytis, 2016), although the news media often overstate the problems in order to appear balanced in their reporting (Bartholomew and Guerrero-Saade, 2016).\n\nFinding an accurate and complete set of attribution indicators is a challenge. While all empirical cases studied in this paper are covered by the Q model, each case does not use even close to the full model. However, one single indicator is rarely going to be sufficient, since e.g. attacker tool use does not reveal much as tools are often openly available (Bartholomew and Guerrero-Saade, 2016).\n\nFurthermore, some indicators are difficult to measure, e.g. code that is too difficult to understand, or jurisdictional issues restricting access to information (Hunker, Hutchinson, and Margulies, 2008; Romanosky and Boudreaux, 2019). Proficient attackers adapt to known indicators and obfuscate their behaviour, e.g. by restricting execution of their malware (Boot, 2019). Allegedly, more than half of Stuxnet development costs were for anti-attribution (Langner, 2013). The Vault7 documents released by Wikileaks (2017a) (and allegedly written by the CIA) show instructions not to leave dates and times in code.\n\nAttackers also mislead attribution efforts by planting false flags, e.g. changing language settings (Pahi and Skopik, 2019) or adding text in different languages (Bartholomew and Guerrero-Saade, 2016). Wikileaks (2017b) suggests that the CIA could use Vault7 to write in a foreign language and make it seem like they tried to conceal that language. Wikileaks (2017c) further suggests that Vault7's \"Umbrage\" code snippets from others' cyber weapons could be used to blame the snippets' original authors. Another alleged use of false flags was how (outdated) certificates used in Stuxnet were later reused in different code to cast blame on Stuxnet (Bartholomew and Guerrero-Saade, 2016).\n\nIn some cases, misleading might even be the main goal in order to blame a third party (Wheeler, Larsen, and Leader, 2003). However, some attackers may wish for attribution in order to claim responsibility, revealing their capability (Floyd, 2018) and gaining status (c.f. terrorist claims in Kearns, 2019). Furthermore, Kaspersky researcher Guerrero-Saade thinks \"false flags are rare and that most attribution that threat researchers do is accurate\" (Zetter, 2017).\n\nTo facilitate attribution, internet protocols may be made more resistant to spoofing, and traffic that is difficult to attribute could be filtered by routers (Nicholson et al., 2015). However, this would be difficult to accomplish (Cook et al., 2016), and privacy implications stopped one such effort by DARPA (Wheeler, Larsen, and Leader, 2003). Another option is to improve the attribution process by comparing different hypotheses (ODNI, 2018), as in Fokker and Beek (2019), using independent reviews (Davis et al., 2017), or public disagreements between analysts as in e.g. Lancaster (2017).\n\n## 4.2 Limitations of the empirical data\n\nAs the CFR database is based on only open sources, attacks that are not publicly attributed might be missed. There are situations when public attribution is not desirable, e.g. warning the attacker and thereby revealing one's sources and methods (Rid and Buchanan, 2015; Bartholomew and Guerrero-Saade, 2016). Attribution can also be harmful to one's reputation, or even dangerous (Romanosky and Boudreaux, 2019). Companies do not point fingers at nation-states as often as other nation-states do (Mueller et al., 2019), and US companies may hesitate to point fingers at the US government (Yadron, 2015; Romanosky and Boudreaux, 2019). Public attribution can also ruin attacks that one would like to happen, such as when being collateral damage of an anti-terrorist operation (Rid and Buchanan, 2015).\n\nAnother flaw with the CFR database and its public sources is that the attribution evidence is typically weak and likely to be insufficient for courts of law (Berghel, 2017). However, weaker evidence may lead to stronger evidence (Clark and Landau, 2010), or be sufficient for security decision-making (Tsagourias, 2012). There is rarely an assessment of evidence strength, with a few exceptions such as Hegel (2018), despite the importance of certainty assessments (Shakarian et al., 2015; Davis et al., 2017). Furthermore, while there are examples of attribution uncertainty scales, e.g. those in ODNI (2018), there is no established scale (Davis et al., 2017). Without an established scale, actors will disagree on what is sufficient evidence, e.g. depending on their ability to collect evidence (when attributing) (Schmitt and Vihul, 2017), and obfuscate (when attacking). Furthermore,",
    "Henrik Karlzén\n\nit is not surprising that those who are accused consider the evidence too weak, such as the Chinese government's reaction to the US attributing attacks to China (Ministry of Foreign Affairs of PRC, 2015).\n\n# 5. Conclusions\n\nThe focus of this paper was to investigate how cyberattacks are attributed in theory and practice. Theoretical works have suggested many different ways to attribute cyberattacks, e.g. the highly detailed Q model. However, the methods used in practice do not seem to use a set methodology. While the Q model fairly well covers all practical cases of attribution in the CFR database as investigated in this paper, only some of the multitude of attribution indicators are applied in each case, such as IP addresses, language settings, required resources, and the apparent (political) goal. Whether attacks required an insider was not used as an indicator in the studied practical cases.\n\nStudying actual attribution cases has its hurdles. Gaining access to attribution data is difficult, and there are reasons to believe that the open sources do not reflect all attribution efforts (some of which are not made public). There are several reasons not to make public attribution statements. Public attribution warns attackers, tips off other potential victims (who one might want to see get hurt), harms the relationship with the alleged attacker, harms the reputation if the attribution is shown to be wrong, and reveals sources and methods. Furthermore, publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential.\n\nAttribution is difficult, requiring a hard process of measuring many different attribution indicators with scientific rigour and overcoming attackers' obfuscation and false flags as well as one's own subjectivity. Furthermore, the indicators may point in different directions – gathered attribution evidence is often weak and based on previous (also weak) attribution. Moreover, the strength of the evidence is rarely assessed in practice. There is also a lack of collaboration between organisations who seek to attribute.\n\n# References\n\nAhmed, B.A. and Perlroth, N. (2019) \"Using Texts as Lures, Government Spyware Targets Mexican Journalists and Their Families\", [online], New York Times, 19 June, www.nytimes.com/2017/06/19/world/americas/mexico-spyware-anticrime.html\nAtch, D. and Neray, P. (2017) \"Operation BugDrop: CyberX Discovers Large-Scale Cyber-Reconnaissance Operation Targeting Ukrainian Organizations\", [online], CyberX Labs, cyberx-labs.com/en/blog/operation-bugdrop-cyberx-discovers-large-scale-cyber-reconnaissance-operation/\nBartholomew, B. and Guerrero-Saade, J.A. (2016) \"Wave Your False Flags! Deception Tactics Muddying Attribution in Targeted Attacks\", Virus Bulletin, October.\nBerghel, H. (2017) \"On the Problem of (Cyber) Attribution\", Computer, Vol. 50, No. 3.\nBoot, C. (2019) \"Applying Supervised Learning on Malware Authorship Attribution\", M.Sc. thesis, Radboud University Nijmegen.\nCaltagirone, S., Pendergast, A. and Betz, C. (2013). The Diamond Model of Intrusion Analysis, Hanover, MD: Center for Cyber Threat Intelligence and Threat Research, 5 July.\nCherepanov, A. (2017) \"TeleBots are back: Supply-chain attacks against Ukraine\", [online], Eset, https://www.welivesecurity.com/2017/06/30/telebots-back-supply-chain-attacks-against-ukraine/\nChernenko, E., Demidov, O. and Lukyanov, F. (2018) \"Increasing international cooperation and cybersecurity and adapting cyber norms\", [online], Council on Foreign Relations, www.cfr.org/report/increasing-international-cooperation-cybersecurity-and-adapting-cyber-norms\nClark, D.D. and Landau, S. (2010) \"The Problem isn't Attribution; It's Multi-Stage Attacks\", ACM ReArch.\nCook, A., Nicholson, A., Janicke, H., Maglaras, L. and Smith, R. (2016) \"Attribution of Cyber Attacks on Industrial Control Systems\", EAI Endorsed Transactions on Industrial Networks and Intelligent Systems, Vol. 3, No. 7.\nDARPA. (2016a) \"DARPA-BAA-16-34, Enhanced Attribution, Frequently Asked Questions\", DARPA.\nDARPA. (2016b) \"Broad Agency Announcement Enhanced Attribution DARPA-BAA-16-34\", DARPA.\nDavis, J., Boudreaux, B., Welburn, J., Aguirre, J., Ogletree, C., McGovern, G. and Chase, M. (2017) \"Stateless Attribution: Toward International Accountability in Cyberspace\", RAND.\nEgloff, F.J. (2018) \"Cybersecurity and Non-State Actors\", Ph.D. thesis, University of Oxford.\nFloyd, G.S. (2018) \"Attribution and Operational Art: Implications for Competing in Time\", Strategic Studies Quarterly, Vol. 12, No. 2.\nFokker, J. and Beek, C. (2019) \"Ryuk Ransomware Attack: Rush to Attribution Misses the Point\", [online], McAfee Blogs, securingtomorrow.mcafee.com/other-blogs/mcafee-labs/ryuk-ransomware-attack-rush-to-attribution-misses-the-point/",
    "Henrik Karlzén\n\nGoeij, H.d. (2017) \"Czech Government Suspects Foreign Power in Hacking of Its Email\", [online], The New York Times, 31 January, www.nytimes.com/2017/01/31/world/europe/czech-government-suspects-foreign-power-in-hacking-of-its-email.html?_r=1%0A\n\nGreat. (2017) \"Introducing WhiteBear\", Securelist, [online], Kaspersky, securelist.com/introducing-whitebear/81638/%0A\n\nHegel, T. (2018) \"Burning Umbrella: An Intelligence Report on the Winnti Umbrella and Associated State-Sponsored Attackers\", [online], 401Trg, 401trg.pw/burning-umbrella/\n\nHomewood, B. (2017) \"IAAF says medical records compromised by Fancy Bear hacking group\", [online], Reuters, www.reuters.com/article/us-sport-doping-iaaf/iaaf-says-medical-records-compromised-by-fancy-bear-hacking-group-idUSKBN1750ZM\n\nHuetteman, E. (2017) \"Marco Rubio Says His Campaign Was a Target of Russian Cyberattacks\", [online], The New York Times, 30 March, www.nytimes.com/2017/03/30/us/politics/marco-rubio-russian-cyberattacks.html\n\nHunker, J., Hutchinson, B. and Margulies, J. (2008) \"Role and Challenges for Sufficient Cyber-Attack Attribution\", Dartmouth College\n\nHutchins, E., Cloppert, M. and Amin, R. (2011) Intelligence-driven computer network defense informed by analysis of adversary campaigns and intrusion kill chains, 6th International Conference on Information Warfare and Security, ICIW\n\nIllinois. (2018) \"2018 WL 4941760 (Ill.Cir.Ct.) (Trial Pleading). MONDELEZ INTERNATIONAL, INC., Plaintiff, v. ZURICH AMERICAN INSURANCE COMPANY, Defendant\", Circuit Court of Illinois.\n\nJolley, J.D. (2017) Attribution, State Responsibility, and the Duty to Prevent Malicious Cyber-Attacks in International Law, University of Glasgow\n\nKearns, E.M. (2019) \"When to Take Credit for Terrorism? A Cross-National Examination of Claims and Attributions\", Terrorism and Political Violence\n\nKeromytis, A. (2016) \"Enhanced Attribution\", [online], DARPA, www.enisa.europa.eu/events/cti-eu-event/cti-eu-event-presentations/enhanced-attribution\n\nLancaster, T. (2017) \"Muddying the Water: Targeted Attacks in the Middle East\", [online], Palo Alto Networks, researchcenter.paloaltonetworks.com/2017/11/unit42-muddying-the-water-targeted-attacks-in-the-middle-east\n\nLangner, R. (2013) To Kill a Centrifuge, The Langner Group.\n\nMalik, W. (2017) \"What are the benefits of attribution?\", [online], TrendMicro, 16 August, blog.trendmicro.com/what-are-the-benefits-of-attribution/\n\nMarczak, B. (2017) \"Champing at the Cyberbit\", [online], The Citizen Lab, citizenlab.ca/2017/12/champing-cyberbit-ethiopian-dissidents-targeted-commercial-spyware\n\nMateski, M., Trevino, C.M., Veitch, C.K., Michalski, J., Harris, J.M., Maruoka, S. and Frye, J. (2012) \"Cyber Threat Metrics\", SANDIA Report, SAND2012-2427, March.\n\nMinistry of Foreign Affairs of PRC. (2015) \"Foreign Ministry Spokesperson Hong Lei's Regular Press Conference\", Ministry of Foreign Affairs, the People's Republic of China, 5 June.\n\nMueller, M., Grindal, K., Kuerbis, B. and Badiei, F. (2019) \"Cyber Attribution\", The Cyber Defense Review, Vol. 4, No. 1.\n\nNeutze, J. (2016) \"The role of cybernorms in preventing digital warfare\", [online], Microsoft EU Policy Blog, blogs.microsoft.com/eupolicy/2016/07/08/the-role-of-cybernorms-in-preventing-digital-warfare/\n\nNicholson, A., Janicke, H., Watson, T. and Smith, R. (2015) \"Rolling the Dice - Deceptive authentication for attack attribution\", Proceedings of the 10th International Conference on Cyber Warfare and Security, ICCWS.\n\nO'Leary, J., Kimble, J., Vanderlee, K. and Fraser, N. (2017) \"Insights into Iranian Cyber Espionage: APT33 Targets Aerospace and Energy Sectors and has Ties to Destructive Malware\", [online], FireEye. www.fireeye.com/blog/threat-research/2017/09/apt33-insights-into-iranian-cyber-espionage.html\n\nODNI. (2018) A Guide to Cyber Attribution, Office of the director of national intelligence\n\nOttis, R. (2009) Theoretical Model for Creating a Nation-State Level Offensive Cyber Capability, European Conference on Information Warfare and Security\n\nPahi, T. and Skopik, F. (2019) Cyber Attribution 2.0: Capture the False Flag, European Conference on Cyber Warfare and Security.\n\nPorter, C. (2017) \"Private Sector Cyber Intelligence Could Be Key to Workable Cyber Arms Control Treaties\", [online], Lawfare www.lawfareblog.com/private-sector-cyber-intelligence-could-be-key-workable-cyber-arms-control-treaties\n\nPWC. (2017) \"Operation Cloud Hopper\", [online], PwC, www.pwc.co.uk/cyber%0Ahttps://www.pwc.co.uk/cyber-security/pdf/cloud-hopper-report-final-v4.pdf\n\nReaqta. (2017) \"A dive into MuddyWater APT targeting\", [online], Reaqta, reaqta.com/2017/11/muddywater-apt-targeting-middle-east\n\nReyes, G., Adams, D., Cooper, J. and Camacaro, D. (2017) \"EXCLUSIVE: Panama's expresident wiretapped Americans, according to court documents\", [online], Univision, 24 June, www.univision.com/univision-news/latin-america/exclusive-panamas-ex-president-wiretapped-americans-according-to-court-documents\n\nRid, T. and Buchanan, B. (2015) \"Attributing Cyber Attacks\", Journal of Strategic Studies, Vol. 38, No. 1-2.\n\nRomanosky, S. and Boudreaux, B. (2019) Private Sector Attribution of Cyber Incidents: Benefits and Risks to the U.S. Government, National Security Research Division. RAND, February.\n\nSchmitt, M. and Vihul, L. (2017) \"International Cyber Law Politicized: The UN GGE's Failure to Advance Cyber Norms\", [online], Just Security, www.justsecurity.org/42768/international-cyber-law-politicized-gges-failure-advance-cybernorms/\n\n175",
    "Henrik Karlzén\n\nSecureworks. (2017) \"BRONZE BUTLER Targets Japanese Enterprises\", [online], Secureworks, www.secureworks.com/research/bronze-butler-targets-japanese-businesses\nShakarian, P., Simari, G.I., Moores, G. and Parsons, S. (2015) \"Cyber attribution: An argumentation-based approach\", Advances in Information Security, Vol. 56.\nSymantec. (2017) \"WannaCry: Ransomware attacks show strong links to Lazarus group\", [online], Symantec, www.symantec.com/connect/blogs/wannacry-ransomware-attacks-show-strong-links-lazarus-group\nSymantec. (2018) \"The Cyber Security Whodunnit: Challenges in Attribution of Targeted Attacks\", [online], Symantec, www.symantec.com/blogs/expert-perspectives/cyber-security-whodunnit-challenges-attribution-targeted-attacks\nThreatConnect. (2017a) \"Fancy Bear Pens the Worst Blog Posts Ever\", [online], ThreatConnect, threatconnect.com/blog/fancy-bear-leverages-blogspot/\nThreatConnect. (2017b) \"Parlez-vous Fancy?\", [online], ThreatConnect, threatconnect.com/blog/activity-targeting-french-election/\nTsagourias, N. (2012) \"Cyber attacks, self-defence and the problem of attribution\", Journal of Conflict and Security Law, Vol. 17, No. 2.\nValeriano, B. and Maness, R. (2013) \"The Dynamics of Cyber Conflict between Rival Antagonists, 2001-2011\", Journal of Peace Research, February.\nWheeler, D.A., Larsen, G.N. and Leader, T. (2003) \"Techniques for cyber attack attribution\", [online], Institute for Defense Analyses, October, apps.dtic.mil/dtic/tr/fulltext/u2/a468859.pdf\nWikileaks. (2017a) \"Development Tradecraft DOs and DON'Ts\", [online], wikileaks.org/ciav7p1/cms/page_14587109.html\nWikileaks. (2017b) \"Vault 7: Projects\", [online], wikileaks.org/vault7\nWikileaks. (2017c) \"Vault 7: CIA Hacking Tools Revealed\", [online], wikileaks.org/ciav7p1\nYadron, D. (2015) \"When Cybersecurity Meets Geopolitics\", [online], Wall Street Journal, 23 March, blogs.wsj.com/digits/2015/03/23/when-cybersecurity-meets-geopolitics/\nZetter, K. (2017) \"Masquerading hackers are forcing a rethink of how attacks are traced\", [online], The Intercept, 4 October, theintercept.com/2017/10/04/masquerading-hackers-are-forcing-a-rethink-of-how-attacks-are-traced\n\n176",
    "Petri Jääskeläinen is a masters student from the Faculty of Information Technology and Communication Sciences in Tampere University. He also works as a freelance journalist specialized in radicalized movements, disinformation, conspiracy theories and technology.\n\nYahlieel Jafta a Software Developer and has been working professionally since 2012. Areas of interest include Software Design patterns and Test Driven Development with a keen interest in Domain Driven Development and Artificial Intelligence. He holds a BSc in Computer Science and is currently completing his Computer Science Honours degree at the University of the Western Cape.\n\nDr. Victor J Jaquire has been within the field of cyber and information security for over 20 years within government and private sector focusing on strategy, performance management and operations. He holds d PhD in Informatics from the University of Johannesburg - specialising in strategies for cyber counterintelligence maturity and the security of cyberspace. His professional certifications include CISSP, CISM and CCISO.\n\nJiri Jelinek Ph.D. (Czech Technical University in Prague). He worked a long time at the University of Economics, Prague. Since 2011 he is a professor assistant in the Institute of Applied Informatics of Faculty of Science at the University of South Bohemia in České Budějovice. Professional interests include distributed artificial intelligence, neural networks, multi-agent systems, social networks, and simulation models.\n\nJuozapavičius holds a PhD in theoretical physics from KTH Royal Institute of Technology, Sweden. He leads the Department of Defence Technologies at General Jonas Žemaitis Military Academy of Lithuania. His research interests are cybersecurity and computer modelling. He participates in EU-funded cybersecurity-related projects, and he is responsible for the cybersecurity specialisation of the study programs\n\nDr. Connie Justice has over 30 years' experience in cybersecurity, computer, and systems engineering. She designed courses in cybersecurity curriculum to NSA/DHS Center of Academic Excellence and NIST National Initiative for Cybersecurity Education standards. Research areas include: misinformation, industrial controls risk, experiential learning, information and security risk management, digital forensics.\n\nLt.Col Harry Kantola conducts research at the Finnish National Defence University, Helsinki. Also currently appointed to the Finnish Army Signal School as commandant.. He served in various capacities in the Finnish Navy, Armoured Signal Coy, and Armoured Brigade from 1991. Also served as a researcher at the NATO Cooperative Cyber Defence Centre of Excellence, Tallinn, Estonia and Chief of Cyber Division in C5 Agency.\n\nPhD Martti J Kari is university teacher of cyber security, hybrid threats and strategic intelligence in Jyväskylä University, Finland. He retired as colonel from Finnish Defense Intelligence in the end of year 2017. His last post in military was Assistant Chief of Defense Intelligence. He has MA in Russian language (1993) and literature, MA in cyber security (2017), and PhD in cyber security 2019 in Jyväskylä University. The topic of his PhD thesis was Russian cyber threat perception.\n\nMr. Antti Kariluoto is a data science and an artificial intelligence enthusiast who researches smart buildings, cybersecurity, and blockchain in the University of Jyväskylä.\n\nHenrik Karlzén is a researcher at the Swedish Defence Research Agency and got his master's in cyber security in 2009 at Chalmers University of Technology, Gothenburg, Sweden. His research focuses on cyberwar, risk management, culture and behaviour.\n\nDr. Kiviharju works as a principal scientist in the Finnish Defence Research Agency in Cyber Defence, for 16 years now. Kiviharju wrote his PhD in cryptography, and specializes in the technological aspects of the cyberspace.\n\nThorsten Kodalle LTC (General Staff) lectures on security policy (Command and Staff College of the German Armed Forces) with a particular focus on NATO, Critical Infrastructure and Cyber. A member of the NATO research task group \"Gamification of Cyber Defense/Resilience\", an experienced facilitator of manual wargaming on the operational level for courses of action analysis, for operational analysis, operations research, serious gaming and especially for matrix wargaming.\n\nxiv",
    "Reproduced with permission of copyright owner. Further reproduction prohibited without permission."
  ],
  "metadata": {
    "title": "Usefulness of Cyber Attribution Indicators",
    "subtitle": "henrik.karlzen@foi.se",
    "document_type": "unknown",
    "venue": "",
    "publication_year": 2017,
    "authors": [
      "Henrik Karlzén",
      "Swedish Defence Research Agency"
    ],
    "affiliations": [],
    "emails": [
      "henrik.karlzen@foi.se"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "Attributing a cyberattack to the attacker is difficult. Cyberspace is conducive to anonymity and many attackers actively hide their tracks by using false flags that point to other culprits. On the other hand, the difficulties of attribution are overstated by some, such as the media, in efforts to remain neutral. Furthermore, the requisite level of certainty in attributions depends on whether the information will be acted upon in a court of law by striking back, or merely to better understand the attack. Attributing cyberattacks would enable counter-attacking and the use of sanctions. If the attribution was to establish a nation-state as the attacker, there could be geopolitical and military implications. Attacks by nation-states may also exempt insurance companies from paying out compensation and reveal cyber weapon sales in violation of export restrictions to those nation-states. The extant academic literature on attribution is interdisciplinary, with research on technical indicators and discussions on political implications. For instance, the Diamond model includes attacker motivations and capabilities, while the Q model includes over a hundred indicators divided into more than thirty categories, such as functionality and skills. Based on the literature, this paper investigates how attribution has been used by cyber security companies to establish attacker identity in all attacks during 2017, as covered by the Council on Foreign Relations database on nation-state cyber operations. It is concluded (1) that attribution is based on indicators such as IP addresses, language settings, required resources, and the apparent (political) goal. It is also concluded (2) that these indicators may be hard to measure, e.g. due to obfuscation and false flags that point in different directions. These are often based on previous (also weak) attribution and are commonly used without scientific rigour. Finally, it is also concluded (3) that publicly pointing fingers at nation-states may be pointless or dangerous because of the power differential, and may reveal one's sources and methods for attribution.",
    "keywords": [
      "cyberattack",
      "attribution",
      "cyber operation",
      "APT",
      "security",
      "usefulness"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.34190/EWS.20.074"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": []
    },
    "references_block_count": 1,
    "references_entries_estimated": 45,
    "heading_count": 13,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 84,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 0.9761904761904762,
      "unique_index_count": 45
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "author_year",
      "recommended_style": "author_year",
      "aligned": true,
      "signals": {
        "superscript_hits": 0,
        "superscript_definition_lines": 0,
        "numeric_bracket_hits": 0,
        "numeric_endnote_lines": 0,
        "author_year_hits": 54
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 129.0,
      "dominant_bib_coverage_rate": 0.34108527131782945,
      "dominant_link_target": "bibliography",
      "dominant_unresolved_flag": "unresolved_reference_links"
    },
    "heading_validation": {
      "heading_count": 13,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 6,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": false,
        "emails": true,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": false,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 2,
        "affiliations": 0,
        "emails": 1,
        "orcids": 0,
        "keywords": 6,
        "doi": 1,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 0
      },
      "coverage": {
        "core_coverage": 1.0,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_affiliations",
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "unresolved_reference_links",
      "low_bib_coverage",
      "heading_numbering_parent_violation",
      "meta_missing_affiliations",
      "meta_low_email_author_link_rate"
    ]
  },
  "citation_summary": {
    "style": "author_year",
    "dominant_bucket": "author_year",
    "dominant": {
      "intext_total": 84.0,
      "success_occurrences": 82.0,
      "success_unique": 44.0,
      "bib_unique_total": 129.0,
      "occurrence_match_rate": 0.9761904761904762,
      "bib_coverage_rate": 0.34108527131782945,
      "success_percentage": 97.62,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "author_year"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 84.0,
        "success_occurrences": 82.0,
        "success_unique": 44.0,
        "bib_unique_total": 129.0,
        "occurrence_match_rate": 0.9761904761904762,
        "bib_coverage_rate": 0.34108527131782945,
        "success_percentage": 97.62,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "updated_at_utc": "2026-02-14T08:16:54.852370+00:00"
}