{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\R9JY8KKM\\Blagden - 2020 - Deterring cyber coercion the exaggerated problem of attribution.pdf",
  "custom_id": "407",
  "response": {
    "id": "batch-b6235e9e-408-8b86db51-3c02-4f15-94d8-62d60e9f0294",
    "custom_id": "407",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "Survival Global Politics and Strategy\n\nSurvival\n\nGlobal Politics and Strategy\n\nTaylor &amp; Francis\n\nTaylor &amp; Francis Group\n\nISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20\n\n# Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\nDavid Blagden\n\nTo cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072\n\nTo link to this article: https://doi.org/10.1080/00396338.2020.1715072\n\nPublished online: 04 Feb 2020.\n\nSubmit your article to this journal\n\nArticle views: 1757\n\nView related articles\n\nView Crossmark data\n\nCiting articles: 5 View citing articles\n\nFull Terms &amp; Conditions of access and use can be found at\n\nhttps://www.tandfonline.com/action/journalInformation?journalCode=tsur20",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2314,
              "width": 1762
            }
          },
          {
            "index": 1,
            "markdown": "# Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\nDavid Blagden\n\nThe potential damage from possible cyber attacks is rising as the sophistication of cyber weapons increases.¹ Accordingly, the question of whether such attacks can be deterred is an increasingly salient one for governments, national-security agencies and the populations they seek to protect.² One characteristic of cyber attack, its potential for anonymity, is often taken as an insurmountable barrier to effective deterrence based on retaliatory punishment. But such assumptions are misguided. Coercion is the form of hostile political influence that deterrence seeks to oppose, and in order to coerce, a belligerent must necessarily identify that which it values. Attempted coercion thereby serves as a preference-revelation mechanism. Even if a belligerent can escape identifying itself via anonymous cyber attack, it cannot escape identifying interests that it holds dear, which can then be held at risk by those seeking deterrence.\n\nThe political interests being advanced by a cyber attack will often make the identity of the aggressor clear, of course, even if the origin of the attack itself cannot be readily traced via technical means.³ While a cyber attack may be technically anonymous, the strategic interaction of which it is a part can make clear whose interests are at stake. Yet many actors could have similar interests, meaning that the specific aggressor might remain unidentified.\n\nDavid Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute.\n\nSurvival | vol. 62 no. 1 | February–March 2020 | pp. 131–148\n\nDOI 10.1080/00396338.2020.1715072",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 2,
            "markdown": "David Blagden\n\nSuch reservations over strategic attribution are overblown, however. This is because they conflate two different variables within the deterrence calculus: aggressor identity and aggressor interests. These variables do often correlate: if you want to retaliate against an attacker's territory, for instance, you need to know whose territory. Yet it is possible to identify valued interests of an attacker without identifying those interests' sole holder. And crucially, coercion is not possible without identifying the interests being advanced, in cyberspace or anywhere else, since the very nature of coercion requires revelation of desired changes in behaviour.⁴ Russia, for example, would not need to identify which specific NATO country cyber-attacked it to still identify – and hold at risk – interests shared by all NATO members. It is therefore possible to retaliate against revealed preferences – to achieve successful strategic attribution of interests – even when strategic attribution of a specific attacker identity remains challenging. Many actors may hold similar interests while only one of them may be responsible for a particular cyber attack, but that need not matter: the very factor that obscures their specific identities (their shared interests) also means that retaliating against those interests will punish the underlying aggressor. The fact that the specific attacker may have ‘gotten away with it’ in terms of not being identified individually will be little consolation when its interests have nonetheless been impaired. And knowing as much beforehand, it is possible for deterrence to hold based on the threat of subsequent retaliatory punishment.\n\nWhat is the value of such analysis? After all, cyber weapons are ill-suited tools for explicit coercive signalling, since their capability is often unclear prior to their use, and degraded by their revelation insofar as defenders can patch exposed vulnerabilities.⁵ And many categories of hostile cyber action – attrition of an opponent's capabilities, hacking for enjoyment or publicity, covert cyber espionage, cyber-enabled theft, subversion and disinformation, and so forth – are pressing security concerns but do not achieve their effects via the issuance of coercive threats. Also, cyber deterrence has hardly been an unambiguous success thus far; there have been plenty of cyber attacks against states with retaliatory means at their disposal, despite successful culprit attribution and superior relative power. Examples include the 2012 attacks on the US financial system and Saudi Aramco, the 2013 attack on the",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 3,
            "markdown": "Sands Casino and the 2014 attack on Sony Pictures. On top of all this, one could question the value of more deterrence theory while empirical scholarship on cyber aggression remains relatively sparse.\n\nNone of these rejoinders hold water, however. By themselves, cyber threats are indeed flawed tools of coercive signalling. But taken in strategic context, a wide range of hostile cyber actions meet a reasonable definition of coercion: cost imposition in pursuit of behavioural change. If an attacker seeks to coercively exploit a favourably changed balance of power following successful attrition or extortion, if a protester draws attention to a cause in a way that generates coercive political costs, or if cyber espionage delivers information that is utilised coercively in another domain, coercive interests are being advanced. Meanwhile, observed cyber attacks -- those that, for whatever reason, have not been deterred -- are not evidence of the futility of the deterrent enterprise, since defenders' resolve to impose punishment rises with the severity of the attack suffered while the pool of capable‐enough potential culprits shrinks. For example, North Korea going undeterred in its 2014 Sony hack -- a rudimentary and low‐damage attack -- does not mean that deterrence has failed with respect to great‐power use of more capable cyber weaponry against other major states. Lastly, owing to unavoidable selection bias, the empirical study of non‐occurrences will underplay deterrence's causal significance; cyber‐deterrence theory can help offset this imbalance.\n\n### Escalation dominance and the ‘return address' problem\n\nDeterrence is achieved when an actor -- a state, an armed group or an individual -- concludes that the likely costs of an attack exceed the likely benefits. Opponents can be deterred in two ways. Deterrence by denial occurs when a potential aggressor concludes that attack will be ineffective because of the strength of the countermeasures in place: it is denied the opportunity of achieving its coercive objectives. Deterrence by punishment, in contrast, does not promise to diminish an attack's effectiveness, but rests on the threat of retaliation of sufficient magnitude that the aggressor will be worse off than if it had not attacked in the first place: it will be punished after the fact. Deterring or thwarting cyber attack via effective",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 4,
            "markdown": "David Blagden\n\ndenial measures, such as information and communications technology (ICT) hardening and resilience, is of course an important component of effective cyber deterrence. But the focus here is deterrence of those threats that cannot be reliably denied.\n\nThere is no reason in principle that the use of any new weapon cannot be deterred via the threat of retaliation using the same or alternative weapons systems. To be insusceptible to such 'cross-domain' deterrence – deterrence reliant on the threat of costs imposed in an operational domain other than that in which the original attack occurred – a new weapon would have to possess destructive capability that no other existing weapon could match and be available exclusively to one party. Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited costs.[12] Although nuclear retaliation against irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence' logic.[13] A similar logic underpinned Cold War 'tripwire' military deployments. US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces attacked.[14]\n\nThe prominence of deterrence by punishment in Western cyber strategy has grown in line with capabilities and understanding. The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and resilience.[15] Following Edward Snowden's revelations of Anglo-American capabilities, however, both countries have become less reluctant to discuss their full range of options. The 2015 US cyber-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of deterrence.[16] The Western allies have also made",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 5,
            "markdown": "it increasingly explicit that cross-domain retaliation is a component of their thinking. Most recently, US posture innovations stemming from the 2018 National Cyber Strategy -- the ‘Cyber Deterrence Initiative' (which aims to bolster retaliatory deterrence through collective alliance responses) and the ‘persistent engagement' doctrine (which contemplates a continuous cycle of tracking and offensive action against emerging cyber threats) -- display yet more emphasis on punishment. There are important questions, discussed later, about whether rising faith in the efficacy of offensive operations -- especially of the pre-emptive variety -- as a response to threatened aggression could itself become an escalatory risk. Yet the fact remains that threatened escalation is already an important component of major powers' responses to emerging cyber threats, and unlikely to be retracted.\n\nFor effective deterrence via the threat of punishment, however, a potential attacker needs to know there is a significant chance of actually being punished. Assessments of this likelihood focus on the defender's capability and resolve: does the victim of an attack have the incentives, determination and wherewithal to retaliate by imposing a sufficient level of costs? Embedded in the capability half of the equation is a crucial subsidiary question: can the aspiring deterrer target its retaliation in the first place? Absent a ‘return address', no amount of retaliatory firepower will deter if attackers can be confident it will never be directed against anything they value.\n\nThis is where cyber attack poses a challenge for deterrence. Sophisticated cyber attacks may prove untraceable, even by the most advanced cybersecurity agencies. Masking internet protocol addresses, routing attacks via numerous connected computers (‘bots') that have wittingly or otherwise been turned into a cross-border network, initiating an attack from a cybercafe or public library, hacking and utilising some unsuspecting individual's internet-connected mobile phone, and so forth, may facilitate apparently unattributable cyber attacks. Furthermore, even if the computer used to initiate an attack can be identified, it is a greater challenge to prove who was sitting at it, or on whose orders they acted. The ongoing state-versus",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 6,
            "markdown": "David Blagden\n\nprivate arms race in encryption technology only intensifies the problem.²⁴ While progress is being made in cyber forensics, technological innovation nevertheless appears unlikely to render all cyber attacks traceable in the near future.²⁵ Crucially, however, cyber attacks are not actually as anonymous as their technical characteristics might imply, and so do not enjoy the immunity from targeted retaliation that is often feared.\n\n## The coercive revelation of preferences\n\nKey research in cyber deterrence and coercion is united around the pivotal importance of attribution. For Thomas Rid and Ben Buchanan, ‘attribution is fundamental: almost any response to a specific offence – law enforcement, diplomatic, or military – requires identifying the offender first’.²⁶ Erica Borghard and Shawn Lonergan similarly contend that ‘coercion in cyberspace requires attribution to be effective’, while Martin Libicki reasons that coercion must be visibly associated with the coercer to operate, the logic being that the coercer must identify themselves if they are to cause the behavioural change they desire.²⁷ These assessments are aligned with seminal early analyses of the role of punishment in deterrence, which treated the existence of an identified enemy against which retaliation could be directed as a baseline assumption.²⁸\n\nSuch orthodoxies, however, obscure a vital distinction in the logic of punishment, with substantial implications for the cyber-deterrence debate. Retaliatory punishment is about imposing costs on political, economic and social interests – populations, cities, forces, wealth, status and anything else from which the attacker derives utility. The specific identity of the attacker is not an interest, and has no necessary political content. Of course, many important interests are exclusively associated with a particular identity, usually a state holding territory. Accordingly, deterrence by threatening some package of political, economic and social assets that are located in a particular territory requires the identification of the custodian of that territory. For this reason, the conflation of interests and identities was largely unproblematic in Cold War deterrence: for practical purposes, the interests that each aspiring deterrer sought to hold at risk were synonymous and coextensive with an exclusive identified adversary.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 7,
            "markdown": "Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\nWhile many interests are indeed unique to a specific holder, many others are not. Notwithstanding the Cold War experience, deterrence based on the threat of retaliatory punishment does not inherently require attribution of the attacker's identity, provided relevant interests can be ascertained. A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic preferences.[29] To advance a set of political interests via coercion, a coercer at least implicitly identifies those interests by specifying what behavioural change it wants to encourage. Attempted coercion therefore serves as a mechanism of preference revelation.\n\nSuch preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical means.[30] If the interests that the cyber coercion seeks to advance align solely with the unique identifiable interests of a particular state or group, then that actor will have identified itself. Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber attack[31] – this too may reveal the attacker's identity. Yet even where a specific attacker is not identifiable via these revealed preferences, preference revelation remains useful for deterrence: if there are a dozen possible culprits behind a given cyber attack, the very thing that makes them hard to distinguish – their similar interests – also unifies them. Thus, while the precise identity of the attacker may indeed remain unclear, this still does not preclude an effective counter-value deterrent posture. The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of retaliation.[32]\n\nThe most high-profile cyber attack to date represents a key example of interest attribution in the absence of specific attacker identification. Iran did not need state-of-the-art cyber forensics to have a good idea that the Stuxnet attack on its nuclear facilities uncovered in 2010 was launched by Israel, the United States or one of those two states' allies. While more than one technically capable actor had an interest in retarding Iran's nuclear programme,",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 8,
            "markdown": "David Blagden\n\nmaking it impossible to identify the specific attacker based on desired behavioural change alone, there were interests common to all possible attackers – the security of the United States' Middle Eastern allies – that Iran could have held at risk to achieve deterrence. Stuxnet was not an attack of explicit coercive signalling, of course; it was covert attrition, intended to degrade a capability. Nevertheless, that attrition was then exploited coercively in non-cyber domains and, once discovered – as it was always likely to be – the interests of its perpetrators were not hard to discern even if specific attacker identity remained opaque. The principal barrier to Iran's achieving deterrence was not the anonymity of the cyber attack, but its military inferiority and associated paucity of sufficiently credible retaliatory options. Cyber attacks on Estonia (2007), Georgia (2008), Finland (2013) and Ukraine (2014) – strategically attributable to Russia, even if technical attribution remained challenging – reflected the failure of deterrence for similar reasons. Beyond such observed incidents, however, the cyber attacks contemplated but not conducted due to the likely costs of potential retaliation would be the most probative indicators of effective deterrence of cyber attacks via the threat of retaliation. Yet such cases remain by definition largely unobservable.\n\n## Caveats and qualifications\n\nOn balance, there are grounds for optimism about prospects for deterring cyber attacks via both cyber and non-cyber retaliatory means, at least by countries powerful enough to threaten meaningful costs. Five broad caveats, however, counsel against wholesale reliance on counter-value deterrence.\n\nFirstly, cyber attacks conducted by individuals solely to disrupt, without intending to change behaviour, are unlikely to be amenable to deterrence. Since such individuals would not be seeking to advance a political purpose, they would have no identifying cause and could thus be genuinely anonymous. The same may be true of those who hack solely to bring private information to public attention.[33] It may also be true of those who hack solely for financial enrichment, absent any higher coercive purpose. Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale casualties.[34]",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 9,
            "markdown": "Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\nSecondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war,[37] so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it.[39] The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.[40]\n\nThirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to achieve.[42] Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis instability.[43] Among recent Western posture innovations, the Cyber Deterrence Initiative – reflecting Washington's goal of coordinating retaliation against cyber attack among its allies – aims to bolster second-strike credibility and therefore increase stability. But persistent engagement – embodying Washington's stated intention to pre-empt possible hostile cyber action – could cut the other way, incentivising US adversaries to strike first rather than risk waiting to be forcibly disarmed.\n\nFourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag operations.[44] If Russia decided that its strategic interests would be served by China and the United States' weakening each other militarily, for example, it might conduct a technically anonymous cyber attack on US forces in Asia that seemingly benefitted China – or even one with ostensibly Chinese technical characteristics – leading Washington to believe Beijing was commencing hostilities against its regional interests. This could provoke swift US retaliation and equally swift Chinese escalation",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 10,
            "markdown": "David Blagden\n\nowing to each side's fear of losing first-move advantages.⁴⁵ Moreover, even without the successful framing of an innocent party as the target for misdirected retaliation, false-flag operations may sow doubt and preclude effective retaliation, undermining the credibility of punishment threats.\n\nThis problem is context-specific and surmountable, however. Between two parties with a less offence-dominant strategic relationship than the contemporary US-Chinese situation is often taken to be⁴⁶ – and even that is contestable on the cyber front⁴⁷ – a dearth of first-move advantages could allow scope for diplomatic consultation over the origin of the attack.⁴⁸ If the framed aggressor repudiated the coercive goals that appeared to point in its direction, consciously and visibly eschewing the potential benefits of the apparent coercion, it would credibly signal that it was not to blame.⁴⁹ For example, if a party that appeared to benefit from a cyber attack on another state's internet-connected military logistics chain refrained from taking offensive conventional action even while the attack victim's forces were immobilised by the attack's effects, that would be a costly – and thus credible – signal of restraint. The third party attempting such framing would then itself be in a perilous situation: if its own subversive agenda were uncovered, the two parties it had attempted to trick could retaliate in concert.⁵⁰ Thus, third-party framing is not a risk-free option, and the threat could be minimised if potential cyber adversaries pursued deterrent postures that downplayed first-move advantages. Indeed, the major powers have already done so at the top rung of the escalatory ladder by way of establishing survivable nuclear arsenals. Similarly, non-malicious cyber accidents could be falsely construed as attacks.⁵¹ But again, identifying the coercive interests at stake could mitigate the risk of errant retaliation, and the repudiation of the coercive benefits would duly signal blamelessness.\n\nFinally, recognising that cyber coercion will always seek to advance some set of interests does not mean that discerning such interests will be easy. Coercers, to be sure, will often want to be correctly identified so as to maximise the clarity of intended signals.⁵² But many potential cyber attackers may instead prefer to achieve their strategic goals via covert cyber action to avoid possible retaliatory costs and – as discussed throughout – cyberspace is particularly amenable to such concealment and obscuration.⁵³",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 11,
            "markdown": "Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\nAccordingly, those seeking to hold the relevant interests at risk to effect deterrence may have to look at the indirect consequences of the initial cyber attack to isolate the set of interests being advanced. Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats credible[54] – removing the necessity of choosing among enemies. Indeed, in retaliating for Stuxnet against Israel (via its Hizbullah and Hamas proxies), the United States (via the 2012 US financial hack) and Saudi Arabia (via the 2012 Saudi Aramco cyber attack), Iran appeared to take this route. Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents.[55] But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are punished.[56] Furthermore, target calculations would also be subject to iterative refinement. For instance, if the potential beneficiaries of the interests ranked as being advanced the most by an attack refused to repudiate the coercive gains, they would effectively certify that those were the interests that should suffer retaliation. By contrast, the repudiation of those gains would signal that a different set of interests than those the attack seemed intended to advance should be held at risk.\n\n\\* \\* \\*\n\nDeterring cyber attacks by threatening to impair the interests they are presumed to advance, as opposed to focusing on identifying a sole attacker, is not without peril. It risks retaliating against innocent states or civilians, which incurs ethical costs and potential blowback, while cross-domain escalation may become dangerously unstable, especially if policymakers become inordinately confident in the efficacy of offensive cyber operations. Nevertheless, the anonymity of cyberspace is not the fundamental obstacle to counter-value deterrence it is often supposed to be, for attempting to coerce via cyber means reveals interests that can be held at risk. Accordingly, as the damage potential of cyber weaponry continues to increase, governments",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 12,
            "markdown": "David Blagden\n\nand the populations they seek to protect may gain security from the threat of retaliatory punishment. For all of its ethical uncertainties, therefore, this form of deterrence remains the final backstop of major powers' strategic postures, and could constitute as potent an instrument against cyber threats as it has against those in the nuclear and conventional domains.\n\n## Acknowledgements\n\nThe author thanks Ben Buchanan, Andrew Futter, Erik Gartzke, Jon Lindsay, Kubo Mačák, Patrick Porter, Simon Smith, Peter Watkins and especially Helena Mills for invaluable comments on drafts of this article.\n\n## Notes\n\n1. On cyber-capability growth, see Dale Peterson, 'Offensive Cyber Weapons: Construction, Development, and Employment', *Journal of Strategic Studies*, vol. 36, no. 1, February 2013, pp. 120–4. For reference, a cyber attack is understood as the intentional use of computer code – a ‘cyber weapon’ – to harm or exert hostile control over another party’s information and communications technology (ICT) systems or networks, along with the physical systems and living beings dependent upon them.\n\n2. Some have derided discussions of cyber deterrence as misguidedly applying an outdated ‘Cold War paradigm’ to an ill-suited strategic context. See, for example, Daniel Steed, ‘Cyber War, Let’s Get Real(ist)’, *War on the Rocks*, 14 October 2013, https://warontherocks.com/2013/10/cyber-war-lets-get-realist/. There is nothing ‘Cold War’ about deterrence, however, despite the nuclear era bringing the concept new-found prominence. Rather, it is a timeless and necessary attribute of interactions between mutually armed parties under anarchy: see Ben Buchanan, ‘Cyber Deterrence Isn’t MAD; It’s Mosaic’, *Georgetown Journal of International Affairs*, International Engagement on Cyber IV, 2014, p. 131. It is therefore an entirely appropriate concept for the cyber age.\n\n3. See Richard L. Kugler, ‘Deterrence of Cyber Attacks’, in Franklin D. Kramer, Stuart H. Starr and Larry K. Wentz (eds), *Cyberpower and National Security* (Dulles, VA: Potomac Books, 2009), pp. 309–41; Martin C. Libicki, *Cyberdeterrence and Cyberwar* (Santa Monica, CA: RAND, 2009), p. 44; and Thomas Rid and Ben Buchanan, ‘Attributing Cyber Attacks’, *Journal of Strategic Studies*, vol. 38, nos. 1–2, February 2015, pp. 4–37.\n\n4. Erica D. Borghard and Shawn M. Lonergan, ‘The Logic of Coercion in Cyberspace’, *Security Studies*, vol. 26, no. 3, May 2017, pp. 452–81.\n\n5. Key recent works on cyber deterrence/ coercion share this perspective. Jon R.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 13,
            "markdown": "Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\nLindsay argues that 'cyber operations are unsuited for coercive signaling' in 'Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence against Cyberattack', Journal of Cybersecurity, vol. 1, no. 1, September 2015, p. 54. Borghard and Lonergan similarly contend that 'signaling in cyberspace is the most problematic of all the domains', in 'The Logic of Coercion in Cyberspace', p. 456.\n\n6 Robert A. Pape, Bombing to Win: Air Power and Coercion in War (Ithaca, NY: Cornell University Press, 1996), p. 4.\n\n7 As Borghard and Lonergan's own Schelling-derived caveat admits, coercion need not take the form of explicit threat-issuance to nonetheless be operative; the key is simply that it is inferred by targets, based on their assessment of others' capabilities, interests and behaviours. 'The Logic of Coercion in Cyberspace', p. 455, note 11. Indeed, cyber capabilities may yield coercive options well beyond mere signalling and threat-issuance: see David Betz, 'Cyberpower in Strategic Affairs: Neither Unthinkable nor Blessed', Journal of Strategic Studies, vol. 35, no. 3, November 2012, pp. 689-711.\n\n8 Lindsay, 'Tipping the Scales', p. 59. This is not to deny that states are using cyber exploits against each other all the time, but simply a recognition that no major power has (as of December 2019) suffered a cyber-induced mass-casualty attack. The Pyongyang-backed WannaCry attack in 2017 perhaps has come closest, insofar as it disrupted various national healthcare systems and thereby harmed a large number of patients.\n\n9 See Christopher H. Achen and Duncan Snidal, 'Rational Deterrence Theory and Comparative Case Studies', World Politics, vol. 41, no. 2, January 1989, pp. 143-69; and Lindsay, 'Tipping the Scales', p. 54. On this relationship between observed events (for instance, deterrence success or failure) and explanatory theory, see David Blagden, 'Induction and Deduction in International Relations: Squaring the Circle between Theory and Evidence', International Studies Review, vol. 18, no. 2, June 2016, pp. 195-213.\n\n10 See Robert Jervis, The Meaning of the Nuclear Revolution: Statecraft and the Prospect of Armageddon (Ithaca, NY: Cornell University Press, 1989), pp. 8-14; and Pape, Bombing to Win, pp. 13-14.\n\n11 The risk of global commerce and communications disruption may also deter potential cyber attackers if they fear the self-harm of such disruption. See Joseph S. Nye, Jr., 'Deterrence and Dissuasion in Cyberspace', International Security, vol. 41, no. 3, Winter 2016/17, pp. 44-71. However, this article's focus is attacks that aggressors would have otherwise judged to be advantageous absent their opponent's deterrent strategies, all else being equal, rather than those forgone due to other concerns.\n\n12 A qualification would arise if cyber attacks became capable of compromising nuclear command and control, thus removing the risk of cross-domain retaliation.\n\n13 This is a more precise rendering of Herman Kahn's concept of 'escalation dominance'. Such dominance",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 14,
            "markdown": "David Blagden\n\nmay be unobtainable in a world of multiple nuclear powers, but retaliatory equivalence creates deterrence through the threatened escalation to ever greater yet still not advantageous pain. See Charles L. Glaser, Analyzing Strategic Nuclear Policy (Princeton, NJ: Princeton University Press, 1990), pp. 50, 55–7; and Thomas C. Schelling, Arms and Influence (New Haven, CT: Yale University Press, 2008 [1966]), p. 104.\n\n14 Schelling, Arms and Influence, p. 47.\n\n15 US Department of Defense, 'Department of Defense Strategy for Operating in Cyberspace', 2011, https://csrc.nist.gov/CSRC/media/Projects/ISPAB/documents/DOD-Strategy-for-Operating-in-Cyberspace.pdf; HM Government, The UK Cyber Security Strategy: Protecting and Promoting the UK in a Digital World (London: UK Cabinet Office, 2011), https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/60961/uk-cyber-security-strategy-final.pdf.\n\n16 US Department of Defense, 'The Department of Defense Cyber Strategy', 2015, https://archive.defense.gov/home/features/2015/0415_cyber-strategy/final_2015_dod_cyber_strategy_for_web.pdf, p. 11; HM Government, National Cyber Security Strategy 2016–2021 (London: UK Cabinet Office, 2016), https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/567242/national_cyber_security_strategy_2016.pdf, pp. 41–52.\n\n17 See David E. Sanger and Elisabeth Bumiller, 'Pentagon to Consider Cyber Attacks Acts of War', New York Times, 31 May 2011, http://www.nytimes.com/2011/06/01/us/politics/01cyber.html?_r=1; Finbarr Bermingham, 'NATO Summit 2014: Cyber-attack Could Trigger Retaliation from all NATO Members', International Business Times, 5 September 2014, http://www.ibtimes.co.uk/nato-summit-2014-cyber-attack-could-trigger-retaliation-all-nato-members-1464230; and Anna Mikhailova, 'UK Could Retaliate Against Cyber Attacks with Missiles, Attorney General Says', Daily Telegraph, 23 May 2018, https://www.telegraph.co.uk/politics/2018/05/23/uk-has-legal-right-retaliate-against-cyber-attacks-missiles/. The US government's invocation of cyber theft as a motive for its trade sanctions on China is consistent with this pattern. See 'A Quick Guide to the US–China Trade War', BBC, 16 December 2019, https://www.bbc.co.uk/news/business-45899310.\n\n18 White House, 'National Cyber Strategy of the United States of America', 2018, https://www.whitehouse.gov/wp-content/uploads/2018/09/National-Cyber-Strategy.pdf. See also Theresa Hitchens, 'US Urges \"Likeminded\" Countries to Collaborate on Cyber Deterrence', Breaking Defense, 24 April 2019, https://breakingdefense.com/2019/04/us-urging-likeminded-countries-to-collaborate-on-cyber-deterrence/; and Greg Myre, \"Persistent Engagement\": The Phrase Driving a More Assertive US Spy Agency', NPR, 26 August 2019, https://www.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 15,
            "markdown": "Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\nnpr.org/2019/08/26/747248636/persistent-engagement-the-phrase-driving-a-more-assertive-u-s-spy-agency?t=1577803786687.\n\n19 Brandon Valeriano and Benjamin Jensen, *The Myth of the Cyber Offense: The Case for Restraint* (Washington DC: Cato Institute, 2019), https://www.cato.org/sites/cato.org/files/pubs/pdf/pa862.pdf.\n\n20 Paul Cornish et al., *On Cyber Warfare* (London: Chatham House, 2010), pp. 42–5. See also Daryl G. Press, *Calculating Credibility: How Leaders Assess Military Threats* (Ithaca, NY: Cornell University Press, 2005), pp. 2–3.\n\n21 Nye, ‘Deterrence and Dissuasion in Cyberspace’, pp. 49–52.\n\n22 Cornish et al., *On Cyber Warfare*, p. 13; Libicki, *Cyberdeterrence and Cyberwarfare*, pp. 41–52.\n\n23 Evidence suggests that the Russian and Chinese governments, among others, see the use of arms-length ‘non-state’ cyber proxies as deniable tools of coercive statecraft. See Alexander Klimberg, ‘Mobilising Cyber Power’, *Survival*, vol. 53, no. 1, February–March 2011, pp. 41–60.\n\n24 Daniel Moore and Thomas Rid, ‘Cryptopolitik and the Darknet’, *Survival*, vol. 58, no. 1, February–March 2016, pp. 7–38.\n\n25 Certainly, progress is being made on this, particularly in identifying technical ‘fingerprints’ of major states’ cyber attacks. See Stewart Baker, ‘The Attribution Revolution’, *Foreign Policy*, 17 June 2013, https://foreignpolicy.com/2013/06/17/the-attribution-revolution/; and Brian M. Mazanec and Bradley A. Thayer,\n\nDeterring Cyber Warfare: Bolstering Strategic Stability in Cyberspace (New York: Palgrave, 2015), pp. 57–63. Nevertheless, this is unlikely to become perfect, particularly as attackers adapt to defenders’ progress, and given the potential for false-flag attacks as discussed below. All other fields of military–technological development have witnessed iterative back-and-forth dynamics between offensive penetration and defensive shielding, so recent innovations in cyber fingerprinting will be countered by anonymisation innovations.\n\n26 Rid and Buchanan, ‘Attributing Cyber Attacks’, pp. 30–1.\n\n27 Borghard and Lonergan, ‘The Logic of Coercion in Cyberspace’, p. 459; Libicki, *Cyberdeterrence and Cyberwar*, p. 128.\n\n28 Glenn H. Snyder, *Deterrence and Defense: Toward a Theory of National Security* (Princeton, NJ: Princeton University Press, 2015), pp. 14–16.\n\n29 Pape, *Bombing to Win*, p. 12. Compellence is sometimes treated separately from coercion, but since it essentially represents ‘total’ coercion, here it is cast as coercive. *Ibid.*, p. 4. See also Schelling, *Arms and Influence*, pp. 69–91.\n\n30 Kugler, ‘Deterrence of Cyberattacks’, pp. 309–10.\n\n31 Erik Gartzke, ‘The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth’, *International Security*, vol. 38, no. 2, Fall 2013, pp. 41–73.\n\n32 Holding interests at risk without specifically identified attribution goes beyond valuable recent work on interests as a route to attribution. See, for instance, Rid and Buchanan,",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 16,
            "markdown": "David Blagden\n\n'Attributing Cyber Attacks', p. 8.\n\n33 Both 'recreational' and 'hacktivist' attackers do have interests that can be jeopardised, of course, but doing so via punishment is challenging. The former values the opportunity to commit a successful attack for the mere thrill of it, making punishment and denial one and the same. The latter values something that the wider population may value too – transparency in public life – so punishing their interests could also penalise people that the state is charged with protecting.\n\n34 Certain capability gaps between individual hackers and state-level cyber forces have closed over time. An example is the reduced need for state-level supercomputers to break encryption due to bot technology. See Libicki, *Cyberdeterrence and Cyberwar*, pp. 47-8. Even so, as those with the greatest resources (powerful states and corporations foremost among them) push out the frontier of technological sophistication, the chances of sparsely resourced individuals or groups – however talented – keeping pace becomes small. Such state-versus-individual capability disparities are thus likely to persist, even if gifted hackers close gaps in certain areas. Stuxnet, in particular, shows the extraordinary resources required – including a replica of the entire targeted infrastructure and an expert human-intelligence operation to penetrate air-gapped systems – to propagate an attack of even modest state-level strategic significance. See Jon R. Lindsay, ‘Stuxnet and the Limits of Cyber Warfare’, *Security Studies*, vol. 22, no. 3, July 2013, pp. 365-404.\n\n35 Sarah Kreps and Jacquelyn Schneider, 'Escalation Firebreaks in the Cyber, Conventional, and Nuclear Domains: Moving Beyond Effects-based Logics', *Journal of Cybersecurity*, vol. 5, no. 1, September 2019, pp. 1-11. Libicki sees the risk of third-party censure and opprobrium as a fundamental challenge to the credibility of deterrence by retaliation in response to cyber attack as being greater than it has been for the deterrence of nuclear attack, particularly on the grounds that numerous capable third parties may join the fight. Libicki, *Cyberdeterrence and Cyberwar*, p. 42. See also Lindsay, 'Tipping the Scales', p. 57. Yet while facing normative opprobrium may indeed affect a state's retaliatory resolve, there is no clear reason third parties would join hostilities against a retaliating state – opening themselves to re-retaliation in the process – simply to censure it for retaliating. A related argument, albeit with different causal underpinnings, is that an attack's victim may be self-deterred from certain retaliatory cyber options through fear that they would result in fratricide of their own ICT systems. *Ibid.*, p. 57. This is a relevant concern, but one contingent on the cyber weapon in question – and on aspiring deterrers' weighting of absolute versus relative gains and losses – rather than a fundamental barrier to retaliation per se.\n\n36 Kenneth Geers, 'The Challenge of Cyber Attack Deterrence', *Computer Law and Security Review*, vol. 26, no. 3, May 2010, pp. 300-1.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 17,
            "markdown": "Deterring Cyber Coercion: The Exaggerated Problem of Attribution\n\n37 Erik Gartzke and Jon R. Lindsay, 'Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace', *Security Studies*, vol. 24, no. 2, June 2015, pp. 316–48.\n\n38 Lawrence J. Cavaiola, David C. Gompert and Martin Libicki, 'Cyber House Rules: On War, Retaliation and Escalation', *Survival*, vol. 57, no. 1, February–March 2015, pp. 81–104.\n\n39 See Lindsay, 'Tipping the Scales', pp. 58–64. This trade-off exists throughout deterrent posture – 'asymmetric escalation' doctrines deliver much deterrence but with escalatory dangers, for example, while 'assured retaliation' doctrines offer less deterrence of low-level irritations but also fewer escalatory risks. See Vipin Narang, *Nuclear Strategy in the Modern Era: Regional Powers and International Conflict* (Princeton, NJ: Princeton University Press, 2014), pp. 17–20.\n\n40 Threatening success-prevention may be inherently more credible than threatening punishment, since the former promises minimised costs on both sides. Snyder, *Deterrence and Defense*, p. 16. Deterrence by punishment also cedes control of the decision over how much pain to bear to one’s opponent, and may therefore also be less precise and reliable when dealing with aggressors of uncertain cost-tolerance and risk-acceptance. Lawrence Freedman, *Deterrence* (Cambridge: Polity, 2004), p. 39.\n\n41 James J. Wirtz, 'The Cyber Pearl Harbor', *Intelligence and National Security*, vol. 32, no. 6, September 2017, pp. 758–67. Of course, this is not to suggest that pulling off such a successful attack – or achieving the strategic shock/paralysis that it might induce – would be easy or even feasible, but it could be an attractive prospect for an aspiring aggressor. James J. Wirtz, 'The Cyber Pearl Harbor Redux: Helpful Analogy or Cyber Hype?', *Intelligence and National Security*, vol. 33, no. 5, April 2018, pp. 771–3.\n\n42 A common characteristic of cyber attack is uncertainty even on the attacker’s part over precisely what effects their action will produce. See Borghard and Lonergan, 'The Logic of Coercion in Cyberspace', p. 456.\n\n43 See Ben Buchanan, *The Cybersecurity Dilemma: Hacking, Trust, and Fear Between Nations* (Oxford: Oxford University Press, 2017); and Herbert Lin, 'Escalation Dynamics and Conflict Termination in Cyberspace', *Strategic Studies Quarterly* (Cyber Special Edition), vol. 6, no. 3, Fall 2012, p. 46–70. For theoretical background, see Carl von Clausewitz, *On War*, trans. Michael Howard and Peter Paret (Princeton, NJ: Princeton University Press, 1976 [1832]), pp. 75–89; Barry R. Posen, *Inadvertent Escalation: Conventional War and Nuclear Risks* (Ithaca, NY: Cornell University Press, 1991), pp. 2–3.\n\n44 Libicki, *Cyberdeterrence and Cyberwar*, p. 44.\n\n45 David C. Gompert and Martin Libicki, 'Cyber Warfare and Sino-American Crisis Instability', *Survival*, vol. 56, no. 4, August–September 2014, pp. 8–10; Joshua Rovner, 'Two Kinds of Catastrophe: Nuclear Escalation and Protracted War in Asia', *Journal of Strategic Studies*, vol. 40, no. 5, July 2017, pp. 699–706.\n\n46 Avery Goldstein, 'First Things",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          },
          {
            "index": 18,
            "markdown": "David Blagden\n\nFirst: The Pressing Danger of Crisis Instability in US–China Relations', International Security, vol. 37, no. 4, Spring 2013, pp. 49–89.\n\n47 See Rebecca Slayton, ‘What Is the Cyber Offense–Defense Balance? Conceptions, Causes, and Assessment’, International Security, vol. 41, no. 3, Winter 2016/17, pp. 72–109; and Valeriano and Jensen, The Myth of the Cyber Offense.\n\n48 Furthermore, while cyber dynamics may contribute to worrisome offence dominance in the larger US–China relationship, Western fears of relative cyber weakness vis-à-vis China may also be overblown. See Jon R. Lindsay, ‘The Impact of China on Cybersecurity: Friction and Fiction’, International Security, vol. 39, no. 3, Winter 2014/15, pp. 7–47; and Rovner, ‘Two Kinds of Catastrophe’, p. 712.\n\n49 See Charles L. Glaser, Rational Theory of International Politics: The Logic of Competition and Cooperation (Princeton, NJ: Princeton University Press, 2010), pp. 64–6; and Andrew Kydd, ‘Trust, Reassurance, and Cooperation’, International Organization, vol. 54, no. 2, Spring 2000, pp. 325–57.\n\n50 One attempt at cataloguing such attacks alleges 53 such admitted attacks since the 1930s, with state use of sponsored false-flag terrorist attacks as a pretext for preferred state policy emerging as a favourite. ‘53 Admitted False Flag Attacks’, WashingtonsBlog, 23 February 2015, https://www.globalresearch.ca/53-admitted-false-flag-attacks/5432931.\n\n51 See Lucas Kello, ‘The Meaning of the Cyber Revolution: Perils to Theory and Statecraft’, International Security, vol. 38, no. 2, Fall 2013, p. 31. Such accidents become increasingly likely as system complexity increases.\n\n52 Borghard and Lonergan, ‘The Logic of Coercion in Cyberspace’, p. 459.\n\n53 See David F. Rudgers, ‘The Origins of Covert Action’, Journal of Contemporary History, vol. 35, no. 2, April 2000, pp. 249–62.\n\n54 Lindsay, ‘Tipping the Scales’, p. 63.\n\n55 Ibid., p. 57.\n\n56 In the absence of precise identification of specific insurgent or terrorist attackers, counter-insurgent or counter-terrorist forces may resort to punishing the attackers’ manifested interests – say, razing an insurgent-hosting village or somehow retarding terrorists’ political cause. See Gil Merom, ‘Strong Powers in Small Wars: The Unnoticed Foundations of Success’, Small Wars and Insurgencies, vol. 9, no. 2, September 1998, pp. 38–63; and Robert F. Trager and Dessislava P. Zagorcheva, ‘Deterring Terrorism: It Can Be Done’, International Security, vol. 30, no. 3, Winter 2005/06, pp. 87–123. On drawing parallels between cyber attack and insurgency, see Lindsay, ‘Tipping the Scales’, p. 57. This approach can involve heavy moral costs and blowback, but the point is that there is a rationale motivating the incurrence of such costs.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1953,
              "width": 1371
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 19,
          "doc_size_bytes": 2277247
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "Survival Global Politics and Strategy\nSurvival\nGlobal Politics and Strategy\nTaylor &amp; Francis\nTaylor &amp; Francis Group\nISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20\n# Deterring Cyber Coercion: The Exaggerated Problem of Attribution\nDavid Blagden\nTo cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072\nTo link to this article: https://doi.org/10.1080/00396338.2020.1715072\nPublished online: 04 Feb 2020.\nSubmit your article to this journal\nArticle views: 1757\nView related articles\nView Crossmark data\nCiting articles: 5 View citing articles\nFull Terms &amp; Conditions of access and use can be found at\nhttps://www.tandfonline.com/action/journalInformation?journalCode=tsur20\n# Deterring Cyber Coercion: The Exaggerated Problem of Attribution\nDavid Blagden\nThe potential damage from possible cyber attacks is rising as the sophistication of cyber weapons increases.¹ Accordingly, the question of whether such attacks can be deterred is an increasingly salient one for governments, national-security agencies and the populations they seek to protect.² One characteristic of cyber attack, its potential for anonymity, is often taken as an insurmountable barrier to effective deterrence based on retaliatory punishment. But such assumptions are misguided. Coercion is the form of hostile political influence that deterrence seeks to oppose, and in order to coerce, a belligerent must necessarily identify that which it values. Attempted coercion thereby serves as a preference-revelation mechanism. Even if a belligerent can escape identifying itself via anonymous cyber attack, it cannot escape identifying interests that it holds dear, which can then be held at risk by those seeking deterrence.\nThe political interests being advanced by a cyber attack will often make the identity of the aggressor clear, of course, even if the origin of the attack itself cannot be readily traced via technical means.³ While a cyber attack may be technically anonymous, the strategic interaction of which it is a part can make clear whose interests are at stake. Yet many actors could have similar interests, meaning that the specific aggressor might remain unidentified.\nDavid Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute.\nSurvival | vol. 62 no. 1 | February–March 2020 | pp. 131–148\nDOI 10.1080/00396338.2020.1715072\nDavid Blagden\nSuch reservations over strategic attribution are overblown, however. This is because they conflate two different variables within the deterrence calculus: aggressor identity and aggressor interests. These variables do often correlate: if you want to retaliate against an attacker's territory, for instance, you need to know whose territory. Yet it is possible to identify valued interests of an attacker without identifying those interests' sole holder. And crucially, coercion is not possible without identifying the interests being advanced, in cyberspace or anywhere else, since the very nature of coercion requires revelation of desired changes in behaviour.⁴ Russia, for example, would not need to identify which specific NATO country cyber-attacked it to still identify – and hold at risk – interests shared by all NATO members. It is therefore possible to retaliate against revealed preferences – to achieve successful strategic attribution of interests – even when strategic attribution of a specific attacker identity remains challenging. Many actors may hold similar interests while only one of them may be responsible for a particular cyber attack, but that need not matter: the very factor that obscures their specific identities (their shared interests) also means that retaliating against those interests will punish the underlying aggressor. The fact that the specific attacker may have ‘gotten away with it’ in terms of not being identified individually will be little consolation when its interests have nonetheless been impaired. And knowing as much beforehand, it is possible for deterrence to hold based on the threat of subsequent retaliatory punishment.\nWhat is the value of such analysis? After all, cyber weapons are ill-suited tools for explicit coercive signalling, since their capability is often unclear prior to their use, and degraded by their revelation insofar as defenders can patch exposed vulnerabilities.⁵ And many categories of hostile cyber action – attrition of an opponent's capabilities, hacking for enjoyment or publicity, covert cyber espionage, cyber-enabled theft, subversion and disinformation, and so forth – are pressing security concerns but do not achieve their effects via the issuance of coercive threats. Also, cyber deterrence has hardly been an unambiguous success thus far; there have been plenty of cyber attacks against states with retaliatory means at their disposal, despite successful culprit attribution and superior relative power. Examples include the 2012 attacks on the US financial system and Saudi Aramco, the 2013 attack on the\nSands Casino and the 2014 attack on Sony Pictures. On top of all this, one could question the value of more deterrence theory while empirical scholarship on cyber aggression remains relatively sparse.\nNone of these rejoinders hold water, however. By themselves, cyber threats are indeed flawed tools of coercive signalling. But taken in strategic context, a wide range of hostile cyber actions meet a reasonable definition of coercion: cost imposition in pursuit of behavioural change. If an attacker seeks to coercively exploit a favourably changed balance of power following successful attrition or extortion, if a protester draws attention to a cause in a way that generates coercive political costs, or if cyber espionage delivers information that is utilised coercively in another domain, coercive interests are being advanced. Meanwhile, observed cyber attacks -- those that, for whatever reason, have not been deterred -- are not evidence of the futility of the deterrent enterprise, since defenders' resolve to impose punishment rises with the severity of the attack suffered while the pool of capable‐enough potential culprits shrinks. For example, North Korea going undeterred in its 2014 Sony hack -- a rudimentary and low‐damage attack -- does not mean that deterrence has failed with respect to great‐power use of more capable cyber weaponry against other major states. Lastly, owing to unavoidable selection bias, the empirical study of non‐occurrences will underplay deterrence's causal significance; cyber‐deterrence theory can help offset this imbalance.\n### Escalation dominance and the ‘return address' problem\nDeterrence is achieved when an actor -- a state, an armed group or an individual -- concludes that the likely costs of an attack exceed the likely benefits. Opponents can be deterred in two ways. Deterrence by denial occurs when a potential aggressor concludes that attack will be ineffective because of the strength of the countermeasures in place: it is denied the opportunity of achieving its coercive objectives. Deterrence by punishment, in contrast, does not promise to diminish an attack's effectiveness, but rests on the threat of retaliation of sufficient magnitude that the aggressor will be worse off than if it had not attacked in the first place: it will be punished after the fact. Deterring or thwarting cyber attack via effective\nDavid Blagden\ndenial measures, such as information and communications technology (ICT) hardening and resilience, is of course an important component of effective cyber deterrence. But the focus here is deterrence of those threats that cannot be reliably denied.\nThere is no reason in principle that the use of any new weapon cannot be deterred via the threat of retaliation using the same or alternative weapons systems. To be insusceptible to such 'cross-domain' deterrence – deterrence reliant on the threat of costs imposed in an operational domain other than that in which the original attack occurred – a new weapon would have to possess destructive capability that no other existing weapon could match and be available exclusively to one party. Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited costs.[12] Although nuclear retaliation against irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence' logic.[13] A similar logic underpinned Cold War 'tripwire' military deployments. US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces attacked.[14]\nThe prominence of deterrence by punishment in Western cyber strategy has grown in line with capabilities and understanding. The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and resilience.[15] Following Edward Snowden's revelations of Anglo-American capabilities, however, both countries have become less reluctant to discuss their full range of options. The 2015 US cyber-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of deterrence.[16] The Western allies have also made\nit increasingly explicit that cross-domain retaliation is a component of their thinking. Most recently, US posture innovations stemming from the 2018 National Cyber Strategy -- the ‘Cyber Deterrence Initiative' (which aims to bolster retaliatory deterrence through collective alliance responses) and the ‘persistent engagement' doctrine (which contemplates a continuous cycle of tracking and offensive action against emerging cyber threats) -- display yet more emphasis on punishment. There are important questions, discussed later, about whether rising faith in the efficacy of offensive operations -- especially of the pre-emptive variety -- as a response to threatened aggression could itself become an escalatory risk. Yet the fact remains that threatened escalation is already an important component of major powers' responses to emerging cyber threats, and unlikely to be retracted.\nFor effective deterrence via the threat of punishment, however, a potential attacker needs to know there is a significant chance of actually being punished. Assessments of this likelihood focus on the defender's capability and resolve: does the victim of an attack have the incentives, determination and wherewithal to retaliate by imposing a sufficient level of costs? Embedded in the capability half of the equation is a crucial subsidiary question: can the aspiring deterrer target its retaliation in the first place? Absent a ‘return address', no amount of retaliatory firepower will deter if attackers can be confident it will never be directed against anything they value.\nThis is where cyber attack poses a challenge for deterrence. Sophisticated cyber attacks may prove untraceable, even by the most advanced cybersecurity agencies. Masking internet protocol addresses, routing attacks via numerous connected computers (‘bots') that have wittingly or otherwise been turned into a cross-border network, initiating an attack from a cybercafe or public library, hacking and utilising some unsuspecting individual's internet-connected mobile phone, and so forth, may facilitate apparently unattributable cyber attacks. Furthermore, even if the computer used to initiate an attack can be identified, it is a greater challenge to prove who was sitting at it, or on whose orders they acted. The ongoing state-versus\nDavid Blagden\nprivate arms race in encryption technology only intensifies the problem.²⁴ While progress is being made in cyber forensics, technological innovation nevertheless appears unlikely to render all cyber attacks traceable in the near future.²⁵ Crucially, however, cyber attacks are not actually as anonymous as their technical characteristics might imply, and so do not enjoy the immunity from targeted retaliation that is often feared.\n## The coercive revelation of preferences\nKey research in cyber deterrence and coercion is united around the pivotal importance of attribution. For Thomas Rid and Ben Buchanan, ‘attribution is fundamental: almost any response to a specific offence – law enforcement, diplomatic, or military – requires identifying the offender first’.²⁶ Erica Borghard and Shawn Lonergan similarly contend that ‘coercion in cyberspace requires attribution to be effective’, while Martin Libicki reasons that coercion must be visibly associated with the coercer to operate, the logic being that the coercer must identify themselves if they are to cause the behavioural change they desire.²⁷ These assessments are aligned with seminal early analyses of the role of punishment in deterrence, which treated the existence of an identified enemy against which retaliation could be directed as a baseline assumption.²⁸\nSuch orthodoxies, however, obscure a vital distinction in the logic of punishment, with substantial implications for the cyber-deterrence debate. Retaliatory punishment is about imposing costs on political, economic and social interests – populations, cities, forces, wealth, status and anything else from which the attacker derives utility. The specific identity of the attacker is not an interest, and has no necessary political content. Of course, many important interests are exclusively associated with a particular identity, usually a state holding territory. Accordingly, deterrence by threatening some package of political, economic and social assets that are located in a particular territory requires the identification of the custodian of that territory. For this reason, the conflation of interests and identities was largely unproblematic in Cold War deterrence: for practical purposes, the interests that each aspiring deterrer sought to hold at risk were synonymous and coextensive with an exclusive identified adversary.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nWhile many interests are indeed unique to a specific holder, many others are not. Notwithstanding the Cold War experience, deterrence based on the threat of retaliatory punishment does not inherently require attribution of the attacker's identity, provided relevant interests can be ascertained. A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic preferences.[29] To advance a set of political interests via coercion, a coercer at least implicitly identifies those interests by specifying what behavioural change it wants to encourage. Attempted coercion therefore serves as a mechanism of preference revelation.\nSuch preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical means.[30] If the interests that the cyber coercion seeks to advance align solely with the unique identifiable interests of a particular state or group, then that actor will have identified itself. Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber attack[31] – this too may reveal the attacker's identity. Yet even where a specific attacker is not identifiable via these revealed preferences, preference revelation remains useful for deterrence: if there are a dozen possible culprits behind a given cyber attack, the very thing that makes them hard to distinguish – their similar interests – also unifies them. Thus, while the precise identity of the attacker may indeed remain unclear, this still does not preclude an effective counter-value deterrent posture. The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of retaliation.[32]\nThe most high-profile cyber attack to date represents a key example of interest attribution in the absence of specific attacker identification. Iran did not need state-of-the-art cyber forensics to have a good idea that the Stuxnet attack on its nuclear facilities uncovered in 2010 was launched by Israel, the United States or one of those two states' allies. While more than one technically capable actor had an interest in retarding Iran's nuclear programme,\nDavid Blagden\nmaking it impossible to identify the specific attacker based on desired behavioural change alone, there were interests common to all possible attackers – the security of the United States' Middle Eastern allies – that Iran could have held at risk to achieve deterrence. Stuxnet was not an attack of explicit coercive signalling, of course; it was covert attrition, intended to degrade a capability. Nevertheless, that attrition was then exploited coercively in non-cyber domains and, once discovered – as it was always likely to be – the interests of its perpetrators were not hard to discern even if specific attacker identity remained opaque. The principal barrier to Iran's achieving deterrence was not the anonymity of the cyber attack, but its military inferiority and associated paucity of sufficiently credible retaliatory options. Cyber attacks on Estonia (2007), Georgia (2008), Finland (2013) and Ukraine (2014) – strategically attributable to Russia, even if technical attribution remained challenging – reflected the failure of deterrence for similar reasons. Beyond such observed incidents, however, the cyber attacks contemplated but not conducted due to the likely costs of potential retaliation would be the most probative indicators of effective deterrence of cyber attacks via the threat of retaliation. Yet such cases remain by definition largely unobservable.\n## Caveats and qualifications\nOn balance, there are grounds for optimism about prospects for deterring cyber attacks via both cyber and non-cyber retaliatory means, at least by countries powerful enough to threaten meaningful costs. Five broad caveats, however, counsel against wholesale reliance on counter-value deterrence.\nFirstly, cyber attacks conducted by individuals solely to disrupt, without intending to change behaviour, are unlikely to be amenable to deterrence. Since such individuals would not be seeking to advance a political purpose, they would have no identifying cause and could thus be genuinely anonymous. The same may be true of those who hack solely to bring private information to public attention.[33] It may also be true of those who hack solely for financial enrichment, absent any higher coercive purpose. Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale casualties.[34]\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nSecondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war,[37] so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it.[39] The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.[40]\nThirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to achieve.[42] Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis instability.[43] Among recent Western posture innovations, the Cyber Deterrence Initiative – reflecting Washington's goal of coordinating retaliation against cyber attack among its allies – aims to bolster second-strike credibility and therefore increase stability. But persistent engagement – embodying Washington's stated intention to pre-empt possible hostile cyber action – could cut the other way, incentivising US adversaries to strike first rather than risk waiting to be forcibly disarmed.\nFourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag operations.[44] If Russia decided that its strategic interests would be served by China and the United States' weakening each other militarily, for example, it might conduct a technically anonymous cyber attack on US forces in Asia that seemingly benefitted China – or even one with ostensibly Chinese technical characteristics – leading Washington to believe Beijing was commencing hostilities against its regional interests. This could provoke swift US retaliation and equally swift Chinese escalation\nDavid Blagden\nowing to each side's fear of losing first-move advantages.⁴⁵ Moreover, even without the successful framing of an innocent party as the target for misdirected retaliation, false-flag operations may sow doubt and preclude effective retaliation, undermining the credibility of punishment threats.\nThis problem is context-specific and surmountable, however. Between two parties with a less offence-dominant strategic relationship than the contemporary US-Chinese situation is often taken to be⁴⁶ – and even that is contestable on the cyber front⁴⁷ – a dearth of first-move advantages could allow scope for diplomatic consultation over the origin of the attack.⁴⁸ If the framed aggressor repudiated the coercive goals that appeared to point in its direction, consciously and visibly eschewing the potential benefits of the apparent coercion, it would credibly signal that it was not to blame.⁴⁹ For example, if a party that appeared to benefit from a cyber attack on another state's internet-connected military logistics chain refrained from taking offensive conventional action even while the attack victim's forces were immobilised by the attack's effects, that would be a costly – and thus credible – signal of restraint. The third party attempting such framing would then itself be in a perilous situation: if its own subversive agenda were uncovered, the two parties it had attempted to trick could retaliate in concert.⁵⁰ Thus, third-party framing is not a risk-free option, and the threat could be minimised if potential cyber adversaries pursued deterrent postures that downplayed first-move advantages. Indeed, the major powers have already done so at the top rung of the escalatory ladder by way of establishing survivable nuclear arsenals. Similarly, non-malicious cyber accidents could be falsely construed as attacks.⁵¹ But again, identifying the coercive interests at stake could mitigate the risk of errant retaliation, and the repudiation of the coercive benefits would duly signal blamelessness.\nFinally, recognising that cyber coercion will always seek to advance some set of interests does not mean that discerning such interests will be easy. Coercers, to be sure, will often want to be correctly identified so as to maximise the clarity of intended signals.⁵² But many potential cyber attackers may instead prefer to achieve their strategic goals via covert cyber action to avoid possible retaliatory costs and – as discussed throughout – cyberspace is particularly amenable to such concealment and obscuration.⁵³\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nAccordingly, those seeking to hold the relevant interests at risk to effect deterrence may have to look at the indirect consequences of the initial cyber attack to isolate the set of interests being advanced. Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats credible[54] – removing the necessity of choosing among enemies. Indeed, in retaliating for Stuxnet against Israel (via its Hizbullah and Hamas proxies), the United States (via the 2012 US financial hack) and Saudi Arabia (via the 2012 Saudi Aramco cyber attack), Iran appeared to take this route. Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents.[55] But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are punished.[56] Furthermore, target calculations would also be subject to iterative refinement. For instance, if the potential beneficiaries of the interests ranked as being advanced the most by an attack refused to repudiate the coercive gains, they would effectively certify that those were the interests that should suffer retaliation. By contrast, the repudiation of those gains would signal that a different set of interests than those the attack seemed intended to advance should be held at risk.\n\\* \\* \\*\nDeterring cyber attacks by threatening to impair the interests they are presumed to advance, as opposed to focusing on identifying a sole attacker, is not without peril. It risks retaliating against innocent states or civilians, which incurs ethical costs and potential blowback, while cross-domain escalation may become dangerously unstable, especially if policymakers become inordinately confident in the efficacy of offensive cyber operations. Nevertheless, the anonymity of cyberspace is not the fundamental obstacle to counter-value deterrence it is often supposed to be, for attempting to coerce via cyber means reveals interests that can be held at risk. Accordingly, as the damage potential of cyber weaponry continues to increase, governments\nDavid Blagden\nand the populations they seek to protect may gain security from the threat of retaliatory punishment. For all of its ethical uncertainties, therefore, this form of deterrence remains the final backstop of major powers' strategic postures, and could constitute as potent an instrument against cyber threats as it has against those in the nuclear and conventional domains.\n## Acknowledgements\nThe author thanks Ben Buchanan, Andrew Futter, Erik Gartzke, Jon Lindsay, Kubo Mačák, Patrick Porter, Simon Smith, Peter Watkins and especially Helena Mills for invaluable comments on drafts of this article.",
  "references": [
    "## Notes\n1. On cyber-capability growth, see Dale Peterson, 'Offensive Cyber Weapons: Construction, Development, and Employment', *Journal of Strategic Studies*, vol. 36, no. 1, February 2013, pp. 120–4. For reference, a cyber attack is understood as the intentional use of computer code – a ‘cyber weapon’ – to harm or exert hostile control over another party’s information and communications technology (ICT) systems or networks, along with the physical systems and living beings dependent upon them.\n2. Some have derided discussions of cyber deterrence as misguidedly applying an outdated ‘Cold War paradigm’ to an ill-suited strategic context. See, for example, Daniel Steed, ‘Cyber War, Let’s Get Real(ist)’, *War on the Rocks*, 14 October 2013, https://warontherocks.com/2013/10/cyber-war-lets-get-realist/. There is nothing ‘Cold War’ about deterrence, however, despite the nuclear era bringing the concept new-found prominence. Rather, it is a timeless and necessary attribute of interactions between mutually armed parties under anarchy: see Ben Buchanan, ‘Cyber Deterrence Isn’t MAD; It’s Mosaic’, *Georgetown Journal of International Affairs*, International Engagement on Cyber IV, 2014, p. 131. It is therefore an entirely appropriate concept for the cyber age.\n3. See Richard L. Kugler, ‘Deterrence of Cyber Attacks’, in Franklin D. Kramer, Stuart H. Starr and Larry K. Wentz (eds), *Cyberpower and National Security* (Dulles, VA: Potomac Books, 2009), pp. 309–41; Martin C. Libicki, *Cyberdeterrence and Cyberwar* (Santa Monica, CA: RAND, 2009), p. 44; and Thomas Rid and Ben Buchanan, ‘Attributing Cyber Attacks’, *Journal of Strategic Studies*, vol. 38, nos. 1–2, February 2015, pp. 4–37.\n4. Erica D. Borghard and Shawn M. Lonergan, ‘The Logic of Coercion in Cyberspace’, *Security Studies*, vol. 26, no. 3, May 2017, pp. 452–81.\n5. Key recent works on cyber deterrence/ coercion share this perspective. Jon R.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nLindsay argues that 'cyber operations are unsuited for coercive signaling' in 'Tipping the Scales: The Attribution Problem and the Feasibility of Deterrence against Cyberattack', Journal of Cybersecurity, vol. 1, no. 1, September 2015, p. 54. Borghard and Lonergan similarly contend that 'signaling in cyberspace is the most problematic of all the domains', in 'The Logic of Coercion in Cyberspace', p. 456.\n6 Robert A. Pape, Bombing to Win: Air Power and Coercion in War (Ithaca, NY: Cornell University Press, 1996), p. 4.\n7 As Borghard and Lonergan's own Schelling-derived caveat admits, coercion need not take the form of explicit threat-issuance to nonetheless be operative; the key is simply that it is inferred by targets, based on their assessment of others' capabilities, interests and behaviours. 'The Logic of Coercion in Cyberspace', p. 455, note 11. Indeed, cyber capabilities may yield coercive options well beyond mere signalling and threat-issuance: see David Betz, 'Cyberpower in Strategic Affairs: Neither Unthinkable nor Blessed', Journal of Strategic Studies, vol. 35, no. 3, November 2012, pp. 689-711.\n8 Lindsay, 'Tipping the Scales', p. 59. This is not to deny that states are using cyber exploits against each other all the time, but simply a recognition that no major power has (as of December 2019) suffered a cyber-induced mass-casualty attack. The Pyongyang-backed WannaCry attack in 2017 perhaps has come closest, insofar as it disrupted various national healthcare systems and thereby harmed a large number of patients.\n9 See Christopher H. Achen and Duncan Snidal, 'Rational Deterrence Theory and Comparative Case Studies', World Politics, vol. 41, no. 2, January 1989, pp. 143-69; and Lindsay, 'Tipping the Scales', p. 54. On this relationship between observed events (for instance, deterrence success or failure) and explanatory theory, see David Blagden, 'Induction and Deduction in International Relations: Squaring the Circle between Theory and Evidence', International Studies Review, vol. 18, no. 2, June 2016, pp. 195-213.\n10 See Robert Jervis, The Meaning of the Nuclear Revolution: Statecraft and the Prospect of Armageddon (Ithaca, NY: Cornell University Press, 1989), pp. 8-14; and Pape, Bombing to Win, pp. 13-14.\n11 The risk of global commerce and communications disruption may also deter potential cyber attackers if they fear the self-harm of such disruption. See Joseph S. Nye, Jr., 'Deterrence and Dissuasion in Cyberspace', International Security, vol. 41, no. 3, Winter 2016/17, pp. 44-71. However, this article's focus is attacks that aggressors would have otherwise judged to be advantageous absent their opponent's deterrent strategies, all else being equal, rather than those forgone due to other concerns.\n12 A qualification would arise if cyber attacks became capable of compromising nuclear command and control, thus removing the risk of cross-domain retaliation.\n13 This is a more precise rendering of Herman Kahn's concept of 'escalation dominance'. Such dominance\nDavid Blagden\nmay be unobtainable in a world of multiple nuclear powers, but retaliatory equivalence creates deterrence through the threatened escalation to ever greater yet still not advantageous pain. See Charles L. Glaser, Analyzing Strategic Nuclear Policy (Princeton, NJ: Princeton University Press, 1990), pp. 50, 55–7; and Thomas C. Schelling, Arms and Influence (New Haven, CT: Yale University Press, 2008 [1966]), p. 104.\n14 Schelling, Arms and Influence, p. 47.\n15 US Department of Defense, 'Department of Defense Strategy for Operating in Cyberspace', 2011, https://csrc.nist.gov/CSRC/media/Projects/ISPAB/documents/DOD-Strategy-for-Operating-in-Cyberspace.pdf; HM Government, The UK Cyber Security Strategy: Protecting and Promoting the UK in a Digital World (London: UK Cabinet Office, 2011), https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/60961/uk-cyber-security-strategy-final.pdf.\n16 US Department of Defense, 'The Department of Defense Cyber Strategy', 2015, https://archive.defense.gov/home/features/2015/0415_cyber-strategy/final_2015_dod_cyber_strategy_for_web.pdf, p. 11; HM Government, National Cyber Security Strategy 2016–2021 (London: UK Cabinet Office, 2016), https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/567242/national_cyber_security_strategy_2016.pdf, pp. 41–52.\n17 See David E. Sanger and Elisabeth Bumiller, 'Pentagon to Consider Cyber Attacks Acts of War', New York Times, 31 May 2011, http://www.nytimes.com/2011/06/01/us/politics/01cyber.html?_r=1; Finbarr Bermingham, 'NATO Summit 2014: Cyber-attack Could Trigger Retaliation from all NATO Members', International Business Times, 5 September 2014, http://www.ibtimes.co.uk/nato-summit-2014-cyber-attack-could-trigger-retaliation-all-nato-members-1464230; and Anna Mikhailova, 'UK Could Retaliate Against Cyber Attacks with Missiles, Attorney General Says', Daily Telegraph, 23 May 2018, https://www.telegraph.co.uk/politics/2018/05/23/uk-has-legal-right-retaliate-against-cyber-attacks-missiles/. The US government's invocation of cyber theft as a motive for its trade sanctions on China is consistent with this pattern. See 'A Quick Guide to the US–China Trade War', BBC, 16 December 2019, https://www.bbc.co.uk/news/business-45899310.\n18 White House, 'National Cyber Strategy of the United States of America', 2018, https://www.whitehouse.gov/wp-content/uploads/2018/09/National-Cyber-Strategy.pdf. See also Theresa Hitchens, 'US Urges \"Likeminded\" Countries to Collaborate on Cyber Deterrence', Breaking Defense, 24 April 2019, https://breakingdefense.com/2019/04/us-urging-likeminded-countries-to-collaborate-on-cyber-deterrence/; and Greg Myre, \"Persistent Engagement\": The Phrase Driving a More Assertive US Spy Agency', NPR, 26 August 2019, https://www.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nnpr.org/2019/08/26/747248636/persistent-engagement-the-phrase-driving-a-more-assertive-u-s-spy-agency?t=1577803786687.\n19 Brandon Valeriano and Benjamin Jensen, *The Myth of the Cyber Offense: The Case for Restraint* (Washington DC: Cato Institute, 2019), https://www.cato.org/sites/cato.org/files/pubs/pdf/pa862.pdf.\n20 Paul Cornish et al., *On Cyber Warfare* (London: Chatham House, 2010), pp. 42–5. See also Daryl G. Press, *Calculating Credibility: How Leaders Assess Military Threats* (Ithaca, NY: Cornell University Press, 2005), pp. 2–3.\n21 Nye, ‘Deterrence and Dissuasion in Cyberspace’, pp. 49–52.\n22 Cornish et al., *On Cyber Warfare*, p. 13; Libicki, *Cyberdeterrence and Cyberwarfare*, pp. 41–52.\n23 Evidence suggests that the Russian and Chinese governments, among others, see the use of arms-length ‘non-state’ cyber proxies as deniable tools of coercive statecraft. See Alexander Klimberg, ‘Mobilising Cyber Power’, *Survival*, vol. 53, no. 1, February–March 2011, pp. 41–60.\n24 Daniel Moore and Thomas Rid, ‘Cryptopolitik and the Darknet’, *Survival*, vol. 58, no. 1, February–March 2016, pp. 7–38.\n25 Certainly, progress is being made on this, particularly in identifying technical ‘fingerprints’ of major states’ cyber attacks. See Stewart Baker, ‘The Attribution Revolution’, *Foreign Policy*, 17 June 2013, https://foreignpolicy.com/2013/06/17/the-attribution-revolution/; and Brian M. Mazanec and Bradley A. Thayer,\nDeterring Cyber Warfare: Bolstering Strategic Stability in Cyberspace (New York: Palgrave, 2015), pp. 57–63. Nevertheless, this is unlikely to become perfect, particularly as attackers adapt to defenders’ progress, and given the potential for false-flag attacks as discussed below. All other fields of military–technological development have witnessed iterative back-and-forth dynamics between offensive penetration and defensive shielding, so recent innovations in cyber fingerprinting will be countered by anonymisation innovations.\n26 Rid and Buchanan, ‘Attributing Cyber Attacks’, pp. 30–1.\n27 Borghard and Lonergan, ‘The Logic of Coercion in Cyberspace’, p. 459; Libicki, *Cyberdeterrence and Cyberwar*, p. 128.\n28 Glenn H. Snyder, *Deterrence and Defense: Toward a Theory of National Security* (Princeton, NJ: Princeton University Press, 2015), pp. 14–16.\n29 Pape, *Bombing to Win*, p. 12. Compellence is sometimes treated separately from coercion, but since it essentially represents ‘total’ coercion, here it is cast as coercive. *Ibid.*, p. 4. See also Schelling, *Arms and Influence*, pp. 69–91.\n30 Kugler, ‘Deterrence of Cyberattacks’, pp. 309–10.\n31 Erik Gartzke, ‘The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth’, *International Security*, vol. 38, no. 2, Fall 2013, pp. 41–73.\n32 Holding interests at risk without specifically identified attribution goes beyond valuable recent work on interests as a route to attribution. See, for instance, Rid and Buchanan,\nDavid Blagden\n'Attributing Cyber Attacks', p. 8.\n33 Both 'recreational' and 'hacktivist' attackers do have interests that can be jeopardised, of course, but doing so via punishment is challenging. The former values the opportunity to commit a successful attack for the mere thrill of it, making punishment and denial one and the same. The latter values something that the wider population may value too – transparency in public life – so punishing their interests could also penalise people that the state is charged with protecting.\n34 Certain capability gaps between individual hackers and state-level cyber forces have closed over time. An example is the reduced need for state-level supercomputers to break encryption due to bot technology. See Libicki, *Cyberdeterrence and Cyberwar*, pp. 47-8. Even so, as those with the greatest resources (powerful states and corporations foremost among them) push out the frontier of technological sophistication, the chances of sparsely resourced individuals or groups – however talented – keeping pace becomes small. Such state-versus-individual capability disparities are thus likely to persist, even if gifted hackers close gaps in certain areas. Stuxnet, in particular, shows the extraordinary resources required – including a replica of the entire targeted infrastructure and an expert human-intelligence operation to penetrate air-gapped systems – to propagate an attack of even modest state-level strategic significance. See Jon R. Lindsay, ‘Stuxnet and the Limits of Cyber Warfare’, *Security Studies*, vol. 22, no. 3, July 2013, pp. 365-404.\n35 Sarah Kreps and Jacquelyn Schneider, 'Escalation Firebreaks in the Cyber, Conventional, and Nuclear Domains: Moving Beyond Effects-based Logics', *Journal of Cybersecurity*, vol. 5, no. 1, September 2019, pp. 1-11. Libicki sees the risk of third-party censure and opprobrium as a fundamental challenge to the credibility of deterrence by retaliation in response to cyber attack as being greater than it has been for the deterrence of nuclear attack, particularly on the grounds that numerous capable third parties may join the fight. Libicki, *Cyberdeterrence and Cyberwar*, p. 42. See also Lindsay, 'Tipping the Scales', p. 57. Yet while facing normative opprobrium may indeed affect a state's retaliatory resolve, there is no clear reason third parties would join hostilities against a retaliating state – opening themselves to re-retaliation in the process – simply to censure it for retaliating. A related argument, albeit with different causal underpinnings, is that an attack's victim may be self-deterred from certain retaliatory cyber options through fear that they would result in fratricide of their own ICT systems. *Ibid.*, p. 57. This is a relevant concern, but one contingent on the cyber weapon in question – and on aspiring deterrers' weighting of absolute versus relative gains and losses – rather than a fundamental barrier to retaliation per se.\n36 Kenneth Geers, 'The Challenge of Cyber Attack Deterrence', *Computer Law and Security Review*, vol. 26, no. 3, May 2010, pp. 300-1.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\n37 Erik Gartzke and Jon R. Lindsay, 'Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace', *Security Studies*, vol. 24, no. 2, June 2015, pp. 316–48.\n38 Lawrence J. Cavaiola, David C. Gompert and Martin Libicki, 'Cyber House Rules: On War, Retaliation and Escalation', *Survival*, vol. 57, no. 1, February–March 2015, pp. 81–104.\n39 See Lindsay, 'Tipping the Scales', pp. 58–64. This trade-off exists throughout deterrent posture – 'asymmetric escalation' doctrines deliver much deterrence but with escalatory dangers, for example, while 'assured retaliation' doctrines offer less deterrence of low-level irritations but also fewer escalatory risks. See Vipin Narang, *Nuclear Strategy in the Modern Era: Regional Powers and International Conflict* (Princeton, NJ: Princeton University Press, 2014), pp. 17–20.\n40 Threatening success-prevention may be inherently more credible than threatening punishment, since the former promises minimised costs on both sides. Snyder, *Deterrence and Defense*, p. 16. Deterrence by punishment also cedes control of the decision over how much pain to bear to one’s opponent, and may therefore also be less precise and reliable when dealing with aggressors of uncertain cost-tolerance and risk-acceptance. Lawrence Freedman, *Deterrence* (Cambridge: Polity, 2004), p. 39.\n41 James J. Wirtz, 'The Cyber Pearl Harbor', *Intelligence and National Security*, vol. 32, no. 6, September 2017, pp. 758–67. Of course, this is not to suggest that pulling off such a successful attack – or achieving the strategic shock/paralysis that it might induce – would be easy or even feasible, but it could be an attractive prospect for an aspiring aggressor. James J. Wirtz, 'The Cyber Pearl Harbor Redux: Helpful Analogy or Cyber Hype?', *Intelligence and National Security*, vol. 33, no. 5, April 2018, pp. 771–3.\n42 A common characteristic of cyber attack is uncertainty even on the attacker’s part over precisely what effects their action will produce. See Borghard and Lonergan, 'The Logic of Coercion in Cyberspace', p. 456.\n43 See Ben Buchanan, *The Cybersecurity Dilemma: Hacking, Trust, and Fear Between Nations* (Oxford: Oxford University Press, 2017); and Herbert Lin, 'Escalation Dynamics and Conflict Termination in Cyberspace', *Strategic Studies Quarterly* (Cyber Special Edition), vol. 6, no. 3, Fall 2012, p. 46–70. For theoretical background, see Carl von Clausewitz, *On War*, trans. Michael Howard and Peter Paret (Princeton, NJ: Princeton University Press, 1976 [1832]), pp. 75–89; Barry R. Posen, *Inadvertent Escalation: Conventional War and Nuclear Risks* (Ithaca, NY: Cornell University Press, 1991), pp. 2–3.\n44 Libicki, *Cyberdeterrence and Cyberwar*, p. 44.\n45 David C. Gompert and Martin Libicki, 'Cyber Warfare and Sino-American Crisis Instability', *Survival*, vol. 56, no. 4, August–September 2014, pp. 8–10; Joshua Rovner, 'Two Kinds of Catastrophe: Nuclear Escalation and Protracted War in Asia', *Journal of Strategic Studies*, vol. 40, no. 5, July 2017, pp. 699–706.\n46 Avery Goldstein, 'First Things\nDavid Blagden\nFirst: The Pressing Danger of Crisis Instability in US–China Relations', International Security, vol. 37, no. 4, Spring 2013, pp. 49–89.\n47 See Rebecca Slayton, ‘What Is the Cyber Offense–Defense Balance? Conceptions, Causes, and Assessment’, International Security, vol. 41, no. 3, Winter 2016/17, pp. 72–109; and Valeriano and Jensen, The Myth of the Cyber Offense.\n48 Furthermore, while cyber dynamics may contribute to worrisome offence dominance in the larger US–China relationship, Western fears of relative cyber weakness vis-à-vis China may also be overblown. See Jon R. Lindsay, ‘The Impact of China on Cybersecurity: Friction and Fiction’, International Security, vol. 39, no. 3, Winter 2014/15, pp. 7–47; and Rovner, ‘Two Kinds of Catastrophe’, p. 712.\n49 See Charles L. Glaser, Rational Theory of International Politics: The Logic of Competition and Cooperation (Princeton, NJ: Princeton University Press, 2010), pp. 64–6; and Andrew Kydd, ‘Trust, Reassurance, and Cooperation’, International Organization, vol. 54, no. 2, Spring 2000, pp. 325–57.\n50 One attempt at cataloguing such attacks alleges 53 such admitted attacks since the 1930s, with state use of sponsored false-flag terrorist attacks as a pretext for preferred state policy emerging as a favourite. ‘53 Admitted False Flag Attacks’, WashingtonsBlog, 23 February 2015, https://www.globalresearch.ca/53-admitted-false-flag-attacks/5432931.\n51 See Lucas Kello, ‘The Meaning of the Cyber Revolution: Perils to Theory and Statecraft’, International Security, vol. 38, no. 2, Fall 2013, p. 31. Such accidents become increasingly likely as system complexity increases.\n52 Borghard and Lonergan, ‘The Logic of Coercion in Cyberspace’, p. 459.\n53 See David F. Rudgers, ‘The Origins of Covert Action’, Journal of Contemporary History, vol. 35, no. 2, April 2000, pp. 249–62.\n54 Lindsay, ‘Tipping the Scales’, p. 63.\n55 Ibid., p. 57.\n56 In the absence of precise identification of specific insurgent or terrorist attackers, counter-insurgent or counter-terrorist forces may resort to punishing the attackers’ manifested interests – say, razing an insurgent-hosting village or somehow retarding terrorists’ political cause. See Gil Merom, ‘Strong Powers in Small Wars: The Unnoticed Foundations of Success’, Small Wars and Insurgencies, vol. 9, no. 2, September 1998, pp. 38–63; and Robert F. Trager and Dessislava P. Zagorcheva, ‘Deterring Terrorism: It Can Be Done’, International Security, vol. 30, no. 3, Winter 2005/06, pp. 87–123. On drawing parallels between cyber attack and insurgency, see Lindsay, ‘Tipping the Scales’, p. 57. This approach can involve heavy moral costs and blowback, but the point is that there is a rationale motivating the incurrence of such costs."
  ],
  "flat_text": "Survival Global Politics and Strategy Survival Global Politics and Strategy Taylor &amp; Francis Taylor &amp; Francis Group ISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden To cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072 To link to this article: https://doi.org/10.1080/00396338.2020.1715072 Published online: 04 Feb 2020.\nSubmit your article to this journal Article views: 1757 View related articles View Crossmark data Citing articles: 5 View citing articles Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden The potential damage from possible cyber attacks is rising as the sophistication of cyber weapons increases.¹ Accordingly, the question of whether such attacks can be deterred is an increasingly salient one for governments, national-security agencies and the populations they seek to protect.² One characteristic of cyber attack, its potential for anonymity, is often taken as an insurmountable barrier to effective deterrence based on retaliatory punishment. But such assumptions are misguided. Coercion is the form of hostile political influence that deterrence seeks to oppose, and in order to coerce, a belligerent must necessarily identify that which it values. Attempted coercion thereby serves as a preference-revelation mechanism. Even if a belligerent can escape identifying itself via anonymous cyber attack, it cannot escape identifying interests that it holds dear, which can then be held at risk by those seeking deterrence.\nThe political interests being advanced by a cyber attack will often make the identity of the aggressor clear, of course, even if the origin of the attack itself cannot be readily traced via technical means.³ While a cyber attack may be technically anonymous, the strategic interaction of which it is a part can make clear whose interests are at stake. Yet many actors could have similar interests, meaning that the specific aggressor might remain unidentified.\nDavid Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute.\nSurvival | vol. 62 no. 1 | February–March 2020 | pp. 131–148 DOI 10.1080/00396338.2020.1715072 David Blagden Such reservations over strategic attribution are overblown, however. This is because they conflate two different variables within the deterrence calculus: aggressor identity and aggressor interests. These variables do often correlate: if you want to retaliate against an attacker's territory, for instance, you need to know whose territory. Yet it is possible to identify valued interests of an attacker without identifying those interests' sole holder. And crucially, coercion is not possible without identifying the interests being advanced, in cyberspace or anywhere else, since the very nature of coercion requires revelation of desired changes in behaviour.⁴ Russia, for example, would not need to identify which specific NATO country cyber-attacked it to still identify – and hold at risk – interests shared by all NATO members. It is therefore possible to retaliate against revealed preferences – to achieve successful strategic attribution of interests – even when strategic attribution of a specific attacker identity remains challenging. Many actors may hold similar interests while only one of them may be responsible for a particular cyber attack, but that need not matter: the very factor that obscures their specific identities (their shared interests) also means that retaliating against those interests will punish the underlying aggressor. The fact that the specific attacker may have ‘gotten away with it’ in terms of not being identified individually will be little consolation when its interests have nonetheless been impaired. And knowing as much beforehand, it is possible for deterrence to hold based on the threat of subsequent retaliatory punishment.\nWhat is the value of such analysis? After all, cyber weapons are ill-suited tools for explicit coercive signalling, since their capability is often unclear prior to their use, and degraded by their revelation insofar as defenders can patch exposed vulnerabilities.⁵ And many categories of hostile cyber action – attrition of an opponent's capabilities, hacking for enjoyment or publicity, covert cyber espionage, cyber-enabled theft, subversion and disinformation, and so forth – are pressing security concerns but do not achieve their effects via the issuance of coercive threats. Also, cyber deterrence has hardly been an unambiguous success thus far; there have been plenty of cyber attacks against states with retaliatory means at their disposal, despite successful culprit attribution and superior relative power. Examples include the 2012 attacks on the US financial system and Saudi Aramco, the 2013 attack on the Sands Casino and the 2014 attack on Sony Pictures. On top of all this, one could question the value of more deterrence theory while empirical scholarship on cyber aggression remains relatively sparse.\nNone of these rejoinders hold water, however. By themselves, cyber threats are indeed flawed tools of coercive signalling. But taken in strategic context, a wide range of hostile cyber actions meet a reasonable definition of coercion: cost imposition in pursuit of behavioural change. If an attacker seeks to coercively exploit a favourably changed balance of power following successful attrition or extortion, if a protester draws attention to a cause in a way that generates coercive political costs, or if cyber espionage delivers information that is utilised coercively in another domain, coercive interests are being advanced. Meanwhile, observed cyber attacks -- those that, for whatever reason, have not been deterred -- are not evidence of the futility of the deterrent enterprise, since defenders' resolve to impose punishment rises with the severity of the attack suffered while the pool of capable‐enough potential culprits shrinks. For example, North Korea going undeterred in its 2014 Sony hack -- a rudimentary and low‐damage attack -- does not mean that deterrence has failed with respect to great‐power use of more capable cyber weaponry against other major states. Lastly, owing to unavoidable selection bias, the empirical study of non‐occurrences will underplay deterrence's causal significance; cyber‐deterrence theory can help offset this imbalance.\n### Escalation dominance and the ‘return address' problem Deterrence is achieved when an actor -- a state, an armed group or an individual -- concludes that the likely costs of an attack exceed the likely benefits. Opponents can be deterred in two ways. Deterrence by denial occurs when a potential aggressor concludes that attack will be ineffective because of the strength of the countermeasures in place: it is denied the opportunity of achieving its coercive objectives. Deterrence by punishment, in contrast, does not promise to diminish an attack's effectiveness, but rests on the threat of retaliation of sufficient magnitude that the aggressor will be worse off than if it had not attacked in the first place: it will be punished after the fact. Deterring or thwarting cyber attack via effective David Blagden denial measures, such as information and communications technology (ICT) hardening and resilience, is of course an important component of effective cyber deterrence. But the focus here is deterrence of those threats that cannot be reliably denied.\nThere is no reason in principle that the use of any new weapon cannot be deterred via the threat of retaliation using the same or alternative weapons systems. To be insusceptible to such 'cross-domain' deterrence – deterrence reliant on the threat of costs imposed in an operational domain other than that in which the original attack occurred – a new weapon would have to possess destructive capability that no other existing weapon could match and be available exclusively to one party. Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited costs.[12] Although nuclear retaliation against irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence' logic.[13] A similar logic underpinned Cold War 'tripwire' military deployments. US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces attacked.[14] The prominence of deterrence by punishment in Western cyber strategy has grown in line with capabilities and understanding. The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and resilience.[15] Following Edward Snowden's revelations of Anglo-American capabilities, however, both countries have become less reluctant to discuss their full range of options. The 2015 US cyber-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of deterrence.[16] The Western allies have also made it increasingly explicit that cross-domain retaliation is a component of their thinking. Most recently, US posture innovations stemming from the 2018 National Cyber Strategy -- the ‘Cyber Deterrence Initiative' (which aims to bolster retaliatory deterrence through collective alliance responses) and the ‘persistent engagement' doctrine (which contemplates a continuous cycle of tracking and offensive action against emerging cyber threats) -- display yet more emphasis on punishment. There are important questions, discussed later, about whether rising faith in the efficacy of offensive operations -- especially of the pre-emptive variety -- as a response to threatened aggression could itself become an escalatory risk. Yet the fact remains that threatened escalation is already an important component of major powers' responses to emerging cyber threats, and unlikely to be retracted.\nFor effective deterrence via the threat of punishment, however, a potential attacker needs to know there is a significant chance of actually being punished. Assessments of this likelihood focus on the defender's capability and resolve: does the victim of an attack have the incentives, determination and wherewithal to retaliate by imposing a sufficient level of costs? Embedded in the capability half of the equation is a crucial subsidiary question: can the aspiring deterrer target its retaliation in the first place? Absent a ‘return address', no amount of retaliatory firepower will deter if attackers can be confident it will never be directed against anything they value.\nThis is where cyber attack poses a challenge for deterrence. Sophisticated cyber attacks may prove untraceable, even by the most advanced cybersecurity agencies. Masking internet protocol addresses, routing attacks via numerous connected computers (‘bots') that have wittingly or otherwise been turned into a cross-border network, initiating an attack from a cybercafe or public library, hacking and utilising some unsuspecting individual's internet-connected mobile phone, and so forth, may facilitate apparently unattributable cyber attacks. Furthermore, even if the computer used to initiate an attack can be identified, it is a greater challenge to prove who was sitting at it, or on whose orders they acted. The ongoing state-versus David Blagden private arms race in encryption technology only intensifies the problem.²⁴ While progress is being made in cyber forensics, technological innovation nevertheless appears unlikely to render all cyber attacks traceable in the near future.²⁵ Crucially, however, cyber attacks are not actually as anonymous as their technical characteristics might imply, and so do not enjoy the immunity from targeted retaliation that is often feared.\n## The coercive revelation of preferences Key research in cyber deterrence and coercion is united around the pivotal importance of attribution. For Thomas Rid and Ben Buchanan, ‘attribution is fundamental: almost any response to a specific offence – law enforcement, diplomatic, or military – requires identifying the offender first’.²⁶ Erica Borghard and Shawn Lonergan similarly contend that ‘coercion in cyberspace requires attribution to be effective’, while Martin Libicki reasons that coercion must be visibly associated with the coercer to operate, the logic being that the coercer must identify themselves if they are to cause the behavioural change they desire.²⁷ These assessments are aligned with seminal early analyses of the role of punishment in deterrence, which treated the existence of an identified enemy against which retaliation could be directed as a baseline assumption.²⁸ Such orthodoxies, however, obscure a vital distinction in the logic of punishment, with substantial implications for the cyber-deterrence debate. Retaliatory punishment is about imposing costs on political, economic and social interests – populations, cities, forces, wealth, status and anything else from which the attacker derives utility. The specific identity of the attacker is not an interest, and has no necessary political content. Of course, many important interests are exclusively associated with a particular identity, usually a state holding territory. Accordingly, deterrence by threatening some package of political, economic and social assets that are located in a particular territory requires the identification of the custodian of that territory. For this reason, the conflation of interests and identities was largely unproblematic in Cold War deterrence: for practical purposes, the interests that each aspiring deterrer sought to hold at risk were synonymous and coextensive with an exclusive identified adversary.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution While many interests are indeed unique to a specific holder, many others are not. Notwithstanding the Cold War experience, deterrence based on the threat of retaliatory punishment does not inherently require attribution of the attacker's identity, provided relevant interests can be ascertained. A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic preferences.[29] To advance a set of political interests via coercion, a coercer at least implicitly identifies those interests by specifying what behavioural change it wants to encourage. Attempted coercion therefore serves as a mechanism of preference revelation.\nSuch preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical means.[30] If the interests that the cyber coercion seeks to advance align solely with the unique identifiable interests of a particular state or group, then that actor will have identified itself. Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber attack[31] – this too may reveal the attacker's identity. Yet even where a specific attacker is not identifiable via these revealed preferences, preference revelation remains useful for deterrence: if there are a dozen possible culprits behind a given cyber attack, the very thing that makes them hard to distinguish – their similar interests – also unifies them. Thus, while the precise identity of the attacker may indeed remain unclear, this still does not preclude an effective counter-value deterrent posture. The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of retaliation.[32] The most high-profile cyber attack to date represents a key example of interest attribution in the absence of specific attacker identification. Iran did not need state-of-the-art cyber forensics to have a good idea that the Stuxnet attack on its nuclear facilities uncovered in 2010 was launched by Israel, the United States or one of those two states' allies. While more than one technically capable actor had an interest in retarding Iran's nuclear programme, David Blagden making it impossible to identify the specific attacker based on desired behavioural change alone, there were interests common to all possible attackers – the security of the United States' Middle Eastern allies – that Iran could have held at risk to achieve deterrence. Stuxnet was not an attack of explicit coercive signalling, of course; it was covert attrition, intended to degrade a capability. Nevertheless, that attrition was then exploited coercively in non-cyber domains and, once discovered – as it was always likely to be – the interests of its perpetrators were not hard to discern even if specific attacker identity remained opaque. The principal barrier to Iran's achieving deterrence was not the anonymity of the cyber attack, but its military inferiority and associated paucity of sufficiently credible retaliatory options. Cyber attacks on Estonia (2007), Georgia (2008), Finland (2013) and Ukraine (2014) – strategically attributable to Russia, even if technical attribution remained challenging – reflected the failure of deterrence for similar reasons. Beyond such observed incidents, however, the cyber attacks contemplated but not conducted due to the likely costs of potential retaliation would be the most probative indicators of effective deterrence of cyber attacks via the threat of retaliation. Yet such cases remain by definition largely unobservable.\n## Caveats and qualifications On balance, there are grounds for optimism about prospects for deterring cyber attacks via both cyber and non-cyber retaliatory means, at least by countries powerful enough to threaten meaningful costs. Five broad caveats, however, counsel against wholesale reliance on counter-value deterrence.\nFirstly, cyber attacks conducted by individuals solely to disrupt, without intending to change behaviour, are unlikely to be amenable to deterrence. Since such individuals would not be seeking to advance a political purpose, they would have no identifying cause and could thus be genuinely anonymous. The same may be true of those who hack solely to bring private information to public attention.[33] It may also be true of those who hack solely for financial enrichment, absent any higher coercive purpose. Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale casualties.[34] Deterring Cyber Coercion: The Exaggerated Problem of Attribution Secondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war,[37] so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it.[39] The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.[40] Thirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to achieve.[42] Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis instability.[43] Among recent Western posture innovations, the Cyber Deterrence Initiative – reflecting Washington's goal of coordinating retaliation against cyber attack among its allies – aims to bolster second-strike credibility and therefore increase stability. But persistent engagement – embodying Washington's stated intention to pre-empt possible hostile cyber action – could cut the other way, incentivising US adversaries to strike first rather than risk waiting to be forcibly disarmed.\nFourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag operations.[44] If Russia decided that its strategic interests would be served by China and the United States' weakening each other militarily, for example, it might conduct a technically anonymous cyber attack on US forces in Asia that seemingly benefitted China – or even one with ostensibly Chinese technical characteristics – leading Washington to believe Beijing was commencing hostilities against its regional interests. This could provoke swift US retaliation and equally swift Chinese escalation David Blagden owing to each side's fear of losing first-move advantages.⁴⁵ Moreover, even without the successful framing of an innocent party as the target for misdirected retaliation, false-flag operations may sow doubt and preclude effective retaliation, undermining the credibility of punishment threats.\nThis problem is context-specific and surmountable, however. Between two parties with a less offence-dominant strategic relationship than the contemporary US-Chinese situation is often taken to be⁴⁶ – and even that is contestable on the cyber front⁴⁷ – a dearth of first-move advantages could allow scope for diplomatic consultation over the origin of the attack.⁴⁸ If the framed aggressor repudiated the coercive goals that appeared to point in its direction, consciously and visibly eschewing the potential benefits of the apparent coercion, it would credibly signal that it was not to blame.⁴⁹ For example, if a party that appeared to benefit from a cyber attack on another state's internet-connected military logistics chain refrained from taking offensive conventional action even while the attack victim's forces were immobilised by the attack's effects, that would be a costly – and thus credible – signal of restraint. The third party attempting such framing would then itself be in a perilous situation: if its own subversive agenda were uncovered, the two parties it had attempted to trick could retaliate in concert.⁵⁰ Thus, third-party framing is not a risk-free option, and the threat could be minimised if potential cyber adversaries pursued deterrent postures that downplayed first-move advantages. Indeed, the major powers have already done so at the top rung of the escalatory ladder by way of establishing survivable nuclear arsenals. Similarly, non-malicious cyber accidents could be falsely construed as attacks.⁵¹ But again, identifying the coercive interests at stake could mitigate the risk of errant retaliation, and the repudiation of the coercive benefits would duly signal blamelessness.\nFinally, recognising that cyber coercion will always seek to advance some set of interests does not mean that discerning such interests will be easy. Coercers, to be sure, will often want to be correctly identified so as to maximise the clarity of intended signals.⁵² But many potential cyber attackers may instead prefer to achieve their strategic goals via covert cyber action to avoid possible retaliatory costs and – as discussed throughout – cyberspace is particularly amenable to such concealment and obscuration.⁵³ Deterring Cyber Coercion: The Exaggerated Problem of Attribution Accordingly, those seeking to hold the relevant interests at risk to effect deterrence may have to look at the indirect consequences of the initial cyber attack to isolate the set of interests being advanced. Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats credible[54] – removing the necessity of choosing among enemies. Indeed, in retaliating for Stuxnet against Israel (via its Hizbullah and Hamas proxies), the United States (via the 2012 US financial hack) and Saudi Arabia (via the 2012 Saudi Aramco cyber attack), Iran appeared to take this route. Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents.[55] But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are punished.[56] Furthermore, target calculations would also be subject to iterative refinement. For instance, if the potential beneficiaries of the interests ranked as being advanced the most by an attack refused to repudiate the coercive gains, they would effectively certify that those were the interests that should suffer retaliation. By contrast, the repudiation of those gains would signal that a different set of interests than those the attack seemed intended to advance should be held at risk.\n\\* \\* \\* Deterring cyber attacks by threatening to impair the interests they are presumed to advance, as opposed to focusing on identifying a sole attacker, is not without peril. It risks retaliating against innocent states or civilians, which incurs ethical costs and potential blowback, while cross-domain escalation may become dangerously unstable, especially if policymakers become inordinately confident in the efficacy of offensive cyber operations. Nevertheless, the anonymity of cyberspace is not the fundamental obstacle to counter-value deterrence it is often supposed to be, for attempting to coerce via cyber means reveals interests that can be held at risk. Accordingly, as the damage potential of cyber weaponry continues to increase, governments David Blagden and the populations they seek to protect may gain security from the threat of retaliatory punishment. For all of its ethical uncertainties, therefore, this form of deterrence remains the final backstop of major powers' strategic postures, and could constitute as potent an instrument against cyber threats as it has against those in the nuclear and conventional domains.\n## Acknowledgements The author thanks Ben Buchanan, Andrew Futter, Erik Gartzke, Jon Lindsay, Kubo Mačák, Patrick Porter, Simon Smith, Peter Watkins and especially Helena Mills for invaluable comments on drafts of this article.",
  "citations": {
    "style": "hybrid",
    "flat_text": "Survival Global Politics and Strategy Survival Global Politics and Strategy Taylor &amp; Francis Taylor &amp; Francis Group ISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden To cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072 To link to this article: https://doi.org/10.1080/00396338.2020.1715072 Published online: 04 Feb 2020.\nSubmit your article to this journal Article views: 1757 View related articles View Crossmark data Citing articles: 5 View citing articles Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden The potential damage from possible cyber attacks is rising as the sophistication of cyber weapons increases.¹ Accordingly, the question of whether such attacks can be deterred is an increasingly salient one for governments, national-security agencies and the populations they seek to protect.² One characteristic of cyber attack, its potential for anonymity, is often taken as an insurmountable barrier to effective deterrence based on retaliatory punishment. But such assumptions are misguided. Coercion is the form of hostile political influence that deterrence seeks to oppose, and in order to coerce, a belligerent must necessarily identify that which it values. Attempted coercion thereby serves as a preference-revelation mechanism. Even if a belligerent can escape identifying itself via anonymous cyber attack, it cannot escape identifying interests that it holds dear, which can then be held at risk by those seeking deterrence.\nThe political interests being advanced by a cyber attack will often make the identity of the aggressor clear, of course, even if the origin of the attack itself cannot be readily traced via technical means.³ While a cyber attack may be technically anonymous, the strategic interaction of which it is a part can make clear whose interests are at stake. Yet many actors could have similar interests, meaning that the specific aggressor might remain unidentified.\nDavid Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute.\nSurvival | vol. 62 no. 1 | February–March 2020 | pp. 131–148 DOI 10.1080/00396338.2020.1715072 David Blagden Such reservations over strategic attribution are overblown, however. This is because they conflate two different variables within the deterrence calculus: aggressor identity and aggressor interests. These variables do often correlate: if you want to retaliate against an attacker's territory, for instance, you need to know whose territory. Yet it is possible to identify valued interests of an attacker without identifying those interests' sole holder. And crucially, coercion is not possible without identifying the interests being advanced, in cyberspace or anywhere else, since the very nature of coercion requires revelation of desired changes in behaviour.⁴ Russia, for example, would not need to identify which specific NATO country cyber-attacked it to still identify – and hold at risk – interests shared by all NATO members. It is therefore possible to retaliate against revealed preferences – to achieve successful strategic attribution of interests – even when strategic attribution of a specific attacker identity remains challenging. Many actors may hold similar interests while only one of them may be responsible for a particular cyber attack, but that need not matter: the very factor that obscures their specific identities (their shared interests) also means that retaliating against those interests will punish the underlying aggressor. The fact that the specific attacker may have ‘gotten away with it’ in terms of not being identified individually will be little consolation when its interests have nonetheless been impaired. And knowing as much beforehand, it is possible for deterrence to hold based on the threat of subsequent retaliatory punishment.\nWhat is the value of such analysis? After all, cyber weapons are ill-suited tools for explicit coercive signalling, since their capability is often unclear prior to their use, and degraded by their revelation insofar as defenders can patch exposed vulnerabilities.⁵ And many categories of hostile cyber action – attrition of an opponent's capabilities, hacking for enjoyment or publicity, covert cyber espionage, cyber-enabled theft, subversion and disinformation, and so forth – are pressing security concerns but do not achieve their effects via the issuance of coercive threats. Also, cyber deterrence has hardly been an unambiguous success thus far; there have been plenty of cyber attacks against states with retaliatory means at their disposal, despite successful culprit attribution and superior relative power. Examples include the 2012 attacks on the US financial system and Saudi Aramco, the 2013 attack on the Sands Casino and the 2014 attack on Sony Pictures. On top of all this, one could question the value of more deterrence theory while empirical scholarship on cyber aggression remains relatively sparse.\nNone of these rejoinders hold water, however. By themselves, cyber threats are indeed flawed tools of coercive signalling. But taken in strategic context, a wide range of hostile cyber actions meet a reasonable definition of coercion: cost imposition in pursuit of behavioural change. If an attacker seeks to coercively exploit a favourably changed balance of power following successful attrition or extortion, if a protester draws attention to a cause in a way that generates coercive political costs, or if cyber espionage delivers information that is utilised coercively in another domain, coercive interests are being advanced. Meanwhile, observed cyber attacks -- those that, for whatever reason, have not been deterred -- are not evidence of the futility of the deterrent enterprise, since defenders' resolve to impose punishment rises with the severity of the attack suffered while the pool of capable‐enough potential culprits shrinks. For example, North Korea going undeterred in its 2014 Sony hack -- a rudimentary and low‐damage attack -- does not mean that deterrence has failed with respect to great‐power use of more capable cyber weaponry against other major states. Lastly, owing to unavoidable selection bias, the empirical study of non‐occurrences will underplay deterrence's causal significance; cyber‐deterrence theory can help offset this imbalance.\n### Escalation dominance and the ‘return address' problem Deterrence is achieved when an actor -- a state, an armed group or an individual -- concludes that the likely costs of an attack exceed the likely benefits. Opponents can be deterred in two ways. Deterrence by denial occurs when a potential aggressor concludes that attack will be ineffective because of the strength of the countermeasures in place: it is denied the opportunity of achieving its coercive objectives. Deterrence by punishment, in contrast, does not promise to diminish an attack's effectiveness, but rests on the threat of retaliation of sufficient magnitude that the aggressor will be worse off than if it had not attacked in the first place: it will be punished after the fact. Deterring or thwarting cyber attack via effective David Blagden denial measures, such as information and communications technology (ICT) hardening and resilience, is of course an important component of effective cyber deterrence. But the focus here is deterrence of those threats that cannot be reliably denied.\nThere is no reason in principle that the use of any new weapon cannot be deterred via the threat of retaliation using the same or alternative weapons systems. To be insusceptible to such 'cross-domain' deterrence – deterrence reliant on the threat of costs imposed in an operational domain other than that in which the original attack occurred – a new weapon would have to possess destructive capability that no other existing weapon could match and be available exclusively to one party. Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited costs.[12] Although nuclear retaliation against irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence' logic.[13] A similar logic underpinned Cold War 'tripwire' military deployments. US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces attacked.[14] The prominence of deterrence by punishment in Western cyber strategy has grown in line with capabilities and understanding. The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and resilience.[15] Following Edward Snowden's revelations of Anglo-American capabilities, however, both countries have become less reluctant to discuss their full range of options. The 2015 US cyber-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of deterrence.[16] The Western allies have also made it increasingly explicit that cross-domain retaliation is a component of their thinking. Most recently, US posture innovations stemming from the 2018 National Cyber Strategy -- the ‘Cyber Deterrence Initiative' (which aims to bolster retaliatory deterrence through collective alliance responses) and the ‘persistent engagement' doctrine (which contemplates a continuous cycle of tracking and offensive action against emerging cyber threats) -- display yet more emphasis on punishment. There are important questions, discussed later, about whether rising faith in the efficacy of offensive operations -- especially of the pre-emptive variety -- as a response to threatened aggression could itself become an escalatory risk. Yet the fact remains that threatened escalation is already an important component of major powers' responses to emerging cyber threats, and unlikely to be retracted.\nFor effective deterrence via the threat of punishment, however, a potential attacker needs to know there is a significant chance of actually being punished. Assessments of this likelihood focus on the defender's capability and resolve: does the victim of an attack have the incentives, determination and wherewithal to retaliate by imposing a sufficient level of costs? Embedded in the capability half of the equation is a crucial subsidiary question: can the aspiring deterrer target its retaliation in the first place? Absent a ‘return address', no amount of retaliatory firepower will deter if attackers can be confident it will never be directed against anything they value.\nThis is where cyber attack poses a challenge for deterrence. Sophisticated cyber attacks may prove untraceable, even by the most advanced cybersecurity agencies. Masking internet protocol addresses, routing attacks via numerous connected computers (‘bots') that have wittingly or otherwise been turned into a cross-border network, initiating an attack from a cybercafe or public library, hacking and utilising some unsuspecting individual's internet-connected mobile phone, and so forth, may facilitate apparently unattributable cyber attacks. Furthermore, even if the computer used to initiate an attack can be identified, it is a greater challenge to prove who was sitting at it, or on whose orders they acted. The ongoing state-versus David Blagden private arms race in encryption technology only intensifies the problem.²⁴ While progress is being made in cyber forensics, technological innovation nevertheless appears unlikely to render all cyber attacks traceable in the near future.²⁵ Crucially, however, cyber attacks are not actually as anonymous as their technical characteristics might imply, and so do not enjoy the immunity from targeted retaliation that is often feared.\n## The coercive revelation of preferences Key research in cyber deterrence and coercion is united around the pivotal importance of attribution. For Thomas Rid and Ben Buchanan, ‘attribution is fundamental: almost any response to a specific offence – law enforcement, diplomatic, or military – requires identifying the offender first’.²⁶ Erica Borghard and Shawn Lonergan similarly contend that ‘coercion in cyberspace requires attribution to be effective’, while Martin Libicki reasons that coercion must be visibly associated with the coercer to operate, the logic being that the coercer must identify themselves if they are to cause the behavioural change they desire.²⁷ These assessments are aligned with seminal early analyses of the role of punishment in deterrence, which treated the existence of an identified enemy against which retaliation could be directed as a baseline assumption.²⁸ Such orthodoxies, however, obscure a vital distinction in the logic of punishment, with substantial implications for the cyber-deterrence debate. Retaliatory punishment is about imposing costs on political, economic and social interests – populations, cities, forces, wealth, status and anything else from which the attacker derives utility. The specific identity of the attacker is not an interest, and has no necessary political content. Of course, many important interests are exclusively associated with a particular identity, usually a state holding territory. Accordingly, deterrence by threatening some package of political, economic and social assets that are located in a particular territory requires the identification of the custodian of that territory. For this reason, the conflation of interests and identities was largely unproblematic in Cold War deterrence: for practical purposes, the interests that each aspiring deterrer sought to hold at risk were synonymous and coextensive with an exclusive identified adversary.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution While many interests are indeed unique to a specific holder, many others are not. Notwithstanding the Cold War experience, deterrence based on the threat of retaliatory punishment does not inherently require attribution of the attacker's identity, provided relevant interests can be ascertained. A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic preferences.[29] To advance a set of political interests via coercion, a coercer at least implicitly identifies those interests by specifying what behavioural change it wants to encourage. Attempted coercion therefore serves as a mechanism of preference revelation.\nSuch preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical means.[30] If the interests that the cyber coercion seeks to advance align solely with the unique identifiable interests of a particular state or group, then that actor will have identified itself. Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber attack[31] – this too may reveal the attacker's identity. Yet even where a specific attacker is not identifiable via these revealed preferences, preference revelation remains useful for deterrence: if there are a dozen possible culprits behind a given cyber attack, the very thing that makes them hard to distinguish – their similar interests – also unifies them. Thus, while the precise identity of the attacker may indeed remain unclear, this still does not preclude an effective counter-value deterrent posture. The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of retaliation.[32] The most high-profile cyber attack to date represents a key example of interest attribution in the absence of specific attacker identification. Iran did not need state-of-the-art cyber forensics to have a good idea that the Stuxnet attack on its nuclear facilities uncovered in 2010 was launched by Israel, the United States or one of those two states' allies. While more than one technically capable actor had an interest in retarding Iran's nuclear programme, David Blagden making it impossible to identify the specific attacker based on desired behavioural change alone, there were interests common to all possible attackers – the security of the United States' Middle Eastern allies – that Iran could have held at risk to achieve deterrence. Stuxnet was not an attack of explicit coercive signalling, of course; it was covert attrition, intended to degrade a capability. Nevertheless, that attrition was then exploited coercively in non-cyber domains and, once discovered – as it was always likely to be – the interests of its perpetrators were not hard to discern even if specific attacker identity remained opaque. The principal barrier to Iran's achieving deterrence was not the anonymity of the cyber attack, but its military inferiority and associated paucity of sufficiently credible retaliatory options. Cyber attacks on Estonia (2007), Georgia (2008), Finland (2013) and Ukraine (2014) – strategically attributable to Russia, even if technical attribution remained challenging – reflected the failure of deterrence for similar reasons. Beyond such observed incidents, however, the cyber attacks contemplated but not conducted due to the likely costs of potential retaliation would be the most probative indicators of effective deterrence of cyber attacks via the threat of retaliation. Yet such cases remain by definition largely unobservable.\n## Caveats and qualifications On balance, there are grounds for optimism about prospects for deterring cyber attacks via both cyber and non-cyber retaliatory means, at least by countries powerful enough to threaten meaningful costs. Five broad caveats, however, counsel against wholesale reliance on counter-value deterrence.\nFirstly, cyber attacks conducted by individuals solely to disrupt, without intending to change behaviour, are unlikely to be amenable to deterrence. Since such individuals would not be seeking to advance a political purpose, they would have no identifying cause and could thus be genuinely anonymous. The same may be true of those who hack solely to bring private information to public attention.[33] It may also be true of those who hack solely for financial enrichment, absent any higher coercive purpose. Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale casualties.[34] Deterring Cyber Coercion: The Exaggerated Problem of Attribution Secondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war,[37] so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it.[39] The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.[40] Thirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to achieve.[42] Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis instability.[43] Among recent Western posture innovations, the Cyber Deterrence Initiative – reflecting Washington's goal of coordinating retaliation against cyber attack among its allies – aims to bolster second-strike credibility and therefore increase stability. But persistent engagement – embodying Washington's stated intention to pre-empt possible hostile cyber action – could cut the other way, incentivising US adversaries to strike first rather than risk waiting to be forcibly disarmed.\nFourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag operations.[44] If Russia decided that its strategic interests would be served by China and the United States' weakening each other militarily, for example, it might conduct a technically anonymous cyber attack on US forces in Asia that seemingly benefitted China – or even one with ostensibly Chinese technical characteristics – leading Washington to believe Beijing was commencing hostilities against its regional interests. This could provoke swift US retaliation and equally swift Chinese escalation David Blagden owing to each side's fear of losing first-move advantages.⁴⁵ Moreover, even without the successful framing of an innocent party as the target for misdirected retaliation, false-flag operations may sow doubt and preclude effective retaliation, undermining the credibility of punishment threats.\nThis problem is context-specific and surmountable, however. Between two parties with a less offence-dominant strategic relationship than the contemporary US-Chinese situation is often taken to be⁴⁶ – and even that is contestable on the cyber front⁴⁷ – a dearth of first-move advantages could allow scope for diplomatic consultation over the origin of the attack.⁴⁸ If the framed aggressor repudiated the coercive goals that appeared to point in its direction, consciously and visibly eschewing the potential benefits of the apparent coercion, it would credibly signal that it was not to blame.⁴⁹ For example, if a party that appeared to benefit from a cyber attack on another state's internet-connected military logistics chain refrained from taking offensive conventional action even while the attack victim's forces were immobilised by the attack's effects, that would be a costly – and thus credible – signal of restraint. The third party attempting such framing would then itself be in a perilous situation: if its own subversive agenda were uncovered, the two parties it had attempted to trick could retaliate in concert.⁵⁰ Thus, third-party framing is not a risk-free option, and the threat could be minimised if potential cyber adversaries pursued deterrent postures that downplayed first-move advantages. Indeed, the major powers have already done so at the top rung of the escalatory ladder by way of establishing survivable nuclear arsenals. Similarly, non-malicious cyber accidents could be falsely construed as attacks.⁵¹ But again, identifying the coercive interests at stake could mitigate the risk of errant retaliation, and the repudiation of the coercive benefits would duly signal blamelessness.\nFinally, recognising that cyber coercion will always seek to advance some set of interests does not mean that discerning such interests will be easy. Coercers, to be sure, will often want to be correctly identified so as to maximise the clarity of intended signals.⁵² But many potential cyber attackers may instead prefer to achieve their strategic goals via covert cyber action to avoid possible retaliatory costs and – as discussed throughout – cyberspace is particularly amenable to such concealment and obscuration.⁵³ Deterring Cyber Coercion: The Exaggerated Problem of Attribution Accordingly, those seeking to hold the relevant interests at risk to effect deterrence may have to look at the indirect consequences of the initial cyber attack to isolate the set of interests being advanced. Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats credible[54] – removing the necessity of choosing among enemies. Indeed, in retaliating for Stuxnet against Israel (via its Hizbullah and Hamas proxies), the United States (via the 2012 US financial hack) and Saudi Arabia (via the 2012 Saudi Aramco cyber attack), Iran appeared to take this route. Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents.[55] But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are punished.[56] Furthermore, target calculations would also be subject to iterative refinement. For instance, if the potential beneficiaries of the interests ranked as being advanced the most by an attack refused to repudiate the coercive gains, they would effectively certify that those were the interests that should suffer retaliation. By contrast, the repudiation of those gains would signal that a different set of interests than those the attack seemed intended to advance should be held at risk.\n\\* \\* \\* Deterring cyber attacks by threatening to impair the interests they are presumed to advance, as opposed to focusing on identifying a sole attacker, is not without peril. It risks retaliating against innocent states or civilians, which incurs ethical costs and potential blowback, while cross-domain escalation may become dangerously unstable, especially if policymakers become inordinately confident in the efficacy of offensive cyber operations. Nevertheless, the anonymity of cyberspace is not the fundamental obstacle to counter-value deterrence it is often supposed to be, for attempting to coerce via cyber means reveals interests that can be held at risk. Accordingly, as the damage potential of cyber weaponry continues to increase, governments David Blagden and the populations they seek to protect may gain security from the threat of retaliatory punishment. For all of its ethical uncertainties, therefore, this form of deterrence remains the final backstop of major powers' strategic postures, and could constitute as potent an instrument against cyber threats as it has against those in the nuclear and conventional domains.\n## Acknowledgements The author thanks Ben Buchanan, Andrew Futter, Erik Gartzke, Jon Lindsay, Kubo Mačák, Patrick Porter, Simon Smith, Peter Watkins and especially Helena Mills for invaluable comments on drafts of this article.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 26,
        "success_occurrences": 26,
        "success_unique": 25,
        "bib_unique_total": 112,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.22321428571428573,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 31,
        "missing_intext_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          17,
          18,
          19,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53
        ],
        "highest_intext_index": 56,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 31,
        "uncited_footnote_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          17,
          18,
          19,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53
        ],
        "style": "hybrid"
      },
      "results": [
        {
          "index": "12",
          "intext_citation": "costs.[12]",
          "preceding_text": "Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited",
          "footnote": "A qualification would arise if cyber attacks became capable of compromising nuclear command and control, thus removing the risk of cross-domain retaliation."
        },
        {
          "index": "13",
          "intext_citation": "logic.[13]",
          "preceding_text": "ainst irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence'",
          "footnote": "This is a more precise rendering of Herman Kahn's concept of 'escalation dominance'. Such dominance"
        },
        {
          "index": "14",
          "intext_citation": "attacked.[14]",
          "preceding_text": "US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces",
          "footnote": "Schelling, Arms and Influence, p. 47."
        },
        {
          "index": "15",
          "intext_citation": "resilience.[15]",
          "preceding_text": "The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and",
          "footnote": "US Department of Defense, 'Department of Defense Strategy for Operating in Cyberspace', 2011, https://csrc.nist.gov/CSRC/media/Projects/ISPAB/documents/DOD-Strategy-for-Operating-in-Cyberspace.pdf; HM Government, The UK Cyber Security Strategy: Protecting and Promoting the UK in a Digital World (London: UK Cabinet Office, 2011), https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/60961/uk-cyber-security-strategy-final.pdf."
        },
        {
          "index": "16",
          "intext_citation": "deterrence.[16]",
          "preceding_text": "-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of",
          "footnote": "US Department of Defense, 'The Department of Defense Cyber Strategy', 2015, https://archive.defense.gov/home/features/2015/0415_cyber-strategy/final_2015_dod_cyber_strategy_for_web.pdf, p. 11; HM Government, National Cyber Security Strategy 2016–2021 (London: UK Cabinet Office, 2016), https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/567242/national_cyber_security_strategy_2016.pdf, pp. 41–52."
        },
        {
          "index": "29",
          "intext_citation": "preferences.[29]",
          "preceding_text": "A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic",
          "footnote": "Pape, *Bombing to Win*, p. 12. Compellence is sometimes treated separately from coercion, but since it essentially represents ‘total’ coercion, here it is cast as coercive. *Ibid.*, p. 4. See also Schelling, *Arms and Influence*, pp. 69–91."
        },
        {
          "index": "30",
          "intext_citation": "means.[30]",
          "preceding_text": "Such preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical",
          "footnote": "Kugler, ‘Deterrence of Cyberattacks’, pp. 309–10."
        },
        {
          "index": "31",
          "intext_citation": "attack[31]",
          "preceding_text": "Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber",
          "footnote": "Erik Gartzke, ‘The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth’, *International Security*, vol. 38, no. 2, Fall 2013, pp. 41–73."
        },
        {
          "index": "32",
          "intext_citation": "retaliation.[32]",
          "preceding_text": "The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of",
          "footnote": "Holding interests at risk without specifically identified attribution goes beyond valuable recent work on interests as a route to attribution. See, for instance, Rid and Buchanan,"
        },
        {
          "index": "33",
          "intext_citation": "attention.[33]",
          "preceding_text": "The same may be true of those who hack solely to bring private information to public",
          "footnote": "Both 'recreational' and 'hacktivist' attackers do have interests that can be jeopardised, of course, but doing so via punishment is challenging. The former values the opportunity to commit a successful attack for the mere thrill of it, making punishment and denial one and the same. The latter values something that the wider population may value too – transparency in public life – so punishing their interests could also penalise people that the state is charged with protecting."
        },
        {
          "index": "34",
          "intext_citation": "casualties.[34]",
          "preceding_text": "Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale",
          "footnote": "Certain capability gaps between individual hackers and state-level cyber forces have closed over time. An example is the reduced need for state-level supercomputers to break encryption due to bot technology. See Libicki, *Cyberdeterrence and Cyberwar*, pp. 47-8. Even so, as those with the greatest resources (powerful states and corporations foremost among them) push out the frontier of technological sophistication, the chances of sparsely resourced individuals or groups – however talented – keeping pace becomes small. Such state-versus-individual capability disparities are thus likely to persist, even if gifted hackers close gaps in certain areas. Stuxnet, in particular, shows the extraordinary resources required – including a replica of the entire targeted infrastructure and an expert human-intelligence operation to penetrate air-gapped systems – to propagate an attack of even modest state-level strategic significance. See Jon R. Lindsay, ‘Stuxnet and the Limits of Cyber Warfare’, *Security Studies*, vol. 22, no. 3, July 2013, pp. 365-404."
        },
        {
          "index": "35",
          "intext_citation": "reasons.[35]",
          "preceding_text": "er Coercion: The Exaggerated Problem of Attribution Secondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral",
          "footnote": "Sarah Kreps and Jacquelyn Schneider, 'Escalation Firebreaks in the Cyber, Conventional, and Nuclear Domains: Moving Beyond Effects-based Logics', *Journal of Cybersecurity*, vol. 5, no. 1, September 2019, pp. 1-11. Libicki sees the risk of third-party censure and opprobrium as a fundamental challenge to the credibility of deterrence by retaliation in response to cyber attack as being greater than it has been for the deterrence of nuclear attack, particularly on the grounds that numerous capable third parties may join the fight. Libicki, *Cyberdeterrence and Cyberwar*, p. 42. See also Lindsay, 'Tipping the Scales', p. 57. Yet while facing normative opprobrium may indeed affect a state's retaliatory resolve, there is no clear reason third parties would join hostilities against a retaliating state – opening themselves to re-retaliation in the process – simply to censure it for retaliating. A related argument, albeit with different causal underpinnings, is that an attack's victim may be self-deterred from certain retaliatory cyber options through fear that they would result in fratricide of their own ICT systems. *Ibid.*, p. 57. This is a relevant concern, but one contingent on the cyber weapon in question – and on aspiring deterrers' weighting of absolute versus relative gains and losses – rather than a fundamental barrier to retaliation per se."
        },
        {
          "index": "36",
          "intext_citation": "cannot.[36]",
          "preceding_text": "nce by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial",
          "footnote": "Kenneth Geers, 'The Challenge of Cyber Attack Deterrence', *Computer Law and Security Review*, vol. 26, no. 3, May 2010, pp. 300-1."
        },
        {
          "index": "37",
          "intext_citation": "war,[37]",
          "preceding_text": "oral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of",
          "footnote": "Erik Gartzke and Jon R. Lindsay, 'Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace', *Security Studies*, vol. 24, no. 2, June 2015, pp. 316–48."
        },
        {
          "index": "38",
          "intext_citation": "infringements.[38]",
          "preceding_text": "t the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war,[37] so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor",
          "footnote": "Lawrence J. Cavaiola, David C. Gompert and Martin Libicki, 'Cyber House Rules: On War, Retaliation and Escalation', *Survival*, vol. 57, no. 1, February–March 2015, pp. 81–104."
        },
        {
          "index": "39",
          "intext_citation": "it.[39]",
          "preceding_text": "rs will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare",
          "footnote": "See Lindsay, 'Tipping the Scales', pp. 58–64. This trade-off exists throughout deterrent posture – 'asymmetric escalation' doctrines deliver much deterrence but with escalatory dangers, for example, while 'assured retaliation' doctrines offer less deterrence of low-level irritations but also fewer escalatory risks. See Vipin Narang, *Nuclear Strategy in the Modern Era: Regional Powers and International Conflict* (Princeton, NJ: Princeton University Press, 2014), pp. 17–20."
        },
        {
          "index": "40",
          "intext_citation": "denial.[40]",
          "preceding_text": "gements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it.[39] The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by",
          "footnote": "Threatening success-prevention may be inherently more credible than threatening punishment, since the former promises minimised costs on both sides. Snyder, *Deterrence and Defense*, p. 16. Deterrence by punishment also cedes control of the decision over how much pain to bear to one’s opponent, and may therefore also be less precise and reliable when dealing with aggressors of uncertain cost-tolerance and risk-acceptance. Lawrence Freedman, *Deterrence* (Cambridge: Polity, 2004), p. 39."
        },
        {
          "index": "41",
          "intext_citation": "retaliation.[41]",
          "preceding_text": " is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.[40] Thirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by",
          "footnote": "James J. Wirtz, 'The Cyber Pearl Harbor', *Intelligence and National Security*, vol. 32, no. 6, September 2017, pp. 758–67. Of course, this is not to suggest that pulling off such a successful attack – or achieving the strategic shock/paralysis that it might induce – would be easy or even feasible, but it could be an attractive prospect for an aspiring aggressor. James J. Wirtz, 'The Cyber Pearl Harbor Redux: Helpful Analogy or Cyber Hype?', *Intelligence and National Security*, vol. 33, no. 5, April 2018, pp. 771–3."
        },
        {
          "index": "42",
          "intext_citation": "achieve.[42]",
          "preceding_text": "ishment should be viewed as complementary to deterrence by denial.[40] Thirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to",
          "footnote": "A common characteristic of cyber attack is uncertainty even on the attacker’s part over precisely what effects their action will produce. See Borghard and Lonergan, 'The Logic of Coercion in Cyberspace', p. 456."
        },
        {
          "index": "43",
          "intext_citation": "instability.[43]",
          "preceding_text": "ss-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to achieve.[42] Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis",
          "footnote": "See Ben Buchanan, *The Cybersecurity Dilemma: Hacking, Trust, and Fear Between Nations* (Oxford: Oxford University Press, 2017); and Herbert Lin, 'Escalation Dynamics and Conflict Termination in Cyberspace', *Strategic Studies Quarterly* (Cyber Special Edition), vol. 6, no. 3, Fall 2012, p. 46–70. For theoretical background, see Carl von Clausewitz, *On War*, trans. Michael Howard and Peter Paret (Princeton, NJ: Princeton University Press, 1976 [1832]), pp. 75–89; Barry R. Posen, *Inadvertent Escalation: Conventional War and Nuclear Risks* (Ithaca, NY: Cornell University Press, 1991), pp. 2–3."
        },
        {
          "index": "44",
          "intext_citation": "operations.[44]",
          "preceding_text": "Fourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag",
          "footnote": "Libicki, *Cyberdeterrence and Cyberwar*, p. 44."
        },
        {
          "index": "54",
          "intext_citation": "credible[54]",
          "preceding_text": "Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats",
          "footnote": "Lindsay, ‘Tipping the Scales’, p. 63."
        },
        {
          "index": "55",
          "intext_citation": "opponents.[55]",
          "preceding_text": "Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden'",
          "footnote": "Ibid., p. 57."
        },
        {
          "index": "56",
          "intext_citation": "punished.[56]",
          "preceding_text": "es of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents.[55] But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are",
          "footnote": "In the absence of precise identification of specific insurgent or terrorist attackers, counter-insurgent or counter-terrorist forces may resort to punishing the attackers’ manifested interests – say, razing an insurgent-hosting village or somehow retarding terrorists’ political cause. See Gil Merom, ‘Strong Powers in Small Wars: The Unnoticed Foundations of Success’, Small Wars and Insurgencies, vol. 9, no. 2, September 1998, pp. 38–63; and Robert F. Trager and Dessislava P. Zagorcheva, ‘Deterring Terrorism: It Can Be Done’, International Security, vol. 30, no. 3, Winter 2005/06, pp. 87–123. On drawing parallels between cyber attack and insurgency, see Lindsay, ‘Tipping the Scales’, p. 57. This approach can involve heavy moral costs and blowback, but the point is that there is a rationale motivating the incurrence of such costs."
        },
        {
          "index": "20",
          "intext_citation": "tsur20",
          "preceding_text": "Survival Global Politics and Strategy Survival Global Politics and Strategy Taylor &amp; Francis Taylor &amp; Francis Group ISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/",
          "footnote": "Paul Cornish et al., *On Cyber Warfare* (London: Chatham House, 2010), pp. 42–5. See also Daryl G. Press, *Calculating Credibility: How Leaders Assess Military Threats* (Ithaca, NY: Cornell University Press, 2005), pp. 2–3."
        },
        {
          "index": "20",
          "intext_citation": "tsur20",
          "preceding_text": "Submit your article to this journal Article views: 1757 View related articles View Crossmark data Citing articles: 5 View citing articles Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=",
          "footnote": "Paul Cornish et al., *On Cyber Warfare* (London: Chatham House, 2010), pp. 42–5. See also Daryl G. Press, *Calculating Credibility: How Leaders Assess Military Threats* (Ithaca, NY: Cornell University Press, 2005), pp. 2–3."
        }
      ],
      "flat_text": "Survival Global Politics and Strategy Survival Global Politics and Strategy Taylor &amp; Francis Taylor &amp; Francis Group ISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden To cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072 To link to this article: https://doi.org/10.1080/00396338.2020.1715072 Published online: 04 Feb 2020.\nSubmit your article to this journal Article views: 1757 View related articles View Crossmark data Citing articles: 5 View citing articles Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden The potential damage from possible cyber attacks is rising as the sophistication of cyber weapons increases.¹ Accordingly, the question of whether such attacks can be deterred is an increasingly salient one for governments, national-security agencies and the populations they seek to protect.² One characteristic of cyber attack, its potential for anonymity, is often taken as an insurmountable barrier to effective deterrence based on retaliatory punishment. But such assumptions are misguided. Coercion is the form of hostile political influence that deterrence seeks to oppose, and in order to coerce, a belligerent must necessarily identify that which it values. Attempted coercion thereby serves as a preference-revelation mechanism. Even if a belligerent can escape identifying itself via anonymous cyber attack, it cannot escape identifying interests that it holds dear, which can then be held at risk by those seeking deterrence.\nThe political interests being advanced by a cyber attack will often make the identity of the aggressor clear, of course, even if the origin of the attack itself cannot be readily traced via technical means.³ While a cyber attack may be technically anonymous, the strategic interaction of which it is a part can make clear whose interests are at stake. Yet many actors could have similar interests, meaning that the specific aggressor might remain unidentified.\nDavid Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute.\nSurvival | vol. 62 no. 1 | February–March 2020 | pp. 131–148 DOI 10.1080/00396338.2020.1715072 David Blagden Such reservations over strategic attribution are overblown, however. This is because they conflate two different variables within the deterrence calculus: aggressor identity and aggressor interests. These variables do often correlate: if you want to retaliate against an attacker's territory, for instance, you need to know whose territory. Yet it is possible to identify valued interests of an attacker without identifying those interests' sole holder. And crucially, coercion is not possible without identifying the interests being advanced, in cyberspace or anywhere else, since the very nature of coercion requires revelation of desired changes in behaviour.⁴ Russia, for example, would not need to identify which specific NATO country cyber-attacked it to still identify – and hold at risk – interests shared by all NATO members. It is therefore possible to retaliate against revealed preferences – to achieve successful strategic attribution of interests – even when strategic attribution of a specific attacker identity remains challenging. Many actors may hold similar interests while only one of them may be responsible for a particular cyber attack, but that need not matter: the very factor that obscures their specific identities (their shared interests) also means that retaliating against those interests will punish the underlying aggressor. The fact that the specific attacker may have ‘gotten away with it’ in terms of not being identified individually will be little consolation when its interests have nonetheless been impaired. And knowing as much beforehand, it is possible for deterrence to hold based on the threat of subsequent retaliatory punishment.\nWhat is the value of such analysis? After all, cyber weapons are ill-suited tools for explicit coercive signalling, since their capability is often unclear prior to their use, and degraded by their revelation insofar as defenders can patch exposed vulnerabilities.⁵ And many categories of hostile cyber action – attrition of an opponent's capabilities, hacking for enjoyment or publicity, covert cyber espionage, cyber-enabled theft, subversion and disinformation, and so forth – are pressing security concerns but do not achieve their effects via the issuance of coercive threats. Also, cyber deterrence has hardly been an unambiguous success thus far; there have been plenty of cyber attacks against states with retaliatory means at their disposal, despite successful culprit attribution and superior relative power. Examples include the 2012 attacks on the US financial system and Saudi Aramco, the 2013 attack on the Sands Casino and the 2014 attack on Sony Pictures. On top of all this, one could question the value of more deterrence theory while empirical scholarship on cyber aggression remains relatively sparse.\nNone of these rejoinders hold water, however. By themselves, cyber threats are indeed flawed tools of coercive signalling. But taken in strategic context, a wide range of hostile cyber actions meet a reasonable definition of coercion: cost imposition in pursuit of behavioural change. If an attacker seeks to coercively exploit a favourably changed balance of power following successful attrition or extortion, if a protester draws attention to a cause in a way that generates coercive political costs, or if cyber espionage delivers information that is utilised coercively in another domain, coercive interests are being advanced. Meanwhile, observed cyber attacks -- those that, for whatever reason, have not been deterred -- are not evidence of the futility of the deterrent enterprise, since defenders' resolve to impose punishment rises with the severity of the attack suffered while the pool of capable‐enough potential culprits shrinks. For example, North Korea going undeterred in its 2014 Sony hack -- a rudimentary and low‐damage attack -- does not mean that deterrence has failed with respect to great‐power use of more capable cyber weaponry against other major states. Lastly, owing to unavoidable selection bias, the empirical study of non‐occurrences will underplay deterrence's causal significance; cyber‐deterrence theory can help offset this imbalance.\n### Escalation dominance and the ‘return address' problem Deterrence is achieved when an actor -- a state, an armed group or an individual -- concludes that the likely costs of an attack exceed the likely benefits. Opponents can be deterred in two ways. Deterrence by denial occurs when a potential aggressor concludes that attack will be ineffective because of the strength of the countermeasures in place: it is denied the opportunity of achieving its coercive objectives. Deterrence by punishment, in contrast, does not promise to diminish an attack's effectiveness, but rests on the threat of retaliation of sufficient magnitude that the aggressor will be worse off than if it had not attacked in the first place: it will be punished after the fact. Deterring or thwarting cyber attack via effective David Blagden denial measures, such as information and communications technology (ICT) hardening and resilience, is of course an important component of effective cyber deterrence. But the focus here is deterrence of those threats that cannot be reliably denied.\nThere is no reason in principle that the use of any new weapon cannot be deterred via the threat of retaliation using the same or alternative weapons systems. To be insusceptible to such 'cross-domain' deterrence – deterrence reliant on the threat of costs imposed in an operational domain other than that in which the original attack occurred – a new weapon would have to possess destructive capability that no other existing weapon could match and be available exclusively to one party. Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited costs.[12] Although nuclear retaliation against irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence' logic.[13] A similar logic underpinned Cold War 'tripwire' military deployments. US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces attacked.[14] The prominence of deterrence by punishment in Western cyber strategy has grown in line with capabilities and understanding. The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and resilience.[15] Following Edward Snowden's revelations of Anglo-American capabilities, however, both countries have become less reluctant to discuss their full range of options. The 2015 US cyber-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of deterrence.[16] The Western allies have also made it increasingly explicit that cross-domain retaliation is a component of their thinking. Most recently, US posture innovations stemming from the 2018 National Cyber Strategy -- the ‘Cyber Deterrence Initiative' (which aims to bolster retaliatory deterrence through collective alliance responses) and the ‘persistent engagement' doctrine (which contemplates a continuous cycle of tracking and offensive action against emerging cyber threats) -- display yet more emphasis on punishment. There are important questions, discussed later, about whether rising faith in the efficacy of offensive operations -- especially of the pre-emptive variety -- as a response to threatened aggression could itself become an escalatory risk. Yet the fact remains that threatened escalation is already an important component of major powers' responses to emerging cyber threats, and unlikely to be retracted.\nFor effective deterrence via the threat of punishment, however, a potential attacker needs to know there is a significant chance of actually being punished. Assessments of this likelihood focus on the defender's capability and resolve: does the victim of an attack have the incentives, determination and wherewithal to retaliate by imposing a sufficient level of costs? Embedded in the capability half of the equation is a crucial subsidiary question: can the aspiring deterrer target its retaliation in the first place? Absent a ‘return address', no amount of retaliatory firepower will deter if attackers can be confident it will never be directed against anything they value.\nThis is where cyber attack poses a challenge for deterrence. Sophisticated cyber attacks may prove untraceable, even by the most advanced cybersecurity agencies. Masking internet protocol addresses, routing attacks via numerous connected computers (‘bots') that have wittingly or otherwise been turned into a cross-border network, initiating an attack from a cybercafe or public library, hacking and utilising some unsuspecting individual's internet-connected mobile phone, and so forth, may facilitate apparently unattributable cyber attacks. Furthermore, even if the computer used to initiate an attack can be identified, it is a greater challenge to prove who was sitting at it, or on whose orders they acted. The ongoing state-versus David Blagden private arms race in encryption technology only intensifies the problem.²⁴ While progress is being made in cyber forensics, technological innovation nevertheless appears unlikely to render all cyber attacks traceable in the near future.²⁵ Crucially, however, cyber attacks are not actually as anonymous as their technical characteristics might imply, and so do not enjoy the immunity from targeted retaliation that is often feared.\n## The coercive revelation of preferences Key research in cyber deterrence and coercion is united around the pivotal importance of attribution. For Thomas Rid and Ben Buchanan, ‘attribution is fundamental: almost any response to a specific offence – law enforcement, diplomatic, or military – requires identifying the offender first’.²⁶ Erica Borghard and Shawn Lonergan similarly contend that ‘coercion in cyberspace requires attribution to be effective’, while Martin Libicki reasons that coercion must be visibly associated with the coercer to operate, the logic being that the coercer must identify themselves if they are to cause the behavioural change they desire.²⁷ These assessments are aligned with seminal early analyses of the role of punishment in deterrence, which treated the existence of an identified enemy against which retaliation could be directed as a baseline assumption.²⁸ Such orthodoxies, however, obscure a vital distinction in the logic of punishment, with substantial implications for the cyber-deterrence debate. Retaliatory punishment is about imposing costs on political, economic and social interests – populations, cities, forces, wealth, status and anything else from which the attacker derives utility. The specific identity of the attacker is not an interest, and has no necessary political content. Of course, many important interests are exclusively associated with a particular identity, usually a state holding territory. Accordingly, deterrence by threatening some package of political, economic and social assets that are located in a particular territory requires the identification of the custodian of that territory. For this reason, the conflation of interests and identities was largely unproblematic in Cold War deterrence: for practical purposes, the interests that each aspiring deterrer sought to hold at risk were synonymous and coextensive with an exclusive identified adversary.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution While many interests are indeed unique to a specific holder, many others are not. Notwithstanding the Cold War experience, deterrence based on the threat of retaliatory punishment does not inherently require attribution of the attacker's identity, provided relevant interests can be ascertained. A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic preferences.[29] To advance a set of political interests via coercion, a coercer at least implicitly identifies those interests by specifying what behavioural change it wants to encourage. Attempted coercion therefore serves as a mechanism of preference revelation.\nSuch preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical means.[30] If the interests that the cyber coercion seeks to advance align solely with the unique identifiable interests of a particular state or group, then that actor will have identified itself. Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber attack[31] – this too may reveal the attacker's identity. Yet even where a specific attacker is not identifiable via these revealed preferences, preference revelation remains useful for deterrence: if there are a dozen possible culprits behind a given cyber attack, the very thing that makes them hard to distinguish – their similar interests – also unifies them. Thus, while the precise identity of the attacker may indeed remain unclear, this still does not preclude an effective counter-value deterrent posture. The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of retaliation.[32] The most high-profile cyber attack to date represents a key example of interest attribution in the absence of specific attacker identification. Iran did not need state-of-the-art cyber forensics to have a good idea that the Stuxnet attack on its nuclear facilities uncovered in 2010 was launched by Israel, the United States or one of those two states' allies. While more than one technically capable actor had an interest in retarding Iran's nuclear programme, David Blagden making it impossible to identify the specific attacker based on desired behavioural change alone, there were interests common to all possible attackers – the security of the United States' Middle Eastern allies – that Iran could have held at risk to achieve deterrence. Stuxnet was not an attack of explicit coercive signalling, of course; it was covert attrition, intended to degrade a capability. Nevertheless, that attrition was then exploited coercively in non-cyber domains and, once discovered – as it was always likely to be – the interests of its perpetrators were not hard to discern even if specific attacker identity remained opaque. The principal barrier to Iran's achieving deterrence was not the anonymity of the cyber attack, but its military inferiority and associated paucity of sufficiently credible retaliatory options. Cyber attacks on Estonia (2007), Georgia (2008), Finland (2013) and Ukraine (2014) – strategically attributable to Russia, even if technical attribution remained challenging – reflected the failure of deterrence for similar reasons. Beyond such observed incidents, however, the cyber attacks contemplated but not conducted due to the likely costs of potential retaliation would be the most probative indicators of effective deterrence of cyber attacks via the threat of retaliation. Yet such cases remain by definition largely unobservable.\n## Caveats and qualifications On balance, there are grounds for optimism about prospects for deterring cyber attacks via both cyber and non-cyber retaliatory means, at least by countries powerful enough to threaten meaningful costs. Five broad caveats, however, counsel against wholesale reliance on counter-value deterrence.\nFirstly, cyber attacks conducted by individuals solely to disrupt, without intending to change behaviour, are unlikely to be amenable to deterrence. Since such individuals would not be seeking to advance a political purpose, they would have no identifying cause and could thus be genuinely anonymous. The same may be true of those who hack solely to bring private information to public attention.[33] It may also be true of those who hack solely for financial enrichment, absent any higher coercive purpose. Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale casualties.[34] Deterring Cyber Coercion: The Exaggerated Problem of Attribution Secondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war,[37] so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it.[39] The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.[40] Thirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to achieve.[42] Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis instability.[43] Among recent Western posture innovations, the Cyber Deterrence Initiative – reflecting Washington's goal of coordinating retaliation against cyber attack among its allies – aims to bolster second-strike credibility and therefore increase stability. But persistent engagement – embodying Washington's stated intention to pre-empt possible hostile cyber action – could cut the other way, incentivising US adversaries to strike first rather than risk waiting to be forcibly disarmed.\nFourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag operations.[44] If Russia decided that its strategic interests would be served by China and the United States' weakening each other militarily, for example, it might conduct a technically anonymous cyber attack on US forces in Asia that seemingly benefitted China – or even one with ostensibly Chinese technical characteristics – leading Washington to believe Beijing was commencing hostilities against its regional interests. This could provoke swift US retaliation and equally swift Chinese escalation David Blagden owing to each side's fear of losing first-move advantages.⁴⁵ Moreover, even without the successful framing of an innocent party as the target for misdirected retaliation, false-flag operations may sow doubt and preclude effective retaliation, undermining the credibility of punishment threats.\nThis problem is context-specific and surmountable, however. Between two parties with a less offence-dominant strategic relationship than the contemporary US-Chinese situation is often taken to be⁴⁶ – and even that is contestable on the cyber front⁴⁷ – a dearth of first-move advantages could allow scope for diplomatic consultation over the origin of the attack.⁴⁸ If the framed aggressor repudiated the coercive goals that appeared to point in its direction, consciously and visibly eschewing the potential benefits of the apparent coercion, it would credibly signal that it was not to blame.⁴⁹ For example, if a party that appeared to benefit from a cyber attack on another state's internet-connected military logistics chain refrained from taking offensive conventional action even while the attack victim's forces were immobilised by the attack's effects, that would be a costly – and thus credible – signal of restraint. The third party attempting such framing would then itself be in a perilous situation: if its own subversive agenda were uncovered, the two parties it had attempted to trick could retaliate in concert.⁵⁰ Thus, third-party framing is not a risk-free option, and the threat could be minimised if potential cyber adversaries pursued deterrent postures that downplayed first-move advantages. Indeed, the major powers have already done so at the top rung of the escalatory ladder by way of establishing survivable nuclear arsenals. Similarly, non-malicious cyber accidents could be falsely construed as attacks.⁵¹ But again, identifying the coercive interests at stake could mitigate the risk of errant retaliation, and the repudiation of the coercive benefits would duly signal blamelessness.\nFinally, recognising that cyber coercion will always seek to advance some set of interests does not mean that discerning such interests will be easy. Coercers, to be sure, will often want to be correctly identified so as to maximise the clarity of intended signals.⁵² But many potential cyber attackers may instead prefer to achieve their strategic goals via covert cyber action to avoid possible retaliatory costs and – as discussed throughout – cyberspace is particularly amenable to such concealment and obscuration.⁵³ Deterring Cyber Coercion: The Exaggerated Problem of Attribution Accordingly, those seeking to hold the relevant interests at risk to effect deterrence may have to look at the indirect consequences of the initial cyber attack to isolate the set of interests being advanced. Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats credible[54] – removing the necessity of choosing among enemies. Indeed, in retaliating for Stuxnet against Israel (via its Hizbullah and Hamas proxies), the United States (via the 2012 US financial hack) and Saudi Arabia (via the 2012 Saudi Aramco cyber attack), Iran appeared to take this route. Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents.[55] But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are punished.[56] Furthermore, target calculations would also be subject to iterative refinement. For instance, if the potential beneficiaries of the interests ranked as being advanced the most by an attack refused to repudiate the coercive gains, they would effectively certify that those were the interests that should suffer retaliation. By contrast, the repudiation of those gains would signal that a different set of interests than those the attack seemed intended to advance should be held at risk.\n\\* \\* \\* Deterring cyber attacks by threatening to impair the interests they are presumed to advance, as opposed to focusing on identifying a sole attacker, is not without peril. It risks retaliating against innocent states or civilians, which incurs ethical costs and potential blowback, while cross-domain escalation may become dangerously unstable, especially if policymakers become inordinately confident in the efficacy of offensive cyber operations. Nevertheless, the anonymity of cyberspace is not the fundamental obstacle to counter-value deterrence it is often supposed to be, for attempting to coerce via cyber means reveals interests that can be held at risk. Accordingly, as the damage potential of cyber weaponry continues to increase, governments David Blagden and the populations they seek to protect may gain security from the threat of retaliatory punishment. For all of its ethical uncertainties, therefore, this form of deterrence remains the final backstop of major powers' strategic postures, and could constitute as potent an instrument against cyber threats as it has against those in the nuclear and conventional domains.\n## Acknowledgements The author thanks Ben Buchanan, Andrew Futter, Erik Gartzke, Jon Lindsay, Kubo Mačák, Patrick Porter, Simon Smith, Peter Watkins and especially Helena Mills for invaluable comments on drafts of this article."
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 5,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Survival Global Politics and Strategy\nSurvival\nGlobal Politics and Strategy\nTaylor &amp; Francis\nTaylor &amp; Francis Group\nISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20\n# Deterring Cyber Coercion: The Exaggerated Problem of Attribution\nDavid Blagden\nTo cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072\nTo link to this article: https://doi.org/10.1080/00396338.2020.1715072\nPublished online: 04 Feb 2020.\nSubmit your article to this journal\nArticle views: 1757\nView related articles\nView Crossmark data\nCiting articles: 5 View citing articles\nFull Terms &amp; Conditions of access and use can be found at\nhttps://www.tandfonline.com/action/journalInformation?journalCode=tsur20\n# Deterring Cyber Coercion: The Exaggerated Problem of Attribution\nDavid Blagden\nThe potential damage from possible cyber attacks is rising as the sophistication of cyber weapons increases.¹ Accordingly, the question of whether such attacks can be deterred is an increasingly salient one for governments, national-security agencies and the populations they seek to protect.² One characteristic of cyber attack, its potential for anonymity, is often taken as an insurmountable barrier to effective deterrence based on retaliatory punishment. But such assumptions are misguided. Coercion is the form of hostile political influence that deterrence seeks to oppose, and in order to coerce, a belligerent must necessarily identify that which it values. Attempted coercion thereby serves as a preference-revelation mechanism. Even if a belligerent can escape identifying itself via anonymous cyber attack, it cannot escape identifying interests that it holds dear, which can then be held at risk by those seeking deterrence.\nThe political interests being advanced by a cyber attack will often make the identity of the aggressor clear, of course, even if the origin of the attack itself cannot be readily traced via technical means.³ While a cyber attack may be technically anonymous, the strategic interaction of which it is a part can make clear whose interests are at stake. Yet many actors could have similar interests, meaning that the specific aggressor might remain unidentified.\nDavid Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute.\nSurvival | vol. 62 no. 1 | February–March 2020 | pp. 131–148\nDOI 10.1080/00396338.2020.1715072\nDavid Blagden\nSuch reservations over strategic attribution are overblown, however. This is because they conflate two different variables within the deterrence calculus: aggressor identity and aggressor interests. These variables do often correlate: if you want to retaliate against an attacker's territory, for instance, you need to know whose territory. Yet it is possible to identify valued interests of an attacker without identifying those interests' sole holder. And crucially, coercion is not possible without identifying the interests being advanced, in cyberspace or anywhere else, since the very nature of coercion requires revelation of desired changes in behaviour.⁴ Russia, for example, would not need to identify which specific NATO country cyber-attacked it to still identify – and hold at risk – interests shared by all NATO members. It is therefore possible to retaliate against revealed preferences – to achieve successful strategic attribution of interests – even when strategic attribution of a specific attacker identity remains challenging. Many actors may hold similar interests while only one of them may be responsible for a particular cyber attack, but that need not matter: the very factor that obscures their specific identities (their shared interests) also means that retaliating against those interests will punish the underlying aggressor. The fact that the specific attacker may have ‘gotten away with it’ in terms of not being identified individually will be little consolation when its interests have nonetheless been impaired. And knowing as much beforehand, it is possible for deterrence to hold based on the threat of subsequent retaliatory punishment.\nWhat is the value of such analysis? After all, cyber weapons are ill-suited tools for explicit coercive signalling, since their capability is often unclear prior to their use, and degraded by their revelation insofar as defenders can patch exposed vulnerabilities.⁵ And many categories of hostile cyber action – attrition of an opponent's capabilities, hacking for enjoyment or publicity, covert cyber espionage, cyber-enabled theft, subversion and disinformation, and so forth – are pressing security concerns but do not achieve their effects via the issuance of coercive threats. Also, cyber deterrence has hardly been an unambiguous success thus far; there have been plenty of cyber attacks against states with retaliatory means at their disposal, despite successful culprit attribution and superior relative power. Examples include the 2012 attacks on the US financial system and Saudi Aramco, the 2013 attack on the\nSands Casino and the 2014 attack on Sony Pictures. On top of all this, one could question the value of more deterrence theory while empirical scholarship on cyber aggression remains relatively sparse.\nNone of these rejoinders hold water, however. By themselves, cyber threats are indeed flawed tools of coercive signalling. But taken in strategic context, a wide range of hostile cyber actions meet a reasonable definition of coercion: cost imposition in pursuit of behavioural change. If an attacker seeks to coercively exploit a favourably changed balance of power following successful attrition or extortion, if a protester draws attention to a cause in a way that generates coercive political costs, or if cyber espionage delivers information that is utilised coercively in another domain, coercive interests are being advanced. Meanwhile, observed cyber attacks -- those that, for whatever reason, have not been deterred -- are not evidence of the futility of the deterrent enterprise, since defenders' resolve to impose punishment rises with the severity of the attack suffered while the pool of capable‐enough potential culprits shrinks. For example, North Korea going undeterred in its 2014 Sony hack -- a rudimentary and low‐damage attack -- does not mean that deterrence has failed with respect to great‐power use of more capable cyber weaponry against other major states. Lastly, owing to unavoidable selection bias, the empirical study of non‐occurrences will underplay deterrence's causal significance; cyber‐deterrence theory can help offset this imbalance.\n### Escalation dominance and the ‘return address' problem\nDeterrence is achieved when an actor -- a state, an armed group or an individual -- concludes that the likely costs of an attack exceed the likely benefits. Opponents can be deterred in two ways. Deterrence by denial occurs when a potential aggressor concludes that attack will be ineffective because of the strength of the countermeasures in place: it is denied the opportunity of achieving its coercive objectives. Deterrence by punishment, in contrast, does not promise to diminish an attack's effectiveness, but rests on the threat of retaliation of sufficient magnitude that the aggressor will be worse off than if it had not attacked in the first place: it will be punished after the fact. Deterring or thwarting cyber attack via effective\nDavid Blagden\ndenial measures, such as information and communications technology (ICT) hardening and resilience, is of course an important component of effective cyber deterrence. But the focus here is deterrence of those threats that cannot be reliably denied.\nThere is no reason in principle that the use of any new weapon cannot be deterred via the threat of retaliation using the same or alternative weapons systems. To be insusceptible to such 'cross-domain' deterrence – deterrence reliant on the threat of costs imposed in an operational domain other than that in which the original attack occurred – a new weapon would have to possess destructive capability that no other existing weapon could match and be available exclusively to one party. Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited costs. Although nuclear retaliation against irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence' logic. A similar logic underpinned Cold War 'tripwire' military deployments. US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces attacked.\nThe prominence of deterrence by punishment in Western cyber strategy has grown in line with capabilities and understanding. The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and resilience. Following Edward Snowden's revelations of Anglo-American capabilities, however, both countries have become less reluctant to discuss their full range of options. The 2015 US cyber-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of deterrence. The Western allies have also made\nit increasingly explicit that cross-domain retaliation is a component of their thinking. Most recently, US posture innovations stemming from the 2018 National Cyber Strategy -- the ‘Cyber Deterrence Initiative' (which aims to bolster retaliatory deterrence through collective alliance responses) and the ‘persistent engagement' doctrine (which contemplates a continuous cycle of tracking and offensive action against emerging cyber threats) -- display yet more emphasis on punishment. There are important questions, discussed later, about whether rising faith in the efficacy of offensive operations -- especially of the pre-emptive variety -- as a response to threatened aggression could itself become an escalatory risk. Yet the fact remains that threatened escalation is already an important component of major powers' responses to emerging cyber threats, and unlikely to be retracted.\nFor effective deterrence via the threat of punishment, however, a potential attacker needs to know there is a significant chance of actually being punished. Assessments of this likelihood focus on the defender's capability and resolve: does the victim of an attack have the incentives, determination and wherewithal to retaliate by imposing a sufficient level of costs? Embedded in the capability half of the equation is a crucial subsidiary question: can the aspiring deterrer target its retaliation in the first place? Absent a ‘return address', no amount of retaliatory firepower will deter if attackers can be confident it will never be directed against anything they value.\nThis is where cyber attack poses a challenge for deterrence. Sophisticated cyber attacks may prove untraceable, even by the most advanced cybersecurity agencies. Masking internet protocol addresses, routing attacks via numerous connected computers (‘bots') that have wittingly or otherwise been turned into a cross-border network, initiating an attack from a cybercafe or public library, hacking and utilising some unsuspecting individual's internet-connected mobile phone, and so forth, may facilitate apparently unattributable cyber attacks. Furthermore, even if the computer used to initiate an attack can be identified, it is a greater challenge to prove who was sitting at it, or on whose orders they acted. The ongoing state-versus\nDavid Blagden\nprivate arms race in encryption technology only intensifies the problem.²⁴ While progress is being made in cyber forensics, technological innovation nevertheless appears unlikely to render all cyber attacks traceable in the near future.²⁵ Crucially, however, cyber attacks are not actually as anonymous as their technical characteristics might imply, and so do not enjoy the immunity from targeted retaliation that is often feared.\n## The coercive revelation of preferences\nKey research in cyber deterrence and coercion is united around the pivotal importance of attribution. For Thomas Rid and Ben Buchanan, ‘attribution is fundamental: almost any response to a specific offence – law enforcement, diplomatic, or military – requires identifying the offender first’.²⁶ Erica Borghard and Shawn Lonergan similarly contend that ‘coercion in cyberspace requires attribution to be effective’, while Martin Libicki reasons that coercion must be visibly associated with the coercer to operate, the logic being that the coercer must identify themselves if they are to cause the behavioural change they desire.²⁷ These assessments are aligned with seminal early analyses of the role of punishment in deterrence, which treated the existence of an identified enemy against which retaliation could be directed as a baseline assumption.²⁸\nSuch orthodoxies, however, obscure a vital distinction in the logic of punishment, with substantial implications for the cyber-deterrence debate. Retaliatory punishment is about imposing costs on political, economic and social interests – populations, cities, forces, wealth, status and anything else from which the attacker derives utility. The specific identity of the attacker is not an interest, and has no necessary political content. Of course, many important interests are exclusively associated with a particular identity, usually a state holding territory. Accordingly, deterrence by threatening some package of political, economic and social assets that are located in a particular territory requires the identification of the custodian of that territory. For this reason, the conflation of interests and identities was largely unproblematic in Cold War deterrence: for practical purposes, the interests that each aspiring deterrer sought to hold at risk were synonymous and coextensive with an exclusive identified adversary.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nWhile many interests are indeed unique to a specific holder, many others are not. Notwithstanding the Cold War experience, deterrence based on the threat of retaliatory punishment does not inherently require attribution of the attacker's identity, provided relevant interests can be ascertained. A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic preferences. To advance a set of political interests via coercion, a coercer at least implicitly identifies those interests by specifying what behavioural change it wants to encourage. Attempted coercion therefore serves as a mechanism of preference revelation.\nSuch preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical means. If the interests that the cyber coercion seeks to advance align solely with the unique identifiable interests of a particular state or group, then that actor will have identified itself. Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber attack – this too may reveal the attacker's identity. Yet even where a specific attacker is not identifiable via these revealed preferences, preference revelation remains useful for deterrence: if there are a dozen possible culprits behind a given cyber attack, the very thing that makes them hard to distinguish – their similar interests – also unifies them. Thus, while the precise identity of the attacker may indeed remain unclear, this still does not preclude an effective counter-value deterrent posture. The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of retaliation.\nThe most high-profile cyber attack to date represents a key example of interest attribution in the absence of specific attacker identification. Iran did not need state-of-the-art cyber forensics to have a good idea that the Stuxnet attack on its nuclear facilities uncovered in 2010 was launched by Israel, the United States or one of those two states' allies. While more than one technically capable actor had an interest in retarding Iran's nuclear programme,\nDavid Blagden\nmaking it impossible to identify the specific attacker based on desired behavioural change alone, there were interests common to all possible attackers – the security of the United States' Middle Eastern allies – that Iran could have held at risk to achieve deterrence. Stuxnet was not an attack of explicit coercive signalling, of course; it was covert attrition, intended to degrade a capability. Nevertheless, that attrition was then exploited coercively in non-cyber domains and, once discovered – as it was always likely to be – the interests of its perpetrators were not hard to discern even if specific attacker identity remained opaque. The principal barrier to Iran's achieving deterrence was not the anonymity of the cyber attack, but its military inferiority and associated paucity of sufficiently credible retaliatory options. Cyber attacks on Estonia (2007), Georgia (2008), Finland (2013) and Ukraine (2014) – strategically attributable to Russia, even if technical attribution remained challenging – reflected the failure of deterrence for similar reasons. Beyond such observed incidents, however, the cyber attacks contemplated but not conducted due to the likely costs of potential retaliation would be the most probative indicators of effective deterrence of cyber attacks via the threat of retaliation. Yet such cases remain by definition largely unobservable.\n## Caveats and qualifications\nOn balance, there are grounds for optimism about prospects for deterring cyber attacks via both cyber and non-cyber retaliatory means, at least by countries powerful enough to threaten meaningful costs. Five broad caveats, however, counsel against wholesale reliance on counter-value deterrence.\nFirstly, cyber attacks conducted by individuals solely to disrupt, without intending to change behaviour, are unlikely to be amenable to deterrence. Since such individuals would not be seeking to advance a political purpose, they would have no identifying cause and could thus be genuinely anonymous. The same may be true of those who hack solely to bring private information to public attention. It may also be true of those who hack solely for financial enrichment, absent any higher coercive purpose. Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale casualties.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nSecondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons. That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot. Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war, so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements. Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it. The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.\nThirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation. Such an attack would be hard to achieve. Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis instability. Among recent Western posture innovations, the Cyber Deterrence Initiative – reflecting Washington's goal of coordinating retaliation against cyber attack among its allies – aims to bolster second-strike credibility and therefore increase stability. But persistent engagement – embodying Washington's stated intention to pre-empt possible hostile cyber action – could cut the other way, incentivising US adversaries to strike first rather than risk waiting to be forcibly disarmed.\nFourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag operations. If Russia decided that its strategic interests would be served by China and the United States' weakening each other militarily, for example, it might conduct a technically anonymous cyber attack on US forces in Asia that seemingly benefitted China – or even one with ostensibly Chinese technical characteristics – leading Washington to believe Beijing was commencing hostilities against its regional interests. This could provoke swift US retaliation and equally swift Chinese escalation\nDavid Blagden\nowing to each side's fear of losing first-move advantages.⁴⁵ Moreover, even without the successful framing of an innocent party as the target for misdirected retaliation, false-flag operations may sow doubt and preclude effective retaliation, undermining the credibility of punishment threats.\nThis problem is context-specific and surmountable, however. Between two parties with a less offence-dominant strategic relationship than the contemporary US-Chinese situation is often taken to be⁴⁶ – and even that is contestable on the cyber front⁴⁷ – a dearth of first-move advantages could allow scope for diplomatic consultation over the origin of the attack.⁴⁸ If the framed aggressor repudiated the coercive goals that appeared to point in its direction, consciously and visibly eschewing the potential benefits of the apparent coercion, it would credibly signal that it was not to blame.⁴⁹ For example, if a party that appeared to benefit from a cyber attack on another state's internet-connected military logistics chain refrained from taking offensive conventional action even while the attack victim's forces were immobilised by the attack's effects, that would be a costly – and thus credible – signal of restraint. The third party attempting such framing would then itself be in a perilous situation: if its own subversive agenda were uncovered, the two parties it had attempted to trick could retaliate in concert.⁵⁰ Thus, third-party framing is not a risk-free option, and the threat could be minimised if potential cyber adversaries pursued deterrent postures that downplayed first-move advantages. Indeed, the major powers have already done so at the top rung of the escalatory ladder by way of establishing survivable nuclear arsenals. Similarly, non-malicious cyber accidents could be falsely construed as attacks.⁵¹ But again, identifying the coercive interests at stake could mitigate the risk of errant retaliation, and the repudiation of the coercive benefits would duly signal blamelessness.\nFinally, recognising that cyber coercion will always seek to advance some set of interests does not mean that discerning such interests will be easy. Coercers, to be sure, will often want to be correctly identified so as to maximise the clarity of intended signals.⁵² But many potential cyber attackers may instead prefer to achieve their strategic goals via covert cyber action to avoid possible retaliatory costs and – as discussed throughout – cyberspace is particularly amenable to such concealment and obscuration.⁵³\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution\nAccordingly, those seeking to hold the relevant interests at risk to effect deterrence may have to look at the indirect consequences of the initial cyber attack to isolate the set of interests being advanced. Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats credible – removing the necessity of choosing among enemies. Indeed, in retaliating for Stuxnet against Israel (via its Hizbullah and Hamas proxies), the United States (via the 2012 US financial hack) and Saudi Arabia (via the 2012 Saudi Aramco cyber attack), Iran appeared to take this route. Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents. But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are punished. Furthermore, target calculations would also be subject to iterative refinement. For instance, if the potential beneficiaries of the interests ranked as being advanced the most by an attack refused to repudiate the coercive gains, they would effectively certify that those were the interests that should suffer retaliation. By contrast, the repudiation of those gains would signal that a different set of interests than those the attack seemed intended to advance should be held at risk.\n\\* \\* \\*\nDeterring cyber attacks by threatening to impair the interests they are presumed to advance, as opposed to focusing on identifying a sole attacker, is not without peril. It risks retaliating against innocent states or civilians, which incurs ethical costs and potential blowback, while cross-domain escalation may become dangerously unstable, especially if policymakers become inordinately confident in the efficacy of offensive cyber operations. Nevertheless, the anonymity of cyberspace is not the fundamental obstacle to counter-value deterrence it is often supposed to be, for attempting to coerce via cyber means reveals interests that can be held at risk. Accordingly, as the damage potential of cyber weaponry continues to increase, governments\nDavid Blagden\nand the populations they seek to protect may gain security from the threat of retaliatory punishment. For all of its ethical uncertainties, therefore, this form of deterrence remains the final backstop of major powers' strategic postures, and could constitute as potent an instrument against cyber threats as it has against those in the nuclear and conventional domains.\n## Acknowledgements\nThe author thanks Ben Buchanan, Andrew Futter, Erik Gartzke, Jon Lindsay, Kubo Mačák, Patrick Porter, Simon Smith, Peter Watkins and especially Helena Mills for invaluable comments on drafts of this article."
    },
    "author_year": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 215,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [],
      "flat_text": "Survival Global Politics and Strategy Survival Global Politics and Strategy Taylor &amp; Francis Taylor &amp; Francis Group ISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden To cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072 To link to this article: https://doi.org/10.1080/00396338.2020.1715072 Published online: 04 Feb 2020.\nSubmit your article to this journal Article views: 1757 View related articles View Crossmark data Citing articles: 5 View citing articles Full Terms &amp; Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=tsur20 # Deterring Cyber Coercion: The Exaggerated Problem of Attribution David Blagden The potential damage from possible cyber attacks is rising as the sophistication of cyber weapons increases.¹ Accordingly, the question of whether such attacks can be deterred is an increasingly salient one for governments, national-security agencies and the populations they seek to protect.² One characteristic of cyber attack, its potential for anonymity, is often taken as an insurmountable barrier to effective deterrence based on retaliatory punishment. But such assumptions are misguided. Coercion is the form of hostile political influence that deterrence seeks to oppose, and in order to coerce, a belligerent must necessarily identify that which it values. Attempted coercion thereby serves as a preference-revelation mechanism. Even if a belligerent can escape identifying itself via anonymous cyber attack, it cannot escape identifying interests that it holds dear, which can then be held at risk by those seeking deterrence.\nThe political interests being advanced by a cyber attack will often make the identity of the aggressor clear, of course, even if the origin of the attack itself cannot be readily traced via technical means.³ While a cyber attack may be technically anonymous, the strategic interaction of which it is a part can make clear whose interests are at stake. Yet many actors could have similar interests, meaning that the specific aggressor might remain unidentified.\nDavid Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute.\nSurvival | vol. 62 no. 1 | February–March 2020 | pp. 131–148 DOI 10.1080/00396338.2020.1715072 David Blagden Such reservations over strategic attribution are overblown, however. This is because they conflate two different variables within the deterrence calculus: aggressor identity and aggressor interests. These variables do often correlate: if you want to retaliate against an attacker's territory, for instance, you need to know whose territory. Yet it is possible to identify valued interests of an attacker without identifying those interests' sole holder. And crucially, coercion is not possible without identifying the interests being advanced, in cyberspace or anywhere else, since the very nature of coercion requires revelation of desired changes in behaviour.⁴ Russia, for example, would not need to identify which specific NATO country cyber-attacked it to still identify – and hold at risk – interests shared by all NATO members. It is therefore possible to retaliate against revealed preferences – to achieve successful strategic attribution of interests – even when strategic attribution of a specific attacker identity remains challenging. Many actors may hold similar interests while only one of them may be responsible for a particular cyber attack, but that need not matter: the very factor that obscures their specific identities (their shared interests) also means that retaliating against those interests will punish the underlying aggressor. The fact that the specific attacker may have ‘gotten away with it’ in terms of not being identified individually will be little consolation when its interests have nonetheless been impaired. And knowing as much beforehand, it is possible for deterrence to hold based on the threat of subsequent retaliatory punishment.\nWhat is the value of such analysis? After all, cyber weapons are ill-suited tools for explicit coercive signalling, since their capability is often unclear prior to their use, and degraded by their revelation insofar as defenders can patch exposed vulnerabilities.⁵ And many categories of hostile cyber action – attrition of an opponent's capabilities, hacking for enjoyment or publicity, covert cyber espionage, cyber-enabled theft, subversion and disinformation, and so forth – are pressing security concerns but do not achieve their effects via the issuance of coercive threats. Also, cyber deterrence has hardly been an unambiguous success thus far; there have been plenty of cyber attacks against states with retaliatory means at their disposal, despite successful culprit attribution and superior relative power. Examples include the 2012 attacks on the US financial system and Saudi Aramco, the 2013 attack on the Sands Casino and the 2014 attack on Sony Pictures. On top of all this, one could question the value of more deterrence theory while empirical scholarship on cyber aggression remains relatively sparse.\nNone of these rejoinders hold water, however. By themselves, cyber threats are indeed flawed tools of coercive signalling. But taken in strategic context, a wide range of hostile cyber actions meet a reasonable definition of coercion: cost imposition in pursuit of behavioural change. If an attacker seeks to coercively exploit a favourably changed balance of power following successful attrition or extortion, if a protester draws attention to a cause in a way that generates coercive political costs, or if cyber espionage delivers information that is utilised coercively in another domain, coercive interests are being advanced. Meanwhile, observed cyber attacks -- those that, for whatever reason, have not been deterred -- are not evidence of the futility of the deterrent enterprise, since defenders' resolve to impose punishment rises with the severity of the attack suffered while the pool of capable‐enough potential culprits shrinks. For example, North Korea going undeterred in its 2014 Sony hack -- a rudimentary and low‐damage attack -- does not mean that deterrence has failed with respect to great‐power use of more capable cyber weaponry against other major states. Lastly, owing to unavoidable selection bias, the empirical study of non‐occurrences will underplay deterrence's causal significance; cyber‐deterrence theory can help offset this imbalance.\n### Escalation dominance and the ‘return address' problem Deterrence is achieved when an actor -- a state, an armed group or an individual -- concludes that the likely costs of an attack exceed the likely benefits. Opponents can be deterred in two ways. Deterrence by denial occurs when a potential aggressor concludes that attack will be ineffective because of the strength of the countermeasures in place: it is denied the opportunity of achieving its coercive objectives. Deterrence by punishment, in contrast, does not promise to diminish an attack's effectiveness, but rests on the threat of retaliation of sufficient magnitude that the aggressor will be worse off than if it had not attacked in the first place: it will be punished after the fact. Deterring or thwarting cyber attack via effective David Blagden denial measures, such as information and communications technology (ICT) hardening and resilience, is of course an important component of effective cyber deterrence. But the focus here is deterrence of those threats that cannot be reliably denied.\nThere is no reason in principle that the use of any new weapon cannot be deterred via the threat of retaliation using the same or alternative weapons systems. To be insusceptible to such 'cross-domain' deterrence – deterrence reliant on the threat of costs imposed in an operational domain other than that in which the original attack occurred – a new weapon would have to possess destructive capability that no other existing weapon could match and be available exclusively to one party. Yet while the second condition may hold for certain cyber weapons given differential rates of development, the first condition will not obtain for cyber capabilities, because nuclear weapons can already impose essentially unlimited costs.[12] Although nuclear retaliation against irritant-level cyber disruption would lack ethical and psychological credibility, the general point is that the risk of escalation to more serious retaliation into different domains raises the potential costs of even low-level attacks – a variant of 'escalation equivalence' logic.[13] A similar logic underpinned Cold War 'tripwire' military deployments. US, British and French garrisons positioned in West Berlin, for example, could not hold the city against the Red Army, but created an unacceptable risk of escalation to general war with NATO's nuclear powers if Soviet forces attacked.[14] The prominence of deterrence by punishment in Western cyber strategy has grown in line with capabilities and understanding. The 2011 cyber-defence strategies of the United States and United Kingdom – the two most capable Western cyber powers – did not mention retaliation, although both referred to deterrence and dwelt extensively on hardening and resilience.[15] Following Edward Snowden's revelations of Anglo-American capabilities, however, both countries have become less reluctant to discuss their full range of options. The 2015 US cyber-defence strategy, for instance, stressed that 'the United States must be able to declare or display effective response capabilities to deter an adversary from initiating an attack', while the 2016 UK strategy has an explicit subsection on offensive capabilities as a component of deterrence.[16] The Western allies have also made it increasingly explicit that cross-domain retaliation is a component of their thinking. Most recently, US posture innovations stemming from the 2018 National Cyber Strategy -- the ‘Cyber Deterrence Initiative' (which aims to bolster retaliatory deterrence through collective alliance responses) and the ‘persistent engagement' doctrine (which contemplates a continuous cycle of tracking and offensive action against emerging cyber threats) -- display yet more emphasis on punishment. There are important questions, discussed later, about whether rising faith in the efficacy of offensive operations -- especially of the pre-emptive variety -- as a response to threatened aggression could itself become an escalatory risk. Yet the fact remains that threatened escalation is already an important component of major powers' responses to emerging cyber threats, and unlikely to be retracted.\nFor effective deterrence via the threat of punishment, however, a potential attacker needs to know there is a significant chance of actually being punished. Assessments of this likelihood focus on the defender's capability and resolve: does the victim of an attack have the incentives, determination and wherewithal to retaliate by imposing a sufficient level of costs? Embedded in the capability half of the equation is a crucial subsidiary question: can the aspiring deterrer target its retaliation in the first place? Absent a ‘return address', no amount of retaliatory firepower will deter if attackers can be confident it will never be directed against anything they value.\nThis is where cyber attack poses a challenge for deterrence. Sophisticated cyber attacks may prove untraceable, even by the most advanced cybersecurity agencies. Masking internet protocol addresses, routing attacks via numerous connected computers (‘bots') that have wittingly or otherwise been turned into a cross-border network, initiating an attack from a cybercafe or public library, hacking and utilising some unsuspecting individual's internet-connected mobile phone, and so forth, may facilitate apparently unattributable cyber attacks. Furthermore, even if the computer used to initiate an attack can be identified, it is a greater challenge to prove who was sitting at it, or on whose orders they acted. The ongoing state-versus David Blagden private arms race in encryption technology only intensifies the problem.²⁴ While progress is being made in cyber forensics, technological innovation nevertheless appears unlikely to render all cyber attacks traceable in the near future.²⁵ Crucially, however, cyber attacks are not actually as anonymous as their technical characteristics might imply, and so do not enjoy the immunity from targeted retaliation that is often feared.\n## The coercive revelation of preferences Key research in cyber deterrence and coercion is united around the pivotal importance of attribution. For Thomas Rid and Ben Buchanan, ‘attribution is fundamental: almost any response to a specific offence – law enforcement, diplomatic, or military – requires identifying the offender first’.²⁶ Erica Borghard and Shawn Lonergan similarly contend that ‘coercion in cyberspace requires attribution to be effective’, while Martin Libicki reasons that coercion must be visibly associated with the coercer to operate, the logic being that the coercer must identify themselves if they are to cause the behavioural change they desire.²⁷ These assessments are aligned with seminal early analyses of the role of punishment in deterrence, which treated the existence of an identified enemy against which retaliation could be directed as a baseline assumption.²⁸ Such orthodoxies, however, obscure a vital distinction in the logic of punishment, with substantial implications for the cyber-deterrence debate. Retaliatory punishment is about imposing costs on political, economic and social interests – populations, cities, forces, wealth, status and anything else from which the attacker derives utility. The specific identity of the attacker is not an interest, and has no necessary political content. Of course, many important interests are exclusively associated with a particular identity, usually a state holding territory. Accordingly, deterrence by threatening some package of political, economic and social assets that are located in a particular territory requires the identification of the custodian of that territory. For this reason, the conflation of interests and identities was largely unproblematic in Cold War deterrence: for practical purposes, the interests that each aspiring deterrer sought to hold at risk were synonymous and coextensive with an exclusive identified adversary.\nDeterring Cyber Coercion: The Exaggerated Problem of Attribution While many interests are indeed unique to a specific holder, many others are not. Notwithstanding the Cold War experience, deterrence based on the threat of retaliatory punishment does not inherently require attribution of the attacker's identity, provided relevant interests can be ascertained. A cyber attack is a form of coercion, whereby an actor seeks to impose costs on an adversary to induce it to change its behaviour so that it aligns with the coercer's political, social and economic preferences.[29] To advance a set of political interests via coercion, a coercer at least implicitly identifies those interests by specifying what behavioural change it wants to encourage. Attempted coercion therefore serves as a mechanism of preference revelation.\nSuch preference revelation may make the identity of a cyber coercer clear, even if the cyber attack itself cannot be traced via technical means.[30] If the interests that the cyber coercion seeks to advance align solely with the unique identifiable interests of a particular state or group, then that actor will have identified itself. Similarly, if a cyber aggressor exploits a successful attack via non-cyber means – say, conventional military action while an opponent's command-and-control systems have been taken temporarily offline by a cyber attack[31] – this too may reveal the attacker's identity. Yet even where a specific attacker is not identifiable via these revealed preferences, preference revelation remains useful for deterrence: if there are a dozen possible culprits behind a given cyber attack, the very thing that makes them hard to distinguish – their similar interests – also unifies them. Thus, while the precise identity of the attacker may indeed remain unclear, this still does not preclude an effective counter-value deterrent posture. The interests the coercion seeks to advance can be identified as something the attacker – whoever it was – values, and be held at risk via the threat of retaliation.[32] The most high-profile cyber attack to date represents a key example of interest attribution in the absence of specific attacker identification. Iran did not need state-of-the-art cyber forensics to have a good idea that the Stuxnet attack on its nuclear facilities uncovered in 2010 was launched by Israel, the United States or one of those two states' allies. While more than one technically capable actor had an interest in retarding Iran's nuclear programme, David Blagden making it impossible to identify the specific attacker based on desired behavioural change alone, there were interests common to all possible attackers – the security of the United States' Middle Eastern allies – that Iran could have held at risk to achieve deterrence. Stuxnet was not an attack of explicit coercive signalling, of course; it was covert attrition, intended to degrade a capability. Nevertheless, that attrition was then exploited coercively in non-cyber domains and, once discovered – as it was always likely to be – the interests of its perpetrators were not hard to discern even if specific attacker identity remained opaque. The principal barrier to Iran's achieving deterrence was not the anonymity of the cyber attack, but its military inferiority and associated paucity of sufficiently credible retaliatory options. Cyber attacks on Estonia (2007), Georgia (2008), Finland (2013) and Ukraine (2014) – strategically attributable to Russia, even if technical attribution remained challenging – reflected the failure of deterrence for similar reasons. Beyond such observed incidents, however, the cyber attacks contemplated but not conducted due to the likely costs of potential retaliation would be the most probative indicators of effective deterrence of cyber attacks via the threat of retaliation. Yet such cases remain by definition largely unobservable.\n## Caveats and qualifications On balance, there are grounds for optimism about prospects for deterring cyber attacks via both cyber and non-cyber retaliatory means, at least by countries powerful enough to threaten meaningful costs. Five broad caveats, however, counsel against wholesale reliance on counter-value deterrence.\nFirstly, cyber attacks conducted by individuals solely to disrupt, without intending to change behaviour, are unlikely to be amenable to deterrence. Since such individuals would not be seeking to advance a political purpose, they would have no identifying cause and could thus be genuinely anonymous. The same may be true of those who hack solely to bring private information to public attention.[33] It may also be true of those who hack solely for financial enrichment, absent any higher coercive purpose. Fortunately, hackers in these three categories are less likely to command the resources needed for cyber attacks causing mass destruction or large-scale casualties.[34] Deterring Cyber Coercion: The Exaggerated Problem of Attribution Secondly, deterrence by denial (hardening ICT systems) may have less severe humanitarian consequences than deterrence by punishment, thereby suffer fewer credibility gaps, and therefore be preferable for both practical and moral reasons.[35] That said, deterrence by denial can also fail if perceived as non-credible, in which case the threat of punishment may achieve what the threat of denial cannot.[36] Relatedly, much malicious cyber activity constitutes an irritating nuisance rather than an act of war,[37] so aspiring deterrers will have to weigh their desire to deter major attacks against their desire to avoid dangerous escalation over minor infringements.[38] Aspiring deterrers thus have to decide the level at which to set their retaliation threshold, how to gradate it and how explicitly to declare it.[39] The upshot is that deterrence via threat of retaliatory punishment should be viewed as complementary to deterrence by denial.[40] Thirdly, a particularly effective cyber attack could neutralise its target's cross-domain capability to retaliate, which would obviously undermine deterrence by retaliation.[41] Such an attack would be hard to achieve.[42] Still, the prospect of a pre-emptive cyber attack that removed subsequent retaliatory capability could become a perilous source of crisis instability.[43] Among recent Western posture innovations, the Cyber Deterrence Initiative – reflecting Washington's goal of coordinating retaliation against cyber attack among its allies – aims to bolster second-strike credibility and therefore increase stability. But persistent engagement – embodying Washington's stated intention to pre-empt possible hostile cyber action – could cut the other way, incentivising US adversaries to strike first rather than risk waiting to be forcibly disarmed.\nFourthly, relying on deterrence that infers targets for retaliation via technically anonymous aggressors' coercive goals poses the risk that devious third parties will try to trick their enemies into mutual conflict by framing them through false-flag operations.[44] If Russia decided that its strategic interests would be served by China and the United States' weakening each other militarily, for example, it might conduct a technically anonymous cyber attack on US forces in Asia that seemingly benefitted China – or even one with ostensibly Chinese technical characteristics – leading Washington to believe Beijing was commencing hostilities against its regional interests. This could provoke swift US retaliation and equally swift Chinese escalation David Blagden owing to each side's fear of losing first-move advantages.⁴⁵ Moreover, even without the successful framing of an innocent party as the target for misdirected retaliation, false-flag operations may sow doubt and preclude effective retaliation, undermining the credibility of punishment threats.\nThis problem is context-specific and surmountable, however. Between two parties with a less offence-dominant strategic relationship than the contemporary US-Chinese situation is often taken to be⁴⁶ – and even that is contestable on the cyber front⁴⁷ – a dearth of first-move advantages could allow scope for diplomatic consultation over the origin of the attack.⁴⁸ If the framed aggressor repudiated the coercive goals that appeared to point in its direction, consciously and visibly eschewing the potential benefits of the apparent coercion, it would credibly signal that it was not to blame.⁴⁹ For example, if a party that appeared to benefit from a cyber attack on another state's internet-connected military logistics chain refrained from taking offensive conventional action even while the attack victim's forces were immobilised by the attack's effects, that would be a costly – and thus credible – signal of restraint. The third party attempting such framing would then itself be in a perilous situation: if its own subversive agenda were uncovered, the two parties it had attempted to trick could retaliate in concert.⁵⁰ Thus, third-party framing is not a risk-free option, and the threat could be minimised if potential cyber adversaries pursued deterrent postures that downplayed first-move advantages. Indeed, the major powers have already done so at the top rung of the escalatory ladder by way of establishing survivable nuclear arsenals. Similarly, non-malicious cyber accidents could be falsely construed as attacks.⁵¹ But again, identifying the coercive interests at stake could mitigate the risk of errant retaliation, and the repudiation of the coercive benefits would duly signal blamelessness.\nFinally, recognising that cyber coercion will always seek to advance some set of interests does not mean that discerning such interests will be easy. Coercers, to be sure, will often want to be correctly identified so as to maximise the clarity of intended signals.⁵² But many potential cyber attackers may instead prefer to achieve their strategic goals via covert cyber action to avoid possible retaliatory costs and – as discussed throughout – cyberspace is particularly amenable to such concealment and obscuration.⁵³ Deterring Cyber Coercion: The Exaggerated Problem of Attribution Accordingly, those seeking to hold the relevant interests at risk to effect deterrence may have to look at the indirect consequences of the initial cyber attack to isolate the set of interests being advanced. Alternatively, the target of such an attack could hold all of the interests seemingly being advanced at risk – and the more severe the suffered attack, the easier it is to make expansive retaliatory threats credible[54] – removing the necessity of choosing among enemies. Indeed, in retaliating for Stuxnet against Israel (via its Hizbullah and Hamas proxies), the United States (via the 2012 US financial hack) and Saudi Arabia (via the 2012 Saudi Aramco cyber attack), Iran appeared to take this route. Jon Lindsay notes, of course, that punishing many for the crimes of a few can be 'unpopular' and 'illegitimate', and could 'counterproductively embolden' opponents.[55] But with high-enough stakes and enough relative power, illegitimacy, unpopularity and agitated enemies may be a price worth paying to ensure that the underlying culprits are punished.[56] Furthermore, target calculations would also be subject to iterative refinement. For instance, if the potential beneficiaries of the interests ranked as being advanced the most by an attack refused to repudiate the coercive gains, they would effectively certify that those were the interests that should suffer retaliation. By contrast, the repudiation of those gains would signal that a different set of interests than those the attack seemed intended to advance should be held at risk.\n\\* \\* \\* Deterring cyber attacks by threatening to impair the interests they are presumed to advance, as opposed to focusing on identifying a sole attacker, is not without peril. It risks retaliating against innocent states or civilians, which incurs ethical costs and potential blowback, while cross-domain escalation may become dangerously unstable, especially if policymakers become inordinately confident in the efficacy of offensive cyber operations. Nevertheless, the anonymity of cyberspace is not the fundamental obstacle to counter-value deterrence it is often supposed to be, for attempting to coerce via cyber means reveals interests that can be held at risk. Accordingly, as the damage potential of cyber weaponry continues to increase, governments David Blagden and the populations they seek to protect may gain security from the threat of retaliatory punishment. For all of its ethical uncertainties, therefore, this form of deterrence remains the final backstop of major powers' strategic postures, and could constitute as potent an instrument against cyber threats as it has against those in the nuclear and conventional domains.\n## Acknowledgements The author thanks Ben Buchanan, Andrew Futter, Erik Gartzke, Jon Lindsay, Kubo Mačák, Patrick Porter, Simon Smith, Peter Watkins and especially Helena Mills for invaluable comments on drafts of this article."
    }
  },
  "citation_summary": {
    "style": "hybrid",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 26.0,
      "success_occurrences": 26.0,
      "success_unique": 25.0,
      "bib_unique_total": 112.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.22321428571428573,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 31.0,
      "highest_intext_index": 56.0,
      "missing_footnotes_for_seen_total": 0.0,
      "uncited_footnote_total": 31.0,
      "style": "hybrid"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 26.0,
        "success_occurrences": 26.0,
        "success_unique": 25.0,
        "bib_unique_total": 112.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.22321428571428573,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 31.0,
        "highest_intext_index": 56.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 31.0,
        "style": "hybrid"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 5.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 215.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "Deterring Cyber Coercion: The Exaggerated Problem of Attribution",
    "subtitle": "To cite this article: David Blagden (2020) Deterring Cyber Coercion: The Exaggerated Problem of Attribution, Survival, 62:1, 131-148, DOI: 10.1080/00396338.2020.1715072",
    "document_type": "journal_article",
    "venue": "ISSN: 0039-6338 (Print) 1468-2699 (Online) journal homepage: www.tandfonline.com/journals/tsur20",
    "publication_year": 2020,
    "authors": [
      "Survival Global Politics",
      "Global Politics",
      "Francis Group",
      "David Blagden",
      "View Crossmark data"
    ],
    "affiliations": [
      "David Blagden is Senior Lecturer in International Security at the University of Exeter's Strategy and Security Institute."
    ],
    "emails": [],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [],
    "publication_dates": {
      "published": "04 Feb 2020",
      "online": "04 Feb 2020"
    },
    "identifiers": {
      "doi": [
        "10.1080/00396338.2020.1715072"
      ],
      "issn": [
        "ISSN: 0039-6338"
      ],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "www.tandfonline.com/journals/tsur20",
        "https://doi.org/10.1080/00396338.2020.1715072",
        "https://www.tandfonline.com/action/journalInformation?journalCode=tsur20"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 56,
    "heading_count": 7,
    "max_heading_level": 3,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 26,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 1.0,
      "unique_index_count": 25
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "hybrid",
      "recommended_style": "numeric",
      "aligned": true,
      "signals": {
        "superscript_hits": 19,
        "superscript_definition_lines": 0,
        "numeric_bracket_hits": 24,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 112.0,
      "dominant_bib_coverage_rate": 0.22321428571428573,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 7,
      "max_heading_level": 3,
      "level_jump_violations": 1,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": false,
        "orcids": false,
        "abstract": false,
        "keywords": false,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 5,
        "affiliations": 1,
        "emails": 0,
        "orcids": 0,
        "keywords": 0,
        "doi": 1,
        "issn": 1,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 3
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_abstract_and_keywords"
      ]
    },
    "flags": [
      "low_bib_coverage",
      "heading_level_jump_violation",
      "meta_missing_abstract_and_keywords"
    ]
  },
  "updated_at_utc": "2026-02-14T08:26:34.852543+00:00"
}