{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\SFJ6BQI8\\Rowe - 2010 - The ethics of cyberweapons in warfare.pdf",
  "custom_id": "425",
  "response": {
    "id": "batch-b6235e9e-426-9b965e27-cce2-4d45-a3ff-957aa283efda",
    "custom_id": "425",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "IGI Global Scientific Publishing Platform\n\nDownloaded: 7/2/2025 11:55:24 AM\n\nIP Address: 82.13.63.56\n\n20 International Journal of Technoethics, 1(1), 20-31, January-March 2010\n\n# The Ethics of Cyberweapons in Warfare\n\nNeil C. Rowe, U.S. Naval Postgraduate School, USA\n\n# ABSTRACT\n\nThe author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement.\n\nKeywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons\n\n# INTRODUCTION\n\nCyberweapons are software used to attack other software or data within computer systems (Bayles, 2001). We distinguish cyberweapons and cyberattacks (attacks using cyberweapons) from \"information warfare\", a more general term that includes propaganda, electronic surveillance, cyber-espionage, and defensive information operations (Jones, Kovacich, &amp; Luzwick, 2002). That is, we will focus on \"network attack\" and not \"network exploitation\" or \"network defense\".\n\nLike conventional weapons, cyberweapons can be used against a variety of targets in a variety of circumstances with a wide range of lethality (White Wolf Security, 2009). Often\n\nCryptography © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\n\ncyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects (Libicki, 2007). Furthermore, unlike chemical, biological, and nuclear weapons, people have no visceral fear of cyberweapons for reasons like health consequences. But maybe they should. All weapons can have serious harms by virtue of their being weapons. The public is unaware of the degree to which they depend on computer systems and the information they store, and thus weapons targeting them can have many unforeseen consequences. For instance, targeting a country's Internet service providers can prevent goods from being delivered, and cause people to starve or die from lack of necessary medical supplies.\n\nDOI: 10.4018/jte.2010081002",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 1,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 21\n\nThere are several schools of ethics. In this article we will follow a pragmatic approach derived from utilitarian ethics in which we argue that a technology is unethical if it has a significant net harm to world society (“negative utilitarianism”). We would also like to derive ethical principles of using cyberweapons, so we will follow “rule utilitarianism”. Such principles can then be codified in laws of warfare. However, we do not need an elaborate ethical foundation here because most of the ethical issues with cyberattacks seem similarly problematic under any ethical framework.\n\n# THE STATE OF THE ART IN CYBERWEAPONS\n\nMilitary organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare (Denning, 1999). Many of these techniques exploit flaws in software. Certain kinds of errors such as failure to check for buffer overflows in loops or failure to properly label data on Web sites can lead to granting of unauthorized special privileges to users of a system. Cyberweapons are programs that package a set of such exploits against a computer system and its data. Cyberweapons can be launched or controlled either externally, from another computer or the Internet, or internally, by spies and saboteurs (Knapp &amp; Boulton, 2007).\n\nCyberattackers can use their access and privileges to destroy the data and software on a computer system or network, but that is pretty obvious and tells the victim they have been attacked. Cyberattackers can modify the data on a victim system to impede military operations, but that requires a good deal of contextual knowledge about the data. So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits” (Kuhnhauser, 2004). Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user (Bailey et al., 2009). Hacker botnets have been used to earn money by sending spam or phishing email from the slave computers, have been used for denial-of-service attacks against organizations the attacker does not like, have been used for blackmail of organizations by threatening malicious mischief, and have been used for espionage. Botnets developed for military purposes could stop an adversary’s military organization from communicating or defending itself.\n\nCyberweapons can be an innocent-looking software module. Running them to see what they do is not easy because many require passwords to run and their effects may be very subtle. Thus it is difficult to identify cyberweapons within a computer system. Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents” (Ceruti, 2001). And when they have served their purpose, they can be deleted. This makes it considerably harder to police cyberweapons than nuclear, chemical, and biological weapons. Nonetheless, traces of a cyberattack will be visible on the victim’s computers and networks, and range of methods of “computer forensics” (Mandia &amp; Prosise, 2003) can analyze these traces.\n\nCyberweapons can attack many kinds of military targets. An obvious one is an adversary’s “command and control”, their communications and electronic mail, because these are essential to organizing a defense. Since command-and-control tools are distributed across many machines, there are many potential entry points for an attack. Weapons-controlling and vehicle-controlling software are also desirable targets of cyberweapons, but they are harder to attack because they are carefully protected and often (especially for weapons) do not use networks much. Logistics and supply could be targeted, but effects would not be immediate, and surprise is a key element of cyberattack effectiveness. Managerial support for the military could be targeted, because its protections tend\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 2,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\n\nto be less, but again the effects would not be immediate, and troops can fight without managers. Public relations (like Web sites) might be a good target, because public perception is so much a part of winning a war, but the damage would only be psychological.\n\nCyberattacks may be coupled to conventional military attacks, and this may enhance the effectiveness of both. For instance, China claims sovereignty over the island of Taiwan, but Taiwan has formidable defenses and the support of the U.S. Navy. If China were to attack, they would need all the resources they could muster, and a simultaneous cyberattack could be very helpful considering the heavy reliance of the U.S. Navy on software and digital data.\n\nCyberattacks can also target a country's important civilian infrastructure such as its Internet sites, its financial services sector, its power grid, or even the common software it uses. The Department of Homeland Security in the United States studies this kind of threat. Attacks on nonmilitary targets are generally outlawed by the international warfare conventions, with exceptions for strong military necessity. They are not guaranteed to succeed because there is considerably less centralization in the civilian sector than there is in military organizations, and it can be hard to hit enough targets to achieve the effect of a conventional military attack. They are thus not the first choice of military commanders because the commanders' biggest concern is preventing counterattacks, and they will get them unless they primarily target a country's military. Terrorists might be more likely to choose civilian targets for cyberattacks because terrorist organizations are hard to find and track. Nonetheless, a terrorist organization needs to do public relations for recruitment, needs to acknowledge attacks to gain a public-relations benefit, and needs to maintain a communications network, and this provides a start in tracking them down.\n\nCyberweapons development has been reported in several major countries in the last few years. Most reports have focused on China which has ambitious goals for military operations in cyberspace, but other countries with\n\nsoftware expertise such as Russia have also been mentioned. The United States military does not like to lag technologically behind anyone; recent announcement of a U.S. Air Force \"Cyberspace Command\" (24th Air Force Command) suggests the United States is now investigating these weapons in secret work. Cyberweapons need not be confined to advanced countries, however, because the technology for developing them does not require much capital investment. It does require expertise in software, which limits their development in countries with poor educational systems. Cyberweapons do not currently seem to be an interest of terrorist groups. They could be (Verton, 2003), but it seems unlikely in the near future since most groups today are anti-technology or, like Al Qaeda, forced to avoid technology to avoid being tracked.\n\n# LAW FOR CYBERATTACKS\n\nCyberattacks using cyberweapons are activities that would classified as crimes in their victim countries if done by ordinary citizens. Necessarily they involve trespassing; to be effective they must employ fraud and vandalism; and often they must also involve espionage, sabotage, and virtual assaults. In many cases they violate international war conventions as well (Arquilla, 1999). While enforcement of international laws of war has been inconsistent, enforcement has been increasingly successful in recent years, so they should be taken seriously.\n\nA particularly troubling issue with cyberattacks is their frequent use of identity deceptions of various kinds, such as by the concealed modifications of an operating system done by rootkits, or the masquerading as legitimate users to gain access. This brings cyberattacks often close to perfidy, a war crime outlawed by international law. Perfidy is attackers masquerading as a legitimate civilian activity, such as soldiers pretending to be Red Cross workers. Perfidy is considered unacceptable in war because it blurs the distinction between combatants and noncombatants, and encourages attacks on civilians. It is certainly fair for combatants to\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 3,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 23\n\nuse camouflage. But an operating system is essential to use a computer, so compromising it and turning it into a computer-virus delivery tool is like putting a poison in a community’s water system. The argument for perfidy is strongest for the critical parts of an operating system for enforcing access controls, the “kernel”, since everyone relies on them and there is no legitimate reason to tamper with them. Other possible candidates for perfidy are tamperings with the key networking software such as routers and as TCP/IP protocols since they are essential for many cyberspace activities.\n\nIf someone damages a computer or data, the owner of the computer or data can sue the attacker in civil legal proceedings in many countries. This may apply to cyberattacks. If the victims are sufficiently widespread within a country, the country as a whole may be able to sue the attacker, even if it is another country, using international tort law. Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare (Walzer, 1977; Nardin, 1998) and many of the ideas extend to cyberweapons. Unethical behavior can be punished by activities like cyber-blockades as discussed below.\n\nA possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease (Lederberg, 1999). These have been banned by international convention because they affect military and civilian personnel equally and are difficult to target exclusively to military personnel. Targeting is difficult because biological agents can spread unpredictably due to wind, contacts, and normal biological processes. Perhaps the best analogy to cyberweapons is that of biological warfare against crops (Whitby, 2002), banned by the Biological and Toxin Weapons Convention of 1972. Crops are necessary resources that everyone in society needs, and are societal infrastructure. Attacking them is akin to terrorism.\n\nAnalogously, cyberwarfare does not target military personnel directly but only their software and data. But usually cyberattacks will be effective against any computer with the same type of vulnerable software. Military\n\norganizations use mostly software that is also used by civilians. So civilian computers could also suffer from military cyberattacks; in fact, they are usually more vulnerable because their countermeasures are not as good. If an attack on a military target goes astray, or if an attack propagates from a military target, civilian computers can easily be damaged. Or it may be tempting for a nation with cyberweapons to deliberately attack civilian computers and networks to cripple the economy of a target country, even though this violates international law. The Allies in World War II deliberately targeted civilian centers with bombing because they thought it would end the war more quickly.\n\n# RELIABILITY AND EFFECTIVENESS\n\nOne important difference between cyberattacks and conventional military attacks is in the reliability and effectiveness of the attack. If you fire a bullet at a target, it is highly likely to arrive there. If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet (Neumann, 1995). For another, the attack design itself may be faulty, the attack may not be able to find the target, or the target may not be vulnerable to the attack because assumptions made about it are no longer valid. Computers and software can be precise and highly controllable tools, so why cannot cyberweapons be made precise and controllable too?\n\nSome of the reason is the nature of warfare. To defend yourself, you need to hide and harden your assets. Military computers and software are known targets of adversaries, and governments try to limit their use to authorized personnel by passwords, encryption, enumerated access rights, and other access controls. Military systems are often on special networks behind layers of firewalls, or left unconnected to networks as in the case of weapons systems. System configurations like IP addresses can be changed periodically to foil overly specific\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 4,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\n\nattacks, and decoy machines and “honeypots” (attack-data gathering machines) can divert an adversary and collect data about them. Network and system logging can track who is using systems and how, so abnormal usage can be caught quickly. Targeting is not as precise as is believed with conventional weapons anyway, as discussed in (Bissett, 2004). So cyberweapons are likely to be unreliable, and “surgical strikes” are unlikely in cyberspace.\n\nA contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability (Dunnigan, 2003). This is because new technology is usually complex and many things can go wrong. Software technology in particular permits implementation of very complex mechanisms. An exacerbating factor is that cyberweapons are poorly understood by military commanders since few have expertise in software. This means that commanders will tend to use cyberweapons, more than regular weapons, against the wrong targets in the wrong circumstances to achieve the wrong goals.\n\nWill cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable (Neumann, 1995). More specifically, cyberattacks depend on the novelty of their methods and secrecy to enforce it (as we discuss below). There are a limited number of attack methods and they generally can be used only once. So attackers will chronically suffer from inability to practice their attacks, and this will hurt their effectiveness.\n\n# THE RISK OF COLLATERAL DAMAGE IN CYBERSPACE\n\n“Collateral damage” or accidental harm to civilians is a key issue in both ethics and laws of warfare. Unfortunately, it is quite possible for cyberattacks aimed at military targets to accidentally hit civilian targets due to their unreliability and uncontrollability. One factor is that it can be hard to distinguish a military computer from a civilian computer. The localization of the target in physical space and\n\nidentification from its appearance that help so much in conventional warfare have no counterpart in cyberspace. Cyberspace addresses can be spoofed so one site can masquerade as another. Military organizations often use the same operating systems, bookkeeping, word-processing, and presentation software as businesses because it saves money (Jones, Kovacich, &amp; Luzwick, 2002), so examining the software may not indicate a military system. Most military files and data look just like files and data from any large civilian business, since most of both are undecipherable without knowing a good deal of specific jargon. (Some specialized sites can be more easily recognized, such as those controlling power plants, but they are well protected.) Within a military site, it may be hard to distinguish information about humanitarian activities such as hospitals and disaster relief from warfare information, so there could be intrasite collateral damage too; on a battlefield, it is easy to distinguish a tank from a Red Cross truck. Although many military computers have military network names and addresses, they could be camouflaged with a civilian name or address to reduce the chances of an adversary finding it (although it is harder in the U.S. where military site names all end in “.mil”). A clever adversary might also camouflage a civilian computer as a military one to provoke an adversary to attack it in the hope of provoking international outrage.\n\nSecondly, because of the difficulty of reaching military targets for a network-based attack or management of an internal attack, it is tempting to use other systems as “stepping stones” which the cyberattack subverts in a chain to reach the target machines. It is appealing to use civilian machines as stepping stones because many (like home computers) have minimal security. Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries (Himma, 2004).\n\nThirdly, even if a civilian computer is not initially attacked, an attack may spread to it. Some cyberattacks use computer viruses and worms that can propagate from one computer\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 5,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 25\n\nto another. Most other cyberattacks have some ability to spread from their original targets because targeting mistakes can be made or defensive surprises may occur. And some attacks like denial-of-service ones require propagation to work. But propagation abilities also make it easier for attacks to spread from military machines to civilian machines. The ubiquity of the Windows operating system and much of the same software on both military and civilian machines facilitates attack spread.\n\nFourthly, technologically developed countries provide the best targets for cyberweapons because they have so many things to attack. But cyberweapons require considerable technical expertise to develop, and such expertise is only readily available in the most technologically developed countries. This means an attack by a less technologically developed country is more likely to go astray and attack civilians, or perhaps be more likely to be deliberately targeted to do so because civilians are easier targets.\n\n# DAMAGE ASSESSMENT\n\nAn issue exacerbating the collateral damage problem with cyberweapons is the difficulty of determining what they did. When aircraft bomb a target, much damage can be seen from the air. With cyberweapons, the damage is not directly visible, which makes it more persistent and costly. Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first (Borg, 2005). Attacks may also fail for a host of unforeseen reasons; (Libicki, 2007) likens information warfare to introducing noise into a military organization, and the organization may or may not succeed at handling it.\n\nThis has important consequences for both the victim and the attacker. It may be hard for the victim to know if they have been attacked. The effects of an attack may be subtle, as when a worm slows down normal operations without changing anything else. Then the harm may persist for a long time because no one realizes anything is wrong. Or the effects may be time-\n\ndelayed, as when a virus in a defender’s weapons system causes it to fail only during combat. Then it may be difficult to find the cause, the harm will also persist until it is found, and repair may be costly. It would be foolish for an attacker to use an attack known to antivirus, antiworm, or antispyware tools, so we can assume such tools will be useless in finding or repairing damage from such attacks. While there are techniques for “system restoration” from backup storage media (Dorf &amp; Johnson, 2007), they are time-consuming and require expertise, and may not be able to restore important data unless backup has been highly diligent. And the original vulnerabilities that enabled the attack need to be found and fixed (“patched”) to prevent new attacks of the same kind, something that requires research and knowledgeable systems personnel. Less advanced countries may not have anyone with the necessary skills to do these things, leading to long-persistent damage much like that of landmines and chemical toxins that get into the water supply.\n\nFor the attacker, it may be very hard to know if their cyberattack had an effect. They may overcompensate by launching an unnecessarily powerful attack to be sure of an effect, or they may attack repeatedly unnecessarily. They may attack unnecessarily many kinds of software or data, and they may do unnecessarily drastic modifications to it. Unnecessarily strong attacks that are deep may be unnecessarily difficult to repair, and unnecessarily strong attacks that are broad run a higher risk of collateral damage to civilians. Unnecessarily strong attacks are particularly a danger for cyber-counterattacks, as we will discuss, because an adversary is anticipating counterattacks.\n\n# SECRECY OF CYBERWEAPONS\n\nAs mentioned, most cyberattacks exploit bugs or flaws in software. If the victims knew of these, they would have fixed them. So secrecy of attack methods is essential to the success of most cyberweapons.\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 6,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\n\nThis secrecy by itself can be unethical. Secrecy makes it harder for victim countries to figure out what happened to them. Standard attack-intelligence resources like Computer Emergency Response Teams (CERTs) collect information about known vulnerabilities, but cannot provide much help for cyberattacks used in warfare because the vulnerabilities will likely be new. This exacerbates the problem of diagnosis and repair discussed above. Also, misinformation about poorly-understood attacks may spread far in a crisis, creating overreaction and panic in the victim country. Misunderstanding can lead to scapegoating of innocent countries or groups, much as terrorist acts tend to be blamed on a country's known adversaries. It will be essential for information-security experts to provide dispassionate technical analysis of what has occurred, perhaps with neutral experts from an international agency.\n\nSecrecy also has negative consequences for the society that uses it (Bok, 1986). It encourages those who know the secrets to think they are better than those that do not, and permits those responsible for foolish attacks to avoid blame. Secret weapons are harder to test, since testing cannot be done publicly, and without adequate testing it is more likely that they will fail or cause collateral damage. An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once (Ranum, 2004). Once they are used and they create some military effect, computer-forensics methods can usually figure out what happened. Then a solution—fixing a bug, disabling software, turning off a utility, or blacklisting a site—can often be found in a day or so, and often a good solution will prevent similar attacks of the same type as well. This means that cyberweapons provide a poor return on investment, since exploitable flaws in software require considerable work to find. They are like a type of bomb that can only be used once anywhere in the world and never any bomb of that type again. It appears ethically unjustifiable for a society to spend resources on developing cyberweapons when there are so many other more useful things they could spend money on.\n\n# CYBER-COUNTERATTACKS\n\nInternational law prohibits attacks on other countries unless a country is attacked first (Walzer, 1977). Countries must agree to this in signing the United Nations charter; in the United States, the charter was a treaty approved by the U.S. Senate, and thus has the same force as any other law of the U.S. So unprovoked cyberattacks are clearly illegal and unethical. But what about cyber-counterattacks?\n\nIt is more difficult to prove responsibility for a cyberattack than for a conventional attack, since it is hard to trace from where it came. The apparent source may be \"spoofed\" by illicit modification of source-identification data, the apparent source may just be a \"stepping-stone\" as discussed earlier, and networks sites do not always keep good records. Even if we can trace an attack, the evidence is highly technical. This makes it hard to justify a counterattack to world public opinion.\n\nIn addition, a serious technical problem of cyber-counterattacks is the preparation and experimentation time necessary to set up good ones. If the cyber-counterattacks are from within a system, time is needed to establish a foothold on that system and station attack software on it. It will be unlikely that an attacker will succumb to the same attack they themselves launched – they should have plenty of time to harden their systems against it. In fact, an attacker should take special pains to harden their systems against all attacks, since counterattacks are sanctioned by international law. A smart attacker could even terminate all their network connections to the rest of the world for a time after an attack to markedly reduce the chances of an externally launched counterattack or exploitation of an internally launched one. Or they could put all their operating systems into hardware to prevent modification by Trojan horses and other exploits. So it will not be easy to launch a successful counterattack, and some considerable\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 7,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 27\n\nnumber of tries by the counterattacker with many methods may be necessary to find one that works, if one can be found at all.\n\nThese issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack (Gardam, 2004). Legitimate counterattacks cannot wait years (such as the claim that the 2001 attack on the New York World Trade Center was a response to the U.S.-Iraq war of 1991), cannot use some quite different technology (as the introduction of poison gas by the Germans in 1915), and cannot be considerably larger. Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical (Fotion and Elfstrom, 1986).\n\nOne way to facilitate counterattacks is to station counterattack software in advance of attack, and channels to communicate with it like those of botnets, on computer systems of adversaries just in the chance there might be hostilities which could use it. Then they might be invoked quickly. Such capabilities could deter an adversary attack in the first place, if the adversary knows or cares about those capabilities (deterrence does not always work well as a military strategy). However, designing counterattacks that will work when needed is not easy. Just because they worked in the laboratory against fixed targets does not provide much confidence they will work during warfare, a problem that occurs in testing much new military technology. Computer systems are installing new protections all the time, so possible attack methods can become obsolete without warning. That means that the older an attack is, the less likely it is to work. Counterattack software is identical to attack software, so it is just as criminal to use in most countries, and just as hard to test in realistic warfare conditions. Furthermore, a hasty counterattack may harm the counterattacker more than the attacker because it reveals counterattacker cyberweapons to the attacker and allows them to test how they\n\ncan be defeated, information that they might not be able to obtain otherwise.\n\nA way to reduce counterattack obsolescence is to use a broader \"strategic\" counterattack rather than a tactical one. An example would be modifying all the code for a networking protocol used by an adversary by modifying the source for that code in a repository. If all adversary military systems download their code from there, all could be infected from a single source, and the code could function normally until the counterattack. Such methods would be high on the scale of perfidy. But there are difficult practical problems. Adversaries that contemplate attacking other countries will set a high priority on protecting their frequently used software and will use hashes (pseudorandom data reductions) regularly to check for modifications to it. Most software is updated regularly, so the counterattacker would need to repeatedly modify the code with each update. Most updates come directly from software companies and not a military repository, and it would be hard for counterattackers to reach all these sources, and even harder to modify code in transmission. A broad strategic attack is easier to diagnose than a tactical (limited) one because there will be many malfunctioning systems simultaneously; this provides good data for identifying the type of attack and its software locus, so such attacks can be fixed more quickly than those that attack just one system. Finally, a broad counterattack based in common software risks more collateral damage to noncombat functions of computer systems than a more targeted counterattack.\n\nNot all cyber-counterattacks require preparation. Those launched across the Internet can be mounted more easily at any time. Defending against such attacks is, however, the primary focus of the network intrusion-prevention systems which defend most of our network sites, which are kept updated with the latest known attacks. It is difficult, though not impossible, to invent a new attack that will succeed against these formidable defenses. A country could try to \"stockpile\" new such attacks in the interests of its defense, but the effort to find such attacks might quickly be wasted as countermeasures are\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 8,
            "markdown": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\n\nindependently discovered as discussed above. What attacks that do succeed in circumventing the first level of defenses may succumb to second levels of defenses that note anomalous behavior, so they are unlikely to succeed for long once they start attacking. For instance, systematic search for the computers on a local-area network is necessary for precisely targeted attacks, but such searching is obvious to network packet monitoring since normal usage rarely does it. So network-based attacks are quite unreliable, and military commanders dislike unreliable technology. Thus it appears that cyber-counterattacks are infeasible.\n\n# DESIGNING ETHICAL CYBERWEAPONS\n\nDespite the issues raised here, countries will likely continue to develop cyberweapons. Can such weapons be designed and used more ethically? We believe they can, since ethical discriminations can be made today among different kinds of weapons. For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately (Johnson, 1984).\n\nSince controllability is a serious concern with cyberweapons, ethical weapons should use a variety of methods to ensure focused targeting. Propagation via viruses and worms should be minimized. Attacks should focus on a limited set of important targets which should be clearly identified and confirmed during the attack using more than their Internet address. Important civilian systems such as commercial infrastructure should clearly identify themselves as civilian so attacks can know to avoid them.\n\nEthical attacks should also be easily stoppable. If an adversary surrenders, it is unethical as well as against international law to continue attacking and causing damage. This means that all attacks should be under quick control via some mechanism such as an emergency channel so that they can be halted if necessary.\n\nThis may be difficult with automated attacks, and the effects of any attack will likely impede communication. But it is important.\n\nIdentification of the attacker (\"attribution\") should also be a key feature of ethical attacks, much as how uniforms to identify military personnel in warfare. Acting as a soldier while not wearing a uniform is outlawed by international law. So some data associated with a cyberattack should identify who is responsible for an attack. One way is to add a digital signature to data or a program (Mel &amp; Baker, 2000). Several technologies to do this are available, and the best-known is encryption with a private key of a public-private key pair of a hash of the contents. Using a hash means that the public key confirms that the contents were not modified after they were signed. Responsible attackers will find signatures useful because they prove they are responsible for an attack and prevent scapegoating of others. Unattributed attacks are not very useful anyway since attacks are usually a way to force a country to do something, and the victim cannot know what to do unless they know who has attacked them. Signatures also permit the attacker to recognize their own signature on already-attacked systems and avoid reattacking them. Public keys for attack signatures could be kept with international organizations like the United Nations as a form of \"key escrow\" like that proposed for backup on encrypted systems.\n\nNot everyone agrees that attacks should be attributable. Robb (2009) argues that cyberattacks will be ineffective unless that have deniability, like some instances of \"special operations\" using commandos. But if he is right, then all effective cyberattacks are forms of terrorism.\n\nA weakness of signatures is that they might be recognized by defenders and enable them to realize they are being attacked, which might matter with the more subtle attacks. But it will not be easy to recognize attack signatures because many programs today have signatures as a security measure. Also, since they are a function of the contents, their bits will differ when attached to different files or data. However, if\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 9,
            "markdown": "IGI Global Scientific Publishing Platform\n\nDownloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\n\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 29\n\nit is important that a signature be concealed, steganography can be used by the attacker (Wayner, 2002). This is a class of techniques for concealing data inside innocent-looking other data, like concealing code messages in the least-significant bits of pictures.\n\nSince damage persistence is a key problem with cyberweapons, it would be more ethical to use weapons whose damage is easily repairable at the end of hostilities. This is more possible in cyberspace than in conventional warfare. For instance, an attack could encrypt important parts of a victim's system so that they cannot be used until the attacker supplies a key to undo (decrypt) them. Since encryption and decryption do not lose any information, the attack would be completely reversible. This would be an ethical alternative whenever it is impossible for a victim to restore a system from backup. Similarly, an attack could withhold important messages (like orders or email) from a victim. If the attacker saves those messages, they could be supplied to the victim at the cessation of hostilities, thereby reversing the attack. In both cases, there may be some damage from denial of timely access to data, but this can be minimized if the target systems are chosen carefully.\n\nthan physical blockades. There are alternatives to banks, but there is only one Internet.\n\n# CONCLUSION\n\nMost coverage of cyberweapons has been relatively neutral, referring to cyberweapons as inevitable new weapons technology that can be employed much like any other. Our argument here is that this cyberweapons have a variety of unique problems that impede their effectiveness and ethicality, and that \"cyberpacifism\" should be encouraged. Cyberweapons are less reliable and less controllable weapons than conventional ones, much like biological weapons, and thus a poor choice in warfare. They disproportionately threaten civilians and harm the society that develops and uses them. It is hard to figure out what is happening when cyberweapons are used due to secrecy and the inherent difficulty of analyzing cyberspace, and their employment for counterattacks seems particularly challenging. While some ways of using cyberweapons are better than others, there are currently insufficient incentives to use them ethically. Their use should be outlawed.\n\n# ACKNOWLEDGMENT\n\nThe views expressed are those of the author and do not represent those of any part of the U.S. Government.\n\n# REFERENCES\n\nArquilla, J. (1999). Ethics and information warfare. In Z. Khalilzad, J. White, &amp; A. Marsall (Eds.), Strategic appraisal: the changing role of information in warfare (pp. 379-401). Rand Corporation, Santa Monica, CA, USA.\n\nBailey, M., Cooke, E., Jahanian, F., Xu, Y., &amp; Karir, M. (2009, March). A survey of botnet technology and defenses. Proc. Conf. for Homeland Security: Cybersecurity Applications and Technology.\n\nBayles, W. (2001). Network attack. Parameters. US Army War College Quarterly, 31, 44-58.\n\n# OTHER CYBER-MEASURES\n\nThere are many alternatives to the use of cyberweapons such as negotiation and conventional weapons. Even within the cyberspace realm, there are nonviolent alternatives. Publicizing a cyberattack may elicit sympathy and support for a victim country, and may make a counterattack unnecessary; if it cannot do so, a counterattack is probably inadvisable. \"Cyber-blockades\" may also be effective responses to cyberattacks. Much as with methods to impede financing of terrorists (Biersteker &amp; Eckert, 2008), countries can block or disable Internet connections (particularly banking transactions) of the offending country. Traditional blockades and sanctions do not always work, but countries depend so much on their Internet connections that cyber-blockades could be more effective\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 10,
            "markdown": "IGI Global Scientific Publishing Platform\n\nDownloaded: 7/2/2025 11:55:24 AM\n\nIP Address: 82.13.63.56\n\n30 International Journal of Technoethics, 1(1), 20-31, January-March 2010\n\nBerman, P. (2002). The globalization of jurisdiction. University of Pennsylvania Law Review, 151(2), 311–545. doi:10.2307/3312952\n\nBiersteker, T., &amp; Eckert, S. (2008). Countering the financing of terrorism. London: Routledge.\n\nBissett, A. (2004). High technology war and ‘surgical strikes’. [ACM SIGCAS]. Computers &amp; Society, 32(7), 4.\n\nBok, S. (1986). Secrets. Oxford, UK: Oxford University Press.\n\nBorg, S. (2005, November-December). Economically complex cyberattacks. IEEE Security and Privacy, 3(6), 64–67. doi:10.1109/MSP.2005.146\n\nCeruti, M. (2001, March). Mobile agents in network-centric warfare. Proc. 5th International Symposium on Autonomous Decentralized Systems (pp. 243–246).\n\nDenning, D. (1999). Information Warfare and Security. Boston, MA: Addison-Wesley.\n\nDenning, D. (2007). The ethics of cyber conflict. In K. Himma, &amp; H. Tavani (Eds.), Information and computer ethics. New York: Wiley.\n\nDorf, J., &amp; Johnson, M. (2007). Restoration component of business continuity planning. In H. Tipton, &amp; M. Krause (Eds.), Information security management handbook (6th ed.) (pp. 645–1654). CRC Press.\n\nDunnigan, J. (2003). How to make war. (4th ed.). New York: Quill.\n\nFotion, N., &amp; Elfstrom, G. (1986). Military ethics: guidelines for peace and war. Boston: Routledge and Kegan Paul.\n\nGardam, J. (2004). Necessity, proportionality, and the use of force by states. Cambridge, UK: Cambridge University Press.\n\nGutman, R., &amp; Rieff, D. (1999). Crimes of war: what the public should know. New York: Norton\n\nHimma, K. (2004). The ethics of tracing hacker attacks through the machines of innocent persons. International Journal of Information Ethics, 2(11), 1–13.\n\nHollis, D. (2007). New tools, new rules: international law and information operations. In G. David, &amp; T. McKeldin (Eds.), The message of war: information, influence, and perception in armed conflict. Temple University Legal Studies Research Paper No. 2007-15, Philadelphia, PA, USA.\n\nICRC (International Committee of the Red Cross). (2007). International humanitarian law – treaties and documents. Retrieved December 1, 2007 from www.icrc.org/icl.nsf.\n\nJensen, E. (2003). Unexpected consequences from knock-on effects: a different standard for computer network operations? American University International Law Review, 18, 1145–1188.\n\nJohnson, J. (1984). Can modern war be just? New Haven: Yale University Press.\n\nJones, A., Kovacich, G., &amp; Luzwick, P. (2002). Global information warfare. Boca Raton, FL: CRC Press.\n\nKnapp, K., &amp; Boulton, W. (2007). Ten information warfare trends. In L. Janczewski &amp; A. Colarik (Eds.), Cyber Warfare and Cyber Terrorism (pp. 17–25). Hershey, PA, USA: IGI Global.\n\nKuhnhauser, W. (2004, January). Root kits: an operating systems viewpoint. ACM SIGOPS Operating Systems Review, 38(1), 12–23. doi:10.1145/974104.974105\n\nLederberg, J. (Ed.). (1999). Biological weapons: limiting the threat. Cambridge, MA: MIT Press.\n\nLibicki, M. (2007). Conquest in cyberspace: national security and information warfare. New York: Cambridge University Press.\n\nMandia, K., &amp; Prosise, C. (2003). Incident response and computer forensics. New York: McGraw-Hill/ Osborne.\n\nMel, H., &amp; Baker, D. (2000). Cryptography decrypted (5th ed.). Boston, MA: Addison-Wesley Professional.\n\nMolander, R., &amp; Siang, S. (1998, Fall). The legitimization of strategic information warfare: ethical considerations. AAAS Professional Ethics Report, 11(4). Retrieved November 23, 2005 from www.aaas.org/spp/sfrl/sfrl.htm.\n\nNardin, T. (Ed.). (1998). The ethics of war and peace. Princeton, NJ: Princeton University Press.\n\nNeumann, P. (1995). Computer related risks. Reading, MA: ACM Press.\n\nRanum, M. (2004). The myth of homeland security. Indianapolis, IN: Wiley.\n\nRobb, J. (2007). The U.S. and cyberwarfare. Retrieved February 6, 2009 from globalguerrillas.typepad.com/globalguerrillas/2007/12/the-us-and-cyber.html.\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          },
          {
            "index": 11,
            "markdown": "IGI Global Scientific Publishing Platform\n\nDownloaded: 7/2/2025 11:55:24 AM\n\nIP Address: 82.13.63.56\n\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 31\n\nSchmitt, M. (2002). Wired warfare: computer network attack and jus in bello. International Review of the Red Cross, 84(846), 365–399.\n\nVerton, D. (2003). Black ice: the invisible threat of cyber-terrorism. New York: McGraw-Hill Osborne Media.\n\nWalzer, D. (1977). Just and unjust wars: a moral argument with historical illustrations. New York: Basic Books.\n\nWayner, P. (2002). Disappearing cryptography: information hiding: steganography and watermarking. San Francisco, CA: Morgan Kaufmann.\n\nWestwood, C. (1997). The future is not what it used to be: conflict in the information age. Fairbairn, ACT, Australia: Air Power Studies Center.\n\nWhitby, S. (2002). Biological warfare against crops. Houndmills, UK: Palgrave.\n\nWhite Wolf Security. Offensive operations in cyberspace. Retrieved February 6, 2009 from www.whitewolfsecurity.com/publications/offensive_ops.php.\n\nNeil C. Rowe is professor of computer science, U.S. Naval Postgraduate School where he has been since 1983. He has a PhD in computer science from Stanford University (1983), and EE (1978), SM (1978), and SB (1975) degrees from the Massachusetts Institute of Technology. His main research interest is the role of deception in information processing, and he has also done research on intelligent access to multimedia databases, image processing, robotic path planning, and intelligent tutoring systems. He is the author of over 100 technical papers and a book.\n\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2339,
              "width": 1654
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 12,
          "doc_size_bytes": 8407857
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\n20 International Journal of Technoethics, 1(1), 20-31, January-March 2010\n# The Ethics of Cyberweapons in Warfare\nNeil C. Rowe, U.S. Naval Postgraduate School, USA\n# ABSTRACT\nThe author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement.\nKeywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons\n# INTRODUCTION\nCyberweapons are software used to attack other software or data within computer systems (Bayles, 2001). We distinguish cyberweapons and cyberattacks (attacks using cyberweapons) from \"information warfare\", a more general term that includes propaganda, electronic surveillance, cyber-espionage, and defensive information operations (Jones, Kovacich, &amp; Luzwick, 2002). That is, we will focus on \"network attack\" and not \"network exploitation\" or \"network defense\".\nLike conventional weapons, cyberweapons can be used against a variety of targets in a variety of circumstances with a wide range of lethality (White Wolf Security, 2009). Often\nCryptography © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\ncyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects (Libicki, 2007). Furthermore, unlike chemical, biological, and nuclear weapons, people have no visceral fear of cyberweapons for reasons like health consequences. But maybe they should. All weapons can have serious harms by virtue of their being weapons. The public is unaware of the degree to which they depend on computer systems and the information they store, and thus weapons targeting them can have many unforeseen consequences. For instance, targeting a country's Internet service providers can prevent goods from being delivered, and cause people to starve or die from lack of necessary medical supplies.\nDOI: 10.4018/jte.2010081002\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 21\nThere are several schools of ethics. In this article we will follow a pragmatic approach derived from utilitarian ethics in which we argue that a technology is unethical if it has a significant net harm to world society (“negative utilitarianism”). We would also like to derive ethical principles of using cyberweapons, so we will follow “rule utilitarianism”. Such principles can then be codified in laws of warfare. However, we do not need an elaborate ethical foundation here because most of the ethical issues with cyberattacks seem similarly problematic under any ethical framework.\n# THE STATE OF THE ART IN CYBERWEAPONS\nMilitary organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare (Denning, 1999). Many of these techniques exploit flaws in software. Certain kinds of errors such as failure to check for buffer overflows in loops or failure to properly label data on Web sites can lead to granting of unauthorized special privileges to users of a system. Cyberweapons are programs that package a set of such exploits against a computer system and its data. Cyberweapons can be launched or controlled either externally, from another computer or the Internet, or internally, by spies and saboteurs (Knapp &amp; Boulton, 2007).\nCyberattackers can use their access and privileges to destroy the data and software on a computer system or network, but that is pretty obvious and tells the victim they have been attacked. Cyberattackers can modify the data on a victim system to impede military operations, but that requires a good deal of contextual knowledge about the data. So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits” (Kuhnhauser, 2004). Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user (Bailey et al., 2009). Hacker botnets have been used to earn money by sending spam or phishing email from the slave computers, have been used for denial-of-service attacks against organizations the attacker does not like, have been used for blackmail of organizations by threatening malicious mischief, and have been used for espionage. Botnets developed for military purposes could stop an adversary’s military organization from communicating or defending itself.\nCyberweapons can be an innocent-looking software module. Running them to see what they do is not easy because many require passwords to run and their effects may be very subtle. Thus it is difficult to identify cyberweapons within a computer system. Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents” (Ceruti, 2001). And when they have served their purpose, they can be deleted. This makes it considerably harder to police cyberweapons than nuclear, chemical, and biological weapons. Nonetheless, traces of a cyberattack will be visible on the victim’s computers and networks, and range of methods of “computer forensics” (Mandia &amp; Prosise, 2003) can analyze these traces.\nCyberweapons can attack many kinds of military targets. An obvious one is an adversary’s “command and control”, their communications and electronic mail, because these are essential to organizing a defense. Since command-and-control tools are distributed across many machines, there are many potential entry points for an attack. Weapons-controlling and vehicle-controlling software are also desirable targets of cyberweapons, but they are harder to attack because they are carefully protected and often (especially for weapons) do not use networks much. Logistics and supply could be targeted, but effects would not be immediate, and surprise is a key element of cyberattack effectiveness. Managerial support for the military could be targeted, because its protections tend\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nto be less, but again the effects would not be immediate, and troops can fight without managers. Public relations (like Web sites) might be a good target, because public perception is so much a part of winning a war, but the damage would only be psychological.\nCyberattacks may be coupled to conventional military attacks, and this may enhance the effectiveness of both. For instance, China claims sovereignty over the island of Taiwan, but Taiwan has formidable defenses and the support of the U.S. Navy. If China were to attack, they would need all the resources they could muster, and a simultaneous cyberattack could be very helpful considering the heavy reliance of the U.S. Navy on software and digital data.\nCyberattacks can also target a country's important civilian infrastructure such as its Internet sites, its financial services sector, its power grid, or even the common software it uses. The Department of Homeland Security in the United States studies this kind of threat. Attacks on nonmilitary targets are generally outlawed by the international warfare conventions, with exceptions for strong military necessity. They are not guaranteed to succeed because there is considerably less centralization in the civilian sector than there is in military organizations, and it can be hard to hit enough targets to achieve the effect of a conventional military attack. They are thus not the first choice of military commanders because the commanders' biggest concern is preventing counterattacks, and they will get them unless they primarily target a country's military. Terrorists might be more likely to choose civilian targets for cyberattacks because terrorist organizations are hard to find and track. Nonetheless, a terrorist organization needs to do public relations for recruitment, needs to acknowledge attacks to gain a public-relations benefit, and needs to maintain a communications network, and this provides a start in tracking them down.\nCyberweapons development has been reported in several major countries in the last few years. Most reports have focused on China which has ambitious goals for military operations in cyberspace, but other countries with\nsoftware expertise such as Russia have also been mentioned. The United States military does not like to lag technologically behind anyone; recent announcement of a U.S. Air Force \"Cyberspace Command\" (24th Air Force Command) suggests the United States is now investigating these weapons in secret work. Cyberweapons need not be confined to advanced countries, however, because the technology for developing them does not require much capital investment. It does require expertise in software, which limits their development in countries with poor educational systems. Cyberweapons do not currently seem to be an interest of terrorist groups. They could be (Verton, 2003), but it seems unlikely in the near future since most groups today are anti-technology or, like Al Qaeda, forced to avoid technology to avoid being tracked.\n# LAW FOR CYBERATTACKS\nCyberattacks using cyberweapons are activities that would classified as crimes in their victim countries if done by ordinary citizens. Necessarily they involve trespassing; to be effective they must employ fraud and vandalism; and often they must also involve espionage, sabotage, and virtual assaults. In many cases they violate international war conventions as well (Arquilla, 1999). While enforcement of international laws of war has been inconsistent, enforcement has been increasingly successful in recent years, so they should be taken seriously.\nA particularly troubling issue with cyberattacks is their frequent use of identity deceptions of various kinds, such as by the concealed modifications of an operating system done by rootkits, or the masquerading as legitimate users to gain access. This brings cyberattacks often close to perfidy, a war crime outlawed by international law. Perfidy is attackers masquerading as a legitimate civilian activity, such as soldiers pretending to be Red Cross workers. Perfidy is considered unacceptable in war because it blurs the distinction between combatants and noncombatants, and encourages attacks on civilians. It is certainly fair for combatants to\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 23\nuse camouflage. But an operating system is essential to use a computer, so compromising it and turning it into a computer-virus delivery tool is like putting a poison in a community’s water system. The argument for perfidy is strongest for the critical parts of an operating system for enforcing access controls, the “kernel”, since everyone relies on them and there is no legitimate reason to tamper with them. Other possible candidates for perfidy are tamperings with the key networking software such as routers and as TCP/IP protocols since they are essential for many cyberspace activities.\nIf someone damages a computer or data, the owner of the computer or data can sue the attacker in civil legal proceedings in many countries. This may apply to cyberattacks. If the victims are sufficiently widespread within a country, the country as a whole may be able to sue the attacker, even if it is another country, using international tort law. Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare (Walzer, 1977; Nardin, 1998) and many of the ideas extend to cyberweapons. Unethical behavior can be punished by activities like cyber-blockades as discussed below.\nA possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease (Lederberg, 1999). These have been banned by international convention because they affect military and civilian personnel equally and are difficult to target exclusively to military personnel. Targeting is difficult because biological agents can spread unpredictably due to wind, contacts, and normal biological processes. Perhaps the best analogy to cyberweapons is that of biological warfare against crops (Whitby, 2002), banned by the Biological and Toxin Weapons Convention of 1972. Crops are necessary resources that everyone in society needs, and are societal infrastructure. Attacking them is akin to terrorism.\nAnalogously, cyberwarfare does not target military personnel directly but only their software and data. But usually cyberattacks will be effective against any computer with the same type of vulnerable software. Military\norganizations use mostly software that is also used by civilians. So civilian computers could also suffer from military cyberattacks; in fact, they are usually more vulnerable because their countermeasures are not as good. If an attack on a military target goes astray, or if an attack propagates from a military target, civilian computers can easily be damaged. Or it may be tempting for a nation with cyberweapons to deliberately attack civilian computers and networks to cripple the economy of a target country, even though this violates international law. The Allies in World War II deliberately targeted civilian centers with bombing because they thought it would end the war more quickly.\n# RELIABILITY AND EFFECTIVENESS\nOne important difference between cyberattacks and conventional military attacks is in the reliability and effectiveness of the attack. If you fire a bullet at a target, it is highly likely to arrive there. If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet (Neumann, 1995). For another, the attack design itself may be faulty, the attack may not be able to find the target, or the target may not be vulnerable to the attack because assumptions made about it are no longer valid. Computers and software can be precise and highly controllable tools, so why cannot cyberweapons be made precise and controllable too?\nSome of the reason is the nature of warfare. To defend yourself, you need to hide and harden your assets. Military computers and software are known targets of adversaries, and governments try to limit their use to authorized personnel by passwords, encryption, enumerated access rights, and other access controls. Military systems are often on special networks behind layers of firewalls, or left unconnected to networks as in the case of weapons systems. System configurations like IP addresses can be changed periodically to foil overly specific\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nattacks, and decoy machines and “honeypots” (attack-data gathering machines) can divert an adversary and collect data about them. Network and system logging can track who is using systems and how, so abnormal usage can be caught quickly. Targeting is not as precise as is believed with conventional weapons anyway, as discussed in (Bissett, 2004). So cyberweapons are likely to be unreliable, and “surgical strikes” are unlikely in cyberspace.\nA contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability (Dunnigan, 2003). This is because new technology is usually complex and many things can go wrong. Software technology in particular permits implementation of very complex mechanisms. An exacerbating factor is that cyberweapons are poorly understood by military commanders since few have expertise in software. This means that commanders will tend to use cyberweapons, more than regular weapons, against the wrong targets in the wrong circumstances to achieve the wrong goals.\nWill cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable (Neumann, 1995). More specifically, cyberattacks depend on the novelty of their methods and secrecy to enforce it (as we discuss below). There are a limited number of attack methods and they generally can be used only once. So attackers will chronically suffer from inability to practice their attacks, and this will hurt their effectiveness.\n# THE RISK OF COLLATERAL DAMAGE IN CYBERSPACE\n“Collateral damage” or accidental harm to civilians is a key issue in both ethics and laws of warfare. Unfortunately, it is quite possible for cyberattacks aimed at military targets to accidentally hit civilian targets due to their unreliability and uncontrollability. One factor is that it can be hard to distinguish a military computer from a civilian computer. The localization of the target in physical space and\nidentification from its appearance that help so much in conventional warfare have no counterpart in cyberspace. Cyberspace addresses can be spoofed so one site can masquerade as another. Military organizations often use the same operating systems, bookkeeping, word-processing, and presentation software as businesses because it saves money (Jones, Kovacich, &amp; Luzwick, 2002), so examining the software may not indicate a military system. Most military files and data look just like files and data from any large civilian business, since most of both are undecipherable without knowing a good deal of specific jargon. (Some specialized sites can be more easily recognized, such as those controlling power plants, but they are well protected.) Within a military site, it may be hard to distinguish information about humanitarian activities such as hospitals and disaster relief from warfare information, so there could be intrasite collateral damage too; on a battlefield, it is easy to distinguish a tank from a Red Cross truck. Although many military computers have military network names and addresses, they could be camouflaged with a civilian name or address to reduce the chances of an adversary finding it (although it is harder in the U.S. where military site names all end in “.mil”). A clever adversary might also camouflage a civilian computer as a military one to provoke an adversary to attack it in the hope of provoking international outrage.\nSecondly, because of the difficulty of reaching military targets for a network-based attack or management of an internal attack, it is tempting to use other systems as “stepping stones” which the cyberattack subverts in a chain to reach the target machines. It is appealing to use civilian machines as stepping stones because many (like home computers) have minimal security. Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries (Himma, 2004).\nThirdly, even if a civilian computer is not initially attacked, an attack may spread to it. Some cyberattacks use computer viruses and worms that can propagate from one computer\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 25\nto another. Most other cyberattacks have some ability to spread from their original targets because targeting mistakes can be made or defensive surprises may occur. And some attacks like denial-of-service ones require propagation to work. But propagation abilities also make it easier for attacks to spread from military machines to civilian machines. The ubiquity of the Windows operating system and much of the same software on both military and civilian machines facilitates attack spread.\nFourthly, technologically developed countries provide the best targets for cyberweapons because they have so many things to attack. But cyberweapons require considerable technical expertise to develop, and such expertise is only readily available in the most technologically developed countries. This means an attack by a less technologically developed country is more likely to go astray and attack civilians, or perhaps be more likely to be deliberately targeted to do so because civilians are easier targets.\n# DAMAGE ASSESSMENT\nAn issue exacerbating the collateral damage problem with cyberweapons is the difficulty of determining what they did. When aircraft bomb a target, much damage can be seen from the air. With cyberweapons, the damage is not directly visible, which makes it more persistent and costly. Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first (Borg, 2005). Attacks may also fail for a host of unforeseen reasons; (Libicki, 2007) likens information warfare to introducing noise into a military organization, and the organization may or may not succeed at handling it.\nThis has important consequences for both the victim and the attacker. It may be hard for the victim to know if they have been attacked. The effects of an attack may be subtle, as when a worm slows down normal operations without changing anything else. Then the harm may persist for a long time because no one realizes anything is wrong. Or the effects may be time-\ndelayed, as when a virus in a defender’s weapons system causes it to fail only during combat. Then it may be difficult to find the cause, the harm will also persist until it is found, and repair may be costly. It would be foolish for an attacker to use an attack known to antivirus, antiworm, or antispyware tools, so we can assume such tools will be useless in finding or repairing damage from such attacks. While there are techniques for “system restoration” from backup storage media (Dorf &amp; Johnson, 2007), they are time-consuming and require expertise, and may not be able to restore important data unless backup has been highly diligent. And the original vulnerabilities that enabled the attack need to be found and fixed (“patched”) to prevent new attacks of the same kind, something that requires research and knowledgeable systems personnel. Less advanced countries may not have anyone with the necessary skills to do these things, leading to long-persistent damage much like that of landmines and chemical toxins that get into the water supply.\nFor the attacker, it may be very hard to know if their cyberattack had an effect. They may overcompensate by launching an unnecessarily powerful attack to be sure of an effect, or they may attack repeatedly unnecessarily. They may attack unnecessarily many kinds of software or data, and they may do unnecessarily drastic modifications to it. Unnecessarily strong attacks that are deep may be unnecessarily difficult to repair, and unnecessarily strong attacks that are broad run a higher risk of collateral damage to civilians. Unnecessarily strong attacks are particularly a danger for cyber-counterattacks, as we will discuss, because an adversary is anticipating counterattacks.\n# SECRECY OF CYBERWEAPONS\nAs mentioned, most cyberattacks exploit bugs or flaws in software. If the victims knew of these, they would have fixed them. So secrecy of attack methods is essential to the success of most cyberweapons.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nThis secrecy by itself can be unethical. Secrecy makes it harder for victim countries to figure out what happened to them. Standard attack-intelligence resources like Computer Emergency Response Teams (CERTs) collect information about known vulnerabilities, but cannot provide much help for cyberattacks used in warfare because the vulnerabilities will likely be new. This exacerbates the problem of diagnosis and repair discussed above. Also, misinformation about poorly-understood attacks may spread far in a crisis, creating overreaction and panic in the victim country. Misunderstanding can lead to scapegoating of innocent countries or groups, much as terrorist acts tend to be blamed on a country's known adversaries. It will be essential for information-security experts to provide dispassionate technical analysis of what has occurred, perhaps with neutral experts from an international agency.\nSecrecy also has negative consequences for the society that uses it (Bok, 1986). It encourages those who know the secrets to think they are better than those that do not, and permits those responsible for foolish attacks to avoid blame. Secret weapons are harder to test, since testing cannot be done publicly, and without adequate testing it is more likely that they will fail or cause collateral damage. An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once (Ranum, 2004). Once they are used and they create some military effect, computer-forensics methods can usually figure out what happened. Then a solution—fixing a bug, disabling software, turning off a utility, or blacklisting a site—can often be found in a day or so, and often a good solution will prevent similar attacks of the same type as well. This means that cyberweapons provide a poor return on investment, since exploitable flaws in software require considerable work to find. They are like a type of bomb that can only be used once anywhere in the world and never any bomb of that type again. It appears ethically unjustifiable for a society to spend resources on developing cyberweapons when there are so many other more useful things they could spend money on.\n# CYBER-COUNTERATTACKS\nInternational law prohibits attacks on other countries unless a country is attacked first (Walzer, 1977). Countries must agree to this in signing the United Nations charter; in the United States, the charter was a treaty approved by the U.S. Senate, and thus has the same force as any other law of the U.S. So unprovoked cyberattacks are clearly illegal and unethical. But what about cyber-counterattacks?\nIt is more difficult to prove responsibility for a cyberattack than for a conventional attack, since it is hard to trace from where it came. The apparent source may be \"spoofed\" by illicit modification of source-identification data, the apparent source may just be a \"stepping-stone\" as discussed earlier, and networks sites do not always keep good records. Even if we can trace an attack, the evidence is highly technical. This makes it hard to justify a counterattack to world public opinion.\nIn addition, a serious technical problem of cyber-counterattacks is the preparation and experimentation time necessary to set up good ones. If the cyber-counterattacks are from within a system, time is needed to establish a foothold on that system and station attack software on it. It will be unlikely that an attacker will succumb to the same attack they themselves launched – they should have plenty of time to harden their systems against it. In fact, an attacker should take special pains to harden their systems against all attacks, since counterattacks are sanctioned by international law. A smart attacker could even terminate all their network connections to the rest of the world for a time after an attack to markedly reduce the chances of an externally launched counterattack or exploitation of an internally launched one. Or they could put all their operating systems into hardware to prevent modification by Trojan horses and other exploits. So it will not be easy to launch a successful counterattack, and some considerable\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 27\nnumber of tries by the counterattacker with many methods may be necessary to find one that works, if one can be found at all.\nThese issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack (Gardam, 2004). Legitimate counterattacks cannot wait years (such as the claim that the 2001 attack on the New York World Trade Center was a response to the U.S.-Iraq war of 1991), cannot use some quite different technology (as the introduction of poison gas by the Germans in 1915), and cannot be considerably larger. Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical (Fotion and Elfstrom, 1986).\nOne way to facilitate counterattacks is to station counterattack software in advance of attack, and channels to communicate with it like those of botnets, on computer systems of adversaries just in the chance there might be hostilities which could use it. Then they might be invoked quickly. Such capabilities could deter an adversary attack in the first place, if the adversary knows or cares about those capabilities (deterrence does not always work well as a military strategy). However, designing counterattacks that will work when needed is not easy. Just because they worked in the laboratory against fixed targets does not provide much confidence they will work during warfare, a problem that occurs in testing much new military technology. Computer systems are installing new protections all the time, so possible attack methods can become obsolete without warning. That means that the older an attack is, the less likely it is to work. Counterattack software is identical to attack software, so it is just as criminal to use in most countries, and just as hard to test in realistic warfare conditions. Furthermore, a hasty counterattack may harm the counterattacker more than the attacker because it reveals counterattacker cyberweapons to the attacker and allows them to test how they\ncan be defeated, information that they might not be able to obtain otherwise.\nA way to reduce counterattack obsolescence is to use a broader \"strategic\" counterattack rather than a tactical one. An example would be modifying all the code for a networking protocol used by an adversary by modifying the source for that code in a repository. If all adversary military systems download their code from there, all could be infected from a single source, and the code could function normally until the counterattack. Such methods would be high on the scale of perfidy. But there are difficult practical problems. Adversaries that contemplate attacking other countries will set a high priority on protecting their frequently used software and will use hashes (pseudorandom data reductions) regularly to check for modifications to it. Most software is updated regularly, so the counterattacker would need to repeatedly modify the code with each update. Most updates come directly from software companies and not a military repository, and it would be hard for counterattackers to reach all these sources, and even harder to modify code in transmission. A broad strategic attack is easier to diagnose than a tactical (limited) one because there will be many malfunctioning systems simultaneously; this provides good data for identifying the type of attack and its software locus, so such attacks can be fixed more quickly than those that attack just one system. Finally, a broad counterattack based in common software risks more collateral damage to noncombat functions of computer systems than a more targeted counterattack.\nNot all cyber-counterattacks require preparation. Those launched across the Internet can be mounted more easily at any time. Defending against such attacks is, however, the primary focus of the network intrusion-prevention systems which defend most of our network sites, which are kept updated with the latest known attacks. It is difficult, though not impossible, to invent a new attack that will succeed against these formidable defenses. A country could try to \"stockpile\" new such attacks in the interests of its defense, but the effort to find such attacks might quickly be wasted as countermeasures are\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nindependently discovered as discussed above. What attacks that do succeed in circumventing the first level of defenses may succumb to second levels of defenses that note anomalous behavior, so they are unlikely to succeed for long once they start attacking. For instance, systematic search for the computers on a local-area network is necessary for precisely targeted attacks, but such searching is obvious to network packet monitoring since normal usage rarely does it. So network-based attacks are quite unreliable, and military commanders dislike unreliable technology. Thus it appears that cyber-counterattacks are infeasible.\n# DESIGNING ETHICAL CYBERWEAPONS\nDespite the issues raised here, countries will likely continue to develop cyberweapons. Can such weapons be designed and used more ethically? We believe they can, since ethical discriminations can be made today among different kinds of weapons. For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately (Johnson, 1984).\nSince controllability is a serious concern with cyberweapons, ethical weapons should use a variety of methods to ensure focused targeting. Propagation via viruses and worms should be minimized. Attacks should focus on a limited set of important targets which should be clearly identified and confirmed during the attack using more than their Internet address. Important civilian systems such as commercial infrastructure should clearly identify themselves as civilian so attacks can know to avoid them.\nEthical attacks should also be easily stoppable. If an adversary surrenders, it is unethical as well as against international law to continue attacking and causing damage. This means that all attacks should be under quick control via some mechanism such as an emergency channel so that they can be halted if necessary.\nThis may be difficult with automated attacks, and the effects of any attack will likely impede communication. But it is important.\nIdentification of the attacker (\"attribution\") should also be a key feature of ethical attacks, much as how uniforms to identify military personnel in warfare. Acting as a soldier while not wearing a uniform is outlawed by international law. So some data associated with a cyberattack should identify who is responsible for an attack. One way is to add a digital signature to data or a program (Mel &amp; Baker, 2000). Several technologies to do this are available, and the best-known is encryption with a private key of a public-private key pair of a hash of the contents. Using a hash means that the public key confirms that the contents were not modified after they were signed. Responsible attackers will find signatures useful because they prove they are responsible for an attack and prevent scapegoating of others. Unattributed attacks are not very useful anyway since attacks are usually a way to force a country to do something, and the victim cannot know what to do unless they know who has attacked them. Signatures also permit the attacker to recognize their own signature on already-attacked systems and avoid reattacking them. Public keys for attack signatures could be kept with international organizations like the United Nations as a form of \"key escrow\" like that proposed for backup on encrypted systems.\nNot everyone agrees that attacks should be attributable. Robb (2009) argues that cyberattacks will be ineffective unless that have deniability, like some instances of \"special operations\" using commandos. But if he is right, then all effective cyberattacks are forms of terrorism.\nA weakness of signatures is that they might be recognized by defenders and enable them to realize they are being attacked, which might matter with the more subtle attacks. But it will not be easy to recognize attack signatures because many programs today have signatures as a security measure. Also, since they are a function of the contents, their bits will differ when attached to different files or data. However, if\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 29\nit is important that a signature be concealed, steganography can be used by the attacker (Wayner, 2002). This is a class of techniques for concealing data inside innocent-looking other data, like concealing code messages in the least-significant bits of pictures.\nSince damage persistence is a key problem with cyberweapons, it would be more ethical to use weapons whose damage is easily repairable at the end of hostilities. This is more possible in cyberspace than in conventional warfare. For instance, an attack could encrypt important parts of a victim's system so that they cannot be used until the attacker supplies a key to undo (decrypt) them. Since encryption and decryption do not lose any information, the attack would be completely reversible. This would be an ethical alternative whenever it is impossible for a victim to restore a system from backup. Similarly, an attack could withhold important messages (like orders or email) from a victim. If the attacker saves those messages, they could be supplied to the victim at the cessation of hostilities, thereby reversing the attack. In both cases, there may be some damage from denial of timely access to data, but this can be minimized if the target systems are chosen carefully.\nthan physical blockades. There are alternatives to banks, but there is only one Internet.\n# CONCLUSION\nMost coverage of cyberweapons has been relatively neutral, referring to cyberweapons as inevitable new weapons technology that can be employed much like any other. Our argument here is that this cyberweapons have a variety of unique problems that impede their effectiveness and ethicality, and that \"cyberpacifism\" should be encouraged. Cyberweapons are less reliable and less controllable weapons than conventional ones, much like biological weapons, and thus a poor choice in warfare. They disproportionately threaten civilians and harm the society that develops and uses them. It is hard to figure out what is happening when cyberweapons are used due to secrecy and the inherent difficulty of analyzing cyberspace, and their employment for counterattacks seems particularly challenging. While some ways of using cyberweapons are better than others, there are currently insufficient incentives to use them ethically. Their use should be outlawed.\n# ACKNOWLEDGMENT\nThe views expressed are those of the author and do not represent those of any part of the U.S. Government.",
  "references": [
    "# REFERENCES\nArquilla, J. (1999). Ethics and information warfare. In Z. Khalilzad, J. White, &amp; A. Marsall (Eds.), Strategic appraisal: the changing role of information in warfare (pp. 379-401). Rand Corporation, Santa Monica, CA, USA.\nBailey, M., Cooke, E., Jahanian, F., Xu, Y., &amp; Karir, M. (2009, March). A survey of botnet technology and defenses. Proc. Conf. for Homeland Security: Cybersecurity Applications and Technology.\nBayles, W. (2001). Network attack. Parameters. US Army War College Quarterly, 31, 44-58.\n# OTHER CYBER-MEASURES\nThere are many alternatives to the use of cyberweapons such as negotiation and conventional weapons. Even within the cyberspace realm, there are nonviolent alternatives. Publicizing a cyberattack may elicit sympathy and support for a victim country, and may make a counterattack unnecessary; if it cannot do so, a counterattack is probably inadvisable. \"Cyber-blockades\" may also be effective responses to cyberattacks. Much as with methods to impede financing of terrorists (Biersteker &amp; Eckert, 2008), countries can block or disable Internet connections (particularly banking transactions) of the offending country. Traditional blockades and sanctions do not always work, but countries depend so much on their Internet connections that cyber-blockades could be more effective\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\n30 International Journal of Technoethics, 1(1), 20-31, January-March 2010\nBerman, P. (2002). The globalization of jurisdiction. University of Pennsylvania Law Review, 151(2), 311–545. doi:10.2307/3312952\nBiersteker, T., &amp; Eckert, S. (2008). Countering the financing of terrorism. London: Routledge.\nBissett, A. (2004). High technology war and ‘surgical strikes’. [ACM SIGCAS]. Computers &amp; Society, 32(7), 4.\nBok, S. (1986). Secrets. Oxford, UK: Oxford University Press.\nBorg, S. (2005, November-December). Economically complex cyberattacks. IEEE Security and Privacy, 3(6), 64–67. doi:10.1109/MSP.2005.146\nCeruti, M. (2001, March). Mobile agents in network-centric warfare. Proc. 5th International Symposium on Autonomous Decentralized Systems (pp. 243–246).\nDenning, D. (1999). Information Warfare and Security. Boston, MA: Addison-Wesley.\nDenning, D. (2007). The ethics of cyber conflict. In K. Himma, &amp; H. Tavani (Eds.), Information and computer ethics. New York: Wiley.\nDorf, J., &amp; Johnson, M. (2007). Restoration component of business continuity planning. In H. Tipton, &amp; M. Krause (Eds.), Information security management handbook (6th ed.) (pp. 645–1654). CRC Press.\nDunnigan, J. (2003). How to make war. (4th ed.). New York: Quill.\nFotion, N., &amp; Elfstrom, G. (1986). Military ethics: guidelines for peace and war. Boston: Routledge and Kegan Paul.\nGardam, J. (2004). Necessity, proportionality, and the use of force by states. Cambridge, UK: Cambridge University Press.\nGutman, R., &amp; Rieff, D. (1999). Crimes of war: what the public should know. New York: Norton\nHimma, K. (2004). The ethics of tracing hacker attacks through the machines of innocent persons. International Journal of Information Ethics, 2(11), 1–13.\nHollis, D. (2007). New tools, new rules: international law and information operations. In G. David, &amp; T. McKeldin (Eds.), The message of war: information, influence, and perception in armed conflict. Temple University Legal Studies Research Paper No. 2007-15, Philadelphia, PA, USA.\nICRC (International Committee of the Red Cross). (2007). International humanitarian law – treaties and documents. Retrieved December 1, 2007 from www.icrc.org/icl.nsf.\nJensen, E. (2003). Unexpected consequences from knock-on effects: a different standard for computer network operations? American University International Law Review, 18, 1145–1188.\nJohnson, J. (1984). Can modern war be just? New Haven: Yale University Press.\nJones, A., Kovacich, G., &amp; Luzwick, P. (2002). Global information warfare. Boca Raton, FL: CRC Press.\nKnapp, K., &amp; Boulton, W. (2007). Ten information warfare trends. In L. Janczewski &amp; A. Colarik (Eds.), Cyber Warfare and Cyber Terrorism (pp. 17–25). Hershey, PA, USA: IGI Global.\nKuhnhauser, W. (2004, January). Root kits: an operating systems viewpoint. ACM SIGOPS Operating Systems Review, 38(1), 12–23. doi:10.1145/974104.974105\nLederberg, J. (Ed.). (1999). Biological weapons: limiting the threat. Cambridge, MA: MIT Press.\nLibicki, M. (2007). Conquest in cyberspace: national security and information warfare. New York: Cambridge University Press.\nMandia, K., &amp; Prosise, C. (2003). Incident response and computer forensics. New York: McGraw-Hill/ Osborne.\nMel, H., &amp; Baker, D. (2000). Cryptography decrypted (5th ed.). Boston, MA: Addison-Wesley Professional.\nMolander, R., &amp; Siang, S. (1998, Fall). The legitimization of strategic information warfare: ethical considerations. AAAS Professional Ethics Report, 11(4). Retrieved November 23, 2005 from www.aaas.org/spp/sfrl/sfrl.htm.\nNardin, T. (Ed.). (1998). The ethics of war and peace. Princeton, NJ: Princeton University Press.\nNeumann, P. (1995). Computer related risks. Reading, MA: ACM Press.\nRanum, M. (2004). The myth of homeland security. Indianapolis, IN: Wiley.\nRobb, J. (2007). The U.S. and cyberwarfare. Retrieved February 6, 2009 from globalguerrillas.typepad.com/globalguerrillas/2007/12/the-us-and-cyber.html.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 31\nSchmitt, M. (2002). Wired warfare: computer network attack and jus in bello. International Review of the Red Cross, 84(846), 365–399.\nVerton, D. (2003). Black ice: the invisible threat of cyber-terrorism. New York: McGraw-Hill Osborne Media.\nWalzer, D. (1977). Just and unjust wars: a moral argument with historical illustrations. New York: Basic Books.\nWayner, P. (2002). Disappearing cryptography: information hiding: steganography and watermarking. San Francisco, CA: Morgan Kaufmann.\nWestwood, C. (1997). The future is not what it used to be: conflict in the information age. Fairbairn, ACT, Australia: Air Power Studies Center.\nWhitby, S. (2002). Biological warfare against crops. Houndmills, UK: Palgrave.\nWhite Wolf Security. Offensive operations in cyberspace. Retrieved February 6, 2009 from www.whitewolfsecurity.com/publications/offensive_ops.php.\nNeil C. Rowe is professor of computer science, U.S. Naval Postgraduate School where he has been since 1983. He has a PhD in computer science from Stanford University (1983), and EE (1978), SM (1978), and SB (1975) degrees from the Massachusetts Institute of Technology. His main research interest is the role of deception in information processing, and he has also done research on intelligent access to multimedia databases, image processing, robotic path planning, and intelligent tutoring systems. He is the author of over 100 technical papers and a book.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited."
  ],
  "flat_text": "IGI Global Scientific Publishing Platform Downloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\n\n# The Ethics of Cyberweapons in Warfare\nNeil C. Rowe, U.S. Naval Postgraduate School, USA\n# ABSTRACT\nThe author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement.\nKeywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons\n# INTRODUCTION\nCyberweapons are software used to attack other software or data within computer systems . We distinguish cyberweapons and cyberattacks (attacks using cyberweapons) from \"information warfare\", a more general term that includes propaganda, electronic surveillance, cyber-espionage, and defensive information operations (Jones, Kovacich, &amp; Luzwick, 2002). That is, we will focus on \"network attack\" and not \"network exploitation\" or \"network defense\".\nLike conventional weapons, cyberweapons can be used against a variety of targets in a variety of circumstances with a wide range of lethality (White Wolf Security, 2009). Often\nCryptography © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\ncyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects . Furthermore, unlike chemical, biological, and nuclear weapons, people have no visceral fear of cyberweapons for reasons like health consequences. But maybe they should. All weapons can have serious harms by virtue of their being weapons. The public is unaware of the degree to which they depend on computer systems and the information they store, and thus weapons targeting them can have many unforeseen consequences. For instance, targeting a country's Internet service providers can prevent goods from being delivered, and cause people to starve or die from lack of necessary medical supplies.\nDOI: 10.4018/jte.2010081002\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 21\nThere are several schools of ethics. In this article we will follow a pragmatic approach derived from utilitarian ethics in which we argue that a technology is unethical if it has a significant net harm to world society (“negative utilitarianism”). We would also like to derive ethical principles of using cyberweapons, so we will follow “rule utilitarianism”. Such principles can then be codified in laws of warfare. However, we do not need an elaborate ethical foundation here because most of the ethical issues with cyberattacks seem similarly problematic under any ethical framework.\n# THE STATE OF THE ART IN CYBERWEAPONS\nMilitary organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare . Many of these techniques exploit flaws in software. Certain kinds of errors such as failure to check for buffer overflows in loops or failure to properly label data on Web sites can lead to granting of unauthorized special privileges to users of a system. Cyberweapons are programs that package a set of such exploits against a computer system and its data. Cyberweapons can be launched or controlled either externally, from another computer or the Internet, or internally, by spies and saboteurs (Knapp &amp; Boulton, 2007).\nCyberattackers can use their access and privileges to destroy the data and software on a computer system or network, but that is pretty obvious and tells the victim they have been attacked. Cyberattackers can modify the data on a victim system to impede military operations, but that requires a good deal of contextual knowledge about the data. So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits” . Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user . Hacker botnets have been used to earn money by sending spam or phishing email from the slave computers, have been used for denial-of-service attacks against organizations the attacker does not like, have been used for blackmail of organizations by threatening malicious mischief, and have been used for espionage. Botnets developed for military purposes could stop an adversary’s military organization from communicating or defending itself.\nCyberweapons can be an innocent-looking software module. Running them to see what they do is not easy because many require passwords to run and their effects may be very subtle. Thus it is difficult to identify cyberweapons within a computer system. Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents” . And when they have served their purpose, they can be deleted. This makes it considerably harder to police cyberweapons than nuclear, chemical, and biological weapons. Nonetheless, traces of a cyberattack will be visible on the victim’s computers and networks, and range of methods of “computer forensics” (Mandia &amp; Prosise, 2003) can analyze these traces.\nCyberweapons can attack many kinds of military targets. An obvious one is an adversary’s “command and control”, their communications and electronic mail, because these are essential to organizing a defense. Since command-and-control tools are distributed across many machines, there are many potential entry points for an attack. Weapons-controlling and vehicle-controlling software are also desirable targets of cyberweapons, but they are harder to attack because they are carefully protected and often (especially for weapons) do not use networks much. Logistics and supply could be targeted, but effects would not be immediate, and surprise is a key element of cyberattack effectiveness. Managerial support for the military could be targeted, because its protections tend\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nto be less, but again the effects would not be immediate, and troops can fight without managers. Public relations (like Web sites) might be a good target, because public perception is so much a part of winning a war, but the damage would only be psychological.\nCyberattacks may be coupled to conventional military attacks, and this may enhance the effectiveness of both. For instance, China claims sovereignty over the island of Taiwan, but Taiwan has formidable defenses and the support of the U.S. Navy. If China were to attack, they would need all the resources they could muster, and a simultaneous cyberattack could be very helpful considering the heavy reliance of the U.S. Navy on software and digital data.\nCyberattacks can also target a country's important civilian infrastructure such as its Internet sites, its financial services sector, its power grid, or even the common software it uses. The Department of Homeland Security in the United States studies this kind of threat. Attacks on nonmilitary targets are generally outlawed by the international warfare conventions, with exceptions for strong military necessity. They are not guaranteed to succeed because there is considerably less centralization in the civilian sector than there is in military organizations, and it can be hard to hit enough targets to achieve the effect of a conventional military attack. They are thus not the first choice of military commanders because the commanders' biggest concern is preventing counterattacks, and they will get them unless they primarily target a country's military. Terrorists might be more likely to choose civilian targets for cyberattacks because terrorist organizations are hard to find and track. Nonetheless, a terrorist organization needs to do public relations for recruitment, needs to acknowledge attacks to gain a public-relations benefit, and needs to maintain a communications network, and this provides a start in tracking them down.\nCyberweapons development has been reported in several major countries in the last few years. Most reports have focused on China which has ambitious goals for military operations in cyberspace, but other countries with\nsoftware expertise such as Russia have also been mentioned. The United States military does not like to lag technologically behind anyone; recent announcement of a U.S. Air Force \"Cyberspace Command\" (24th Air Force Command) suggests the United States is now investigating these weapons in secret work. Cyberweapons need not be confined to advanced countries, however, because the technology for developing them does not require much capital investment. It does require expertise in software, which limits their development in countries with poor educational systems. Cyberweapons do not currently seem to be an interest of terrorist groups. They could be , but it seems unlikely in the near future since most groups today are anti-technology or, like Al Qaeda, forced to avoid technology to avoid being tracked.\n# LAW FOR CYBERATTACKS\nCyberattacks using cyberweapons are activities that would classified as crimes in their victim countries if done by ordinary citizens. Necessarily they involve trespassing; to be effective they must employ fraud and vandalism; and often they must also involve espionage, sabotage, and virtual assaults. In many cases they violate international war conventions as well . While enforcement of international laws of war has been inconsistent, enforcement has been increasingly successful in recent years, so they should be taken seriously.\nA particularly troubling issue with cyberattacks is their frequent use of identity deceptions of various kinds, such as by the concealed modifications of an operating system done by rootkits, or the masquerading as legitimate users to gain access. This brings cyberattacks often close to perfidy, a war crime outlawed by international law. Perfidy is attackers masquerading as a legitimate civilian activity, such as soldiers pretending to be Red Cross workers. Perfidy is considered unacceptable in war because it blurs the distinction between combatants and noncombatants, and encourages attacks on civilians. It is certainly fair for combatants to\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 23\nuse camouflage. But an operating system is essential to use a computer, so compromising it and turning it into a computer-virus delivery tool is like putting a poison in a community’s water system. The argument for perfidy is strongest for the critical parts of an operating system for enforcing access controls, the “kernel”, since everyone relies on them and there is no legitimate reason to tamper with them. Other possible candidates for perfidy are tamperings with the key networking software such as routers and as TCP/IP protocols since they are essential for many cyberspace activities.\nIf someone damages a computer or data, the owner of the computer or data can sue the attacker in civil legal proceedings in many countries. This may apply to cyberattacks. If the victims are sufficiently widespread within a country, the country as a whole may be able to sue the attacker, even if it is another country, using international tort law. Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare  and many of the ideas extend to cyberweapons. Unethical behavior can be punished by activities like cyber-blockades as discussed below.\nA possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease . These have been banned by international convention because they affect military and civilian personnel equally and are difficult to target exclusively to military personnel. Targeting is difficult because biological agents can spread unpredictably due to wind, contacts, and normal biological processes. Perhaps the best analogy to cyberweapons is that of biological warfare against crops , banned by the Biological and Toxin Weapons Convention of 1972. Crops are necessary resources that everyone in society needs, and are societal infrastructure. Attacking them is akin to terrorism.\nAnalogously, cyberwarfare does not target military personnel directly but only their software and data. But usually cyberattacks will be effective against any computer with the same type of vulnerable software. Military\norganizations use mostly software that is also used by civilians. So civilian computers could also suffer from military cyberattacks; in fact, they are usually more vulnerable because their countermeasures are not as good. If an attack on a military target goes astray, or if an attack propagates from a military target, civilian computers can easily be damaged. Or it may be tempting for a nation with cyberweapons to deliberately attack civilian computers and networks to cripple the economy of a target country, even though this violates international law. The Allies in World War II deliberately targeted civilian centers with bombing because they thought it would end the war more quickly.\n# RELIABILITY AND EFFECTIVENESS\nOne important difference between cyberattacks and conventional military attacks is in the reliability and effectiveness of the attack. If you fire a bullet at a target, it is highly likely to arrive there. If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet . For another, the attack design itself may be faulty, the attack may not be able to find the target, or the target may not be vulnerable to the attack because assumptions made about it are no longer valid. Computers and software can be precise and highly controllable tools, so why cannot cyberweapons be made precise and controllable too?\nSome of the reason is the nature of warfare. To defend yourself, you need to hide and harden your assets. Military computers and software are known targets of adversaries, and governments try to limit their use to authorized personnel by passwords, encryption, enumerated access rights, and other access controls. Military systems are often on special networks behind layers of firewalls, or left unconnected to networks as in the case of weapons systems. System configurations like IP addresses can be changed periodically to foil overly specific\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nattacks, and decoy machines and “honeypots” (attack-data gathering machines) can divert an adversary and collect data about them. Network and system logging can track who is using systems and how, so abnormal usage can be caught quickly. Targeting is not as precise as is believed with conventional weapons anyway, as discussed in . So cyberweapons are likely to be unreliable, and “surgical strikes” are unlikely in cyberspace.\nA contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability . This is because new technology is usually complex and many things can go wrong. Software technology in particular permits implementation of very complex mechanisms. An exacerbating factor is that cyberweapons are poorly understood by military commanders since few have expertise in software. This means that commanders will tend to use cyberweapons, more than regular weapons, against the wrong targets in the wrong circumstances to achieve the wrong goals.\nWill cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable . More specifically, cyberattacks depend on the novelty of their methods and secrecy to enforce it (as we discuss below). There are a limited number of attack methods and they generally can be used only once. So attackers will chronically suffer from inability to practice their attacks, and this will hurt their effectiveness.\n# THE RISK OF COLLATERAL DAMAGE IN CYBERSPACE\n“Collateral damage” or accidental harm to civilians is a key issue in both ethics and laws of warfare. Unfortunately, it is quite possible for cyberattacks aimed at military targets to accidentally hit civilian targets due to their unreliability and uncontrollability. One factor is that it can be hard to distinguish a military computer from a civilian computer. The localization of the target in physical space and\nidentification from its appearance that help so much in conventional warfare have no counterpart in cyberspace. Cyberspace addresses can be spoofed so one site can masquerade as another. Military organizations often use the same operating systems, bookkeeping, word-processing, and presentation software as businesses because it saves money (Jones, Kovacich, &amp; Luzwick, 2002), so examining the software may not indicate a military system. Most military files and data look just like files and data from any large civilian business, since most of both are undecipherable without knowing a good deal of specific jargon. (Some specialized sites can be more easily recognized, such as those controlling power plants, but they are well protected.) Within a military site, it may be hard to distinguish information about humanitarian activities such as hospitals and disaster relief from warfare information, so there could be intrasite collateral damage too; on a battlefield, it is easy to distinguish a tank from a Red Cross truck. Although many military computers have military network names and addresses, they could be camouflaged with a civilian name or address to reduce the chances of an adversary finding it (although it is harder in the U.S. where military site names all end in “.mil”). A clever adversary might also camouflage a civilian computer as a military one to provoke an adversary to attack it in the hope of provoking international outrage.\nSecondly, because of the difficulty of reaching military targets for a network-based attack or management of an internal attack, it is tempting to use other systems as “stepping stones” which the cyberattack subverts in a chain to reach the target machines. It is appealing to use civilian machines as stepping stones because many (like home computers) have minimal security. Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries .\nThirdly, even if a civilian computer is not initially attacked, an attack may spread to it. Some cyberattacks use computer viruses and worms that can propagate from one computer\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 25\nto another. Most other cyberattacks have some ability to spread from their original targets because targeting mistakes can be made or defensive surprises may occur. And some attacks like denial-of-service ones require propagation to work. But propagation abilities also make it easier for attacks to spread from military machines to civilian machines. The ubiquity of the Windows operating system and much of the same software on both military and civilian machines facilitates attack spread.\nFourthly, technologically developed countries provide the best targets for cyberweapons because they have so many things to attack. But cyberweapons require considerable technical expertise to develop, and such expertise is only readily available in the most technologically developed countries. This means an attack by a less technologically developed country is more likely to go astray and attack civilians, or perhaps be more likely to be deliberately targeted to do so because civilians are easier targets.\n# DAMAGE ASSESSMENT\nAn issue exacerbating the collateral damage problem with cyberweapons is the difficulty of determining what they did. When aircraft bomb a target, much damage can be seen from the air. With cyberweapons, the damage is not directly visible, which makes it more persistent and costly. Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first . Attacks may also fail for a host of unforeseen reasons;  likens information warfare to introducing noise into a military organization, and the organization may or may not succeed at handling it.\nThis has important consequences for both the victim and the attacker. It may be hard for the victim to know if they have been attacked. The effects of an attack may be subtle, as when a worm slows down normal operations without changing anything else. Then the harm may persist for a long time because no one realizes anything is wrong. Or the effects may be time-\ndelayed, as when a virus in a defender’s weapons system causes it to fail only during combat. Then it may be difficult to find the cause, the harm will also persist until it is found, and repair may be costly. It would be foolish for an attacker to use an attack known to antivirus, antiworm, or antispyware tools, so we can assume such tools will be useless in finding or repairing damage from such attacks. While there are techniques for “system restoration” from backup storage media (Dorf &amp; Johnson, 2007), they are time-consuming and require expertise, and may not be able to restore important data unless backup has been highly diligent. And the original vulnerabilities that enabled the attack need to be found and fixed (“patched”) to prevent new attacks of the same kind, something that requires research and knowledgeable systems personnel. Less advanced countries may not have anyone with the necessary skills to do these things, leading to long-persistent damage much like that of landmines and chemical toxins that get into the water supply.\nFor the attacker, it may be very hard to know if their cyberattack had an effect. They may overcompensate by launching an unnecessarily powerful attack to be sure of an effect, or they may attack repeatedly unnecessarily. They may attack unnecessarily many kinds of software or data, and they may do unnecessarily drastic modifications to it. Unnecessarily strong attacks that are deep may be unnecessarily difficult to repair, and unnecessarily strong attacks that are broad run a higher risk of collateral damage to civilians. Unnecessarily strong attacks are particularly a danger for cyber-counterattacks, as we will discuss, because an adversary is anticipating counterattacks.\n# SECRECY OF CYBERWEAPONS\nAs mentioned, most cyberattacks exploit bugs or flaws in software. If the victims knew of these, they would have fixed them. So secrecy of attack methods is essential to the success of most cyberweapons.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nThis secrecy by itself can be unethical. Secrecy makes it harder for victim countries to figure out what happened to them. Standard attack-intelligence resources like Computer Emergency Response Teams (CERTs) collect information about known vulnerabilities, but cannot provide much help for cyberattacks used in warfare because the vulnerabilities will likely be new. This exacerbates the problem of diagnosis and repair discussed above. Also, misinformation about poorly-understood attacks may spread far in a crisis, creating overreaction and panic in the victim country. Misunderstanding can lead to scapegoating of innocent countries or groups, much as terrorist acts tend to be blamed on a country's known adversaries. It will be essential for information-security experts to provide dispassionate technical analysis of what has occurred, perhaps with neutral experts from an international agency.\nSecrecy also has negative consequences for the society that uses it . It encourages those who know the secrets to think they are better than those that do not, and permits those responsible for foolish attacks to avoid blame. Secret weapons are harder to test, since testing cannot be done publicly, and without adequate testing it is more likely that they will fail or cause collateral damage. An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once . Once they are used and they create some military effect, computer-forensics methods can usually figure out what happened. Then a solution—fixing a bug, disabling software, turning off a utility, or blacklisting a site—can often be found in a day or so, and often a good solution will prevent similar attacks of the same type as well. This means that cyberweapons provide a poor return on investment, since exploitable flaws in software require considerable work to find. They are like a type of bomb that can only be used once anywhere in the world and never any bomb of that type again. It appears ethically unjustifiable for a society to spend resources on developing cyberweapons when there are so many other more useful things they could spend money on.\n# CYBER-COUNTERATTACKS\nInternational law prohibits attacks on other countries unless a country is attacked first . Countries must agree to this in signing the United Nations charter; in the United States, the charter was a treaty approved by the U.S. Senate, and thus has the same force as any other law of the U.S. So unprovoked cyberattacks are clearly illegal and unethical. But what about cyber-counterattacks?\nIt is more difficult to prove responsibility for a cyberattack than for a conventional attack, since it is hard to trace from where it came. The apparent source may be \"spoofed\" by illicit modification of source-identification data, the apparent source may just be a \"stepping-stone\" as discussed earlier, and networks sites do not always keep good records. Even if we can trace an attack, the evidence is highly technical. This makes it hard to justify a counterattack to world public opinion.\nIn addition, a serious technical problem of cyber-counterattacks is the preparation and experimentation time necessary to set up good ones. If the cyber-counterattacks are from within a system, time is needed to establish a foothold on that system and station attack software on it. It will be unlikely that an attacker will succumb to the same attack they themselves launched – they should have plenty of time to harden their systems against it. In fact, an attacker should take special pains to harden their systems against all attacks, since counterattacks are sanctioned by international law. A smart attacker could even terminate all their network connections to the rest of the world for a time after an attack to markedly reduce the chances of an externally launched counterattack or exploitation of an internally launched one. Or they could put all their operating systems into hardware to prevent modification by Trojan horses and other exploits. So it will not be easy to launch a successful counterattack, and some considerable\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 27\nnumber of tries by the counterattacker with many methods may be necessary to find one that works, if one can be found at all.\nThese issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack . Legitimate counterattacks cannot wait years (such as the claim that the 2001 attack on the New York World Trade Center was a response to the U.S.-Iraq war of 1991), cannot use some quite different technology (as the introduction of poison gas by the Germans in 1915), and cannot be considerably larger. Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical .\nOne way to facilitate counterattacks is to station counterattack software in advance of attack, and channels to communicate with it like those of botnets, on computer systems of adversaries just in the chance there might be hostilities which could use it. Then they might be invoked quickly. Such capabilities could deter an adversary attack in the first place, if the adversary knows or cares about those capabilities (deterrence does not always work well as a military strategy). However, designing counterattacks that will work when needed is not easy. Just because they worked in the laboratory against fixed targets does not provide much confidence they will work during warfare, a problem that occurs in testing much new military technology. Computer systems are installing new protections all the time, so possible attack methods can become obsolete without warning. That means that the older an attack is, the less likely it is to work. Counterattack software is identical to attack software, so it is just as criminal to use in most countries, and just as hard to test in realistic warfare conditions. Furthermore, a hasty counterattack may harm the counterattacker more than the attacker because it reveals counterattacker cyberweapons to the attacker and allows them to test how they\ncan be defeated, information that they might not be able to obtain otherwise.\nA way to reduce counterattack obsolescence is to use a broader \"strategic\" counterattack rather than a tactical one. An example would be modifying all the code for a networking protocol used by an adversary by modifying the source for that code in a repository. If all adversary military systems download their code from there, all could be infected from a single source, and the code could function normally until the counterattack. Such methods would be high on the scale of perfidy. But there are difficult practical problems. Adversaries that contemplate attacking other countries will set a high priority on protecting their frequently used software and will use hashes (pseudorandom data reductions) regularly to check for modifications to it. Most software is updated regularly, so the counterattacker would need to repeatedly modify the code with each update. Most updates come directly from software companies and not a military repository, and it would be hard for counterattackers to reach all these sources, and even harder to modify code in transmission. A broad strategic attack is easier to diagnose than a tactical (limited) one because there will be many malfunctioning systems simultaneously; this provides good data for identifying the type of attack and its software locus, so such attacks can be fixed more quickly than those that attack just one system. Finally, a broad counterattack based in common software risks more collateral damage to noncombat functions of computer systems than a more targeted counterattack.\nNot all cyber-counterattacks require preparation. Those launched across the Internet can be mounted more easily at any time. Defending against such attacks is, however, the primary focus of the network intrusion-prevention systems which defend most of our network sites, which are kept updated with the latest known attacks. It is difficult, though not impossible, to invent a new attack that will succeed against these formidable defenses. A country could try to \"stockpile\" new such attacks in the interests of its defense, but the effort to find such attacks might quickly be wasted as countermeasures are\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nindependently discovered as discussed above. What attacks that do succeed in circumventing the first level of defenses may succumb to second levels of defenses that note anomalous behavior, so they are unlikely to succeed for long once they start attacking. For instance, systematic search for the computers on a local-area network is necessary for precisely targeted attacks, but such searching is obvious to network packet monitoring since normal usage rarely does it. So network-based attacks are quite unreliable, and military commanders dislike unreliable technology. Thus it appears that cyber-counterattacks are infeasible.\n# DESIGNING ETHICAL CYBERWEAPONS\nDespite the issues raised here, countries will likely continue to develop cyberweapons. Can such weapons be designed and used more ethically? We believe they can, since ethical discriminations can be made today among different kinds of weapons. For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately .\nSince controllability is a serious concern with cyberweapons, ethical weapons should use a variety of methods to ensure focused targeting. Propagation via viruses and worms should be minimized. Attacks should focus on a limited set of important targets which should be clearly identified and confirmed during the attack using more than their Internet address. Important civilian systems such as commercial infrastructure should clearly identify themselves as civilian so attacks can know to avoid them.\nEthical attacks should also be easily stoppable. If an adversary surrenders, it is unethical as well as against international law to continue attacking and causing damage. This means that all attacks should be under quick control via some mechanism such as an emergency channel so that they can be halted if necessary.\nThis may be difficult with automated attacks, and the effects of any attack will likely impede communication. But it is important.\nIdentification of the attacker (\"attribution\") should also be a key feature of ethical attacks, much as how uniforms to identify military personnel in warfare. Acting as a soldier while not wearing a uniform is outlawed by international law. So some data associated with a cyberattack should identify who is responsible for an attack. One way is to add a digital signature to data or a program (Mel &amp; Baker, 2000). Several technologies to do this are available, and the best-known is encryption with a private key of a public-private key pair of a hash of the contents. Using a hash means that the public key confirms that the contents were not modified after they were signed. Responsible attackers will find signatures useful because they prove they are responsible for an attack and prevent scapegoating of others. Unattributed attacks are not very useful anyway since attacks are usually a way to force a country to do something, and the victim cannot know what to do unless they know who has attacked them. Signatures also permit the attacker to recognize their own signature on already-attacked systems and avoid reattacking them. Public keys for attack signatures could be kept with international organizations like the United Nations as a form of \"key escrow\" like that proposed for backup on encrypted systems.\nNot everyone agrees that attacks should be attributable. Robb (2009) argues that cyberattacks will be ineffective unless that have deniability, like some instances of \"special operations\" using commandos. But if he is right, then all effective cyberattacks are forms of terrorism.\nA weakness of signatures is that they might be recognized by defenders and enable them to realize they are being attacked, which might matter with the more subtle attacks. But it will not be easy to recognize attack signatures because many programs today have signatures as a security measure. Also, since they are a function of the contents, their bits will differ when attached to different files or data. However, if\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 29\nit is important that a signature be concealed, steganography can be used by the attacker . This is a class of techniques for concealing data inside innocent-looking other data, like concealing code messages in the least-significant bits of pictures.\nSince damage persistence is a key problem with cyberweapons, it would be more ethical to use weapons whose damage is easily repairable at the end of hostilities. This is more possible in cyberspace than in conventional warfare. For instance, an attack could encrypt important parts of a victim's system so that they cannot be used until the attacker supplies a key to undo (decrypt) them. Since encryption and decryption do not lose any information, the attack would be completely reversible. This would be an ethical alternative whenever it is impossible for a victim to restore a system from backup. Similarly, an attack could withhold important messages (like orders or email) from a victim. If the attacker saves those messages, they could be supplied to the victim at the cessation of hostilities, thereby reversing the attack. In both cases, there may be some damage from denial of timely access to data, but this can be minimized if the target systems are chosen carefully.\nthan physical blockades. There are alternatives to banks, but there is only one Internet.\n# CONCLUSION\nMost coverage of cyberweapons has been relatively neutral, referring to cyberweapons as inevitable new weapons technology that can be employed much like any other. Our argument here is that this cyberweapons have a variety of unique problems that impede their effectiveness and ethicality, and that \"cyberpacifism\" should be encouraged. Cyberweapons are less reliable and less controllable weapons than conventional ones, much like biological weapons, and thus a poor choice in warfare. They disproportionately threaten civilians and harm the society that develops and uses them. It is hard to figure out what is happening when cyberweapons are used due to secrecy and the inherent difficulty of analyzing cyberspace, and their employment for counterattacks seems particularly challenging. While some ways of using cyberweapons are better than others, there are currently insufficient incentives to use them ethically. Their use should be outlawed.\n# ACKNOWLEDGMENT\nThe views expressed are those of the author and do not represent those of any part of the U.S. Government.",
  "citations": {
    "style": "author_year",
    "flat_text": "IGI Global Scientific Publishing Platform Downloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\n\n# The Ethics of Cyberweapons in Warfare\nNeil C. Rowe, U.S. Naval Postgraduate School, USA\n# ABSTRACT\nThe author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement.\nKeywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons\n# INTRODUCTION\nCyberweapons are software used to attack other software or data within computer systems . We distinguish cyberweapons and cyberattacks (attacks using cyberweapons) from \"information warfare\", a more general term that includes propaganda, electronic surveillance, cyber-espionage, and defensive information operations (Jones, Kovacich, &amp; Luzwick, 2002). That is, we will focus on \"network attack\" and not \"network exploitation\" or \"network defense\".\nLike conventional weapons, cyberweapons can be used against a variety of targets in a variety of circumstances with a wide range of lethality (White Wolf Security, 2009). Often\nCryptography © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\ncyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects . Furthermore, unlike chemical, biological, and nuclear weapons, people have no visceral fear of cyberweapons for reasons like health consequences. But maybe they should. All weapons can have serious harms by virtue of their being weapons. The public is unaware of the degree to which they depend on computer systems and the information they store, and thus weapons targeting them can have many unforeseen consequences. For instance, targeting a country's Internet service providers can prevent goods from being delivered, and cause people to starve or die from lack of necessary medical supplies.\nDOI: 10.4018/jte.2010081002\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 21\nThere are several schools of ethics. In this article we will follow a pragmatic approach derived from utilitarian ethics in which we argue that a technology is unethical if it has a significant net harm to world society (“negative utilitarianism”). We would also like to derive ethical principles of using cyberweapons, so we will follow “rule utilitarianism”. Such principles can then be codified in laws of warfare. However, we do not need an elaborate ethical foundation here because most of the ethical issues with cyberattacks seem similarly problematic under any ethical framework.\n# THE STATE OF THE ART IN CYBERWEAPONS\nMilitary organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare . Many of these techniques exploit flaws in software. Certain kinds of errors such as failure to check for buffer overflows in loops or failure to properly label data on Web sites can lead to granting of unauthorized special privileges to users of a system. Cyberweapons are programs that package a set of such exploits against a computer system and its data. Cyberweapons can be launched or controlled either externally, from another computer or the Internet, or internally, by spies and saboteurs (Knapp &amp; Boulton, 2007).\nCyberattackers can use their access and privileges to destroy the data and software on a computer system or network, but that is pretty obvious and tells the victim they have been attacked. Cyberattackers can modify the data on a victim system to impede military operations, but that requires a good deal of contextual knowledge about the data. So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits” . Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user . Hacker botnets have been used to earn money by sending spam or phishing email from the slave computers, have been used for denial-of-service attacks against organizations the attacker does not like, have been used for blackmail of organizations by threatening malicious mischief, and have been used for espionage. Botnets developed for military purposes could stop an adversary’s military organization from communicating or defending itself.\nCyberweapons can be an innocent-looking software module. Running them to see what they do is not easy because many require passwords to run and their effects may be very subtle. Thus it is difficult to identify cyberweapons within a computer system. Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents” . And when they have served their purpose, they can be deleted. This makes it considerably harder to police cyberweapons than nuclear, chemical, and biological weapons. Nonetheless, traces of a cyberattack will be visible on the victim’s computers and networks, and range of methods of “computer forensics” (Mandia &amp; Prosise, 2003) can analyze these traces.\nCyberweapons can attack many kinds of military targets. An obvious one is an adversary’s “command and control”, their communications and electronic mail, because these are essential to organizing a defense. Since command-and-control tools are distributed across many machines, there are many potential entry points for an attack. Weapons-controlling and vehicle-controlling software are also desirable targets of cyberweapons, but they are harder to attack because they are carefully protected and often (especially for weapons) do not use networks much. Logistics and supply could be targeted, but effects would not be immediate, and surprise is a key element of cyberattack effectiveness. Managerial support for the military could be targeted, because its protections tend\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nto be less, but again the effects would not be immediate, and troops can fight without managers. Public relations (like Web sites) might be a good target, because public perception is so much a part of winning a war, but the damage would only be psychological.\nCyberattacks may be coupled to conventional military attacks, and this may enhance the effectiveness of both. For instance, China claims sovereignty over the island of Taiwan, but Taiwan has formidable defenses and the support of the U.S. Navy. If China were to attack, they would need all the resources they could muster, and a simultaneous cyberattack could be very helpful considering the heavy reliance of the U.S. Navy on software and digital data.\nCyberattacks can also target a country's important civilian infrastructure such as its Internet sites, its financial services sector, its power grid, or even the common software it uses. The Department of Homeland Security in the United States studies this kind of threat. Attacks on nonmilitary targets are generally outlawed by the international warfare conventions, with exceptions for strong military necessity. They are not guaranteed to succeed because there is considerably less centralization in the civilian sector than there is in military organizations, and it can be hard to hit enough targets to achieve the effect of a conventional military attack. They are thus not the first choice of military commanders because the commanders' biggest concern is preventing counterattacks, and they will get them unless they primarily target a country's military. Terrorists might be more likely to choose civilian targets for cyberattacks because terrorist organizations are hard to find and track. Nonetheless, a terrorist organization needs to do public relations for recruitment, needs to acknowledge attacks to gain a public-relations benefit, and needs to maintain a communications network, and this provides a start in tracking them down.\nCyberweapons development has been reported in several major countries in the last few years. Most reports have focused on China which has ambitious goals for military operations in cyberspace, but other countries with\nsoftware expertise such as Russia have also been mentioned. The United States military does not like to lag technologically behind anyone; recent announcement of a U.S. Air Force \"Cyberspace Command\" (24th Air Force Command) suggests the United States is now investigating these weapons in secret work. Cyberweapons need not be confined to advanced countries, however, because the technology for developing them does not require much capital investment. It does require expertise in software, which limits their development in countries with poor educational systems. Cyberweapons do not currently seem to be an interest of terrorist groups. They could be , but it seems unlikely in the near future since most groups today are anti-technology or, like Al Qaeda, forced to avoid technology to avoid being tracked.\n# LAW FOR CYBERATTACKS\nCyberattacks using cyberweapons are activities that would classified as crimes in their victim countries if done by ordinary citizens. Necessarily they involve trespassing; to be effective they must employ fraud and vandalism; and often they must also involve espionage, sabotage, and virtual assaults. In many cases they violate international war conventions as well . While enforcement of international laws of war has been inconsistent, enforcement has been increasingly successful in recent years, so they should be taken seriously.\nA particularly troubling issue with cyberattacks is their frequent use of identity deceptions of various kinds, such as by the concealed modifications of an operating system done by rootkits, or the masquerading as legitimate users to gain access. This brings cyberattacks often close to perfidy, a war crime outlawed by international law. Perfidy is attackers masquerading as a legitimate civilian activity, such as soldiers pretending to be Red Cross workers. Perfidy is considered unacceptable in war because it blurs the distinction between combatants and noncombatants, and encourages attacks on civilians. It is certainly fair for combatants to\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 23\nuse camouflage. But an operating system is essential to use a computer, so compromising it and turning it into a computer-virus delivery tool is like putting a poison in a community’s water system. The argument for perfidy is strongest for the critical parts of an operating system for enforcing access controls, the “kernel”, since everyone relies on them and there is no legitimate reason to tamper with them. Other possible candidates for perfidy are tamperings with the key networking software such as routers and as TCP/IP protocols since they are essential for many cyberspace activities.\nIf someone damages a computer or data, the owner of the computer or data can sue the attacker in civil legal proceedings in many countries. This may apply to cyberattacks. If the victims are sufficiently widespread within a country, the country as a whole may be able to sue the attacker, even if it is another country, using international tort law. Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare  and many of the ideas extend to cyberweapons. Unethical behavior can be punished by activities like cyber-blockades as discussed below.\nA possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease . These have been banned by international convention because they affect military and civilian personnel equally and are difficult to target exclusively to military personnel. Targeting is difficult because biological agents can spread unpredictably due to wind, contacts, and normal biological processes. Perhaps the best analogy to cyberweapons is that of biological warfare against crops , banned by the Biological and Toxin Weapons Convention of 1972. Crops are necessary resources that everyone in society needs, and are societal infrastructure. Attacking them is akin to terrorism.\nAnalogously, cyberwarfare does not target military personnel directly but only their software and data. But usually cyberattacks will be effective against any computer with the same type of vulnerable software. Military\norganizations use mostly software that is also used by civilians. So civilian computers could also suffer from military cyberattacks; in fact, they are usually more vulnerable because their countermeasures are not as good. If an attack on a military target goes astray, or if an attack propagates from a military target, civilian computers can easily be damaged. Or it may be tempting for a nation with cyberweapons to deliberately attack civilian computers and networks to cripple the economy of a target country, even though this violates international law. The Allies in World War II deliberately targeted civilian centers with bombing because they thought it would end the war more quickly.\n# RELIABILITY AND EFFECTIVENESS\nOne important difference between cyberattacks and conventional military attacks is in the reliability and effectiveness of the attack. If you fire a bullet at a target, it is highly likely to arrive there. If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet . For another, the attack design itself may be faulty, the attack may not be able to find the target, or the target may not be vulnerable to the attack because assumptions made about it are no longer valid. Computers and software can be precise and highly controllable tools, so why cannot cyberweapons be made precise and controllable too?\nSome of the reason is the nature of warfare. To defend yourself, you need to hide and harden your assets. Military computers and software are known targets of adversaries, and governments try to limit their use to authorized personnel by passwords, encryption, enumerated access rights, and other access controls. Military systems are often on special networks behind layers of firewalls, or left unconnected to networks as in the case of weapons systems. System configurations like IP addresses can be changed periodically to foil overly specific\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nattacks, and decoy machines and “honeypots” (attack-data gathering machines) can divert an adversary and collect data about them. Network and system logging can track who is using systems and how, so abnormal usage can be caught quickly. Targeting is not as precise as is believed with conventional weapons anyway, as discussed in . So cyberweapons are likely to be unreliable, and “surgical strikes” are unlikely in cyberspace.\nA contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability . This is because new technology is usually complex and many things can go wrong. Software technology in particular permits implementation of very complex mechanisms. An exacerbating factor is that cyberweapons are poorly understood by military commanders since few have expertise in software. This means that commanders will tend to use cyberweapons, more than regular weapons, against the wrong targets in the wrong circumstances to achieve the wrong goals.\nWill cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable . More specifically, cyberattacks depend on the novelty of their methods and secrecy to enforce it (as we discuss below). There are a limited number of attack methods and they generally can be used only once. So attackers will chronically suffer from inability to practice their attacks, and this will hurt their effectiveness.\n# THE RISK OF COLLATERAL DAMAGE IN CYBERSPACE\n“Collateral damage” or accidental harm to civilians is a key issue in both ethics and laws of warfare. Unfortunately, it is quite possible for cyberattacks aimed at military targets to accidentally hit civilian targets due to their unreliability and uncontrollability. One factor is that it can be hard to distinguish a military computer from a civilian computer. The localization of the target in physical space and\nidentification from its appearance that help so much in conventional warfare have no counterpart in cyberspace. Cyberspace addresses can be spoofed so one site can masquerade as another. Military organizations often use the same operating systems, bookkeeping, word-processing, and presentation software as businesses because it saves money (Jones, Kovacich, &amp; Luzwick, 2002), so examining the software may not indicate a military system. Most military files and data look just like files and data from any large civilian business, since most of both are undecipherable without knowing a good deal of specific jargon. (Some specialized sites can be more easily recognized, such as those controlling power plants, but they are well protected.) Within a military site, it may be hard to distinguish information about humanitarian activities such as hospitals and disaster relief from warfare information, so there could be intrasite collateral damage too; on a battlefield, it is easy to distinguish a tank from a Red Cross truck. Although many military computers have military network names and addresses, they could be camouflaged with a civilian name or address to reduce the chances of an adversary finding it (although it is harder in the U.S. where military site names all end in “.mil”). A clever adversary might also camouflage a civilian computer as a military one to provoke an adversary to attack it in the hope of provoking international outrage.\nSecondly, because of the difficulty of reaching military targets for a network-based attack or management of an internal attack, it is tempting to use other systems as “stepping stones” which the cyberattack subverts in a chain to reach the target machines. It is appealing to use civilian machines as stepping stones because many (like home computers) have minimal security. Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries .\nThirdly, even if a civilian computer is not initially attacked, an attack may spread to it. Some cyberattacks use computer viruses and worms that can propagate from one computer\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 25\nto another. Most other cyberattacks have some ability to spread from their original targets because targeting mistakes can be made or defensive surprises may occur. And some attacks like denial-of-service ones require propagation to work. But propagation abilities also make it easier for attacks to spread from military machines to civilian machines. The ubiquity of the Windows operating system and much of the same software on both military and civilian machines facilitates attack spread.\nFourthly, technologically developed countries provide the best targets for cyberweapons because they have so many things to attack. But cyberweapons require considerable technical expertise to develop, and such expertise is only readily available in the most technologically developed countries. This means an attack by a less technologically developed country is more likely to go astray and attack civilians, or perhaps be more likely to be deliberately targeted to do so because civilians are easier targets.\n# DAMAGE ASSESSMENT\nAn issue exacerbating the collateral damage problem with cyberweapons is the difficulty of determining what they did. When aircraft bomb a target, much damage can be seen from the air. With cyberweapons, the damage is not directly visible, which makes it more persistent and costly. Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first . Attacks may also fail for a host of unforeseen reasons;  likens information warfare to introducing noise into a military organization, and the organization may or may not succeed at handling it.\nThis has important consequences for both the victim and the attacker. It may be hard for the victim to know if they have been attacked. The effects of an attack may be subtle, as when a worm slows down normal operations without changing anything else. Then the harm may persist for a long time because no one realizes anything is wrong. Or the effects may be time-\ndelayed, as when a virus in a defender’s weapons system causes it to fail only during combat. Then it may be difficult to find the cause, the harm will also persist until it is found, and repair may be costly. It would be foolish for an attacker to use an attack known to antivirus, antiworm, or antispyware tools, so we can assume such tools will be useless in finding or repairing damage from such attacks. While there are techniques for “system restoration” from backup storage media (Dorf &amp; Johnson, 2007), they are time-consuming and require expertise, and may not be able to restore important data unless backup has been highly diligent. And the original vulnerabilities that enabled the attack need to be found and fixed (“patched”) to prevent new attacks of the same kind, something that requires research and knowledgeable systems personnel. Less advanced countries may not have anyone with the necessary skills to do these things, leading to long-persistent damage much like that of landmines and chemical toxins that get into the water supply.\nFor the attacker, it may be very hard to know if their cyberattack had an effect. They may overcompensate by launching an unnecessarily powerful attack to be sure of an effect, or they may attack repeatedly unnecessarily. They may attack unnecessarily many kinds of software or data, and they may do unnecessarily drastic modifications to it. Unnecessarily strong attacks that are deep may be unnecessarily difficult to repair, and unnecessarily strong attacks that are broad run a higher risk of collateral damage to civilians. Unnecessarily strong attacks are particularly a danger for cyber-counterattacks, as we will discuss, because an adversary is anticipating counterattacks.\n# SECRECY OF CYBERWEAPONS\nAs mentioned, most cyberattacks exploit bugs or flaws in software. If the victims knew of these, they would have fixed them. So secrecy of attack methods is essential to the success of most cyberweapons.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nThis secrecy by itself can be unethical. Secrecy makes it harder for victim countries to figure out what happened to them. Standard attack-intelligence resources like Computer Emergency Response Teams (CERTs) collect information about known vulnerabilities, but cannot provide much help for cyberattacks used in warfare because the vulnerabilities will likely be new. This exacerbates the problem of diagnosis and repair discussed above. Also, misinformation about poorly-understood attacks may spread far in a crisis, creating overreaction and panic in the victim country. Misunderstanding can lead to scapegoating of innocent countries or groups, much as terrorist acts tend to be blamed on a country's known adversaries. It will be essential for information-security experts to provide dispassionate technical analysis of what has occurred, perhaps with neutral experts from an international agency.\nSecrecy also has negative consequences for the society that uses it . It encourages those who know the secrets to think they are better than those that do not, and permits those responsible for foolish attacks to avoid blame. Secret weapons are harder to test, since testing cannot be done publicly, and without adequate testing it is more likely that they will fail or cause collateral damage. An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once . Once they are used and they create some military effect, computer-forensics methods can usually figure out what happened. Then a solution—fixing a bug, disabling software, turning off a utility, or blacklisting a site—can often be found in a day or so, and often a good solution will prevent similar attacks of the same type as well. This means that cyberweapons provide a poor return on investment, since exploitable flaws in software require considerable work to find. They are like a type of bomb that can only be used once anywhere in the world and never any bomb of that type again. It appears ethically unjustifiable for a society to spend resources on developing cyberweapons when there are so many other more useful things they could spend money on.\n# CYBER-COUNTERATTACKS\nInternational law prohibits attacks on other countries unless a country is attacked first . Countries must agree to this in signing the United Nations charter; in the United States, the charter was a treaty approved by the U.S. Senate, and thus has the same force as any other law of the U.S. So unprovoked cyberattacks are clearly illegal and unethical. But what about cyber-counterattacks?\nIt is more difficult to prove responsibility for a cyberattack than for a conventional attack, since it is hard to trace from where it came. The apparent source may be \"spoofed\" by illicit modification of source-identification data, the apparent source may just be a \"stepping-stone\" as discussed earlier, and networks sites do not always keep good records. Even if we can trace an attack, the evidence is highly technical. This makes it hard to justify a counterattack to world public opinion.\nIn addition, a serious technical problem of cyber-counterattacks is the preparation and experimentation time necessary to set up good ones. If the cyber-counterattacks are from within a system, time is needed to establish a foothold on that system and station attack software on it. It will be unlikely that an attacker will succumb to the same attack they themselves launched – they should have plenty of time to harden their systems against it. In fact, an attacker should take special pains to harden their systems against all attacks, since counterattacks are sanctioned by international law. A smart attacker could even terminate all their network connections to the rest of the world for a time after an attack to markedly reduce the chances of an externally launched counterattack or exploitation of an internally launched one. Or they could put all their operating systems into hardware to prevent modification by Trojan horses and other exploits. So it will not be easy to launch a successful counterattack, and some considerable\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 27\nnumber of tries by the counterattacker with many methods may be necessary to find one that works, if one can be found at all.\nThese issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack . Legitimate counterattacks cannot wait years (such as the claim that the 2001 attack on the New York World Trade Center was a response to the U.S.-Iraq war of 1991), cannot use some quite different technology (as the introduction of poison gas by the Germans in 1915), and cannot be considerably larger. Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical .\nOne way to facilitate counterattacks is to station counterattack software in advance of attack, and channels to communicate with it like those of botnets, on computer systems of adversaries just in the chance there might be hostilities which could use it. Then they might be invoked quickly. Such capabilities could deter an adversary attack in the first place, if the adversary knows or cares about those capabilities (deterrence does not always work well as a military strategy). However, designing counterattacks that will work when needed is not easy. Just because they worked in the laboratory against fixed targets does not provide much confidence they will work during warfare, a problem that occurs in testing much new military technology. Computer systems are installing new protections all the time, so possible attack methods can become obsolete without warning. That means that the older an attack is, the less likely it is to work. Counterattack software is identical to attack software, so it is just as criminal to use in most countries, and just as hard to test in realistic warfare conditions. Furthermore, a hasty counterattack may harm the counterattacker more than the attacker because it reveals counterattacker cyberweapons to the attacker and allows them to test how they\ncan be defeated, information that they might not be able to obtain otherwise.\nA way to reduce counterattack obsolescence is to use a broader \"strategic\" counterattack rather than a tactical one. An example would be modifying all the code for a networking protocol used by an adversary by modifying the source for that code in a repository. If all adversary military systems download their code from there, all could be infected from a single source, and the code could function normally until the counterattack. Such methods would be high on the scale of perfidy. But there are difficult practical problems. Adversaries that contemplate attacking other countries will set a high priority on protecting their frequently used software and will use hashes (pseudorandom data reductions) regularly to check for modifications to it. Most software is updated regularly, so the counterattacker would need to repeatedly modify the code with each update. Most updates come directly from software companies and not a military repository, and it would be hard for counterattackers to reach all these sources, and even harder to modify code in transmission. A broad strategic attack is easier to diagnose than a tactical (limited) one because there will be many malfunctioning systems simultaneously; this provides good data for identifying the type of attack and its software locus, so such attacks can be fixed more quickly than those that attack just one system. Finally, a broad counterattack based in common software risks more collateral damage to noncombat functions of computer systems than a more targeted counterattack.\nNot all cyber-counterattacks require preparation. Those launched across the Internet can be mounted more easily at any time. Defending against such attacks is, however, the primary focus of the network intrusion-prevention systems which defend most of our network sites, which are kept updated with the latest known attacks. It is difficult, though not impossible, to invent a new attack that will succeed against these formidable defenses. A country could try to \"stockpile\" new such attacks in the interests of its defense, but the effort to find such attacks might quickly be wasted as countermeasures are\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nindependently discovered as discussed above. What attacks that do succeed in circumventing the first level of defenses may succumb to second levels of defenses that note anomalous behavior, so they are unlikely to succeed for long once they start attacking. For instance, systematic search for the computers on a local-area network is necessary for precisely targeted attacks, but such searching is obvious to network packet monitoring since normal usage rarely does it. So network-based attacks are quite unreliable, and military commanders dislike unreliable technology. Thus it appears that cyber-counterattacks are infeasible.\n# DESIGNING ETHICAL CYBERWEAPONS\nDespite the issues raised here, countries will likely continue to develop cyberweapons. Can such weapons be designed and used more ethically? We believe they can, since ethical discriminations can be made today among different kinds of weapons. For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately .\nSince controllability is a serious concern with cyberweapons, ethical weapons should use a variety of methods to ensure focused targeting. Propagation via viruses and worms should be minimized. Attacks should focus on a limited set of important targets which should be clearly identified and confirmed during the attack using more than their Internet address. Important civilian systems such as commercial infrastructure should clearly identify themselves as civilian so attacks can know to avoid them.\nEthical attacks should also be easily stoppable. If an adversary surrenders, it is unethical as well as against international law to continue attacking and causing damage. This means that all attacks should be under quick control via some mechanism such as an emergency channel so that they can be halted if necessary.\nThis may be difficult with automated attacks, and the effects of any attack will likely impede communication. But it is important.\nIdentification of the attacker (\"attribution\") should also be a key feature of ethical attacks, much as how uniforms to identify military personnel in warfare. Acting as a soldier while not wearing a uniform is outlawed by international law. So some data associated with a cyberattack should identify who is responsible for an attack. One way is to add a digital signature to data or a program (Mel &amp; Baker, 2000). Several technologies to do this are available, and the best-known is encryption with a private key of a public-private key pair of a hash of the contents. Using a hash means that the public key confirms that the contents were not modified after they were signed. Responsible attackers will find signatures useful because they prove they are responsible for an attack and prevent scapegoating of others. Unattributed attacks are not very useful anyway since attacks are usually a way to force a country to do something, and the victim cannot know what to do unless they know who has attacked them. Signatures also permit the attacker to recognize their own signature on already-attacked systems and avoid reattacking them. Public keys for attack signatures could be kept with international organizations like the United Nations as a form of \"key escrow\" like that proposed for backup on encrypted systems.\nNot everyone agrees that attacks should be attributable. Robb (2009) argues that cyberattacks will be ineffective unless that have deniability, like some instances of \"special operations\" using commandos. But if he is right, then all effective cyberattacks are forms of terrorism.\nA weakness of signatures is that they might be recognized by defenders and enable them to realize they are being attacked, which might matter with the more subtle attacks. But it will not be easy to recognize attack signatures because many programs today have signatures as a security measure. Also, since they are a function of the contents, their bits will differ when attached to different files or data. However, if\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 29\nit is important that a signature be concealed, steganography can be used by the attacker . This is a class of techniques for concealing data inside innocent-looking other data, like concealing code messages in the least-significant bits of pictures.\nSince damage persistence is a key problem with cyberweapons, it would be more ethical to use weapons whose damage is easily repairable at the end of hostilities. This is more possible in cyberspace than in conventional warfare. For instance, an attack could encrypt important parts of a victim's system so that they cannot be used until the attacker supplies a key to undo (decrypt) them. Since encryption and decryption do not lose any information, the attack would be completely reversible. This would be an ethical alternative whenever it is impossible for a victim to restore a system from backup. Similarly, an attack could withhold important messages (like orders or email) from a victim. If the attacker saves those messages, they could be supplied to the victim at the cessation of hostilities, thereby reversing the attack. In both cases, there may be some damage from denial of timely access to data, but this can be minimized if the target systems are chosen carefully.\nthan physical blockades. There are alternatives to banks, but there is only one Internet.\n# CONCLUSION\nMost coverage of cyberweapons has been relatively neutral, referring to cyberweapons as inevitable new weapons technology that can be employed much like any other. Our argument here is that this cyberweapons have a variety of unique problems that impede their effectiveness and ethicality, and that \"cyberpacifism\" should be encouraged. Cyberweapons are less reliable and less controllable weapons than conventional ones, much like biological weapons, and thus a poor choice in warfare. They disproportionately threaten civilians and harm the society that develops and uses them. It is hard to figure out what is happening when cyberweapons are used due to secrecy and the inherent difficulty of analyzing cyberspace, and their employment for counterattacks seems particularly challenging. While some ways of using cyberweapons are better than others, there are currently insufficient incentives to use them ethically. Their use should be outlawed.\n# ACKNOWLEDGMENT\nThe views expressed are those of the author and do not represent those of any part of the U.S. Government.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\n20 International Journal of Technoethics, 1(1), 20-31, January-March 2010\n# The Ethics of Cyberweapons in Warfare\nNeil C. Rowe, U.S. Naval Postgraduate School, USA\n# ABSTRACT\nThe author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement.\nKeywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons\n# INTRODUCTION\nCyberweapons are software used to attack other software or data within computer systems (Bayles, 2001). We distinguish cyberweapons and cyberattacks (attacks using cyberweapons) from \"information warfare\", a more general term that includes propaganda, electronic surveillance, cyber-espionage, and defensive information operations (Jones, Kovacich, &amp; Luzwick, 2002). That is, we will focus on \"network attack\" and not \"network exploitation\" or \"network defense\".\nLike conventional weapons, cyberweapons can be used against a variety of targets in a variety of circumstances with a wide range of lethality (White Wolf Security, 2009). Often\nCryptography © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\ncyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects (Libicki, 2007). Furthermore, unlike chemical, biological, and nuclear weapons, people have no visceral fear of cyberweapons for reasons like health consequences. But maybe they should. All weapons can have serious harms by virtue of their being weapons. The public is unaware of the degree to which they depend on computer systems and the information they store, and thus weapons targeting them can have many unforeseen consequences. For instance, targeting a country's Internet service providers can prevent goods from being delivered, and cause people to starve or die from lack of necessary medical supplies.\nDOI: 10.4018/jte.2010081002\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 21\nThere are several schools of ethics. In this article we will follow a pragmatic approach derived from utilitarian ethics in which we argue that a technology is unethical if it has a significant net harm to world society (“negative utilitarianism”). We would also like to derive ethical principles of using cyberweapons, so we will follow “rule utilitarianism”. Such principles can then be codified in laws of warfare. However, we do not need an elaborate ethical foundation here because most of the ethical issues with cyberattacks seem similarly problematic under any ethical framework.\n# THE STATE OF THE ART IN CYBERWEAPONS\nMilitary organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare (Denning, 1999). Many of these techniques exploit flaws in software. Certain kinds of errors such as failure to check for buffer overflows in loops or failure to properly label data on Web sites can lead to granting of unauthorized special privileges to users of a system. Cyberweapons are programs that package a set of such exploits against a computer system and its data. Cyberweapons can be launched or controlled either externally, from another computer or the Internet, or internally, by spies and saboteurs (Knapp &amp; Boulton, 2007).\nCyberattackers can use their access and privileges to destroy the data and software on a computer system or network, but that is pretty obvious and tells the victim they have been attacked. Cyberattackers can modify the data on a victim system to impede military operations, but that requires a good deal of contextual knowledge about the data. So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits” (Kuhnhauser, 2004). Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user (Bailey et al., 2009). Hacker botnets have been used to earn money by sending spam or phishing email from the slave computers, have been used for denial-of-service attacks against organizations the attacker does not like, have been used for blackmail of organizations by threatening malicious mischief, and have been used for espionage. Botnets developed for military purposes could stop an adversary’s military organization from communicating or defending itself.\nCyberweapons can be an innocent-looking software module. Running them to see what they do is not easy because many require passwords to run and their effects may be very subtle. Thus it is difficult to identify cyberweapons within a computer system. Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents” (Ceruti, 2001). And when they have served their purpose, they can be deleted. This makes it considerably harder to police cyberweapons than nuclear, chemical, and biological weapons. Nonetheless, traces of a cyberattack will be visible on the victim’s computers and networks, and range of methods of “computer forensics” (Mandia &amp; Prosise, 2003) can analyze these traces.\nCyberweapons can attack many kinds of military targets. An obvious one is an adversary’s “command and control”, their communications and electronic mail, because these are essential to organizing a defense. Since command-and-control tools are distributed across many machines, there are many potential entry points for an attack. Weapons-controlling and vehicle-controlling software are also desirable targets of cyberweapons, but they are harder to attack because they are carefully protected and often (especially for weapons) do not use networks much. Logistics and supply could be targeted, but effects would not be immediate, and surprise is a key element of cyberattack effectiveness. Managerial support for the military could be targeted, because its protections tend\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nto be less, but again the effects would not be immediate, and troops can fight without managers. Public relations (like Web sites) might be a good target, because public perception is so much a part of winning a war, but the damage would only be psychological.\nCyberattacks may be coupled to conventional military attacks, and this may enhance the effectiveness of both. For instance, China claims sovereignty over the island of Taiwan, but Taiwan has formidable defenses and the support of the U.S. Navy. If China were to attack, they would need all the resources they could muster, and a simultaneous cyberattack could be very helpful considering the heavy reliance of the U.S. Navy on software and digital data.\nCyberattacks can also target a country's important civilian infrastructure such as its Internet sites, its financial services sector, its power grid, or even the common software it uses. The Department of Homeland Security in the United States studies this kind of threat. Attacks on nonmilitary targets are generally outlawed by the international warfare conventions, with exceptions for strong military necessity. They are not guaranteed to succeed because there is considerably less centralization in the civilian sector than there is in military organizations, and it can be hard to hit enough targets to achieve the effect of a conventional military attack. They are thus not the first choice of military commanders because the commanders' biggest concern is preventing counterattacks, and they will get them unless they primarily target a country's military. Terrorists might be more likely to choose civilian targets for cyberattacks because terrorist organizations are hard to find and track. Nonetheless, a terrorist organization needs to do public relations for recruitment, needs to acknowledge attacks to gain a public-relations benefit, and needs to maintain a communications network, and this provides a start in tracking them down.\nCyberweapons development has been reported in several major countries in the last few years. Most reports have focused on China which has ambitious goals for military operations in cyberspace, but other countries with\nsoftware expertise such as Russia have also been mentioned. The United States military does not like to lag technologically behind anyone; recent announcement of a U.S. Air Force \"Cyberspace Command\" (24th Air Force Command) suggests the United States is now investigating these weapons in secret work. Cyberweapons need not be confined to advanced countries, however, because the technology for developing them does not require much capital investment. It does require expertise in software, which limits their development in countries with poor educational systems. Cyberweapons do not currently seem to be an interest of terrorist groups. They could be (Verton, 2003), but it seems unlikely in the near future since most groups today are anti-technology or, like Al Qaeda, forced to avoid technology to avoid being tracked.\n# LAW FOR CYBERATTACKS\nCyberattacks using cyberweapons are activities that would classified as crimes in their victim countries if done by ordinary citizens. Necessarily they involve trespassing; to be effective they must employ fraud and vandalism; and often they must also involve espionage, sabotage, and virtual assaults. In many cases they violate international war conventions as well (Arquilla, 1999). While enforcement of international laws of war has been inconsistent, enforcement has been increasingly successful in recent years, so they should be taken seriously.\nA particularly troubling issue with cyberattacks is their frequent use of identity deceptions of various kinds, such as by the concealed modifications of an operating system done by rootkits, or the masquerading as legitimate users to gain access. This brings cyberattacks often close to perfidy, a war crime outlawed by international law. Perfidy is attackers masquerading as a legitimate civilian activity, such as soldiers pretending to be Red Cross workers. Perfidy is considered unacceptable in war because it blurs the distinction between combatants and noncombatants, and encourages attacks on civilians. It is certainly fair for combatants to\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 23\nuse camouflage. But an operating system is essential to use a computer, so compromising it and turning it into a computer-virus delivery tool is like putting a poison in a community’s water system. The argument for perfidy is strongest for the critical parts of an operating system for enforcing access controls, the “kernel”, since everyone relies on them and there is no legitimate reason to tamper with them. Other possible candidates for perfidy are tamperings with the key networking software such as routers and as TCP/IP protocols since they are essential for many cyberspace activities.\nIf someone damages a computer or data, the owner of the computer or data can sue the attacker in civil legal proceedings in many countries. This may apply to cyberattacks. If the victims are sufficiently widespread within a country, the country as a whole may be able to sue the attacker, even if it is another country, using international tort law. Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare (Walzer, 1977; Nardin, 1998) and many of the ideas extend to cyberweapons. Unethical behavior can be punished by activities like cyber-blockades as discussed below.\nA possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease (Lederberg, 1999). These have been banned by international convention because they affect military and civilian personnel equally and are difficult to target exclusively to military personnel. Targeting is difficult because biological agents can spread unpredictably due to wind, contacts, and normal biological processes. Perhaps the best analogy to cyberweapons is that of biological warfare against crops (Whitby, 2002), banned by the Biological and Toxin Weapons Convention of 1972. Crops are necessary resources that everyone in society needs, and are societal infrastructure. Attacking them is akin to terrorism.\nAnalogously, cyberwarfare does not target military personnel directly but only their software and data. But usually cyberattacks will be effective against any computer with the same type of vulnerable software. Military\norganizations use mostly software that is also used by civilians. So civilian computers could also suffer from military cyberattacks; in fact, they are usually more vulnerable because their countermeasures are not as good. If an attack on a military target goes astray, or if an attack propagates from a military target, civilian computers can easily be damaged. Or it may be tempting for a nation with cyberweapons to deliberately attack civilian computers and networks to cripple the economy of a target country, even though this violates international law. The Allies in World War II deliberately targeted civilian centers with bombing because they thought it would end the war more quickly.\n# RELIABILITY AND EFFECTIVENESS\nOne important difference between cyberattacks and conventional military attacks is in the reliability and effectiveness of the attack. If you fire a bullet at a target, it is highly likely to arrive there. If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet (Neumann, 1995). For another, the attack design itself may be faulty, the attack may not be able to find the target, or the target may not be vulnerable to the attack because assumptions made about it are no longer valid. Computers and software can be precise and highly controllable tools, so why cannot cyberweapons be made precise and controllable too?\nSome of the reason is the nature of warfare. To defend yourself, you need to hide and harden your assets. Military computers and software are known targets of adversaries, and governments try to limit their use to authorized personnel by passwords, encryption, enumerated access rights, and other access controls. Military systems are often on special networks behind layers of firewalls, or left unconnected to networks as in the case of weapons systems. System configurations like IP addresses can be changed periodically to foil overly specific\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nattacks, and decoy machines and “honeypots” (attack-data gathering machines) can divert an adversary and collect data about them. Network and system logging can track who is using systems and how, so abnormal usage can be caught quickly. Targeting is not as precise as is believed with conventional weapons anyway, as discussed in (Bissett, 2004). So cyberweapons are likely to be unreliable, and “surgical strikes” are unlikely in cyberspace.\nA contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability (Dunnigan, 2003). This is because new technology is usually complex and many things can go wrong. Software technology in particular permits implementation of very complex mechanisms. An exacerbating factor is that cyberweapons are poorly understood by military commanders since few have expertise in software. This means that commanders will tend to use cyberweapons, more than regular weapons, against the wrong targets in the wrong circumstances to achieve the wrong goals.\nWill cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable (Neumann, 1995). More specifically, cyberattacks depend on the novelty of their methods and secrecy to enforce it (as we discuss below). There are a limited number of attack methods and they generally can be used only once. So attackers will chronically suffer from inability to practice their attacks, and this will hurt their effectiveness.\n# THE RISK OF COLLATERAL DAMAGE IN CYBERSPACE\n“Collateral damage” or accidental harm to civilians is a key issue in both ethics and laws of warfare. Unfortunately, it is quite possible for cyberattacks aimed at military targets to accidentally hit civilian targets due to their unreliability and uncontrollability. One factor is that it can be hard to distinguish a military computer from a civilian computer. The localization of the target in physical space and\nidentification from its appearance that help so much in conventional warfare have no counterpart in cyberspace. Cyberspace addresses can be spoofed so one site can masquerade as another. Military organizations often use the same operating systems, bookkeeping, word-processing, and presentation software as businesses because it saves money (Jones, Kovacich, &amp; Luzwick, 2002), so examining the software may not indicate a military system. Most military files and data look just like files and data from any large civilian business, since most of both are undecipherable without knowing a good deal of specific jargon. (Some specialized sites can be more easily recognized, such as those controlling power plants, but they are well protected.) Within a military site, it may be hard to distinguish information about humanitarian activities such as hospitals and disaster relief from warfare information, so there could be intrasite collateral damage too; on a battlefield, it is easy to distinguish a tank from a Red Cross truck. Although many military computers have military network names and addresses, they could be camouflaged with a civilian name or address to reduce the chances of an adversary finding it (although it is harder in the U.S. where military site names all end in “.mil”). A clever adversary might also camouflage a civilian computer as a military one to provoke an adversary to attack it in the hope of provoking international outrage.\nSecondly, because of the difficulty of reaching military targets for a network-based attack or management of an internal attack, it is tempting to use other systems as “stepping stones” which the cyberattack subverts in a chain to reach the target machines. It is appealing to use civilian machines as stepping stones because many (like home computers) have minimal security. Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries (Himma, 2004).\nThirdly, even if a civilian computer is not initially attacked, an attack may spread to it. Some cyberattacks use computer viruses and worms that can propagate from one computer\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 25\nto another. Most other cyberattacks have some ability to spread from their original targets because targeting mistakes can be made or defensive surprises may occur. And some attacks like denial-of-service ones require propagation to work. But propagation abilities also make it easier for attacks to spread from military machines to civilian machines. The ubiquity of the Windows operating system and much of the same software on both military and civilian machines facilitates attack spread.\nFourthly, technologically developed countries provide the best targets for cyberweapons because they have so many things to attack. But cyberweapons require considerable technical expertise to develop, and such expertise is only readily available in the most technologically developed countries. This means an attack by a less technologically developed country is more likely to go astray and attack civilians, or perhaps be more likely to be deliberately targeted to do so because civilians are easier targets.\n# DAMAGE ASSESSMENT\nAn issue exacerbating the collateral damage problem with cyberweapons is the difficulty of determining what they did. When aircraft bomb a target, much damage can be seen from the air. With cyberweapons, the damage is not directly visible, which makes it more persistent and costly. Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first (Borg, 2005). Attacks may also fail for a host of unforeseen reasons; (Libicki, 2007) likens information warfare to introducing noise into a military organization, and the organization may or may not succeed at handling it.\nThis has important consequences for both the victim and the attacker. It may be hard for the victim to know if they have been attacked. The effects of an attack may be subtle, as when a worm slows down normal operations without changing anything else. Then the harm may persist for a long time because no one realizes anything is wrong. Or the effects may be time-\ndelayed, as when a virus in a defender’s weapons system causes it to fail only during combat. Then it may be difficult to find the cause, the harm will also persist until it is found, and repair may be costly. It would be foolish for an attacker to use an attack known to antivirus, antiworm, or antispyware tools, so we can assume such tools will be useless in finding or repairing damage from such attacks. While there are techniques for “system restoration” from backup storage media (Dorf &amp; Johnson, 2007), they are time-consuming and require expertise, and may not be able to restore important data unless backup has been highly diligent. And the original vulnerabilities that enabled the attack need to be found and fixed (“patched”) to prevent new attacks of the same kind, something that requires research and knowledgeable systems personnel. Less advanced countries may not have anyone with the necessary skills to do these things, leading to long-persistent damage much like that of landmines and chemical toxins that get into the water supply.\nFor the attacker, it may be very hard to know if their cyberattack had an effect. They may overcompensate by launching an unnecessarily powerful attack to be sure of an effect, or they may attack repeatedly unnecessarily. They may attack unnecessarily many kinds of software or data, and they may do unnecessarily drastic modifications to it. Unnecessarily strong attacks that are deep may be unnecessarily difficult to repair, and unnecessarily strong attacks that are broad run a higher risk of collateral damage to civilians. Unnecessarily strong attacks are particularly a danger for cyber-counterattacks, as we will discuss, because an adversary is anticipating counterattacks.\n# SECRECY OF CYBERWEAPONS\nAs mentioned, most cyberattacks exploit bugs or flaws in software. If the victims knew of these, they would have fixed them. So secrecy of attack methods is essential to the success of most cyberweapons.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nThis secrecy by itself can be unethical. Secrecy makes it harder for victim countries to figure out what happened to them. Standard attack-intelligence resources like Computer Emergency Response Teams (CERTs) collect information about known vulnerabilities, but cannot provide much help for cyberattacks used in warfare because the vulnerabilities will likely be new. This exacerbates the problem of diagnosis and repair discussed above. Also, misinformation about poorly-understood attacks may spread far in a crisis, creating overreaction and panic in the victim country. Misunderstanding can lead to scapegoating of innocent countries or groups, much as terrorist acts tend to be blamed on a country's known adversaries. It will be essential for information-security experts to provide dispassionate technical analysis of what has occurred, perhaps with neutral experts from an international agency.\nSecrecy also has negative consequences for the society that uses it (Bok, 1986). It encourages those who know the secrets to think they are better than those that do not, and permits those responsible for foolish attacks to avoid blame. Secret weapons are harder to test, since testing cannot be done publicly, and without adequate testing it is more likely that they will fail or cause collateral damage. An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once (Ranum, 2004). Once they are used and they create some military effect, computer-forensics methods can usually figure out what happened. Then a solution—fixing a bug, disabling software, turning off a utility, or blacklisting a site—can often be found in a day or so, and often a good solution will prevent similar attacks of the same type as well. This means that cyberweapons provide a poor return on investment, since exploitable flaws in software require considerable work to find. They are like a type of bomb that can only be used once anywhere in the world and never any bomb of that type again. It appears ethically unjustifiable for a society to spend resources on developing cyberweapons when there are so many other more useful things they could spend money on.\n# CYBER-COUNTERATTACKS\nInternational law prohibits attacks on other countries unless a country is attacked first (Walzer, 1977). Countries must agree to this in signing the United Nations charter; in the United States, the charter was a treaty approved by the U.S. Senate, and thus has the same force as any other law of the U.S. So unprovoked cyberattacks are clearly illegal and unethical. But what about cyber-counterattacks?\nIt is more difficult to prove responsibility for a cyberattack than for a conventional attack, since it is hard to trace from where it came. The apparent source may be \"spoofed\" by illicit modification of source-identification data, the apparent source may just be a \"stepping-stone\" as discussed earlier, and networks sites do not always keep good records. Even if we can trace an attack, the evidence is highly technical. This makes it hard to justify a counterattack to world public opinion.\nIn addition, a serious technical problem of cyber-counterattacks is the preparation and experimentation time necessary to set up good ones. If the cyber-counterattacks are from within a system, time is needed to establish a foothold on that system and station attack software on it. It will be unlikely that an attacker will succumb to the same attack they themselves launched – they should have plenty of time to harden their systems against it. In fact, an attacker should take special pains to harden their systems against all attacks, since counterattacks are sanctioned by international law. A smart attacker could even terminate all their network connections to the rest of the world for a time after an attack to markedly reduce the chances of an externally launched counterattack or exploitation of an internally launched one. Or they could put all their operating systems into hardware to prevent modification by Trojan horses and other exploits. So it will not be easy to launch a successful counterattack, and some considerable\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 27\nnumber of tries by the counterattacker with many methods may be necessary to find one that works, if one can be found at all.\nThese issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack (Gardam, 2004). Legitimate counterattacks cannot wait years (such as the claim that the 2001 attack on the New York World Trade Center was a response to the U.S.-Iraq war of 1991), cannot use some quite different technology (as the introduction of poison gas by the Germans in 1915), and cannot be considerably larger. Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical (Fotion and Elfstrom, 1986).\nOne way to facilitate counterattacks is to station counterattack software in advance of attack, and channels to communicate with it like those of botnets, on computer systems of adversaries just in the chance there might be hostilities which could use it. Then they might be invoked quickly. Such capabilities could deter an adversary attack in the first place, if the adversary knows or cares about those capabilities (deterrence does not always work well as a military strategy). However, designing counterattacks that will work when needed is not easy. Just because they worked in the laboratory against fixed targets does not provide much confidence they will work during warfare, a problem that occurs in testing much new military technology. Computer systems are installing new protections all the time, so possible attack methods can become obsolete without warning. That means that the older an attack is, the less likely it is to work. Counterattack software is identical to attack software, so it is just as criminal to use in most countries, and just as hard to test in realistic warfare conditions. Furthermore, a hasty counterattack may harm the counterattacker more than the attacker because it reveals counterattacker cyberweapons to the attacker and allows them to test how they\ncan be defeated, information that they might not be able to obtain otherwise.\nA way to reduce counterattack obsolescence is to use a broader \"strategic\" counterattack rather than a tactical one. An example would be modifying all the code for a networking protocol used by an adversary by modifying the source for that code in a repository. If all adversary military systems download their code from there, all could be infected from a single source, and the code could function normally until the counterattack. Such methods would be high on the scale of perfidy. But there are difficult practical problems. Adversaries that contemplate attacking other countries will set a high priority on protecting their frequently used software and will use hashes (pseudorandom data reductions) regularly to check for modifications to it. Most software is updated regularly, so the counterattacker would need to repeatedly modify the code with each update. Most updates come directly from software companies and not a military repository, and it would be hard for counterattackers to reach all these sources, and even harder to modify code in transmission. A broad strategic attack is easier to diagnose than a tactical (limited) one because there will be many malfunctioning systems simultaneously; this provides good data for identifying the type of attack and its software locus, so such attacks can be fixed more quickly than those that attack just one system. Finally, a broad counterattack based in common software risks more collateral damage to noncombat functions of computer systems than a more targeted counterattack.\nNot all cyber-counterattacks require preparation. Those launched across the Internet can be mounted more easily at any time. Defending against such attacks is, however, the primary focus of the network intrusion-prevention systems which defend most of our network sites, which are kept updated with the latest known attacks. It is difficult, though not impossible, to invent a new attack that will succeed against these formidable defenses. A country could try to \"stockpile\" new such attacks in the interests of its defense, but the effort to find such attacks might quickly be wasted as countermeasures are\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nindependently discovered as discussed above. What attacks that do succeed in circumventing the first level of defenses may succumb to second levels of defenses that note anomalous behavior, so they are unlikely to succeed for long once they start attacking. For instance, systematic search for the computers on a local-area network is necessary for precisely targeted attacks, but such searching is obvious to network packet monitoring since normal usage rarely does it. So network-based attacks are quite unreliable, and military commanders dislike unreliable technology. Thus it appears that cyber-counterattacks are infeasible.\n# DESIGNING ETHICAL CYBERWEAPONS\nDespite the issues raised here, countries will likely continue to develop cyberweapons. Can such weapons be designed and used more ethically? We believe they can, since ethical discriminations can be made today among different kinds of weapons. For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately (Johnson, 1984).\nSince controllability is a serious concern with cyberweapons, ethical weapons should use a variety of methods to ensure focused targeting. Propagation via viruses and worms should be minimized. Attacks should focus on a limited set of important targets which should be clearly identified and confirmed during the attack using more than their Internet address. Important civilian systems such as commercial infrastructure should clearly identify themselves as civilian so attacks can know to avoid them.\nEthical attacks should also be easily stoppable. If an adversary surrenders, it is unethical as well as against international law to continue attacking and causing damage. This means that all attacks should be under quick control via some mechanism such as an emergency channel so that they can be halted if necessary.\nThis may be difficult with automated attacks, and the effects of any attack will likely impede communication. But it is important.\nIdentification of the attacker (\"attribution\") should also be a key feature of ethical attacks, much as how uniforms to identify military personnel in warfare. Acting as a soldier while not wearing a uniform is outlawed by international law. So some data associated with a cyberattack should identify who is responsible for an attack. One way is to add a digital signature to data or a program (Mel &amp; Baker, 2000). Several technologies to do this are available, and the best-known is encryption with a private key of a public-private key pair of a hash of the contents. Using a hash means that the public key confirms that the contents were not modified after they were signed. Responsible attackers will find signatures useful because they prove they are responsible for an attack and prevent scapegoating of others. Unattributed attacks are not very useful anyway since attacks are usually a way to force a country to do something, and the victim cannot know what to do unless they know who has attacked them. Signatures also permit the attacker to recognize their own signature on already-attacked systems and avoid reattacking them. Public keys for attack signatures could be kept with international organizations like the United Nations as a form of \"key escrow\" like that proposed for backup on encrypted systems.\nNot everyone agrees that attacks should be attributable. Robb (2009) argues that cyberattacks will be ineffective unless that have deniability, like some instances of \"special operations\" using commandos. But if he is right, then all effective cyberattacks are forms of terrorism.\nA weakness of signatures is that they might be recognized by defenders and enable them to realize they are being attacked, which might matter with the more subtle attacks. But it will not be easy to recognize attack signatures because many programs today have signatures as a security measure. Also, since they are a function of the contents, their bits will differ when attached to different files or data. However, if\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 29\nit is important that a signature be concealed, steganography can be used by the attacker (Wayner, 2002). This is a class of techniques for concealing data inside innocent-looking other data, like concealing code messages in the least-significant bits of pictures.\nSince damage persistence is a key problem with cyberweapons, it would be more ethical to use weapons whose damage is easily repairable at the end of hostilities. This is more possible in cyberspace than in conventional warfare. For instance, an attack could encrypt important parts of a victim's system so that they cannot be used until the attacker supplies a key to undo (decrypt) them. Since encryption and decryption do not lose any information, the attack would be completely reversible. This would be an ethical alternative whenever it is impossible for a victim to restore a system from backup. Similarly, an attack could withhold important messages (like orders or email) from a victim. If the attacker saves those messages, they could be supplied to the victim at the cessation of hostilities, thereby reversing the attack. In both cases, there may be some damage from denial of timely access to data, but this can be minimized if the target systems are chosen carefully.\nthan physical blockades. There are alternatives to banks, but there is only one Internet.\n# CONCLUSION\nMost coverage of cyberweapons has been relatively neutral, referring to cyberweapons as inevitable new weapons technology that can be employed much like any other. Our argument here is that this cyberweapons have a variety of unique problems that impede their effectiveness and ethicality, and that \"cyberpacifism\" should be encouraged. Cyberweapons are less reliable and less controllable weapons than conventional ones, much like biological weapons, and thus a poor choice in warfare. They disproportionately threaten civilians and harm the society that develops and uses them. It is hard to figure out what is happening when cyberweapons are used due to secrecy and the inherent difficulty of analyzing cyberspace, and their employment for counterattacks seems particularly challenging. While some ways of using cyberweapons are better than others, there are currently insufficient incentives to use them ethically. Their use should be outlawed.\n# ACKNOWLEDGMENT\nThe views expressed are those of the author and do not represent those of any part of the U.S. Government."
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "IGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\n20 International Journal of Technoethics, 1(1), 20-31, January-March 2010\n# The Ethics of Cyberweapons in Warfare\nNeil C. Rowe, U.S. Naval Postgraduate School, USA\n# ABSTRACT\nThe author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement.\nKeywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons\n# INTRODUCTION\nCyberweapons are software used to attack other software or data within computer systems (Bayles, 2001). We distinguish cyberweapons and cyberattacks (attacks using cyberweapons) from \"information warfare\", a more general term that includes propaganda, electronic surveillance, cyber-espionage, and defensive information operations (Jones, Kovacich, &amp; Luzwick, 2002). That is, we will focus on \"network attack\" and not \"network exploitation\" or \"network defense\".\nLike conventional weapons, cyberweapons can be used against a variety of targets in a variety of circumstances with a wide range of lethality (White Wolf Security, 2009). Often\nCryptography © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\ncyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects (Libicki, 2007). Furthermore, unlike chemical, biological, and nuclear weapons, people have no visceral fear of cyberweapons for reasons like health consequences. But maybe they should. All weapons can have serious harms by virtue of their being weapons. The public is unaware of the degree to which they depend on computer systems and the information they store, and thus weapons targeting them can have many unforeseen consequences. For instance, targeting a country's Internet service providers can prevent goods from being delivered, and cause people to starve or die from lack of necessary medical supplies.\nDOI: 10.4018/jte.2010081002\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 21\nThere are several schools of ethics. In this article we will follow a pragmatic approach derived from utilitarian ethics in which we argue that a technology is unethical if it has a significant net harm to world society (“negative utilitarianism”). We would also like to derive ethical principles of using cyberweapons, so we will follow “rule utilitarianism”. Such principles can then be codified in laws of warfare. However, we do not need an elaborate ethical foundation here because most of the ethical issues with cyberattacks seem similarly problematic under any ethical framework.\n# THE STATE OF THE ART IN CYBERWEAPONS\nMilitary organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare (Denning, 1999). Many of these techniques exploit flaws in software. Certain kinds of errors such as failure to check for buffer overflows in loops or failure to properly label data on Web sites can lead to granting of unauthorized special privileges to users of a system. Cyberweapons are programs that package a set of such exploits against a computer system and its data. Cyberweapons can be launched or controlled either externally, from another computer or the Internet, or internally, by spies and saboteurs (Knapp &amp; Boulton, 2007).\nCyberattackers can use their access and privileges to destroy the data and software on a computer system or network, but that is pretty obvious and tells the victim they have been attacked. Cyberattackers can modify the data on a victim system to impede military operations, but that requires a good deal of contextual knowledge about the data. So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits” (Kuhnhauser, 2004). Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user (Bailey et al., 2009). Hacker botnets have been used to earn money by sending spam or phishing email from the slave computers, have been used for denial-of-service attacks against organizations the attacker does not like, have been used for blackmail of organizations by threatening malicious mischief, and have been used for espionage. Botnets developed for military purposes could stop an adversary’s military organization from communicating or defending itself.\nCyberweapons can be an innocent-looking software module. Running them to see what they do is not easy because many require passwords to run and their effects may be very subtle. Thus it is difficult to identify cyberweapons within a computer system. Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents” (Ceruti, 2001). And when they have served their purpose, they can be deleted. This makes it considerably harder to police cyberweapons than nuclear, chemical, and biological weapons. Nonetheless, traces of a cyberattack will be visible on the victim’s computers and networks, and range of methods of “computer forensics” (Mandia &amp; Prosise, 2003) can analyze these traces.\nCyberweapons can attack many kinds of military targets. An obvious one is an adversary’s “command and control”, their communications and electronic mail, because these are essential to organizing a defense. Since command-and-control tools are distributed across many machines, there are many potential entry points for an attack. Weapons-controlling and vehicle-controlling software are also desirable targets of cyberweapons, but they are harder to attack because they are carefully protected and often (especially for weapons) do not use networks much. Logistics and supply could be targeted, but effects would not be immediate, and surprise is a key element of cyberattack effectiveness. Managerial support for the military could be targeted, because its protections tend\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nto be less, but again the effects would not be immediate, and troops can fight without managers. Public relations (like Web sites) might be a good target, because public perception is so much a part of winning a war, but the damage would only be psychological.\nCyberattacks may be coupled to conventional military attacks, and this may enhance the effectiveness of both. For instance, China claims sovereignty over the island of Taiwan, but Taiwan has formidable defenses and the support of the U.S. Navy. If China were to attack, they would need all the resources they could muster, and a simultaneous cyberattack could be very helpful considering the heavy reliance of the U.S. Navy on software and digital data.\nCyberattacks can also target a country's important civilian infrastructure such as its Internet sites, its financial services sector, its power grid, or even the common software it uses. The Department of Homeland Security in the United States studies this kind of threat. Attacks on nonmilitary targets are generally outlawed by the international warfare conventions, with exceptions for strong military necessity. They are not guaranteed to succeed because there is considerably less centralization in the civilian sector than there is in military organizations, and it can be hard to hit enough targets to achieve the effect of a conventional military attack. They are thus not the first choice of military commanders because the commanders' biggest concern is preventing counterattacks, and they will get them unless they primarily target a country's military. Terrorists might be more likely to choose civilian targets for cyberattacks because terrorist organizations are hard to find and track. Nonetheless, a terrorist organization needs to do public relations for recruitment, needs to acknowledge attacks to gain a public-relations benefit, and needs to maintain a communications network, and this provides a start in tracking them down.\nCyberweapons development has been reported in several major countries in the last few years. Most reports have focused on China which has ambitious goals for military operations in cyberspace, but other countries with\nsoftware expertise such as Russia have also been mentioned. The United States military does not like to lag technologically behind anyone; recent announcement of a U.S. Air Force \"Cyberspace Command\" (24th Air Force Command) suggests the United States is now investigating these weapons in secret work. Cyberweapons need not be confined to advanced countries, however, because the technology for developing them does not require much capital investment. It does require expertise in software, which limits their development in countries with poor educational systems. Cyberweapons do not currently seem to be an interest of terrorist groups. They could be (Verton, 2003), but it seems unlikely in the near future since most groups today are anti-technology or, like Al Qaeda, forced to avoid technology to avoid being tracked.\n# LAW FOR CYBERATTACKS\nCyberattacks using cyberweapons are activities that would classified as crimes in their victim countries if done by ordinary citizens. Necessarily they involve trespassing; to be effective they must employ fraud and vandalism; and often they must also involve espionage, sabotage, and virtual assaults. In many cases they violate international war conventions as well (Arquilla, 1999). While enforcement of international laws of war has been inconsistent, enforcement has been increasingly successful in recent years, so they should be taken seriously.\nA particularly troubling issue with cyberattacks is their frequent use of identity deceptions of various kinds, such as by the concealed modifications of an operating system done by rootkits, or the masquerading as legitimate users to gain access. This brings cyberattacks often close to perfidy, a war crime outlawed by international law. Perfidy is attackers masquerading as a legitimate civilian activity, such as soldiers pretending to be Red Cross workers. Perfidy is considered unacceptable in war because it blurs the distinction between combatants and noncombatants, and encourages attacks on civilians. It is certainly fair for combatants to\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 23\nuse camouflage. But an operating system is essential to use a computer, so compromising it and turning it into a computer-virus delivery tool is like putting a poison in a community’s water system. The argument for perfidy is strongest for the critical parts of an operating system for enforcing access controls, the “kernel”, since everyone relies on them and there is no legitimate reason to tamper with them. Other possible candidates for perfidy are tamperings with the key networking software such as routers and as TCP/IP protocols since they are essential for many cyberspace activities.\nIf someone damages a computer or data, the owner of the computer or data can sue the attacker in civil legal proceedings in many countries. This may apply to cyberattacks. If the victims are sufficiently widespread within a country, the country as a whole may be able to sue the attacker, even if it is another country, using international tort law. Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare (Walzer, 1977; Nardin, 1998) and many of the ideas extend to cyberweapons. Unethical behavior can be punished by activities like cyber-blockades as discussed below.\nA possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease (Lederberg, 1999). These have been banned by international convention because they affect military and civilian personnel equally and are difficult to target exclusively to military personnel. Targeting is difficult because biological agents can spread unpredictably due to wind, contacts, and normal biological processes. Perhaps the best analogy to cyberweapons is that of biological warfare against crops (Whitby, 2002), banned by the Biological and Toxin Weapons Convention of 1972. Crops are necessary resources that everyone in society needs, and are societal infrastructure. Attacking them is akin to terrorism.\nAnalogously, cyberwarfare does not target military personnel directly but only their software and data. But usually cyberattacks will be effective against any computer with the same type of vulnerable software. Military\norganizations use mostly software that is also used by civilians. So civilian computers could also suffer from military cyberattacks; in fact, they are usually more vulnerable because their countermeasures are not as good. If an attack on a military target goes astray, or if an attack propagates from a military target, civilian computers can easily be damaged. Or it may be tempting for a nation with cyberweapons to deliberately attack civilian computers and networks to cripple the economy of a target country, even though this violates international law. The Allies in World War II deliberately targeted civilian centers with bombing because they thought it would end the war more quickly.\n# RELIABILITY AND EFFECTIVENESS\nOne important difference between cyberattacks and conventional military attacks is in the reliability and effectiveness of the attack. If you fire a bullet at a target, it is highly likely to arrive there. If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet (Neumann, 1995). For another, the attack design itself may be faulty, the attack may not be able to find the target, or the target may not be vulnerable to the attack because assumptions made about it are no longer valid. Computers and software can be precise and highly controllable tools, so why cannot cyberweapons be made precise and controllable too?\nSome of the reason is the nature of warfare. To defend yourself, you need to hide and harden your assets. Military computers and software are known targets of adversaries, and governments try to limit their use to authorized personnel by passwords, encryption, enumerated access rights, and other access controls. Military systems are often on special networks behind layers of firewalls, or left unconnected to networks as in the case of weapons systems. System configurations like IP addresses can be changed periodically to foil overly specific\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nattacks, and decoy machines and “honeypots” (attack-data gathering machines) can divert an adversary and collect data about them. Network and system logging can track who is using systems and how, so abnormal usage can be caught quickly. Targeting is not as precise as is believed with conventional weapons anyway, as discussed in (Bissett, 2004). So cyberweapons are likely to be unreliable, and “surgical strikes” are unlikely in cyberspace.\nA contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability (Dunnigan, 2003). This is because new technology is usually complex and many things can go wrong. Software technology in particular permits implementation of very complex mechanisms. An exacerbating factor is that cyberweapons are poorly understood by military commanders since few have expertise in software. This means that commanders will tend to use cyberweapons, more than regular weapons, against the wrong targets in the wrong circumstances to achieve the wrong goals.\nWill cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable (Neumann, 1995). More specifically, cyberattacks depend on the novelty of their methods and secrecy to enforce it (as we discuss below). There are a limited number of attack methods and they generally can be used only once. So attackers will chronically suffer from inability to practice their attacks, and this will hurt their effectiveness.\n# THE RISK OF COLLATERAL DAMAGE IN CYBERSPACE\n“Collateral damage” or accidental harm to civilians is a key issue in both ethics and laws of warfare. Unfortunately, it is quite possible for cyberattacks aimed at military targets to accidentally hit civilian targets due to their unreliability and uncontrollability. One factor is that it can be hard to distinguish a military computer from a civilian computer. The localization of the target in physical space and\nidentification from its appearance that help so much in conventional warfare have no counterpart in cyberspace. Cyberspace addresses can be spoofed so one site can masquerade as another. Military organizations often use the same operating systems, bookkeeping, word-processing, and presentation software as businesses because it saves money (Jones, Kovacich, &amp; Luzwick, 2002), so examining the software may not indicate a military system. Most military files and data look just like files and data from any large civilian business, since most of both are undecipherable without knowing a good deal of specific jargon. (Some specialized sites can be more easily recognized, such as those controlling power plants, but they are well protected.) Within a military site, it may be hard to distinguish information about humanitarian activities such as hospitals and disaster relief from warfare information, so there could be intrasite collateral damage too; on a battlefield, it is easy to distinguish a tank from a Red Cross truck. Although many military computers have military network names and addresses, they could be camouflaged with a civilian name or address to reduce the chances of an adversary finding it (although it is harder in the U.S. where military site names all end in “.mil”). A clever adversary might also camouflage a civilian computer as a military one to provoke an adversary to attack it in the hope of provoking international outrage.\nSecondly, because of the difficulty of reaching military targets for a network-based attack or management of an internal attack, it is tempting to use other systems as “stepping stones” which the cyberattack subverts in a chain to reach the target machines. It is appealing to use civilian machines as stepping stones because many (like home computers) have minimal security. Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries (Himma, 2004).\nThirdly, even if a civilian computer is not initially attacked, an attack may spread to it. Some cyberattacks use computer viruses and worms that can propagate from one computer\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 25\nto another. Most other cyberattacks have some ability to spread from their original targets because targeting mistakes can be made or defensive surprises may occur. And some attacks like denial-of-service ones require propagation to work. But propagation abilities also make it easier for attacks to spread from military machines to civilian machines. The ubiquity of the Windows operating system and much of the same software on both military and civilian machines facilitates attack spread.\nFourthly, technologically developed countries provide the best targets for cyberweapons because they have so many things to attack. But cyberweapons require considerable technical expertise to develop, and such expertise is only readily available in the most technologically developed countries. This means an attack by a less technologically developed country is more likely to go astray and attack civilians, or perhaps be more likely to be deliberately targeted to do so because civilians are easier targets.\n# DAMAGE ASSESSMENT\nAn issue exacerbating the collateral damage problem with cyberweapons is the difficulty of determining what they did. When aircraft bomb a target, much damage can be seen from the air. With cyberweapons, the damage is not directly visible, which makes it more persistent and costly. Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first (Borg, 2005). Attacks may also fail for a host of unforeseen reasons; (Libicki, 2007) likens information warfare to introducing noise into a military organization, and the organization may or may not succeed at handling it.\nThis has important consequences for both the victim and the attacker. It may be hard for the victim to know if they have been attacked. The effects of an attack may be subtle, as when a worm slows down normal operations without changing anything else. Then the harm may persist for a long time because no one realizes anything is wrong. Or the effects may be time-\ndelayed, as when a virus in a defender’s weapons system causes it to fail only during combat. Then it may be difficult to find the cause, the harm will also persist until it is found, and repair may be costly. It would be foolish for an attacker to use an attack known to antivirus, antiworm, or antispyware tools, so we can assume such tools will be useless in finding or repairing damage from such attacks. While there are techniques for “system restoration” from backup storage media (Dorf &amp; Johnson, 2007), they are time-consuming and require expertise, and may not be able to restore important data unless backup has been highly diligent. And the original vulnerabilities that enabled the attack need to be found and fixed (“patched”) to prevent new attacks of the same kind, something that requires research and knowledgeable systems personnel. Less advanced countries may not have anyone with the necessary skills to do these things, leading to long-persistent damage much like that of landmines and chemical toxins that get into the water supply.\nFor the attacker, it may be very hard to know if their cyberattack had an effect. They may overcompensate by launching an unnecessarily powerful attack to be sure of an effect, or they may attack repeatedly unnecessarily. They may attack unnecessarily many kinds of software or data, and they may do unnecessarily drastic modifications to it. Unnecessarily strong attacks that are deep may be unnecessarily difficult to repair, and unnecessarily strong attacks that are broad run a higher risk of collateral damage to civilians. Unnecessarily strong attacks are particularly a danger for cyber-counterattacks, as we will discuss, because an adversary is anticipating counterattacks.\n# SECRECY OF CYBERWEAPONS\nAs mentioned, most cyberattacks exploit bugs or flaws in software. If the victims knew of these, they would have fixed them. So secrecy of attack methods is essential to the success of most cyberweapons.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nThis secrecy by itself can be unethical. Secrecy makes it harder for victim countries to figure out what happened to them. Standard attack-intelligence resources like Computer Emergency Response Teams (CERTs) collect information about known vulnerabilities, but cannot provide much help for cyberattacks used in warfare because the vulnerabilities will likely be new. This exacerbates the problem of diagnosis and repair discussed above. Also, misinformation about poorly-understood attacks may spread far in a crisis, creating overreaction and panic in the victim country. Misunderstanding can lead to scapegoating of innocent countries or groups, much as terrorist acts tend to be blamed on a country's known adversaries. It will be essential for information-security experts to provide dispassionate technical analysis of what has occurred, perhaps with neutral experts from an international agency.\nSecrecy also has negative consequences for the society that uses it (Bok, 1986). It encourages those who know the secrets to think they are better than those that do not, and permits those responsible for foolish attacks to avoid blame. Secret weapons are harder to test, since testing cannot be done publicly, and without adequate testing it is more likely that they will fail or cause collateral damage. An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once (Ranum, 2004). Once they are used and they create some military effect, computer-forensics methods can usually figure out what happened. Then a solution—fixing a bug, disabling software, turning off a utility, or blacklisting a site—can often be found in a day or so, and often a good solution will prevent similar attacks of the same type as well. This means that cyberweapons provide a poor return on investment, since exploitable flaws in software require considerable work to find. They are like a type of bomb that can only be used once anywhere in the world and never any bomb of that type again. It appears ethically unjustifiable for a society to spend resources on developing cyberweapons when there are so many other more useful things they could spend money on.\n# CYBER-COUNTERATTACKS\nInternational law prohibits attacks on other countries unless a country is attacked first (Walzer, 1977). Countries must agree to this in signing the United Nations charter; in the United States, the charter was a treaty approved by the U.S. Senate, and thus has the same force as any other law of the U.S. So unprovoked cyberattacks are clearly illegal and unethical. But what about cyber-counterattacks?\nIt is more difficult to prove responsibility for a cyberattack than for a conventional attack, since it is hard to trace from where it came. The apparent source may be \"spoofed\" by illicit modification of source-identification data, the apparent source may just be a \"stepping-stone\" as discussed earlier, and networks sites do not always keep good records. Even if we can trace an attack, the evidence is highly technical. This makes it hard to justify a counterattack to world public opinion.\nIn addition, a serious technical problem of cyber-counterattacks is the preparation and experimentation time necessary to set up good ones. If the cyber-counterattacks are from within a system, time is needed to establish a foothold on that system and station attack software on it. It will be unlikely that an attacker will succumb to the same attack they themselves launched – they should have plenty of time to harden their systems against it. In fact, an attacker should take special pains to harden their systems against all attacks, since counterattacks are sanctioned by international law. A smart attacker could even terminate all their network connections to the rest of the world for a time after an attack to markedly reduce the chances of an externally launched counterattack or exploitation of an internally launched one. Or they could put all their operating systems into hardware to prevent modification by Trojan horses and other exploits. So it will not be easy to launch a successful counterattack, and some considerable\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 27\nnumber of tries by the counterattacker with many methods may be necessary to find one that works, if one can be found at all.\nThese issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack (Gardam, 2004). Legitimate counterattacks cannot wait years (such as the claim that the 2001 attack on the New York World Trade Center was a response to the U.S.-Iraq war of 1991), cannot use some quite different technology (as the introduction of poison gas by the Germans in 1915), and cannot be considerably larger. Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical (Fotion and Elfstrom, 1986).\nOne way to facilitate counterattacks is to station counterattack software in advance of attack, and channels to communicate with it like those of botnets, on computer systems of adversaries just in the chance there might be hostilities which could use it. Then they might be invoked quickly. Such capabilities could deter an adversary attack in the first place, if the adversary knows or cares about those capabilities (deterrence does not always work well as a military strategy). However, designing counterattacks that will work when needed is not easy. Just because they worked in the laboratory against fixed targets does not provide much confidence they will work during warfare, a problem that occurs in testing much new military technology. Computer systems are installing new protections all the time, so possible attack methods can become obsolete without warning. That means that the older an attack is, the less likely it is to work. Counterattack software is identical to attack software, so it is just as criminal to use in most countries, and just as hard to test in realistic warfare conditions. Furthermore, a hasty counterattack may harm the counterattacker more than the attacker because it reveals counterattacker cyberweapons to the attacker and allows them to test how they\ncan be defeated, information that they might not be able to obtain otherwise.\nA way to reduce counterattack obsolescence is to use a broader \"strategic\" counterattack rather than a tactical one. An example would be modifying all the code for a networking protocol used by an adversary by modifying the source for that code in a repository. If all adversary military systems download their code from there, all could be infected from a single source, and the code could function normally until the counterattack. Such methods would be high on the scale of perfidy. But there are difficult practical problems. Adversaries that contemplate attacking other countries will set a high priority on protecting their frequently used software and will use hashes (pseudorandom data reductions) regularly to check for modifications to it. Most software is updated regularly, so the counterattacker would need to repeatedly modify the code with each update. Most updates come directly from software companies and not a military repository, and it would be hard for counterattackers to reach all these sources, and even harder to modify code in transmission. A broad strategic attack is easier to diagnose than a tactical (limited) one because there will be many malfunctioning systems simultaneously; this provides good data for identifying the type of attack and its software locus, so such attacks can be fixed more quickly than those that attack just one system. Finally, a broad counterattack based in common software risks more collateral damage to noncombat functions of computer systems than a more targeted counterattack.\nNot all cyber-counterattacks require preparation. Those launched across the Internet can be mounted more easily at any time. Defending against such attacks is, however, the primary focus of the network intrusion-prevention systems which defend most of our network sites, which are kept updated with the latest known attacks. It is difficult, though not impossible, to invent a new attack that will succeed against these formidable defenses. A country could try to \"stockpile\" new such attacks in the interests of its defense, but the effort to find such attacks might quickly be wasted as countermeasures are\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nindependently discovered as discussed above. What attacks that do succeed in circumventing the first level of defenses may succumb to second levels of defenses that note anomalous behavior, so they are unlikely to succeed for long once they start attacking. For instance, systematic search for the computers on a local-area network is necessary for precisely targeted attacks, but such searching is obvious to network packet monitoring since normal usage rarely does it. So network-based attacks are quite unreliable, and military commanders dislike unreliable technology. Thus it appears that cyber-counterattacks are infeasible.\n# DESIGNING ETHICAL CYBERWEAPONS\nDespite the issues raised here, countries will likely continue to develop cyberweapons. Can such weapons be designed and used more ethically? We believe they can, since ethical discriminations can be made today among different kinds of weapons. For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately (Johnson, 1984).\nSince controllability is a serious concern with cyberweapons, ethical weapons should use a variety of methods to ensure focused targeting. Propagation via viruses and worms should be minimized. Attacks should focus on a limited set of important targets which should be clearly identified and confirmed during the attack using more than their Internet address. Important civilian systems such as commercial infrastructure should clearly identify themselves as civilian so attacks can know to avoid them.\nEthical attacks should also be easily stoppable. If an adversary surrenders, it is unethical as well as against international law to continue attacking and causing damage. This means that all attacks should be under quick control via some mechanism such as an emergency channel so that they can be halted if necessary.\nThis may be difficult with automated attacks, and the effects of any attack will likely impede communication. But it is important.\nIdentification of the attacker (\"attribution\") should also be a key feature of ethical attacks, much as how uniforms to identify military personnel in warfare. Acting as a soldier while not wearing a uniform is outlawed by international law. So some data associated with a cyberattack should identify who is responsible for an attack. One way is to add a digital signature to data or a program (Mel &amp; Baker, 2000). Several technologies to do this are available, and the best-known is encryption with a private key of a public-private key pair of a hash of the contents. Using a hash means that the public key confirms that the contents were not modified after they were signed. Responsible attackers will find signatures useful because they prove they are responsible for an attack and prevent scapegoating of others. Unattributed attacks are not very useful anyway since attacks are usually a way to force a country to do something, and the victim cannot know what to do unless they know who has attacked them. Signatures also permit the attacker to recognize their own signature on already-attacked systems and avoid reattacking them. Public keys for attack signatures could be kept with international organizations like the United Nations as a form of \"key escrow\" like that proposed for backup on encrypted systems.\nNot everyone agrees that attacks should be attributable. Robb (2009) argues that cyberattacks will be ineffective unless that have deniability, like some instances of \"special operations\" using commandos. But if he is right, then all effective cyberattacks are forms of terrorism.\nA weakness of signatures is that they might be recognized by defenders and enable them to realize they are being attacked, which might matter with the more subtle attacks. But it will not be easy to recognize attack signatures because many programs today have signatures as a security measure. Also, since they are a function of the contents, their bits will differ when attached to different files or data. However, if\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 29\nit is important that a signature be concealed, steganography can be used by the attacker (Wayner, 2002). This is a class of techniques for concealing data inside innocent-looking other data, like concealing code messages in the least-significant bits of pictures.\nSince damage persistence is a key problem with cyberweapons, it would be more ethical to use weapons whose damage is easily repairable at the end of hostilities. This is more possible in cyberspace than in conventional warfare. For instance, an attack could encrypt important parts of a victim's system so that they cannot be used until the attacker supplies a key to undo (decrypt) them. Since encryption and decryption do not lose any information, the attack would be completely reversible. This would be an ethical alternative whenever it is impossible for a victim to restore a system from backup. Similarly, an attack could withhold important messages (like orders or email) from a victim. If the attacker saves those messages, they could be supplied to the victim at the cessation of hostilities, thereby reversing the attack. In both cases, there may be some damage from denial of timely access to data, but this can be minimized if the target systems are chosen carefully.\nthan physical blockades. There are alternatives to banks, but there is only one Internet.\n# CONCLUSION\nMost coverage of cyberweapons has been relatively neutral, referring to cyberweapons as inevitable new weapons technology that can be employed much like any other. Our argument here is that this cyberweapons have a variety of unique problems that impede their effectiveness and ethicality, and that \"cyberpacifism\" should be encouraged. Cyberweapons are less reliable and less controllable weapons than conventional ones, much like biological weapons, and thus a poor choice in warfare. They disproportionately threaten civilians and harm the society that develops and uses them. It is hard to figure out what is happening when cyberweapons are used due to secrecy and the inherent difficulty of analyzing cyberspace, and their employment for counterattacks seems particularly challenging. While some ways of using cyberweapons are better than others, there are currently insufficient incentives to use them ethically. Their use should be outlawed.\n# ACKNOWLEDGMENT\nThe views expressed are those of the author and do not represent those of any part of the U.S. Government."
    },
    "author_year": {
      "total": {
        "intext_total": 25,
        "success_occurrences": 25,
        "success_unique": 22,
        "bib_unique_total": 66,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.3333333333333333,
        "success_percentage": 100.0,
        "style": "author_year"
      },
      "results": [
        {
          "index": "bayles|2001",
          "intext_citation": "(Bayles, 2001)",
          "preceding_text": "Cyberweapons are software used to attack other software or data within computer systems",
          "footnote": "Bayles, W. (2001). Network attack. Parameters. US Army War College Quarterly, 31, 44-58."
        },
        {
          "index": "libicki|2007",
          "intext_citation": "(Libicki, 2007)",
          "preceding_text": "cyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects",
          "footnote": "Libicki, M. (2007). Conquest in cyberspace: national security and information warfare. New York: Cambridge University Press."
        },
        {
          "index": "denning|1999",
          "intext_citation": "(Denning, 1999)",
          "preceding_text": "Military organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare",
          "footnote": "Denning, D. (1999). Information Warfare and Security. Boston, MA: Addison-Wesley."
        },
        {
          "index": "kuhnhauser|2004",
          "intext_citation": "(Kuhnhauser, 2004)",
          "preceding_text": "So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits”",
          "footnote": "Kuhnhauser, W. (2004, January). Root kits: an operating systems viewpoint. ACM SIGOPS Operating Systems Review, 38(1), 12–23. doi:10.1145/974104.974105"
        },
        {
          "index": "bailey|2009",
          "intext_citation": "(Bailey et al., 2009)",
          "preceding_text": "This technology is called “rootkits” (Kuhnhauser, 2004). Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user",
          "footnote": "Bailey, M., Cooke, E., Jahanian, F., Xu, Y., &amp; Karir, M. (2009, March). A survey of botnet technology and defenses. Proc. Conf. for Homeland Security: Cybersecurity Applications and Technology."
        },
        {
          "index": "ceruti|2001",
          "intext_citation": "(Ceruti, 2001)",
          "preceding_text": "Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents”",
          "footnote": "Ceruti, M. (2001, March). Mobile agents in network-centric warfare. Proc. 5th International Symposium on Autonomous Decentralized Systems (pp. 243–246)."
        },
        {
          "index": "verton|2003",
          "intext_citation": "(Verton, 2003)",
          "preceding_text": "Cyberweapons do not currently seem to be an interest of terrorist groups. They could be",
          "footnote": "Verton, D. (2003). Black ice: the invisible threat of cyber-terrorism. New York: McGraw-Hill Osborne Media."
        },
        {
          "index": "arquilla|1999",
          "intext_citation": "(Arquilla, 1999)",
          "preceding_text": "In many cases they violate international war conventions as well",
          "footnote": "Arquilla, J. (1999). Ethics and information warfare. In Z. Khalilzad, J. White, &amp; A. Marsall (Eds.), Strategic appraisal: the changing role of information in warfare (pp. 379-401). Rand Corporation, Santa Monica, CA, USA."
        },
        {
          "index": "walzer|1977",
          "intext_citation": "(Walzer, 1977; Nardin, 1998)",
          "preceding_text": "Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare",
          "footnote": "Walzer, D. (1977). Just and unjust wars: a moral argument with historical illustrations. New York: Basic Books."
        },
        {
          "index": "lederberg|1999",
          "intext_citation": "(Lederberg, 1999)",
          "preceding_text": "A possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease",
          "footnote": "Lederberg, J. (Ed.). (1999). Biological weapons: limiting the threat. Cambridge, MA: MIT Press."
        },
        {
          "index": "whitby|2002",
          "intext_citation": "(Whitby, 2002)",
          "preceding_text": "Perhaps the best analogy to cyberweapons is that of biological warfare against crops",
          "footnote": "Whitby, S. (2002). Biological warfare against crops. Houndmills, UK: Palgrave."
        },
        {
          "index": "neumann|1995",
          "intext_citation": "(Neumann, 1995)",
          "preceding_text": "If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet",
          "footnote": "Neumann, P. (1995). Computer related risks. Reading, MA: ACM Press."
        },
        {
          "index": "bissett|2004",
          "intext_citation": "(Bissett, 2004)",
          "preceding_text": "Targeting is not as precise as is believed with conventional weapons anyway, as discussed in",
          "footnote": "Bissett, A. (2004). High technology war and ‘surgical strikes’. [ACM SIGCAS]. Computers &amp; Society, 32(7), 4."
        },
        {
          "index": "dunnigan|2003",
          "intext_citation": "(Dunnigan, 2003)",
          "preceding_text": "A contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability",
          "footnote": "Dunnigan, J. (2003). How to make war. (4th ed.). New York: Quill."
        },
        {
          "index": "neumann|1995",
          "intext_citation": "(Neumann, 1995)",
          "preceding_text": "Will cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable",
          "footnote": "Neumann, P. (1995). Computer related risks. Reading, MA: ACM Press."
        },
        {
          "index": "himma|2004",
          "intext_citation": "(Himma, 2004)",
          "preceding_text": "Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries",
          "footnote": "Himma, K. (2004). The ethics of tracing hacker attacks through the machines of innocent persons. International Journal of Information Ethics, 2(11), 1–13."
        },
        {
          "index": "borg|2005",
          "intext_citation": "(Borg, 2005)",
          "preceding_text": "Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first",
          "footnote": "Borg, S. (2005, November-December). Economically complex cyberattacks. IEEE Security and Privacy, 3(6), 64–67. doi:10.1109/MSP.2005.146"
        },
        {
          "index": "libicki|2007",
          "intext_citation": "(Libicki, 2007)",
          "preceding_text": "Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first (Borg, 2005). Attacks may also fail for a host of unforeseen reasons;",
          "footnote": "Libicki, M. (2007). Conquest in cyberspace: national security and information warfare. New York: Cambridge University Press."
        },
        {
          "index": "bok|1986",
          "intext_citation": "(Bok, 1986)",
          "preceding_text": "Secrecy also has negative consequences for the society that uses it",
          "footnote": "Bok, S. (1986). Secrets. Oxford, UK: Oxford University Press."
        },
        {
          "index": "ranum|2004",
          "intext_citation": "(Ranum, 2004)",
          "preceding_text": "An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once",
          "footnote": "Ranum, M. (2004). The myth of homeland security. Indianapolis, IN: Wiley."
        },
        {
          "index": "walzer|1977",
          "intext_citation": "(Walzer, 1977)",
          "preceding_text": "International law prohibits attacks on other countries unless a country is attacked first",
          "footnote": "Walzer, D. (1977). Just and unjust wars: a moral argument with historical illustrations. New York: Basic Books."
        },
        {
          "index": "gardam|2004",
          "intext_citation": "(Gardam, 2004)",
          "preceding_text": "se issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack",
          "footnote": "Gardam, J. (2004). Necessity, proportionality, and the use of force by states. Cambridge, UK: Cambridge University Press."
        },
        {
          "index": "fotion|1986",
          "intext_citation": "(Fotion and Elfstrom, 1986)",
          "preceding_text": "Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical",
          "footnote": "Fotion, N., &amp; Elfstrom, G. (1986). Military ethics: guidelines for peace and war. Boston: Routledge and Kegan Paul."
        },
        {
          "index": "johnson|1984",
          "intext_citation": "(Johnson, 1984)",
          "preceding_text": "For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately",
          "footnote": "Johnson, J. (1984). Can modern war be just? New Haven: Yale University Press."
        },
        {
          "index": "wayner|2002",
          "intext_citation": "(Wayner, 2002)",
          "preceding_text": "it is important that a signature be concealed, steganography can be used by the attacker",
          "footnote": "Wayner, P. (2002). Disappearing cryptography: information hiding: steganography and watermarking. San Francisco, CA: Morgan Kaufmann."
        }
      ],
      "flat_text": "IGI Global Scientific Publishing Platform Downloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\n\n# The Ethics of Cyberweapons in Warfare\nNeil C. Rowe, U.S. Naval Postgraduate School, USA\n# ABSTRACT\nThe author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement.\nKeywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons\n# INTRODUCTION\nCyberweapons are software used to attack other software or data within computer systems . We distinguish cyberweapons and cyberattacks (attacks using cyberweapons) from \"information warfare\", a more general term that includes propaganda, electronic surveillance, cyber-espionage, and defensive information operations (Jones, Kovacich, &amp; Luzwick, 2002). That is, we will focus on \"network attack\" and not \"network exploitation\" or \"network defense\".\nLike conventional weapons, cyberweapons can be used against a variety of targets in a variety of circumstances with a wide range of lethality (White Wolf Security, 2009). Often\nCryptography © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\ncyberweapons exploit flaws or errors in software. Proponents have cited these as \"clean\" weapons that are safer than conventional weapons since they do not damage physical objects . Furthermore, unlike chemical, biological, and nuclear weapons, people have no visceral fear of cyberweapons for reasons like health consequences. But maybe they should. All weapons can have serious harms by virtue of their being weapons. The public is unaware of the degree to which they depend on computer systems and the information they store, and thus weapons targeting them can have many unforeseen consequences. For instance, targeting a country's Internet service providers can prevent goods from being delivered, and cause people to starve or die from lack of necessary medical supplies.\nDOI: 10.4018/jte.2010081002\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 21\nThere are several schools of ethics. In this article we will follow a pragmatic approach derived from utilitarian ethics in which we argue that a technology is unethical if it has a significant net harm to world society (“negative utilitarianism”). We would also like to derive ethical principles of using cyberweapons, so we will follow “rule utilitarianism”. Such principles can then be codified in laws of warfare. However, we do not need an elaborate ethical foundation here because most of the ethical issues with cyberattacks seem similarly problematic under any ethical framework.\n# THE STATE OF THE ART IN CYBERWEAPONS\nMilitary organizations have noted the success of amateur attackers (“hackers”) in damaging computer systems, and have hoped to use these techniques or “exploits” for military advantage, much as they seek a wide variety of ways to gain advantage in warfare . Many of these techniques exploit flaws in software. Certain kinds of errors such as failure to check for buffer overflows in loops or failure to properly label data on Web sites can lead to granting of unauthorized special privileges to users of a system. Cyberweapons are programs that package a set of such exploits against a computer system and its data. Cyberweapons can be launched or controlled either externally, from another computer or the Internet, or internally, by spies and saboteurs (Knapp &amp; Boulton, 2007).\nCyberattackers can use their access and privileges to destroy the data and software on a computer system or network, but that is pretty obvious and tells the victim they have been attacked. Cyberattackers can modify the data on a victim system to impede military operations, but that requires a good deal of contextual knowledge about the data. So a better goal for cyberweapons is to take control of a system without the knowledge of the system’s owner so it can be used for the attacker’s purposes. This technology is called “rootkits” . Sets of such remotely controlled computers can be used to create “botnets”, networks of slave computers under the control of a single user . Hacker botnets have been used to earn money by sending spam or phishing email from the slave computers, have been used for denial-of-service attacks against organizations the attacker does not like, have been used for blackmail of organizations by threatening malicious mischief, and have been used for espionage. Botnets developed for military purposes could stop an adversary’s military organization from communicating or defending itself.\nCyberweapons can be an innocent-looking software module. Running them to see what they do is not easy because many require passwords to run and their effects may be very subtle. Thus it is difficult to identify cyberweapons within a computer system. Cyberweapons are easy to transport because they are just bit patterns that can be easily copied, or they can even wander autonomously as mobile “agents” . And when they have served their purpose, they can be deleted. This makes it considerably harder to police cyberweapons than nuclear, chemical, and biological weapons. Nonetheless, traces of a cyberattack will be visible on the victim’s computers and networks, and range of methods of “computer forensics” (Mandia &amp; Prosise, 2003) can analyze these traces.\nCyberweapons can attack many kinds of military targets. An obvious one is an adversary’s “command and control”, their communications and electronic mail, because these are essential to organizing a defense. Since command-and-control tools are distributed across many machines, there are many potential entry points for an attack. Weapons-controlling and vehicle-controlling software are also desirable targets of cyberweapons, but they are harder to attack because they are carefully protected and often (especially for weapons) do not use networks much. Logistics and supply could be targeted, but effects would not be immediate, and surprise is a key element of cyberattack effectiveness. Managerial support for the military could be targeted, because its protections tend\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nto be less, but again the effects would not be immediate, and troops can fight without managers. Public relations (like Web sites) might be a good target, because public perception is so much a part of winning a war, but the damage would only be psychological.\nCyberattacks may be coupled to conventional military attacks, and this may enhance the effectiveness of both. For instance, China claims sovereignty over the island of Taiwan, but Taiwan has formidable defenses and the support of the U.S. Navy. If China were to attack, they would need all the resources they could muster, and a simultaneous cyberattack could be very helpful considering the heavy reliance of the U.S. Navy on software and digital data.\nCyberattacks can also target a country's important civilian infrastructure such as its Internet sites, its financial services sector, its power grid, or even the common software it uses. The Department of Homeland Security in the United States studies this kind of threat. Attacks on nonmilitary targets are generally outlawed by the international warfare conventions, with exceptions for strong military necessity. They are not guaranteed to succeed because there is considerably less centralization in the civilian sector than there is in military organizations, and it can be hard to hit enough targets to achieve the effect of a conventional military attack. They are thus not the first choice of military commanders because the commanders' biggest concern is preventing counterattacks, and they will get them unless they primarily target a country's military. Terrorists might be more likely to choose civilian targets for cyberattacks because terrorist organizations are hard to find and track. Nonetheless, a terrorist organization needs to do public relations for recruitment, needs to acknowledge attacks to gain a public-relations benefit, and needs to maintain a communications network, and this provides a start in tracking them down.\nCyberweapons development has been reported in several major countries in the last few years. Most reports have focused on China which has ambitious goals for military operations in cyberspace, but other countries with\nsoftware expertise such as Russia have also been mentioned. The United States military does not like to lag technologically behind anyone; recent announcement of a U.S. Air Force \"Cyberspace Command\" (24th Air Force Command) suggests the United States is now investigating these weapons in secret work. Cyberweapons need not be confined to advanced countries, however, because the technology for developing them does not require much capital investment. It does require expertise in software, which limits their development in countries with poor educational systems. Cyberweapons do not currently seem to be an interest of terrorist groups. They could be , but it seems unlikely in the near future since most groups today are anti-technology or, like Al Qaeda, forced to avoid technology to avoid being tracked.\n# LAW FOR CYBERATTACKS\nCyberattacks using cyberweapons are activities that would classified as crimes in their victim countries if done by ordinary citizens. Necessarily they involve trespassing; to be effective they must employ fraud and vandalism; and often they must also involve espionage, sabotage, and virtual assaults. In many cases they violate international war conventions as well . While enforcement of international laws of war has been inconsistent, enforcement has been increasingly successful in recent years, so they should be taken seriously.\nA particularly troubling issue with cyberattacks is their frequent use of identity deceptions of various kinds, such as by the concealed modifications of an operating system done by rootkits, or the masquerading as legitimate users to gain access. This brings cyberattacks often close to perfidy, a war crime outlawed by international law. Perfidy is attackers masquerading as a legitimate civilian activity, such as soldiers pretending to be Red Cross workers. Perfidy is considered unacceptable in war because it blurs the distinction between combatants and noncombatants, and encourages attacks on civilians. It is certainly fair for combatants to\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 23\nuse camouflage. But an operating system is essential to use a computer, so compromising it and turning it into a computer-virus delivery tool is like putting a poison in a community’s water system. The argument for perfidy is strongest for the critical parts of an operating system for enforcing access controls, the “kernel”, since everyone relies on them and there is no legitimate reason to tamper with them. Other possible candidates for perfidy are tamperings with the key networking software such as routers and as TCP/IP protocols since they are essential for many cyberspace activities.\nIf someone damages a computer or data, the owner of the computer or data can sue the attacker in civil legal proceedings in many countries. This may apply to cyberattacks. If the victims are sufficiently widespread within a country, the country as a whole may be able to sue the attacker, even if it is another country, using international tort law. Cyberattacks also can be unethical even if legal. Much literature over the years has addressed the ethics of warfare  and many of the ideas extend to cyberweapons. Unethical behavior can be punished by activities like cyber-blockades as discussed below.\nA possible analogy to cyberweapons are biological weapons, weapons that cause illness and disease . These have been banned by international convention because they affect military and civilian personnel equally and are difficult to target exclusively to military personnel. Targeting is difficult because biological agents can spread unpredictably due to wind, contacts, and normal biological processes. Perhaps the best analogy to cyberweapons is that of biological warfare against crops , banned by the Biological and Toxin Weapons Convention of 1972. Crops are necessary resources that everyone in society needs, and are societal infrastructure. Attacking them is akin to terrorism.\nAnalogously, cyberwarfare does not target military personnel directly but only their software and data. But usually cyberattacks will be effective against any computer with the same type of vulnerable software. Military\norganizations use mostly software that is also used by civilians. So civilian computers could also suffer from military cyberattacks; in fact, they are usually more vulnerable because their countermeasures are not as good. If an attack on a military target goes astray, or if an attack propagates from a military target, civilian computers can easily be damaged. Or it may be tempting for a nation with cyberweapons to deliberately attack civilian computers and networks to cripple the economy of a target country, even though this violates international law. The Allies in World War II deliberately targeted civilian centers with bombing because they thought it would end the war more quickly.\n# RELIABILITY AND EFFECTIVENESS\nOne important difference between cyberattacks and conventional military attacks is in the reliability and effectiveness of the attack. If you fire a bullet at a target, it is highly likely to arrive there. If you execute cyberattack software against a cyber target, it is much less likely to work. For one thing, software-based systems can fail in many more ways than a bullet . For another, the attack design itself may be faulty, the attack may not be able to find the target, or the target may not be vulnerable to the attack because assumptions made about it are no longer valid. Computers and software can be precise and highly controllable tools, so why cannot cyberweapons be made precise and controllable too?\nSome of the reason is the nature of warfare. To defend yourself, you need to hide and harden your assets. Military computers and software are known targets of adversaries, and governments try to limit their use to authorized personnel by passwords, encryption, enumerated access rights, and other access controls. Military systems are often on special networks behind layers of firewalls, or left unconnected to networks as in the case of weapons systems. System configurations like IP addresses can be changed periodically to foil overly specific\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nattacks, and decoy machines and “honeypots” (attack-data gathering machines) can divert an adversary and collect data about them. Network and system logging can track who is using systems and how, so abnormal usage can be caught quickly. Targeting is not as precise as is believed with conventional weapons anyway, as discussed in . So cyberweapons are likely to be unreliable, and “surgical strikes” are unlikely in cyberspace.\nA contributing factor is that cyberweapons are new, and new weapons have high error rates and low reliability . This is because new technology is usually complex and many things can go wrong. Software technology in particular permits implementation of very complex mechanisms. An exacerbating factor is that cyberweapons are poorly understood by military commanders since few have expertise in software. This means that commanders will tend to use cyberweapons, more than regular weapons, against the wrong targets in the wrong circumstances to achieve the wrong goals.\nWill cyberweapons improve in reliability and effectiveness with time? It is unlikely, as software in general is not getting any more reliable . More specifically, cyberattacks depend on the novelty of their methods and secrecy to enforce it (as we discuss below). There are a limited number of attack methods and they generally can be used only once. So attackers will chronically suffer from inability to practice their attacks, and this will hurt their effectiveness.\n# THE RISK OF COLLATERAL DAMAGE IN CYBERSPACE\n“Collateral damage” or accidental harm to civilians is a key issue in both ethics and laws of warfare. Unfortunately, it is quite possible for cyberattacks aimed at military targets to accidentally hit civilian targets due to their unreliability and uncontrollability. One factor is that it can be hard to distinguish a military computer from a civilian computer. The localization of the target in physical space and\nidentification from its appearance that help so much in conventional warfare have no counterpart in cyberspace. Cyberspace addresses can be spoofed so one site can masquerade as another. Military organizations often use the same operating systems, bookkeeping, word-processing, and presentation software as businesses because it saves money (Jones, Kovacich, &amp; Luzwick, 2002), so examining the software may not indicate a military system. Most military files and data look just like files and data from any large civilian business, since most of both are undecipherable without knowing a good deal of specific jargon. (Some specialized sites can be more easily recognized, such as those controlling power plants, but they are well protected.) Within a military site, it may be hard to distinguish information about humanitarian activities such as hospitals and disaster relief from warfare information, so there could be intrasite collateral damage too; on a battlefield, it is easy to distinguish a tank from a Red Cross truck. Although many military computers have military network names and addresses, they could be camouflaged with a civilian name or address to reduce the chances of an adversary finding it (although it is harder in the U.S. where military site names all end in “.mil”). A clever adversary might also camouflage a civilian computer as a military one to provoke an adversary to attack it in the hope of provoking international outrage.\nSecondly, because of the difficulty of reaching military targets for a network-based attack or management of an internal attack, it is tempting to use other systems as “stepping stones” which the cyberattack subverts in a chain to reach the target machines. It is appealing to use civilian machines as stepping stones because many (like home computers) have minimal security. Damage to the stepping stones will occur in setting up communications. This kind of activity is trespassing and is illegal in most countries .\nThirdly, even if a civilian computer is not initially attacked, an attack may spread to it. Some cyberattacks use computer viruses and worms that can propagate from one computer\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 25\nto another. Most other cyberattacks have some ability to spread from their original targets because targeting mistakes can be made or defensive surprises may occur. And some attacks like denial-of-service ones require propagation to work. But propagation abilities also make it easier for attacks to spread from military machines to civilian machines. The ubiquity of the Windows operating system and much of the same software on both military and civilian machines facilitates attack spread.\nFourthly, technologically developed countries provide the best targets for cyberweapons because they have so many things to attack. But cyberweapons require considerable technical expertise to develop, and such expertise is only readily available in the most technologically developed countries. This means an attack by a less technologically developed country is more likely to go astray and attack civilians, or perhaps be more likely to be deliberately targeted to do so because civilians are easier targets.\n# DAMAGE ASSESSMENT\nAn issue exacerbating the collateral damage problem with cyberweapons is the difficulty of determining what they did. When aircraft bomb a target, much damage can be seen from the air. With cyberweapons, the damage is not directly visible, which makes it more persistent and costly. Attacks may also cause much indirect damage because of interdependencies that may not be obvious at first . Attacks may also fail for a host of unforeseen reasons;  likens information warfare to introducing noise into a military organization, and the organization may or may not succeed at handling it.\nThis has important consequences for both the victim and the attacker. It may be hard for the victim to know if they have been attacked. The effects of an attack may be subtle, as when a worm slows down normal operations without changing anything else. Then the harm may persist for a long time because no one realizes anything is wrong. Or the effects may be time-\ndelayed, as when a virus in a defender’s weapons system causes it to fail only during combat. Then it may be difficult to find the cause, the harm will also persist until it is found, and repair may be costly. It would be foolish for an attacker to use an attack known to antivirus, antiworm, or antispyware tools, so we can assume such tools will be useless in finding or repairing damage from such attacks. While there are techniques for “system restoration” from backup storage media (Dorf &amp; Johnson, 2007), they are time-consuming and require expertise, and may not be able to restore important data unless backup has been highly diligent. And the original vulnerabilities that enabled the attack need to be found and fixed (“patched”) to prevent new attacks of the same kind, something that requires research and knowledgeable systems personnel. Less advanced countries may not have anyone with the necessary skills to do these things, leading to long-persistent damage much like that of landmines and chemical toxins that get into the water supply.\nFor the attacker, it may be very hard to know if their cyberattack had an effect. They may overcompensate by launching an unnecessarily powerful attack to be sure of an effect, or they may attack repeatedly unnecessarily. They may attack unnecessarily many kinds of software or data, and they may do unnecessarily drastic modifications to it. Unnecessarily strong attacks that are deep may be unnecessarily difficult to repair, and unnecessarily strong attacks that are broad run a higher risk of collateral damage to civilians. Unnecessarily strong attacks are particularly a danger for cyber-counterattacks, as we will discuss, because an adversary is anticipating counterattacks.\n# SECRECY OF CYBERWEAPONS\nAs mentioned, most cyberattacks exploit bugs or flaws in software. If the victims knew of these, they would have fixed them. So secrecy of attack methods is essential to the success of most cyberweapons.\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nThis secrecy by itself can be unethical. Secrecy makes it harder for victim countries to figure out what happened to them. Standard attack-intelligence resources like Computer Emergency Response Teams (CERTs) collect information about known vulnerabilities, but cannot provide much help for cyberattacks used in warfare because the vulnerabilities will likely be new. This exacerbates the problem of diagnosis and repair discussed above. Also, misinformation about poorly-understood attacks may spread far in a crisis, creating overreaction and panic in the victim country. Misunderstanding can lead to scapegoating of innocent countries or groups, much as terrorist acts tend to be blamed on a country's known adversaries. It will be essential for information-security experts to provide dispassionate technical analysis of what has occurred, perhaps with neutral experts from an international agency.\nSecrecy also has negative consequences for the society that uses it . It encourages those who know the secrets to think they are better than those that do not, and permits those responsible for foolish attacks to avoid blame. Secret weapons are harder to test, since testing cannot be done publicly, and without adequate testing it is more likely that they will fail or cause collateral damage. An especially important consequence of the necessary secrecy of cyberweapons is that they can only be used effectively once . Once they are used and they create some military effect, computer-forensics methods can usually figure out what happened. Then a solution—fixing a bug, disabling software, turning off a utility, or blacklisting a site—can often be found in a day or so, and often a good solution will prevent similar attacks of the same type as well. This means that cyberweapons provide a poor return on investment, since exploitable flaws in software require considerable work to find. They are like a type of bomb that can only be used once anywhere in the world and never any bomb of that type again. It appears ethically unjustifiable for a society to spend resources on developing cyberweapons when there are so many other more useful things they could spend money on.\n# CYBER-COUNTERATTACKS\nInternational law prohibits attacks on other countries unless a country is attacked first . Countries must agree to this in signing the United Nations charter; in the United States, the charter was a treaty approved by the U.S. Senate, and thus has the same force as any other law of the U.S. So unprovoked cyberattacks are clearly illegal and unethical. But what about cyber-counterattacks?\nIt is more difficult to prove responsibility for a cyberattack than for a conventional attack, since it is hard to trace from where it came. The apparent source may be \"spoofed\" by illicit modification of source-identification data, the apparent source may just be a \"stepping-stone\" as discussed earlier, and networks sites do not always keep good records. Even if we can trace an attack, the evidence is highly technical. This makes it hard to justify a counterattack to world public opinion.\nIn addition, a serious technical problem of cyber-counterattacks is the preparation and experimentation time necessary to set up good ones. If the cyber-counterattacks are from within a system, time is needed to establish a foothold on that system and station attack software on it. It will be unlikely that an attacker will succumb to the same attack they themselves launched – they should have plenty of time to harden their systems against it. In fact, an attacker should take special pains to harden their systems against all attacks, since counterattacks are sanctioned by international law. A smart attacker could even terminate all their network connections to the rest of the world for a time after an attack to markedly reduce the chances of an externally launched counterattack or exploitation of an internally launched one. Or they could put all their operating systems into hardware to prevent modification by Trojan horses and other exploits. So it will not be easy to launch a successful counterattack, and some considerable\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 27\nnumber of tries by the counterattacker with many methods may be necessary to find one that works, if one can be found at all.\nThese issues create problems for the laws of war, because the legitimacy of a counterattack in conventional warfare is established by its immediacy after the attack, its being of the same type as the attack, and its proportionality to the magnitude of the attack . Legitimate counterattacks cannot wait years (such as the claim that the 2001 attack on the New York World Trade Center was a response to the U.S.-Iraq war of 1991), cannot use some quite different technology (as the introduction of poison gas by the Germans in 1915), and cannot be considerably larger. Counterattacks that violate these criteria must be classified as new attacks and are therefore illegal and unethical .\nOne way to facilitate counterattacks is to station counterattack software in advance of attack, and channels to communicate with it like those of botnets, on computer systems of adversaries just in the chance there might be hostilities which could use it. Then they might be invoked quickly. Such capabilities could deter an adversary attack in the first place, if the adversary knows or cares about those capabilities (deterrence does not always work well as a military strategy). However, designing counterattacks that will work when needed is not easy. Just because they worked in the laboratory against fixed targets does not provide much confidence they will work during warfare, a problem that occurs in testing much new military technology. Computer systems are installing new protections all the time, so possible attack methods can become obsolete without warning. That means that the older an attack is, the less likely it is to work. Counterattack software is identical to attack software, so it is just as criminal to use in most countries, and just as hard to test in realistic warfare conditions. Furthermore, a hasty counterattack may harm the counterattacker more than the attacker because it reveals counterattacker cyberweapons to the attacker and allows them to test how they\ncan be defeated, information that they might not be able to obtain otherwise.\nA way to reduce counterattack obsolescence is to use a broader \"strategic\" counterattack rather than a tactical one. An example would be modifying all the code for a networking protocol used by an adversary by modifying the source for that code in a repository. If all adversary military systems download their code from there, all could be infected from a single source, and the code could function normally until the counterattack. Such methods would be high on the scale of perfidy. But there are difficult practical problems. Adversaries that contemplate attacking other countries will set a high priority on protecting their frequently used software and will use hashes (pseudorandom data reductions) regularly to check for modifications to it. Most software is updated regularly, so the counterattacker would need to repeatedly modify the code with each update. Most updates come directly from software companies and not a military repository, and it would be hard for counterattackers to reach all these sources, and even harder to modify code in transmission. A broad strategic attack is easier to diagnose than a tactical (limited) one because there will be many malfunctioning systems simultaneously; this provides good data for identifying the type of attack and its software locus, so such attacks can be fixed more quickly than those that attack just one system. Finally, a broad counterattack based in common software risks more collateral damage to noncombat functions of computer systems than a more targeted counterattack.\nNot all cyber-counterattacks require preparation. Those launched across the Internet can be mounted more easily at any time. Defending against such attacks is, however, the primary focus of the network intrusion-prevention systems which defend most of our network sites, which are kept updated with the latest known attacks. It is difficult, though not impossible, to invent a new attack that will succeed against these formidable defenses. A country could try to \"stockpile\" new such attacks in the interests of its defense, but the effort to find such attacks might quickly be wasted as countermeasures are\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM\nIP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010\nindependently discovered as discussed above. What attacks that do succeed in circumventing the first level of defenses may succumb to second levels of defenses that note anomalous behavior, so they are unlikely to succeed for long once they start attacking. For instance, systematic search for the computers on a local-area network is necessary for precisely targeted attacks, but such searching is obvious to network packet monitoring since normal usage rarely does it. So network-based attacks are quite unreliable, and military commanders dislike unreliable technology. Thus it appears that cyber-counterattacks are infeasible.\n# DESIGNING ETHICAL CYBERWEAPONS\nDespite the issues raised here, countries will likely continue to develop cyberweapons. Can such weapons be designed and used more ethically? We believe they can, since ethical discriminations can be made today among different kinds of weapons. For instance among nuclear weapons, neutron bombs are arguably less ethical than hydrogen bombs of the same explosive power when civilians are at risk because they harm humans disproportionately .\nSince controllability is a serious concern with cyberweapons, ethical weapons should use a variety of methods to ensure focused targeting. Propagation via viruses and worms should be minimized. Attacks should focus on a limited set of important targets which should be clearly identified and confirmed during the attack using more than their Internet address. Important civilian systems such as commercial infrastructure should clearly identify themselves as civilian so attacks can know to avoid them.\nEthical attacks should also be easily stoppable. If an adversary surrenders, it is unethical as well as against international law to continue attacking and causing damage. This means that all attacks should be under quick control via some mechanism such as an emergency channel so that they can be halted if necessary.\nThis may be difficult with automated attacks, and the effects of any attack will likely impede communication. But it is important.\nIdentification of the attacker (\"attribution\") should also be a key feature of ethical attacks, much as how uniforms to identify military personnel in warfare. Acting as a soldier while not wearing a uniform is outlawed by international law. So some data associated with a cyberattack should identify who is responsible for an attack. One way is to add a digital signature to data or a program (Mel &amp; Baker, 2000). Several technologies to do this are available, and the best-known is encryption with a private key of a public-private key pair of a hash of the contents. Using a hash means that the public key confirms that the contents were not modified after they were signed. Responsible attackers will find signatures useful because they prove they are responsible for an attack and prevent scapegoating of others. Unattributed attacks are not very useful anyway since attacks are usually a way to force a country to do something, and the victim cannot know what to do unless they know who has attacked them. Signatures also permit the attacker to recognize their own signature on already-attacked systems and avoid reattacking them. Public keys for attack signatures could be kept with international organizations like the United Nations as a form of \"key escrow\" like that proposed for backup on encrypted systems.\nNot everyone agrees that attacks should be attributable. Robb (2009) argues that cyberattacks will be ineffective unless that have deniability, like some instances of \"special operations\" using commandos. But if he is right, then all effective cyberattacks are forms of terrorism.\nA weakness of signatures is that they might be recognized by defenders and enable them to realize they are being attacked, which might matter with the more subtle attacks. But it will not be easy to recognize attack signatures because many programs today have signatures as a security measure. Also, since they are a function of the contents, their bits will differ when attached to different files or data. However, if\nCopyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.\nIGI Global Scientific Publishing Platform\nDownloaded: 7/2/2025 11:55:24 AM IP Address: 82.13.63.56\nInternational Journal of Technoethics, 1(1), 20-31, January-March 2010 29\nit is important that a signature be concealed, steganography can be used by the attacker . This is a class of techniques for concealing data inside innocent-looking other data, like concealing code messages in the least-significant bits of pictures.\nSince damage persistence is a key problem with cyberweapons, it would be more ethical to use weapons whose damage is easily repairable at the end of hostilities. This is more possible in cyberspace than in conventional warfare. For instance, an attack could encrypt important parts of a victim's system so that they cannot be used until the attacker supplies a key to undo (decrypt) them. Since encryption and decryption do not lose any information, the attack would be completely reversible. This would be an ethical alternative whenever it is impossible for a victim to restore a system from backup. Similarly, an attack could withhold important messages (like orders or email) from a victim. If the attacker saves those messages, they could be supplied to the victim at the cessation of hostilities, thereby reversing the attack. In both cases, there may be some damage from denial of timely access to data, but this can be minimized if the target systems are chosen carefully.\nthan physical blockades. There are alternatives to banks, but there is only one Internet.\n# CONCLUSION\nMost coverage of cyberweapons has been relatively neutral, referring to cyberweapons as inevitable new weapons technology that can be employed much like any other. Our argument here is that this cyberweapons have a variety of unique problems that impede their effectiveness and ethicality, and that \"cyberpacifism\" should be encouraged. Cyberweapons are less reliable and less controllable weapons than conventional ones, much like biological weapons, and thus a poor choice in warfare. They disproportionately threaten civilians and harm the society that develops and uses them. It is hard to figure out what is happening when cyberweapons are used due to secrecy and the inherent difficulty of analyzing cyberspace, and their employment for counterattacks seems particularly challenging. While some ways of using cyberweapons are better than others, there are currently insufficient incentives to use them ethically. Their use should be outlawed.\n# ACKNOWLEDGMENT\nThe views expressed are those of the author and do not represent those of any part of the U.S. Government."
    }
  },
  "citation_summary": {
    "style": "author_year",
    "dominant_bucket": "author_year",
    "dominant": {
      "intext_total": 25.0,
      "success_occurrences": 25.0,
      "success_unique": 22.0,
      "bib_unique_total": 66.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.3333333333333333,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "author_year"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 25.0,
        "success_occurrences": 25.0,
        "success_unique": 22.0,
        "bib_unique_total": 66.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.3333333333333333,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "The Ethics of Cyberweapons in Warfare",
    "subtitle": "Neil C. Rowe, U.S. Naval Postgraduate School, USA",
    "document_type": "journal_article",
    "venue": "20 International Journal of Technoethics, 1(1), 20-31, January-March 2010",
    "publication_year": 2010,
    "authors": [
      "IGI Global Scientific Publishing Platform"
    ],
    "affiliations": [
      "Neil C. Rowe, U.S. Naval Postgraduate School, USA"
    ],
    "emails": [],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "The author discusses the ethical issues of using cyberweapons, software that attacks data and other software during warfare. Many people assume these are relatively benign weapons, but we argue that they can create serious harms like any weapon. He defines cyberweapons and describes them in general terms, and survey their status as per the laws of war. He then discusses the unreliability of cyberweapons, the problem of collateral damage, and the associated problems of damage assessment, maintenance of secrecy, and mounting cyber-counterattacks. He examines some possibilities for creating more ethical cyberweapons and discusses the alternative of cyber-blockades. He concludes that cyberattacks should generally be outlawed by international agreement. Keywords: Attribution, Collateral Damage, Cyberattack, Cyberweapons, Damage Assessment, Ethics, Perfidy, Secrecy, Vulnerability, Weapons",
    "keywords": [
      "Attribution",
      "Collateral Damage",
      "Cyberattack",
      "Cyberweapons",
      "Damage Assessment",
      "Ethics",
      "Perfidy",
      "Secrecy",
      "Vulnerability",
      "Weapons"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.4018/jte.2010081002",
        "10.2307/3312952",
        "10.1109/MSP.2005.146",
        "10.1145/974104.974105"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": []
    },
    "references_block_count": 1,
    "references_entries_estimated": 39,
    "heading_count": 15,
    "max_heading_level": 1,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 25,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 1.0,
      "unique_index_count": 22
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "author_year",
      "recommended_style": "author_year",
      "aligned": true,
      "signals": {
        "superscript_hits": 0,
        "superscript_definition_lines": 0,
        "numeric_bracket_hits": 0,
        "numeric_endnote_lines": 0,
        "author_year_hits": 23
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 66.0,
      "dominant_bib_coverage_rate": 0.3333333333333333,
      "dominant_link_target": "bibliography",
      "dominant_unresolved_flag": "unresolved_reference_links"
    },
    "heading_validation": {
      "heading_count": 15,
      "max_heading_level": 1,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": false
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": false,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 1,
        "affiliations": 1,
        "emails": 0,
        "orcids": 0,
        "keywords": 10,
        "doi": 4,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 0
      },
      "coverage": {
        "core_coverage": 1.0,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [],
        "toc_dot_lines": 0
      },
      "flags": []
    },
    "flags": [
      "low_bib_coverage"
    ]
  },
  "updated_at_utc": "2026-02-14T08:26:40.583801+00:00"
}