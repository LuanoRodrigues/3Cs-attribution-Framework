{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\J5ANVN29\\Brantly - 2018 - The cyber deterrence problem.pdf",
  "custom_id": "299",
  "response": {
    "id": "batch-b6235e9e-300-fc7d194a-b8c5-4b17-8e74-4072f5673c94",
    "custom_id": "299",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "2018 10th International Conference on Cyber Conflict\nCyCon X: Maximising Effects\nT. Minárik, R. Jakschis, L. Lindström (Eds.)\n2018 © NATO CCD COE Publications, Tallinn\n\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n\n# The Cyber Deterrence Problem\n\nAaron F. Brantly\nAssistant Professor, Department of Political Science\nVirginia Polytechnic and State University\nUnited States\nabrantly@vt.edu\n\nAbstract: What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.\n\nKeywords: cyber, deterrence, denial, punishment\n\n# 1. INTRODUCTION\n\nThe challenge of the digital era is not to define deterrence. Deterrence is a well-defined concept that has been studied and practiced throughout history and to an even greater depth following the advent of nuclear weapons. The present challenge it is to understand the role digital technologies play in the broader scope of interstate deterrence. Deterrence in one domain rarely if ever operates independently of other domains. Much of the literature on cyber deterrence focuses on within domain deterrence. Yet, this is a dangerous constraint that elevates risks and minimizes the probability of success. This paper seeks to draw out the literature on deterrence and identify its applicability within a newly delineated domain of interactions, cyberspace. The resultant analysis strives to encompass the complexity of deterrence and advance an argument beyond within domain modeling.\n\n31",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 1,
            "markdown": "Classical deterrence centers on a potential adversary's cost-benefit calculus to dissuade specific actions and differs from compellence by focusing on ex-ante behavior manipulation through a priori uses of force or other tools of state power. Both compellence and deterrence are forms of coercion, however, the former employs both hard and soft power both in the present and future with continued or escalated actions, while the latter threatens use of force (power) absent their employment. The focus below is on ex-ante actions by states and sub-state entities that threaten, but that do not use the tools of state against an adversary to manipulate their decision-making calculus. Additionally, actions undertaken independent of threats that can, ex-ante, reduce the benefits associated with a given attack are examined.\n\nFocusing on classical deterrence and deterrence by denial helps illustrate the similarities and differences between deterrence in the pre- and post-delineation of cyberspace as a domain of military operations. Deterrence in cyberspace has been addressed by a variety of scholars across the subfields of International Relations.¹ Many examinations of cyber deterrence rely on direct applications of IR theory absent robust technical understandings of how the domain functions. The development and application of classical deterrence theories to a domain necessarily requires an understanding of how state and non-state actors achieve, develop, and assess costs and benefits within this domain.\n\nThis work proceeds in three sections. First, it examines some of the relevant literature on deterrence and identifies some of the gaps within the field and provides a trajectory for the subsequent sections to examine a more dynamic theory of deterrence in cyberspace. The second section focuses on the technical, tactical, operational, and strategic aspects of the domain in an effort to identify those areas where deterrence can alter the costs-benefit analysis of adversaries. Third, the work concludes by providing a discussion on national strategy development for integrated cyber deterrence incorporating the lessons from the first two sections.\n\n## 2. FROM ATOMS TO BITS AND BYTES\n\nDeterrence is not a novel concept. The classical IR cannon on deterrence can be traced back to the Peloponnesian War and the threat of violence in response to adversary actions.² Yet, more modern formulations of deterrence are largely rooted in the nuclear world following World War 2. The most common form of deterrence known as conventional deterrence was established by Bernard Brodie, Thomas Schelling and\n\n¹ Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n\n² Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 2,
            "markdown": "others and focuses on the ex-ante dissuasion of adversaries through the threat of ex-post costs in response to potential adversary actions.\n\nRobert Jervis identified three “waves” of deterrence theorizing to which a potential fourth wave has been added by Jeffery Knopf.³ First wave deterrence theory rested on the rise and consequences of nuclear weapons. Bernard Brodie et al. asserted that the use of nuclear weapons had almost no innate strategic or tactical value outside of being a threat against an adversary.⁴ The consequences of nuclear weapons use, even in limited strike situations, would quickly and dramatically escalate. This escalation made the limited use of such weapons untenable in all but the most extreme situations. Lawrence Freedman summarized the second wave as the realization that “total war could now only be threatened, but never fought”.⁵\n\nSecond wave deterrence posited how nuclear weapons could be threatened and the dynamics of those threats.⁶ Thomas Schelling and others posited a series of conditions in which states could develop deterrence in the nuclear era. As Jervis noted, second wave theorizing became extremely popular because of its abstraction and logical structuring.⁷ Game theory and other rational models were used to illustrate rational costs and benefits, creating models suited to rigorous concepts of rationality.⁸ The second wave arose under stable bi-polar conditions in which it was assumed states engaged in rational decision-making in matters of foreign policy and national security. Schelling found deterrence largely dependent upon credibility and rationality. He illustrated that signaling potential costs to an adversary absent credibility creates deterrence failure. By using divergent game-theoretic structures from prisoner’s dilemma to chicken – theorists developed arguments about deterrence. Despite rigorous theory, this abstraction contained systemic flaws and gave rise to a third wave of deterrence.\n\nThe third wave of deterrence theory in the 1970s addressed challenges beyond game theoretic models, including the failing rationality. Irving Janis and Graham Allison, both, but with different perspectives, illustrated the weaknesses of rationality in decision-making.⁹ The third wave led to extensions into cognitive psychology and behavioral studies. Robert Jervis, Richard Ned Lebow, and Janis Stein provided insight into the general problems associated with parsimonious use of rationality through case analyses. Specifically, Jervis et al. identified the potential for over-valuation of\n\n³ Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.\n\n⁴ Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.\n\n⁵ Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.\n\n⁶ Ibid: 22.\n\n⁷ Jervis. Review: 291-292.\n\n⁸ Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.\n\n⁹ Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n\n33",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 3,
            "markdown": "certain attributes of classic deterrence that might inadvertently make conflict more and not less likely.¹⁰\n\nJeffrey Berejikian incorporated Daniel Kahneman and Amos Tversky’s analysis of prospect theory into the deterrence calculus and challenged parsimonious rational thought by illustrating cognitive dimensions associated with decision-making beyond groupthink and bureaucratic processes. His work highlighted issues related to risk in cognitive decision-making that undermine rationality. Concepts such as sunk costs or tying hands fit well within parsimonious deterrence theory, yet the mechanisms that made them effective were not well understood prior to the third wave.\n\nAlthough modern deterrence theory encompasses a spectrum from pure rational modeling to cognitive models, the objective of deterrence as identified by John Mearsheimer remains the development of fear of the consequences (in particular of “military action”) or a “function of costs and risks”.¹¹ Developing shared knowledge about costs and risks for nuclear events differs from non-nuclear conflicts. Early deterrence models relied heavily on rationality and parsimony but did not underestimate the clarity provided by the use and subsequent impact of the weapons themselves. The generation of fear or knowledge of consequences to assess costs and risks loses clarity the as analyses shift away from nuclear weapons. Lawrence Freedman defines single weapon or type of warfare deterrence as “narrow deterrence”.¹² Narrow deterrence is less effective when expanded beyond single weapon or type warfare.\n\nGeneral or broad deterrence covers a range threatened actions to dissuade an adversary. Freedman writes: “broad deterrence involves deterring all war”.¹³ Ted Hopf explains: within deterrence there is a need to expand deterrence beyond the scope of military tools to the entire range of options available to actors.¹⁴ Extending analysis further, scholars also emphasize concepts of direct deterrence and extended deterrence. Direct deterrence is concerned with actions against “your” state and its immediate interests as opposed to extended deterrence – dissuasion of adversary actions against a third party or non-immediate interests. Delineating between these two types of deterrence in a globalized world is difficult. Cyberspace compounds the challenge of delineation because attacks on foreign infrastructure can and do have ramifications globally.\n\nConcepts of the means to achieve deterrence or more simply how to deter are often contested. Threats can be narrowed to weapon type or category, or include\n\n¹⁰ Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n\n¹¹ Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.\n\n¹² Freedman. 2004.\n\n¹³ Ibid.\n\n¹⁴ Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n\n34",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 4,
            "markdown": "interdependent relationships such as diplomatic, informational, military and economic effects. Threats signaling a potential response to adversary action should provide clear, unambiguous consequences. The ex-ante threat should causally lead to an ex-post consequence; punishment.\n\nOften left out of traditional international relations literature, deterrence by denial has seen a surge of interest in the years following the 9/11 terrorist attacks. Alex Wilner defines deterrence by denial as “reducing the perceived benefits an action is expected to provide a challenger”.¹⁵ Deterrence by denial in the physical world often includes hardening targets by building higher walls, adding security mechanisms, or other tactics to reduce the susceptibility of targets to attack. If the Strategic Defense Initiative (SDI – also known as Star Wars) had been successful, it would have been a deterrence by denial strategy to limit the effect of Soviet nuclear weapons. Commonly used forms of deterrence by denial in conflict zones include land mines, razor wire, surface to air missiles (SAMs) and fortifications.\n\nDeterrence by punishment and denial are intended to manipulate the cost-benefit analysis of an adversary. To function they must both be credible. Credibility requires undertaking ex-ante costs by the deterrer. Threats absent ante impetum costs lack credibility. A state without nuclear weapons cannot credibly threaten nuclear retaliation. If a state wishes to deter it must provide demonstrable evidence that it is able to carry out its threat.\n\nLikewise, deterrence by denial fails when it lacks the material capabilities to deny. The Maginot Line built by the French following World War I stands an example of failed deterrence by denial. The French system of fortifications on portions of their northern territory failed because the line itself only covered one vector of attack into France. The elevation of costs to a potential attacker must be complete and provide no reasonable alternatives to achieve the attacker’s intended utility. Both strategies require ex-ante costs by the defender to alter the ex-post perceived benefits of an attacker. Punishment strategies increase adversary costs after a violation and denial strategies increases adversary costs in advance of a violation.\n\nDeterrence by denial is a successful strategy in many instances; SAMs effectively deter enemy aircraft. The relative costs of upgrading certain denial tools is comparatively less than the costs of surmounting them. In the case of SAMs, the United States spent billions of dollars to defeat the S-300 missile system (~$100 million/system).¹⁶ Following the development and use of stealth, S-300 designer Almaz upgraded its\n\n¹⁵ Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.\n\n¹⁶ Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n\n35",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 5,
            "markdown": "systems to the S-400 variant with greater accuracy and anti-stealth technology.¹⁷ The cost ratio between the denial tool and offensive weapon system is approximately 1 to 1,000. The defensive and offensive capabilities, industrial, and financial resources of these two states exceed most other nations. Even with a $18.5 trillion GDP a $1 to $1,000 cost to benefit ratio is high and demonstrates how denial can be a remarkably effective strategy.\n\nDeterrence by denial is not always successful as illustrated by the Israel – Hamas conflict. In response to Hamas’ use of Katyusha rockets, Israel developed the Iron Dome System. Iron Dome batteries cost $100 million and each rocket costs $50,000.¹⁸ To intercept an incoming Katyusha rocket, the Israelis launch 2 interceptor rockets.¹⁹ By contrast, Hamas spends between $500 and $1,000 per rocket launch.²⁰ If the cost of the battery is ignored, the cost of deterrence by denial is still between 100 to 1 and 200 to 1.\n\nDenial strategies are not passive. They require continuous modification relative to adversary capability development. Static denial strategies in cyberspace or in conventional conflict are likely to have limited credibility over time. Similarly, punishment strategies also require constant updating in relation to adversary capabilities and geopolitical considerations. In cyberspace, this involves adapting denial strategies to technological advances such as artificial intelligence, polymorphic malware and the Internet of Things, to name just a few.\n\nPunishment strategies also require ex-ante costs. Below the nuclear threshold, threats of force are common, yet the credibility of these threats is difficult to establish. Alexander George and Richard Smoke identify three attributes important for signaling in conventional deterrence: “(1) the full formulation of one’s intent to protect a nation; (2) the acquisition and deployment of capacities to back up that intent; (3) the communication of intent to a potential aggressor”.²¹ These three aspects are also at times limited in their ability to convey commitment to fulfill the intent.²²\n\nCharles Glaser, writing on cyber deterrence, established four components of basic deterrence:\n\n¹⁷ Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n\n¹⁸ Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n\n¹⁹ Ibid.\n\n²⁰ Ibid.\n\n²¹ George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.\n\n²² Ibid: 558.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 6,
            "markdown": "\"1) the benefits of taking the action—the larger the benefits, the harder the adversary is to deter; 2) the probability of achieving the benefits—the higher the probability, the harder the adversary is to deter; 3) the costs the defender will impose if the adversary takes the action—the higher the costs, the more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".[23]\n\nGeorge and Smoke and Glaser acknowledge the challenge of establishing not just threats of punishment, but the credibility associated with carrying out that threat.\n\nCreating material capability (i.e. weapon systems capable of carrying out a given threat) and clear signaling might occur and yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework.[24] Credibility and hand-tying are most closely associated with extended deterrence, yet when expanding deterrence to cyberspace it also finds relevance. The establishment of credibility through hand-tying establishes a forcing mechanism for decisions, indicating costs have already been incurred or are likely to occur. This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs.[25] An attack on West Berlin would have resulted in sunk costs and provided a strong inducement or \"tripwire\" to actuate US retaliatory threats. Nearly all forms of kinetic attacks against the direct interests of a nation implicitly include hand-tying. It is unclear how to effectively signal prospective costs within cyberspace to an adversary.\n\nCharles Glaser identifies several problems associated with deterrence by punishment specific to cyberspace that extend beyond basic credibility issues. First, he notes that deterrence often relies on the attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.[27] Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty.[28] Second, hands-tying and other forms of credibility enhancing measures are likely lacking in cyberspace. Moreover, the ability to respond within domain simply might not be possible within certain conditions.[29] Third, Glaser identifies potential spillovers\n\n23 Glaser, Charles. 2011. \"Deterrence of Cyber-attacks and US National Security\". GW-CSPRI-2011-5. Washington, DC: Cyber Security Policy and Research Institute: 2.\n24 Fearon, James D. 1997. \"Signaling Foreign Policy Interests\". Journal of Conflict Resolution 41(1): 69–90.\n25 Kydd, Andrew H, and Roseanne W McManus. 2017. \"Threats and Assurances in Crisis Bargaining\". Journal of Conflict Resolution 61(2).\n26 Glaser. 2011: 3.\n27 Ibid.\n28 Rid, Thomas and Ben Buchanan. 2015. \"Attributing Cyber Attacks\". Journal of Strategic Studies 38(1-2): 4–37.\n29 Ibid.\n\n37",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 7,
            "markdown": "in which limited within domain options result in cross-domain, kinetic responses.³⁰ To date there is limited evidence of cross-domain responses and therefore lacks in credibility. Moreover, cross-domain retaliation alters the escalation framework from digital to kinetic or other and poses a challenge for states wishing to establish credibility while controlling potential escalatory behaviors.\n\nDeterrence is more than simply threatening punishment. Deterrence requires substantial target relevant costs and the development of mechanisms to establish that further costs are credibly wagered to provide clarity for an adversary. The goal of this clarity is to establish within an adversary’s calculus that their expected gains are less than any potential losses incurred. Reassessments of rational modeling and the increasing importance of cognitive modeling increase the value of tailored deterrence strategies predicated on the uniqueness of conditions and actors. Paul notes that deterrence is complex and is most logically broken down into five ideal types:\n\n“(1) deterrence among great powers; (2) deterrence among new nuclear states; (3) deterrence and extended deterrence involving great powers and regional powers armed with chemical, biological and nuclear weapons; (4) deterrence between nuclear states and non-state actors (5) deterrence by collective actors”.³¹\n\nIt follows that tailored deterrence for cyber actors is also one potential avenue of exploration.\n\nThe potential for tailored deterrence strategies could be highlighted in numerous significant cyber incident cases. The 1998 cyber attack code-named SOLAR SUNRISE discovered by US Air Force Computer Emergency Response Team (AFCERT) stands as a prime example. The three-week hack affected more than 500 systems across the US Air Force, Navy, NASA, Lawrence Livermore Labs, MIT, Harvard, and UC Berkeley. The attack coincided with increased tensions between the United States and Iraq and resulted in high-level governmental meetings to identify a proper response action.³² At the time, the attack was believed to be state-sponsored cyber attack focused on degrading US military capabilities. Subsequently, it was discovered that the attack was conducted by two California teenagers with guidance from Israeli hacker Ehud Tenebaum. The incident is relevant to tailored deterrence because it highlights challenges faced in developing a deterrence strategy. The adversaries were domestic, yet foreign inspired and attacked the operational infrastructure of the Department of Defense. No form of deterrence by punishment delineated above could have appropriately accounted this challenge. The only realistic\n\n³⁰ Ibid.\n\n³¹ Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.\n\n³² Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n\n38",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 8,
            "markdown": "deterrence frameworks for SOLAR SUNRISE would have been deterrence by denial or punishment in cooperation with allies.\n\nRichard Kugler writes that a strategy or general framework for deterrence in cyberspace must necessarily be tailored to differing threats, situations, and objectives.³³ The threats, situations, and objectives in cyberspace differ from the concerns addressed by first wave theorists. While the potential for physical damage through cyberspace has been demonstrated in tests such as the Aurora generator experiment that resulted in the destruction of a multi-ton diesel generator, or the Stuxnet attack that destroyed segments of a centrifuge cascade in Iran’s Natanz nuclear facility, many attacks do not have kinetic parallels.³⁴ Building on Kugler, Jeffrey Cooper identifies three important factors that frame concepts on deterrence in cyberspace. First, there is a wide range of actors each with different capabilities and attributes as well as cost benefits structures; second, cyberspace is a unique operational domain that carries with vastly different concepts of risk and reward; third, to develop deterrence, models must be applicable to the virtual and physical aspects of the domain.³⁵\n\nThis section has provided a summary of a large and robust literature on deterrence. The concepts that need to be carried forward include, the type of deterrence, the credibility of that deterrence and the attributes of the environment in which deterrence occurs, and who and what actors and weapons are to be deterred. The next section builds on the literature above, with a specific emphasis on the technical, tactical, operational and strategic attributes of cyberspace.\n\n# 3. ONE SIZE DOESN'T FIT ALL\n\nTo deter adversaries in cyberspace it is helpful to first define what cyberspace is and what types of actions and actors a state would like to deter. The US Department of Defense defines cyberspace in the following way:\n\n“Cyberspace consists of many different and often overlapping networks, as well as the nodes (any device or logical location with an Internet protocol address or other analogous identifier) on those networks, and the system data (such as routing tables) that support them. Cyberspace can be described in terms of three\n\n³³ Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.\n\n³⁴ US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.\n\n³⁵ Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 9,
            "markdown": "layers: physical network, logical network, and cyber-persona. The physical network layer of cyberspace is comprised of the geographic component and the physical network components. It is the medium where the data travel. The logical network layer consists of those elements of the network that are related to one another in a way that is abstracted from the physical network, i.e., the form or relationships are not tied to an individual, specific path, or node. A simple example is any Web site that is hosted on servers in multiple physical locations where all content can be accessed through a single uniform resource locator. The cyber-persona layer represents yet a higher level of abstraction of the logical network in cyberspace; it uses the rules that apply in the logical network layer to develop a digital representation of an individual or entity identity in cyberspace. The cyber-persona layer consists of the people actually on the network\".36\n\nThe inclusion of the full definition illustrates the complexity within which defense strategists and operators in the various services engage. Because the domain spans the physical, logical, and persona layers, deterrence strategies can reasonably occur within and across all three. This fundamentally differs from the conceptualization of deterrence in physical domains of land, sea, air, and space. Physical domain deterrence might include physical and cognitive aspects analogous to the cyber persona and physical network layers, however, the logical layer is wholly absent. The cyber persona layer also diverges significantly from personas within the physical domain as individuals and states have the capacity to alter their attributes within the persona, logical, and network layers.\n\nTo construct a meaningful model of deterrence in cyberspace we must first ask what it is we wish to deter. Herein lies the largest distinction between deterrence in the physical world and in cyberspace. Whereas in the physical world deterrence is directed most commonly against physical attacks against specific assets or categories of assets that when attacked provide strong, largely non-repudiable forms of attribution, in cyberspace deterrence is directed against manipulations of the elements within the environment and the environment itself. Manipulation of elements of cyberspace and the environment itself can be examined in multiple ways. Simplifying cyberspace operations into three broad categories, there are cyber attacks, cyber espionage, and cyber theft. Despite simplification, it is important to note these categories are not entirely discrete in process or function. Cyber attacks are those acts in cyberspace that degrade, deny or destroy. Acts of cyber espionage steal information for state or corporate intelligence gain. Cyber theft is the stealing of information for financial gain with no direct state utility. Attacks, espionage, and theft occur across all levels\n\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 10,
            "markdown": "of actors from script kiddies to the military units of states – a problem which will be examined more below. States are most commonly concerned with cyber attacks and espionage at the national level, and theft at lower-jurisdictions.\n\nBecause attacks, espionage, and theft are perpetrated by a variety of actors against almost any target in cyberspace, sending an overt signal from one state to another, while still applicable, might not deter attacks at other levels that are of equal or greater significance. Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy$^{37}$ usage by states to maintain plausible deniability.$^{38}$ Using proxies to engage in cyber acts against targets deflects deterrence by threats of punishment unless sufficient evidence is present to indicate involvement by the instigating state rather than the third-party proxy. The use of proxies to engage in attacks, espionage and theft against target states outside of cyberspace has been the practice of states since Katulaya and Sun Tzu.$^{39}$ However, unlike the difficulties of non-repudiability within conventional conflicts, cyber attacks are frequently repudiable. Attackers might use Virtual Private Networks (VPNs), proxies or other means by which to engage in an attack.\n\nAdditional problems in cyberspace not frequently encountered in conventional physical domains are second and third order effects. As noted by Herbert Lin, the results of a cyber attack itself might not be identifiable, rather it is second or third order effects that generate an intended outcome.$^{40}$ Classical deterrence and tailored deterrence strategies used against terrorist organizations are unable to account for disconnected action and reaction pairs commonly found in cyberspace. The time to punish a violation can be weeks, months or years based on discovery and attribution challenges, a problem not present in classical deterrence.\n\nCyber attacks are incidents occurring in or through cyberspace that degrade, deny or destroy. Attacks in cyberspace can and are perpetrated by all levels of actors. The differentiation between actors is most closely correlated with targets and outcomes of attacks.$^{41}$ For example, criminal actors may use phishing attacks to ingress into a hospital's computer systems to install Cryptolocker or a similar ransomware malware on the hospital's systems. Cryptolocker is an attack that degrades civilian critical infrastructure, denies user access and has the potential to destroy critical\n\n37 Here proxy usage refers to the authority to represent someone else not the technical usage of the term in information communications.\n\n38 Borghard, Erica D, and Shawn W Lonergan. 2016. “Can States Calculate the Risks of Using Cyber Proxies?” *Orbis* 60(3): 395–416.\n\n39 Kautalya and L. N. Rangarajan. 1992. *The Arthashastra*. New Delhi: Penguin Books India; Griffith, Samuel B, and Sun Tzu. 1971. *The Art of War*. New York: Oxford University Press.\n\n40 Lin, Herbert. “Operational Considerations in Cyber-attack and Cyber Exploitation”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press.\n\n41 Brantly, Aaron F. 2015. “Aesop’s Wolves: The Deceptive Appearance of Espionage and Attacks in Cyberspace”. *Intelligence and National Security* 31(5): 674-685.\n\n41",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 11,
            "markdown": "information.42 Very few states have national deterrence strategies aimed at sub-state actors, criminal organizations or individuals. State deterrence strategies aimed at non-terrorist sub-state actors are confined to criminological models of deterrence. Yet, if a soldier or spy from an adversary state walked into the server room at the same hospital and threatened to detonate a bomb and destroy all the files unless he was paid a ransom, the act would align more closely with a conventional deterrence framework of state-to-state deterrence by threats of punishment or tailored deterrence against terrorist actors.\n\nMost scholars and practitioners are likely to contend that it is not the responsibility of the state to deter non-state actors (excepting terrorists), particularly criminals from cyber attacks against non-federal infrastructure outside of a criminological framework.43 Yet, the same tool used by a criminal is available to the state and presents the same challenges associated with attribution irrespective of the perpetrator. What actions could a state undertake to deter an adversary state actor from engaging in this behavior and would these actions have a measurable effect on non-state actors as well?\n\nExamples of cyber attacks abound and include the destruction, denial or degradation of military or civilian communications platforms. Attacks such as the Mirai (malware) botnet attack in 2016 are capable of being directed at both critical and non-critical infrastructure by both state and non-state actors. A botnet using Mirai was able to generate in excess of 1Tbps of traffic and degrade dozens of websites in the United States on 20 September 2016.44 This same form of attack could be directed towards IP addresses of the FAA and emergency service providers or any number of Internet-enabled systems found on Shodan.io or similar services.45\n\nAlthough DDoS attacks are generally considered to be among the least complicated forms of cyber attacks they still challenge state and sub-state entities both public and private. DDoS attacks have been used against US government infrastructure, against Estonia in 2007 and the Republic of Georgia in 2008.46 To date, DDoS attacks against the US government or critical infrastructure have received little attention in discussions on deterrence in cyberspace. On 21 January 2016 a grand jury in the Southern District of New York indicted 7 Iranian Hackers in absentia for their involvement in DDoS\n\n42 Winton, Richard. 2016. \"Hollywood Hospital Pays $17,000 in Bitcoin to Hackers; FBI Investigating\". Los Angeles Times. February 18, 2016. http://www.latimes.com/business/technology/la-me-ln-hollywood-hospital-bitcoin-20160217-story.html.\n\n43 Akers, Ronald L. 2017. \"Rational Choice, Deterrence, and Social Learning Theory in Criminology: The Path Not Taken\" Journal of Criminal Law and Criminology 81(3): 1–25.\n\n44 Bonderud, Douglas. 2016. \"Leaked Mirai Malware Boosts IoT Insecurity Threat Level\". securityintelligence.com. October 4, 2016. https://securityintelligence.com/news/leaked-mirai-malware-boosts-iot-insecurity-threat-level/.\n\n45 Bodenheim, Roland, Jonathan Butts, Stephen Dunlap, and Barry Mullins. 2014. \"Evaluation of the Ability of the Shodan Search Engine to Identify Internet-Facing Industrial Control Devices\". International Journal of Critical Infrastructure Protection 7(2): 114–23.\n\n46 Klimburg, Alexander. 2011. \"Mobilizing Cyber Power\". Survival 53(1): 41–60; Hollis, David. 2011. \"Cyberwar Case Study: Georgia 2008\". Small Wars Journal, http://smallwarsjournal.com/jrnl/art/cyberwar-case-study-georgia-2008.\n\n42",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 12,
            "markdown": "attacks against US financial sector interests and a variety of other US companies occurring from 2011-2013.⁴⁷ These indictments are: (a) not deterrent threats or denials, but criminological deterrents; (b) temporally distant from the time of attack as to be ineffective at signaling deterrence; and (c) impose little to no costs on Iran or the individual perpetrators or organizers of the attack.\n\nBeyond DDoS attacks, Russian attacks against Ukrainian electric infrastructure and US political organizations also resulted in no or weak responses that offer no indication that deterrence is making headway in cyberspace.⁴⁸ In response to massive influence operations perpetrated by the Russian Federation against the United States and its two major political parties during the 2016 Presidential election the United States expelled 35 suspected Russian intelligence operatives and placed sanctions on Russia’s two leading intelligence services, the FSB and the GRU.⁴⁹ The US response imposed insignificant costs in comparison to the utility achieved by the Russian Federation.\n\nThe latter case of Russian influence and hacking during the 2016 election cycle provides a case study for why deterrence by threat in cyberspace is so difficult to achieve. The first indications of Russian interference in the 2016 election were identified by the FBI in September 2015 more than a year before the election.⁵⁰ The FBI phoned the DNC to try and alert them to a potential attack, but the call was not considered credible and was subsequently ignored by DNC staffers.⁵¹ The progression of hacking attempts against the DNC continued and President Obama was notified in the summer of 2016. Moreover, the “attack” against the DNC was not an attack, but espionage or theft and therefore falls outside conventionally defined deterrence frameworks. Yet the impact of the espionage and the later release of private DNC emails was substantial as indicated in a declassified report by the Office of the Director of National Intelligence (ODNI).⁵² The report assessed that information warfare conducted following the espionage campaign substantially degraded the DNC and engendered a loss of confidence in the US electoral system.⁵³ Cyber deterrence has fundamental problems including the realization that the most valuable assets in cyberspace might not be destroyed or degraded, but rather stolen and used.\n\n⁴⁷ US Federal Bureau of Investigation. 2016. “Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion”. https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n\n⁴⁸ US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n\n⁴⁹ Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n\n⁵⁰ Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n\n⁵¹ Ibid.\n\n⁵² US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n\n⁵³ Ibid.\n\n43",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 13,
            "markdown": "Even in instances where specific code is used to achieve damage such as Iranian efforts to hack a spillway dam⁵⁴ or malware implants in critical infrastructure such as a German steel mill,⁵⁵ there are no formal mechanisms by which to signal a threat within cyberspace or beyond other than by referencing responses to kinetic effects. Current deterrence by threat signaling for attacks occurring in or through cyberspace is ambiguous. Efforts by the NATO CCD COE through the production of the Tallinn Manuals have begun to outline the frameworks in which deterrence could legally take place, yet the application of threats is still uncertain.⁵⁶\n\nDeterrence by threat within cyberspace is realistically only applicable to cyber operations that result in direct physical effects that are non-repudiable and attributed quickly. Using formal modeling in the Decision to Attack: Military and Intelligence Cyber Decision-making I found that most cyber attacks, with the notable exception of DDoS, operate under varying conditions of anonymity.⁵⁷ The anonymity associated with attacks is usually necessary for attacks to be successful in bypassing deterrence by denial frameworks found in the perimeter defenses of networks such as intrusion detection and prevention systems found in the logical or physical network layers of cyberspace. Threats of punishment could impact the persona layer of cyberspace as well, but as will be examined below there are some fundamental challenges unique to cyberspace posed by anonymity.\n\n## 4. TECHNICAL CHALLENGES: THREATS OF PUNISHMENT WITHIN DOMAIN\n\nPunishing an adversary in cyberspace is not cheap or fast outside of pre-established botnets or damage done to physical infrastructure. Punishment in or across any of the layers cyberspace requires what the US Department of the Army refers to as intelligence preparation of the battlefield (IPB):\n\n“IPB is a systemic, continuous process of analyzing the threat and environment in a specific geographic area. It is designed to support staff estimates and military decision making”.⁵⁸\n\n⁵⁴ Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n\n⁵⁵ Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n\n⁵⁶ Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n\n⁵⁷ Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n\n⁵⁸ US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 14,
            "markdown": "In response to a nuclear attack on a city in the US, the proportional response would be a counter attack on an adversary city. The city itself is geographically fixed and immovable both logically and physically. Threatening in-kind retaliation is both plausible and technically feasible with ballistic missiles or air assets. The same logic does not hold in cyberspace.\n\nWhy are in kind retaliations or other forms of punishment not viable solutions for most retaliations in cyberspace? First, a state must fulfill the burden of proof in identifying the perpetrator of an action. All the above IPB and potential for retaliation still depends upon attribution of who, what, and potentially why an attack occurred.59 Retaliation absent strong evidence is likely to lead to misidentification and unnecessary escalation.\n\nSecond, a state must retaliate within a proximate temporal range. If state X does not have detailed intelligence on the asset it wishes to retaliate against, developing intelligence along with a cyber weapon to target it increases the time horizon of response such that it is days, weeks, months or even years out from the original attack for which it is retaliating. Due to this temporal disconnect, the threat to punish in response to a given action falls into a category of what economists refer to as hyperbolic discounting. The risk of punishment for an attack is possible but so temporally, distant as to be discounted to the point of irrelevance.\n\nThird, deterrence by punishment requires proportionality. It is necessary to have comparable assets to punish to prevent escalation or violations of international law.60 Comparable assets are not a given within cyberspace and are often difficult to identify.61 To punish an asset within a domain requires pre-established access or knowledge of that asset beyond its location. Whereas a city is immovable and likely to be as susceptible today as it will be tomorrow to a missile or bomb, a computer system that is penetrated today for prepositioned access, might be patched, upgraded or taken offline tomorrow.\n\nFourth, a state must possess a specific cyber weapon system tailored to its target. If state X alerts state Y that it is going to punish an asset or state X uses a repeated cyber weapon to attack state Y’s system, it is likely to be ineffectual the longer it is used due to updated perimeter defenses, such as intrusion detection and prevention systems (IDPS), antivirus programs or a variety of other security measures. If state X wants to punish state Y it must have knowledge of the attributes of the asset it wishes to retaliate against and what the status of that asset is. State X must also develop new exploits to achieve effects or be confident that State Y has not accounted for previous exploits that have been used.\n\n59 Brantly. 2016.\n60 Schmitt, Michael N. (Ed.) 2017. Tallinn Manual on the International Law Applicable to Cyber Operations: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press: Kindle Location: 4530.\n61 Libicki, Martin C. 2016. Cyberspace in Peace and War. Naval Institute Press: 262.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 15,
            "markdown": "The challenges of signaling deterrence by punishment are numerous within cyberspace whether the conflict is contained within domain or crosses over domains. Advances in attribution within a timely manner and the availability and reasonable assumption that proportional assets of an adversary can be held at risk need to be improved to credibly threaten punishment. This is a challenge not isolated to within domain retaliation. While proportional target selection might be slightly easier in cross-domain retaliation, the first three issues raised above are still relevant.\n\nDeterrence by punishment in cyberspace is possible, but it is not a reliable or credible option under most conditions absent sufficient and sustained intelligence. This assessment is not unique and is borne out in the analysis of Valeriano and Maness, who find that deterrence via punishment is generally ineffective and likely more dangerous than other means of preventing attacks.[62] Moreover, sustained invasive intelligence into adversary networks creates its own unique problems, including a security dilemma.[63] The more states engage in highly invasive intelligence via cyberspace, the more their actions are likely to be misinterpreted. Differentiating between various forms of cyber actions are difficult and can lead to miscalculation.[64]\n\n![img-0.jpeg](img-0.jpeg)\nFigure 1 illustrates the relationship between attacking and defending forces and area where both forms of deterrence function.\n\n62 Valeriano, Brandon, and Ryan C Maness. 2015. Cyber War Versus Cyber Realities: Cyber Conflict in the International System. New York: Oxford University Press: 57-60.\n63 Buchanan, Ben. 2017. The Cybersecurity Dilemma Hacking, Trust and Fear Between Nations. Oxford: Oxford University Press.\n64 Brantly. 2016.",
            "images": [
              {
                "id": "img-0.jpeg",
                "top_left_x": 198,
                "top_left_y": 1020,
                "bottom_right_x": 1124,
                "bottom_right_y": 1542,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 16,
            "markdown": "As seen in Figure 1, deterrence by threat of punishment and denial operate within the same temporal ranges, yet while attribution matters a great deal for threats of punishment they are generally unimportant for denial. In their initial stages both denial and punishment focus on ante-impetum means of dissuasion, yet deterrence by punishment necessarily needs post-impetum attribution for it to be used. Based on the technical realities of cyberspace and of international relations deterrence by threat of punishment is more complicated and difficult to effectively establish.\n\n# 5. TECHNICAL CHALLENGES AND OPPORTUNITIES: DETERRENCE BY DENIAL\n\nBoth deterrence by denial and punishment require ante-impetum costs by the defender. The allocation of resources between denial and deterrence and the efficiency with which they deter adversaries differ. The establishment of credible deterrence by denial often starts with the allocation of financial capital to purchase technical resources and provide human capital sufficient to continually update, enhance, audit and manage complex network infrastructure.[65] Network-based and host-based defenses such as intrusion detection and prevention systems, anti-virus products and similar systems are some of the variety of overlapping expenditures that can be undertaken to increasingly make the intrusion of adversaries into a given network more difficult.[66]\n\nIn cyberspace, such expenditures are regularized and often included as overhead costs, however they are deterrent in nature.[67] Although they are not glamorous, they substantially decrease the probability of penetration. The same types of deterrence strategies are used by stores in placing electronic tracking tags on their products and detectors at doors, by banks in the construction of vaults, silent alarms and dyed packets of money, by critical infrastructure in extending the perimeter of security outward to prevent vehicle-borne improvised explosive devices, increased numbers of security guards, cameras and the use of razor wire or other physical structures. These devices signal to adversaries both criminal and terrorist alike that the costs of successfully perpetrating an attack are high and that the likelihood of success is low, although both terrorist and criminal deterrence models include deterrence by punishment through criminal proceedings and potential lethal actions against terrorist they rely far more heavily on preventive measures that deny would be adversaries.\n\nSceptics might contend denial mechanisms are unlikely to deter a state, yet this is in and of itself not accurate. The vast majority of probes by states do not translate into successfully attacks. The US Department of Defense suffers from millions of probes\n\n[65] Riggs, Cliff. (2004). *Network Perimeter Security*. New York: Auerbach Publications.\n\n[66] Buecher, Axel, Per Andreas, and Scott Paisley. 2009. “Understanding IT Perimeter Security”. IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n\n[67] Filkins, Barbara. 2016. “IT Security Spending Trends”. SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n\n47",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 17,
            "markdown": "a day. Yet nearly 99.99% of them are unsuccessful.⁶⁸ Moreover, in the face of a global onslaught of cyber attacks and espionage the United States re-architected much of its military network infrastructure. This restructuring allows the initial point of contact with adversaries to be chosen. In military parlance, it allowed the defenders to choose the terrain of the battle. While it did not obviate the need for denial mechanisms within the network infrastructure, it did signal increased cost imposition on adversaries and it did allow for more efficient resource allocation.\n\nUnlike in any other battlespace, whether conventional kinetic terrorism, conventional kinetic or mass destruction military force, the opportunities for deterrence by denial are substantial in cyberspace and unique. While denial opportunities in land, sea, air, and even space are predicated on the control of a given geospatial area, the party establishing deterrence by denial has limited abilities to manipulate the nature of the domain itself. The same is not true within cyberspace. Every aspect of a defender’s cyberspace from the structure of the network, to the hardware, firmware, and software within a network, to the access of individuals within and external to that network is manipulable. At every stage of an attack an adversary is always attempting to operate on or against the defender’s cyberspace over which it has no control and has limited visibility.\n\nFor denial, the historical literature of deterrence theory remains relevant, in particular the second and third stages of deterrence which focused on rational game theoretic and cognitive modeling. While in conventional deterrence the emphasis was on punishment, here these same modeling techniques find applicability in deterrence by denial. Although the games might be the same, the payoffs in cyberspace manipulable and favor the defender. In few other applications of deterrence are the payoff matrices of deterrence so favorable to the defender. Despite the favorability of conditions, the ability to manipulate the potential payoff for attackers remains difficult. Although possible for defenders to reduce the probability of attack success, the potential payoff for a successful attack can remain large.\n\nDespite conditions favoring defenders, the potential payoffs are often not affected by deterrence by denial. Minimizing the potential payoffs from attacks on data repositories requires disaggregation of data. These types of denial mechanisms come with efficiency or financial costs. Although denial offers more potential than punishment, it is not a silver bullet to the cyber deterrence problem. Denial decreases the probability of success for attackers and is likely to reduce classes of actors focused on certain targets. Despite efforts to signal through the purchase and implementation of various defensive measures, the re-architecting of network infrastructure, the cyber deterrence problem remains.\n\n⁶⁸ Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 18,
            "markdown": "# 6. BEYOND THE DETERRENCE PROBLEM\n\nIf punishment and denial are unable to fully remediate the cyber deterrence problem, are there any meaningful solutions? The core debate remains, with no simple and readily apparent solutions. The search for a single solution is likely to remain fruitless for the foreseeable future. Deterrence has never been the single tool within the toolbox of the state to dissuade or shape adversary behavior. Rather, it has always been combined with efforts that extend beyond traditional concepts of deterrence to include geopolitical and technical practices including norm development, entanglement, cumulative deterrence, research and development, policies and laws, liability structures for software and hardware, training for users and human capital development within information technology and cybersecurity.⁶⁹\n\nEfficient and effective cyber deterrence should extend international politics and include fields such as criminology, immunology and public health.⁷⁰ The capacity of states to punish criminals is high and the credibility of punishment actions in developed nations is strong. Despite a capacity to punish criminal behaviors, they still occur. Extending beyond punishment, states also focus on denying criminals opportunities to commit crimes. Yet crime still occurs. The root causes of crime are not simple nor isolatable to a single phenomenon. Likewise, states engage one another in cyberspace for a variety of reasons. Some reasons fit within conventional deterrence frameworks of denial and punishment and do not suffer from challenges with attribution. For instance, larger and more harmful attacks increase the probability of attribution. However, many states remain perturbed by the death by a thousand cuts phenomena which falls below thresholds and required to provide timely attribution.\n\nShifting the focus away from within domain deterrence focused solely on punishment and denial and changing the emphasis to a basket of strategies focused on reducing incentives, availability and anonymity fosters an environment less conducive both to hostile actions and potential malicious actors. The solution to the deterrence problem is not abandoning it, but expanding the range of alternative strategies not presently considered. By acknowledging the failures and inadequacies of deterrence strategies and the potential places where novel strategies found in other fields are applicable the intractable problem of cyber deterrence becomes more manageable.\n\n⁶⁹ Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.\n\n⁷⁰ Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n\n49",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 19,
            "markdown": "# REFERENCES\n\nAkers, Ronald L. 2017. \"Rational Choice, Deterrence, and Social Learning Theory in Criminology: The Path Not Taken\". Journal of Criminal Law and Criminology 81(3).\n\nAllison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n\nAviation Week. 2015. \"Program Dossier S-300 Surface-to-Air Missile System\". Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n\nBerejikian, Jeffrey D. 2004. International Relations Under Risk: Framing State Choice. Albany: State University of New York Press.\n\nBodenheim, Roland, Jonathan Butts, Stephen Dunlap, and Barry Mullins. 2014. \"Evaluation of the Ability of the Shodan Search Engine to Identify Internet-Facing Industrial Control Devices\". International Journal of Critical Infrastructure Protection 7(2).\n\nBonderud, Douglas. 2016. \"Leaked Mirai Malware Boosts IoT Insecurity Threat Level\". securityintelligence.com. October 4, 2016. https://securityintelligence.com/news/leaked-mirai-malware-boosts-iot-insecurity-threat-level/.\n\nBorghard, Erica D, and Shawn W Lonergan. 2016. \"Can States Calculate the Risks of Using Cyber Proxies?\" Orbis 60(3).\n\nBrantly, Aaron \"Epidemiological Approaches to National Cybersecurity\". In US National Cybersecurity: International Politics, Concepts and Organization. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n\nBrantly, Aaron F. 2015. \"Aesop's Wolves: The Deceptive Appearance of Espionage and Attacks in Cyberspace\". Intelligence and National Security 31(5).\n\nBrantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n\nBrodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. The Absolute Weapon: Atomic Power and World Order. New York: Harcourt, Brace and Co.\n\nBuchanan, Ben. 2017. The Cybersecurity Dilemma Hacking, Trust and Fear Between Nations. Oxford: Oxford University Press.\n\nBuecher, Axel, Per Andreas, and Scott Paisley. 2009. \"Understanding IT Perimeter Security\". IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n\nCooper, Jeffrey R. 2012. \"A New Framework for Cyber Deterrence\". In Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press.\n\nCylance. 2014. \"Operation Cleaver\". https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n\nFearon, James D. 1997. \"Signaling Foreign Policy Interests\". Journal of Conflict Resolution 41(1).\n\nFilkins, Barbara. 2016. \"IT Security Spending Trends\". SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n\nFreedman, Lawrence. 2004. Deterrence. Cambridge: Polity Press.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 20,
            "markdown": "51\n\nGeorge, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press.\n\nGlaser, Charles. 2011. “Deterrence of Cyber-attacks and US National Security”. GW-CSPRI-2011-5. Washington, DC: Cyber Security Policy and Research Institute.\n\nGrazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604.\n\nGriffith, Samuel B, and Sun Tzu. 1971. *The Art of War*. New York: Oxford University Press.\n\nHealey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n\nHollis, David. 2011. “Cyberwar Case Study: Georgia 2008”. *Small Wars Journal*. http://smallwarsjournal.com/jrnl/art/cyberwar-case-study-georgia-2008.\n\nHopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n\nHoward, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\n\nJaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press.\n\nJanis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin.\n\nJasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n\nJervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n\nJervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2).\n\nKahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2).\n\nKautalya and L. N. Rangarajan. 1992. *The Arthashastra*. New Delhi: Penguin Books India.\n\nKlimburg, Alexander. 2011. “Mobilizing Cyber Power”. *Survival* 53(1).\n\nKnopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1).\n\nKugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press.\n\nKydd, Andrew H, and Roseanne W McManus. 2017. “Threats and Assurances in Crisis Bargaining”. *Journal of Conflict Resolution* 61(2).\n\nLee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. *SANS Industrial Control Systems*. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n\nLibicki, Martin C. 2016. *Cyberspace in Peace and War*. Naval Institute Press.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 21,
            "markdown": "52\n\nLin, Herbert. 2012. \"Operational Considerations in Cyber-attack and Cyber Exploitation\" in *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. Washington: Georgetown University Press.\n\nLipton, Eric, David E Sanger, and Scott Shane. 2016. \"The Perfect Weapon: How Russian Cyberpower Invaded the US\". *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n\nMandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press.\n\nMearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press.\n\nMorris, Benny. 2014. \"Should Israel and the US Rethink Iron Dome's Usefulness?\" *LA Times*. August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n\nRid, Thomas and Ben Buchanan. 2015. \"Attributing Cyber Attacks\". *Journal of Strategic Studies* 38(1-2).\n\nRid, Thomas. 2016. \"How Russia Pulled Off the Biggest Election Hack in US History\". *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n\nRiggs, Cliff. 2004. *Network Perimeter Security*. New York: Auerbach Publications.\n\nRogoway, Tyler. 2015. \"Here's Russia's S-400 Missile System in Action, and How the US Would Deal with It\". *Foxtrotalpha.Jalopnik.com*. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n\nSanger, David E. 2016. \"Obama Strikes Back at Russia for Election Hacking\". *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n\nSchelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press.\n\nSchmitt, Michael N. (Ed.). 2013. *Tallinn Manual on the International Law Applicable to Cyber Warfare*: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n\nSchmitt, Michael N. (Ed.). 2017. *Tallinn Manual on the International Law Applicable to Cyber Operations*: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n\nThucydides, and Rex Warner. 1968. \"The Sixth Book, Chapter XVIII\". In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\n\nTor, Uri. 2017. “Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2).\n\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\n\nUS Department of Homeland Security. 2014. \"FOIA Documents: Control Systems Security Aurora Update Brief\". Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf.\n\nUS Department of Homeland Security. 2016. \"Cyber-Attack Against Ukrainian Critical Infrastructure ICS-CERT\". Washington, DC.\n\nUS Department of the Army. 1994. *FM 34-130 Intelligence Preparation of the Battlefield*. Washington, DC.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 22,
            "markdown": "53\n\nUS Federal Bureau of Investigation. 2016. \"Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion\". https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n\nUS Office of the Director of National Intelligence. 2017. \"Assessing Russian Activities and Intentions in Recent US Elections\" Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n\nValeriano, Brandon, and Ryan C Maness. 2015. Cyber War Versus Cyber Realities: Cyber Conflict in the International System. New York: Oxford University Press.\n\nWilner, Alex S. 2015. \"Deterrence Theory: Exploring Core Concepts\". In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press.\n\nWinton, Richard. 2016. \"Hollywood Hospital Pays $17,000 in Bitcoin to Hackers; FBI Investigating\". Los Angeles Times. February 18, 2016. http://www.latimes.com/business/technology/la-me-ln-hollywood-hospital-bitcoin-20160217-story.html.\n\nWirtz, James J, Patrick M Morgan, and T V Paul. 2009. Complex Deterrence: Strategy in the Global Age. Chicago: University of Chicago Press.\n\nZetter, Kim. 2014. Countdown to Zero Day: Stuxnet and the Launch of the World's First Digital Weapon. New York: Crown Publishers.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          },
          {
            "index": 23,
            "markdown": "54",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1890,
              "width": 1339
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 24,
          "doc_size_bytes": 2144933
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "2018 10th International Conference on Cyber Conflict\nCyCon X: Maximising Effects\nT. Minárik, R. Jakschis, L. Lindström (Eds.)\n2018 © NATO CCD COE Publications, Tallinn\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# The Cyber Deterrence Problem\nAaron F. Brantly\nAssistant Professor, Department of Political Science\nVirginia Polytechnic and State University\nUnited States\nabrantly@vt.edu\nAbstract: What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.\nKeywords: cyber, deterrence, denial, punishment\n# 1. INTRODUCTION\nThe challenge of the digital era is not to define deterrence. Deterrence is a well-defined concept that has been studied and practiced throughout history and to an even greater depth following the advent of nuclear weapons. The present challenge it is to understand the role digital technologies play in the broader scope of interstate deterrence. Deterrence in one domain rarely if ever operates independently of other domains. Much of the literature on cyber deterrence focuses on within domain deterrence. Yet, this is a dangerous constraint that elevates risks and minimizes the probability of success. This paper seeks to draw out the literature on deterrence and identify its applicability within a newly delineated domain of interactions, cyberspace. The resultant analysis strives to encompass the complexity of deterrence and advance an argument beyond within domain modeling.\n31\nClassical deterrence centers on a potential adversary's cost-benefit calculus to dissuade specific actions and differs from compellence by focusing on ex-ante behavior manipulation through a priori uses of force or other tools of state power. Both compellence and deterrence are forms of coercion, however, the former employs both hard and soft power both in the present and future with continued or escalated actions, while the latter threatens use of force (power) absent their employment. The focus below is on ex-ante actions by states and sub-state entities that threaten, but that do not use the tools of state against an adversary to manipulate their decision-making calculus. Additionally, actions undertaken independent of threats that can, ex-ante, reduce the benefits associated with a given attack are examined.\nFocusing on classical deterrence and deterrence by denial helps illustrate the similarities and differences between deterrence in the pre- and post-delineation of cyberspace as a domain of military operations. Deterrence in cyberspace has been addressed by a variety of scholars across the subfields of International Relations.¹ Many examinations of cyber deterrence rely on direct applications of IR theory absent robust technical understandings of how the domain functions. The development and application of classical deterrence theories to a domain necessarily requires an understanding of how state and non-state actors achieve, develop, and assess costs and benefits within this domain.\nThis work proceeds in three sections. First, it examines some of the relevant literature on deterrence and identifies some of the gaps within the field and provides a trajectory for the subsequent sections to examine a more dynamic theory of deterrence in cyberspace. The second section focuses on the technical, tactical, operational, and strategic aspects of the domain in an effort to identify those areas where deterrence can alter the costs-benefit analysis of adversaries. Third, the work concludes by providing a discussion on national strategy development for integrated cyber deterrence incorporating the lessons from the first two sections.\n## 2. FROM ATOMS TO BITS AND BYTES\nDeterrence is not a novel concept. The classical IR cannon on deterrence can be traced back to the Peloponnesian War and the threat of violence in response to adversary actions.² Yet, more modern formulations of deterrence are largely rooted in the nuclear world following World War 2. The most common form of deterrence known as conventional deterrence was established by Bernard Brodie, Thomas Schelling and\n¹ Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n² Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\nothers and focuses on the ex-ante dissuasion of adversaries through the threat of ex-post costs in response to potential adversary actions.\nRobert Jervis identified three “waves” of deterrence theorizing to which a potential fourth wave has been added by Jeffery Knopf.³ First wave deterrence theory rested on the rise and consequences of nuclear weapons. Bernard Brodie et al. asserted that the use of nuclear weapons had almost no innate strategic or tactical value outside of being a threat against an adversary.⁴ The consequences of nuclear weapons use, even in limited strike situations, would quickly and dramatically escalate. This escalation made the limited use of such weapons untenable in all but the most extreme situations. Lawrence Freedman summarized the second wave as the realization that “total war could now only be threatened, but never fought”.⁵\nSecond wave deterrence posited how nuclear weapons could be threatened and the dynamics of those threats.⁶ Thomas Schelling and others posited a series of conditions in which states could develop deterrence in the nuclear era. As Jervis noted, second wave theorizing became extremely popular because of its abstraction and logical structuring.⁷ Game theory and other rational models were used to illustrate rational costs and benefits, creating models suited to rigorous concepts of rationality.⁸ The second wave arose under stable bi-polar conditions in which it was assumed states engaged in rational decision-making in matters of foreign policy and national security. Schelling found deterrence largely dependent upon credibility and rationality. He illustrated that signaling potential costs to an adversary absent credibility creates deterrence failure. By using divergent game-theoretic structures from prisoner’s dilemma to chicken – theorists developed arguments about deterrence. Despite rigorous theory, this abstraction contained systemic flaws and gave rise to a third wave of deterrence.\nThe third wave of deterrence theory in the 1970s addressed challenges beyond game theoretic models, including the failing rationality. Irving Janis and Graham Allison, both, but with different perspectives, illustrated the weaknesses of rationality in decision-making.⁹ The third wave led to extensions into cognitive psychology and behavioral studies. Robert Jervis, Richard Ned Lebow, and Janis Stein provided insight into the general problems associated with parsimonious use of rationality through case analyses. Specifically, Jervis et al. identified the potential for over-valuation of\n³ Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.\n⁴ Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.\n⁵ Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.\n⁶ Ibid: 22.\n⁷ Jervis. Review: 291-292.\n⁸ Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.\n⁹ Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n33\ncertain attributes of classic deterrence that might inadvertently make conflict more and not less likely.¹⁰\nJeffrey Berejikian incorporated Daniel Kahneman and Amos Tversky’s analysis of prospect theory into the deterrence calculus and challenged parsimonious rational thought by illustrating cognitive dimensions associated with decision-making beyond groupthink and bureaucratic processes. His work highlighted issues related to risk in cognitive decision-making that undermine rationality. Concepts such as sunk costs or tying hands fit well within parsimonious deterrence theory, yet the mechanisms that made them effective were not well understood prior to the third wave.\nAlthough modern deterrence theory encompasses a spectrum from pure rational modeling to cognitive models, the objective of deterrence as identified by John Mearsheimer remains the development of fear of the consequences (in particular of “military action”) or a “function of costs and risks”.¹¹ Developing shared knowledge about costs and risks for nuclear events differs from non-nuclear conflicts. Early deterrence models relied heavily on rationality and parsimony but did not underestimate the clarity provided by the use and subsequent impact of the weapons themselves. The generation of fear or knowledge of consequences to assess costs and risks loses clarity the as analyses shift away from nuclear weapons. Lawrence Freedman defines single weapon or type of warfare deterrence as “narrow deterrence”.¹² Narrow deterrence is less effective when expanded beyond single weapon or type warfare.\nGeneral or broad deterrence covers a range threatened actions to dissuade an adversary. Freedman writes: “broad deterrence involves deterring all war”.¹³ Ted Hopf explains: within deterrence there is a need to expand deterrence beyond the scope of military tools to the entire range of options available to actors.¹⁴ Extending analysis further, scholars also emphasize concepts of direct deterrence and extended deterrence. Direct deterrence is concerned with actions against “your” state and its immediate interests as opposed to extended deterrence – dissuasion of adversary actions against a third party or non-immediate interests. Delineating between these two types of deterrence in a globalized world is difficult. Cyberspace compounds the challenge of delineation because attacks on foreign infrastructure can and do have ramifications globally.\nConcepts of the means to achieve deterrence or more simply how to deter are often contested. Threats can be narrowed to weapon type or category, or include\n¹⁰ Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n¹¹ Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.\n¹² Freedman. 2004.\n¹³ Ibid.\n¹⁴ Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n34\ninterdependent relationships such as diplomatic, informational, military and economic effects. Threats signaling a potential response to adversary action should provide clear, unambiguous consequences. The ex-ante threat should causally lead to an ex-post consequence; punishment.\nOften left out of traditional international relations literature, deterrence by denial has seen a surge of interest in the years following the 9/11 terrorist attacks. Alex Wilner defines deterrence by denial as “reducing the perceived benefits an action is expected to provide a challenger”.¹⁵ Deterrence by denial in the physical world often includes hardening targets by building higher walls, adding security mechanisms, or other tactics to reduce the susceptibility of targets to attack. If the Strategic Defense Initiative (SDI – also known as Star Wars) had been successful, it would have been a deterrence by denial strategy to limit the effect of Soviet nuclear weapons. Commonly used forms of deterrence by denial in conflict zones include land mines, razor wire, surface to air missiles (SAMs) and fortifications.\nDeterrence by punishment and denial are intended to manipulate the cost-benefit analysis of an adversary. To function they must both be credible. Credibility requires undertaking ex-ante costs by the deterrer. Threats absent ante impetum costs lack credibility. A state without nuclear weapons cannot credibly threaten nuclear retaliation. If a state wishes to deter it must provide demonstrable evidence that it is able to carry out its threat.\nLikewise, deterrence by denial fails when it lacks the material capabilities to deny. The Maginot Line built by the French following World War I stands an example of failed deterrence by denial. The French system of fortifications on portions of their northern territory failed because the line itself only covered one vector of attack into France. The elevation of costs to a potential attacker must be complete and provide no reasonable alternatives to achieve the attacker’s intended utility. Both strategies require ex-ante costs by the defender to alter the ex-post perceived benefits of an attacker. Punishment strategies increase adversary costs after a violation and denial strategies increases adversary costs in advance of a violation.\nDeterrence by denial is a successful strategy in many instances; SAMs effectively deter enemy aircraft. The relative costs of upgrading certain denial tools is comparatively less than the costs of surmounting them. In the case of SAMs, the United States spent billions of dollars to defeat the S-300 missile system (~$100 million/system).¹⁶ Following the development and use of stealth, S-300 designer Almaz upgraded its\n¹⁵ Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.\n¹⁶ Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n35\nsystems to the S-400 variant with greater accuracy and anti-stealth technology.¹⁷ The cost ratio between the denial tool and offensive weapon system is approximately 1 to 1,000. The defensive and offensive capabilities, industrial, and financial resources of these two states exceed most other nations. Even with a $18.5 trillion GDP a $1 to $1,000 cost to benefit ratio is high and demonstrates how denial can be a remarkably effective strategy.\nDeterrence by denial is not always successful as illustrated by the Israel – Hamas conflict. In response to Hamas’ use of Katyusha rockets, Israel developed the Iron Dome System. Iron Dome batteries cost $100 million and each rocket costs $50,000.¹⁸ To intercept an incoming Katyusha rocket, the Israelis launch 2 interceptor rockets.¹⁹ By contrast, Hamas spends between $500 and $1,000 per rocket launch.²⁰ If the cost of the battery is ignored, the cost of deterrence by denial is still between 100 to 1 and 200 to 1.\nDenial strategies are not passive. They require continuous modification relative to adversary capability development. Static denial strategies in cyberspace or in conventional conflict are likely to have limited credibility over time. Similarly, punishment strategies also require constant updating in relation to adversary capabilities and geopolitical considerations. In cyberspace, this involves adapting denial strategies to technological advances such as artificial intelligence, polymorphic malware and the Internet of Things, to name just a few.\nPunishment strategies also require ex-ante costs. Below the nuclear threshold, threats of force are common, yet the credibility of these threats is difficult to establish. Alexander George and Richard Smoke identify three attributes important for signaling in conventional deterrence: “(1) the full formulation of one’s intent to protect a nation; (2) the acquisition and deployment of capacities to back up that intent; (3) the communication of intent to a potential aggressor”.²¹ These three aspects are also at times limited in their ability to convey commitment to fulfill the intent.²²\nCharles Glaser, writing on cyber deterrence, established four components of basic deterrence:\n¹⁷ Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n¹⁸ Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n¹⁹ Ibid.\n²⁰ Ibid.\n²¹ George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.\n²² Ibid: 558.\n\"1) the benefits of taking the action—the larger the benefits, the harder the adversary is to deter; 2) the probability of achieving the benefits—the higher the probability, the harder the adversary is to deter; 3) the costs the defender will impose if the adversary takes the action—the higher the costs, the more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".[23]\nGeorge and Smoke and Glaser acknowledge the challenge of establishing not just threats of punishment, but the credibility associated with carrying out that threat.\nCreating material capability (i.e. weapon systems capable of carrying out a given threat) and clear signaling might occur and yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework.[24] Credibility and hand-tying are most closely associated with extended deterrence, yet when expanding deterrence to cyberspace it also finds relevance. The establishment of credibility through hand-tying establishes a forcing mechanism for decisions, indicating costs have already been incurred or are likely to occur. This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs.[25] An attack on West Berlin would have resulted in sunk costs and provided a strong inducement or \"tripwire\" to actuate US retaliatory threats. Nearly all forms of kinetic attacks against the direct interests of a nation implicitly include hand-tying. It is unclear how to effectively signal prospective costs within cyberspace to an adversary.\nCharles Glaser identifies several problems associated with deterrence by punishment specific to cyberspace that extend beyond basic credibility issues. First, he notes that deterrence often relies on the attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.[27] Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty.[28] Second, hands-tying and other forms of credibility enhancing measures are likely lacking in cyberspace. Moreover, the ability to respond within domain simply might not be possible within certain conditions.[29] Third, Glaser identifies potential spillovers\n23 Glaser, Charles. 2011. \"Deterrence of Cyber-attacks and US National Security\". GW-CSPRI-2011-5. Washington, DC: Cyber Security Policy and Research Institute: 2.\n24 Fearon, James D. 1997. \"Signaling Foreign Policy Interests\". Journal of Conflict Resolution 41(1): 69–90.\n25 Kydd, Andrew H, and Roseanne W McManus. 2017. \"Threats and Assurances in Crisis Bargaining\". Journal of Conflict Resolution 61(2).\n26 Glaser. 2011: 3.\n27 Ibid.\n28 Rid, Thomas and Ben Buchanan. 2015. \"Attributing Cyber Attacks\". Journal of Strategic Studies 38(1-2): 4–37.\n29 Ibid.\n37\nin which limited within domain options result in cross-domain, kinetic responses.³⁰ To date there is limited evidence of cross-domain responses and therefore lacks in credibility. Moreover, cross-domain retaliation alters the escalation framework from digital to kinetic or other and poses a challenge for states wishing to establish credibility while controlling potential escalatory behaviors.\nDeterrence is more than simply threatening punishment. Deterrence requires substantial target relevant costs and the development of mechanisms to establish that further costs are credibly wagered to provide clarity for an adversary. The goal of this clarity is to establish within an adversary’s calculus that their expected gains are less than any potential losses incurred. Reassessments of rational modeling and the increasing importance of cognitive modeling increase the value of tailored deterrence strategies predicated on the uniqueness of conditions and actors. Paul notes that deterrence is complex and is most logically broken down into five ideal types:\n“(1) deterrence among great powers; (2) deterrence among new nuclear states; (3) deterrence and extended deterrence involving great powers and regional powers armed with chemical, biological and nuclear weapons; (4) deterrence between nuclear states and non-state actors (5) deterrence by collective actors”.³¹\nIt follows that tailored deterrence for cyber actors is also one potential avenue of exploration.\nThe potential for tailored deterrence strategies could be highlighted in numerous significant cyber incident cases. The 1998 cyber attack code-named SOLAR SUNRISE discovered by US Air Force Computer Emergency Response Team (AFCERT) stands as a prime example. The three-week hack affected more than 500 systems across the US Air Force, Navy, NASA, Lawrence Livermore Labs, MIT, Harvard, and UC Berkeley. The attack coincided with increased tensions between the United States and Iraq and resulted in high-level governmental meetings to identify a proper response action.³² At the time, the attack was believed to be state-sponsored cyber attack focused on degrading US military capabilities. Subsequently, it was discovered that the attack was conducted by two California teenagers with guidance from Israeli hacker Ehud Tenebaum. The incident is relevant to tailored deterrence because it highlights challenges faced in developing a deterrence strategy. The adversaries were domestic, yet foreign inspired and attacked the operational infrastructure of the Department of Defense. No form of deterrence by punishment delineated above could have appropriately accounted this challenge. The only realistic\n³⁰ Ibid.\n³¹ Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.\n³² Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n38\ndeterrence frameworks for SOLAR SUNRISE would have been deterrence by denial or punishment in cooperation with allies.\nRichard Kugler writes that a strategy or general framework for deterrence in cyberspace must necessarily be tailored to differing threats, situations, and objectives.³³ The threats, situations, and objectives in cyberspace differ from the concerns addressed by first wave theorists. While the potential for physical damage through cyberspace has been demonstrated in tests such as the Aurora generator experiment that resulted in the destruction of a multi-ton diesel generator, or the Stuxnet attack that destroyed segments of a centrifuge cascade in Iran’s Natanz nuclear facility, many attacks do not have kinetic parallels.³⁴ Building on Kugler, Jeffrey Cooper identifies three important factors that frame concepts on deterrence in cyberspace. First, there is a wide range of actors each with different capabilities and attributes as well as cost benefits structures; second, cyberspace is a unique operational domain that carries with vastly different concepts of risk and reward; third, to develop deterrence, models must be applicable to the virtual and physical aspects of the domain.³⁵\nThis section has provided a summary of a large and robust literature on deterrence. The concepts that need to be carried forward include, the type of deterrence, the credibility of that deterrence and the attributes of the environment in which deterrence occurs, and who and what actors and weapons are to be deterred. The next section builds on the literature above, with a specific emphasis on the technical, tactical, operational and strategic attributes of cyberspace.\n# 3. ONE SIZE DOESN'T FIT ALL\nTo deter adversaries in cyberspace it is helpful to first define what cyberspace is and what types of actions and actors a state would like to deter. The US Department of Defense defines cyberspace in the following way:\n“Cyberspace consists of many different and often overlapping networks, as well as the nodes (any device or logical location with an Internet protocol address or other analogous identifier) on those networks, and the system data (such as routing tables) that support them. Cyberspace can be described in terms of three\n³³ Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.\n³⁴ US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.\n³⁵ Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.\nlayers: physical network, logical network, and cyber-persona. The physical network layer of cyberspace is comprised of the geographic component and the physical network components. It is the medium where the data travel. The logical network layer consists of those elements of the network that are related to one another in a way that is abstracted from the physical network, i.e., the form or relationships are not tied to an individual, specific path, or node. A simple example is any Web site that is hosted on servers in multiple physical locations where all content can be accessed through a single uniform resource locator. The cyber-persona layer represents yet a higher level of abstraction of the logical network in cyberspace; it uses the rules that apply in the logical network layer to develop a digital representation of an individual or entity identity in cyberspace. The cyber-persona layer consists of the people actually on the network\".36\nThe inclusion of the full definition illustrates the complexity within which defense strategists and operators in the various services engage. Because the domain spans the physical, logical, and persona layers, deterrence strategies can reasonably occur within and across all three. This fundamentally differs from the conceptualization of deterrence in physical domains of land, sea, air, and space. Physical domain deterrence might include physical and cognitive aspects analogous to the cyber persona and physical network layers, however, the logical layer is wholly absent. The cyber persona layer also diverges significantly from personas within the physical domain as individuals and states have the capacity to alter their attributes within the persona, logical, and network layers.\nTo construct a meaningful model of deterrence in cyberspace we must first ask what it is we wish to deter. Herein lies the largest distinction between deterrence in the physical world and in cyberspace. Whereas in the physical world deterrence is directed most commonly against physical attacks against specific assets or categories of assets that when attacked provide strong, largely non-repudiable forms of attribution, in cyberspace deterrence is directed against manipulations of the elements within the environment and the environment itself. Manipulation of elements of cyberspace and the environment itself can be examined in multiple ways. Simplifying cyberspace operations into three broad categories, there are cyber attacks, cyber espionage, and cyber theft. Despite simplification, it is important to note these categories are not entirely discrete in process or function. Cyber attacks are those acts in cyberspace that degrade, deny or destroy. Acts of cyber espionage steal information for state or corporate intelligence gain. Cyber theft is the stealing of information for financial gain with no direct state utility. Attacks, espionage, and theft occur across all levels\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\nof actors from script kiddies to the military units of states – a problem which will be examined more below. States are most commonly concerned with cyber attacks and espionage at the national level, and theft at lower-jurisdictions.\nBecause attacks, espionage, and theft are perpetrated by a variety of actors against almost any target in cyberspace, sending an overt signal from one state to another, while still applicable, might not deter attacks at other levels that are of equal or greater significance. Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy$^{37}$ usage by states to maintain plausible deniability.$^{38}$ Using proxies to engage in cyber acts against targets deflects deterrence by threats of punishment unless sufficient evidence is present to indicate involvement by the instigating state rather than the third-party proxy. The use of proxies to engage in attacks, espionage and theft against target states outside of cyberspace has been the practice of states since Katulaya and Sun Tzu.$^{39}$ However, unlike the difficulties of non-repudiability within conventional conflicts, cyber attacks are frequently repudiable. Attackers might use Virtual Private Networks (VPNs), proxies or other means by which to engage in an attack.\nAdditional problems in cyberspace not frequently encountered in conventional physical domains are second and third order effects. As noted by Herbert Lin, the results of a cyber attack itself might not be identifiable, rather it is second or third order effects that generate an intended outcome.$^{40}$ Classical deterrence and tailored deterrence strategies used against terrorist organizations are unable to account for disconnected action and reaction pairs commonly found in cyberspace. The time to punish a violation can be weeks, months or years based on discovery and attribution challenges, a problem not present in classical deterrence.\nCyber attacks are incidents occurring in or through cyberspace that degrade, deny or destroy. Attacks in cyberspace can and are perpetrated by all levels of actors. The differentiation between actors is most closely correlated with targets and outcomes of attacks.$^{41}$ For example, criminal actors may use phishing attacks to ingress into a hospital's computer systems to install Cryptolocker or a similar ransomware malware on the hospital's systems. Cryptolocker is an attack that degrades civilian critical infrastructure, denies user access and has the potential to destroy critical\n37 Here proxy usage refers to the authority to represent someone else not the technical usage of the term in information communications.\n38 Borghard, Erica D, and Shawn W Lonergan. 2016. “Can States Calculate the Risks of Using Cyber Proxies?” *Orbis* 60(3): 395–416.\n39 Kautalya and L. N. Rangarajan. 1992. *The Arthashastra*. New Delhi: Penguin Books India; Griffith, Samuel B, and Sun Tzu. 1971. *The Art of War*. New York: Oxford University Press.\n40 Lin, Herbert. “Operational Considerations in Cyber-attack and Cyber Exploitation”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press.\n41 Brantly, Aaron F. 2015. “Aesop’s Wolves: The Deceptive Appearance of Espionage and Attacks in Cyberspace”. *Intelligence and National Security* 31(5): 674-685.\n41\ninformation.42 Very few states have national deterrence strategies aimed at sub-state actors, criminal organizations or individuals. State deterrence strategies aimed at non-terrorist sub-state actors are confined to criminological models of deterrence. Yet, if a soldier or spy from an adversary state walked into the server room at the same hospital and threatened to detonate a bomb and destroy all the files unless he was paid a ransom, the act would align more closely with a conventional deterrence framework of state-to-state deterrence by threats of punishment or tailored deterrence against terrorist actors.\nMost scholars and practitioners are likely to contend that it is not the responsibility of the state to deter non-state actors (excepting terrorists), particularly criminals from cyber attacks against non-federal infrastructure outside of a criminological framework.43 Yet, the same tool used by a criminal is available to the state and presents the same challenges associated with attribution irrespective of the perpetrator. What actions could a state undertake to deter an adversary state actor from engaging in this behavior and would these actions have a measurable effect on non-state actors as well?\nExamples of cyber attacks abound and include the destruction, denial or degradation of military or civilian communications platforms. Attacks such as the Mirai (malware) botnet attack in 2016 are capable of being directed at both critical and non-critical infrastructure by both state and non-state actors. A botnet using Mirai was able to generate in excess of 1Tbps of traffic and degrade dozens of websites in the United States on 20 September 2016.44 This same form of attack could be directed towards IP addresses of the FAA and emergency service providers or any number of Internet-enabled systems found on Shodan.io or similar services.45\nAlthough DDoS attacks are generally considered to be among the least complicated forms of cyber attacks they still challenge state and sub-state entities both public and private. DDoS attacks have been used against US government infrastructure, against Estonia in 2007 and the Republic of Georgia in 2008.46 To date, DDoS attacks against the US government or critical infrastructure have received little attention in discussions on deterrence in cyberspace. On 21 January 2016 a grand jury in the Southern District of New York indicted 7 Iranian Hackers in absentia for their involvement in DDoS\n42 Winton, Richard. 2016. \"Hollywood Hospital Pays $17,000 in Bitcoin to Hackers; FBI Investigating\". Los Angeles Times. February 18, 2016. http://www.latimes.com/business/technology/la-me-ln-hollywood-hospital-bitcoin-20160217-story.html.\n43 Akers, Ronald L. 2017. \"Rational Choice, Deterrence, and Social Learning Theory in Criminology: The Path Not Taken\" Journal of Criminal Law and Criminology 81(3): 1–25.\n44 Bonderud, Douglas. 2016. \"Leaked Mirai Malware Boosts IoT Insecurity Threat Level\". securityintelligence.com. October 4, 2016. https://securityintelligence.com/news/leaked-mirai-malware-boosts-iot-insecurity-threat-level/.\n45 Bodenheim, Roland, Jonathan Butts, Stephen Dunlap, and Barry Mullins. 2014. \"Evaluation of the Ability of the Shodan Search Engine to Identify Internet-Facing Industrial Control Devices\". International Journal of Critical Infrastructure Protection 7(2): 114–23.\n46 Klimburg, Alexander. 2011. \"Mobilizing Cyber Power\". Survival 53(1): 41–60; Hollis, David. 2011. \"Cyberwar Case Study: Georgia 2008\". Small Wars Journal, http://smallwarsjournal.com/jrnl/art/cyberwar-case-study-georgia-2008.\n42\nattacks against US financial sector interests and a variety of other US companies occurring from 2011-2013.⁴⁷ These indictments are: (a) not deterrent threats or denials, but criminological deterrents; (b) temporally distant from the time of attack as to be ineffective at signaling deterrence; and (c) impose little to no costs on Iran or the individual perpetrators or organizers of the attack.\nBeyond DDoS attacks, Russian attacks against Ukrainian electric infrastructure and US political organizations also resulted in no or weak responses that offer no indication that deterrence is making headway in cyberspace.⁴⁸ In response to massive influence operations perpetrated by the Russian Federation against the United States and its two major political parties during the 2016 Presidential election the United States expelled 35 suspected Russian intelligence operatives and placed sanctions on Russia’s two leading intelligence services, the FSB and the GRU.⁴⁹ The US response imposed insignificant costs in comparison to the utility achieved by the Russian Federation.\nThe latter case of Russian influence and hacking during the 2016 election cycle provides a case study for why deterrence by threat in cyberspace is so difficult to achieve. The first indications of Russian interference in the 2016 election were identified by the FBI in September 2015 more than a year before the election.⁵⁰ The FBI phoned the DNC to try and alert them to a potential attack, but the call was not considered credible and was subsequently ignored by DNC staffers.⁵¹ The progression of hacking attempts against the DNC continued and President Obama was notified in the summer of 2016. Moreover, the “attack” against the DNC was not an attack, but espionage or theft and therefore falls outside conventionally defined deterrence frameworks. Yet the impact of the espionage and the later release of private DNC emails was substantial as indicated in a declassified report by the Office of the Director of National Intelligence (ODNI).⁵² The report assessed that information warfare conducted following the espionage campaign substantially degraded the DNC and engendered a loss of confidence in the US electoral system.⁵³ Cyber deterrence has fundamental problems including the realization that the most valuable assets in cyberspace might not be destroyed or degraded, but rather stolen and used.\n⁴⁷ US Federal Bureau of Investigation. 2016. “Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion”. https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n⁴⁸ US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n⁴⁹ Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n⁵⁰ Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n⁵¹ Ibid.\n⁵² US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n⁵³ Ibid.\n43\nEven in instances where specific code is used to achieve damage such as Iranian efforts to hack a spillway dam⁵⁴ or malware implants in critical infrastructure such as a German steel mill,⁵⁵ there are no formal mechanisms by which to signal a threat within cyberspace or beyond other than by referencing responses to kinetic effects. Current deterrence by threat signaling for attacks occurring in or through cyberspace is ambiguous. Efforts by the NATO CCD COE through the production of the Tallinn Manuals have begun to outline the frameworks in which deterrence could legally take place, yet the application of threats is still uncertain.⁵⁶\nDeterrence by threat within cyberspace is realistically only applicable to cyber operations that result in direct physical effects that are non-repudiable and attributed quickly. Using formal modeling in the Decision to Attack: Military and Intelligence Cyber Decision-making I found that most cyber attacks, with the notable exception of DDoS, operate under varying conditions of anonymity.⁵⁷ The anonymity associated with attacks is usually necessary for attacks to be successful in bypassing deterrence by denial frameworks found in the perimeter defenses of networks such as intrusion detection and prevention systems found in the logical or physical network layers of cyberspace. Threats of punishment could impact the persona layer of cyberspace as well, but as will be examined below there are some fundamental challenges unique to cyberspace posed by anonymity.\n## 4. TECHNICAL CHALLENGES: THREATS OF PUNISHMENT WITHIN DOMAIN\nPunishing an adversary in cyberspace is not cheap or fast outside of pre-established botnets or damage done to physical infrastructure. Punishment in or across any of the layers cyberspace requires what the US Department of the Army refers to as intelligence preparation of the battlefield (IPB):\n“IPB is a systemic, continuous process of analyzing the threat and environment in a specific geographic area. It is designed to support staff estimates and military decision making”.⁵⁸\n⁵⁴ Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n⁵⁵ Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n⁵⁶ Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n⁵⁷ Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n⁵⁸ US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.\nIn response to a nuclear attack on a city in the US, the proportional response would be a counter attack on an adversary city. The city itself is geographically fixed and immovable both logically and physically. Threatening in-kind retaliation is both plausible and technically feasible with ballistic missiles or air assets. The same logic does not hold in cyberspace.\nWhy are in kind retaliations or other forms of punishment not viable solutions for most retaliations in cyberspace? First, a state must fulfill the burden of proof in identifying the perpetrator of an action. All the above IPB and potential for retaliation still depends upon attribution of who, what, and potentially why an attack occurred.59 Retaliation absent strong evidence is likely to lead to misidentification and unnecessary escalation.\nSecond, a state must retaliate within a proximate temporal range. If state X does not have detailed intelligence on the asset it wishes to retaliate against, developing intelligence along with a cyber weapon to target it increases the time horizon of response such that it is days, weeks, months or even years out from the original attack for which it is retaliating. Due to this temporal disconnect, the threat to punish in response to a given action falls into a category of what economists refer to as hyperbolic discounting. The risk of punishment for an attack is possible but so temporally, distant as to be discounted to the point of irrelevance.\nThird, deterrence by punishment requires proportionality. It is necessary to have comparable assets to punish to prevent escalation or violations of international law.60 Comparable assets are not a given within cyberspace and are often difficult to identify.61 To punish an asset within a domain requires pre-established access or knowledge of that asset beyond its location. Whereas a city is immovable and likely to be as susceptible today as it will be tomorrow to a missile or bomb, a computer system that is penetrated today for prepositioned access, might be patched, upgraded or taken offline tomorrow.\nFourth, a state must possess a specific cyber weapon system tailored to its target. If state X alerts state Y that it is going to punish an asset or state X uses a repeated cyber weapon to attack state Y’s system, it is likely to be ineffectual the longer it is used due to updated perimeter defenses, such as intrusion detection and prevention systems (IDPS), antivirus programs or a variety of other security measures. If state X wants to punish state Y it must have knowledge of the attributes of the asset it wishes to retaliate against and what the status of that asset is. State X must also develop new exploits to achieve effects or be confident that State Y has not accounted for previous exploits that have been used.\n59 Brantly. 2016.\n60 Schmitt, Michael N. (Ed.) 2017. Tallinn Manual on the International Law Applicable to Cyber Operations: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press: Kindle Location: 4530.\n61 Libicki, Martin C. 2016. Cyberspace in Peace and War. Naval Institute Press: 262.\nThe challenges of signaling deterrence by punishment are numerous within cyberspace whether the conflict is contained within domain or crosses over domains. Advances in attribution within a timely manner and the availability and reasonable assumption that proportional assets of an adversary can be held at risk need to be improved to credibly threaten punishment. This is a challenge not isolated to within domain retaliation. While proportional target selection might be slightly easier in cross-domain retaliation, the first three issues raised above are still relevant.\nDeterrence by punishment in cyberspace is possible, but it is not a reliable or credible option under most conditions absent sufficient and sustained intelligence. This assessment is not unique and is borne out in the analysis of Valeriano and Maness, who find that deterrence via punishment is generally ineffective and likely more dangerous than other means of preventing attacks.[62] Moreover, sustained invasive intelligence into adversary networks creates its own unique problems, including a security dilemma.[63] The more states engage in highly invasive intelligence via cyberspace, the more their actions are likely to be misinterpreted. Differentiating between various forms of cyber actions are difficult and can lead to miscalculation.[64]\nFigure 1 illustrates the relationship between attacking and defending forces and area where both forms of deterrence function.\n62 Valeriano, Brandon, and Ryan C Maness. 2015. Cyber War Versus Cyber Realities: Cyber Conflict in the International System. New York: Oxford University Press: 57-60.\n63 Buchanan, Ben. 2017. The Cybersecurity Dilemma Hacking, Trust and Fear Between Nations. Oxford: Oxford University Press.\n64 Brantly. 2016.\nAs seen in Figure 1, deterrence by threat of punishment and denial operate within the same temporal ranges, yet while attribution matters a great deal for threats of punishment they are generally unimportant for denial. In their initial stages both denial and punishment focus on ante-impetum means of dissuasion, yet deterrence by punishment necessarily needs post-impetum attribution for it to be used. Based on the technical realities of cyberspace and of international relations deterrence by threat of punishment is more complicated and difficult to effectively establish.\n# 5. TECHNICAL CHALLENGES AND OPPORTUNITIES: DETERRENCE BY DENIAL\nBoth deterrence by denial and punishment require ante-impetum costs by the defender. The allocation of resources between denial and deterrence and the efficiency with which they deter adversaries differ. The establishment of credible deterrence by denial often starts with the allocation of financial capital to purchase technical resources and provide human capital sufficient to continually update, enhance, audit and manage complex network infrastructure.[65] Network-based and host-based defenses such as intrusion detection and prevention systems, anti-virus products and similar systems are some of the variety of overlapping expenditures that can be undertaken to increasingly make the intrusion of adversaries into a given network more difficult.[66]\nIn cyberspace, such expenditures are regularized and often included as overhead costs, however they are deterrent in nature.[67] Although they are not glamorous, they substantially decrease the probability of penetration. The same types of deterrence strategies are used by stores in placing electronic tracking tags on their products and detectors at doors, by banks in the construction of vaults, silent alarms and dyed packets of money, by critical infrastructure in extending the perimeter of security outward to prevent vehicle-borne improvised explosive devices, increased numbers of security guards, cameras and the use of razor wire or other physical structures. These devices signal to adversaries both criminal and terrorist alike that the costs of successfully perpetrating an attack are high and that the likelihood of success is low, although both terrorist and criminal deterrence models include deterrence by punishment through criminal proceedings and potential lethal actions against terrorist they rely far more heavily on preventive measures that deny would be adversaries.\nSceptics might contend denial mechanisms are unlikely to deter a state, yet this is in and of itself not accurate. The vast majority of probes by states do not translate into successfully attacks. The US Department of Defense suffers from millions of probes\n[65] Riggs, Cliff. (2004). *Network Perimeter Security*. New York: Auerbach Publications.\n[66] Buecher, Axel, Per Andreas, and Scott Paisley. 2009. “Understanding IT Perimeter Security”. IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n[67] Filkins, Barbara. 2016. “IT Security Spending Trends”. SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n47\na day. Yet nearly 99.99% of them are unsuccessful.⁶⁸ Moreover, in the face of a global onslaught of cyber attacks and espionage the United States re-architected much of its military network infrastructure. This restructuring allows the initial point of contact with adversaries to be chosen. In military parlance, it allowed the defenders to choose the terrain of the battle. While it did not obviate the need for denial mechanisms within the network infrastructure, it did signal increased cost imposition on adversaries and it did allow for more efficient resource allocation.\nUnlike in any other battlespace, whether conventional kinetic terrorism, conventional kinetic or mass destruction military force, the opportunities for deterrence by denial are substantial in cyberspace and unique. While denial opportunities in land, sea, air, and even space are predicated on the control of a given geospatial area, the party establishing deterrence by denial has limited abilities to manipulate the nature of the domain itself. The same is not true within cyberspace. Every aspect of a defender’s cyberspace from the structure of the network, to the hardware, firmware, and software within a network, to the access of individuals within and external to that network is manipulable. At every stage of an attack an adversary is always attempting to operate on or against the defender’s cyberspace over which it has no control and has limited visibility.\nFor denial, the historical literature of deterrence theory remains relevant, in particular the second and third stages of deterrence which focused on rational game theoretic and cognitive modeling. While in conventional deterrence the emphasis was on punishment, here these same modeling techniques find applicability in deterrence by denial. Although the games might be the same, the payoffs in cyberspace manipulable and favor the defender. In few other applications of deterrence are the payoff matrices of deterrence so favorable to the defender. Despite the favorability of conditions, the ability to manipulate the potential payoff for attackers remains difficult. Although possible for defenders to reduce the probability of attack success, the potential payoff for a successful attack can remain large.\nDespite conditions favoring defenders, the potential payoffs are often not affected by deterrence by denial. Minimizing the potential payoffs from attacks on data repositories requires disaggregation of data. These types of denial mechanisms come with efficiency or financial costs. Although denial offers more potential than punishment, it is not a silver bullet to the cyber deterrence problem. Denial decreases the probability of success for attackers and is likely to reduce classes of actors focused on certain targets. Despite efforts to signal through the purchase and implementation of various defensive measures, the re-architecting of network infrastructure, the cyber deterrence problem remains.\n⁶⁸ Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\n# 6. BEYOND THE DETERRENCE PROBLEM\nIf punishment and denial are unable to fully remediate the cyber deterrence problem, are there any meaningful solutions? The core debate remains, with no simple and readily apparent solutions. The search for a single solution is likely to remain fruitless for the foreseeable future. Deterrence has never been the single tool within the toolbox of the state to dissuade or shape adversary behavior. Rather, it has always been combined with efforts that extend beyond traditional concepts of deterrence to include geopolitical and technical practices including norm development, entanglement, cumulative deterrence, research and development, policies and laws, liability structures for software and hardware, training for users and human capital development within information technology and cybersecurity.⁶⁹\nEfficient and effective cyber deterrence should extend international politics and include fields such as criminology, immunology and public health.⁷⁰ The capacity of states to punish criminals is high and the credibility of punishment actions in developed nations is strong. Despite a capacity to punish criminal behaviors, they still occur. Extending beyond punishment, states also focus on denying criminals opportunities to commit crimes. Yet crime still occurs. The root causes of crime are not simple nor isolatable to a single phenomenon. Likewise, states engage one another in cyberspace for a variety of reasons. Some reasons fit within conventional deterrence frameworks of denial and punishment and do not suffer from challenges with attribution. For instance, larger and more harmful attacks increase the probability of attribution. However, many states remain perturbed by the death by a thousand cuts phenomena which falls below thresholds and required to provide timely attribution.\nShifting the focus away from within domain deterrence focused solely on punishment and denial and changing the emphasis to a basket of strategies focused on reducing incentives, availability and anonymity fosters an environment less conducive both to hostile actions and potential malicious actors. The solution to the deterrence problem is not abandoning it, but expanding the range of alternative strategies not presently considered. By acknowledging the failures and inadequacies of deterrence strategies and the potential places where novel strategies found in other fields are applicable the intractable problem of cyber deterrence becomes more manageable.\n⁶⁹ Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.\n⁷⁰ Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n49",
  "references": [
    "# REFERENCES\nAkers, Ronald L. 2017. \"Rational Choice, Deterrence, and Social Learning Theory in Criminology: The Path Not Taken\". Journal of Criminal Law and Criminology 81(3).\nAllison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\nAviation Week. 2015. \"Program Dossier S-300 Surface-to-Air Missile System\". Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\nBerejikian, Jeffrey D. 2004. International Relations Under Risk: Framing State Choice. Albany: State University of New York Press.\nBodenheim, Roland, Jonathan Butts, Stephen Dunlap, and Barry Mullins. 2014. \"Evaluation of the Ability of the Shodan Search Engine to Identify Internet-Facing Industrial Control Devices\". International Journal of Critical Infrastructure Protection 7(2).\nBonderud, Douglas. 2016. \"Leaked Mirai Malware Boosts IoT Insecurity Threat Level\". securityintelligence.com. October 4, 2016. https://securityintelligence.com/news/leaked-mirai-malware-boosts-iot-insecurity-threat-level/.\nBorghard, Erica D, and Shawn W Lonergan. 2016. \"Can States Calculate the Risks of Using Cyber Proxies?\" Orbis 60(3).\nBrantly, Aaron \"Epidemiological Approaches to National Cybersecurity\". In US National Cybersecurity: International Politics, Concepts and Organization. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\nBrantly, Aaron F. 2015. \"Aesop's Wolves: The Deceptive Appearance of Espionage and Attacks in Cyberspace\". Intelligence and National Security 31(5).\nBrantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\nBrodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. The Absolute Weapon: Atomic Power and World Order. New York: Harcourt, Brace and Co.\nBuchanan, Ben. 2017. The Cybersecurity Dilemma Hacking, Trust and Fear Between Nations. Oxford: Oxford University Press.\nBuecher, Axel, Per Andreas, and Scott Paisley. 2009. \"Understanding IT Perimeter Security\". IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\nCooper, Jeffrey R. 2012. \"A New Framework for Cyber Deterrence\". In Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press.\nCylance. 2014. \"Operation Cleaver\". https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\nFearon, James D. 1997. \"Signaling Foreign Policy Interests\". Journal of Conflict Resolution 41(1).\nFilkins, Barbara. 2016. \"IT Security Spending Trends\". SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\nFreedman, Lawrence. 2004. Deterrence. Cambridge: Polity Press.\n51\nGeorge, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press.\nGlaser, Charles. 2011. “Deterrence of Cyber-attacks and US National Security”. GW-CSPRI-2011-5. Washington, DC: Cyber Security Policy and Research Institute.\nGrazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604.\nGriffith, Samuel B, and Sun Tzu. 1971. *The Art of War*. New York: Oxford University Press.\nHealey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\nHollis, David. 2011. “Cyberwar Case Study: Georgia 2008”. *Small Wars Journal*. http://smallwarsjournal.com/jrnl/art/cyberwar-case-study-georgia-2008.\nHopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\nHoward, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\nJaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press.\nJanis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin.\nJasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\nJervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\nJervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2).\nKahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2).\nKautalya and L. N. Rangarajan. 1992. *The Arthashastra*. New Delhi: Penguin Books India.\nKlimburg, Alexander. 2011. “Mobilizing Cyber Power”. *Survival* 53(1).\nKnopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1).\nKugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press.\nKydd, Andrew H, and Roseanne W McManus. 2017. “Threats and Assurances in Crisis Bargaining”. *Journal of Conflict Resolution* 61(2).\nLee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. *SANS Industrial Control Systems*. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\nLibicki, Martin C. 2016. *Cyberspace in Peace and War*. Naval Institute Press.\n52\nLin, Herbert. 2012. \"Operational Considerations in Cyber-attack and Cyber Exploitation\" in *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. Washington: Georgetown University Press.\nLipton, Eric, David E Sanger, and Scott Shane. 2016. \"The Perfect Weapon: How Russian Cyberpower Invaded the US\". *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\nMandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press.\nMearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press.\nMorris, Benny. 2014. \"Should Israel and the US Rethink Iron Dome's Usefulness?\" *LA Times*. August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\nRid, Thomas and Ben Buchanan. 2015. \"Attributing Cyber Attacks\". *Journal of Strategic Studies* 38(1-2).\nRid, Thomas. 2016. \"How Russia Pulled Off the Biggest Election Hack in US History\". *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\nRiggs, Cliff. 2004. *Network Perimeter Security*. New York: Auerbach Publications.\nRogoway, Tyler. 2015. \"Here's Russia's S-400 Missile System in Action, and How the US Would Deal with It\". *Foxtrotalpha.Jalopnik.com*. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\nSanger, David E. 2016. \"Obama Strikes Back at Russia for Election Hacking\". *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\nSchelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press.\nSchmitt, Michael N. (Ed.). 2013. *Tallinn Manual on the International Law Applicable to Cyber Warfare*: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\nSchmitt, Michael N. (Ed.). 2017. *Tallinn Manual on the International Law Applicable to Cyber Operations*: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\nThucydides, and Rex Warner. 1968. \"The Sixth Book, Chapter XVIII\". In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\nTor, Uri. 2017. “Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2).\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\nUS Department of Homeland Security. 2014. \"FOIA Documents: Control Systems Security Aurora Update Brief\". Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf.\nUS Department of Homeland Security. 2016. \"Cyber-Attack Against Ukrainian Critical Infrastructure ICS-CERT\". Washington, DC.\nUS Department of the Army. 1994. *FM 34-130 Intelligence Preparation of the Battlefield*. Washington, DC.\n53\nUS Federal Bureau of Investigation. 2016. \"Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion\". https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\nUS Office of the Director of National Intelligence. 2017. \"Assessing Russian Activities and Intentions in Recent US Elections\" Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\nValeriano, Brandon, and Ryan C Maness. 2015. Cyber War Versus Cyber Realities: Cyber Conflict in the International System. New York: Oxford University Press.\nWilner, Alex S. 2015. \"Deterrence Theory: Exploring Core Concepts\". In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press.\nWinton, Richard. 2016. \"Hollywood Hospital Pays $17,000 in Bitcoin to Hackers; FBI Investigating\". Los Angeles Times. February 18, 2016. http://www.latimes.com/business/technology/la-me-ln-hollywood-hospital-bitcoin-20160217-story.html.\nWirtz, James J, Patrick M Morgan, and T V Paul. 2009. Complex Deterrence: Strategy in the Global Age. Chicago: University of Chicago Press.\nZetter, Kim. 2014. Countdown to Zero Day: Stuxnet and the Launch of the World's First Digital Weapon. New York: Crown Publishers.\n54"
  ],
  "flat_text": "CyCon X: Maximising Effects\nT. Minárik, R. Jakschis, L. Lindström (Eds.)\n\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# The Cyber Deterrence Problem\nAaron F. Brantly\nAssistant Professor, Department of Political Science\nVirginia Polytechnic and State University\nUnited States\nabrantly@vt.edu\nAbstract: What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.\nKeywords: cyber, deterrence, denial, punishment\n# 1. INTRODUCTION\nThe challenge of the digital era is not to define deterrence. Deterrence is a well-defined concept that has been studied and practiced throughout history and to an even greater depth following the advent of nuclear weapons. The present challenge it is to understand the role digital technologies play in the broader scope of interstate deterrence. Deterrence in one domain rarely if ever operates independently of other domains. Much of the literature on cyber deterrence focuses on within domain deterrence. Yet, this is a dangerous constraint that elevates risks and minimizes the probability of success. This paper seeks to draw out the literature on deterrence and identify its applicability within a newly delineated domain of interactions, cyberspace. The resultant analysis strives to encompass the complexity of deterrence and advance an argument beyond within domain modeling.\n\nFocusing on classical deterrence and deterrence by denial helps illustrate the similarities and differences between deterrence in the pre- and post-delineation of cyberspace as a domain of military operations. Deterrence in cyberspace has been addressed by a variety of scholars across the subfields of International Relations. Many examinations of cyber deterrence rely on direct applications of IR theory absent robust technical understandings of how the domain functions. The development and application of classical deterrence theories to a domain necessarily requires an understanding of how state and non-state actors achieve, develop, and assess costs and benefits within this domain.\nThis work proceeds in three sections. First, it examines some of the relevant literature on deterrence and identifies some of the gaps within the field and provides a trajectory for the subsequent sections to examine a more dynamic theory of deterrence in cyberspace. The second section focuses on the technical, tactical, operational, and strategic aspects of the domain in an effort to identify those areas where deterrence can alter the costs-benefit analysis of adversaries. Third, the work concludes by providing a discussion on national strategy development for integrated cyber deterrence incorporating the lessons from the first two sections.\n## 2. FROM ATOMS TO BITS AND BYTES\nDeterrence is not a novel concept. The classical IR cannon on deterrence can be traced back to the Peloponnesian War and the threat of violence in response to adversary actions. Yet, more modern formulations of deterrence are largely rooted in the nuclear world following World War 2. The most common form of deterrence known as conventional deterrence was established by Bernard Brodie, Thomas Schelling and\n Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\nothers and focuses on the ex-ante dissuasion of adversaries through the threat of ex-post costs in response to potential adversary actions.\nRobert Jervis identified three “waves” of deterrence theorizing to which a potential fourth wave has been added by Jeffery Knopf. First wave deterrence theory rested on the rise and consequences of nuclear weapons. Bernard Brodie et al. asserted that the use of nuclear weapons had almost no innate strategic or tactical value outside of being a threat against an adversary. The consequences of nuclear weapons use, even in limited strike situations, would quickly and dramatically escalate. This escalation made the limited use of such weapons untenable in all but the most extreme situations. Lawrence Freedman summarized the second wave as the realization that “total war could now only be threatened, but never fought”.\nSecond wave deterrence posited how nuclear weapons could be threatened and the dynamics of those threats. Thomas Schelling and others posited a series of conditions in which states could develop deterrence in the nuclear era. As Jervis noted, second wave theorizing became extremely popular because of its abstraction and logical structuring. Game theory and other rational models were used to illustrate rational costs and benefits, creating models suited to rigorous concepts of rationality. The second wave arose under stable bi-polar conditions in which it was assumed states engaged in rational decision-making in matters of foreign policy and national security. Schelling found deterrence largely dependent upon credibility and rationality. He illustrated that signaling potential costs to an adversary absent credibility creates deterrence failure. By using divergent game-theoretic structures from prisoner’s dilemma to chicken – theorists developed arguments about deterrence. Despite rigorous theory, this abstraction contained systemic flaws and gave rise to a third wave of deterrence.\nThe third wave of deterrence theory in the 1970s addressed challenges beyond game theoretic models, including the failing rationality. Irving Janis and Graham Allison, both, but with different perspectives, illustrated the weaknesses of rationality in decision-making. The third wave led to extensions into cognitive psychology and behavioral studies. Robert Jervis, Richard Ned Lebow, and Janis Stein provided insight into the general problems associated with parsimonious use of rationality through case analyses. Specifically, Jervis et al. identified the potential for over-valuation of\n Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.\n Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.\n Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.\n Ibid: 22.\n Jervis. Review: 291-292.\n Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.\n Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n\nJeffrey Berejikian incorporated Daniel Kahneman and Amos Tversky’s analysis of prospect theory into the deterrence calculus and challenged parsimonious rational thought by illustrating cognitive dimensions associated with decision-making beyond groupthink and bureaucratic processes. His work highlighted issues related to risk in cognitive decision-making that undermine rationality. Concepts such as sunk costs or tying hands fit well within parsimonious deterrence theory, yet the mechanisms that made them effective were not well understood prior to the third wave.\nAlthough modern deterrence theory encompasses a spectrum from pure rational modeling to cognitive models, the objective of deterrence as identified by John Mearsheimer remains the development of fear of the consequences (in particular of “military action”) or a “function of costs and risks”. Developing shared knowledge about costs and risks for nuclear events differs from non-nuclear conflicts. Early deterrence models relied heavily on rationality and parsimony but did not underestimate the clarity provided by the use and subsequent impact of the weapons themselves. The generation of fear or knowledge of consequences to assess costs and risks loses clarity the as analyses shift away from nuclear weapons. Lawrence Freedman defines single weapon or type of warfare deterrence as “narrow deterrence”. Narrow deterrence is less effective when expanded beyond single weapon or type warfare.\nGeneral or broad deterrence covers a range threatened actions to dissuade an adversary. Freedman writes: “broad deterrence involves deterring all war”. Ted Hopf explains: within deterrence there is a need to expand deterrence beyond the scope of military tools to the entire range of options available to actors. Extending analysis further, scholars also emphasize concepts of direct deterrence and extended deterrence. Direct deterrence is concerned with actions against “your” state and its immediate interests as opposed to extended deterrence – dissuasion of adversary actions against a third party or non-immediate interests. Delineating between these two types of deterrence in a globalized world is difficult. Cyberspace compounds the challenge of delineation because attacks on foreign infrastructure can and do have ramifications globally.\nConcepts of the means to achieve deterrence or more simply how to deter are often contested. Threats can be narrowed to weapon type or category, or include\n Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.\n Freedman. 2004.\n Ibid.\n Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n\nOften left out of traditional international relations literature, deterrence by denial has seen a surge of interest in the years following the 9/11 terrorist attacks. Alex Wilner defines deterrence by denial as “reducing the perceived benefits an action is expected to provide a challenger”. Deterrence by denial in the physical world often includes hardening targets by building higher walls, adding security mechanisms, or other tactics to reduce the susceptibility of targets to attack. If the Strategic Defense Initiative (SDI – also known as Star Wars) had been successful, it would have been a deterrence by denial strategy to limit the effect of Soviet nuclear weapons. Commonly used forms of deterrence by denial in conflict zones include land mines, razor wire, surface to air missiles (SAMs) and fortifications.\nDeterrence by punishment and denial are intended to manipulate the cost-benefit analysis of an adversary. To function they must both be credible. Credibility requires undertaking ex-ante costs by the deterrer. Threats absent ante impetum costs lack credibility. A state without nuclear weapons cannot credibly threaten nuclear retaliation. If a state wishes to deter it must provide demonstrable evidence that it is able to carry out its threat.\nLikewise, deterrence by denial fails when it lacks the material capabilities to deny. The Maginot Line built by the French following World War I stands an example of failed deterrence by denial. The French system of fortifications on portions of their northern territory failed because the line itself only covered one vector of attack into France. The elevation of costs to a potential attacker must be complete and provide no reasonable alternatives to achieve the attacker’s intended utility. Both strategies require ex-ante costs by the defender to alter the ex-post perceived benefits of an attacker. Punishment strategies increase adversary costs after a violation and denial strategies increases adversary costs in advance of a violation.\nDeterrence by denial is a successful strategy in many instances; SAMs effectively deter enemy aircraft. The relative costs of upgrading certain denial tools is comparatively less than the costs of surmounting them. In the case of SAMs, the United States spent billions of dollars to defeat the S-300 missile system (~$100 million/system). Following the development and use of stealth, S-300 designer Almaz upgraded its\n Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.\n Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n\nDeterrence by denial is not always successful as illustrated by the Israel – Hamas conflict. In response to Hamas’ use of Katyusha rockets, Israel developed the Iron Dome System. Iron Dome batteries cost $100 million and each rocket costs $50,000. To intercept an incoming Katyusha rocket, the Israelis launch 2 interceptor rockets. By contrast, Hamas spends between $500 and $1,000 per rocket launch. If the cost of the battery is ignored, the cost of deterrence by denial is still between 100 to 1 and 200 to 1.\nDenial strategies are not passive. They require continuous modification relative to adversary capability development. Static denial strategies in cyberspace or in conventional conflict are likely to have limited credibility over time. Similarly, punishment strategies also require constant updating in relation to adversary capabilities and geopolitical considerations. In cyberspace, this involves adapting denial strategies to technological advances such as artificial intelligence, polymorphic malware and the Internet of Things, to name just a few.\nPunishment strategies also require ex-ante costs. Below the nuclear threshold, threats of force are common, yet the credibility of these threats is difficult to establish. Alexander George and Richard Smoke identify three attributes important for signaling in conventional deterrence: “(1) the full formulation of one’s intent to protect a nation; (2) the acquisition and deployment of capacities to back up that intent; (3) the communication of intent to a potential aggressor”. These three aspects are also at times limited in their ability to convey commitment to fulfill the intent.\nCharles Glaser, writing on cyber deterrence, established four components of basic deterrence:\n Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n Ibid.\n Ibid.\n George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.\n Ibid: 558.\n\"1) the benefits of taking the action—the larger the benefits, the harder the adversary is to deter; 2) the probability of achieving the benefits—the higher the probability, the harder the adversary is to deter; 3) the costs the defender will impose if the adversary takes the action—the higher the costs, the more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".[23]\nGeorge and Smoke and Glaser acknowledge the challenge of establishing not just threats of punishment, but the credibility associated with carrying out that threat.\nCreating material capability (i.e. weapon systems capable of carrying out a given threat) and clear signaling might occur and yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework.[24] Credibility and hand-tying are most closely associated with extended deterrence, yet when expanding deterrence to cyberspace it also finds relevance. The establishment of credibility through hand-tying establishes a forcing mechanism for decisions, indicating costs have already been incurred or are likely to occur. This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs.[25] An attack on West Berlin would have resulted in sunk costs and provided a strong inducement or \"tripwire\" to actuate US retaliatory threats. Nearly all forms of kinetic attacks against the direct interests of a nation implicitly include hand-tying. It is unclear how to effectively signal prospective costs within cyberspace to an adversary.\nCharles Glaser identifies several problems associated with deterrence by punishment specific to cyberspace that extend beyond basic credibility issues. First, he notes that deterrence often relies on the attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.[27] Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty.[28] Second, hands-tying and other forms of credibility enhancing measures are likely lacking in cyberspace. Moreover, the ability to respond within domain simply might not be possible within certain conditions.[29] Third, Glaser identifies potential spillovers\n\nDeterrence is more than simply threatening punishment. Deterrence requires substantial target relevant costs and the development of mechanisms to establish that further costs are credibly wagered to provide clarity for an adversary. The goal of this clarity is to establish within an adversary’s calculus that their expected gains are less than any potential losses incurred. Reassessments of rational modeling and the increasing importance of cognitive modeling increase the value of tailored deterrence strategies predicated on the uniqueness of conditions and actors. Paul notes that deterrence is complex and is most logically broken down into five ideal types:\n“(1) deterrence among great powers; (2) deterrence among new nuclear states; (3) deterrence and extended deterrence involving great powers and regional powers armed with chemical, biological and nuclear weapons; (4) deterrence between nuclear states and non-state actors (5) deterrence by collective actors”.\nIt follows that tailored deterrence for cyber actors is also one potential avenue of exploration.\nThe potential for tailored deterrence strategies could be highlighted in numerous significant cyber incident cases. The 1998 cyber attack code-named SOLAR SUNRISE discovered by US Air Force Computer Emergency Response Team (AFCERT) stands as a prime example. The three-week hack affected more than 500 systems across the US Air Force, Navy, NASA, Lawrence Livermore Labs, MIT, Harvard, and UC Berkeley. The attack coincided with increased tensions between the United States and Iraq and resulted in high-level governmental meetings to identify a proper response action. At the time, the attack was believed to be state-sponsored cyber attack focused on degrading US military capabilities. Subsequently, it was discovered that the attack was conducted by two California teenagers with guidance from Israeli hacker Ehud Tenebaum. The incident is relevant to tailored deterrence because it highlights challenges faced in developing a deterrence strategy. The adversaries were domestic, yet foreign inspired and attacked the operational infrastructure of the Department of Defense. No form of deterrence by punishment delineated above could have appropriately accounted this challenge. The only realistic\n Ibid.\n Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.\n Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n\nRichard Kugler writes that a strategy or general framework for deterrence in cyberspace must necessarily be tailored to differing threats, situations, and objectives. The threats, situations, and objectives in cyberspace differ from the concerns addressed by first wave theorists. While the potential for physical damage through cyberspace has been demonstrated in tests such as the Aurora generator experiment that resulted in the destruction of a multi-ton diesel generator, or the Stuxnet attack that destroyed segments of a centrifuge cascade in Iran’s Natanz nuclear facility, many attacks do not have kinetic parallels. Building on Kugler, Jeffrey Cooper identifies three important factors that frame concepts on deterrence in cyberspace. First, there is a wide range of actors each with different capabilities and attributes as well as cost benefits structures; second, cyberspace is a unique operational domain that carries with vastly different concepts of risk and reward; third, to develop deterrence, models must be applicable to the virtual and physical aspects of the domain.\nThis section has provided a summary of a large and robust literature on deterrence. The concepts that need to be carried forward include, the type of deterrence, the credibility of that deterrence and the attributes of the environment in which deterrence occurs, and who and what actors and weapons are to be deterred. The next section builds on the literature above, with a specific emphasis on the technical, tactical, operational and strategic attributes of cyberspace.\n# 3. ONE SIZE DOESN'T FIT ALL\nTo deter adversaries in cyberspace it is helpful to first define what cyberspace is and what types of actions and actors a state would like to deter. The US Department of Defense defines cyberspace in the following way:\n“Cyberspace consists of many different and often overlapping networks, as well as the nodes (any device or logical location with an Internet protocol address or other analogous identifier) on those networks, and the system data (such as routing tables) that support them. Cyberspace can be described in terms of three\n Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.\n US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.\n Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.\nlayers: physical network, logical network, and cyber-persona. The physical network layer of cyberspace is comprised of the geographic component and the physical network components. It is the medium where the data travel. The logical network layer consists of those elements of the network that are related to one another in a way that is abstracted from the physical network, i.e., the form or relationships are not tied to an individual, specific path, or node. A simple example is any Web site that is hosted on servers in multiple physical locations where all content can be accessed through a single uniform resource locator. The cyber-persona layer represents yet a higher level of abstraction of the logical network in cyberspace; it uses the rules that apply in the logical network layer to develop a digital representation of an individual or entity identity in cyberspace. The cyber-persona layer consists of the people actually on the network\".36\nThe inclusion of the full definition illustrates the complexity within which defense strategists and operators in the various services engage. Because the domain spans the physical, logical, and persona layers, deterrence strategies can reasonably occur within and across all three. This fundamentally differs from the conceptualization of deterrence in physical domains of land, sea, air, and space. Physical domain deterrence might include physical and cognitive aspects analogous to the cyber persona and physical network layers, however, the logical layer is wholly absent. The cyber persona layer also diverges significantly from personas within the physical domain as individuals and states have the capacity to alter their attributes within the persona, logical, and network layers.\nTo construct a meaningful model of deterrence in cyberspace we must first ask what it is we wish to deter. Herein lies the largest distinction between deterrence in the physical world and in cyberspace. Whereas in the physical world deterrence is directed most commonly against physical attacks against specific assets or categories of assets that when attacked provide strong, largely non-repudiable forms of attribution, in cyberspace deterrence is directed against manipulations of the elements within the environment and the environment itself. Manipulation of elements of cyberspace and the environment itself can be examined in multiple ways. Simplifying cyberspace operations into three broad categories, there are cyber attacks, cyber espionage, and cyber theft. Despite simplification, it is important to note these categories are not entirely discrete in process or function. Cyber attacks are those acts in cyberspace that degrade, deny or destroy. Acts of cyber espionage steal information for state or corporate intelligence gain. Cyber theft is the stealing of information for financial gain with no direct state utility. Attacks, espionage, and theft occur across all levels\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\nof actors from script kiddies to the military units of states – a problem which will be examined more below. States are most commonly concerned with cyber attacks and espionage at the national level, and theft at lower-jurisdictions.\nBecause attacks, espionage, and theft are perpetrated by a variety of actors against almost any target in cyberspace, sending an overt signal from one state to another, while still applicable, might not deter attacks at other levels that are of equal or greater significance. Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy$^{37}$ usage by states to maintain plausible deniability.$^{38}$ Using proxies to engage in cyber acts against targets deflects deterrence by threats of punishment unless sufficient evidence is present to indicate involvement by the instigating state rather than the third-party proxy. The use of proxies to engage in attacks, espionage and theft against target states outside of cyberspace has been the practice of states since Katulaya and Sun Tzu.$^{39}$ However, unlike the difficulties of non-repudiability within conventional conflicts, cyber attacks are frequently repudiable. Attackers might use Virtual Private Networks (VPNs), proxies or other means by which to engage in an attack.\nAdditional problems in cyberspace not frequently encountered in conventional physical domains are second and third order effects. As noted by Herbert Lin, the results of a cyber attack itself might not be identifiable, rather it is second or third order effects that generate an intended outcome.$^{40}$ Classical deterrence and tailored deterrence strategies used against terrorist organizations are unable to account for disconnected action and reaction pairs commonly found in cyberspace. The time to punish a violation can be weeks, months or years based on discovery and attribution challenges, a problem not present in classical deterrence.\nCyber attacks are incidents occurring in or through cyberspace that degrade, deny or destroy. Attacks in cyberspace can and are perpetrated by all levels of actors. The differentiation between actors is most closely correlated with targets and outcomes of attacks.$^{41}$ For example, criminal actors may use phishing attacks to ingress into a hospital's computer systems to install Cryptolocker or a similar ransomware malware on the hospital's systems. Cryptolocker is an attack that degrades civilian critical infrastructure, denies user access and has the potential to destroy critical\n\nMost scholars and practitioners are likely to contend that it is not the responsibility of the state to deter non-state actors (excepting terrorists), particularly criminals from cyber attacks against non-federal infrastructure outside of a criminological framework.43 Yet, the same tool used by a criminal is available to the state and presents the same challenges associated with attribution irrespective of the perpetrator. What actions could a state undertake to deter an adversary state actor from engaging in this behavior and would these actions have a measurable effect on non-state actors as well?\nExamples of cyber attacks abound and include the destruction, denial or degradation of military or civilian communications platforms. Attacks such as the Mirai (malware) botnet attack in 2016 are capable of being directed at both critical and non-critical infrastructure by both state and non-state actors. A botnet using Mirai was able to generate in excess of 1Tbps of traffic and degrade dozens of websites in the United States on 20 September 2016.44 This same form of attack could be directed towards IP addresses of the FAA and emergency service providers or any number of Internet-enabled systems found on Shodan.io or similar services.45\nAlthough DDoS attacks are generally considered to be among the least complicated forms of cyber attacks they still challenge state and sub-state entities both public and private. DDoS attacks have been used against US government infrastructure, against Estonia in 2007 and the Republic of Georgia in 2008.46 To date, DDoS attacks against the US government or critical infrastructure have received little attention in discussions on deterrence in cyberspace. On 21 January 2016 a grand jury in the Southern District of New York indicted 7 Iranian Hackers in absentia for their involvement in DDoS\n\nBeyond DDoS attacks, Russian attacks against Ukrainian electric infrastructure and US political organizations also resulted in no or weak responses that offer no indication that deterrence is making headway in cyberspace. In response to massive influence operations perpetrated by the Russian Federation against the United States and its two major political parties during the 2016 Presidential election the United States expelled 35 suspected Russian intelligence operatives and placed sanctions on Russia’s two leading intelligence services, the FSB and the GRU. The US response imposed insignificant costs in comparison to the utility achieved by the Russian Federation.\nThe latter case of Russian influence and hacking during the 2016 election cycle provides a case study for why deterrence by threat in cyberspace is so difficult to achieve. The first indications of Russian interference in the 2016 election were identified by the FBI in September 2015 more than a year before the election. The FBI phoned the DNC to try and alert them to a potential attack, but the call was not considered credible and was subsequently ignored by DNC staffers. The progression of hacking attempts against the DNC continued and President Obama was notified in the summer of 2016. Moreover, the “attack” against the DNC was not an attack, but espionage or theft and therefore falls outside conventionally defined deterrence frameworks. Yet the impact of the espionage and the later release of private DNC emails was substantial as indicated in a declassified report by the Office of the Director of National Intelligence (ODNI). The report assessed that information warfare conducted following the espionage campaign substantially degraded the DNC and engendered a loss of confidence in the US electoral system. Cyber deterrence has fundamental problems including the realization that the most valuable assets in cyberspace might not be destroyed or degraded, but rather stolen and used.\n US Federal Bureau of Investigation. 2016. “Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion”. https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n Ibid.\n US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n Ibid.\n\nDeterrence by threat within cyberspace is realistically only applicable to cyber operations that result in direct physical effects that are non-repudiable and attributed quickly. Using formal modeling in the Decision to Attack: Military and Intelligence Cyber Decision-making I found that most cyber attacks, with the notable exception of DDoS, operate under varying conditions of anonymity. The anonymity associated with attacks is usually necessary for attacks to be successful in bypassing deterrence by denial frameworks found in the perimeter defenses of networks such as intrusion detection and prevention systems found in the logical or physical network layers of cyberspace. Threats of punishment could impact the persona layer of cyberspace as well, but as will be examined below there are some fundamental challenges unique to cyberspace posed by anonymity.\n## 4. TECHNICAL CHALLENGES: THREATS OF PUNISHMENT WITHIN DOMAIN\nPunishing an adversary in cyberspace is not cheap or fast outside of pre-established botnets or damage done to physical infrastructure. Punishment in or across any of the layers cyberspace requires what the US Department of the Army refers to as intelligence preparation of the battlefield (IPB):\n“IPB is a systemic, continuous process of analyzing the threat and environment in a specific geographic area. It is designed to support staff estimates and military decision making”.\n Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.\nIn response to a nuclear attack on a city in the US, the proportional response would be a counter attack on an adversary city. The city itself is geographically fixed and immovable both logically and physically. Threatening in-kind retaliation is both plausible and technically feasible with ballistic missiles or air assets. The same logic does not hold in cyberspace.\nWhy are in kind retaliations or other forms of punishment not viable solutions for most retaliations in cyberspace? First, a state must fulfill the burden of proof in identifying the perpetrator of an action. All the above IPB and potential for retaliation still depends upon attribution of who, what, and potentially why an attack occurred.59 Retaliation absent strong evidence is likely to lead to misidentification and unnecessary escalation.\nSecond, a state must retaliate within a proximate temporal range. If state X does not have detailed intelligence on the asset it wishes to retaliate against, developing intelligence along with a cyber weapon to target it increases the time horizon of response such that it is days, weeks, months or even years out from the original attack for which it is retaliating. Due to this temporal disconnect, the threat to punish in response to a given action falls into a category of what economists refer to as hyperbolic discounting. The risk of punishment for an attack is possible but so temporally, distant as to be discounted to the point of irrelevance.\nThird, deterrence by punishment requires proportionality. It is necessary to have comparable assets to punish to prevent escalation or violations of international law.60 Comparable assets are not a given within cyberspace and are often difficult to identify.61 To punish an asset within a domain requires pre-established access or knowledge of that asset beyond its location. Whereas a city is immovable and likely to be as susceptible today as it will be tomorrow to a missile or bomb, a computer system that is penetrated today for prepositioned access, might be patched, upgraded or taken offline tomorrow.\nFourth, a state must possess a specific cyber weapon system tailored to its target. If state X alerts state Y that it is going to punish an asset or state X uses a repeated cyber weapon to attack state Y’s system, it is likely to be ineffectual the longer it is used due to updated perimeter defenses, such as intrusion detection and prevention systems (IDPS), antivirus programs or a variety of other security measures. If state X wants to punish state Y it must have knowledge of the attributes of the asset it wishes to retaliate against and what the status of that asset is. State X must also develop new exploits to achieve effects or be confident that State Y has not accounted for previous exploits that have been used.\n\nThe challenges of signaling deterrence by punishment are numerous within cyberspace whether the conflict is contained within domain or crosses over domains. Advances in attribution within a timely manner and the availability and reasonable assumption that proportional assets of an adversary can be held at risk need to be improved to credibly threaten punishment. This is a challenge not isolated to within domain retaliation. While proportional target selection might be slightly easier in cross-domain retaliation, the first three issues raised above are still relevant.\nDeterrence by punishment in cyberspace is possible, but it is not a reliable or credible option under most conditions absent sufficient and sustained intelligence. This assessment is not unique and is borne out in the analysis of Valeriano and Maness, who find that deterrence via punishment is generally ineffective and likely more dangerous than other means of preventing attacks.[62] Moreover, sustained invasive intelligence into adversary networks creates its own unique problems, including a security dilemma.[63] The more states engage in highly invasive intelligence via cyberspace, the more their actions are likely to be misinterpreted. Differentiating between various forms of cyber actions are difficult and can lead to miscalculation.[64]\nFigure 1 illustrates the relationship between attacking and defending forces and area where both forms of deterrence function.\n\nAs seen in Figure 1, deterrence by threat of punishment and denial operate within the same temporal ranges, yet while attribution matters a great deal for threats of punishment they are generally unimportant for denial. In their initial stages both denial and punishment focus on ante-impetum means of dissuasion, yet deterrence by punishment necessarily needs post-impetum attribution for it to be used. Based on the technical realities of cyberspace and of international relations deterrence by threat of punishment is more complicated and difficult to effectively establish.\n# 5. TECHNICAL CHALLENGES AND OPPORTUNITIES: DETERRENCE BY DENIAL\nBoth deterrence by denial and punishment require ante-impetum costs by the defender. The allocation of resources between denial and deterrence and the efficiency with which they deter adversaries differ. The establishment of credible deterrence by denial often starts with the allocation of financial capital to purchase technical resources and provide human capital sufficient to continually update, enhance, audit and manage complex network infrastructure.[65] Network-based and host-based defenses such as intrusion detection and prevention systems, anti-virus products and similar systems are some of the variety of overlapping expenditures that can be undertaken to increasingly make the intrusion of adversaries into a given network more difficult.[66]\nIn cyberspace, such expenditures are regularized and often included as overhead costs, however they are deterrent in nature.[67] Although they are not glamorous, they substantially decrease the probability of penetration. The same types of deterrence strategies are used by stores in placing electronic tracking tags on their products and detectors at doors, by banks in the construction of vaults, silent alarms and dyed packets of money, by critical infrastructure in extending the perimeter of security outward to prevent vehicle-borne improvised explosive devices, increased numbers of security guards, cameras and the use of razor wire or other physical structures. These devices signal to adversaries both criminal and terrorist alike that the costs of successfully perpetrating an attack are high and that the likelihood of success is low, although both terrorist and criminal deterrence models include deterrence by punishment through criminal proceedings and potential lethal actions against terrorist they rely far more heavily on preventive measures that deny would be adversaries.\nSceptics might contend denial mechanisms are unlikely to deter a state, yet this is in and of itself not accurate. The vast majority of probes by states do not translate into successfully attacks. The US Department of Defense suffers from millions of probes\n[65] Riggs, Cliff. (2004). *Network Perimeter Security*. New York: Auerbach Publications.\n[66] Buecher, Axel, Per Andreas, and Scott Paisley. 2009. “Understanding IT Perimeter Security”. IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n[67] Filkins, Barbara. 2016. “IT Security Spending Trends”. SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n\nUnlike in any other battlespace, whether conventional kinetic terrorism, conventional kinetic or mass destruction military force, the opportunities for deterrence by denial are substantial in cyberspace and unique. While denial opportunities in land, sea, air, and even space are predicated on the control of a given geospatial area, the party establishing deterrence by denial has limited abilities to manipulate the nature of the domain itself. The same is not true within cyberspace. Every aspect of a defender’s cyberspace from the structure of the network, to the hardware, firmware, and software within a network, to the access of individuals within and external to that network is manipulable. At every stage of an attack an adversary is always attempting to operate on or against the defender’s cyberspace over which it has no control and has limited visibility.\nFor denial, the historical literature of deterrence theory remains relevant, in particular the second and third stages of deterrence which focused on rational game theoretic and cognitive modeling. While in conventional deterrence the emphasis was on punishment, here these same modeling techniques find applicability in deterrence by denial. Although the games might be the same, the payoffs in cyberspace manipulable and favor the defender. In few other applications of deterrence are the payoff matrices of deterrence so favorable to the defender. Despite the favorability of conditions, the ability to manipulate the potential payoff for attackers remains difficult. Although possible for defenders to reduce the probability of attack success, the potential payoff for a successful attack can remain large.\nDespite conditions favoring defenders, the potential payoffs are often not affected by deterrence by denial. Minimizing the potential payoffs from attacks on data repositories requires disaggregation of data. These types of denial mechanisms come with efficiency or financial costs. Although denial offers more potential than punishment, it is not a silver bullet to the cyber deterrence problem. Denial decreases the probability of success for attackers and is likely to reduce classes of actors focused on certain targets. Despite efforts to signal through the purchase and implementation of various defensive measures, the re-architecting of network infrastructure, the cyber deterrence problem remains.\n Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\n# 6. BEYOND THE DETERRENCE PROBLEM\nIf punishment and denial are unable to fully remediate the cyber deterrence problem, are there any meaningful solutions? The core debate remains, with no simple and readily apparent solutions. The search for a single solution is likely to remain fruitless for the foreseeable future. Deterrence has never been the single tool within the toolbox of the state to dissuade or shape adversary behavior. Rather, it has always been combined with efforts that extend beyond traditional concepts of deterrence to include geopolitical and technical practices including norm development, entanglement, cumulative deterrence, research and development, policies and laws, liability structures for software and hardware, training for users and human capital development within information technology and cybersecurity.\nEfficient and effective cyber deterrence should extend international politics and include fields such as criminology, immunology and public health. The capacity of states to punish criminals is high and the credibility of punishment actions in developed nations is strong. Despite a capacity to punish criminal behaviors, they still occur. Extending beyond punishment, states also focus on denying criminals opportunities to commit crimes. Yet crime still occurs. The root causes of crime are not simple nor isolatable to a single phenomenon. Likewise, states engage one another in cyberspace for a variety of reasons. Some reasons fit within conventional deterrence frameworks of denial and punishment and do not suffer from challenges with attribution. For instance, larger and more harmful attacks increase the probability of attribution. However, many states remain perturbed by the death by a thousand cuts phenomena which falls below thresholds and required to provide timely attribution.\nShifting the focus away from within domain deterrence focused solely on punishment and denial and changing the emphasis to a basket of strategies focused on reducing incentives, availability and anonymity fosters an environment less conducive both to hostile actions and potential malicious actors. The solution to the deterrence problem is not abandoning it, but expanding the range of alternative strategies not presently considered. By acknowledging the failures and inadequacies of deterrence strategies and the potential places where novel strategies found in other fields are applicable the intractable problem of cyber deterrence becomes more manageable.\n Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.\n Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n49",
  "citations": {
    "style": "superscript",
    "flat_text": "CyCon X: Maximising Effects\nT. Minárik, R. Jakschis, L. Lindström (Eds.)\n\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# The Cyber Deterrence Problem\nAaron F. Brantly\nAssistant Professor, Department of Political Science\nVirginia Polytechnic and State University\nUnited States\nabrantly@vt.edu\nAbstract: What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.\nKeywords: cyber, deterrence, denial, punishment\n# 1. INTRODUCTION\nThe challenge of the digital era is not to define deterrence. Deterrence is a well-defined concept that has been studied and practiced throughout history and to an even greater depth following the advent of nuclear weapons. The present challenge it is to understand the role digital technologies play in the broader scope of interstate deterrence. Deterrence in one domain rarely if ever operates independently of other domains. Much of the literature on cyber deterrence focuses on within domain deterrence. Yet, this is a dangerous constraint that elevates risks and minimizes the probability of success. This paper seeks to draw out the literature on deterrence and identify its applicability within a newly delineated domain of interactions, cyberspace. The resultant analysis strives to encompass the complexity of deterrence and advance an argument beyond within domain modeling.\n\nFocusing on classical deterrence and deterrence by denial helps illustrate the similarities and differences between deterrence in the pre- and post-delineation of cyberspace as a domain of military operations. Deterrence in cyberspace has been addressed by a variety of scholars across the subfields of International Relations. Many examinations of cyber deterrence rely on direct applications of IR theory absent robust technical understandings of how the domain functions. The development and application of classical deterrence theories to a domain necessarily requires an understanding of how state and non-state actors achieve, develop, and assess costs and benefits within this domain.\nThis work proceeds in three sections. First, it examines some of the relevant literature on deterrence and identifies some of the gaps within the field and provides a trajectory for the subsequent sections to examine a more dynamic theory of deterrence in cyberspace. The second section focuses on the technical, tactical, operational, and strategic aspects of the domain in an effort to identify those areas where deterrence can alter the costs-benefit analysis of adversaries. Third, the work concludes by providing a discussion on national strategy development for integrated cyber deterrence incorporating the lessons from the first two sections.\n## 2. FROM ATOMS TO BITS AND BYTES\nDeterrence is not a novel concept. The classical IR cannon on deterrence can be traced back to the Peloponnesian War and the threat of violence in response to adversary actions. Yet, more modern formulations of deterrence are largely rooted in the nuclear world following World War 2. The most common form of deterrence known as conventional deterrence was established by Bernard Brodie, Thomas Schelling and\n Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\nothers and focuses on the ex-ante dissuasion of adversaries through the threat of ex-post costs in response to potential adversary actions.\nRobert Jervis identified three “waves” of deterrence theorizing to which a potential fourth wave has been added by Jeffery Knopf. First wave deterrence theory rested on the rise and consequences of nuclear weapons. Bernard Brodie et al. asserted that the use of nuclear weapons had almost no innate strategic or tactical value outside of being a threat against an adversary. The consequences of nuclear weapons use, even in limited strike situations, would quickly and dramatically escalate. This escalation made the limited use of such weapons untenable in all but the most extreme situations. Lawrence Freedman summarized the second wave as the realization that “total war could now only be threatened, but never fought”.\nSecond wave deterrence posited how nuclear weapons could be threatened and the dynamics of those threats. Thomas Schelling and others posited a series of conditions in which states could develop deterrence in the nuclear era. As Jervis noted, second wave theorizing became extremely popular because of its abstraction and logical structuring. Game theory and other rational models were used to illustrate rational costs and benefits, creating models suited to rigorous concepts of rationality. The second wave arose under stable bi-polar conditions in which it was assumed states engaged in rational decision-making in matters of foreign policy and national security. Schelling found deterrence largely dependent upon credibility and rationality. He illustrated that signaling potential costs to an adversary absent credibility creates deterrence failure. By using divergent game-theoretic structures from prisoner’s dilemma to chicken – theorists developed arguments about deterrence. Despite rigorous theory, this abstraction contained systemic flaws and gave rise to a third wave of deterrence.\nThe third wave of deterrence theory in the 1970s addressed challenges beyond game theoretic models, including the failing rationality. Irving Janis and Graham Allison, both, but with different perspectives, illustrated the weaknesses of rationality in decision-making. The third wave led to extensions into cognitive psychology and behavioral studies. Robert Jervis, Richard Ned Lebow, and Janis Stein provided insight into the general problems associated with parsimonious use of rationality through case analyses. Specifically, Jervis et al. identified the potential for over-valuation of\n Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.\n Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.\n Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.\n Ibid: 22.\n Jervis. Review: 291-292.\n Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.\n Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n\nJeffrey Berejikian incorporated Daniel Kahneman and Amos Tversky’s analysis of prospect theory into the deterrence calculus and challenged parsimonious rational thought by illustrating cognitive dimensions associated with decision-making beyond groupthink and bureaucratic processes. His work highlighted issues related to risk in cognitive decision-making that undermine rationality. Concepts such as sunk costs or tying hands fit well within parsimonious deterrence theory, yet the mechanisms that made them effective were not well understood prior to the third wave.\nAlthough modern deterrence theory encompasses a spectrum from pure rational modeling to cognitive models, the objective of deterrence as identified by John Mearsheimer remains the development of fear of the consequences (in particular of “military action”) or a “function of costs and risks”. Developing shared knowledge about costs and risks for nuclear events differs from non-nuclear conflicts. Early deterrence models relied heavily on rationality and parsimony but did not underestimate the clarity provided by the use and subsequent impact of the weapons themselves. The generation of fear or knowledge of consequences to assess costs and risks loses clarity the as analyses shift away from nuclear weapons. Lawrence Freedman defines single weapon or type of warfare deterrence as “narrow deterrence”. Narrow deterrence is less effective when expanded beyond single weapon or type warfare.\nGeneral or broad deterrence covers a range threatened actions to dissuade an adversary. Freedman writes: “broad deterrence involves deterring all war”. Ted Hopf explains: within deterrence there is a need to expand deterrence beyond the scope of military tools to the entire range of options available to actors. Extending analysis further, scholars also emphasize concepts of direct deterrence and extended deterrence. Direct deterrence is concerned with actions against “your” state and its immediate interests as opposed to extended deterrence – dissuasion of adversary actions against a third party or non-immediate interests. Delineating between these two types of deterrence in a globalized world is difficult. Cyberspace compounds the challenge of delineation because attacks on foreign infrastructure can and do have ramifications globally.\nConcepts of the means to achieve deterrence or more simply how to deter are often contested. Threats can be narrowed to weapon type or category, or include\n Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.\n Freedman. 2004.\n Ibid.\n Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n\nOften left out of traditional international relations literature, deterrence by denial has seen a surge of interest in the years following the 9/11 terrorist attacks. Alex Wilner defines deterrence by denial as “reducing the perceived benefits an action is expected to provide a challenger”. Deterrence by denial in the physical world often includes hardening targets by building higher walls, adding security mechanisms, or other tactics to reduce the susceptibility of targets to attack. If the Strategic Defense Initiative (SDI – also known as Star Wars) had been successful, it would have been a deterrence by denial strategy to limit the effect of Soviet nuclear weapons. Commonly used forms of deterrence by denial in conflict zones include land mines, razor wire, surface to air missiles (SAMs) and fortifications.\nDeterrence by punishment and denial are intended to manipulate the cost-benefit analysis of an adversary. To function they must both be credible. Credibility requires undertaking ex-ante costs by the deterrer. Threats absent ante impetum costs lack credibility. A state without nuclear weapons cannot credibly threaten nuclear retaliation. If a state wishes to deter it must provide demonstrable evidence that it is able to carry out its threat.\nLikewise, deterrence by denial fails when it lacks the material capabilities to deny. The Maginot Line built by the French following World War I stands an example of failed deterrence by denial. The French system of fortifications on portions of their northern territory failed because the line itself only covered one vector of attack into France. The elevation of costs to a potential attacker must be complete and provide no reasonable alternatives to achieve the attacker’s intended utility. Both strategies require ex-ante costs by the defender to alter the ex-post perceived benefits of an attacker. Punishment strategies increase adversary costs after a violation and denial strategies increases adversary costs in advance of a violation.\nDeterrence by denial is a successful strategy in many instances; SAMs effectively deter enemy aircraft. The relative costs of upgrading certain denial tools is comparatively less than the costs of surmounting them. In the case of SAMs, the United States spent billions of dollars to defeat the S-300 missile system (~$100 million/system). Following the development and use of stealth, S-300 designer Almaz upgraded its\n Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.\n Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n\nDeterrence by denial is not always successful as illustrated by the Israel – Hamas conflict. In response to Hamas’ use of Katyusha rockets, Israel developed the Iron Dome System. Iron Dome batteries cost $100 million and each rocket costs $50,000. To intercept an incoming Katyusha rocket, the Israelis launch 2 interceptor rockets. By contrast, Hamas spends between $500 and $1,000 per rocket launch. If the cost of the battery is ignored, the cost of deterrence by denial is still between 100 to 1 and 200 to 1.\nDenial strategies are not passive. They require continuous modification relative to adversary capability development. Static denial strategies in cyberspace or in conventional conflict are likely to have limited credibility over time. Similarly, punishment strategies also require constant updating in relation to adversary capabilities and geopolitical considerations. In cyberspace, this involves adapting denial strategies to technological advances such as artificial intelligence, polymorphic malware and the Internet of Things, to name just a few.\nPunishment strategies also require ex-ante costs. Below the nuclear threshold, threats of force are common, yet the credibility of these threats is difficult to establish. Alexander George and Richard Smoke identify three attributes important for signaling in conventional deterrence: “(1) the full formulation of one’s intent to protect a nation; (2) the acquisition and deployment of capacities to back up that intent; (3) the communication of intent to a potential aggressor”. These three aspects are also at times limited in their ability to convey commitment to fulfill the intent.\nCharles Glaser, writing on cyber deterrence, established four components of basic deterrence:\n Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n Ibid.\n Ibid.\n George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.\n Ibid: 558.\n\"1) the benefits of taking the action—the larger the benefits, the harder the adversary is to deter; 2) the probability of achieving the benefits—the higher the probability, the harder the adversary is to deter; 3) the costs the defender will impose if the adversary takes the action—the higher the costs, the more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".[23]\nGeorge and Smoke and Glaser acknowledge the challenge of establishing not just threats of punishment, but the credibility associated with carrying out that threat.\nCreating material capability (i.e. weapon systems capable of carrying out a given threat) and clear signaling might occur and yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework.[24] Credibility and hand-tying are most closely associated with extended deterrence, yet when expanding deterrence to cyberspace it also finds relevance. The establishment of credibility through hand-tying establishes a forcing mechanism for decisions, indicating costs have already been incurred or are likely to occur. This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs.[25] An attack on West Berlin would have resulted in sunk costs and provided a strong inducement or \"tripwire\" to actuate US retaliatory threats. Nearly all forms of kinetic attacks against the direct interests of a nation implicitly include hand-tying. It is unclear how to effectively signal prospective costs within cyberspace to an adversary.\nCharles Glaser identifies several problems associated with deterrence by punishment specific to cyberspace that extend beyond basic credibility issues. First, he notes that deterrence often relies on the attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.[27] Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty.[28] Second, hands-tying and other forms of credibility enhancing measures are likely lacking in cyberspace. Moreover, the ability to respond within domain simply might not be possible within certain conditions.[29] Third, Glaser identifies potential spillovers\n\nDeterrence is more than simply threatening punishment. Deterrence requires substantial target relevant costs and the development of mechanisms to establish that further costs are credibly wagered to provide clarity for an adversary. The goal of this clarity is to establish within an adversary’s calculus that their expected gains are less than any potential losses incurred. Reassessments of rational modeling and the increasing importance of cognitive modeling increase the value of tailored deterrence strategies predicated on the uniqueness of conditions and actors. Paul notes that deterrence is complex and is most logically broken down into five ideal types:\n“(1) deterrence among great powers; (2) deterrence among new nuclear states; (3) deterrence and extended deterrence involving great powers and regional powers armed with chemical, biological and nuclear weapons; (4) deterrence between nuclear states and non-state actors (5) deterrence by collective actors”.\nIt follows that tailored deterrence for cyber actors is also one potential avenue of exploration.\nThe potential for tailored deterrence strategies could be highlighted in numerous significant cyber incident cases. The 1998 cyber attack code-named SOLAR SUNRISE discovered by US Air Force Computer Emergency Response Team (AFCERT) stands as a prime example. The three-week hack affected more than 500 systems across the US Air Force, Navy, NASA, Lawrence Livermore Labs, MIT, Harvard, and UC Berkeley. The attack coincided with increased tensions between the United States and Iraq and resulted in high-level governmental meetings to identify a proper response action. At the time, the attack was believed to be state-sponsored cyber attack focused on degrading US military capabilities. Subsequently, it was discovered that the attack was conducted by two California teenagers with guidance from Israeli hacker Ehud Tenebaum. The incident is relevant to tailored deterrence because it highlights challenges faced in developing a deterrence strategy. The adversaries were domestic, yet foreign inspired and attacked the operational infrastructure of the Department of Defense. No form of deterrence by punishment delineated above could have appropriately accounted this challenge. The only realistic\n Ibid.\n Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.\n Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n\nRichard Kugler writes that a strategy or general framework for deterrence in cyberspace must necessarily be tailored to differing threats, situations, and objectives. The threats, situations, and objectives in cyberspace differ from the concerns addressed by first wave theorists. While the potential for physical damage through cyberspace has been demonstrated in tests such as the Aurora generator experiment that resulted in the destruction of a multi-ton diesel generator, or the Stuxnet attack that destroyed segments of a centrifuge cascade in Iran’s Natanz nuclear facility, many attacks do not have kinetic parallels. Building on Kugler, Jeffrey Cooper identifies three important factors that frame concepts on deterrence in cyberspace. First, there is a wide range of actors each with different capabilities and attributes as well as cost benefits structures; second, cyberspace is a unique operational domain that carries with vastly different concepts of risk and reward; third, to develop deterrence, models must be applicable to the virtual and physical aspects of the domain.\nThis section has provided a summary of a large and robust literature on deterrence. The concepts that need to be carried forward include, the type of deterrence, the credibility of that deterrence and the attributes of the environment in which deterrence occurs, and who and what actors and weapons are to be deterred. The next section builds on the literature above, with a specific emphasis on the technical, tactical, operational and strategic attributes of cyberspace.\n# 3. ONE SIZE DOESN'T FIT ALL\nTo deter adversaries in cyberspace it is helpful to first define what cyberspace is and what types of actions and actors a state would like to deter. The US Department of Defense defines cyberspace in the following way:\n“Cyberspace consists of many different and often overlapping networks, as well as the nodes (any device or logical location with an Internet protocol address or other analogous identifier) on those networks, and the system data (such as routing tables) that support them. Cyberspace can be described in terms of three\n Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.\n US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.\n Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.\nlayers: physical network, logical network, and cyber-persona. The physical network layer of cyberspace is comprised of the geographic component and the physical network components. It is the medium where the data travel. The logical network layer consists of those elements of the network that are related to one another in a way that is abstracted from the physical network, i.e., the form or relationships are not tied to an individual, specific path, or node. A simple example is any Web site that is hosted on servers in multiple physical locations where all content can be accessed through a single uniform resource locator. The cyber-persona layer represents yet a higher level of abstraction of the logical network in cyberspace; it uses the rules that apply in the logical network layer to develop a digital representation of an individual or entity identity in cyberspace. The cyber-persona layer consists of the people actually on the network\".36\nThe inclusion of the full definition illustrates the complexity within which defense strategists and operators in the various services engage. Because the domain spans the physical, logical, and persona layers, deterrence strategies can reasonably occur within and across all three. This fundamentally differs from the conceptualization of deterrence in physical domains of land, sea, air, and space. Physical domain deterrence might include physical and cognitive aspects analogous to the cyber persona and physical network layers, however, the logical layer is wholly absent. The cyber persona layer also diverges significantly from personas within the physical domain as individuals and states have the capacity to alter their attributes within the persona, logical, and network layers.\nTo construct a meaningful model of deterrence in cyberspace we must first ask what it is we wish to deter. Herein lies the largest distinction between deterrence in the physical world and in cyberspace. Whereas in the physical world deterrence is directed most commonly against physical attacks against specific assets or categories of assets that when attacked provide strong, largely non-repudiable forms of attribution, in cyberspace deterrence is directed against manipulations of the elements within the environment and the environment itself. Manipulation of elements of cyberspace and the environment itself can be examined in multiple ways. Simplifying cyberspace operations into three broad categories, there are cyber attacks, cyber espionage, and cyber theft. Despite simplification, it is important to note these categories are not entirely discrete in process or function. Cyber attacks are those acts in cyberspace that degrade, deny or destroy. Acts of cyber espionage steal information for state or corporate intelligence gain. Cyber theft is the stealing of information for financial gain with no direct state utility. Attacks, espionage, and theft occur across all levels\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\nof actors from script kiddies to the military units of states – a problem which will be examined more below. States are most commonly concerned with cyber attacks and espionage at the national level, and theft at lower-jurisdictions.\nBecause attacks, espionage, and theft are perpetrated by a variety of actors against almost any target in cyberspace, sending an overt signal from one state to another, while still applicable, might not deter attacks at other levels that are of equal or greater significance. Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy$^{37}$ usage by states to maintain plausible deniability.$^{38}$ Using proxies to engage in cyber acts against targets deflects deterrence by threats of punishment unless sufficient evidence is present to indicate involvement by the instigating state rather than the third-party proxy. The use of proxies to engage in attacks, espionage and theft against target states outside of cyberspace has been the practice of states since Katulaya and Sun Tzu.$^{39}$ However, unlike the difficulties of non-repudiability within conventional conflicts, cyber attacks are frequently repudiable. Attackers might use Virtual Private Networks (VPNs), proxies or other means by which to engage in an attack.\nAdditional problems in cyberspace not frequently encountered in conventional physical domains are second and third order effects. As noted by Herbert Lin, the results of a cyber attack itself might not be identifiable, rather it is second or third order effects that generate an intended outcome.$^{40}$ Classical deterrence and tailored deterrence strategies used against terrorist organizations are unable to account for disconnected action and reaction pairs commonly found in cyberspace. The time to punish a violation can be weeks, months or years based on discovery and attribution challenges, a problem not present in classical deterrence.\nCyber attacks are incidents occurring in or through cyberspace that degrade, deny or destroy. Attacks in cyberspace can and are perpetrated by all levels of actors. The differentiation between actors is most closely correlated with targets and outcomes of attacks.$^{41}$ For example, criminal actors may use phishing attacks to ingress into a hospital's computer systems to install Cryptolocker or a similar ransomware malware on the hospital's systems. Cryptolocker is an attack that degrades civilian critical infrastructure, denies user access and has the potential to destroy critical\n\nMost scholars and practitioners are likely to contend that it is not the responsibility of the state to deter non-state actors (excepting terrorists), particularly criminals from cyber attacks against non-federal infrastructure outside of a criminological framework.43 Yet, the same tool used by a criminal is available to the state and presents the same challenges associated with attribution irrespective of the perpetrator. What actions could a state undertake to deter an adversary state actor from engaging in this behavior and would these actions have a measurable effect on non-state actors as well?\nExamples of cyber attacks abound and include the destruction, denial or degradation of military or civilian communications platforms. Attacks such as the Mirai (malware) botnet attack in 2016 are capable of being directed at both critical and non-critical infrastructure by both state and non-state actors. A botnet using Mirai was able to generate in excess of 1Tbps of traffic and degrade dozens of websites in the United States on 20 September 2016.44 This same form of attack could be directed towards IP addresses of the FAA and emergency service providers or any number of Internet-enabled systems found on Shodan.io or similar services.45\nAlthough DDoS attacks are generally considered to be among the least complicated forms of cyber attacks they still challenge state and sub-state entities both public and private. DDoS attacks have been used against US government infrastructure, against Estonia in 2007 and the Republic of Georgia in 2008.46 To date, DDoS attacks against the US government or critical infrastructure have received little attention in discussions on deterrence in cyberspace. On 21 January 2016 a grand jury in the Southern District of New York indicted 7 Iranian Hackers in absentia for their involvement in DDoS\n\nBeyond DDoS attacks, Russian attacks against Ukrainian electric infrastructure and US political organizations also resulted in no or weak responses that offer no indication that deterrence is making headway in cyberspace. In response to massive influence operations perpetrated by the Russian Federation against the United States and its two major political parties during the 2016 Presidential election the United States expelled 35 suspected Russian intelligence operatives and placed sanctions on Russia’s two leading intelligence services, the FSB and the GRU. The US response imposed insignificant costs in comparison to the utility achieved by the Russian Federation.\nThe latter case of Russian influence and hacking during the 2016 election cycle provides a case study for why deterrence by threat in cyberspace is so difficult to achieve. The first indications of Russian interference in the 2016 election were identified by the FBI in September 2015 more than a year before the election. The FBI phoned the DNC to try and alert them to a potential attack, but the call was not considered credible and was subsequently ignored by DNC staffers. The progression of hacking attempts against the DNC continued and President Obama was notified in the summer of 2016. Moreover, the “attack” against the DNC was not an attack, but espionage or theft and therefore falls outside conventionally defined deterrence frameworks. Yet the impact of the espionage and the later release of private DNC emails was substantial as indicated in a declassified report by the Office of the Director of National Intelligence (ODNI). The report assessed that information warfare conducted following the espionage campaign substantially degraded the DNC and engendered a loss of confidence in the US electoral system. Cyber deterrence has fundamental problems including the realization that the most valuable assets in cyberspace might not be destroyed or degraded, but rather stolen and used.\n US Federal Bureau of Investigation. 2016. “Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion”. https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n Ibid.\n US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n Ibid.\n\nDeterrence by threat within cyberspace is realistically only applicable to cyber operations that result in direct physical effects that are non-repudiable and attributed quickly. Using formal modeling in the Decision to Attack: Military and Intelligence Cyber Decision-making I found that most cyber attacks, with the notable exception of DDoS, operate under varying conditions of anonymity. The anonymity associated with attacks is usually necessary for attacks to be successful in bypassing deterrence by denial frameworks found in the perimeter defenses of networks such as intrusion detection and prevention systems found in the logical or physical network layers of cyberspace. Threats of punishment could impact the persona layer of cyberspace as well, but as will be examined below there are some fundamental challenges unique to cyberspace posed by anonymity.\n## 4. TECHNICAL CHALLENGES: THREATS OF PUNISHMENT WITHIN DOMAIN\nPunishing an adversary in cyberspace is not cheap or fast outside of pre-established botnets or damage done to physical infrastructure. Punishment in or across any of the layers cyberspace requires what the US Department of the Army refers to as intelligence preparation of the battlefield (IPB):\n“IPB is a systemic, continuous process of analyzing the threat and environment in a specific geographic area. It is designed to support staff estimates and military decision making”.\n Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.\nIn response to a nuclear attack on a city in the US, the proportional response would be a counter attack on an adversary city. The city itself is geographically fixed and immovable both logically and physically. Threatening in-kind retaliation is both plausible and technically feasible with ballistic missiles or air assets. The same logic does not hold in cyberspace.\nWhy are in kind retaliations or other forms of punishment not viable solutions for most retaliations in cyberspace? First, a state must fulfill the burden of proof in identifying the perpetrator of an action. All the above IPB and potential for retaliation still depends upon attribution of who, what, and potentially why an attack occurred.59 Retaliation absent strong evidence is likely to lead to misidentification and unnecessary escalation.\nSecond, a state must retaliate within a proximate temporal range. If state X does not have detailed intelligence on the asset it wishes to retaliate against, developing intelligence along with a cyber weapon to target it increases the time horizon of response such that it is days, weeks, months or even years out from the original attack for which it is retaliating. Due to this temporal disconnect, the threat to punish in response to a given action falls into a category of what economists refer to as hyperbolic discounting. The risk of punishment for an attack is possible but so temporally, distant as to be discounted to the point of irrelevance.\nThird, deterrence by punishment requires proportionality. It is necessary to have comparable assets to punish to prevent escalation or violations of international law.60 Comparable assets are not a given within cyberspace and are often difficult to identify.61 To punish an asset within a domain requires pre-established access or knowledge of that asset beyond its location. Whereas a city is immovable and likely to be as susceptible today as it will be tomorrow to a missile or bomb, a computer system that is penetrated today for prepositioned access, might be patched, upgraded or taken offline tomorrow.\nFourth, a state must possess a specific cyber weapon system tailored to its target. If state X alerts state Y that it is going to punish an asset or state X uses a repeated cyber weapon to attack state Y’s system, it is likely to be ineffectual the longer it is used due to updated perimeter defenses, such as intrusion detection and prevention systems (IDPS), antivirus programs or a variety of other security measures. If state X wants to punish state Y it must have knowledge of the attributes of the asset it wishes to retaliate against and what the status of that asset is. State X must also develop new exploits to achieve effects or be confident that State Y has not accounted for previous exploits that have been used.\n\nThe challenges of signaling deterrence by punishment are numerous within cyberspace whether the conflict is contained within domain or crosses over domains. Advances in attribution within a timely manner and the availability and reasonable assumption that proportional assets of an adversary can be held at risk need to be improved to credibly threaten punishment. This is a challenge not isolated to within domain retaliation. While proportional target selection might be slightly easier in cross-domain retaliation, the first three issues raised above are still relevant.\nDeterrence by punishment in cyberspace is possible, but it is not a reliable or credible option under most conditions absent sufficient and sustained intelligence. This assessment is not unique and is borne out in the analysis of Valeriano and Maness, who find that deterrence via punishment is generally ineffective and likely more dangerous than other means of preventing attacks.[62] Moreover, sustained invasive intelligence into adversary networks creates its own unique problems, including a security dilemma.[63] The more states engage in highly invasive intelligence via cyberspace, the more their actions are likely to be misinterpreted. Differentiating between various forms of cyber actions are difficult and can lead to miscalculation.[64]\nFigure 1 illustrates the relationship between attacking and defending forces and area where both forms of deterrence function.\n\nAs seen in Figure 1, deterrence by threat of punishment and denial operate within the same temporal ranges, yet while attribution matters a great deal for threats of punishment they are generally unimportant for denial. In their initial stages both denial and punishment focus on ante-impetum means of dissuasion, yet deterrence by punishment necessarily needs post-impetum attribution for it to be used. Based on the technical realities of cyberspace and of international relations deterrence by threat of punishment is more complicated and difficult to effectively establish.\n# 5. TECHNICAL CHALLENGES AND OPPORTUNITIES: DETERRENCE BY DENIAL\nBoth deterrence by denial and punishment require ante-impetum costs by the defender. The allocation of resources between denial and deterrence and the efficiency with which they deter adversaries differ. The establishment of credible deterrence by denial often starts with the allocation of financial capital to purchase technical resources and provide human capital sufficient to continually update, enhance, audit and manage complex network infrastructure.[65] Network-based and host-based defenses such as intrusion detection and prevention systems, anti-virus products and similar systems are some of the variety of overlapping expenditures that can be undertaken to increasingly make the intrusion of adversaries into a given network more difficult.[66]\nIn cyberspace, such expenditures are regularized and often included as overhead costs, however they are deterrent in nature.[67] Although they are not glamorous, they substantially decrease the probability of penetration. The same types of deterrence strategies are used by stores in placing electronic tracking tags on their products and detectors at doors, by banks in the construction of vaults, silent alarms and dyed packets of money, by critical infrastructure in extending the perimeter of security outward to prevent vehicle-borne improvised explosive devices, increased numbers of security guards, cameras and the use of razor wire or other physical structures. These devices signal to adversaries both criminal and terrorist alike that the costs of successfully perpetrating an attack are high and that the likelihood of success is low, although both terrorist and criminal deterrence models include deterrence by punishment through criminal proceedings and potential lethal actions against terrorist they rely far more heavily on preventive measures that deny would be adversaries.\nSceptics might contend denial mechanisms are unlikely to deter a state, yet this is in and of itself not accurate. The vast majority of probes by states do not translate into successfully attacks. The US Department of Defense suffers from millions of probes\n[65] Riggs, Cliff. (2004). *Network Perimeter Security*. New York: Auerbach Publications.\n[66] Buecher, Axel, Per Andreas, and Scott Paisley. 2009. “Understanding IT Perimeter Security”. IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n[67] Filkins, Barbara. 2016. “IT Security Spending Trends”. SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n\nUnlike in any other battlespace, whether conventional kinetic terrorism, conventional kinetic or mass destruction military force, the opportunities for deterrence by denial are substantial in cyberspace and unique. While denial opportunities in land, sea, air, and even space are predicated on the control of a given geospatial area, the party establishing deterrence by denial has limited abilities to manipulate the nature of the domain itself. The same is not true within cyberspace. Every aspect of a defender’s cyberspace from the structure of the network, to the hardware, firmware, and software within a network, to the access of individuals within and external to that network is manipulable. At every stage of an attack an adversary is always attempting to operate on or against the defender’s cyberspace over which it has no control and has limited visibility.\nFor denial, the historical literature of deterrence theory remains relevant, in particular the second and third stages of deterrence which focused on rational game theoretic and cognitive modeling. While in conventional deterrence the emphasis was on punishment, here these same modeling techniques find applicability in deterrence by denial. Although the games might be the same, the payoffs in cyberspace manipulable and favor the defender. In few other applications of deterrence are the payoff matrices of deterrence so favorable to the defender. Despite the favorability of conditions, the ability to manipulate the potential payoff for attackers remains difficult. Although possible for defenders to reduce the probability of attack success, the potential payoff for a successful attack can remain large.\nDespite conditions favoring defenders, the potential payoffs are often not affected by deterrence by denial. Minimizing the potential payoffs from attacks on data repositories requires disaggregation of data. These types of denial mechanisms come with efficiency or financial costs. Although denial offers more potential than punishment, it is not a silver bullet to the cyber deterrence problem. Denial decreases the probability of success for attackers and is likely to reduce classes of actors focused on certain targets. Despite efforts to signal through the purchase and implementation of various defensive measures, the re-architecting of network infrastructure, the cyber deterrence problem remains.\n Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\n# 6. BEYOND THE DETERRENCE PROBLEM\nIf punishment and denial are unable to fully remediate the cyber deterrence problem, are there any meaningful solutions? The core debate remains, with no simple and readily apparent solutions. The search for a single solution is likely to remain fruitless for the foreseeable future. Deterrence has never been the single tool within the toolbox of the state to dissuade or shape adversary behavior. Rather, it has always been combined with efforts that extend beyond traditional concepts of deterrence to include geopolitical and technical practices including norm development, entanglement, cumulative deterrence, research and development, policies and laws, liability structures for software and hardware, training for users and human capital development within information technology and cybersecurity.\nEfficient and effective cyber deterrence should extend international politics and include fields such as criminology, immunology and public health. The capacity of states to punish criminals is high and the credibility of punishment actions in developed nations is strong. Despite a capacity to punish criminal behaviors, they still occur. Extending beyond punishment, states also focus on denying criminals opportunities to commit crimes. Yet crime still occurs. The root causes of crime are not simple nor isolatable to a single phenomenon. Likewise, states engage one another in cyberspace for a variety of reasons. Some reasons fit within conventional deterrence frameworks of denial and punishment and do not suffer from challenges with attribution. For instance, larger and more harmful attacks increase the probability of attribution. However, many states remain perturbed by the death by a thousand cuts phenomena which falls below thresholds and required to provide timely attribution.\nShifting the focus away from within domain deterrence focused solely on punishment and denial and changing the emphasis to a basket of strategies focused on reducing incentives, availability and anonymity fosters an environment less conducive both to hostile actions and potential malicious actors. The solution to the deterrence problem is not abandoning it, but expanding the range of alternative strategies not presently considered. By acknowledging the failures and inadequacies of deterrence strategies and the potential places where novel strategies found in other fields are applicable the intractable problem of cyber deterrence becomes more manageable.\n Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.\n Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n49",
    "footnotes": {
      "items": {},
      "intext": [
        {
          "index": "37",
          "intext_citation": "$^{37}$",
          "preceding_text": "Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy",
          "footnote": null
        },
        {
          "index": "38",
          "intext_citation": "$^{38}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "39",
          "intext_citation": "$^{39}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "40",
          "intext_citation": "$^{40}$",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "41",
          "intext_citation": "$^{41}$",
          "preceding_text": "",
          "footnote": null
        }
      ],
      "stats": {
        "intext_total": 5,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 36,
        "missing_intext_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
        ],
        "highest_intext_index": 41,
        "missing_footnotes_for_seen_total": 5,
        "missing_footnotes_for_seen_intext": [
          37,
          38,
          39,
          40,
          41
        ],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 86,
        "success_occurrences": 86,
        "success_unique": 43,
        "bib_unique_total": 67,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.6417910447761194,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": "",
          "footnote": "Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.",
          "position": 3542
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.",
          "position": 4771
        },
        {
          "index": 1,
          "intext_citation": "¹",
          "preceding_text": " Brodie, Thomas Schelling and\n",
          "footnote": "Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.",
          "position": 5004
        },
        {
          "index": 2,
          "intext_citation": "²",
          "preceding_text": "",
          "footnote": "Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.",
          "position": 5270
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "",
          "footnote": "Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.",
          "position": 5676
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.",
          "position": 5922
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "",
          "footnote": "Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.",
          "position": 6272
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "",
          "footnote": "Ibid: 22.",
          "position": 6379
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "Jervis. Review: 291-292.",
          "position": 6617
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.",
          "position": 6769
        },
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": "",
          "footnote": "Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.",
          "position": 7643
        },
        {
          "index": 3,
          "intext_citation": "³",
          "preceding_text": "tential for over-valuation of\n",
          "footnote": "Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.",
          "position": 7967
        },
        {
          "index": 4,
          "intext_citation": "⁴",
          "preceding_text": "",
          "footnote": "Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.",
          "position": 8173
        },
        {
          "index": 5,
          "intext_citation": "⁵",
          "preceding_text": "",
          "footnote": "Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.",
          "position": 8372
        },
        {
          "index": 6,
          "intext_citation": "⁶",
          "preceding_text": "",
          "footnote": "Ibid: 22.",
          "position": 8443
        },
        {
          "index": 7,
          "intext_citation": "⁷",
          "preceding_text": "",
          "footnote": "Jervis. Review: 291-292.",
          "position": 8455
        },
        {
          "index": 8,
          "intext_citation": "⁸",
          "preceding_text": "",
          "footnote": "Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.",
          "position": 8482
        },
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": "",
          "footnote": "Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.",
          "position": 8574
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": "",
          "footnote": "Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.",
          "position": 8909
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "",
          "footnote": "Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.",
          "position": 9774
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "",
          "footnote": "Freedman. 2004.",
          "position": 10291
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 10533
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "",
          "footnote": "Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.",
          "position": 10696
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": " type or category, or include\n",
          "footnote": "Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.",
          "position": 11391
        },
        {
          "index": 11,
          "intext_citation": "¹¹",
          "preceding_text": "",
          "footnote": "Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.",
          "position": 11786
        },
        {
          "index": 12,
          "intext_citation": "¹²",
          "preceding_text": "",
          "footnote": "Freedman. 2004.",
          "position": 11883
        },
        {
          "index": 13,
          "intext_citation": "¹³",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 11902
        },
        {
          "index": 14,
          "intext_citation": "¹⁴",
          "preceding_text": "",
          "footnote": "Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.",
          "position": 11911
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "",
          "footnote": "Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.",
          "position": 12646
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.",
          "position": 14709
        },
        {
          "index": 15,
          "intext_citation": "¹⁵",
          "preceding_text": "0 designer Almaz upgraded its\n",
          "footnote": "Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.",
          "position": 14792
        },
        {
          "index": 16,
          "intext_citation": "¹⁶",
          "preceding_text": "",
          "footnote": "Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.",
          "position": 14952
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "",
          "footnote": "Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.",
          "position": 15468
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.",
          "position": 16083
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 16170
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 16241
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.",
          "position": 17388
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "",
          "footnote": "Ibid: 558.",
          "position": 17497
        },
        {
          "index": 17,
          "intext_citation": "¹⁷",
          "preceding_text": "mponents of basic deterrence:\n",
          "footnote": "Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.",
          "position": 17594
        },
        {
          "index": 18,
          "intext_citation": "¹⁸",
          "preceding_text": "",
          "footnote": "Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.",
          "position": 17850
        },
        {
          "index": 19,
          "intext_citation": "¹⁹",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 18065
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 18074
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.",
          "position": 18083
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "",
          "footnote": "Ibid: 558.",
          "position": 18235
        },
        {
          "index": 30,
          "intext_citation": "³⁰",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 21454
        },
        {
          "index": 31,
          "intext_citation": "³¹",
          "preceding_text": "",
          "footnote": "Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.",
          "position": 22743
        },
        {
          "index": 32,
          "intext_citation": "³²",
          "preceding_text": "",
          "footnote": "Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.",
          "position": 23413
        },
        {
          "index": 30,
          "intext_citation": "³⁰",
          "preceding_text": "The only realistic",
          "footnote": "Ibid.",
          "position": 24047
        },
        {
          "index": 31,
          "intext_citation": "³¹",
          "preceding_text": "",
          "footnote": "Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.",
          "position": 24056
        },
        {
          "index": 32,
          "intext_citation": "³²",
          "preceding_text": "",
          "footnote": "Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.",
          "position": 24204
        },
        {
          "index": 33,
          "intext_citation": "³³",
          "preceding_text": "",
          "footnote": "Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.",
          "position": 24621
        },
        {
          "index": 34,
          "intext_citation": "³⁴",
          "preceding_text": "",
          "footnote": "US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.",
          "position": 25082
        },
        {
          "index": 35,
          "intext_citation": "³⁵",
          "preceding_text": "",
          "footnote": "Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.",
          "position": 25548
        },
        {
          "index": 33,
          "intext_citation": "³³",
          "preceding_text": "e described in terms of three\n",
          "footnote": "Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.",
          "position": 26592
        },
        {
          "index": 34,
          "intext_citation": "³⁴",
          "preceding_text": "",
          "footnote": "US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.",
          "position": 26812
        },
        {
          "index": 35,
          "intext_citation": "³⁵",
          "preceding_text": "",
          "footnote": "Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.",
          "position": 27139
        },
        {
          "index": 47,
          "intext_citation": "⁴⁷",
          "preceding_text": "",
          "footnote": "a day. Yet nearly 99.99% of them are unsuccessful.⁶⁸ Moreover, in the face of a global onslaught of cyber attacks and espionage the United States re-architected much of its military network infrastructure. This restructuring allows the initial point of contact with adversaries to be chosen. In military parlance, it allowed the defenders to choose the terrain of the battle. While it did not obviate the need for denial mechanisms within the network infrastructure, it did signal increased cost imposition on adversaries and it did allow for more efficient resource allocation.",
          "position": 37578
        },
        {
          "index": 48,
          "intext_citation": "⁴⁸",
          "preceding_text": "",
          "footnote": "US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.",
          "position": 38089
        },
        {
          "index": 49,
          "intext_citation": "⁴⁹",
          "preceding_text": "",
          "footnote": "Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.",
          "position": 38434
        },
        {
          "index": 50,
          "intext_citation": "⁵⁰",
          "preceding_text": "",
          "footnote": "Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.",
          "position": 38868
        },
        {
          "index": 51,
          "intext_citation": "⁵¹",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 39025
        },
        {
          "index": 52,
          "intext_citation": "⁵²",
          "preceding_text": "",
          "footnote": "US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.",
          "position": 39493
        },
        {
          "index": 53,
          "intext_citation": "⁵³",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 39678
        },
        {
          "index": 47,
          "intext_citation": "⁴⁷",
          "preceding_text": "",
          "footnote": "a day. Yet nearly 99.99% of them are unsuccessful.⁶⁸ Moreover, in the face of a global onslaught of cyber attacks and espionage the United States re-architected much of its military network infrastructure. This restructuring allows the initial point of contact with adversaries to be chosen. In military parlance, it allowed the defenders to choose the terrain of the battle. While it did not obviate the need for denial mechanisms within the network infrastructure, it did signal increased cost imposition on adversaries and it did allow for more efficient resource allocation.",
          "position": 39857
        },
        {
          "index": 48,
          "intext_citation": "⁴⁸",
          "preceding_text": "",
          "footnote": "US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.",
          "position": 40022
        },
        {
          "index": 49,
          "intext_citation": "⁴⁹",
          "preceding_text": "",
          "footnote": "Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.",
          "position": 40337
        },
        {
          "index": 50,
          "intext_citation": "⁵⁰",
          "preceding_text": "",
          "footnote": "Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.",
          "position": 40554
        },
        {
          "index": 51,
          "intext_citation": "⁵¹",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 40790
        },
        {
          "index": 52,
          "intext_citation": "⁵²",
          "preceding_text": "",
          "footnote": "US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.",
          "position": 40799
        },
        {
          "index": 53,
          "intext_citation": "⁵³",
          "preceding_text": "",
          "footnote": "Ibid.",
          "position": 41016
        },
        {
          "index": 54,
          "intext_citation": "⁵⁴",
          "preceding_text": "efforts to hack a spillway dam",
          "footnote": "Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.",
          "position": 41138
        },
        {
          "index": 55,
          "intext_citation": "⁵⁵",
          "preceding_text": "e such as a German steel mill,",
          "footnote": "Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.",
          "position": 41216
        },
        {
          "index": 56,
          "intext_citation": "⁵⁶",
          "preceding_text": "",
          "footnote": "Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.",
          "position": 41669
        },
        {
          "index": 57,
          "intext_citation": "⁵⁷",
          "preceding_text": "",
          "footnote": "Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.",
          "position": 42063
        },
        {
          "index": 58,
          "intext_citation": "⁵⁸",
          "preceding_text": "",
          "footnote": "US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.",
          "position": 43085
        },
        {
          "index": 54,
          "intext_citation": "⁵⁴",
          "preceding_text": "⁵⁸",
          "footnote": "Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.",
          "position": 43088
        },
        {
          "index": 55,
          "intext_citation": "⁵⁵",
          "preceding_text": "",
          "footnote": "Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.",
          "position": 43233
        },
        {
          "index": 56,
          "intext_citation": "⁵⁶",
          "preceding_text": "",
          "footnote": "Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.",
          "position": 43459
        },
        {
          "index": 57,
          "intext_citation": "⁵⁷",
          "preceding_text": "",
          "footnote": "Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.",
          "position": 43727
        },
        {
          "index": 58,
          "intext_citation": "⁵⁸",
          "preceding_text": "",
          "footnote": "US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.",
          "position": 43871
        },
        {
          "index": 68,
          "intext_citation": "⁶⁸",
          "preceding_text": "",
          "footnote": "Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.",
          "position": 52152
        },
        {
          "index": 68,
          "intext_citation": "⁶⁸",
          "preceding_text": "",
          "footnote": "Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.",
          "position": 55070
        },
        {
          "index": 69,
          "intext_citation": "⁶⁹",
          "preceding_text": "",
          "footnote": "Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.",
          "position": 56133
        },
        {
          "index": 70,
          "intext_citation": "⁷⁰",
          "preceding_text": "",
          "footnote": "Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.",
          "position": 56283
        },
        {
          "index": 69,
          "intext_citation": "⁶⁹",
          "preceding_text": "",
          "footnote": "Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.",
          "position": 57795
        },
        {
          "index": 70,
          "intext_citation": "⁷⁰",
          "preceding_text": "",
          "footnote": "Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.",
          "position": 57946
        }
      ],
      "flat_text": "CyCon X: Maximising Effects\nT. Minárik, R. Jakschis, L. Lindström (Eds.)\n\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# The Cyber Deterrence Problem\nAaron F. Brantly\nAssistant Professor, Department of Political Science\nVirginia Polytechnic and State University\nUnited States\nabrantly@vt.edu\nAbstract: What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.\nKeywords: cyber, deterrence, denial, punishment\n# 1. INTRODUCTION\nThe challenge of the digital era is not to define deterrence. Deterrence is a well-defined concept that has been studied and practiced throughout history and to an even greater depth following the advent of nuclear weapons. The present challenge it is to understand the role digital technologies play in the broader scope of interstate deterrence. Deterrence in one domain rarely if ever operates independently of other domains. Much of the literature on cyber deterrence focuses on within domain deterrence. Yet, this is a dangerous constraint that elevates risks and minimizes the probability of success. This paper seeks to draw out the literature on deterrence and identify its applicability within a newly delineated domain of interactions, cyberspace. The resultant analysis strives to encompass the complexity of deterrence and advance an argument beyond within domain modeling.\n\nFocusing on classical deterrence and deterrence by denial helps illustrate the similarities and differences between deterrence in the pre- and post-delineation of cyberspace as a domain of military operations. Deterrence in cyberspace has been addressed by a variety of scholars across the subfields of International Relations. Many examinations of cyber deterrence rely on direct applications of IR theory absent robust technical understandings of how the domain functions. The development and application of classical deterrence theories to a domain necessarily requires an understanding of how state and non-state actors achieve, develop, and assess costs and benefits within this domain.\nThis work proceeds in three sections. First, it examines some of the relevant literature on deterrence and identifies some of the gaps within the field and provides a trajectory for the subsequent sections to examine a more dynamic theory of deterrence in cyberspace. The second section focuses on the technical, tactical, operational, and strategic aspects of the domain in an effort to identify those areas where deterrence can alter the costs-benefit analysis of adversaries. Third, the work concludes by providing a discussion on national strategy development for integrated cyber deterrence incorporating the lessons from the first two sections.\n## 2. FROM ATOMS TO BITS AND BYTES\nDeterrence is not a novel concept. The classical IR cannon on deterrence can be traced back to the Peloponnesian War and the threat of violence in response to adversary actions. Yet, more modern formulations of deterrence are largely rooted in the nuclear world following World War 2. The most common form of deterrence known as conventional deterrence was established by Bernard Brodie, Thomas Schelling and\n Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\nothers and focuses on the ex-ante dissuasion of adversaries through the threat of ex-post costs in response to potential adversary actions.\nRobert Jervis identified three “waves” of deterrence theorizing to which a potential fourth wave has been added by Jeffery Knopf. First wave deterrence theory rested on the rise and consequences of nuclear weapons. Bernard Brodie et al. asserted that the use of nuclear weapons had almost no innate strategic or tactical value outside of being a threat against an adversary. The consequences of nuclear weapons use, even in limited strike situations, would quickly and dramatically escalate. This escalation made the limited use of such weapons untenable in all but the most extreme situations. Lawrence Freedman summarized the second wave as the realization that “total war could now only be threatened, but never fought”.\nSecond wave deterrence posited how nuclear weapons could be threatened and the dynamics of those threats. Thomas Schelling and others posited a series of conditions in which states could develop deterrence in the nuclear era. As Jervis noted, second wave theorizing became extremely popular because of its abstraction and logical structuring. Game theory and other rational models were used to illustrate rational costs and benefits, creating models suited to rigorous concepts of rationality. The second wave arose under stable bi-polar conditions in which it was assumed states engaged in rational decision-making in matters of foreign policy and national security. Schelling found deterrence largely dependent upon credibility and rationality. He illustrated that signaling potential costs to an adversary absent credibility creates deterrence failure. By using divergent game-theoretic structures from prisoner’s dilemma to chicken – theorists developed arguments about deterrence. Despite rigorous theory, this abstraction contained systemic flaws and gave rise to a third wave of deterrence.\nThe third wave of deterrence theory in the 1970s addressed challenges beyond game theoretic models, including the failing rationality. Irving Janis and Graham Allison, both, but with different perspectives, illustrated the weaknesses of rationality in decision-making. The third wave led to extensions into cognitive psychology and behavioral studies. Robert Jervis, Richard Ned Lebow, and Janis Stein provided insight into the general problems associated with parsimonious use of rationality through case analyses. Specifically, Jervis et al. identified the potential for over-valuation of\n Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.\n Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.\n Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.\n Ibid: 22.\n Jervis. Review: 291-292.\n Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.\n Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n\nJeffrey Berejikian incorporated Daniel Kahneman and Amos Tversky’s analysis of prospect theory into the deterrence calculus and challenged parsimonious rational thought by illustrating cognitive dimensions associated with decision-making beyond groupthink and bureaucratic processes. His work highlighted issues related to risk in cognitive decision-making that undermine rationality. Concepts such as sunk costs or tying hands fit well within parsimonious deterrence theory, yet the mechanisms that made them effective were not well understood prior to the third wave.\nAlthough modern deterrence theory encompasses a spectrum from pure rational modeling to cognitive models, the objective of deterrence as identified by John Mearsheimer remains the development of fear of the consequences (in particular of “military action”) or a “function of costs and risks”. Developing shared knowledge about costs and risks for nuclear events differs from non-nuclear conflicts. Early deterrence models relied heavily on rationality and parsimony but did not underestimate the clarity provided by the use and subsequent impact of the weapons themselves. The generation of fear or knowledge of consequences to assess costs and risks loses clarity the as analyses shift away from nuclear weapons. Lawrence Freedman defines single weapon or type of warfare deterrence as “narrow deterrence”. Narrow deterrence is less effective when expanded beyond single weapon or type warfare.\nGeneral or broad deterrence covers a range threatened actions to dissuade an adversary. Freedman writes: “broad deterrence involves deterring all war”. Ted Hopf explains: within deterrence there is a need to expand deterrence beyond the scope of military tools to the entire range of options available to actors. Extending analysis further, scholars also emphasize concepts of direct deterrence and extended deterrence. Direct deterrence is concerned with actions against “your” state and its immediate interests as opposed to extended deterrence – dissuasion of adversary actions against a third party or non-immediate interests. Delineating between these two types of deterrence in a globalized world is difficult. Cyberspace compounds the challenge of delineation because attacks on foreign infrastructure can and do have ramifications globally.\nConcepts of the means to achieve deterrence or more simply how to deter are often contested. Threats can be narrowed to weapon type or category, or include\n Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.\n Freedman. 2004.\n Ibid.\n Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n\nOften left out of traditional international relations literature, deterrence by denial has seen a surge of interest in the years following the 9/11 terrorist attacks. Alex Wilner defines deterrence by denial as “reducing the perceived benefits an action is expected to provide a challenger”. Deterrence by denial in the physical world often includes hardening targets by building higher walls, adding security mechanisms, or other tactics to reduce the susceptibility of targets to attack. If the Strategic Defense Initiative (SDI – also known as Star Wars) had been successful, it would have been a deterrence by denial strategy to limit the effect of Soviet nuclear weapons. Commonly used forms of deterrence by denial in conflict zones include land mines, razor wire, surface to air missiles (SAMs) and fortifications.\nDeterrence by punishment and denial are intended to manipulate the cost-benefit analysis of an adversary. To function they must both be credible. Credibility requires undertaking ex-ante costs by the deterrer. Threats absent ante impetum costs lack credibility. A state without nuclear weapons cannot credibly threaten nuclear retaliation. If a state wishes to deter it must provide demonstrable evidence that it is able to carry out its threat.\nLikewise, deterrence by denial fails when it lacks the material capabilities to deny. The Maginot Line built by the French following World War I stands an example of failed deterrence by denial. The French system of fortifications on portions of their northern territory failed because the line itself only covered one vector of attack into France. The elevation of costs to a potential attacker must be complete and provide no reasonable alternatives to achieve the attacker’s intended utility. Both strategies require ex-ante costs by the defender to alter the ex-post perceived benefits of an attacker. Punishment strategies increase adversary costs after a violation and denial strategies increases adversary costs in advance of a violation.\nDeterrence by denial is a successful strategy in many instances; SAMs effectively deter enemy aircraft. The relative costs of upgrading certain denial tools is comparatively less than the costs of surmounting them. In the case of SAMs, the United States spent billions of dollars to defeat the S-300 missile system (~$100 million/system). Following the development and use of stealth, S-300 designer Almaz upgraded its\n Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.\n Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n\nDeterrence by denial is not always successful as illustrated by the Israel – Hamas conflict. In response to Hamas’ use of Katyusha rockets, Israel developed the Iron Dome System. Iron Dome batteries cost $100 million and each rocket costs $50,000. To intercept an incoming Katyusha rocket, the Israelis launch 2 interceptor rockets. By contrast, Hamas spends between $500 and $1,000 per rocket launch. If the cost of the battery is ignored, the cost of deterrence by denial is still between 100 to 1 and 200 to 1.\nDenial strategies are not passive. They require continuous modification relative to adversary capability development. Static denial strategies in cyberspace or in conventional conflict are likely to have limited credibility over time. Similarly, punishment strategies also require constant updating in relation to adversary capabilities and geopolitical considerations. In cyberspace, this involves adapting denial strategies to technological advances such as artificial intelligence, polymorphic malware and the Internet of Things, to name just a few.\nPunishment strategies also require ex-ante costs. Below the nuclear threshold, threats of force are common, yet the credibility of these threats is difficult to establish. Alexander George and Richard Smoke identify three attributes important for signaling in conventional deterrence: “(1) the full formulation of one’s intent to protect a nation; (2) the acquisition and deployment of capacities to back up that intent; (3) the communication of intent to a potential aggressor”. These three aspects are also at times limited in their ability to convey commitment to fulfill the intent.\nCharles Glaser, writing on cyber deterrence, established four components of basic deterrence:\n Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n Ibid.\n Ibid.\n George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.\n Ibid: 558.\n\"1) the benefits of taking the action—the larger the benefits, the harder the adversary is to deter; 2) the probability of achieving the benefits—the higher the probability, the harder the adversary is to deter; 3) the costs the defender will impose if the adversary takes the action—the higher the costs, the more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".[23]\nGeorge and Smoke and Glaser acknowledge the challenge of establishing not just threats of punishment, but the credibility associated with carrying out that threat.\nCreating material capability (i.e. weapon systems capable of carrying out a given threat) and clear signaling might occur and yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework.[24] Credibility and hand-tying are most closely associated with extended deterrence, yet when expanding deterrence to cyberspace it also finds relevance. The establishment of credibility through hand-tying establishes a forcing mechanism for decisions, indicating costs have already been incurred or are likely to occur. This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs.[25] An attack on West Berlin would have resulted in sunk costs and provided a strong inducement or \"tripwire\" to actuate US retaliatory threats. Nearly all forms of kinetic attacks against the direct interests of a nation implicitly include hand-tying. It is unclear how to effectively signal prospective costs within cyberspace to an adversary.\nCharles Glaser identifies several problems associated with deterrence by punishment specific to cyberspace that extend beyond basic credibility issues. First, he notes that deterrence often relies on the attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.[27] Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty.[28] Second, hands-tying and other forms of credibility enhancing measures are likely lacking in cyberspace. Moreover, the ability to respond within domain simply might not be possible within certain conditions.[29] Third, Glaser identifies potential spillovers\n\nDeterrence is more than simply threatening punishment. Deterrence requires substantial target relevant costs and the development of mechanisms to establish that further costs are credibly wagered to provide clarity for an adversary. The goal of this clarity is to establish within an adversary’s calculus that their expected gains are less than any potential losses incurred. Reassessments of rational modeling and the increasing importance of cognitive modeling increase the value of tailored deterrence strategies predicated on the uniqueness of conditions and actors. Paul notes that deterrence is complex and is most logically broken down into five ideal types:\n“(1) deterrence among great powers; (2) deterrence among new nuclear states; (3) deterrence and extended deterrence involving great powers and regional powers armed with chemical, biological and nuclear weapons; (4) deterrence between nuclear states and non-state actors (5) deterrence by collective actors”.\nIt follows that tailored deterrence for cyber actors is also one potential avenue of exploration.\nThe potential for tailored deterrence strategies could be highlighted in numerous significant cyber incident cases. The 1998 cyber attack code-named SOLAR SUNRISE discovered by US Air Force Computer Emergency Response Team (AFCERT) stands as a prime example. The three-week hack affected more than 500 systems across the US Air Force, Navy, NASA, Lawrence Livermore Labs, MIT, Harvard, and UC Berkeley. The attack coincided with increased tensions between the United States and Iraq and resulted in high-level governmental meetings to identify a proper response action. At the time, the attack was believed to be state-sponsored cyber attack focused on degrading US military capabilities. Subsequently, it was discovered that the attack was conducted by two California teenagers with guidance from Israeli hacker Ehud Tenebaum. The incident is relevant to tailored deterrence because it highlights challenges faced in developing a deterrence strategy. The adversaries were domestic, yet foreign inspired and attacked the operational infrastructure of the Department of Defense. No form of deterrence by punishment delineated above could have appropriately accounted this challenge. The only realistic\n Ibid.\n Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.\n Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n\nRichard Kugler writes that a strategy or general framework for deterrence in cyberspace must necessarily be tailored to differing threats, situations, and objectives. The threats, situations, and objectives in cyberspace differ from the concerns addressed by first wave theorists. While the potential for physical damage through cyberspace has been demonstrated in tests such as the Aurora generator experiment that resulted in the destruction of a multi-ton diesel generator, or the Stuxnet attack that destroyed segments of a centrifuge cascade in Iran’s Natanz nuclear facility, many attacks do not have kinetic parallels. Building on Kugler, Jeffrey Cooper identifies three important factors that frame concepts on deterrence in cyberspace. First, there is a wide range of actors each with different capabilities and attributes as well as cost benefits structures; second, cyberspace is a unique operational domain that carries with vastly different concepts of risk and reward; third, to develop deterrence, models must be applicable to the virtual and physical aspects of the domain.\nThis section has provided a summary of a large and robust literature on deterrence. The concepts that need to be carried forward include, the type of deterrence, the credibility of that deterrence and the attributes of the environment in which deterrence occurs, and who and what actors and weapons are to be deterred. The next section builds on the literature above, with a specific emphasis on the technical, tactical, operational and strategic attributes of cyberspace.\n# 3. ONE SIZE DOESN'T FIT ALL\nTo deter adversaries in cyberspace it is helpful to first define what cyberspace is and what types of actions and actors a state would like to deter. The US Department of Defense defines cyberspace in the following way:\n“Cyberspace consists of many different and often overlapping networks, as well as the nodes (any device or logical location with an Internet protocol address or other analogous identifier) on those networks, and the system data (such as routing tables) that support them. Cyberspace can be described in terms of three\n Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.\n US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.\n Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.\nlayers: physical network, logical network, and cyber-persona. The physical network layer of cyberspace is comprised of the geographic component and the physical network components. It is the medium where the data travel. The logical network layer consists of those elements of the network that are related to one another in a way that is abstracted from the physical network, i.e., the form or relationships are not tied to an individual, specific path, or node. A simple example is any Web site that is hosted on servers in multiple physical locations where all content can be accessed through a single uniform resource locator. The cyber-persona layer represents yet a higher level of abstraction of the logical network in cyberspace; it uses the rules that apply in the logical network layer to develop a digital representation of an individual or entity identity in cyberspace. The cyber-persona layer consists of the people actually on the network\".36\nThe inclusion of the full definition illustrates the complexity within which defense strategists and operators in the various services engage. Because the domain spans the physical, logical, and persona layers, deterrence strategies can reasonably occur within and across all three. This fundamentally differs from the conceptualization of deterrence in physical domains of land, sea, air, and space. Physical domain deterrence might include physical and cognitive aspects analogous to the cyber persona and physical network layers, however, the logical layer is wholly absent. The cyber persona layer also diverges significantly from personas within the physical domain as individuals and states have the capacity to alter their attributes within the persona, logical, and network layers.\nTo construct a meaningful model of deterrence in cyberspace we must first ask what it is we wish to deter. Herein lies the largest distinction between deterrence in the physical world and in cyberspace. Whereas in the physical world deterrence is directed most commonly against physical attacks against specific assets or categories of assets that when attacked provide strong, largely non-repudiable forms of attribution, in cyberspace deterrence is directed against manipulations of the elements within the environment and the environment itself. Manipulation of elements of cyberspace and the environment itself can be examined in multiple ways. Simplifying cyberspace operations into three broad categories, there are cyber attacks, cyber espionage, and cyber theft. Despite simplification, it is important to note these categories are not entirely discrete in process or function. Cyber attacks are those acts in cyberspace that degrade, deny or destroy. Acts of cyber espionage steal information for state or corporate intelligence gain. Cyber theft is the stealing of information for financial gain with no direct state utility. Attacks, espionage, and theft occur across all levels\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\nof actors from script kiddies to the military units of states – a problem which will be examined more below. States are most commonly concerned with cyber attacks and espionage at the national level, and theft at lower-jurisdictions.\nBecause attacks, espionage, and theft are perpetrated by a variety of actors against almost any target in cyberspace, sending an overt signal from one state to another, while still applicable, might not deter attacks at other levels that are of equal or greater significance. Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy$^{37}$ usage by states to maintain plausible deniability.$^{38}$ Using proxies to engage in cyber acts against targets deflects deterrence by threats of punishment unless sufficient evidence is present to indicate involvement by the instigating state rather than the third-party proxy. The use of proxies to engage in attacks, espionage and theft against target states outside of cyberspace has been the practice of states since Katulaya and Sun Tzu.$^{39}$ However, unlike the difficulties of non-repudiability within conventional conflicts, cyber attacks are frequently repudiable. Attackers might use Virtual Private Networks (VPNs), proxies or other means by which to engage in an attack.\nAdditional problems in cyberspace not frequently encountered in conventional physical domains are second and third order effects. As noted by Herbert Lin, the results of a cyber attack itself might not be identifiable, rather it is second or third order effects that generate an intended outcome.$^{40}$ Classical deterrence and tailored deterrence strategies used against terrorist organizations are unable to account for disconnected action and reaction pairs commonly found in cyberspace. The time to punish a violation can be weeks, months or years based on discovery and attribution challenges, a problem not present in classical deterrence.\nCyber attacks are incidents occurring in or through cyberspace that degrade, deny or destroy. Attacks in cyberspace can and are perpetrated by all levels of actors. The differentiation between actors is most closely correlated with targets and outcomes of attacks.$^{41}$ For example, criminal actors may use phishing attacks to ingress into a hospital's computer systems to install Cryptolocker or a similar ransomware malware on the hospital's systems. Cryptolocker is an attack that degrades civilian critical infrastructure, denies user access and has the potential to destroy critical\n\nMost scholars and practitioners are likely to contend that it is not the responsibility of the state to deter non-state actors (excepting terrorists), particularly criminals from cyber attacks against non-federal infrastructure outside of a criminological framework.43 Yet, the same tool used by a criminal is available to the state and presents the same challenges associated with attribution irrespective of the perpetrator. What actions could a state undertake to deter an adversary state actor from engaging in this behavior and would these actions have a measurable effect on non-state actors as well?\nExamples of cyber attacks abound and include the destruction, denial or degradation of military or civilian communications platforms. Attacks such as the Mirai (malware) botnet attack in 2016 are capable of being directed at both critical and non-critical infrastructure by both state and non-state actors. A botnet using Mirai was able to generate in excess of 1Tbps of traffic and degrade dozens of websites in the United States on 20 September 2016.44 This same form of attack could be directed towards IP addresses of the FAA and emergency service providers or any number of Internet-enabled systems found on Shodan.io or similar services.45\nAlthough DDoS attacks are generally considered to be among the least complicated forms of cyber attacks they still challenge state and sub-state entities both public and private. DDoS attacks have been used against US government infrastructure, against Estonia in 2007 and the Republic of Georgia in 2008.46 To date, DDoS attacks against the US government or critical infrastructure have received little attention in discussions on deterrence in cyberspace. On 21 January 2016 a grand jury in the Southern District of New York indicted 7 Iranian Hackers in absentia for their involvement in DDoS\n\nBeyond DDoS attacks, Russian attacks against Ukrainian electric infrastructure and US political organizations also resulted in no or weak responses that offer no indication that deterrence is making headway in cyberspace. In response to massive influence operations perpetrated by the Russian Federation against the United States and its two major political parties during the 2016 Presidential election the United States expelled 35 suspected Russian intelligence operatives and placed sanctions on Russia’s two leading intelligence services, the FSB and the GRU. The US response imposed insignificant costs in comparison to the utility achieved by the Russian Federation.\nThe latter case of Russian influence and hacking during the 2016 election cycle provides a case study for why deterrence by threat in cyberspace is so difficult to achieve. The first indications of Russian interference in the 2016 election were identified by the FBI in September 2015 more than a year before the election. The FBI phoned the DNC to try and alert them to a potential attack, but the call was not considered credible and was subsequently ignored by DNC staffers. The progression of hacking attempts against the DNC continued and President Obama was notified in the summer of 2016. Moreover, the “attack” against the DNC was not an attack, but espionage or theft and therefore falls outside conventionally defined deterrence frameworks. Yet the impact of the espionage and the later release of private DNC emails was substantial as indicated in a declassified report by the Office of the Director of National Intelligence (ODNI). The report assessed that information warfare conducted following the espionage campaign substantially degraded the DNC and engendered a loss of confidence in the US electoral system. Cyber deterrence has fundamental problems including the realization that the most valuable assets in cyberspace might not be destroyed or degraded, but rather stolen and used.\n US Federal Bureau of Investigation. 2016. “Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion”. https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n Ibid.\n US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n Ibid.\n\nDeterrence by threat within cyberspace is realistically only applicable to cyber operations that result in direct physical effects that are non-repudiable and attributed quickly. Using formal modeling in the Decision to Attack: Military and Intelligence Cyber Decision-making I found that most cyber attacks, with the notable exception of DDoS, operate under varying conditions of anonymity. The anonymity associated with attacks is usually necessary for attacks to be successful in bypassing deterrence by denial frameworks found in the perimeter defenses of networks such as intrusion detection and prevention systems found in the logical or physical network layers of cyberspace. Threats of punishment could impact the persona layer of cyberspace as well, but as will be examined below there are some fundamental challenges unique to cyberspace posed by anonymity.\n## 4. TECHNICAL CHALLENGES: THREATS OF PUNISHMENT WITHIN DOMAIN\nPunishing an adversary in cyberspace is not cheap or fast outside of pre-established botnets or damage done to physical infrastructure. Punishment in or across any of the layers cyberspace requires what the US Department of the Army refers to as intelligence preparation of the battlefield (IPB):\n“IPB is a systemic, continuous process of analyzing the threat and environment in a specific geographic area. It is designed to support staff estimates and military decision making”.\n Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.\nIn response to a nuclear attack on a city in the US, the proportional response would be a counter attack on an adversary city. The city itself is geographically fixed and immovable both logically and physically. Threatening in-kind retaliation is both plausible and technically feasible with ballistic missiles or air assets. The same logic does not hold in cyberspace.\nWhy are in kind retaliations or other forms of punishment not viable solutions for most retaliations in cyberspace? First, a state must fulfill the burden of proof in identifying the perpetrator of an action. All the above IPB and potential for retaliation still depends upon attribution of who, what, and potentially why an attack occurred.59 Retaliation absent strong evidence is likely to lead to misidentification and unnecessary escalation.\nSecond, a state must retaliate within a proximate temporal range. If state X does not have detailed intelligence on the asset it wishes to retaliate against, developing intelligence along with a cyber weapon to target it increases the time horizon of response such that it is days, weeks, months or even years out from the original attack for which it is retaliating. Due to this temporal disconnect, the threat to punish in response to a given action falls into a category of what economists refer to as hyperbolic discounting. The risk of punishment for an attack is possible but so temporally, distant as to be discounted to the point of irrelevance.\nThird, deterrence by punishment requires proportionality. It is necessary to have comparable assets to punish to prevent escalation or violations of international law.60 Comparable assets are not a given within cyberspace and are often difficult to identify.61 To punish an asset within a domain requires pre-established access or knowledge of that asset beyond its location. Whereas a city is immovable and likely to be as susceptible today as it will be tomorrow to a missile or bomb, a computer system that is penetrated today for prepositioned access, might be patched, upgraded or taken offline tomorrow.\nFourth, a state must possess a specific cyber weapon system tailored to its target. If state X alerts state Y that it is going to punish an asset or state X uses a repeated cyber weapon to attack state Y’s system, it is likely to be ineffectual the longer it is used due to updated perimeter defenses, such as intrusion detection and prevention systems (IDPS), antivirus programs or a variety of other security measures. If state X wants to punish state Y it must have knowledge of the attributes of the asset it wishes to retaliate against and what the status of that asset is. State X must also develop new exploits to achieve effects or be confident that State Y has not accounted for previous exploits that have been used.\n\nThe challenges of signaling deterrence by punishment are numerous within cyberspace whether the conflict is contained within domain or crosses over domains. Advances in attribution within a timely manner and the availability and reasonable assumption that proportional assets of an adversary can be held at risk need to be improved to credibly threaten punishment. This is a challenge not isolated to within domain retaliation. While proportional target selection might be slightly easier in cross-domain retaliation, the first three issues raised above are still relevant.\nDeterrence by punishment in cyberspace is possible, but it is not a reliable or credible option under most conditions absent sufficient and sustained intelligence. This assessment is not unique and is borne out in the analysis of Valeriano and Maness, who find that deterrence via punishment is generally ineffective and likely more dangerous than other means of preventing attacks.[62] Moreover, sustained invasive intelligence into adversary networks creates its own unique problems, including a security dilemma.[63] The more states engage in highly invasive intelligence via cyberspace, the more their actions are likely to be misinterpreted. Differentiating between various forms of cyber actions are difficult and can lead to miscalculation.[64]\nFigure 1 illustrates the relationship between attacking and defending forces and area where both forms of deterrence function.\n\nAs seen in Figure 1, deterrence by threat of punishment and denial operate within the same temporal ranges, yet while attribution matters a great deal for threats of punishment they are generally unimportant for denial. In their initial stages both denial and punishment focus on ante-impetum means of dissuasion, yet deterrence by punishment necessarily needs post-impetum attribution for it to be used. Based on the technical realities of cyberspace and of international relations deterrence by threat of punishment is more complicated and difficult to effectively establish.\n# 5. TECHNICAL CHALLENGES AND OPPORTUNITIES: DETERRENCE BY DENIAL\nBoth deterrence by denial and punishment require ante-impetum costs by the defender. The allocation of resources between denial and deterrence and the efficiency with which they deter adversaries differ. The establishment of credible deterrence by denial often starts with the allocation of financial capital to purchase technical resources and provide human capital sufficient to continually update, enhance, audit and manage complex network infrastructure.[65] Network-based and host-based defenses such as intrusion detection and prevention systems, anti-virus products and similar systems are some of the variety of overlapping expenditures that can be undertaken to increasingly make the intrusion of adversaries into a given network more difficult.[66]\nIn cyberspace, such expenditures are regularized and often included as overhead costs, however they are deterrent in nature.[67] Although they are not glamorous, they substantially decrease the probability of penetration. The same types of deterrence strategies are used by stores in placing electronic tracking tags on their products and detectors at doors, by banks in the construction of vaults, silent alarms and dyed packets of money, by critical infrastructure in extending the perimeter of security outward to prevent vehicle-borne improvised explosive devices, increased numbers of security guards, cameras and the use of razor wire or other physical structures. These devices signal to adversaries both criminal and terrorist alike that the costs of successfully perpetrating an attack are high and that the likelihood of success is low, although both terrorist and criminal deterrence models include deterrence by punishment through criminal proceedings and potential lethal actions against terrorist they rely far more heavily on preventive measures that deny would be adversaries.\nSceptics might contend denial mechanisms are unlikely to deter a state, yet this is in and of itself not accurate. The vast majority of probes by states do not translate into successfully attacks. The US Department of Defense suffers from millions of probes\n[65] Riggs, Cliff. (2004). *Network Perimeter Security*. New York: Auerbach Publications.\n[66] Buecher, Axel, Per Andreas, and Scott Paisley. 2009. “Understanding IT Perimeter Security”. IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n[67] Filkins, Barbara. 2016. “IT Security Spending Trends”. SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n\nUnlike in any other battlespace, whether conventional kinetic terrorism, conventional kinetic or mass destruction military force, the opportunities for deterrence by denial are substantial in cyberspace and unique. While denial opportunities in land, sea, air, and even space are predicated on the control of a given geospatial area, the party establishing deterrence by denial has limited abilities to manipulate the nature of the domain itself. The same is not true within cyberspace. Every aspect of a defender’s cyberspace from the structure of the network, to the hardware, firmware, and software within a network, to the access of individuals within and external to that network is manipulable. At every stage of an attack an adversary is always attempting to operate on or against the defender’s cyberspace over which it has no control and has limited visibility.\nFor denial, the historical literature of deterrence theory remains relevant, in particular the second and third stages of deterrence which focused on rational game theoretic and cognitive modeling. While in conventional deterrence the emphasis was on punishment, here these same modeling techniques find applicability in deterrence by denial. Although the games might be the same, the payoffs in cyberspace manipulable and favor the defender. In few other applications of deterrence are the payoff matrices of deterrence so favorable to the defender. Despite the favorability of conditions, the ability to manipulate the potential payoff for attackers remains difficult. Although possible for defenders to reduce the probability of attack success, the potential payoff for a successful attack can remain large.\nDespite conditions favoring defenders, the potential payoffs are often not affected by deterrence by denial. Minimizing the potential payoffs from attacks on data repositories requires disaggregation of data. These types of denial mechanisms come with efficiency or financial costs. Although denial offers more potential than punishment, it is not a silver bullet to the cyber deterrence problem. Denial decreases the probability of success for attackers and is likely to reduce classes of actors focused on certain targets. Despite efforts to signal through the purchase and implementation of various defensive measures, the re-architecting of network infrastructure, the cyber deterrence problem remains.\n Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\n# 6. BEYOND THE DETERRENCE PROBLEM\nIf punishment and denial are unable to fully remediate the cyber deterrence problem, are there any meaningful solutions? The core debate remains, with no simple and readily apparent solutions. The search for a single solution is likely to remain fruitless for the foreseeable future. Deterrence has never been the single tool within the toolbox of the state to dissuade or shape adversary behavior. Rather, it has always been combined with efforts that extend beyond traditional concepts of deterrence to include geopolitical and technical practices including norm development, entanglement, cumulative deterrence, research and development, policies and laws, liability structures for software and hardware, training for users and human capital development within information technology and cybersecurity.\nEfficient and effective cyber deterrence should extend international politics and include fields such as criminology, immunology and public health. The capacity of states to punish criminals is high and the credibility of punishment actions in developed nations is strong. Despite a capacity to punish criminal behaviors, they still occur. Extending beyond punishment, states also focus on denying criminals opportunities to commit crimes. Yet crime still occurs. The root causes of crime are not simple nor isolatable to a single phenomenon. Likewise, states engage one another in cyberspace for a variety of reasons. Some reasons fit within conventional deterrence frameworks of denial and punishment and do not suffer from challenges with attribution. For instance, larger and more harmful attacks increase the probability of attribution. However, many states remain perturbed by the death by a thousand cuts phenomena which falls below thresholds and required to provide timely attribution.\nShifting the focus away from within domain deterrence focused solely on punishment and denial and changing the emphasis to a basket of strategies focused on reducing incentives, availability and anonymity fosters an environment less conducive both to hostile actions and potential malicious actors. The solution to the deterrence problem is not abandoning it, but expanding the range of alternative strategies not presently considered. By acknowledging the failures and inadequacies of deterrence strategies and the potential places where novel strategies found in other fields are applicable the intractable problem of cyber deterrence becomes more manageable.\n Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.\n Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n49"
    },
    "numeric": {
      "total": {
        "intext_total": 7,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "23",
          "intext_citation": "[23]",
          "preceding_text": "more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".",
          "footnote": null
        },
        {
          "index": "24",
          "intext_citation": "[24]",
          "preceding_text": "nd yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework.",
          "footnote": null
        },
        {
          "index": "25",
          "intext_citation": "[25]",
          "preceding_text": "This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs.",
          "footnote": null
        },
        {
          "index": "26",
          "intext_citation": "[26]",
          "preceding_text": "First, he notes that deterrence often relies on the attribution of an adversary's actions.",
          "footnote": null
        },
        {
          "index": "27",
          "intext_citation": "[27]",
          "preceding_text": "First, he notes that deterrence often relies on the attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.",
          "footnote": null
        },
        {
          "index": "28",
          "intext_citation": "[28]",
          "preceding_text": "he attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.[27] Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty.",
          "footnote": null
        },
        {
          "index": "29",
          "intext_citation": "[29]",
          "preceding_text": "Moreover, the ability to respond within domain simply might not be possible within certain conditions.",
          "footnote": null
        }
      ],
      "flat_text": "2018 10th International Conference on Cyber Conflict\nCyCon X: Maximising Effects\nT. Minárik, R. Jakschis, L. Lindström (Eds.)\n2018 © NATO CCD COE Publications, Tallinn\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# The Cyber Deterrence Problem\nAaron F. Brantly\nAssistant Professor, Department of Political Science\nVirginia Polytechnic and State University\nUnited States\nabrantly@vt.edu\nAbstract: What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.\nKeywords: cyber, deterrence, denial, punishment\n# 1. INTRODUCTION\nThe challenge of the digital era is not to define deterrence. Deterrence is a well-defined concept that has been studied and practiced throughout history and to an even greater depth following the advent of nuclear weapons. The present challenge it is to understand the role digital technologies play in the broader scope of interstate deterrence. Deterrence in one domain rarely if ever operates independently of other domains. Much of the literature on cyber deterrence focuses on within domain deterrence. Yet, this is a dangerous constraint that elevates risks and minimizes the probability of success. This paper seeks to draw out the literature on deterrence and identify its applicability within a newly delineated domain of interactions, cyberspace. The resultant analysis strives to encompass the complexity of deterrence and advance an argument beyond within domain modeling.\n31\nClassical deterrence centers on a potential adversary's cost-benefit calculus to dissuade specific actions and differs from compellence by focusing on ex-ante behavior manipulation through a priori uses of force or other tools of state power. Both compellence and deterrence are forms of coercion, however, the former employs both hard and soft power both in the present and future with continued or escalated actions, while the latter threatens use of force (power) absent their employment. The focus below is on ex-ante actions by states and sub-state entities that threaten, but that do not use the tools of state against an adversary to manipulate their decision-making calculus. Additionally, actions undertaken independent of threats that can, ex-ante, reduce the benefits associated with a given attack are examined.\nFocusing on classical deterrence and deterrence by denial helps illustrate the similarities and differences between deterrence in the pre- and post-delineation of cyberspace as a domain of military operations. Deterrence in cyberspace has been addressed by a variety of scholars across the subfields of International Relations.¹ Many examinations of cyber deterrence rely on direct applications of IR theory absent robust technical understandings of how the domain functions. The development and application of classical deterrence theories to a domain necessarily requires an understanding of how state and non-state actors achieve, develop, and assess costs and benefits within this domain.\nThis work proceeds in three sections. First, it examines some of the relevant literature on deterrence and identifies some of the gaps within the field and provides a trajectory for the subsequent sections to examine a more dynamic theory of deterrence in cyberspace. The second section focuses on the technical, tactical, operational, and strategic aspects of the domain in an effort to identify those areas where deterrence can alter the costs-benefit analysis of adversaries. Third, the work concludes by providing a discussion on national strategy development for integrated cyber deterrence incorporating the lessons from the first two sections.\n## 2. FROM ATOMS TO BITS AND BYTES\nDeterrence is not a novel concept. The classical IR cannon on deterrence can be traced back to the Peloponnesian War and the threat of violence in response to adversary actions.² Yet, more modern formulations of deterrence are largely rooted in the nuclear world following World War 2. The most common form of deterrence known as conventional deterrence was established by Bernard Brodie, Thomas Schelling and\n¹ Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n² Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\nothers and focuses on the ex-ante dissuasion of adversaries through the threat of ex-post costs in response to potential adversary actions.\nRobert Jervis identified three “waves” of deterrence theorizing to which a potential fourth wave has been added by Jeffery Knopf.³ First wave deterrence theory rested on the rise and consequences of nuclear weapons. Bernard Brodie et al. asserted that the use of nuclear weapons had almost no innate strategic or tactical value outside of being a threat against an adversary.⁴ The consequences of nuclear weapons use, even in limited strike situations, would quickly and dramatically escalate. This escalation made the limited use of such weapons untenable in all but the most extreme situations. Lawrence Freedman summarized the second wave as the realization that “total war could now only be threatened, but never fought”.⁵\nSecond wave deterrence posited how nuclear weapons could be threatened and the dynamics of those threats.⁶ Thomas Schelling and others posited a series of conditions in which states could develop deterrence in the nuclear era. As Jervis noted, second wave theorizing became extremely popular because of its abstraction and logical structuring.⁷ Game theory and other rational models were used to illustrate rational costs and benefits, creating models suited to rigorous concepts of rationality.⁸ The second wave arose under stable bi-polar conditions in which it was assumed states engaged in rational decision-making in matters of foreign policy and national security. Schelling found deterrence largely dependent upon credibility and rationality. He illustrated that signaling potential costs to an adversary absent credibility creates deterrence failure. By using divergent game-theoretic structures from prisoner’s dilemma to chicken – theorists developed arguments about deterrence. Despite rigorous theory, this abstraction contained systemic flaws and gave rise to a third wave of deterrence.\nThe third wave of deterrence theory in the 1970s addressed challenges beyond game theoretic models, including the failing rationality. Irving Janis and Graham Allison, both, but with different perspectives, illustrated the weaknesses of rationality in decision-making.⁹ The third wave led to extensions into cognitive psychology and behavioral studies. Robert Jervis, Richard Ned Lebow, and Janis Stein provided insight into the general problems associated with parsimonious use of rationality through case analyses. Specifically, Jervis et al. identified the potential for over-valuation of\n³ Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.\n⁴ Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.\n⁵ Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.\n⁶ Ibid: 22.\n⁷ Jervis. Review: 291-292.\n⁸ Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.\n⁹ Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n33\ncertain attributes of classic deterrence that might inadvertently make conflict more and not less likely.¹⁰\nJeffrey Berejikian incorporated Daniel Kahneman and Amos Tversky’s analysis of prospect theory into the deterrence calculus and challenged parsimonious rational thought by illustrating cognitive dimensions associated with decision-making beyond groupthink and bureaucratic processes. His work highlighted issues related to risk in cognitive decision-making that undermine rationality. Concepts such as sunk costs or tying hands fit well within parsimonious deterrence theory, yet the mechanisms that made them effective were not well understood prior to the third wave.\nAlthough modern deterrence theory encompasses a spectrum from pure rational modeling to cognitive models, the objective of deterrence as identified by John Mearsheimer remains the development of fear of the consequences (in particular of “military action”) or a “function of costs and risks”.¹¹ Developing shared knowledge about costs and risks for nuclear events differs from non-nuclear conflicts. Early deterrence models relied heavily on rationality and parsimony but did not underestimate the clarity provided by the use and subsequent impact of the weapons themselves. The generation of fear or knowledge of consequences to assess costs and risks loses clarity the as analyses shift away from nuclear weapons. Lawrence Freedman defines single weapon or type of warfare deterrence as “narrow deterrence”.¹² Narrow deterrence is less effective when expanded beyond single weapon or type warfare.\nGeneral or broad deterrence covers a range threatened actions to dissuade an adversary. Freedman writes: “broad deterrence involves deterring all war”.¹³ Ted Hopf explains: within deterrence there is a need to expand deterrence beyond the scope of military tools to the entire range of options available to actors.¹⁴ Extending analysis further, scholars also emphasize concepts of direct deterrence and extended deterrence. Direct deterrence is concerned with actions against “your” state and its immediate interests as opposed to extended deterrence – dissuasion of adversary actions against a third party or non-immediate interests. Delineating between these two types of deterrence in a globalized world is difficult. Cyberspace compounds the challenge of delineation because attacks on foreign infrastructure can and do have ramifications globally.\nConcepts of the means to achieve deterrence or more simply how to deter are often contested. Threats can be narrowed to weapon type or category, or include\n¹⁰ Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n¹¹ Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.\n¹² Freedman. 2004.\n¹³ Ibid.\n¹⁴ Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n34\ninterdependent relationships such as diplomatic, informational, military and economic effects. Threats signaling a potential response to adversary action should provide clear, unambiguous consequences. The ex-ante threat should causally lead to an ex-post consequence; punishment.\nOften left out of traditional international relations literature, deterrence by denial has seen a surge of interest in the years following the 9/11 terrorist attacks. Alex Wilner defines deterrence by denial as “reducing the perceived benefits an action is expected to provide a challenger”.¹⁵ Deterrence by denial in the physical world often includes hardening targets by building higher walls, adding security mechanisms, or other tactics to reduce the susceptibility of targets to attack. If the Strategic Defense Initiative (SDI – also known as Star Wars) had been successful, it would have been a deterrence by denial strategy to limit the effect of Soviet nuclear weapons. Commonly used forms of deterrence by denial in conflict zones include land mines, razor wire, surface to air missiles (SAMs) and fortifications.\nDeterrence by punishment and denial are intended to manipulate the cost-benefit analysis of an adversary. To function they must both be credible. Credibility requires undertaking ex-ante costs by the deterrer. Threats absent ante impetum costs lack credibility. A state without nuclear weapons cannot credibly threaten nuclear retaliation. If a state wishes to deter it must provide demonstrable evidence that it is able to carry out its threat.\nLikewise, deterrence by denial fails when it lacks the material capabilities to deny. The Maginot Line built by the French following World War I stands an example of failed deterrence by denial. The French system of fortifications on portions of their northern territory failed because the line itself only covered one vector of attack into France. The elevation of costs to a potential attacker must be complete and provide no reasonable alternatives to achieve the attacker’s intended utility. Both strategies require ex-ante costs by the defender to alter the ex-post perceived benefits of an attacker. Punishment strategies increase adversary costs after a violation and denial strategies increases adversary costs in advance of a violation.\nDeterrence by denial is a successful strategy in many instances; SAMs effectively deter enemy aircraft. The relative costs of upgrading certain denial tools is comparatively less than the costs of surmounting them. In the case of SAMs, the United States spent billions of dollars to defeat the S-300 missile system (~$100 million/system).¹⁶ Following the development and use of stealth, S-300 designer Almaz upgraded its\n¹⁵ Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.\n¹⁶ Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n35\nsystems to the S-400 variant with greater accuracy and anti-stealth technology.¹⁷ The cost ratio between the denial tool and offensive weapon system is approximately 1 to 1,000. The defensive and offensive capabilities, industrial, and financial resources of these two states exceed most other nations. Even with a $18.5 trillion GDP a $1 to $1,000 cost to benefit ratio is high and demonstrates how denial can be a remarkably effective strategy.\nDeterrence by denial is not always successful as illustrated by the Israel – Hamas conflict. In response to Hamas’ use of Katyusha rockets, Israel developed the Iron Dome System. Iron Dome batteries cost $100 million and each rocket costs $50,000.¹⁸ To intercept an incoming Katyusha rocket, the Israelis launch 2 interceptor rockets.¹⁹ By contrast, Hamas spends between $500 and $1,000 per rocket launch.²⁰ If the cost of the battery is ignored, the cost of deterrence by denial is still between 100 to 1 and 200 to 1.\nDenial strategies are not passive. They require continuous modification relative to adversary capability development. Static denial strategies in cyberspace or in conventional conflict are likely to have limited credibility over time. Similarly, punishment strategies also require constant updating in relation to adversary capabilities and geopolitical considerations. In cyberspace, this involves adapting denial strategies to technological advances such as artificial intelligence, polymorphic malware and the Internet of Things, to name just a few.\nPunishment strategies also require ex-ante costs. Below the nuclear threshold, threats of force are common, yet the credibility of these threats is difficult to establish. Alexander George and Richard Smoke identify three attributes important for signaling in conventional deterrence: “(1) the full formulation of one’s intent to protect a nation; (2) the acquisition and deployment of capacities to back up that intent; (3) the communication of intent to a potential aggressor”.²¹ These three aspects are also at times limited in their ability to convey commitment to fulfill the intent.²²\nCharles Glaser, writing on cyber deterrence, established four components of basic deterrence:\n¹⁷ Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n¹⁸ Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n¹⁹ Ibid.\n²⁰ Ibid.\n²¹ George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.\n²² Ibid: 558.\n\"1) the benefits of taking the action—the larger the benefits, the harder the adversary is to deter; 2) the probability of achieving the benefits—the higher the probability, the harder the adversary is to deter; 3) the costs the defender will impose if the adversary takes the action—the higher the costs, the more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".\nGeorge and Smoke and Glaser acknowledge the challenge of establishing not just threats of punishment, but the credibility associated with carrying out that threat.\nCreating material capability (i.e. weapon systems capable of carrying out a given threat) and clear signaling might occur and yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework. Credibility and hand-tying are most closely associated with extended deterrence, yet when expanding deterrence to cyberspace it also finds relevance. The establishment of credibility through hand-tying establishes a forcing mechanism for decisions, indicating costs have already been incurred or are likely to occur. This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs. An attack on West Berlin would have resulted in sunk costs and provided a strong inducement or \"tripwire\" to actuate US retaliatory threats. Nearly all forms of kinetic attacks against the direct interests of a nation implicitly include hand-tying. It is unclear how to effectively signal prospective costs within cyberspace to an adversary.\nCharles Glaser identifies several problems associated with deterrence by punishment specific to cyberspace that extend beyond basic credibility issues. First, he notes that deterrence often relies on the attribution of an adversary's actions. In cyberspace, this can be difficult and time-consuming. Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty. Second, hands-tying and other forms of credibility enhancing measures are likely lacking in cyberspace. Moreover, the ability to respond within domain simply might not be possible within certain conditions. Third, Glaser identifies potential spillovers\n23 Glaser, Charles. 2011. \"Deterrence of Cyber-attacks and US National Security\". GW-CSPRI-2011-5. Washington, DC: Cyber Security Policy and Research Institute: 2.\n24 Fearon, James D. 1997. \"Signaling Foreign Policy Interests\". Journal of Conflict Resolution 41(1): 69–90.\n25 Kydd, Andrew H, and Roseanne W McManus. 2017. \"Threats and Assurances in Crisis Bargaining\". Journal of Conflict Resolution 61(2).\n26 Glaser. 2011: 3.\n27 Ibid.\n28 Rid, Thomas and Ben Buchanan. 2015. \"Attributing Cyber Attacks\". Journal of Strategic Studies 38(1-2): 4–37.\n29 Ibid.\n37\nin which limited within domain options result in cross-domain, kinetic responses.³⁰ To date there is limited evidence of cross-domain responses and therefore lacks in credibility. Moreover, cross-domain retaliation alters the escalation framework from digital to kinetic or other and poses a challenge for states wishing to establish credibility while controlling potential escalatory behaviors.\nDeterrence is more than simply threatening punishment. Deterrence requires substantial target relevant costs and the development of mechanisms to establish that further costs are credibly wagered to provide clarity for an adversary. The goal of this clarity is to establish within an adversary’s calculus that their expected gains are less than any potential losses incurred. Reassessments of rational modeling and the increasing importance of cognitive modeling increase the value of tailored deterrence strategies predicated on the uniqueness of conditions and actors. Paul notes that deterrence is complex and is most logically broken down into five ideal types:\n“(1) deterrence among great powers; (2) deterrence among new nuclear states; (3) deterrence and extended deterrence involving great powers and regional powers armed with chemical, biological and nuclear weapons; (4) deterrence between nuclear states and non-state actors (5) deterrence by collective actors”.³¹\nIt follows that tailored deterrence for cyber actors is also one potential avenue of exploration.\nThe potential for tailored deterrence strategies could be highlighted in numerous significant cyber incident cases. The 1998 cyber attack code-named SOLAR SUNRISE discovered by US Air Force Computer Emergency Response Team (AFCERT) stands as a prime example. The three-week hack affected more than 500 systems across the US Air Force, Navy, NASA, Lawrence Livermore Labs, MIT, Harvard, and UC Berkeley. The attack coincided with increased tensions between the United States and Iraq and resulted in high-level governmental meetings to identify a proper response action.³² At the time, the attack was believed to be state-sponsored cyber attack focused on degrading US military capabilities. Subsequently, it was discovered that the attack was conducted by two California teenagers with guidance from Israeli hacker Ehud Tenebaum. The incident is relevant to tailored deterrence because it highlights challenges faced in developing a deterrence strategy. The adversaries were domestic, yet foreign inspired and attacked the operational infrastructure of the Department of Defense. No form of deterrence by punishment delineated above could have appropriately accounted this challenge. The only realistic\n³⁰ Ibid.\n³¹ Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.\n³² Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n38\ndeterrence frameworks for SOLAR SUNRISE would have been deterrence by denial or punishment in cooperation with allies.\nRichard Kugler writes that a strategy or general framework for deterrence in cyberspace must necessarily be tailored to differing threats, situations, and objectives.³³ The threats, situations, and objectives in cyberspace differ from the concerns addressed by first wave theorists. While the potential for physical damage through cyberspace has been demonstrated in tests such as the Aurora generator experiment that resulted in the destruction of a multi-ton diesel generator, or the Stuxnet attack that destroyed segments of a centrifuge cascade in Iran’s Natanz nuclear facility, many attacks do not have kinetic parallels.³⁴ Building on Kugler, Jeffrey Cooper identifies three important factors that frame concepts on deterrence in cyberspace. First, there is a wide range of actors each with different capabilities and attributes as well as cost benefits structures; second, cyberspace is a unique operational domain that carries with vastly different concepts of risk and reward; third, to develop deterrence, models must be applicable to the virtual and physical aspects of the domain.³⁵\nThis section has provided a summary of a large and robust literature on deterrence. The concepts that need to be carried forward include, the type of deterrence, the credibility of that deterrence and the attributes of the environment in which deterrence occurs, and who and what actors and weapons are to be deterred. The next section builds on the literature above, with a specific emphasis on the technical, tactical, operational and strategic attributes of cyberspace.\n# 3. ONE SIZE DOESN'T FIT ALL\nTo deter adversaries in cyberspace it is helpful to first define what cyberspace is and what types of actions and actors a state would like to deter. The US Department of Defense defines cyberspace in the following way:\n“Cyberspace consists of many different and often overlapping networks, as well as the nodes (any device or logical location with an Internet protocol address or other analogous identifier) on those networks, and the system data (such as routing tables) that support them. Cyberspace can be described in terms of three\n³³ Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.\n³⁴ US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.\n³⁵ Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.\nlayers: physical network, logical network, and cyber-persona. The physical network layer of cyberspace is comprised of the geographic component and the physical network components. It is the medium where the data travel. The logical network layer consists of those elements of the network that are related to one another in a way that is abstracted from the physical network, i.e., the form or relationships are not tied to an individual, specific path, or node. A simple example is any Web site that is hosted on servers in multiple physical locations where all content can be accessed through a single uniform resource locator. The cyber-persona layer represents yet a higher level of abstraction of the logical network in cyberspace; it uses the rules that apply in the logical network layer to develop a digital representation of an individual or entity identity in cyberspace. The cyber-persona layer consists of the people actually on the network\".36\nThe inclusion of the full definition illustrates the complexity within which defense strategists and operators in the various services engage. Because the domain spans the physical, logical, and persona layers, deterrence strategies can reasonably occur within and across all three. This fundamentally differs from the conceptualization of deterrence in physical domains of land, sea, air, and space. Physical domain deterrence might include physical and cognitive aspects analogous to the cyber persona and physical network layers, however, the logical layer is wholly absent. The cyber persona layer also diverges significantly from personas within the physical domain as individuals and states have the capacity to alter their attributes within the persona, logical, and network layers.\nTo construct a meaningful model of deterrence in cyberspace we must first ask what it is we wish to deter. Herein lies the largest distinction between deterrence in the physical world and in cyberspace. Whereas in the physical world deterrence is directed most commonly against physical attacks against specific assets or categories of assets that when attacked provide strong, largely non-repudiable forms of attribution, in cyberspace deterrence is directed against manipulations of the elements within the environment and the environment itself. Manipulation of elements of cyberspace and the environment itself can be examined in multiple ways. Simplifying cyberspace operations into three broad categories, there are cyber attacks, cyber espionage, and cyber theft. Despite simplification, it is important to note these categories are not entirely discrete in process or function. Cyber attacks are those acts in cyberspace that degrade, deny or destroy. Acts of cyber espionage steal information for state or corporate intelligence gain. Cyber theft is the stealing of information for financial gain with no direct state utility. Attacks, espionage, and theft occur across all levels\nUS Department of Defense. 2013. \"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\nof actors from script kiddies to the military units of states – a problem which will be examined more below. States are most commonly concerned with cyber attacks and espionage at the national level, and theft at lower-jurisdictions.\nBecause attacks, espionage, and theft are perpetrated by a variety of actors against almost any target in cyberspace, sending an overt signal from one state to another, while still applicable, might not deter attacks at other levels that are of equal or greater significance. Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy$^{37}$ usage by states to maintain plausible deniability.$^{38}$ Using proxies to engage in cyber acts against targets deflects deterrence by threats of punishment unless sufficient evidence is present to indicate involvement by the instigating state rather than the third-party proxy. The use of proxies to engage in attacks, espionage and theft against target states outside of cyberspace has been the practice of states since Katulaya and Sun Tzu.$^{39}$ However, unlike the difficulties of non-repudiability within conventional conflicts, cyber attacks are frequently repudiable. Attackers might use Virtual Private Networks (VPNs), proxies or other means by which to engage in an attack.\nAdditional problems in cyberspace not frequently encountered in conventional physical domains are second and third order effects. As noted by Herbert Lin, the results of a cyber attack itself might not be identifiable, rather it is second or third order effects that generate an intended outcome.$^{40}$ Classical deterrence and tailored deterrence strategies used against terrorist organizations are unable to account for disconnected action and reaction pairs commonly found in cyberspace. The time to punish a violation can be weeks, months or years based on discovery and attribution challenges, a problem not present in classical deterrence.\nCyber attacks are incidents occurring in or through cyberspace that degrade, deny or destroy. Attacks in cyberspace can and are perpetrated by all levels of actors. The differentiation between actors is most closely correlated with targets and outcomes of attacks.$^{41}$ For example, criminal actors may use phishing attacks to ingress into a hospital's computer systems to install Cryptolocker or a similar ransomware malware on the hospital's systems. Cryptolocker is an attack that degrades civilian critical infrastructure, denies user access and has the potential to destroy critical\n37 Here proxy usage refers to the authority to represent someone else not the technical usage of the term in information communications.\n38 Borghard, Erica D, and Shawn W Lonergan. 2016. “Can States Calculate the Risks of Using Cyber Proxies?” *Orbis* 60(3): 395–416.\n39 Kautalya and L. N. Rangarajan. 1992. *The Arthashastra*. New Delhi: Penguin Books India; Griffith, Samuel B, and Sun Tzu. 1971. *The Art of War*. New York: Oxford University Press.\n40 Lin, Herbert. “Operational Considerations in Cyber-attack and Cyber Exploitation”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press.\n41 Brantly, Aaron F. 2015. “Aesop’s Wolves: The Deceptive Appearance of Espionage and Attacks in Cyberspace”. *Intelligence and National Security* 31(5): 674-685.\n41\ninformation.42 Very few states have national deterrence strategies aimed at sub-state actors, criminal organizations or individuals. State deterrence strategies aimed at non-terrorist sub-state actors are confined to criminological models of deterrence. Yet, if a soldier or spy from an adversary state walked into the server room at the same hospital and threatened to detonate a bomb and destroy all the files unless he was paid a ransom, the act would align more closely with a conventional deterrence framework of state-to-state deterrence by threats of punishment or tailored deterrence against terrorist actors.\nMost scholars and practitioners are likely to contend that it is not the responsibility of the state to deter non-state actors (excepting terrorists), particularly criminals from cyber attacks against non-federal infrastructure outside of a criminological framework.43 Yet, the same tool used by a criminal is available to the state and presents the same challenges associated with attribution irrespective of the perpetrator. What actions could a state undertake to deter an adversary state actor from engaging in this behavior and would these actions have a measurable effect on non-state actors as well?\nExamples of cyber attacks abound and include the destruction, denial or degradation of military or civilian communications platforms. Attacks such as the Mirai (malware) botnet attack in 2016 are capable of being directed at both critical and non-critical infrastructure by both state and non-state actors. A botnet using Mirai was able to generate in excess of 1Tbps of traffic and degrade dozens of websites in the United States on 20 September 2016.44 This same form of attack could be directed towards IP addresses of the FAA and emergency service providers or any number of Internet-enabled systems found on Shodan.io or similar services.45\nAlthough DDoS attacks are generally considered to be among the least complicated forms of cyber attacks they still challenge state and sub-state entities both public and private. DDoS attacks have been used against US government infrastructure, against Estonia in 2007 and the Republic of Georgia in 2008.46 To date, DDoS attacks against the US government or critical infrastructure have received little attention in discussions on deterrence in cyberspace. On 21 January 2016 a grand jury in the Southern District of New York indicted 7 Iranian Hackers in absentia for their involvement in DDoS\n42 Winton, Richard. 2016. \"Hollywood Hospital Pays $17,000 in Bitcoin to Hackers; FBI Investigating\". Los Angeles Times. February 18, 2016. http://www.latimes.com/business/technology/la-me-ln-hollywood-hospital-bitcoin-20160217-story.html.\n43 Akers, Ronald L. 2017. \"Rational Choice, Deterrence, and Social Learning Theory in Criminology: The Path Not Taken\" Journal of Criminal Law and Criminology 81(3): 1–25.\n44 Bonderud, Douglas. 2016. \"Leaked Mirai Malware Boosts IoT Insecurity Threat Level\". securityintelligence.com. October 4, 2016. https://securityintelligence.com/news/leaked-mirai-malware-boosts-iot-insecurity-threat-level/.\n45 Bodenheim, Roland, Jonathan Butts, Stephen Dunlap, and Barry Mullins. 2014. \"Evaluation of the Ability of the Shodan Search Engine to Identify Internet-Facing Industrial Control Devices\". International Journal of Critical Infrastructure Protection 7(2): 114–23.\n46 Klimburg, Alexander. 2011. \"Mobilizing Cyber Power\". Survival 53(1): 41–60; Hollis, David. 2011. \"Cyberwar Case Study: Georgia 2008\". Small Wars Journal, http://smallwarsjournal.com/jrnl/art/cyberwar-case-study-georgia-2008.\n42\nattacks against US financial sector interests and a variety of other US companies occurring from 2011-2013.⁴⁷ These indictments are: (a) not deterrent threats or denials, but criminological deterrents; (b) temporally distant from the time of attack as to be ineffective at signaling deterrence; and (c) impose little to no costs on Iran or the individual perpetrators or organizers of the attack.\nBeyond DDoS attacks, Russian attacks against Ukrainian electric infrastructure and US political organizations also resulted in no or weak responses that offer no indication that deterrence is making headway in cyberspace.⁴⁸ In response to massive influence operations perpetrated by the Russian Federation against the United States and its two major political parties during the 2016 Presidential election the United States expelled 35 suspected Russian intelligence operatives and placed sanctions on Russia’s two leading intelligence services, the FSB and the GRU.⁴⁹ The US response imposed insignificant costs in comparison to the utility achieved by the Russian Federation.\nThe latter case of Russian influence and hacking during the 2016 election cycle provides a case study for why deterrence by threat in cyberspace is so difficult to achieve. The first indications of Russian interference in the 2016 election were identified by the FBI in September 2015 more than a year before the election.⁵⁰ The FBI phoned the DNC to try and alert them to a potential attack, but the call was not considered credible and was subsequently ignored by DNC staffers.⁵¹ The progression of hacking attempts against the DNC continued and President Obama was notified in the summer of 2016. Moreover, the “attack” against the DNC was not an attack, but espionage or theft and therefore falls outside conventionally defined deterrence frameworks. Yet the impact of the espionage and the later release of private DNC emails was substantial as indicated in a declassified report by the Office of the Director of National Intelligence (ODNI).⁵² The report assessed that information warfare conducted following the espionage campaign substantially degraded the DNC and engendered a loss of confidence in the US electoral system.⁵³ Cyber deterrence has fundamental problems including the realization that the most valuable assets in cyberspace might not be destroyed or degraded, but rather stolen and used.\n⁴⁷ US Federal Bureau of Investigation. 2016. “Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion”. https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n⁴⁸ US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n⁴⁹ Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n⁵⁰ Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n⁵¹ Ibid.\n⁵² US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n⁵³ Ibid.\n43\nEven in instances where specific code is used to achieve damage such as Iranian efforts to hack a spillway dam⁵⁴ or malware implants in critical infrastructure such as a German steel mill,⁵⁵ there are no formal mechanisms by which to signal a threat within cyberspace or beyond other than by referencing responses to kinetic effects. Current deterrence by threat signaling for attacks occurring in or through cyberspace is ambiguous. Efforts by the NATO CCD COE through the production of the Tallinn Manuals have begun to outline the frameworks in which deterrence could legally take place, yet the application of threats is still uncertain.⁵⁶\nDeterrence by threat within cyberspace is realistically only applicable to cyber operations that result in direct physical effects that are non-repudiable and attributed quickly. Using formal modeling in the Decision to Attack: Military and Intelligence Cyber Decision-making I found that most cyber attacks, with the notable exception of DDoS, operate under varying conditions of anonymity.⁵⁷ The anonymity associated with attacks is usually necessary for attacks to be successful in bypassing deterrence by denial frameworks found in the perimeter defenses of networks such as intrusion detection and prevention systems found in the logical or physical network layers of cyberspace. Threats of punishment could impact the persona layer of cyberspace as well, but as will be examined below there are some fundamental challenges unique to cyberspace posed by anonymity.\n## 4. TECHNICAL CHALLENGES: THREATS OF PUNISHMENT WITHIN DOMAIN\nPunishing an adversary in cyberspace is not cheap or fast outside of pre-established botnets or damage done to physical infrastructure. Punishment in or across any of the layers cyberspace requires what the US Department of the Army refers to as intelligence preparation of the battlefield (IPB):\n“IPB is a systemic, continuous process of analyzing the threat and environment in a specific geographic area. It is designed to support staff estimates and military decision making”.⁵⁸\n⁵⁴ Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n⁵⁵ Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n⁵⁶ Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n⁵⁷ Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n⁵⁸ US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.\nIn response to a nuclear attack on a city in the US, the proportional response would be a counter attack on an adversary city. The city itself is geographically fixed and immovable both logically and physically. Threatening in-kind retaliation is both plausible and technically feasible with ballistic missiles or air assets. The same logic does not hold in cyberspace.\nWhy are in kind retaliations or other forms of punishment not viable solutions for most retaliations in cyberspace? First, a state must fulfill the burden of proof in identifying the perpetrator of an action. All the above IPB and potential for retaliation still depends upon attribution of who, what, and potentially why an attack occurred.59 Retaliation absent strong evidence is likely to lead to misidentification and unnecessary escalation.\nSecond, a state must retaliate within a proximate temporal range. If state X does not have detailed intelligence on the asset it wishes to retaliate against, developing intelligence along with a cyber weapon to target it increases the time horizon of response such that it is days, weeks, months or even years out from the original attack for which it is retaliating. Due to this temporal disconnect, the threat to punish in response to a given action falls into a category of what economists refer to as hyperbolic discounting. The risk of punishment for an attack is possible but so temporally, distant as to be discounted to the point of irrelevance.\nThird, deterrence by punishment requires proportionality. It is necessary to have comparable assets to punish to prevent escalation or violations of international law.60 Comparable assets are not a given within cyberspace and are often difficult to identify.61 To punish an asset within a domain requires pre-established access or knowledge of that asset beyond its location. Whereas a city is immovable and likely to be as susceptible today as it will be tomorrow to a missile or bomb, a computer system that is penetrated today for prepositioned access, might be patched, upgraded or taken offline tomorrow.\nFourth, a state must possess a specific cyber weapon system tailored to its target. If state X alerts state Y that it is going to punish an asset or state X uses a repeated cyber weapon to attack state Y’s system, it is likely to be ineffectual the longer it is used due to updated perimeter defenses, such as intrusion detection and prevention systems (IDPS), antivirus programs or a variety of other security measures. If state X wants to punish state Y it must have knowledge of the attributes of the asset it wishes to retaliate against and what the status of that asset is. State X must also develop new exploits to achieve effects or be confident that State Y has not accounted for previous exploits that have been used.\n59 Brantly. 2016.\n60 Schmitt, Michael N. (Ed.) 2017. Tallinn Manual on the International Law Applicable to Cyber Operations: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press: Kindle Location: 4530.\n61 Libicki, Martin C. 2016. Cyberspace in Peace and War. Naval Institute Press: 262.\nThe challenges of signaling deterrence by punishment are numerous within cyberspace whether the conflict is contained within domain or crosses over domains. Advances in attribution within a timely manner and the availability and reasonable assumption that proportional assets of an adversary can be held at risk need to be improved to credibly threaten punishment. This is a challenge not isolated to within domain retaliation. While proportional target selection might be slightly easier in cross-domain retaliation, the first three issues raised above are still relevant.\nDeterrence by punishment in cyberspace is possible, but it is not a reliable or credible option under most conditions absent sufficient and sustained intelligence. This assessment is not unique and is borne out in the analysis of Valeriano and Maness, who find that deterrence via punishment is generally ineffective and likely more dangerous than other means of preventing attacks. Moreover, sustained invasive intelligence into adversary networks creates its own unique problems, including a security dilemma. The more states engage in highly invasive intelligence via cyberspace, the more their actions are likely to be misinterpreted. Differentiating between various forms of cyber actions are difficult and can lead to miscalculation.\nFigure 1 illustrates the relationship between attacking and defending forces and area where both forms of deterrence function.\n62 Valeriano, Brandon, and Ryan C Maness. 2015. Cyber War Versus Cyber Realities: Cyber Conflict in the International System. New York: Oxford University Press: 57-60.\n63 Buchanan, Ben. 2017. The Cybersecurity Dilemma Hacking, Trust and Fear Between Nations. Oxford: Oxford University Press.\n64 Brantly. 2016.\nAs seen in Figure 1, deterrence by threat of punishment and denial operate within the same temporal ranges, yet while attribution matters a great deal for threats of punishment they are generally unimportant for denial. In their initial stages both denial and punishment focus on ante-impetum means of dissuasion, yet deterrence by punishment necessarily needs post-impetum attribution for it to be used. Based on the technical realities of cyberspace and of international relations deterrence by threat of punishment is more complicated and difficult to effectively establish.\n# 5. TECHNICAL CHALLENGES AND OPPORTUNITIES: DETERRENCE BY DENIAL\nBoth deterrence by denial and punishment require ante-impetum costs by the defender. The allocation of resources between denial and deterrence and the efficiency with which they deter adversaries differ. The establishment of credible deterrence by denial often starts with the allocation of financial capital to purchase technical resources and provide human capital sufficient to continually update, enhance, audit and manage complex network infrastructure. Network-based and host-based defenses such as intrusion detection and prevention systems, anti-virus products and similar systems are some of the variety of overlapping expenditures that can be undertaken to increasingly make the intrusion of adversaries into a given network more difficult.\nIn cyberspace, such expenditures are regularized and often included as overhead costs, however they are deterrent in nature. Although they are not glamorous, they substantially decrease the probability of penetration. The same types of deterrence strategies are used by stores in placing electronic tracking tags on their products and detectors at doors, by banks in the construction of vaults, silent alarms and dyed packets of money, by critical infrastructure in extending the perimeter of security outward to prevent vehicle-borne improvised explosive devices, increased numbers of security guards, cameras and the use of razor wire or other physical structures. These devices signal to adversaries both criminal and terrorist alike that the costs of successfully perpetrating an attack are high and that the likelihood of success is low, although both terrorist and criminal deterrence models include deterrence by punishment through criminal proceedings and potential lethal actions against terrorist they rely far more heavily on preventive measures that deny would be adversaries.\nSceptics might contend denial mechanisms are unlikely to deter a state, yet this is in and of itself not accurate. The vast majority of probes by states do not translate into successfully attacks. The US Department of Defense suffers from millions of probes\n Riggs, Cliff. (2004). *Network Perimeter Security*. New York: Auerbach Publications.\n Buecher, Axel, Per Andreas, and Scott Paisley. 2009. “Understanding IT Perimeter Security”. IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n Filkins, Barbara. 2016. “IT Security Spending Trends”. SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n47\na day. Yet nearly 99.99% of them are unsuccessful.⁶⁸ Moreover, in the face of a global onslaught of cyber attacks and espionage the United States re-architected much of its military network infrastructure. This restructuring allows the initial point of contact with adversaries to be chosen. In military parlance, it allowed the defenders to choose the terrain of the battle. While it did not obviate the need for denial mechanisms within the network infrastructure, it did signal increased cost imposition on adversaries and it did allow for more efficient resource allocation.\nUnlike in any other battlespace, whether conventional kinetic terrorism, conventional kinetic or mass destruction military force, the opportunities for deterrence by denial are substantial in cyberspace and unique. While denial opportunities in land, sea, air, and even space are predicated on the control of a given geospatial area, the party establishing deterrence by denial has limited abilities to manipulate the nature of the domain itself. The same is not true within cyberspace. Every aspect of a defender’s cyberspace from the structure of the network, to the hardware, firmware, and software within a network, to the access of individuals within and external to that network is manipulable. At every stage of an attack an adversary is always attempting to operate on or against the defender’s cyberspace over which it has no control and has limited visibility.\nFor denial, the historical literature of deterrence theory remains relevant, in particular the second and third stages of deterrence which focused on rational game theoretic and cognitive modeling. While in conventional deterrence the emphasis was on punishment, here these same modeling techniques find applicability in deterrence by denial. Although the games might be the same, the payoffs in cyberspace manipulable and favor the defender. In few other applications of deterrence are the payoff matrices of deterrence so favorable to the defender. Despite the favorability of conditions, the ability to manipulate the potential payoff for attackers remains difficult. Although possible for defenders to reduce the probability of attack success, the potential payoff for a successful attack can remain large.\nDespite conditions favoring defenders, the potential payoffs are often not affected by deterrence by denial. Minimizing the potential payoffs from attacks on data repositories requires disaggregation of data. These types of denial mechanisms come with efficiency or financial costs. Although denial offers more potential than punishment, it is not a silver bullet to the cyber deterrence problem. Denial decreases the probability of success for attackers and is likely to reduce classes of actors focused on certain targets. Despite efforts to signal through the purchase and implementation of various defensive measures, the re-architecting of network infrastructure, the cyber deterrence problem remains.\n⁶⁸ Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\n# 6. BEYOND THE DETERRENCE PROBLEM\nIf punishment and denial are unable to fully remediate the cyber deterrence problem, are there any meaningful solutions? The core debate remains, with no simple and readily apparent solutions. The search for a single solution is likely to remain fruitless for the foreseeable future. Deterrence has never been the single tool within the toolbox of the state to dissuade or shape adversary behavior. Rather, it has always been combined with efforts that extend beyond traditional concepts of deterrence to include geopolitical and technical practices including norm development, entanglement, cumulative deterrence, research and development, policies and laws, liability structures for software and hardware, training for users and human capital development within information technology and cybersecurity.⁶⁹\nEfficient and effective cyber deterrence should extend international politics and include fields such as criminology, immunology and public health.⁷⁰ The capacity of states to punish criminals is high and the credibility of punishment actions in developed nations is strong. Despite a capacity to punish criminal behaviors, they still occur. Extending beyond punishment, states also focus on denying criminals opportunities to commit crimes. Yet crime still occurs. The root causes of crime are not simple nor isolatable to a single phenomenon. Likewise, states engage one another in cyberspace for a variety of reasons. Some reasons fit within conventional deterrence frameworks of denial and punishment and do not suffer from challenges with attribution. For instance, larger and more harmful attacks increase the probability of attribution. However, many states remain perturbed by the death by a thousand cuts phenomena which falls below thresholds and required to provide timely attribution.\nShifting the focus away from within domain deterrence focused solely on punishment and denial and changing the emphasis to a basket of strategies focused on reducing incentives, availability and anonymity fosters an environment less conducive both to hostile actions and potential malicious actors. The solution to the deterrence problem is not abandoning it, but expanding the range of alternative strategies not presently considered. By acknowledging the failures and inadequacies of deterrence strategies and the potential places where novel strategies found in other fields are applicable the intractable problem of cyber deterrence becomes more manageable.\n⁶⁹ Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.\n⁷⁰ Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n49"
    },
    "author_year": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 99,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "author_year"
      },
      "results": [],
      "flat_text": "CyCon X: Maximising Effects T. Minárik, R. Jakschis, L. Lindström (Eds.)\n\nPermission to make digital or hard copies of this publication for internal use within NATO and for personal or educational use when for non-profit or non-commercial purposes is granted providing that copies bear this notice and a full citation on the first page. Any other reproduction or transmission requires prior written permission by NATO CCD COE.\n# The Cyber Deterrence Problem Aaron F. Brantly Assistant Professor, Department of Political Science Virginia Polytechnic and State University United States abrantly@vt.edu Abstract: What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.\nKeywords: cyber, deterrence, denial, punishment # 1. INTRODUCTION The challenge of the digital era is not to define deterrence. Deterrence is a well-defined concept that has been studied and practiced throughout history and to an even greater depth following the advent of nuclear weapons. The present challenge it is to understand the role digital technologies play in the broader scope of interstate deterrence. Deterrence in one domain rarely if ever operates independently of other domains. Much of the literature on cyber deterrence focuses on within domain deterrence. Yet, this is a dangerous constraint that elevates risks and minimizes the probability of success. This paper seeks to draw out the literature on deterrence and identify its applicability within a newly delineated domain of interactions, cyberspace. The resultant analysis strives to encompass the complexity of deterrence and advance an argument beyond within domain modeling.\n\nFocusing on classical deterrence and deterrence by denial helps illustrate the similarities and differences between deterrence in the pre- and post-delineation of cyberspace as a domain of military operations. Deterrence in cyberspace has been addressed by a variety of scholars across the subfields of International Relations.¹ Many examinations of cyber deterrence rely on direct applications of IR theory absent robust technical understandings of how the domain functions. The development and application of classical deterrence theories to a domain necessarily requires an understanding of how state and non-state actors achieve, develop, and assess costs and benefits within this domain.\nThis work proceeds in three sections. First, it examines some of the relevant literature on deterrence and identifies some of the gaps within the field and provides a trajectory for the subsequent sections to examine a more dynamic theory of deterrence in cyberspace. The second section focuses on the technical, tactical, operational, and strategic aspects of the domain in an effort to identify those areas where deterrence can alter the costs-benefit analysis of adversaries. Third, the work concludes by providing a discussion on national strategy development for integrated cyber deterrence incorporating the lessons from the first two sections.\n## 2. FROM ATOMS TO BITS AND BYTES Deterrence is not a novel concept. The classical IR cannon on deterrence can be traced back to the Peloponnesian War and the threat of violence in response to adversary actions.² Yet, more modern formulations of deterrence are largely rooted in the nuclear world following World War 2. The most common form of deterrence known as conventional deterrence was established by Bernard Brodie, Thomas Schelling and ¹ Mandel, Robert. 2017. *Optimizing Cyberdeterrence: A Comprehensive Strategy for Preventing Foreign Cyberattacks*. Georgetown University Press; Jasper, Scott. 2017. *Strategic Cyber Deterrence the Active Cyber Defense Option*. Lanham, MD: Rowman &amp; Littlefield.\n² Thucydides and Rex Warner. 1968. “The Sixth Book, Chapter XVIII”. In *History of the Peloponnesian War*. Baltimore, MD: Penguin Books.\nothers and focuses on the ex-ante dissuasion of adversaries through the threat of ex-post costs in response to potential adversary actions.\nRobert Jervis identified three “waves” of deterrence theorizing to which a potential fourth wave has been added by Jeffery Knopf.³ First wave deterrence theory rested on the rise and consequences of nuclear weapons. Bernard Brodie et al. asserted that the use of nuclear weapons had almost no innate strategic or tactical value outside of being a threat against an adversary.⁴ The consequences of nuclear weapons use, even in limited strike situations, would quickly and dramatically escalate. This escalation made the limited use of such weapons untenable in all but the most extreme situations. Lawrence Freedman summarized the second wave as the realization that “total war could now only be threatened, but never fought”.⁵ Second wave deterrence posited how nuclear weapons could be threatened and the dynamics of those threats.⁶ Thomas Schelling and others posited a series of conditions in which states could develop deterrence in the nuclear era. As Jervis noted, second wave theorizing became extremely popular because of its abstraction and logical structuring.⁷ Game theory and other rational models were used to illustrate rational costs and benefits, creating models suited to rigorous concepts of rationality.⁸ The second wave arose under stable bi-polar conditions in which it was assumed states engaged in rational decision-making in matters of foreign policy and national security. Schelling found deterrence largely dependent upon credibility and rationality. He illustrated that signaling potential costs to an adversary absent credibility creates deterrence failure. By using divergent game-theoretic structures from prisoner’s dilemma to chicken – theorists developed arguments about deterrence. Despite rigorous theory, this abstraction contained systemic flaws and gave rise to a third wave of deterrence.\nThe third wave of deterrence theory in the 1970s addressed challenges beyond game theoretic models, including the failing rationality. Irving Janis and Graham Allison, both, but with different perspectives, illustrated the weaknesses of rationality in decision-making.⁹ The third wave led to extensions into cognitive psychology and behavioral studies. Robert Jervis, Richard Ned Lebow, and Janis Stein provided insight into the general problems associated with parsimonious use of rationality through case analyses. Specifically, Jervis et al. identified the potential for over-valuation of ³ Jervis, Robert. 1979. “Review: Deterrence Theory Revisited”. *World Politics* 31(2): 289–324; Knopf, Jeffrey W. 2010. “The Fourth Wave in Deterrence Research”. *Contemporary Security Policy* 31(1): 1–33.\n⁴ Brodie, Bernard, Frederick Sherwood Dunn, Arnold Wolfers, Percy Ellwood Corbett, and William T. R. Fox. 1946. *The Absolute Weapon: Atomic Power and World Order*. New York: Harcourt, Brace and Co.\n⁵ Freedman, Lawrence. 2004. *Deterrence*. Cambridge: Polity Press: 21.\n⁶ Ibid: 22.\n⁷ Jervis. Review: 291-292.\n⁸ Schelling, Thomas C. 1966. *Arms and Influence*. New Haven: Yale University Press: 36-40.\n⁹ Janis, Irving L. 1982. *Groupthink: Psychological Studies of Policy Decisions and Fiascoes*. Boston: Houghton Mifflin; Allison, Graham T. 1971. Essence of Decision; Explaining the Cuban Missile Crisis. Boston: Little, Brown.\n\nJeffrey Berejikian incorporated Daniel Kahneman and Amos Tversky’s analysis of prospect theory into the deterrence calculus and challenged parsimonious rational thought by illustrating cognitive dimensions associated with decision-making beyond groupthink and bureaucratic processes. His work highlighted issues related to risk in cognitive decision-making that undermine rationality. Concepts such as sunk costs or tying hands fit well within parsimonious deterrence theory, yet the mechanisms that made them effective were not well understood prior to the third wave.\nAlthough modern deterrence theory encompasses a spectrum from pure rational modeling to cognitive models, the objective of deterrence as identified by John Mearsheimer remains the development of fear of the consequences (in particular of “military action”) or a “function of costs and risks”.¹¹ Developing shared knowledge about costs and risks for nuclear events differs from non-nuclear conflicts. Early deterrence models relied heavily on rationality and parsimony but did not underestimate the clarity provided by the use and subsequent impact of the weapons themselves. The generation of fear or knowledge of consequences to assess costs and risks loses clarity the as analyses shift away from nuclear weapons. Lawrence Freedman defines single weapon or type of warfare deterrence as “narrow deterrence”.¹² Narrow deterrence is less effective when expanded beyond single weapon or type warfare.\nGeneral or broad deterrence covers a range threatened actions to dissuade an adversary. Freedman writes: “broad deterrence involves deterring all war”.¹³ Ted Hopf explains: within deterrence there is a need to expand deterrence beyond the scope of military tools to the entire range of options available to actors.¹⁴ Extending analysis further, scholars also emphasize concepts of direct deterrence and extended deterrence. Direct deterrence is concerned with actions against “your” state and its immediate interests as opposed to extended deterrence – dissuasion of adversary actions against a third party or non-immediate interests. Delineating between these two types of deterrence in a globalized world is difficult. Cyberspace compounds the challenge of delineation because attacks on foreign infrastructure can and do have ramifications globally.\nConcepts of the means to achieve deterrence or more simply how to deter are often contested. Threats can be narrowed to weapon type or category, or include ¹⁰ Berejikian, Jeffrey D. 2004. “International Relations Under Risk: Framing State Choice”. Albany: State University of New York Press; Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk”. *Econometrica* 4(2); Jervis, Robert, Richard Ned Lebow, and Janice Gross Stein. 1985. *Psychology and Deterrence*. Baltimore, MD: Johns Hopkins University Press.\n¹¹ Mearsheimer, John J. 1990. *Conventional Deterrence*. Ithaca: Cornell University Press: p 23.\n¹² Freedman. 2004.\n¹³ Ibid.\n¹⁴ Hopf, Ted. 1994. *Peripheral Visions: Deterrence Theory and American Foreign Policy in the Third World, 1965-1990*. Ann Arbor: University of Michigan Press.\n\nOften left out of traditional international relations literature, deterrence by denial has seen a surge of interest in the years following the 9/11 terrorist attacks. Alex Wilner defines deterrence by denial as “reducing the perceived benefits an action is expected to provide a challenger”.¹⁵ Deterrence by denial in the physical world often includes hardening targets by building higher walls, adding security mechanisms, or other tactics to reduce the susceptibility of targets to attack. If the Strategic Defense Initiative (SDI – also known as Star Wars) had been successful, it would have been a deterrence by denial strategy to limit the effect of Soviet nuclear weapons. Commonly used forms of deterrence by denial in conflict zones include land mines, razor wire, surface to air missiles (SAMs) and fortifications.\nDeterrence by punishment and denial are intended to manipulate the cost-benefit analysis of an adversary. To function they must both be credible. Credibility requires undertaking ex-ante costs by the deterrer. Threats absent ante impetum costs lack credibility. A state without nuclear weapons cannot credibly threaten nuclear retaliation. If a state wishes to deter it must provide demonstrable evidence that it is able to carry out its threat.\nLikewise, deterrence by denial fails when it lacks the material capabilities to deny. The Maginot Line built by the French following World War I stands an example of failed deterrence by denial. The French system of fortifications on portions of their northern territory failed because the line itself only covered one vector of attack into France. The elevation of costs to a potential attacker must be complete and provide no reasonable alternatives to achieve the attacker’s intended utility. Both strategies require ex-ante costs by the defender to alter the ex-post perceived benefits of an attacker. Punishment strategies increase adversary costs after a violation and denial strategies increases adversary costs in advance of a violation.\nDeterrence by denial is a successful strategy in many instances; SAMs effectively deter enemy aircraft. The relative costs of upgrading certain denial tools is comparatively less than the costs of surmounting them. In the case of SAMs, the United States spent billions of dollars to defeat the S-300 missile system (~$100 million/system).¹⁶ Following the development and use of stealth, S-300 designer Almaz upgraded its ¹⁵ Wilner, Alex S. 2015. “Deterrence Theory: Exploring Core Concepts”. In *Deterring Rational Fanatics*. Philadelphia: University of Pennsylvania Press: 16-36.\n¹⁶ Grazier, Dan. 2015. “The Price of the New B-21 Stealth Bomber? Sorry, That’s a Secret”. *The National Interest*. June 15, 2015. http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604; 2015. “Program Dossier S-300 Surface-to-Air Missile System”. Aviationweek.com. August 6, 2015. http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf.\n\nDeterrence by denial is not always successful as illustrated by the Israel – Hamas conflict. In response to Hamas’ use of Katyusha rockets, Israel developed the Iron Dome System. Iron Dome batteries cost $100 million and each rocket costs $50,000.¹⁸ To intercept an incoming Katyusha rocket, the Israelis launch 2 interceptor rockets.¹⁹ By contrast, Hamas spends between $500 and $1,000 per rocket launch.²⁰ If the cost of the battery is ignored, the cost of deterrence by denial is still between 100 to 1 and 200 to 1.\nDenial strategies are not passive. They require continuous modification relative to adversary capability development. Static denial strategies in cyberspace or in conventional conflict are likely to have limited credibility over time. Similarly, punishment strategies also require constant updating in relation to adversary capabilities and geopolitical considerations. In cyberspace, this involves adapting denial strategies to technological advances such as artificial intelligence, polymorphic malware and the Internet of Things, to name just a few.\nPunishment strategies also require ex-ante costs. Below the nuclear threshold, threats of force are common, yet the credibility of these threats is difficult to establish. Alexander George and Richard Smoke identify three attributes important for signaling in conventional deterrence: “(1) the full formulation of one’s intent to protect a nation; (2) the acquisition and deployment of capacities to back up that intent; (3) the communication of intent to a potential aggressor”.²¹ These three aspects are also at times limited in their ability to convey commitment to fulfill the intent.²² Charles Glaser, writing on cyber deterrence, established four components of basic deterrence: ¹⁷ Rogoway, Tyler. 2015. “Here’s Russia’s S-400 Missile System in Action, and How the US Would Deal with It”. Foxtrotalpha.Jalopnik.com. December 6, 2015. https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022.\n¹⁸ Morris, Benny. 2014. “Should Israel and the US Rethink Iron Dome’s Usefulness?” *LA Times*, August 21, 2016. http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html.\n¹⁹ Ibid.\n²⁰ Ibid.\n²¹ George, Alexander L, and Richard Smoke. 1974. *Deterrence in American Foreign Policy: Theory and Practice*. New York: Columbia University Press: 64.\n²² Ibid: 558.\"1) the benefits of taking the action—the larger the benefits, the harder the adversary is to deter; 2) the probability of achieving the benefits—the higher the probability, the harder the adversary is to deter; 3) the costs the defender will impose if the adversary takes the action—the higher the costs, the more likely the adversary is to be deterred; and 4) the adversary's assessment of the probability that the defender will inflict these costs—the higher this probability, the more likely the adversary is to be deterred\".[23] George and Smoke and Glaser acknowledge the challenge of establishing not just threats of punishment, but the credibility associated with carrying out that threat.\nCreating material capability (i.e. weapon systems capable of carrying out a given threat) and clear signaling might occur and yet the utilization of this capability in response to an adversary's action will lack credibility (fulfillment of commitment) unless it contains what James Fearon refers to as hand-tying within a sunk costs framework.[24] Credibility and hand-tying are most closely associated with extended deterrence, yet when expanding deterrence to cyberspace it also finds relevance. The establishment of credibility through hand-tying establishes a forcing mechanism for decisions, indicating costs have already been incurred or are likely to occur. This subsequently alters the cost-benefit calculus of retaliation. The stationing of US forces in West Berlin serves as an example of hand-tying through prospective costs.[25] An attack on West Berlin would have resulted in sunk costs and provided a strong inducement or\"tripwire\"to actuate US retaliatory threats. Nearly all forms of kinetic attacks against the direct interests of a nation implicitly include hand-tying. It is unclear how to effectively signal prospective costs within cyberspace to an adversary.\nCharles Glaser identifies several problems associated with deterrence by punishment specific to cyberspace that extend beyond basic credibility issues. First, he notes that deterrence often relies on the attribution of an adversary's actions.[26] In cyberspace, this can be difficult and time-consuming.[27] Although the attribution problem is decreasing as more data becomes available, it does not eliminate uncertainty.[28] Second, hands-tying and other forms of credibility enhancing measures are likely lacking in cyberspace. Moreover, the ability to respond within domain simply might not be possible within certain conditions.[29] Third, Glaser identifies potential spillovers Deterrence is more than simply threatening punishment. Deterrence requires substantial target relevant costs and the development of mechanisms to establish that further costs are credibly wagered to provide clarity for an adversary. The goal of this clarity is to establish within an adversary’s calculus that their expected gains are less than any potential losses incurred. Reassessments of rational modeling and the increasing importance of cognitive modeling increase the value of tailored deterrence strategies predicated on the uniqueness of conditions and actors. Paul notes that deterrence is complex and is most logically broken down into five ideal types: “(1) deterrence among great powers; (2) deterrence among new nuclear states; (3) deterrence and extended deterrence involving great powers and regional powers armed with chemical, biological and nuclear weapons; (4) deterrence between nuclear states and non-state actors (5) deterrence by collective actors”.³¹ It follows that tailored deterrence for cyber actors is also one potential avenue of exploration.\nThe potential for tailored deterrence strategies could be highlighted in numerous significant cyber incident cases. The 1998 cyber attack code-named SOLAR SUNRISE discovered by US Air Force Computer Emergency Response Team (AFCERT) stands as a prime example. The three-week hack affected more than 500 systems across the US Air Force, Navy, NASA, Lawrence Livermore Labs, MIT, Harvard, and UC Berkeley. The attack coincided with increased tensions between the United States and Iraq and resulted in high-level governmental meetings to identify a proper response action.³² At the time, the attack was believed to be state-sponsored cyber attack focused on degrading US military capabilities. Subsequently, it was discovered that the attack was conducted by two California teenagers with guidance from Israeli hacker Ehud Tenebaum. The incident is relevant to tailored deterrence because it highlights challenges faced in developing a deterrence strategy. The adversaries were domestic, yet foreign inspired and attacked the operational infrastructure of the Department of Defense. No form of deterrence by punishment delineated above could have appropriately accounted this challenge. The only realistic ³⁰ Ibid.\n³¹ Wirtz, James J, Patrick M Morgan, and T V Paul. 2009. *Complex Deterrence: Strategy in the Global Age*. Chicago: University of Chicago Press: 9.\n³² Healey, Jason. 2013. *A Fierce Domain: Conflict in Cyberspace, 1986 to 2012*. Vienna, VA: Cyber Conflict Studies Association.\n\nRichard Kugler writes that a strategy or general framework for deterrence in cyberspace must necessarily be tailored to differing threats, situations, and objectives.³³ The threats, situations, and objectives in cyberspace differ from the concerns addressed by first wave theorists. While the potential for physical damage through cyberspace has been demonstrated in tests such as the Aurora generator experiment that resulted in the destruction of a multi-ton diesel generator, or the Stuxnet attack that destroyed segments of a centrifuge cascade in Iran’s Natanz nuclear facility, many attacks do not have kinetic parallels.³⁴ Building on Kugler, Jeffrey Cooper identifies three important factors that frame concepts on deterrence in cyberspace. First, there is a wide range of actors each with different capabilities and attributes as well as cost benefits structures; second, cyberspace is a unique operational domain that carries with vastly different concepts of risk and reward; third, to develop deterrence, models must be applicable to the virtual and physical aspects of the domain.³⁵ This section has provided a summary of a large and robust literature on deterrence. The concepts that need to be carried forward include, the type of deterrence, the credibility of that deterrence and the attributes of the environment in which deterrence occurs, and who and what actors and weapons are to be deterred. The next section builds on the literature above, with a specific emphasis on the technical, tactical, operational and strategic attributes of cyberspace.\n# 3. ONE SIZE DOESN'T FIT ALL To deter adversaries in cyberspace it is helpful to first define what cyberspace is and what types of actions and actors a state would like to deter. The US Department of Defense defines cyberspace in the following way: “Cyberspace consists of many different and often overlapping networks, as well as the nodes (any device or logical location with an Internet protocol address or other analogous identifier) on those networks, and the system data (such as routing tables) that support them. Cyberspace can be described in terms of three ³³ Kugler, Richard L. 2009. “Deterrence of Cyber-attacks”. In *Cyberpower and National Security*. Edited by Larry K Wentz, Franklin D Kramer, and Stuart H Starr. Washington DC: National Defense University Press: 309–42.\n³⁴ US Department of Homeland Security. 2014. “FOIA Documents: Control Systems Security Aurora Update Brief”. Washington, DC. http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf; Zetter, Kim. 2014. *Countdown to Zero Day: Stuxnet and the Launch of the World’s First Digital Weapon*. New York: Crown Publishers.\n³⁵ Cooper, Jeffrey R. 2012. “A New Framework for Cyber Deterrence”. In *Cyberspace and National Security Threats, Opportunities, and Power in a Virtual World*. Edited by Reveron, Derek S. 2012. Washington: Georgetown University Press: 105–20.\nlayers: physical network, logical network, and cyber-persona. The physical network layer of cyberspace is comprised of the geographic component and the physical network components. It is the medium where the data travel. The logical network layer consists of those elements of the network that are related to one another in a way that is abstracted from the physical network, i.e., the form or relationships are not tied to an individual, specific path, or node. A simple example is any Web site that is hosted on servers in multiple physical locations where all content can be accessed through a single uniform resource locator. The cyber-persona layer represents yet a higher level of abstraction of the logical network in cyberspace; it uses the rules that apply in the logical network layer to develop a digital representation of an individual or entity identity in cyberspace. The cyber-persona layer consists of the people actually on the network\".36 The inclusion of the full definition illustrates the complexity within which defense strategists and operators in the various services engage. Because the domain spans the physical, logical, and persona layers, deterrence strategies can reasonably occur within and across all three. This fundamentally differs from the conceptualization of deterrence in physical domains of land, sea, air, and space. Physical domain deterrence might include physical and cognitive aspects analogous to the cyber persona and physical network layers, however, the logical layer is wholly absent. The cyber persona layer also diverges significantly from personas within the physical domain as individuals and states have the capacity to alter their attributes within the persona, logical, and network layers.\nTo construct a meaningful model of deterrence in cyberspace we must first ask what it is we wish to deter. Herein lies the largest distinction between deterrence in the physical world and in cyberspace. Whereas in the physical world deterrence is directed most commonly against physical attacks against specific assets or categories of assets that when attacked provide strong, largely non-repudiable forms of attribution, in cyberspace deterrence is directed against manipulations of the elements within the environment and the environment itself. Manipulation of elements of cyberspace and the environment itself can be examined in multiple ways. Simplifying cyberspace operations into three broad categories, there are cyber attacks, cyber espionage, and cyber theft. Despite simplification, it is important to note these categories are not entirely discrete in process or function. Cyber attacks are those acts in cyberspace that degrade, deny or destroy. Acts of cyber espionage steal information for state or corporate intelligence gain. Cyber theft is the stealing of information for financial gain with no direct state utility. Attacks, espionage, and theft occur across all levels US Department of Defense. 2013.\"Joint Publication 3-12: Cyberspace Operations\". Washington, DC. http://www.dtic.mil/doctrine/new_pubs/jp3_12R.pdf.\nof actors from script kiddies to the military units of states – a problem which will be examined more below. States are most commonly concerned with cyber attacks and espionage at the national level, and theft at lower-jurisdictions.\nBecause attacks, espionage, and theft are perpetrated by a variety of actors against almost any target in cyberspace, sending an overt signal from one state to another, while still applicable, might not deter attacks at other levels that are of equal or greater significance. Moreover, research by Shawn Lonergan and Erica Borghard indicate a high prevalence of proxy usage by states to maintain plausible deniability. Using proxies to engage in cyber acts against targets deflects deterrence by threats of punishment unless sufficient evidence is present to indicate involvement by the instigating state rather than the third-party proxy. The use of proxies to engage in attacks, espionage and theft against target states outside of cyberspace has been the practice of states since Katulaya and Sun Tzu. However, unlike the difficulties of non-repudiability within conventional conflicts, cyber attacks are frequently repudiable. Attackers might use Virtual Private Networks (VPNs), proxies or other means by which to engage in an attack.\nAdditional problems in cyberspace not frequently encountered in conventional physical domains are second and third order effects. As noted by Herbert Lin, the results of a cyber attack itself might not be identifiable, rather it is second or third order effects that generate an intended outcome. Classical deterrence and tailored deterrence strategies used against terrorist organizations are unable to account for disconnected action and reaction pairs commonly found in cyberspace. The time to punish a violation can be weeks, months or years based on discovery and attribution challenges, a problem not present in classical deterrence.\nCyber attacks are incidents occurring in or through cyberspace that degrade, deny or destroy. Attacks in cyberspace can and are perpetrated by all levels of actors. The differentiation between actors is most closely correlated with targets and outcomes of attacks. For example, criminal actors may use phishing attacks to ingress into a hospital's computer systems to install Cryptolocker or a similar ransomware malware on the hospital's systems. Cryptolocker is an attack that degrades civilian critical infrastructure, denies user access and has the potential to destroy critical Most scholars and practitioners are likely to contend that it is not the responsibility of the state to deter non-state actors (excepting terrorists), particularly criminals from cyber attacks against non-federal infrastructure outside of a criminological framework.43 Yet, the same tool used by a criminal is available to the state and presents the same challenges associated with attribution irrespective of the perpetrator. What actions could a state undertake to deter an adversary state actor from engaging in this behavior and would these actions have a measurable effect on non-state actors as well?\nExamples of cyber attacks abound and include the destruction, denial or degradation of military or civilian communications platforms. Attacks such as the Mirai (malware) botnet attack in 2016 are capable of being directed at both critical and non-critical infrastructure by both state and non-state actors. A botnet using Mirai was able to generate in excess of 1Tbps of traffic and degrade dozens of websites in the United States on 20 September 2016.44 This same form of attack could be directed towards IP addresses of the FAA and emergency service providers or any number of Internet-enabled systems found on Shodan.io or similar services.45 Although DDoS attacks are generally considered to be among the least complicated forms of cyber attacks they still challenge state and sub-state entities both public and private. DDoS attacks have been used against US government infrastructure, against Estonia in 2007 and the Republic of Georgia in 2008.46 To date, DDoS attacks against the US government or critical infrastructure have received little attention in discussions on deterrence in cyberspace. On 21 January 2016 a grand jury in the Southern District of New York indicted 7 Iranian Hackers in absentia for their involvement in DDoS Beyond DDoS attacks, Russian attacks against Ukrainian electric infrastructure and US political organizations also resulted in no or weak responses that offer no indication that deterrence is making headway in cyberspace.⁴⁸ In response to massive influence operations perpetrated by the Russian Federation against the United States and its two major political parties during the 2016 Presidential election the United States expelled 35 suspected Russian intelligence operatives and placed sanctions on Russia’s two leading intelligence services, the FSB and the GRU.⁴⁹ The US response imposed insignificant costs in comparison to the utility achieved by the Russian Federation.\nThe latter case of Russian influence and hacking during the 2016 election cycle provides a case study for why deterrence by threat in cyberspace is so difficult to achieve. The first indications of Russian interference in the 2016 election were identified by the FBI in September 2015 more than a year before the election.⁵⁰ The FBI phoned the DNC to try and alert them to a potential attack, but the call was not considered credible and was subsequently ignored by DNC staffers.⁵¹ The progression of hacking attempts against the DNC continued and President Obama was notified in the summer of 2016. Moreover, the “attack” against the DNC was not an attack, but espionage or theft and therefore falls outside conventionally defined deterrence frameworks. Yet the impact of the espionage and the later release of private DNC emails was substantial as indicated in a declassified report by the Office of the Director of National Intelligence (ODNI).⁵² The report assessed that information warfare conducted following the espionage campaign substantially degraded the DNC and engendered a loss of confidence in the US electoral system.⁵³ Cyber deterrence has fundamental problems including the realization that the most valuable assets in cyberspace might not be destroyed or degraded, but rather stolen and used.\n⁴⁷ US Federal Bureau of Investigation. 2016. “Iranian DDoS Attacks: Conspiracy to Commit Computer Intrusion”. https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks.\n⁴⁸ US Department of Homeland Security. 2016. “Cyber-Attack Against Ukrainian Critical Infrastructure | ICS-CERT”. Washington, DC; Rid, Thomas. 2016. “How Russia Pulled Off the Biggest Election Hack in US History”. *Esquire*. October 20, 2016. http://www.esquire.com/news-politics/a49791/russian-dnc-emails-hacked/.\n⁴⁹ Sanger, David E. 2016. “Obama Strikes Back at Russia for Election Hacking”. *The New York Times*. New York. December 29, 2016. https://www.nytimes.com/2016/12/29/us/politics/russia-election-hacking-sanctions.html.\n⁵⁰ Lipton, Eric, David E Sanger, and Scott Shane. 2016. “The Perfect Weapon: How Russian Cyberpower Invaded the US”. *The New York Times*. December 13, 2016. https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html.\n⁵¹ Ibid.\n⁵² US Office of the Director of National Intelligence. 2017. “Assessing Russian Activities and Intentions in Recent US Elections” Washington, D.C. January 6, 2017. https://www.dni.gov/files/documents/ICA_2017_01.pdf.\n⁵³ Ibid.\n\nDeterrence by threat within cyberspace is realistically only applicable to cyber operations that result in direct physical effects that are non-repudiable and attributed quickly. Using formal modeling in the Decision to Attack: Military and Intelligence Cyber Decision-making I found that most cyber attacks, with the notable exception of DDoS, operate under varying conditions of anonymity.⁵⁷ The anonymity associated with attacks is usually necessary for attacks to be successful in bypassing deterrence by denial frameworks found in the perimeter defenses of networks such as intrusion detection and prevention systems found in the logical or physical network layers of cyberspace. Threats of punishment could impact the persona layer of cyberspace as well, but as will be examined below there are some fundamental challenges unique to cyberspace posed by anonymity.\n## 4. TECHNICAL CHALLENGES: THREATS OF PUNISHMENT WITHIN DOMAIN Punishing an adversary in cyberspace is not cheap or fast outside of pre-established botnets or damage done to physical infrastructure. Punishment in or across any of the layers cyberspace requires what the US Department of the Army refers to as intelligence preparation of the battlefield (IPB): “IPB is a systemic, continuous process of analyzing the threat and environment in a specific geographic area. It is designed to support staff estimates and military decision making”.⁵⁸ ⁵⁴ Cylance. 2014. “Operation Cleaver”. https://www.cylance.com/content/dam/cylance/pages/operation-cleaver/Cylance_Operation_Cleaver_Report.pdf.\n⁵⁵ Lee, Robert M, Michael J Assante, and Tim Conway. 2014. “German Steel Mill Cyber-attack”. SANS Industrial Control Systems. December 30, 2014. https://ics.sans.org/media/ICS-CPPE-case-Study-2-German-Steelworks_Facility.pdf.\n⁵⁶ Schmitt, Michael N. (Ed.). 2013. Tallinn Manual on the International Law Applicable to Cyber Warfare: Prepared by the International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence. New York: Cambridge University Press.\n⁵⁷ Brantly, Aaron Franklin. 2016. The Decision to Attack: Military and Intelligence Cyber Decision-Making. Athens: University of Georgia Press.\n⁵⁸ US Department of the Army. 1994. FM 34-130 Intelligence Preparation of the Battlefield. Washington, DC.\nIn response to a nuclear attack on a city in the US, the proportional response would be a counter attack on an adversary city. The city itself is geographically fixed and immovable both logically and physically. Threatening in-kind retaliation is both plausible and technically feasible with ballistic missiles or air assets. The same logic does not hold in cyberspace.\nWhy are in kind retaliations or other forms of punishment not viable solutions for most retaliations in cyberspace? First, a state must fulfill the burden of proof in identifying the perpetrator of an action. All the above IPB and potential for retaliation still depends upon attribution of who, what, and potentially why an attack occurred.59 Retaliation absent strong evidence is likely to lead to misidentification and unnecessary escalation.\nSecond, a state must retaliate within a proximate temporal range. If state X does not have detailed intelligence on the asset it wishes to retaliate against, developing intelligence along with a cyber weapon to target it increases the time horizon of response such that it is days, weeks, months or even years out from the original attack for which it is retaliating. Due to this temporal disconnect, the threat to punish in response to a given action falls into a category of what economists refer to as hyperbolic discounting. The risk of punishment for an attack is possible but so temporally, distant as to be discounted to the point of irrelevance.\nThird, deterrence by punishment requires proportionality. It is necessary to have comparable assets to punish to prevent escalation or violations of international law.60 Comparable assets are not a given within cyberspace and are often difficult to identify.61 To punish an asset within a domain requires pre-established access or knowledge of that asset beyond its location. Whereas a city is immovable and likely to be as susceptible today as it will be tomorrow to a missile or bomb, a computer system that is penetrated today for prepositioned access, might be patched, upgraded or taken offline tomorrow.\nFourth, a state must possess a specific cyber weapon system tailored to its target. If state X alerts state Y that it is going to punish an asset or state X uses a repeated cyber weapon to attack state Y’s system, it is likely to be ineffectual the longer it is used due to updated perimeter defenses, such as intrusion detection and prevention systems (IDPS), antivirus programs or a variety of other security measures. If state X wants to punish state Y it must have knowledge of the attributes of the asset it wishes to retaliate against and what the status of that asset is. State X must also develop new exploits to achieve effects or be confident that State Y has not accounted for previous exploits that have been used.\n\nThe challenges of signaling deterrence by punishment are numerous within cyberspace whether the conflict is contained within domain or crosses over domains. Advances in attribution within a timely manner and the availability and reasonable assumption that proportional assets of an adversary can be held at risk need to be improved to credibly threaten punishment. This is a challenge not isolated to within domain retaliation. While proportional target selection might be slightly easier in cross-domain retaliation, the first three issues raised above are still relevant.\nDeterrence by punishment in cyberspace is possible, but it is not a reliable or credible option under most conditions absent sufficient and sustained intelligence. This assessment is not unique and is borne out in the analysis of Valeriano and Maness, who find that deterrence via punishment is generally ineffective and likely more dangerous than other means of preventing attacks.[62] Moreover, sustained invasive intelligence into adversary networks creates its own unique problems, including a security dilemma.[63] The more states engage in highly invasive intelligence via cyberspace, the more their actions are likely to be misinterpreted. Differentiating between various forms of cyber actions are difficult and can lead to miscalculation.[64]\nFigure 1 illustrates the relationship between attacking and defending forces and area where both forms of deterrence function.\n\nAs seen in Figure 1, deterrence by threat of punishment and denial operate within the same temporal ranges, yet while attribution matters a great deal for threats of punishment they are generally unimportant for denial. In their initial stages both denial and punishment focus on ante-impetum means of dissuasion, yet deterrence by punishment necessarily needs post-impetum attribution for it to be used. Based on the technical realities of cyberspace and of international relations deterrence by threat of punishment is more complicated and difficult to effectively establish.\n# 5. TECHNICAL CHALLENGES AND OPPORTUNITIES: DETERRENCE BY DENIAL Both deterrence by denial and punishment require ante-impetum costs by the defender. The allocation of resources between denial and deterrence and the efficiency with which they deter adversaries differ. The establishment of credible deterrence by denial often starts with the allocation of financial capital to purchase technical resources and provide human capital sufficient to continually update, enhance, audit and manage complex network infrastructure.[65] Network-based and host-based defenses such as intrusion detection and prevention systems, anti-virus products and similar systems are some of the variety of overlapping expenditures that can be undertaken to increasingly make the intrusion of adversaries into a given network more difficult.[66] In cyberspace, such expenditures are regularized and often included as overhead costs, however they are deterrent in nature.[67] Although they are not glamorous, they substantially decrease the probability of penetration. The same types of deterrence strategies are used by stores in placing electronic tracking tags on their products and detectors at doors, by banks in the construction of vaults, silent alarms and dyed packets of money, by critical infrastructure in extending the perimeter of security outward to prevent vehicle-borne improvised explosive devices, increased numbers of security guards, cameras and the use of razor wire or other physical structures. These devices signal to adversaries both criminal and terrorist alike that the costs of successfully perpetrating an attack are high and that the likelihood of success is low, although both terrorist and criminal deterrence models include deterrence by punishment through criminal proceedings and potential lethal actions against terrorist they rely far more heavily on preventive measures that deny would be adversaries.\nSceptics might contend denial mechanisms are unlikely to deter a state, yet this is in and of itself not accurate. The vast majority of probes by states do not translate into successfully attacks. The US Department of Defense suffers from millions of probes [65] Riggs, Cliff. (2004). *Network Perimeter Security*. New York: Auerbach Publications.\n[66] Buecher, Axel, Per Andreas, and Scott Paisley. 2009. “Understanding IT Perimeter Security”. IBM. http://www.redbooks.ibm.com/redpapers/pdfs/redp4397.pdf.\n[67] Filkins, Barbara. 2016. “IT Security Spending Trends”. SANS. https://www.sans.org/reading-room/whitepapers/analyst/security-spending-trends-36697.\n\nUnlike in any other battlespace, whether conventional kinetic terrorism, conventional kinetic or mass destruction military force, the opportunities for deterrence by denial are substantial in cyberspace and unique. While denial opportunities in land, sea, air, and even space are predicated on the control of a given geospatial area, the party establishing deterrence by denial has limited abilities to manipulate the nature of the domain itself. The same is not true within cyberspace. Every aspect of a defender’s cyberspace from the structure of the network, to the hardware, firmware, and software within a network, to the access of individuals within and external to that network is manipulable. At every stage of an attack an adversary is always attempting to operate on or against the defender’s cyberspace over which it has no control and has limited visibility.\nFor denial, the historical literature of deterrence theory remains relevant, in particular the second and third stages of deterrence which focused on rational game theoretic and cognitive modeling. While in conventional deterrence the emphasis was on punishment, here these same modeling techniques find applicability in deterrence by denial. Although the games might be the same, the payoffs in cyberspace manipulable and favor the defender. In few other applications of deterrence are the payoff matrices of deterrence so favorable to the defender. Despite the favorability of conditions, the ability to manipulate the potential payoff for attackers remains difficult. Although possible for defenders to reduce the probability of attack success, the potential payoff for a successful attack can remain large.\nDespite conditions favoring defenders, the potential payoffs are often not affected by deterrence by denial. Minimizing the potential payoffs from attacks on data repositories requires disaggregation of data. These types of denial mechanisms come with efficiency or financial costs. Although denial offers more potential than punishment, it is not a silver bullet to the cyber deterrence problem. Denial decreases the probability of success for attackers and is likely to reduce classes of actors focused on certain targets. Despite efforts to signal through the purchase and implementation of various defensive measures, the re-architecting of network infrastructure, the cyber deterrence problem remains.\n⁶⁸ Howard, Travis, and Jose de Arimateia de Cruz. 2017. “The Cyber Vulnerabilities of the US Navy”. *The Maritime Executive*. January 31, 2017. https://maritime-executive.com/article/the-cyber-vulnerability-of-the-us-navy.\n# 6. BEYOND THE DETERRENCE PROBLEM If punishment and denial are unable to fully remediate the cyber deterrence problem, are there any meaningful solutions? The core debate remains, with no simple and readily apparent solutions. The search for a single solution is likely to remain fruitless for the foreseeable future. Deterrence has never been the single tool within the toolbox of the state to dissuade or shape adversary behavior. Rather, it has always been combined with efforts that extend beyond traditional concepts of deterrence to include geopolitical and technical practices including norm development, entanglement, cumulative deterrence, research and development, policies and laws, liability structures for software and hardware, training for users and human capital development within information technology and cybersecurity.⁶⁹ Efficient and effective cyber deterrence should extend international politics and include fields such as criminology, immunology and public health.⁷⁰ The capacity of states to punish criminals is high and the credibility of punishment actions in developed nations is strong. Despite a capacity to punish criminal behaviors, they still occur. Extending beyond punishment, states also focus on denying criminals opportunities to commit crimes. Yet crime still occurs. The root causes of crime are not simple nor isolatable to a single phenomenon. Likewise, states engage one another in cyberspace for a variety of reasons. Some reasons fit within conventional deterrence frameworks of denial and punishment and do not suffer from challenges with attribution. For instance, larger and more harmful attacks increase the probability of attribution. However, many states remain perturbed by the death by a thousand cuts phenomena which falls below thresholds and required to provide timely attribution.\nShifting the focus away from within domain deterrence focused solely on punishment and denial and changing the emphasis to a basket of strategies focused on reducing incentives, availability and anonymity fosters an environment less conducive both to hostile actions and potential malicious actors. The solution to the deterrence problem is not abandoning it, but expanding the range of alternative strategies not presently considered. By acknowledging the failures and inadequacies of deterrence strategies and the potential places where novel strategies found in other fields are applicable the intractable problem of cyber deterrence becomes more manageable.\n⁶⁹ Nye. 2017: 45-69; Tor, Uri. 2017. “‘Cumulative Deterrence’ as a New Paradigm for Cyber Deterrence”. *Journal of Strategic Studies* 40(1-2): 92–117.\n⁷⁰ Jaishankar, K. 2011. *Cyber Criminology: Exploring Internet Crimes and Criminal Behavior*. Boca Raton, FL: CRC Press; Brantly, Aaron “Epidemiological Approaches to National Cybersecurity”. In *US National Cybersecurity: International Politics, Concepts and Organization*. Edited by Damien Van Puyvelde and Aaron Franklin Brantly. 2017. New York: Routledge.\n49"
    }
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 86.0,
      "success_occurrences": 86.0,
      "success_unique": 43.0,
      "bib_unique_total": 67.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.6417910447761194,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 5.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 36.0,
        "highest_intext_index": 41.0,
        "missing_footnotes_for_seen_total": 5.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 86.0,
        "success_occurrences": 86.0,
        "success_unique": 43.0,
        "bib_unique_total": 67.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.6417910447761194,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 7.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 99.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "2018 © NATO CCD COE Publications, Tallinn",
    "subtitle": "abrantly@vt.edu",
    "document_type": "conference_paper",
    "venue": "2018 10th International Conference on Cyber Conflict",
    "publication_year": 2018,
    "authors": [
      "T. Minárik",
      "R. Jakschis",
      "L. Lindström (Eds.)",
      "Aaron F. Brantly",
      "Assistant Professor",
      "Virginia Polytechnic",
      "United States"
    ],
    "affiliations": [
      "Assistant Professor, Department of Political Science",
      "Virginia Polytechnic and State University"
    ],
    "emails": [
      "abrantly@vt.edu"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "What is the role of deterrence in an age where adept hackers can credibly hold strategic assets at risk? Do conventional frameworks of deterrence maintain their applicability and meaning against state actors in cyberspace? Is it possible to demonstrate credibility with either in-domain or cross-domain signaling or is cyberspace fundamentally ill-suited to the application of deterrence frameworks? Building on concepts from both rational deterrence theory and cognitive theories of deterrence this work attempts to leverage relevant examples from both within and beyond cyberspace to examine applicability of deterrence in the digital age and for digital tools in an effort to shift the conversation from Atoms to Bits and Bytes.",
    "keywords": [
      "cyber",
      "deterrence",
      "denial",
      "punishment"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "http://nationalinterest.org/blog/the-buzz/the-price-the-new-b-21-stealth-bomber-sorry-thats-secret-16604",
        "http://aviationweek.com/site-files/aviationweek.com/files/uploads/2015/07/asd_08_06_2015_dossier.pdf",
        "https://foxtrotalpha.jalopnik.com/heres-russias-s-400-missile-system-in-action-and-heres-1746490022",
        "http://www.latimes.com/opinion/op-ed/la-oe-morris-iron-dome-disastrous-for-israel-20140822-story.html",
        "http://s3.documentcloud.org/documents/1212530/14f00304-documents.pdf"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 55,
    "heading_count": 8,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_identifier"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 86,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.11627906976744186,
      "footnote_coverage": 1.0,
      "unique_index_count": 43
    },
    "footnotes_quality": {
      "intext_total": 5,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.2,
      "footnote_coverage": 0.0,
      "unique_index_count": 5,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 86,
        "superscript_definition_lines": 43,
        "numeric_bracket_hits": 16,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 67.0,
      "dominant_bib_coverage_rate": 0.6417910447761194,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 8,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": true,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": true,
        "persistent_identifier": false,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 7,
        "affiliations": 2,
        "emails": 1,
        "orcids": 0,
        "keywords": 4,
        "doi": 0,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 5
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 1.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_identifier"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_persistent_identifier"
      ]
    },
    "flags": [
      "missing_preceding_text",
      "footnotes_bucket_unresolved",
      "meta_missing_persistent_identifier"
    ]
  },
  "updated_at_utc": "2026-02-14T08:27:38.196017+00:00"
}