{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\4ALCTATC\\Kostyuk - 2021 - Deterrence in the cyber realm public versus private cyber capacity.pdf",
  "custom_id": "38",
  "response": {
    "id": "batch-b6235e9e-39-918f86d7-c360-4f11-9d1a-4b8137937e68",
    "custom_id": "38",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "International Studies Quarterly (2021) 65, 1151-1162\n\n# Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\n\nNADIYA KOSTYUK\nSchool of Public Policy, Georgia Institute of Technology, USA\n\nCan cyber deterrence work? Existing scholarly works argue that deterrence by punishment using cyberattacks is ineffective because the difficulty of attributing the origin of cyberattacks makes the threat of future attacks less credible. However, these works have told us relatively little about the deterrence ability of public cyberinstitutions (PCIs), defined as publicly observable proactive efforts aimed at signaling a country's level of cyber offensive and defensive capability. This research shows that middle powers (that have scarce cyber arsenals) can use PCIs to deter cyber attacks that cause significant damage to their economy and prosperity; however, this deterrent capability is rather limited. Using an incomplete-information model, we demonstrate that PCIs only deter adversaries that are susceptible to the costs created by these institutions. Despite this limited deterrence ability, middle powers tend to over-invest resources in these cyberinstitutions: Weak cyber states tend to over-invest to convince strong cyber adversaries that they are strong, whereas strong cyber states over-invest so that adversaries do not believe that they are weak states pretending to be strong. By doing so, states reduce their overall cybercapacity. We establish the empirical plausibility of these results using election interference campaigns as examples of strategic attacks. Our focus on the strategic use of PCIs as a deterrent represents a departure from existing literature—which has focused only on cyberoperations—and has important policy implications.\n\nPuede funcionar la ciberdisuasión? Los trabajos académicos existentes sostienen que la disuasión mediante el castigo de los ciberataques es ineficaz porque la dificultad de atribuir el origen de los ciberataques hace menos creíble la amenaza de futuros ataques. Sin embargo, estos trabajos nos han aportado relativamente poco sobre la capacidad de disuasión de las ciberinstituciones públicas (Public Cyberinstitutions, PCI), definidas como esfuerzos proactivos públicamente observables destinados a señalar el nivel de capacidad ciberofensiva y defensiva de un país. Esta investigación muestra que las potencias medias (que disponen de escasos arsenales cibernéticos) pueden utilizar las PCI para disuadir los ciberataques que causan un daño importante a su economía y prosperidad; pero esta capacidad de disuasión es bastante limitada. Mediante un modelo de información incompleta, demostramos que las PCI solo disuaden a los adversarios que son susceptibles a los costos creados por estas instituciones. A pesar de esta limitada capacidad de disuasión, las potencias intermedias tienden a invertir en exceso sus recursos en estas instituciones cibernéticas: los ciberestados vulnerables tienden a invertir en exceso para convencer a los ciberadversarios fuertes de que son fuertes, mientras que los ciberestados fuertes invierten en exceso para que los adversarios no crean que son estados vulnerables que fingen ser poderosos. Al hacerlo, los estados reducen su cibercapacidad general. Determinamos la credibilidad empírica de estos resultados utilizando campañas de interferencia electoral como ejemplos de ataques estratégicos. Nuestro enfoque en el uso estratégico de las PCI como elemento de disuasión representa un cambio respecto a la literatura existente, que se ha centrado únicamente en las ciberoperaciones, y tiene importantes implicaciones políticas.\n\nLa cyber-dissuasion peut-elle fonctionner? Les travaux de recherche existants soutiennent que la dissuasion par une sanction reposant sur des cyber-attaques est inefficace car la difficulté de détermination de l'origine des cyber-attaques rend la menace de futures attaques moins crédible. Toutefois, ces travaux ne nous ont donné que relativement peu d'informations sur la capacité de dissuasion des cyber-institutions publiques, qui est définie comme étant constituée des efforts proactifs publiquement observables visant à signaler le niveau des cyber-capacités offensives et défensives d'un pays. Cette recherche montre que les puissances intermédiaires (qui disposent de cyber-arsenaux limités) peuvent avoir recours aux cyber-institutions publiques pour dissuader les auteurs de cyber-attaques nuisant considérablement à leur économie et à leur prospérité, mais cette capacité de dissuasion est plutôt limitée. Nous nous appuyons sur un modèle d'information incomplète et nous démontrons que les cyber-institutions publiques ne dissuadent que les adversaires qui sont sensibles aux coûts engendrés par ces institutions. Malgré cette capacité de dissuasion limitée, les puissances intermédiaires tendent à surinvestir des ressources dans ces cyber-institutions : les cyber-États faibles tendent en effet à surinvestir pour convaincre leurs puissants cyber-adversaires qu'ils sont forts, tandis que les cyber-États forts tendent à le faire afin que leurs adversaires ne croient pas qu'ils sont faibles alors qu'ils se prétendent forts. Ce faisant, les États réduisent leur cyber-capacité globale. Nous établissons la plausibilité empirique de ces résultats en nous basant sur les campagnes d'ingérence électorale comme exemples d'attaques stratégiques. Notre concentration sur l'utilisation stratégique des cyber-institutions publiques comme dissuasion diverge de la littérature existante qui s'est uniquement concentrée sur les cyber-opérations et a d'importantes implications politiques.\n\n\"To those thinking about trying to influence the outcome of the elections in our country: Stay away!\" (as quoted in Cederberg 2018, 11). Sweden's Prime Minister Stefan Löfven articulated this warning and the country's willingness to act in the event of election interference at a security conference in January 2018. The Swedish government\n\nNadiya Kostyuk is an Assistant Professor, School of Public Policy, Georgia Institute of Technology.\nAuthor's note: I would like to thank Erica Borghard, Aaron Brantly, Ben Buchanan, John Ciorciari, Fiona Cunningham, Tiberiu Dragu, Mathias Frendem, Andres Gannon, Erik Gartzke, John Leahy, Susan Landau, Herb Lin, Jon Lindsay, Shawn Lonergan, Carla Martinez Machain, Tamar Mitts, James D. Morrow, Jacquelyn Schneider, Jeffrey W. Taliaferro, Brandon Valeriano, Ketian Zhang, Yuri M. Zhukov, and the participants of the Peace and Science Society International pre-conference workshop, of the Student Cybersecurity Symposium at Tufts University, of the International Security Seminar at the Belfer Center for Science and Technology at Harvard Kennedy School, of the Peace Science OPSC, and of the Cybersecurity Series at the Stanford Center for International Security and Cooperation. This paper was presented at the 2019 International Studies Association Conference.\n\nKostyuk, Nadiya (2021) Deterrence in the Cyber Realm: Public versus Private Cyber Capacity. International Studies Quarterly, doi: 10.1093/isq/sqab039\n\n© The Author(s) (2021). Published by Oxford University Press on behalf of the International Studies Association.\n\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 1,
            "markdown": "Deterrence in the Cyber Realm\n\nsubstantiated this rather bold statement with a number of measures meant to deter potential intruders. Specifically, in preparation to its September 2018 election, the country created a number of public cyberinstitutions (PCIs)—publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities.\n\nSome of these measures aimed at creating better cyber defenses to “raise the threshold [of] attacking Sweden” (National Cybersecurity Policy 2017, 19). Specifically, the government increased the budgets of existing agencies to include election protection into their scope, and it established new agencies, forums, and programs to protect against election interference and disinformation campaigns. For instance, the Swedish government’s crisis preparation and response agency became the main authority for election coordination. The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’” (SverigesRadio 2017). Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats (Cederberg 2018). Media, political parties, and schools ran similar education campaigns. To prepare for total defense awareness, including cases of cyber emergencies, MSB also sent a pamphlet titled “If Crisis or War Comes” to all 4.7 million households.\n\nIn addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats (Rettman and Kirk 2018). The National Defense Radio Establishment and the Military Intelligence and Security Service installed special detection and warning systems to guard against foreign powers hacking into sensitive agencies. The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators” (O’Dwyer 2018).\n\nWe argue that these PCIs established by the Swedish government in order to protect its 2018 elections convinced the Russian government that an interference campaign would have been too costly. Why were PCIs successful in deterring a potential interference campaign? Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy (Fernandino 2018)—under what conditions can PCIs deter any strategic cyberattack?\n\nTo answer these questions, we develop an incomplete-information model in which a challenger considers attacking a defender. The defender in this case is a middle power, since these nations have scarce cyber arsenals and are more likely to invest in PCIs for deterrence. The challenger is not certain about the defender’s cybercapacity—how cyber “strong” or “weak” it is—and can only infer it from the defender’s observable PCIs. Thus, the challenger’s decision to attack depends on the defender’s type, and the defender has an incentive to over-invest in public cybercapacity in order to signal that it is stronger that it actually is.\n\nThis model leads to several insights. First, there is a large number of equilibria for which PCIs have no influence on the challenger. Second, we show that the defender’s strategic use of PCIs to deter the challenger works only when two conditions are met: (1) the challenger believes that the defender possesses significant cybercapabilities and that it would therefore be too costly to attack the defender; and (2) the challenger is susceptible to the cost exacted by PCIs. This finding shows that PCIs influence the challenger’s decision to attack only in limited cases. Despite that, weaker defenders over-invest in PCIs to signal higher cybercapacity than they possess, and strong defenders over-invest so that their adversaries do not believe that they are weak states pretending to be strong.\n\nThis paper makes a number of theoretical contributions to the existing international-relations literature. First, it helps us better understand the nature of deterrence in the information age. Our unique strategic logic of PCIs as a proxy for a country’s cybercapacity represents a departure from existing literature. While most scholarly works on cyber-to-cyber deterrence focuses on deterrence by punishment using cyberoperations (Baliga, de Mesquita, and Wolitzky 2020; Valeriano, Jensen, and Maness 2018), this project presents a new theory that explains how PCIs can deter by both prevention and by threat of punishment, by signaling an increase in both defensive and offensive cybercapabilities. This project also contributes to the literature on cross-domain deterrence (Gartzke and Lindsay 2019) by explaining situations in which countries use PCIs to deter their adversaries instead of non-cyber foreign policy options (i.e., economic sanctions, or diplomatic or military responses) that are ineffective and/or costly.\n\nSecond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). We, instead, seek to explain the strategic behavior of weaker cyber states or middle powers that suspect a cyberattack. In these situations, middle powers often must rely on their own cybercapabilities because their allies are unlikely to help. Cyberdefenses are unique to each country and not easily transferable; close allies are often reluctant to disclose information about their offensive cybercapabilities and/or commit cyberattacks on an ally’s behalf (as compared with their willingness to offer military assistance during territorial invasions).\n\nThe literature on the “bargaining model of war” focuses on how private information and incentives to misrepresent, and commitment problems affected by power shifts, explain costly armed conflict (e.g., Schultz 1998; Slantchev 2003, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power (Morrow 1989); states also tend to keep certain capabilities secret to obtain military advantage (Reiter 2003).\n\nWhat is new about our model then? First, a different theoretical foundation drives how nations signal their cybercapacities. Unlike in the case of military capacity, a state cannot launch a parade to signal its cybercapacity. Satellite images are also unlikely to be useful to adversaries seeking to estimate a state’s cyberstrength. An executed cyberattack may provide a target with a good estimate of the attacker’s capabilities, but such an attack de-values capability because it provides the target with instructions on how to fix flaws in their own networks and systems. The time-limited life-span and the dynamic nature of cyberoperations further complicate their signaling potential. While the basic parameters for most traditional weapons remain relatively static,\n\n1 In addition to election interference campaigns, attacks against critical infrastructure are other examples of strategic cyberattacks.\n\n2 Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by “burning” their covert cybercapabilities to demonstrate their ability to acquire such capabilities.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 2,
            "markdown": "NADIYA KOSTYUK\n1153\n\nstrategically relevant features of certain cyberweapons might look quite different tomorrow. Signaling cybercapacity via PCIs, on the other hand, (1) preserves the value of a state's cyberoperations, which diminishes after use; (2) signals organizational capability that is not about specific secret vulnerabilities, which are ephemeral and easily compromised, but the ability to readily produce and use those vulnerabilities in complex operations for political ends; and (3) provides the adversary with an immediate, often rough proxy for the state's cybercapacity.\n\nSecond, existing models focus only on whether and how investment in military capacity can deter a future attack or affect the likelihood of winning a war. Our theoretical foundation instead explains that sources of state cybercapacity are more diverse, lie beyond military and government, and extend to a state's private sector and even public-opinion management. While investing in military cybercapacity is important for deterrence by the threat of punishment, to deter adversaries by prevention, states might, for example, invest significant resources into building public awareness about the danger of cyberoperations and information operations, making potential election-interference campaigns harder.\n\nRegarding the model, the closest work, which focuses on the relative impact of scarce resource allocation on the likelihood of attack, is Arena and Wolford (2012). Unlike Arena and Wolford (2012), which examines a state's decision to allocate its resources between armaments and intelligence gathering capabilities in order to reduce uncertainty over its opponent's military strength, our model explores a state's decision to allocate its resources between public and private cybercapacity in order to deter its strong opponent from executing a cyberattack against the state. Similarly to works on counter-terrorism policies (Bueno de Mesquita 2007; Dragu 2011), our model explains why nations over-invest in public capacity and that such policies are generally ineffective in deterring adversaries.\n\nBaliga, de Mesquita, and Wolitzky (2020) and Welburn, Grana, and Schwindt (2019) are the only two other models that focus on cyberdeterrence; they explore how a state's inability to correctly attribute the origin of cyber operations and to detect cyberattacks affects the state's chances of deterring potential attackers. Unlike these models, our model focuses on organizational capability which signals the state's ability to readily produce and use covert cybercapacity. Unlike Baliga, de Mesquita, and Wolitzky (2020)'s model, in which there is uncertainty over the signal's sender (i.e., the attacker's identity) while the signal's quality (i.e., the strength of cybercapacity) is clear, our model investigates situations in which the signal's sender is known but the signal's quality is unclear. Unlike Welburn, Grana, and Schwindt (2019)'s model, in which a defender can signal any cybercapability with no cost, our model explains how the defender's choice to allocate its limited resources translates into observable cybercapacity.\n\nThe paper proceeds as follows. We start with explaining how a state can signal its cybercapacity. Then, we explain when and how public cyberinstitutions can deter strategic cyberattacks. Next, we introduce the model and derive the model equilibria. We use illustrative examples from elections to establish the empirical plausibility of our theory. We conclude with a discussion of our study's implications.\n\n## Signaling Cybercapacity\n\nStates can signal their cybercapability by (1) attributing cyber operations (COs) to attackers; (2) executing COs against adversaries; and (3) establishing public cyberinstitutions—publicly observable efforts aimed at demonstrating a country's level of offensive and defensive cybercapability. Each of these methods has its pros and cons.\n\nSignaling cybercapacity via attribution is a recent trend, as demonstrated by the number of US indictments. Attribution is a powerful deterrent because it signals to both the attacker and future perpetrators that they are not as invisible as they would like to be in cyberspace. But cyber attribution is difficult and costly: Not only does cyber attribution require significant resources and technical expertise to correctly attribute an attack to a specific computer, but it also demands intelligence to connect the used computer to a perpetrator. Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources (Clark and Landau 2011; Egloff and Wenger 2019). As a result, only a few nations have the resources, technical expertise, and political will to use attribution as a way to signal their cybercapability.\n\nSignaling cybercapacity via covert COs provides the target with an accurate estimate of the attacker's capability. However, the difficulty of attributing the origin of COs and the time it takes to do so diminish the signal's value, which is further reduced by the time-limited life-span and the dynamic nature of COs. Moreover, if a victim is not able to attribute the attack or remains quiet about the attack, the signaling value of COs is either zero or quite low. Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons (Gartzke 2013); only a few nations have a large enough cyber arsenal that they can burn some of their exploits for signaling purposes.\n\nWhile cybercapacity cannot be revealed because it depends on secret access and vulnerabilities, the state can reveal its ability to find such vulnerabilities by establishing PCIs, defined as publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities. PCIs signal an increase in organizational cybercapability, which demonstrates the state's ability to readily produce cybercapability and use cyberoperations for political purposes. As a result, signaling via PCIs provides the state's allies, adversaries, and domestic and international audiences with an immediate, often rough proxy for the state's cybercapacity and preserves the value of the state's covert COs.\n\nFor simplicity, I distinguish two ways in which a state can establish its PCIs: It can (1) create a new agency program, initiative, doctrine, strategy, or policy to address some aspect of cybersecurity; and/or (2) add new cyber roles to existing agencies or new cyber provisions to existing policies. For instance, to deter election interference campaigns, Sweden established an agency responsible for psychological defense. When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time (Schwirtz 2017).\n\n5Some of these works include Debs and Monteiro (2014), Fearon (2018), Kydd (2000), Meirowitz and Sartori (2008), and Slantchev (2005).\n\n4Germany's hack-back strategy is a PCI even though the government does not give any details regarding the scope of this strategy. Since they publicly discussed its development (instead of only privately executing it), we have an idea of the steps that the German government considers adopting in order to deter election interference. If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage (Schwirtz 2017). For instance, in response to the attack against the parliament, the German government could remove servers on which stolen parliament data were located.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 3,
            "markdown": "1154\nDeterrence in the Cyber Realm\n\nEven though these two options differ in how governments created their PCIs, they both might involve a similar set of measures. Specifically, a new agency and a new strategy might require additional budget, stuff, training, and expertise. While PCIs often do not reveal all the details about created cybercapacity, unlike covert cyberactivity they allow an adversary to estimate the scope of the change and the potential resulting increase in the target state's cybercapacity. The Swedish and German actions, for instance, signaled that both countries prioritized spending their resources on building better cyber defensive and offensive capabilities to deter potential election interference campaigns.\n\nBefore we explain how PCIs can deter adversaries, we would like to clarify that our theory focuses on middle powers—the nations that have scarce cyber arsenals and are more likely to invest in PCIs as a means of deterrence. Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by \"burning\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities.⁵\n\n## The Theory of Cyber Deterrence\n\nThe theory presented in this section examines the specific context in which a strong challenger (including cyber powers) contemplates a strategic cyberattack against a defender.⁶\n\nWhen the challenger considers a cyberattack, he calculates the value he can gain from this attack (e.g., undermining democratic processes, in the case of election interference) and the cost he can incur. There are two types of costs. First is the cost of the defender's potential retaliation (e.g., using economic sanctions, military operations or cyberoperations). Second is the tendency of cyberoperations—unlike military operations—to diminish in value after their first use. A tank, for example, can be successfully deployed many times over many years. Cyberattacks, on the other hand, often lose their effectiveness after their first use, even if the attack fails due to the defender's defenses. In using cyberattacks, the challenger risks the possibility that the defender might be able to develop protection against similar attacks in the future.\n\nWe argue that, for a challenger to decide to use a cyberattack against a defender, it must believe that the attack's value will outweigh its cost. What can change this cost-benefit calculation? Specifically, what can raise the cost enough to deter the challenger?\n\nWe assume that the costs from non-cyber foreign policy tools (i.e., diplomatic or military responses, or economic sanctions) will not change the cost-benefit calculation because the challenger has considered them initially. These costs are easy to estimate using the defender's past history and are highly predictable based on the challenger's \"prior beliefs about the defender's willingness\" to use one\n\n⁵Some anecdotal evidence suggests that even though the US government could not hack back in response to the election, it went into Russian servers and left non-malicious code that had \"U.S. Cyber Command\" in the comments. They did so to signal to the Russians, in a covert way, that they had the ability to strike whenever they wanted.\n\n⁶I employ the language from the traditional deterrence literature and refer to an adversary as a challenger and a defending state as a defender. The model makes the assumption that the defender attempts to deter her strongest challenger, which is the challenger that can potentially cause the most significant damage. If she is able to deter her strongest challenger, then all her other challengers will be deterred by default. Because the model focuses only on the strong challenger, I have omitted \"strong\" and refer only to a \"challenger\" for the remainder of the paper.\n\nof these options (Fearon 2002, 6). Moreover, given that the defender's capability in non-cyber foreign policy domains is unlikely to change rapidly, the challenger's estimate of the costs imposed by diplomatic responses and economic sanctions is likely to be fairly accurate. The challenger is also aware that military responses are costly and that the defender is unlikely to launch a military strike in response to information operations or cyberoperations.⁷\n\nEven though these non-cyber foreign policy tools cannot change the challenger's cost-benefit calculation, the challenger considers the defender's capability in these non-cyber domains when forming its opinion of the defender's cybercapacity. Since nations with significant resources and expertise can build sophisticated cyber weapons (Gartzke 2013), the challenger can accurately conclude that the most powerful military nations have impressive cyber arsenals. While the country's military capability might often be correlated with its cybercapacity, it is not always the case because some nations might choose to purchase cyber weapons from third parties or work with proxy groups to execute attacks on their behalf. Despite that we argue that both the defender's capability in non-cyber and the defender's capability in cyber domains form the challenger's prior belief of the defender's cybercapacity.\n\nGiven that the challenger is quite certain about the costs associated with non-cyber responses and, as a result, is unlikely to be deterred by them, the defender is left with cyber foreign policy tools to deter the challenger from executing cyberattacks. We argue that cyber foreign policy tools may raise the cost of a cyberattack for the challenger because the challenger remains uncertain about the defender's cybercapacity. Even if the challenger has a rough estimate of the defender's cybercapacity, the dynamic, time-limited nature of cyber tools makes it difficult for the challenger to determine the defender's cybercapacity with precision or certainty. Specifically, while the basic parameters for most traditional weapons remain relatively static, strategically relevant features of certain cyber weapons can change significantly over a short period of time. Moreover, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it (Axelrod and Iliev 2014). We explore this challenger's uncertainty over the defender's cybercapacity as the main mechanism that affects the probability of successful deterrence.⁸ How can the defender signal its cybercapacity\n\n⁷The Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations (Newman 2019).\n\n⁸For deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity (Schelling 2008). Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high (Press 2005). Moreover, as earlier explained, many nations cannot afford to \"burn\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities, and those that do send a rather costly signal about their sophisticated cyber arsenal. Furthermore, many countries conduct cyber espionage to observe other countries' cyberattack plans and capabilities. As a result, cyber powers that consider challenging other nations probably know enough about other countries' covert cyber strength to know whether they face another cyber power or not, though they do not necessarily know its precise capabilities. Thus, there is no uncertainty about the capabilities of these cyber powers; instead, this theory explores uncertainty over the capabilities of weaker nations—middle powers—and specifically how cyber \"strong\" or \"weak\" they are. These nations tend to have a rather scarce cyber arsenal and are more likely to invest in PCIs as a means of deterrence. However, the better a challenger's cyber-intelligence, the less uncertainty the challenger has about the defender's cybercapacity.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 4,
            "markdown": "NADIYA KOSTYUK\n1155\n\nso it increases the challenger's uncertainty about the defender's cybercapacity? By attributing COs to the challenger, the defender reveals some of its capabilities, reducing uncertainty about its capacity. Signaling by executing COs against the challenger does not help achieve the desired result either. If COs are correctly attributed to the defender, COs quite accurately signal the defender's cybercapacity, improving the challenger's estimates of the defender's cybercapacity. If COs are incorrectly attributed to a third party or not attributed at all, the defender uselessly burns its exploits without changing the challenger's beliefs about the defender's cybercapacity. Since signaling via attribution and signaling via COs are unlikely to increase the challenger's uncertainty about the defender's cybercapacity, the defender is left with PCIs to deter strategic cyberattacks.⁹\n\n## Deterrence by PCIs\n\nPCIs can leave the challenger uncertain about the defender's cybercapacity because they demonstrate the defender's ability to produce cybercapability without revealing any concrete details about this capability. PCIs can deter by prevention and/or by threat of punishment.¹⁰ These two types of deterrence are associated with the two types of costs that PCIs can inflict on the challenger, increasing the cost of its cyberattack. PCIs can deter by prevention because adversaries may infer that their attacks are likely to fail against the defenses implied by a PCI. Firewalls, updated computer software, programs aimed at educating public about cyberthreats, and policies that outline a set of measure to provide better security of critical infrastructure are examples of PCIs that can deter by prevention because they make hacking more difficult. While the challenger can keep using conventional weapons even if a conventional attack fails, the challenger often burns its cyber exploits in the case of an unsuccessful cyberattack. This is because having discovered an attempted hack, the defender can close the existing vulnerability making the future use of this exploit impossible. PCIs can also deter by the threat of punishment; for instance, new military doctrines and units signal the state's ability to use its cyber weapons in response to cyberthreats.\n\nWe investigate situations in which both deterrence mechanisms are at play for the following two reasons. First, one cyberinstitution can signal both cyber offensive and defensive capability, making it hard to separate deterrence by the threat of punishment from deterrence by prevention. The US Department of Defense Cyber Strategy (2015, 3), for instance, uses deterrence by prevention by specifying the Department of Defense's role in defending its information networks, and it uses the threat of punishment by establishing a Cyber Mission Force to be used to defend the United States against cyberattacks of \"significant consequence\". Second, when facing a strategic cyberthreat, states tend to respond with multiple PCIs and, as a result, implement both types of deterrence at the same time to maximize their chances of success.\n\nSince PCIs can increase uncertainty about the defender's cybercapacity raising the probability of successful deterrence, the defender might want to invest most, if not all, of its resources into PCIs. But such a strategy takes valuable resources away from covert cyberactivity (CCA) or private cybercapacity, which involves secret development of cybercapabilities and ongoing cyberoperations.¹¹ For instance, a polished strategy document, newly-constructed headquarters, or a new initiative meant to bring public awareness of cyberthreats is a poor substitute for a CCA aimed at penetrating the challenger's electricity grid and preparing for a future attack that could be used for retaliation.\n\nWe argue that this trade-off between PCIs and CCAs is important. Even though some PCIs involve the development of private cybercapability (e.g., the German's hack-back strategy), such PCIs give a high-level view on what capacity a government develops whereas CCAs remain truly covert and only signal capability after being discovered and correctly attributed. The Stuxnet worm, which the US and Israeli governments developed and deployed in 2005 against an Iranian nuclear enrichment facility, was an example of such a CCA, until it was discovered in 2010. Even though the US government created a number of PCIs between 2005 and 2010 to signal an increase in its cybercapacity, none of them signaled the tremendous potential of the US cybercapability. Only the attributed Stuxnet worm signaled the true scope of the US cyber arsenal. Unlike PCIs, which send an immediate, although often imprecise signal about a state's level of cybercapabilities, the Stuxnet example demonstrates that CCAs send a more accurate signal of a state's cybercapabilities but this signal might be delayed.\n\nSince an investment in both PCIs and CCAs is important for overall cyber capacity, over-investment in PCIs at the expense of investment in CCAs can make a defender weaker. However, the relationship between the defender's overall cybercapacity and its chances at deterrence is not linear—i.e., an increase in one does not necessarily mean an increase in the other. Therefore, a defender with weak cybercapabilities might strategically invest more in PCIs if such an investment maximizes its chances at deterrence, even if it decreases its overall cybercapacity.\n\nWe argue that the effectiveness of this deterrent strategy depends on the type of the challenger. Specifically, it only works against a challenger that is susceptible to the costs created by PCIs. We call this challenger opportunistic. During the 2018 Swedish elections, Russia was an example of an opportunistic challenger. Having considered a potential interference campaign, the Kremlin realized that the rather small marginal value from this campaign was not worth the additional potential costs imposed by the improved defenses and offenses that Sweden created in the form of PCIs prior to the elections. But an over-investment in PCIs as a deterrent strategy does not work against an disinterested challenger; such challengers never attack, even if they give the impression that they are considering attacking. During the 2017 German elections, Russia was an example of a disinterested challenger. PCIs put in place prior to the 2017 elections had no\n\n⁹ It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.\n\n¹⁰ Given that early scholarly works perpetuated the offense dominance in cyberspace (Choucri 2012; Demchak 2011; Kello 2013), prevention is often seen as somewhat futile as it is nearly impossible to protect all vulnerable targets; thus, preemption may be a more cost-effective tactic. Recent works, however, refute the offense-dominance thesis (Gartzke 2013; Lindsay 2013). While it is easier to find a vulnerability in an adversary's network/system than to defend its own networks/systems from hundreds of possible cyberattacks, Slayton (2017) stresses the importance of looking at the cumulative effort required for building cyber offense or defense. Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\" (Slayton 2017, 74). Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense (Borghard and Lonergan 2017).",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 5,
            "markdown": "1156\nDeterrence in the Cyber Realm\n\n![img-0.jpeg](img-0.jpeg)\n![img-1.jpeg](img-1.jpeg)\n\nFigure 1. Defender’s cybercapacity: (a) relationship between defender’s observed and overall cybercapacity; and (b) relationship between defender’s type and her overall cybercapacity as a function of $I_{\\theta}$. Note: $I$: PCIs that $D$ can develop with $r$ units of resources; $N$: CCAs that $D$ can develop with $r$ units of resources; $I + N$: $D$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}$: the level of PCIs at which $D$’s overall cybercapability is maximized (point Max). Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $\\text{Max}_{S}(\\text{Max}_{W})$).\n\neffect on Russia’s decision to stay away from these elections because a combination of non-cyber factors shifted Russia’s cost-benefit calculus towards not attacking even before Germany establish its PCIs. Lastly, an over-investment in PCIs is also a waste of resources when the defender faces a undeterred challenger; such challengers always attack because the value of attacking is much higher than any additional costs created by PCIs. During the 2017 French elections, Russia was an example of an undeterred challenger. Having witnessed the worldwide impact of the mass disclosures of private data prior to the 2016 US elections, Moscow was willing to pay any cost and to risk any potential French (cyber or non-) retaliation for its influence campaign, which could help elect a pro-Kremlin candidate.\n\nThe next section models cyber deterrence by PCIs explicitly. It is worth noting that since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though the type of an attempted attack requires different types of PCIs, this does not affect the model logic and the obtained results.\n\n## Model\n\nThis section provides the intuition behind the game and the Online Appendix includes the detailed explanation and mathematical proofs.\n\n**Game Overview.** This is a game between a challenger ($C$, “he”) and a defender ($D$, “she”). $C$ considers executing a cyberattack against $D$. To deter $C$, $D$ decides how to signal her cybercapacity by allocating her resources between public and private cybercapacity and, as a result, which level of PCIs to implement. $D$ has a type $\\theta \\in [S, W]$ that differs in the amount of resources $a_{\\theta}$ available to her. The strong defender $D_{S}$ has many more resources available to her than the weak defender $D_{W}$. $\\theta$ is unobservable to the challenger.\n\nThe game starts with Nature’s choice. Nature selects that $\\theta = S$ with probability $\\pi$ and that $\\theta = W$ with probability $1 - \\pi$. The model assumes that both players have a common prior belief and that $\\pi$ is the true probability that the defender is strong. Then $D$ decides how to allocate her resources between PCIs and CCA. After $D$ implements PCIs, $C$ observes it, (possibly) updates his beliefs about $D$’s type, and decides whether he wants to attack $D$. When $C$ chooses whether to attack, $C$ observes $D$’s move but not $D$’s type. If $C$ does not attack, $D_{\\theta}$ successfully deters $C$ and the game\n\nends. If $C$ decides to attack $D_{\\theta}$, Nature selects that his attack is successful with probability $Q_{\\alpha}$, and unsuccessful with probability $1 - Q_{\\alpha}$. The probability of a successful attack is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. If $C$’s attack succeeds, $D_{\\theta}$ must decide whether to retaliate against $C$. If $D_{\\theta}$ does not retaliate against $C$, the game ends. If $D_{\\theta}$ retaliates against $C$, Nature selects that her retaliation is successful with probability $P_{\\theta}$ and is unsuccessful with probability $1 - P_{\\theta}$. The probability of a successful retaliation is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.[12]\n\n**Signaling Cyber Capacity.** To understand how $D$ can deter strategic cyberattacks, we must first understand how she can create her cybercapacity because $D$’s cybercapacity is a proxy for $D$’s ability to deter $C$. The higher $D$’s capacity is, the higher the likelihood that $D$ deters $C$. To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA.[13] Both PCIs and CCA create $D$’s overall cybercapability. As mentioned earlier, $D$’s overall cybercapability does not necessarily increase simply by investing more in her PCIs because such a strategy takes valuable resources away from CCA. As a result, it makes $D$ weaker.\n\nFigure 1(a) explains the intuition of how this works graphically. $C$ has a prior belief of $D$’s cybercapability, given COs attributed to $D$ or using various indicators of $D$’s technological development. Given the public nature of PCIs, $C$ can only observe PCIs and estimate $D$’s cybercapability. We call it $D$’s observed cybercapability and place it on the x-axis in Figure 1(a). The y-axis in Figure 1(a) represents $D$’s overall cybercapability that we receive by adding the resources that $D$ invests into PCIs and CCAs. Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.[14] The\n\n[12] We display this two-player game with incomplete information concerning $D$’s type in Online Appendix Section 1.1.\n\n[13] Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.\n\n[14] I assume that both $I$ and $N$ are increasing in $r$ and that there are diminishing returns to investment in each (i.e. $I'(r), N'(r) &gt; 0$ and $I''(r), N''(r) &lt; 0$).",
            "images": [
              {
                "id": "img-0.jpeg",
                "top_left_x": 387,
                "top_left_y": 160,
                "bottom_right_x": 802,
                "bottom_right_y": 457,
                "image_base64": null,
                "image_annotation": null
              },
              {
                "id": "img-1.jpeg",
                "top_left_x": 851,
                "top_left_y": 154,
                "bottom_right_x": 1268,
                "bottom_right_y": 457,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 6,
            "markdown": "NADIYA KOSTYUK\n\n![img-2.jpeg](img-2.jpeg)\nFigure 2. Equilibria and challenger's types. Note:  $C$ : a challenger;  $D_W$ : a weak type of the defender;  $D_S$ : a strong type of the defender;  $\\pi$ : a prior probability that  $D$  is strong;  $1 - \\pi$ : a prior probability that  $D$  is weak; and  $\\tilde{I}_S$ : the level of PCIs at which overall cybercapability is maximized for the strong type of the defender. 1:  $C$ 's gains from attacking  $D_S$ , given the probability of this attack is successful; 2:  $C$ 's gains from attacking  $D$ , given that with  $\\pi$  probability he is facing  $D_S$  and with  $1 - \\pi$  probability, he is facing  $D_W$  that pools with  $D_S$  and implements  $\\tilde{I}_S$ ; and 3:  $C$ 's gains from attacking  $D_W$ , given the probability of this attack is successful.\n\nfunction  $I + N$  stands for  $D$ 's overall cybercapability when the resources are distributed between PCIs and CCAs. We define  $\\tilde{I}$  to be the level of PCIs at which  $D$ 's overall cybercapability is maximized (point Max in Figure 1a).\n\nBefore  $D$  creates her PCIs, often she already has some existing cybercapabilities. For instance, before the Swedish Civil Contingencies Agency (MSB) became responsible for election protection, it dealt with civil protection; MSB could use these expertise to provide public safety during the time of elections. This existing level of cybercapability determines  $D$ 's type. We distinguish two types of  $D$ -strong  $(D_S)$  and weak  $(D_W)$ .  $D_S$ , depicted by the black line in figure 1(b), has a higher level of existing cybercapability, thus she can implement a higher level of PCIs and have higher chances of deterrence than  $D_W$ , depicted by a gray line in figure 1(b). Similarly,  $\\tilde{I}_S$  and  $\\tilde{I}_W$  are the levels of PCIs at which overall cybercapability is maximized for the defender's weak and strong types, respectively.\n\nWe assume that the costs of producing public  $(I)$  and private  $(N)$  cybercapacity are the same for the strong and weak type of the defender because we primarily focus on explaining the behavior of middle powers. Some nations that have developed technological expertise in this area—cyber powers, for instance—can develop \"more\" capability for a given budget. In such cases, it might be difficult for other nations to imitate PCIs developed by these cyber powers. For these reasons, our model excludes these powerful nations and primarily focuses on the behavior of middle powers that can imitate each other's behavior in order to deter their challengers.\n\n# Model Equilibria\n\nNext we discuss the intuition behind the model equilibria.\n\nAs explained earlier, the effectiveness of the defender's PCIs on deterring the challenger, depends on the challenger's type. We distinguish three types of the challenger that depend on the three cut-off points depicted in figure 2. If  $C$  is undeterred and always attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region I in figure 2). If  $C$  is disinterested and never attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region IV in figure 2). In these two equilibria,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. Proposition 1 summarizes both equilibria.\n\nProposition 1. Challenger's decision to attack is independent of defender's PCIs.\n\n(a) If  $C$  is undeterred and always attacks (Region I in Figure 2),  $D_{0}$  maximizes her cybercapacity and  $C$  always attacks.\n(b) If  $C$  is disinterested and never attacks (Region IV in Figure 2),  $D_0$  maximizes her cybercapacity and  $C$  never attacks.\n\nIn both equilibria in Proposition 1,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. But what happens if they do? We argue that different types of the defender would invest their resources differently to maximize their chances of deterring adversaries that are susceptible to the costs created by PCIs. Specifically, the strategic use of PCIs to deter  $C$  occurs in the signaling region where there is both the need for and the possibility of deterrence. Here  $D_0$ 's PCIs can influence  $C$ , which will take different actions depending on the defender's true type. Specifically, the challenger will attack the defender if he knows that the defender is weak and will avoid attacking if he knows the defender is strong. We call this challenger opportunistic. In this region, depicted by Regions II and III in Figure 2, there are two pure strategy equilibria (Propositions 2-3) and one mixed strategy equilibrium. We focus on the pure strategy equilibria in the main manuscript and present the mixed equilibria in the Online Appendix.\n\nIf  $C$  prefers attacking a defender that he thinks is weak and avoiding attacking a defender that he thinks is strong due to the fear of retaliation or attack failure,  $D_W$ 's natural response is to increase her investment into PCIs to appear strong. Specifically, instead of redistributing her resources so that her overall cybercapability achieves its maximum (Max  $W$  in Figure 3 (a)),  $D_W$  distributes them so they are her overall cybercapability is at point A in Figure 3(a). By doing so,  $D_W$  creates the same level of PCIs  $(\\tilde{I}_S)$  as  $D_S$  (i.e.,  $D_W$  pools with  $D_S$ ), so when  $C$  observes these institutions, he concludes that he is dealing with a strong defender and does not attack. Because this deterrent strategy decreases  $D_W$ 's overall cybercapability, by appearing strong,  $D_W$ , in fact, hides her actual weakness. This pooling equilibrium holds only when  $D$ 's gain of appearing strong outweighs  $D$ 's loss to inefficiently allocating her resources and when  $C$ 's prior belief that  $D$  is strong is high. Proposition 2 presents this pooling equilibrium.\n\n# Proposition 2. Pooling Equilibrium.\n\nSuppose  $C$  is opportunistic and prefers attacking  $D$  only if he believes that  $D$  is weak. If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.[15]",
            "images": [
              {
                "id": "img-2.jpeg",
                "top_left_x": 411,
                "top_left_y": 151,
                "bottom_right_x": 1322,
                "bottom_right_y": 422,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 7,
            "markdown": "1158\nDeterrence in the Cyber Realm\n\n![img-3.jpeg](img-3.jpeg)\nFigure 3. Defender's pure strategy actions when facing an opportunistic challenger: (a) pooling strategy; and (b) strategic separation strategy. Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$'s overall cybercapability when the resources are distributed between PCIs and CCAs; $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $Max_{S}(Max_{W})$); $\\hat{I}$: the level of PCIs that $D_{W}$ cannot attain; $A$: $D_{W}$ imitates PCIs of $D_{S}$; and $B$: $D_{S}$ strategically separates herself from $D_{W}$ by implementing PCIs that $D_{W}$ cannot implement.\n\nIf $C$'s prior belief that $D$ is strong is low, then $C$ interprets pooling as weak and attacks if $D$ implements $\\hat{I}_S$ (Region II of figure 2). $D_S$ is aware that $D_W$ is trying to imitate her PCIs and takes one of the two actions. Not wanting to be confused with $D_W$, $D_S$ can alter her behavior to clearly distinguish herself (i.e., separate) from $D_W$ to ensure that $C$ is deterred. Specifically, $D_S$ spends enough resources to reach a level of PCIs that $D_W$ cannot attain—$\\hat{I}$ (point B in Figure 3(b)). Observing $\\hat{I}$, $C$ knows that the defender is strong as $D_W$ could not implement $\\hat{I}$, as Figure 3(b) shows. Since $D_W$ cannot imitate $D_S$ and implement PCIs to reach $\\hat{I}$ in Figure 3(b), $D_W$ implements her optimal strategy $\\hat{I}_W$. Since separation is costly as it reduces $D_S$'s overall capacity, for this equilibrium to hold, $C$ should not attack when he sees $\\hat{I}$ even though he knows that $D_S$'s overall capacity is reduced. Proposition 3 summarizes this separating equilibrium.\n\n**Proposition 3.** Separating Equilibrium. Suppose $C$ is opportunistic and prefers attacking $D$ only if he believes that $D$ is weak. If $C$'s prior belief that $D$ is strong is low, then (1) $D_S$ implements a level of PCIs that $D_W$ cannot imitate $(\\hat{I} &gt; \\hat{I}_S)$, (2) $D_W$ is not able to pool with $D_S$ and implements $\\hat{I}_W$, and (3) $C$ attacks only when he sees $\\hat{I}_W$. [16]\n\nAlternatively, $D_{S}$ can decide not to implement PCIs that $D_{W}$ is not able to mimic because this will weaken her overall cybercapacity and invite an attack. In this case, a pure strategy equilibrium does not exist in Region II of Figure 2. But there exists a mixed strategy equilibrium where $D_{W}$ mixes between $\\hat{I}_{W}$ and $\\hat{I}_{S}$ and $C$ is indifferent between attacking and not. The Online Appendix presents this mixed strategy equilibrium.\n\n## Illustrative Examples of Elections\n\nThe novelty, secrecy, and sensitivity of the topic of cyber deterrence prevents us from conducting a rigorous empirical test of our findings. Instead, we aim at demonstrating the empirical plausibility of our theory of deterrence of strategic cyberattacks using PCIs. Since our theory is agnostic towards the type of a strategic cyberattack that a\n\nnation prefers to deter, we use illustrative examples from elections to provide support for our model equilibria. [17] Specifically, we focus on Kremlin-directed attempts to influence electoral campaigns in Western democracies: the 2016 US elections, the 2017 German elections, and the 2018 Swedish elections. We choose the most similar examples for our comparison (George 2019); they share the same cyber-capable attacker (Russia), have similar targets (Western democracies), use the same methods (cyber and information operations), have the same purpose (election interference), and have similar timeframes (2016–2018). They differ, however, in (1) the stakes involved in each campaign (e.g., a challenger's type); and (2) the level of PCIs that the targets implement (e.g., strong versus weak). As a result, these examples help demonstrate (1) under what conditions the challenger's uncertainty over the defender's cybercapacity increases the probability of successful deterrence; and (2) when this uncertainty has no effect.\n\nWe focus on the three different illustrative examples because they match the model's scope conditions that must be met if PCIs deter the challenger. First, there must be a difference in how different types of defenders allocate their resources to signal their cybercapacity. As we shortly demonstrate, the Swedish government, a weak cyber nation, prioritized investing in PCIs to appear that it had strong cyber defenses and offenses. Second, the challenger must face uncertainty about the defender's cybercapacity and its type. The time-limited and dynamic nature of COs generally raises uncertainty about cybercapacity, but this uncertainty over the defender's type does not play a role when facing an undeterred or disinterested challenger. But it is important when facing an opportunistic challenger: By investing more of its resources into PCIs, a weak defender can deter the challenger by pretending that it is strong. Uncertain about Sweden's actual cybercapacity, Russia observed the overwhelming number of PCIs that Sweden created prior its 2018 election that are typical of strong types; it is conceivable that based on these observations, the Kremlin chose not to attack. Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In\n\n[16] This equilibrium relies on the off-the-equilibrium beliefs that the defender is weak \"enough\" if it plays $\\hat{I}_S$.\n\n[17] We use an illustrative example to provide support only for the pooling equilibrium when the challenger is opportunistic (Region III in figure 2) because it provides the most interesting result by demonstrating when PCIs can, in fact, deter the challenger.",
            "images": [
              {
                "id": "img-3.jpeg",
                "top_left_x": 387,
                "top_left_y": 149,
                "bottom_right_x": 1263,
                "bottom_right_y": 512,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 8,
            "markdown": "NADIYA KOSTYUK\n\nthe elections we are considering, the cost-benefit calculations differ. In the 2018 Swedish elections, the additional costs created by Swedish PCIs outweighed the low value of Russia's interference campaign and deterred Russia from interfering. In the 2017 German elections, the Kremlin did not consider the extra costs created by PCIs because they were irrelevant—a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place. In the 2017 French elections, benefits outweighed the costs.\n\n# 2018 SWEDISH NATIONAL ELECTIONS: OPPORTUNISTIC CHALLENGER AND POOLING EQUILIBRIUM\n\nThe 2018 Swedish national elections provide support for the pooling equilibrium in which the weak defender over-invests in PCIs to appear strong and, as a result, deters the opportunistic challenger (Region III in Figure 2). To show that this is the case, we need to demonstrate that the Russian government was opportunistic and additional PCIs that Sweden created prior to the elections changed the Kremlin's cost-benefit calculation of the election interference campaign.\n\nTo understand how PCIs as a deterrent strategy worked in this case, we first explain why the Kremlin even considered interfering in the Swedish electoral process. Sweden's nonalignment policy has always served as a guarantee of Russia's security. Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO) (Kunz 2015). In response, Russia's Defense Minister Sergei Shoigu described Sweden's involvement in NATO activities as \"worrying\" and added that \"such steps...[were] forcing us to take response measures\" (Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister 2018). Military actions and/or economic sanctions are possible response measures, although to date, Russia has pursued neither of these. The Ukrainian and Syrian conflicts, combined with NATO-Swedish defense cooperation (even if it falls short of collective defense), are most likely responsible for preventing Russia from taking a military approach.\n\nRussia is, on the other hand, a mastermind of influence campaigns and had been preparing a strong foundation for such a campaign on the Swedish population for some time. Starting in 2014, the Swedish information landscape witnessed an increase in disinformation campaigns, led by trolls, bots, and Kremlin-sponsored media outlets, such as Sputnik International. In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\" (Cederberg 2018, 5) and Sweden remained one of the few \"favorite target[s] of the Kremlin's propaganda machine\" at the beginning of 2018 (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018, 109). Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks[18] against Swedish news sites and a disinformation campaign about NATO in the Swedish media.[19]\n\nAn anti-immigration sentiment in both the Swedish parliament and the populace bolstered these ongoing COs and information operations. Immigration has always been a contentious issue in Swedish politics, recently exacerbated by the Syrian refugee crisis. Over the last five years, Sweden, a country of 10 million, has welcomed 165,000 asylum-seekers from the Middle East. Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010 (Johnson and Evans 2018). The party's anti-immigration stance and the divide in the general population over the immigration issue presented the perfect environment for the Kremlin's influence campaigns.\n\nHowever, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference (Cederberg 2018). Why? What stopped Russia from interfering in the Swedish elections?\n\nLet us look at Russia's cost-benefit calculus. While Sweden had a favorable political climate and Russia had some ongoing COs and information operations, the value of a potential interference campaign was quite low, compared to, for instance, the interference into the US elections that we will discuss below. We argue that the low interference value, combined with additional costs created by PCIs that Sweden established prior to its elections, deterred Russia from interfering into the 2018 Swedish elections.\n\nIn addition to the PCIs outlined in the introduction, there are many others that the Swedish government established in order to raise the cost of election interference. Here are just a few examples. The government reiterated the protection of democracy as one of the country's top security objectives and designated its election systems as critical infrastructure. It tasked the Civil Contingencies Agency (MSB) and the Security Services and the Election Authority with coordinating election protection and made MSB responsible for countering Russian disinformation. Most importantly, Sweden's Prime Minister Stefan Lofven emphasized the country's military offensive cybercapability and the government's willingness to use it. When discussing a three-point plan to stop foreign powers from influencing the 2018 Swedish elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities (SverigesRadio 2017). Some might argue that factors other than PCIs deterred Russia. First is NATO's military capabilities. The NATO-Sweden cooperation defense pact that prioritizes security in the Baltic Sea region protects Sweden from a physical invasion by Russia (akin to those in Ukraine and Georgia) but not from election interference. Second is the threat of Western economic sanctions. The ineffectiveness of these sanctions in changing Moscow's behavior in Ukraine and Syria suggest that they are unlikely to have deterred the Kremlin from executing its plan. Third is Russia's lack of interest in interfering. While the interference value was low, preparatory influence operations aimed at undermining the 2018 Swedish elections demonstrate that the interest was, in fact, present (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018). Having ruled out the above factors, we have further evidence that Sweden's PCIs, put in place before elections, raised the cost of a potential election interference campaign and deterred Russia from interfering into the 2018 Swedish elections.\n\n# 2017 GERMAN FEDERAL ELECTION: DISINTERESTED CHALLENGER AND PCIs HAVE NO EFFECT\n\nThe 2017 German federal election provides support for the equilibrium in which the defender's PCIs have no effect on the challenger because the challenger is\n\n10 These attacks flood a website with multiple requests, making it crash.\n10 See https://www.documentcloud.org/documents/4627057-16-2517-CKK-2017-09-15-State-Production-3.html.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 9,
            "markdown": "1160\nDeterrence in the Cyber Realm\n\ndisinterested—the interference value is already so low that the challenger has no interest in interfering in the elections (Region IV in figure 2). We argue that German PCIs had no effect on Russia's decision to stay away from the 2017 German federal election. Instead, a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place.\n\nThe history of COs and information operations attributed to the Kremlin a few years prior to the election demonstrate that the Russian state had interest in German election interference. Information operations started in 2013, when three key German-language Kremlin-linked propaganda outlets—Sputnik Deutsch, RT Deutsch, and NewsFront Deutsch—entered the German market and were later joined by trolls²⁰ and bots.²¹ The 2015 and 2016 COs against the parliament and political parties demonstrate that Moscow was also eager to obtain sensitive information for potential future use. But the value of an effective influence campaign were overwhelmed by potential costs resulting from the following factors.\n\nFirst, Germany's balanced media systems, the lack of polarization among the German public, Germany's multiparty and proportional system, and a \"gentleman's agreement\" between major political parties not to use any information leaked as a result of cyberattacks made it difficult for Moscow to sow confusion in the public. (Schwirtz 2017). Second, the only clear beneficiary of these campaigns was the Alliance for Germany (AfD)—the rest of parties supported the sanction regime against Moscow. But when AfD entered the race, they only had between eight and ten percent of vote, which was not enough to gain the majority. Third, the use of old-fashioned paper ballots on the local level afforded Germany with an accurate recount in the event that digitized votes used on the federal level were compromised. Lastly, high-level deterrent rhetoric by German politicians referencing a deterioration of the relationship between the two countries if interference occurred likely played a part.²² Although Putin and Merkel's relationship has eroded over time, alienating Germany—an important bridge between the West and Russia—was not in Russia's interest.\n\nIf not these factors, what other factors could have stopped Russia from election interference? Brattberg and Maurer (2018) and Schwirtz (2017) suggest that a failure to influence the 2017 French presidential elections made the Kremlin re-think its approach, since it lost the element of surprise. While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives (Galante and EE 2018).\n\n## 2017 FRENCH ELECTION: UNDETERRED CHALLENGER AND PCIs HAVE NO EFFECT\n\nThe 2017 French elections provide an illustrative example for the equilibrium in which the defender's PCIs have no effect on the challenger because it is undeterred—the interference value significantly outweighs its costs (Region I in Figure 2). Given this high value, we argue that the Russian government was like an unstoppable tank moving towards its\n\ntarget and no French PCIs could have stopped the Kremlin from executing its plan.\n\nWhat was the value from interfering into the 2017 French elections? The lowest value was undermining faith in the democratic process whereas the highest value was electing a pro-Kremlin candidate that could have resulted in a change in French foreign policy. We argue that even the lowest value of the interference campaign was far greater than any costs Russia could envision paying.\n\nIf caught, Moscow knew that it faced potential (cyber and non-cyber) retaliation. Diplomatic retaliation was the least of Russia's worries considering some existing tension between the two countries. Moscow expected that, if elected, Emmanuel Macron—as the only unequivocal critic of Putin's Russia out of all presidential candidates—would only exacerbate this tension. The cost of additional economic sanctions—in addition to those that the country already faced for the Ukrainian conflict—was marginal. Nuclear and military responses to COs and information operations were off the table.\n\nGiven these rather low costs from non-cyber foreign policy options, what additional cyber costs could have Russia anticipated? French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations (Brattberg and Maurer 2018). Deterrence by punishment was unlikely to work either. Even if Paris targeted Russia's critical infrastructure (even though it is quite unlikely), the damage that Russia experienced would have been limited. For example, it is impossible to hack Russia's entire power grid system at once because most stations are manually controlled and can be restored by flipping a switch. Similarly, Paris was unlikely to attempt information operations because of the Kremlin's tight control of Russia's print, online, and social media and because of Russia's treatment of information as a weapon, allowing its military to respond to such information threats (Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space 2011).\n\nIn short, the potential worst-case scenario costs that Moscow faced were lower than the value it would gain by election interference. Thus, the Kremlin's interference campaign was never going to be deterred by French PCIs.\n\n## Discussion and Implications\n\nAs scholars and policymakers continue debating cyber deterrence using COs, attribution, and non-cyber threats, we explore the feasibility of cyber deterrence using means that have been largely overlooked by the international relations literature—public cyberinstitutions which signal organizational capacity to produce and use cybercapability to achieve strategic objectives.\n\nOur main contribution is to identify the precise conditions under which PCIs can deter strategic cyberattacks, which cause significant damage to a country's economy and security. Since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though different types attacks are deterred by different types of PCIs, the results do not change. Specifically, we reveal several important patterns of the strategic use of PCIs to deter challengers that differ by type. PCIs have no effect on disinterested challengers because they have no interest in attacking the defender and undeterred challengers because they have decided to attack even before observing the defender's PCIs. Both scenarios demonstrate that states are wasting their resources if they\n\n²⁰ A troll is someone who argues for extreme views without credible sources.\n²¹ An automated program that runs over the Internet.\n²² During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 10,
            "markdown": "NADIYA KOSTYUK\n1161\n\nuse PCIs as their deterrent strategy against disinterested and undeterred challengers.\n\nPCIs, however, can deter opportunistic challengers that only attack defenders that they perceive as cyber weak and avoid attacking those defenders that they perceive as cyber strong. To deter opportunistic challengers, weak cyber nations might choose to over-invest their limited resources into PCIs to appear strong. Strong cyber nations, in their turn, over-invest their limited resources into PCIs to distinguish themselves from weak cyber nations pretending to be cyber strong. This sub-optimal resource allocation, which makes the defender weaker in its overall cybercapacity, is worthwhile for weak cyber nations because it deters opportunistic challengers. These results have important theoretical and policy implications.\n\nOur findings shed light on a theoretical debate surrounding cyber deterrence (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). Similar to Tor (2017), this article stresses the need to re-think our reference to absolute nuclear deterrence as a matrix of deterrence success for cyberoperations. Countries do not create cybercapacity to deter low-level COs; instead, their goal is to stop adversaries from executing strategic cyberattacks, which can cause detrimental damage to the country's economy, prosperity, and security.\n\nWhat constitutes strategic cyberattacks, however, continues to evolve with changes in global cyberthreat landscape; countries only focused on critical infrastructure protection less than a decade ago and added election protection to their top national security priorities following the 2016 US elections. As countries re-define what constitutes strategic cyberattacks, adversaries find more creative ways to achieve their strategic goals using cyber means that operate below the strategic cyberattack threshold. For example, in response to Russia's meddling in the 2016 US elections, the US government took significant steps to protect its 2018 elections. In response to this stern measure, Russian bots and trolls adjusted their behavior and started operating during the election off-season. These influence campaigns, even if conducted during election off-seasons, shape public opinion and might affect public voting behavior. Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace (Murray and Mansoor 2012).\n\nOur results also show that states should take the signaling of cybercapacity via PCIs with a grain of salt. While PCIs serve as a cyberthreat assessment barometer because they allow a challenger to estimate a defender's ability to conduct COs, the defender's willingness to use these operations, and the scope of the defender's potential retaliation, this assessment is not precise. To better estimate the defender's cybercapacity, challengers should also examine other indicators, such as economic and technological achievements and the defender's reliance on the private sector for cybercapacity. This cumulative approach used to estimate cybercapacity will help governments better evaluate options that minimize the risk of escalation.\n\nFurthermore, our results speak to the scholarship in international relations theory that focuses on deterrence.[23] Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence.[24] We show that the challenger's\n\nchoice to cyberattack the defender is independent of the defender's PCIs in two equilibria. In the first one, the challenger has no interest in attacking the defender, giving a false impression of deterrence success. In the second one, the challenger has already decided to attack the defender, despite its PCIs, giving a false impression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios (Danilovic 2002; Snyder 1977). Before concluding the ineffectiveness of PCIs or other means of deterrence, researchers and policy-makers should consider these variables in their estimations. Moreover, since our model is limited to states that have limited cyber arsenals and are not able to burn their exploits to send deterrent signals, we expect to see more investment in PCIs among relatively weaker cyber nations or middle powers. But as more nations invest in PCIs, this deterrent approach might be less effective.\n\nWhile we take the first stab at understanding deterrence by PCIs, future research should further investigate this important mechanism. Here, we highlight a few venues that future research could explore. First, our model oversimplifies real-world scenarios by making assumptions to identify the causal effect of PCIs on deterrence chances. We view the challenger's choice to attack and the defender's choice to establish PCIs as a one-time decision. In practice, PCIs present a state's cumulative effort to boost its cybercapacity. Similarly, cyber and influence campaigns are composed of many, often low-level activities that span an extended period. Future research should explore how much updating-of-beliefs takes place during different stages of strategic cyberattacks and a state's cumulative efforts to build PCIs. Second, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities (Schneider 2019). Future iterations of this model should explore scenarios when it is not the case. For instance, when PCIs only signal an increase in offensive cybercapability, the threat of cyber retaliation might not deter a country that does not have many cyber targets, like North Korea. PCIs that only signal an increase in cyber defenses might deter countries that view attacking well-protected targets as too costly.\n\nThird, our model does not distinguish the defender by regime type. Democratic leaders are more transparent, responsive to constituents, and willing to provide public goods in the form of security to satisfy voters and secure their reelection (De Mesquita 2005). While autocracies might be less likely to create PCIs because they face a lesser demand to respond to their domestic audience, they, in fact, might be more likely to exaggerate their PCIs because of this lesser demand. Future research should investigate how these tendencies among different regime types affect model equilibria.\n\nAs Schelling (2008, 44) puts it, \"If deterrence fails, it is usually because someone thought he saw an 'option' that the... government had failed to dispose of, a loophole that it hadn't closed against itself.\" By building cybercapabilities, governments seem to assume that these capabilities alone have a deterrent effect. As my model demonstrates, successful deterrence depends on a defender's cybercapacity, its willingness to use it, and a challenger's type. Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or\n\n[23] For an overview of this scholarship, see Lupovici (2010).\n\n[24] We can describe undeterred challengers as resolute, opportunistic challengers as semi-resolute, and disinterested challengers as resolute.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          },
          {
            "index": 11,
            "markdown": "1162\nDeterrence in the Cyber Realm\n\nChina. In these cases, states might perceive potential consequences of entering an escalation cycle with such adversaries as too great to risk. To maximize the desired deterrent effect of publicly flexing their cyber muscles, nations' strategies should demonstrate their willingness to hold assets at risk and face consequences in cases of escalation. Only then, states will be able to close some of the loopholes that adversaries can exploit. Until that is done, the pessimistic view of cyber deterrence will persist.\n\n## Funding\n\nNadiya Kostyuk's work was partially supported by the William and Flora Hewlett Foundation under grant 2018-7727.\n\n## REFERENCES\n\nARENA, PHILIP, AND SCOTT WOLFORD. 2012. \"Arms, Intelligence, and War.\" *International Studies Quarterly* 56 (2): 351-65.\nAXELROU, ROBERT, AND RUBEN ILIFF. 2014. \"Timing of Cyber Conflict.\" *Proceedings of the National Academy of Sciences* 111 (4): 1298-303.\nBALIGA, SANDEEP, ETHAN BUENO DE MESQUITA, AND ALEXANDER WOLITZKY. 2020. \"Deterrence with Imperfect Attribution.\" *American Political Science Review* 114 (4): 1155-78.\nBEUTH, PATRICK, KAI BIERMANN, MARTIN KLINGST, AND HOLGER STARK. 2017. \"Merkel and the Fancy Bear.\" *ZEIT Online*.\nBORGHARD, ERICA D., AND SHAWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452-81.\nBRATTBERG, ERIK, AND TIM MAURER. 2018. *Russian Election Interference: Europe's Counter to Fake News and Cyber Attacks*. Vol. 23 Carnegie Endowment for International Peace.\nBUENO DE MESQUITA, ETHAN. 2007. \"Politics and the Suboptimal Provision of Counterterror.\" *International Organization* 61 (01): 9-36.\nCEDERBERG, GABRIEL. 2018. *Catching Swedish Phish: How Sweden is Protecting its 2018 Elections*. Cambridge, MA: Defending Digital Democracy Project, Belfer Center for Science and International Security.\nCHOUCHI, NAZLI., 2012. *Cyberpolitics in International Relations*. Cambridge, MA: MIT Press.\nCLARK, DAVID D., AND SUSAN LANDAU. 2011. \"Untangling Attribution.\" *Harvard Law School National Security Journal* 2: 323.\n*Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space*. 2011. Moscow: Ministry of Defence of the Russian Federation.\nDANILOVIC, VESNA. 2002. *When the Stakes Are High: Deterrence and Conflict Among Major Powers*. Ann Arbor, MI: University of Michigan Press.\nDE MESQUITA, BRUCE BUENO. 2005. *The Logic of Political Survival*. Cambridge, MA: MIT Press.\nDEBS, ALEXANDRE, AND NUNO P. MONTEIRO. 2014. \"Known Unknowns: Power Shifts, Uncertainty, and War.\" *International Organization* 68 (1): 1-31.\nDEMCHAK, CHRIS C. 2011. *Wars of Disruption and Resilience: Cybered Conflict, Power, and National Security*. Athens, GA: University of Georgia Press.\nDRAGU, TIBERIU. 2011. \"Is There a Trade-Off between Security and Liberty? Executive Bias, Privacy Protections, and Terrorism Prevention.\" *American Political Science Review* 105 (1): 64-78.\nEGLOFF, FLORIAN J., AND ANDREAS WENGER. 2019. *Public Attribution of Cyber Incidents*. Zurich: Center for Security Studies.\nFEARON, JAMES. 2002. \"Selection Effects and Deterrence.\" *International Interactions* 28 (1): 5-29.\nFEARON, JAMES D. 2018. \"Cooperation, Conflict, and the Costs of Anarchy.\" *International Organization* 72 (3): 523-59.\nFERNANDINO, LISA. 2018. *Cybercom to Elevate to Combatant Command*. Arlington, VA: US Department of Defense.\nGALANTE, LAURA, AND E. E. SHAUN. 2018. *Defining Russian Election Interference: An Analysis of Select 2014 to 2018 Cyber Enabled Incidents*. Washington, DC: Atlantic Council.\nGARTZKE, ERIK. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace back Down to Earth.\" *International Security* 38 (2): 41-73.\nGARTZKE, ERIK, AND JON R. LINDSAY. 2019. *Cross-Domain Deterrence: Strategy in an Era of Complexity*. Oxford, UK: Oxford University Press.\nGEORGE, ALEXANDER L. 2019. \"Case Studies and Theory Development: The Method of Structured, Focused Comparison.\" In *Alexander L. George: A Pioneer in Political and Social Sciences*, edited by D. Caldwell, 191-214. New York, NY: Springer.\nJOHNSON, SIMON, AND CATHERINE EVANS. 2018. \"Anti-Immigration Sweden Democrats Poll Record High ahead of September Election.\" *Reuters*.\nKELLO, LUCAS. 2013. \"The Meaning of the Cyber Revolution: Perils to Theory and Statecraft.\" *International Security* 38 (2): 7-40.\nKUNZ, BARBARA. 2015. \"Sweden's NATO Workaround: Swedish Security and Defense Policy against the Backdrop of Russian Revisionism.\" *Enote. Focus Strateguque*.\nKEDD, ANDREW. 2000. \"Arms Races and Arms Control: Modeling the Hawk Perspective.\" *American Journal of Political Science* 44 (2): 228-44.\nLINDAW, JON R. 2013. \"Stuxnet and the Limits of Cyber Warfare.\" *Security Studies* 22 (3): 365-404.\nLUPOVICI, AMS. 2010. \"The Emerging Fourth Wave of Deterrence theory-toward a New Research Agenda.\" *International Studies Quarterly* 54 (3): 705-32.\nMEROWITZ, ADAM, AND ANNE E. SARTORI. 2008. \"Strategic Uncertainty as a Cause of War.\" *Quarterly Journal of Political Science* 3 (4): 327-52.\nMORROW, JAMES D. 1989. \"Capabilities, Uncertainty, and Resolve: A Limited Information Model of Crisis Bargaining.\" *American Journal of Political Science* 33 (4): 941-72.\nMURRAY, WILLIAMSON, AND PETER R. MANSOOK. 2012. *Hybrid Warfare: Fighting Complex Opponents from the Ancient World to the Present*. Cambridge, UK: Cambridge University Press.\n*National Cybersecurity Policy*. 2017.\nNEWMAN, LILY HAY. 2019. \"What Israel's Strike on Hamas Hackers Means for Cyberwar.\" *Wired*. https://www.wired.com/story/israel-hamas-cyberattack-air-strike-cyberwar/\nNYE, JOSEPH S., JR. 2017. \"Deterrence and Dissuasion in Cyberspace.\" *International Security* 41 (3): 44-71.\nO'Dwyer, GERARD. 2018. \"Sweden Steps up Cyber Defence Measures.\" *ComputerWeekly.com*.\nPRESS, DARIY. GRAYSON. 2005. *Calculating Credibility: How Leaders Assess Military Threats*. Ithaca, NY: Cornell University Press.\n*Putin's Asymmetric Assault on Democracy in Russia and Europe*. 2018.\nREITER, DAN. 2003. \"Exploring the Bargaining Model of War.\" *Perspectives on Politics* 1 (1): 27-43.\nRETTMAN, ANDREW, AND LIBBETH KIRK. 2018. \"Sweden Raises Alarm on Election Meddling.\" *EU Observer*.\n*Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister*. 2018.\nSCHELLING, THOMAS C. 2008. *Arms and Influence: With a New Preface and Afterword*. New Haven, CT: Yale University Press.\nSCHNEIDER, JACQUELYN. 2019. \"Cyber and Cross Domain Deterrence: Deterring within and from Cyberspace.\" In *Cross-Domain Deterrence: Strategy in an Era of Complexity*, edited by LINDSAY, JON R., AND ERIK GARTZKE, chapter 5. Oxford, UK: Oxford University Press.\nSCHUITZ, KENNETH A. 1998. \"Domestic Opposition and Signaling in International Crises.\" *American Political Science Review* 92 (4): 829-44.\nSCHWIRTZ, MICHAEL. 2017. \"German Election Mystery: Why No Russian Meddling?\" *New York Times*.\nSLANTSCHEY, BRANISLAV L. 2003. \"The Power to Hurt: Costly Conflict with Completely Informed States.\" *American Political Science Review* 97 (1): 123-33.\nSLANTSCHEY, BRANISLAV L. 2005. \"Military Coercion in Interstate Crises.\" *American Political Science Review* 99 (4): 533-47.\nSLANTSCHEY, BRANISLAV L. 2010. \"Feigning Weakness.\" *International Organization* 64 (3): 357-88.\nSLATTON, REBECCA. 2017. \"What Is the Cyber Offense-Defense Balance? Conceptions, Causes, and Assessment.\" *International Security* 41 (3): 72-109.\nSANDER, JACK L. 1977. \"The Soviet Strategic Culture. Implications for Limited Nuclear Operations.\" *RAND Technical Report*, R-2154-AF, 1-38.\nSVERIGES RADIO. 2017. \"Swedish PM Warns of Foreign Influence ahead of 2018 Poll.\" *Radio Sweden*.\n*The US Department of Defense Cyber Strategy*. 2015.\nTOR, URI. 2017. \"Cumulative Deterrence' as a New Paradigm for Cyber Deterrence.\" *Journal of Strategic Studies* 40 (1-2): 92-117.\nVALERIANO, BRANDON, BENJAMIN JENSEN, AND RYAN C. MANESS. 2018. *Cyber Strategy: The Evolving Character of Power and Coercion*. Oxford, UK: Oxford University Press.\nWELBURN, JONATHAN WILLIAM, JUSTIN GRANA, AND KAREN SCHWINDT. 2019. \"Cyber Deterrence or: How We Learned to Stop Worrying and Love the Signal.\" RAND Technical Report, WR-1294-OSD, 1-46.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 2200,
              "width": 1700
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 12,
          "doc_size_bytes": 760284
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "International Studies Quarterly (2021) 65, 1151-1162\n# Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\nNADIYA KOSTYUK\nSchool of Public Policy, Georgia Institute of Technology, USA\nCan cyber deterrence work? Existing scholarly works argue that deterrence by punishment using cyberattacks is ineffective because the difficulty of attributing the origin of cyberattacks makes the threat of future attacks less credible. However, these works have told us relatively little about the deterrence ability of public cyberinstitutions (PCIs), defined as publicly observable proactive efforts aimed at signaling a country's level of cyber offensive and defensive capability. This research shows that middle powers (that have scarce cyber arsenals) can use PCIs to deter cyber attacks that cause significant damage to their economy and prosperity; however, this deterrent capability is rather limited. Using an incomplete-information model, we demonstrate that PCIs only deter adversaries that are susceptible to the costs created by these institutions. Despite this limited deterrence ability, middle powers tend to over-invest resources in these cyberinstitutions: Weak cyber states tend to over-invest to convince strong cyber adversaries that they are strong, whereas strong cyber states over-invest so that adversaries do not believe that they are weak states pretending to be strong. By doing so, states reduce their overall cybercapacity. We establish the empirical plausibility of these results using election interference campaigns as examples of strategic attacks. Our focus on the strategic use of PCIs as a deterrent represents a departure from existing literature—which has focused only on cyberoperations—and has important policy implications.\nPuede funcionar la ciberdisuasión? Los trabajos académicos existentes sostienen que la disuasión mediante el castigo de los ciberataques es ineficaz porque la dificultad de atribuir el origen de los ciberataques hace menos creíble la amenaza de futuros ataques. Sin embargo, estos trabajos nos han aportado relativamente poco sobre la capacidad de disuasión de las ciberinstituciones públicas (Public Cyberinstitutions, PCI), definidas como esfuerzos proactivos públicamente observables destinados a señalar el nivel de capacidad ciberofensiva y defensiva de un país. Esta investigación muestra que las potencias medias (que disponen de escasos arsenales cibernéticos) pueden utilizar las PCI para disuadir los ciberataques que causan un daño importante a su economía y prosperidad; pero esta capacidad de disuasión es bastante limitada. Mediante un modelo de información incompleta, demostramos que las PCI solo disuaden a los adversarios que son susceptibles a los costos creados por estas instituciones. A pesar de esta limitada capacidad de disuasión, las potencias intermedias tienden a invertir en exceso sus recursos en estas instituciones cibernéticas: los ciberestados vulnerables tienden a invertir en exceso para convencer a los ciberadversarios fuertes de que son fuertes, mientras que los ciberestados fuertes invierten en exceso para que los adversarios no crean que son estados vulnerables que fingen ser poderosos. Al hacerlo, los estados reducen su cibercapacidad general. Determinamos la credibilidad empírica de estos resultados utilizando campañas de interferencia electoral como ejemplos de ataques estratégicos. Nuestro enfoque en el uso estratégico de las PCI como elemento de disuasión representa un cambio respecto a la literatura existente, que se ha centrado únicamente en las ciberoperaciones, y tiene importantes implicaciones políticas.\nLa cyber-dissuasion peut-elle fonctionner? Les travaux de recherche existants soutiennent que la dissuasion par une sanction reposant sur des cyber-attaques est inefficace car la difficulté de détermination de l'origine des cyber-attaques rend la menace de futures attaques moins crédible. Toutefois, ces travaux ne nous ont donné que relativement peu d'informations sur la capacité de dissuasion des cyber-institutions publiques, qui est définie comme étant constituée des efforts proactifs publiquement observables visant à signaler le niveau des cyber-capacités offensives et défensives d'un pays. Cette recherche montre que les puissances intermédiaires (qui disposent de cyber-arsenaux limités) peuvent avoir recours aux cyber-institutions publiques pour dissuader les auteurs de cyber-attaques nuisant considérablement à leur économie et à leur prospérité, mais cette capacité de dissuasion est plutôt limitée. Nous nous appuyons sur un modèle d'information incomplète et nous démontrons que les cyber-institutions publiques ne dissuadent que les adversaires qui sont sensibles aux coûts engendrés par ces institutions. Malgré cette capacité de dissuasion limitée, les puissances intermédiaires tendent à surinvestir des ressources dans ces cyber-institutions : les cyber-États faibles tendent en effet à surinvestir pour convaincre leurs puissants cyber-adversaires qu'ils sont forts, tandis que les cyber-États forts tendent à le faire afin que leurs adversaires ne croient pas qu'ils sont faibles alors qu'ils se prétendent forts. Ce faisant, les États réduisent leur cyber-capacité globale. Nous établissons la plausibilité empirique de ces résultats en nous basant sur les campagnes d'ingérence électorale comme exemples d'attaques stratégiques. Notre concentration sur l'utilisation stratégique des cyber-institutions publiques comme dissuasion diverge de la littérature existante qui s'est uniquement concentrée sur les cyber-opérations et a d'importantes implications politiques.\n\"To those thinking about trying to influence the outcome of the elections in our country: Stay away!\" (as quoted in Cederberg 2018, 11). Sweden's Prime Minister Stefan Löfven articulated this warning and the country's willingness to act in the event of election interference at a security conference in January 2018. The Swedish government\nNadiya Kostyuk is an Assistant Professor, School of Public Policy, Georgia Institute of Technology.\nAuthor's note: I would like to thank Erica Borghard, Aaron Brantly, Ben Buchanan, John Ciorciari, Fiona Cunningham, Tiberiu Dragu, Mathias Frendem, Andres Gannon, Erik Gartzke, John Leahy, Susan Landau, Herb Lin, Jon Lindsay, Shawn Lonergan, Carla Martinez Machain, Tamar Mitts, James D. Morrow, Jacquelyn Schneider, Jeffrey W. Taliaferro, Brandon Valeriano, Ketian Zhang, Yuri M. Zhukov, and the participants of the Peace and Science Society International pre-conference workshop, of the Student Cybersecurity Symposium at Tufts University, of the International Security Seminar at the Belfer Center for Science and Technology at Harvard Kennedy School, of the Peace Science OPSC, and of the Cybersecurity Series at the Stanford Center for International Security and Cooperation. This paper was presented at the 2019 International Studies Association Conference.\nKostyuk, Nadiya (2021) Deterrence in the Cyber Realm: Public versus Private Cyber Capacity. International Studies Quarterly, doi: 10.1093/isq/sqab039\n© The Author(s) (2021). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nDeterrence in the Cyber Realm\nsubstantiated this rather bold statement with a number of measures meant to deter potential intruders. Specifically, in preparation to its September 2018 election, the country created a number of public cyberinstitutions (PCIs)—publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities.\nSome of these measures aimed at creating better cyber defenses to “raise the threshold [of] attacking Sweden” (National Cybersecurity Policy 2017, 19). Specifically, the government increased the budgets of existing agencies to include election protection into their scope, and it established new agencies, forums, and programs to protect against election interference and disinformation campaigns. For instance, the Swedish government’s crisis preparation and response agency became the main authority for election coordination. The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’” (SverigesRadio 2017). Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats (Cederberg 2018). Media, political parties, and schools ran similar education campaigns. To prepare for total defense awareness, including cases of cyber emergencies, MSB also sent a pamphlet titled “If Crisis or War Comes” to all 4.7 million households.\nIn addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats (Rettman and Kirk 2018). The National Defense Radio Establishment and the Military Intelligence and Security Service installed special detection and warning systems to guard against foreign powers hacking into sensitive agencies. The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators” (O’Dwyer 2018).\nWe argue that these PCIs established by the Swedish government in order to protect its 2018 elections convinced the Russian government that an interference campaign would have been too costly. Why were PCIs successful in deterring a potential interference campaign? Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy (Fernandino 2018)—under what conditions can PCIs deter any strategic cyberattack?\nTo answer these questions, we develop an incomplete-information model in which a challenger considers attacking a defender. The defender in this case is a middle power, since these nations have scarce cyber arsenals and are more likely to invest in PCIs for deterrence. The challenger is not certain about the defender’s cybercapacity—how cyber “strong” or “weak” it is—and can only infer it from the defender’s observable PCIs. Thus, the challenger’s decision to attack depends on the defender’s type, and the defender has an incentive to over-invest in public cybercapacity in order to signal that it is stronger that it actually is.\nThis model leads to several insights. First, there is a large number of equilibria for which PCIs have no influence on the challenger. Second, we show that the defender’s strategic use of PCIs to deter the challenger works only when two conditions are met: (1) the challenger believes that the defender possesses significant cybercapabilities and that it would therefore be too costly to attack the defender; and (2) the challenger is susceptible to the cost exacted by PCIs. This finding shows that PCIs influence the challenger’s decision to attack only in limited cases. Despite that, weaker defenders over-invest in PCIs to signal higher cybercapacity than they possess, and strong defenders over-invest so that their adversaries do not believe that they are weak states pretending to be strong.\nThis paper makes a number of theoretical contributions to the existing international-relations literature. First, it helps us better understand the nature of deterrence in the information age. Our unique strategic logic of PCIs as a proxy for a country’s cybercapacity represents a departure from existing literature. While most scholarly works on cyber-to-cyber deterrence focuses on deterrence by punishment using cyberoperations (Baliga, de Mesquita, and Wolitzky 2020; Valeriano, Jensen, and Maness 2018), this project presents a new theory that explains how PCIs can deter by both prevention and by threat of punishment, by signaling an increase in both defensive and offensive cybercapabilities. This project also contributes to the literature on cross-domain deterrence (Gartzke and Lindsay 2019) by explaining situations in which countries use PCIs to deter their adversaries instead of non-cyber foreign policy options (i.e., economic sanctions, or diplomatic or military responses) that are ineffective and/or costly.\nSecond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). We, instead, seek to explain the strategic behavior of weaker cyber states or middle powers that suspect a cyberattack. In these situations, middle powers often must rely on their own cybercapabilities because their allies are unlikely to help. Cyberdefenses are unique to each country and not easily transferable; close allies are often reluctant to disclose information about their offensive cybercapabilities and/or commit cyberattacks on an ally’s behalf (as compared with their willingness to offer military assistance during territorial invasions).\nThe literature on the “bargaining model of war” focuses on how private information and incentives to misrepresent, and commitment problems affected by power shifts, explain costly armed conflict (e.g., Schultz 1998; Slantchev 2003, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power (Morrow 1989); states also tend to keep certain capabilities secret to obtain military advantage (Reiter 2003).\nWhat is new about our model then? First, a different theoretical foundation drives how nations signal their cybercapacities. Unlike in the case of military capacity, a state cannot launch a parade to signal its cybercapacity. Satellite images are also unlikely to be useful to adversaries seeking to estimate a state’s cyberstrength. An executed cyberattack may provide a target with a good estimate of the attacker’s capabilities, but such an attack de-values capability because it provides the target with instructions on how to fix flaws in their own networks and systems. The time-limited life-span and the dynamic nature of cyberoperations further complicate their signaling potential. While the basic parameters for most traditional weapons remain relatively static,\n1 In addition to election interference campaigns, attacks against critical infrastructure are other examples of strategic cyberattacks.\n2 Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by “burning” their covert cybercapabilities to demonstrate their ability to acquire such capabilities.\nNADIYA KOSTYUK\n1153\nstrategically relevant features of certain cyberweapons might look quite different tomorrow. Signaling cybercapacity via PCIs, on the other hand, (1) preserves the value of a state's cyberoperations, which diminishes after use; (2) signals organizational capability that is not about specific secret vulnerabilities, which are ephemeral and easily compromised, but the ability to readily produce and use those vulnerabilities in complex operations for political ends; and (3) provides the adversary with an immediate, often rough proxy for the state's cybercapacity.\nSecond, existing models focus only on whether and how investment in military capacity can deter a future attack or affect the likelihood of winning a war. Our theoretical foundation instead explains that sources of state cybercapacity are more diverse, lie beyond military and government, and extend to a state's private sector and even public-opinion management. While investing in military cybercapacity is important for deterrence by the threat of punishment, to deter adversaries by prevention, states might, for example, invest significant resources into building public awareness about the danger of cyberoperations and information operations, making potential election-interference campaigns harder.\nRegarding the model, the closest work, which focuses on the relative impact of scarce resource allocation on the likelihood of attack, is Arena and Wolford (2012). Unlike Arena and Wolford (2012), which examines a state's decision to allocate its resources between armaments and intelligence gathering capabilities in order to reduce uncertainty over its opponent's military strength, our model explores a state's decision to allocate its resources between public and private cybercapacity in order to deter its strong opponent from executing a cyberattack against the state. Similarly to works on counter-terrorism policies (Bueno de Mesquita 2007; Dragu 2011), our model explains why nations over-invest in public capacity and that such policies are generally ineffective in deterring adversaries.\nBaliga, de Mesquita, and Wolitzky (2020) and Welburn, Grana, and Schwindt (2019) are the only two other models that focus on cyberdeterrence; they explore how a state's inability to correctly attribute the origin of cyber operations and to detect cyberattacks affects the state's chances of deterring potential attackers. Unlike these models, our model focuses on organizational capability which signals the state's ability to readily produce and use covert cybercapacity. Unlike Baliga, de Mesquita, and Wolitzky (2020)'s model, in which there is uncertainty over the signal's sender (i.e., the attacker's identity) while the signal's quality (i.e., the strength of cybercapacity) is clear, our model investigates situations in which the signal's sender is known but the signal's quality is unclear. Unlike Welburn, Grana, and Schwindt (2019)'s model, in which a defender can signal any cybercapability with no cost, our model explains how the defender's choice to allocate its limited resources translates into observable cybercapacity.\nThe paper proceeds as follows. We start with explaining how a state can signal its cybercapacity. Then, we explain when and how public cyberinstitutions can deter strategic cyberattacks. Next, we introduce the model and derive the model equilibria. We use illustrative examples from elections to establish the empirical plausibility of our theory. We conclude with a discussion of our study's implications.\n## Signaling Cybercapacity\nStates can signal their cybercapability by (1) attributing cyber operations (COs) to attackers; (2) executing COs against adversaries; and (3) establishing public cyberinstitutions—publicly observable efforts aimed at demonstrating a country's level of offensive and defensive cybercapability. Each of these methods has its pros and cons.\nSignaling cybercapacity via attribution is a recent trend, as demonstrated by the number of US indictments. Attribution is a powerful deterrent because it signals to both the attacker and future perpetrators that they are not as invisible as they would like to be in cyberspace. But cyber attribution is difficult and costly: Not only does cyber attribution require significant resources and technical expertise to correctly attribute an attack to a specific computer, but it also demands intelligence to connect the used computer to a perpetrator. Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources (Clark and Landau 2011; Egloff and Wenger 2019). As a result, only a few nations have the resources, technical expertise, and political will to use attribution as a way to signal their cybercapability.\nSignaling cybercapacity via covert COs provides the target with an accurate estimate of the attacker's capability. However, the difficulty of attributing the origin of COs and the time it takes to do so diminish the signal's value, which is further reduced by the time-limited life-span and the dynamic nature of COs. Moreover, if a victim is not able to attribute the attack or remains quiet about the attack, the signaling value of COs is either zero or quite low. Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons (Gartzke 2013); only a few nations have a large enough cyber arsenal that they can burn some of their exploits for signaling purposes.\nWhile cybercapacity cannot be revealed because it depends on secret access and vulnerabilities, the state can reveal its ability to find such vulnerabilities by establishing PCIs, defined as publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities. PCIs signal an increase in organizational cybercapability, which demonstrates the state's ability to readily produce cybercapability and use cyberoperations for political purposes. As a result, signaling via PCIs provides the state's allies, adversaries, and domestic and international audiences with an immediate, often rough proxy for the state's cybercapacity and preserves the value of the state's covert COs.\nFor simplicity, I distinguish two ways in which a state can establish its PCIs: It can (1) create a new agency program, initiative, doctrine, strategy, or policy to address some aspect of cybersecurity; and/or (2) add new cyber roles to existing agencies or new cyber provisions to existing policies. For instance, to deter election interference campaigns, Sweden established an agency responsible for psychological defense. When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time (Schwirtz 2017).\n5Some of these works include Debs and Monteiro (2014), Fearon (2018), Kydd (2000), Meirowitz and Sartori (2008), and Slantchev (2005).\n4Germany's hack-back strategy is a PCI even though the government does not give any details regarding the scope of this strategy. Since they publicly discussed its development (instead of only privately executing it), we have an idea of the steps that the German government considers adopting in order to deter election interference. If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage (Schwirtz 2017). For instance, in response to the attack against the parliament, the German government could remove servers on which stolen parliament data were located.\n1154\nDeterrence in the Cyber Realm\nEven though these two options differ in how governments created their PCIs, they both might involve a similar set of measures. Specifically, a new agency and a new strategy might require additional budget, stuff, training, and expertise. While PCIs often do not reveal all the details about created cybercapacity, unlike covert cyberactivity they allow an adversary to estimate the scope of the change and the potential resulting increase in the target state's cybercapacity. The Swedish and German actions, for instance, signaled that both countries prioritized spending their resources on building better cyber defensive and offensive capabilities to deter potential election interference campaigns.\nBefore we explain how PCIs can deter adversaries, we would like to clarify that our theory focuses on middle powers—the nations that have scarce cyber arsenals and are more likely to invest in PCIs as a means of deterrence. Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by \"burning\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities.⁵\n## The Theory of Cyber Deterrence\nThe theory presented in this section examines the specific context in which a strong challenger (including cyber powers) contemplates a strategic cyberattack against a defender.⁶\nWhen the challenger considers a cyberattack, he calculates the value he can gain from this attack (e.g., undermining democratic processes, in the case of election interference) and the cost he can incur. There are two types of costs. First is the cost of the defender's potential retaliation (e.g., using economic sanctions, military operations or cyberoperations). Second is the tendency of cyberoperations—unlike military operations—to diminish in value after their first use. A tank, for example, can be successfully deployed many times over many years. Cyberattacks, on the other hand, often lose their effectiveness after their first use, even if the attack fails due to the defender's defenses. In using cyberattacks, the challenger risks the possibility that the defender might be able to develop protection against similar attacks in the future.\nWe argue that, for a challenger to decide to use a cyberattack against a defender, it must believe that the attack's value will outweigh its cost. What can change this cost-benefit calculation? Specifically, what can raise the cost enough to deter the challenger?\nWe assume that the costs from non-cyber foreign policy tools (i.e., diplomatic or military responses, or economic sanctions) will not change the cost-benefit calculation because the challenger has considered them initially. These costs are easy to estimate using the defender's past history and are highly predictable based on the challenger's \"prior beliefs about the defender's willingness\" to use one\n⁵Some anecdotal evidence suggests that even though the US government could not hack back in response to the election, it went into Russian servers and left non-malicious code that had \"U.S. Cyber Command\" in the comments. They did so to signal to the Russians, in a covert way, that they had the ability to strike whenever they wanted.\n⁶I employ the language from the traditional deterrence literature and refer to an adversary as a challenger and a defending state as a defender. The model makes the assumption that the defender attempts to deter her strongest challenger, which is the challenger that can potentially cause the most significant damage. If she is able to deter her strongest challenger, then all her other challengers will be deterred by default. Because the model focuses only on the strong challenger, I have omitted \"strong\" and refer only to a \"challenger\" for the remainder of the paper.\nof these options (Fearon 2002, 6). Moreover, given that the defender's capability in non-cyber foreign policy domains is unlikely to change rapidly, the challenger's estimate of the costs imposed by diplomatic responses and economic sanctions is likely to be fairly accurate. The challenger is also aware that military responses are costly and that the defender is unlikely to launch a military strike in response to information operations or cyberoperations.⁷\nEven though these non-cyber foreign policy tools cannot change the challenger's cost-benefit calculation, the challenger considers the defender's capability in these non-cyber domains when forming its opinion of the defender's cybercapacity. Since nations with significant resources and expertise can build sophisticated cyber weapons (Gartzke 2013), the challenger can accurately conclude that the most powerful military nations have impressive cyber arsenals. While the country's military capability might often be correlated with its cybercapacity, it is not always the case because some nations might choose to purchase cyber weapons from third parties or work with proxy groups to execute attacks on their behalf. Despite that we argue that both the defender's capability in non-cyber and the defender's capability in cyber domains form the challenger's prior belief of the defender's cybercapacity.\nGiven that the challenger is quite certain about the costs associated with non-cyber responses and, as a result, is unlikely to be deterred by them, the defender is left with cyber foreign policy tools to deter the challenger from executing cyberattacks. We argue that cyber foreign policy tools may raise the cost of a cyberattack for the challenger because the challenger remains uncertain about the defender's cybercapacity. Even if the challenger has a rough estimate of the defender's cybercapacity, the dynamic, time-limited nature of cyber tools makes it difficult for the challenger to determine the defender's cybercapacity with precision or certainty. Specifically, while the basic parameters for most traditional weapons remain relatively static, strategically relevant features of certain cyber weapons can change significantly over a short period of time. Moreover, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it (Axelrod and Iliev 2014). We explore this challenger's uncertainty over the defender's cybercapacity as the main mechanism that affects the probability of successful deterrence.⁸ How can the defender signal its cybercapacity\n⁷The Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations (Newman 2019).\n⁸For deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity (Schelling 2008). Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high (Press 2005). Moreover, as earlier explained, many nations cannot afford to \"burn\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities, and those that do send a rather costly signal about their sophisticated cyber arsenal. Furthermore, many countries conduct cyber espionage to observe other countries' cyberattack plans and capabilities. As a result, cyber powers that consider challenging other nations probably know enough about other countries' covert cyber strength to know whether they face another cyber power or not, though they do not necessarily know its precise capabilities. Thus, there is no uncertainty about the capabilities of these cyber powers; instead, this theory explores uncertainty over the capabilities of weaker nations—middle powers—and specifically how cyber \"strong\" or \"weak\" they are. These nations tend to have a rather scarce cyber arsenal and are more likely to invest in PCIs as a means of deterrence. However, the better a challenger's cyber-intelligence, the less uncertainty the challenger has about the defender's cybercapacity.\nNADIYA KOSTYUK\n1155\nso it increases the challenger's uncertainty about the defender's cybercapacity? By attributing COs to the challenger, the defender reveals some of its capabilities, reducing uncertainty about its capacity. Signaling by executing COs against the challenger does not help achieve the desired result either. If COs are correctly attributed to the defender, COs quite accurately signal the defender's cybercapacity, improving the challenger's estimates of the defender's cybercapacity. If COs are incorrectly attributed to a third party or not attributed at all, the defender uselessly burns its exploits without changing the challenger's beliefs about the defender's cybercapacity. Since signaling via attribution and signaling via COs are unlikely to increase the challenger's uncertainty about the defender's cybercapacity, the defender is left with PCIs to deter strategic cyberattacks.⁹\n## Deterrence by PCIs\nPCIs can leave the challenger uncertain about the defender's cybercapacity because they demonstrate the defender's ability to produce cybercapability without revealing any concrete details about this capability. PCIs can deter by prevention and/or by threat of punishment.¹⁰ These two types of deterrence are associated with the two types of costs that PCIs can inflict on the challenger, increasing the cost of its cyberattack. PCIs can deter by prevention because adversaries may infer that their attacks are likely to fail against the defenses implied by a PCI. Firewalls, updated computer software, programs aimed at educating public about cyberthreats, and policies that outline a set of measure to provide better security of critical infrastructure are examples of PCIs that can deter by prevention because they make hacking more difficult. While the challenger can keep using conventional weapons even if a conventional attack fails, the challenger often burns its cyber exploits in the case of an unsuccessful cyberattack. This is because having discovered an attempted hack, the defender can close the existing vulnerability making the future use of this exploit impossible. PCIs can also deter by the threat of punishment; for instance, new military doctrines and units signal the state's ability to use its cyber weapons in response to cyberthreats.\nWe investigate situations in which both deterrence mechanisms are at play for the following two reasons. First, one cyberinstitution can signal both cyber offensive and defensive capability, making it hard to separate deterrence by the threat of punishment from deterrence by prevention. The US Department of Defense Cyber Strategy (2015, 3), for instance, uses deterrence by prevention by specifying the Department of Defense's role in defending its information networks, and it uses the threat of punishment by establishing a Cyber Mission Force to be used to defend the United States against cyberattacks of \"significant consequence\". Second, when facing a strategic cyberthreat, states tend to respond with multiple PCIs and, as a result, implement both types of deterrence at the same time to maximize their chances of success.\nSince PCIs can increase uncertainty about the defender's cybercapacity raising the probability of successful deterrence, the defender might want to invest most, if not all, of its resources into PCIs. But such a strategy takes valuable resources away from covert cyberactivity (CCA) or private cybercapacity, which involves secret development of cybercapabilities and ongoing cyberoperations.¹¹ For instance, a polished strategy document, newly-constructed headquarters, or a new initiative meant to bring public awareness of cyberthreats is a poor substitute for a CCA aimed at penetrating the challenger's electricity grid and preparing for a future attack that could be used for retaliation.\nWe argue that this trade-off between PCIs and CCAs is important. Even though some PCIs involve the development of private cybercapability (e.g., the German's hack-back strategy), such PCIs give a high-level view on what capacity a government develops whereas CCAs remain truly covert and only signal capability after being discovered and correctly attributed. The Stuxnet worm, which the US and Israeli governments developed and deployed in 2005 against an Iranian nuclear enrichment facility, was an example of such a CCA, until it was discovered in 2010. Even though the US government created a number of PCIs between 2005 and 2010 to signal an increase in its cybercapacity, none of them signaled the tremendous potential of the US cybercapability. Only the attributed Stuxnet worm signaled the true scope of the US cyber arsenal. Unlike PCIs, which send an immediate, although often imprecise signal about a state's level of cybercapabilities, the Stuxnet example demonstrates that CCAs send a more accurate signal of a state's cybercapabilities but this signal might be delayed.\nSince an investment in both PCIs and CCAs is important for overall cyber capacity, over-investment in PCIs at the expense of investment in CCAs can make a defender weaker. However, the relationship between the defender's overall cybercapacity and its chances at deterrence is not linear—i.e., an increase in one does not necessarily mean an increase in the other. Therefore, a defender with weak cybercapabilities might strategically invest more in PCIs if such an investment maximizes its chances at deterrence, even if it decreases its overall cybercapacity.\nWe argue that the effectiveness of this deterrent strategy depends on the type of the challenger. Specifically, it only works against a challenger that is susceptible to the costs created by PCIs. We call this challenger opportunistic. During the 2018 Swedish elections, Russia was an example of an opportunistic challenger. Having considered a potential interference campaign, the Kremlin realized that the rather small marginal value from this campaign was not worth the additional potential costs imposed by the improved defenses and offenses that Sweden created in the form of PCIs prior to the elections. But an over-investment in PCIs as a deterrent strategy does not work against an disinterested challenger; such challengers never attack, even if they give the impression that they are considering attacking. During the 2017 German elections, Russia was an example of a disinterested challenger. PCIs put in place prior to the 2017 elections had no\n⁹ It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.\n¹⁰ Given that early scholarly works perpetuated the offense dominance in cyberspace (Choucri 2012; Demchak 2011; Kello 2013), prevention is often seen as somewhat futile as it is nearly impossible to protect all vulnerable targets; thus, preemption may be a more cost-effective tactic. Recent works, however, refute the offense-dominance thesis (Gartzke 2013; Lindsay 2013). While it is easier to find a vulnerability in an adversary's network/system than to defend its own networks/systems from hundreds of possible cyberattacks, Slayton (2017) stresses the importance of looking at the cumulative effort required for building cyber offense or defense. Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\" (Slayton 2017, 74). Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense (Borghard and Lonergan 2017).\n1156\nDeterrence in the Cyber Realm\nFigure 1. Defender’s cybercapacity: (a) relationship between defender’s observed and overall cybercapacity; and (b) relationship between defender’s type and her overall cybercapacity as a function of $I_{\\theta}$. Note: $I$: PCIs that $D$ can develop with $r$ units of resources; $N$: CCAs that $D$ can develop with $r$ units of resources; $I + N$: $D$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}$: the level of PCIs at which $D$’s overall cybercapability is maximized (point Max). Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $\\text{Max}_{S}(\\text{Max}_{W})$).\neffect on Russia’s decision to stay away from these elections because a combination of non-cyber factors shifted Russia’s cost-benefit calculus towards not attacking even before Germany establish its PCIs. Lastly, an over-investment in PCIs is also a waste of resources when the defender faces a undeterred challenger; such challengers always attack because the value of attacking is much higher than any additional costs created by PCIs. During the 2017 French elections, Russia was an example of an undeterred challenger. Having witnessed the worldwide impact of the mass disclosures of private data prior to the 2016 US elections, Moscow was willing to pay any cost and to risk any potential French (cyber or non-) retaliation for its influence campaign, which could help elect a pro-Kremlin candidate.\nThe next section models cyber deterrence by PCIs explicitly. It is worth noting that since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though the type of an attempted attack requires different types of PCIs, this does not affect the model logic and the obtained results.\n## Model\nThis section provides the intuition behind the game and the Online Appendix includes the detailed explanation and mathematical proofs.\n**Game Overview.** This is a game between a challenger ($C$, “he”) and a defender ($D$, “she”). $C$ considers executing a cyberattack against $D$. To deter $C$, $D$ decides how to signal her cybercapacity by allocating her resources between public and private cybercapacity and, as a result, which level of PCIs to implement. $D$ has a type $\\theta \\in [S, W]$ that differs in the amount of resources $a_{\\theta}$ available to her. The strong defender $D_{S}$ has many more resources available to her than the weak defender $D_{W}$. $\\theta$ is unobservable to the challenger.\nThe game starts with Nature’s choice. Nature selects that $\\theta = S$ with probability $\\pi$ and that $\\theta = W$ with probability $1 - \\pi$. The model assumes that both players have a common prior belief and that $\\pi$ is the true probability that the defender is strong. Then $D$ decides how to allocate her resources between PCIs and CCA. After $D$ implements PCIs, $C$ observes it, (possibly) updates his beliefs about $D$’s type, and decides whether he wants to attack $D$. When $C$ chooses whether to attack, $C$ observes $D$’s move but not $D$’s type. If $C$ does not attack, $D_{\\theta}$ successfully deters $C$ and the game\nends. If $C$ decides to attack $D_{\\theta}$, Nature selects that his attack is successful with probability $Q_{\\alpha}$, and unsuccessful with probability $1 - Q_{\\alpha}$. The probability of a successful attack is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. If $C$’s attack succeeds, $D_{\\theta}$ must decide whether to retaliate against $C$. If $D_{\\theta}$ does not retaliate against $C$, the game ends. If $D_{\\theta}$ retaliates against $C$, Nature selects that her retaliation is successful with probability $P_{\\theta}$ and is unsuccessful with probability $1 - P_{\\theta}$. The probability of a successful retaliation is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.[12]\n**Signaling Cyber Capacity.** To understand how $D$ can deter strategic cyberattacks, we must first understand how she can create her cybercapacity because $D$’s cybercapacity is a proxy for $D$’s ability to deter $C$. The higher $D$’s capacity is, the higher the likelihood that $D$ deters $C$. To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA.[13] Both PCIs and CCA create $D$’s overall cybercapability. As mentioned earlier, $D$’s overall cybercapability does not necessarily increase simply by investing more in her PCIs because such a strategy takes valuable resources away from CCA. As a result, it makes $D$ weaker.\nFigure 1(a) explains the intuition of how this works graphically. $C$ has a prior belief of $D$’s cybercapability, given COs attributed to $D$ or using various indicators of $D$’s technological development. Given the public nature of PCIs, $C$ can only observe PCIs and estimate $D$’s cybercapability. We call it $D$’s observed cybercapability and place it on the x-axis in Figure 1(a). The y-axis in Figure 1(a) represents $D$’s overall cybercapability that we receive by adding the resources that $D$ invests into PCIs and CCAs. Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.[14] The\n[12] We display this two-player game with incomplete information concerning $D$’s type in Online Appendix Section 1.1.\n[13] Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.\n[14] I assume that both $I$ and $N$ are increasing in $r$ and that there are diminishing returns to investment in each (i.e. $I'(r), N'(r) &gt; 0$ and $I''(r), N''(r) &lt; 0$).\nNADIYA KOSTYUK\nFigure 2. Equilibria and challenger's types. Note:  $C$ : a challenger;  $D_W$ : a weak type of the defender;  $D_S$ : a strong type of the defender;  $\\pi$ : a prior probability that  $D$  is strong;  $1 - \\pi$ : a prior probability that  $D$  is weak; and  $\\tilde{I}_S$ : the level of PCIs at which overall cybercapability is maximized for the strong type of the defender. 1:  $C$ 's gains from attacking  $D_S$ , given the probability of this attack is successful; 2:  $C$ 's gains from attacking  $D$ , given that with  $\\pi$  probability he is facing  $D_S$  and with  $1 - \\pi$  probability, he is facing  $D_W$  that pools with  $D_S$  and implements  $\\tilde{I}_S$ ; and 3:  $C$ 's gains from attacking  $D_W$ , given the probability of this attack is successful.\nfunction  $I + N$  stands for  $D$ 's overall cybercapability when the resources are distributed between PCIs and CCAs. We define  $\\tilde{I}$  to be the level of PCIs at which  $D$ 's overall cybercapability is maximized (point Max in Figure 1a).\nBefore  $D$  creates her PCIs, often she already has some existing cybercapabilities. For instance, before the Swedish Civil Contingencies Agency (MSB) became responsible for election protection, it dealt with civil protection; MSB could use these expertise to provide public safety during the time of elections. This existing level of cybercapability determines  $D$ 's type. We distinguish two types of  $D$ -strong  $(D_S)$  and weak  $(D_W)$ .  $D_S$ , depicted by the black line in figure 1(b), has a higher level of existing cybercapability, thus she can implement a higher level of PCIs and have higher chances of deterrence than  $D_W$ , depicted by a gray line in figure 1(b). Similarly,  $\\tilde{I}_S$  and  $\\tilde{I}_W$  are the levels of PCIs at which overall cybercapability is maximized for the defender's weak and strong types, respectively.\nWe assume that the costs of producing public  $(I)$  and private  $(N)$  cybercapacity are the same for the strong and weak type of the defender because we primarily focus on explaining the behavior of middle powers. Some nations that have developed technological expertise in this area—cyber powers, for instance—can develop \"more\" capability for a given budget. In such cases, it might be difficult for other nations to imitate PCIs developed by these cyber powers. For these reasons, our model excludes these powerful nations and primarily focuses on the behavior of middle powers that can imitate each other's behavior in order to deter their challengers.\n# Model Equilibria\nNext we discuss the intuition behind the model equilibria.\nAs explained earlier, the effectiveness of the defender's PCIs on deterring the challenger, depends on the challenger's type. We distinguish three types of the challenger that depend on the three cut-off points depicted in figure 2. If  $C$  is undeterred and always attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region I in figure 2). If  $C$  is disinterested and never attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region IV in figure 2). In these two equilibria,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. Proposition 1 summarizes both equilibria.\nProposition 1. Challenger's decision to attack is independent of defender's PCIs.\n(a) If  $C$  is undeterred and always attacks (Region I in Figure 2),  $D_{0}$  maximizes her cybercapacity and  $C$  always attacks.\n(b) If  $C$  is disinterested and never attacks (Region IV in Figure 2),  $D_0$  maximizes her cybercapacity and  $C$  never attacks.\nIn both equilibria in Proposition 1,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. But what happens if they do? We argue that different types of the defender would invest their resources differently to maximize their chances of deterring adversaries that are susceptible to the costs created by PCIs. Specifically, the strategic use of PCIs to deter  $C$  occurs in the signaling region where there is both the need for and the possibility of deterrence. Here  $D_0$ 's PCIs can influence  $C$ , which will take different actions depending on the defender's true type. Specifically, the challenger will attack the defender if he knows that the defender is weak and will avoid attacking if he knows the defender is strong. We call this challenger opportunistic. In this region, depicted by Regions II and III in Figure 2, there are two pure strategy equilibria (Propositions 2-3) and one mixed strategy equilibrium. We focus on the pure strategy equilibria in the main manuscript and present the mixed equilibria in the Online Appendix.\nIf  $C$  prefers attacking a defender that he thinks is weak and avoiding attacking a defender that he thinks is strong due to the fear of retaliation or attack failure,  $D_W$ 's natural response is to increase her investment into PCIs to appear strong. Specifically, instead of redistributing her resources so that her overall cybercapability achieves its maximum (Max  $W$  in Figure 3 (a)),  $D_W$  distributes them so they are her overall cybercapability is at point A in Figure 3(a). By doing so,  $D_W$  creates the same level of PCIs  $(\\tilde{I}_S)$  as  $D_S$  (i.e.,  $D_W$  pools with  $D_S$ ), so when  $C$  observes these institutions, he concludes that he is dealing with a strong defender and does not attack. Because this deterrent strategy decreases  $D_W$ 's overall cybercapability, by appearing strong,  $D_W$ , in fact, hides her actual weakness. This pooling equilibrium holds only when  $D$ 's gain of appearing strong outweighs  $D$ 's loss to inefficiently allocating her resources and when  $C$ 's prior belief that  $D$  is strong is high. Proposition 2 presents this pooling equilibrium.\n# Proposition 2. Pooling Equilibrium.\nSuppose  $C$  is opportunistic and prefers attacking  $D$  only if he believes that  $D$  is weak. If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.[15]\n1158\nDeterrence in the Cyber Realm\nFigure 3. Defender's pure strategy actions when facing an opportunistic challenger: (a) pooling strategy; and (b) strategic separation strategy. Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$'s overall cybercapability when the resources are distributed between PCIs and CCAs; $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $Max_{S}(Max_{W})$); $\\hat{I}$: the level of PCIs that $D_{W}$ cannot attain; $A$: $D_{W}$ imitates PCIs of $D_{S}$; and $B$: $D_{S}$ strategically separates herself from $D_{W}$ by implementing PCIs that $D_{W}$ cannot implement.\nIf $C$'s prior belief that $D$ is strong is low, then $C$ interprets pooling as weak and attacks if $D$ implements $\\hat{I}_S$ (Region II of figure 2). $D_S$ is aware that $D_W$ is trying to imitate her PCIs and takes one of the two actions. Not wanting to be confused with $D_W$, $D_S$ can alter her behavior to clearly distinguish herself (i.e., separate) from $D_W$ to ensure that $C$ is deterred. Specifically, $D_S$ spends enough resources to reach a level of PCIs that $D_W$ cannot attain—$\\hat{I}$ (point B in Figure 3(b)). Observing $\\hat{I}$, $C$ knows that the defender is strong as $D_W$ could not implement $\\hat{I}$, as Figure 3(b) shows. Since $D_W$ cannot imitate $D_S$ and implement PCIs to reach $\\hat{I}$ in Figure 3(b), $D_W$ implements her optimal strategy $\\hat{I}_W$. Since separation is costly as it reduces $D_S$'s overall capacity, for this equilibrium to hold, $C$ should not attack when he sees $\\hat{I}$ even though he knows that $D_S$'s overall capacity is reduced. Proposition 3 summarizes this separating equilibrium.\n**Proposition 3.** Separating Equilibrium. Suppose $C$ is opportunistic and prefers attacking $D$ only if he believes that $D$ is weak. If $C$'s prior belief that $D$ is strong is low, then (1) $D_S$ implements a level of PCIs that $D_W$ cannot imitate $(\\hat{I} &gt; \\hat{I}_S)$, (2) $D_W$ is not able to pool with $D_S$ and implements $\\hat{I}_W$, and (3) $C$ attacks only when he sees $\\hat{I}_W$. [16]\nAlternatively, $D_{S}$ can decide not to implement PCIs that $D_{W}$ is not able to mimic because this will weaken her overall cybercapacity and invite an attack. In this case, a pure strategy equilibrium does not exist in Region II of Figure 2. But there exists a mixed strategy equilibrium where $D_{W}$ mixes between $\\hat{I}_{W}$ and $\\hat{I}_{S}$ and $C$ is indifferent between attacking and not. The Online Appendix presents this mixed strategy equilibrium.\n## Illustrative Examples of Elections\nThe novelty, secrecy, and sensitivity of the topic of cyber deterrence prevents us from conducting a rigorous empirical test of our findings. Instead, we aim at demonstrating the empirical plausibility of our theory of deterrence of strategic cyberattacks using PCIs. Since our theory is agnostic towards the type of a strategic cyberattack that a\nnation prefers to deter, we use illustrative examples from elections to provide support for our model equilibria. [17] Specifically, we focus on Kremlin-directed attempts to influence electoral campaigns in Western democracies: the 2016 US elections, the 2017 German elections, and the 2018 Swedish elections. We choose the most similar examples for our comparison (George 2019); they share the same cyber-capable attacker (Russia), have similar targets (Western democracies), use the same methods (cyber and information operations), have the same purpose (election interference), and have similar timeframes (2016–2018). They differ, however, in (1) the stakes involved in each campaign (e.g., a challenger's type); and (2) the level of PCIs that the targets implement (e.g., strong versus weak). As a result, these examples help demonstrate (1) under what conditions the challenger's uncertainty over the defender's cybercapacity increases the probability of successful deterrence; and (2) when this uncertainty has no effect.\nWe focus on the three different illustrative examples because they match the model's scope conditions that must be met if PCIs deter the challenger. First, there must be a difference in how different types of defenders allocate their resources to signal their cybercapacity. As we shortly demonstrate, the Swedish government, a weak cyber nation, prioritized investing in PCIs to appear that it had strong cyber defenses and offenses. Second, the challenger must face uncertainty about the defender's cybercapacity and its type. The time-limited and dynamic nature of COs generally raises uncertainty about cybercapacity, but this uncertainty over the defender's type does not play a role when facing an undeterred or disinterested challenger. But it is important when facing an opportunistic challenger: By investing more of its resources into PCIs, a weak defender can deter the challenger by pretending that it is strong. Uncertain about Sweden's actual cybercapacity, Russia observed the overwhelming number of PCIs that Sweden created prior its 2018 election that are typical of strong types; it is conceivable that based on these observations, the Kremlin chose not to attack. Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In\n[16] This equilibrium relies on the off-the-equilibrium beliefs that the defender is weak \"enough\" if it plays $\\hat{I}_S$.\n[17] We use an illustrative example to provide support only for the pooling equilibrium when the challenger is opportunistic (Region III in figure 2) because it provides the most interesting result by demonstrating when PCIs can, in fact, deter the challenger.\nNADIYA KOSTYUK\nthe elections we are considering, the cost-benefit calculations differ. In the 2018 Swedish elections, the additional costs created by Swedish PCIs outweighed the low value of Russia's interference campaign and deterred Russia from interfering. In the 2017 German elections, the Kremlin did not consider the extra costs created by PCIs because they were irrelevant—a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place. In the 2017 French elections, benefits outweighed the costs.\n# 2018 SWEDISH NATIONAL ELECTIONS: OPPORTUNISTIC CHALLENGER AND POOLING EQUILIBRIUM\nThe 2018 Swedish national elections provide support for the pooling equilibrium in which the weak defender over-invests in PCIs to appear strong and, as a result, deters the opportunistic challenger (Region III in Figure 2). To show that this is the case, we need to demonstrate that the Russian government was opportunistic and additional PCIs that Sweden created prior to the elections changed the Kremlin's cost-benefit calculation of the election interference campaign.\nTo understand how PCIs as a deterrent strategy worked in this case, we first explain why the Kremlin even considered interfering in the Swedish electoral process. Sweden's nonalignment policy has always served as a guarantee of Russia's security. Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO) (Kunz 2015). In response, Russia's Defense Minister Sergei Shoigu described Sweden's involvement in NATO activities as \"worrying\" and added that \"such steps...[were] forcing us to take response measures\" (Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister 2018). Military actions and/or economic sanctions are possible response measures, although to date, Russia has pursued neither of these. The Ukrainian and Syrian conflicts, combined with NATO-Swedish defense cooperation (even if it falls short of collective defense), are most likely responsible for preventing Russia from taking a military approach.\nRussia is, on the other hand, a mastermind of influence campaigns and had been preparing a strong foundation for such a campaign on the Swedish population for some time. Starting in 2014, the Swedish information landscape witnessed an increase in disinformation campaigns, led by trolls, bots, and Kremlin-sponsored media outlets, such as Sputnik International. In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\" (Cederberg 2018, 5) and Sweden remained one of the few \"favorite target[s] of the Kremlin's propaganda machine\" at the beginning of 2018 (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018, 109). Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks[18] against Swedish news sites and a disinformation campaign about NATO in the Swedish media.[19]\nAn anti-immigration sentiment in both the Swedish parliament and the populace bolstered these ongoing COs and information operations. Immigration has always been a contentious issue in Swedish politics, recently exacerbated by the Syrian refugee crisis. Over the last five years, Sweden, a country of 10 million, has welcomed 165,000 asylum-seekers from the Middle East. Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010 (Johnson and Evans 2018). The party's anti-immigration stance and the divide in the general population over the immigration issue presented the perfect environment for the Kremlin's influence campaigns.\nHowever, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference (Cederberg 2018). Why? What stopped Russia from interfering in the Swedish elections?\nLet us look at Russia's cost-benefit calculus. While Sweden had a favorable political climate and Russia had some ongoing COs and information operations, the value of a potential interference campaign was quite low, compared to, for instance, the interference into the US elections that we will discuss below. We argue that the low interference value, combined with additional costs created by PCIs that Sweden established prior to its elections, deterred Russia from interfering into the 2018 Swedish elections.\nIn addition to the PCIs outlined in the introduction, there are many others that the Swedish government established in order to raise the cost of election interference. Here are just a few examples. The government reiterated the protection of democracy as one of the country's top security objectives and designated its election systems as critical infrastructure. It tasked the Civil Contingencies Agency (MSB) and the Security Services and the Election Authority with coordinating election protection and made MSB responsible for countering Russian disinformation. Most importantly, Sweden's Prime Minister Stefan Lofven emphasized the country's military offensive cybercapability and the government's willingness to use it. When discussing a three-point plan to stop foreign powers from influencing the 2018 Swedish elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities (SverigesRadio 2017). Some might argue that factors other than PCIs deterred Russia. First is NATO's military capabilities. The NATO-Sweden cooperation defense pact that prioritizes security in the Baltic Sea region protects Sweden from a physical invasion by Russia (akin to those in Ukraine and Georgia) but not from election interference. Second is the threat of Western economic sanctions. The ineffectiveness of these sanctions in changing Moscow's behavior in Ukraine and Syria suggest that they are unlikely to have deterred the Kremlin from executing its plan. Third is Russia's lack of interest in interfering. While the interference value was low, preparatory influence operations aimed at undermining the 2018 Swedish elections demonstrate that the interest was, in fact, present (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018). Having ruled out the above factors, we have further evidence that Sweden's PCIs, put in place before elections, raised the cost of a potential election interference campaign and deterred Russia from interfering into the 2018 Swedish elections.\n# 2017 GERMAN FEDERAL ELECTION: DISINTERESTED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 German federal election provides support for the equilibrium in which the defender's PCIs have no effect on the challenger because the challenger is\n10 These attacks flood a website with multiple requests, making it crash.\n10 See https://www.documentcloud.org/documents/4627057-16-2517-CKK-2017-09-15-State-Production-3.html.\n1160\nDeterrence in the Cyber Realm\ndisinterested—the interference value is already so low that the challenger has no interest in interfering in the elections (Region IV in figure 2). We argue that German PCIs had no effect on Russia's decision to stay away from the 2017 German federal election. Instead, a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place.\nThe history of COs and information operations attributed to the Kremlin a few years prior to the election demonstrate that the Russian state had interest in German election interference. Information operations started in 2013, when three key German-language Kremlin-linked propaganda outlets—Sputnik Deutsch, RT Deutsch, and NewsFront Deutsch—entered the German market and were later joined by trolls²⁰ and bots.²¹ The 2015 and 2016 COs against the parliament and political parties demonstrate that Moscow was also eager to obtain sensitive information for potential future use. But the value of an effective influence campaign were overwhelmed by potential costs resulting from the following factors.\nFirst, Germany's balanced media systems, the lack of polarization among the German public, Germany's multiparty and proportional system, and a \"gentleman's agreement\" between major political parties not to use any information leaked as a result of cyberattacks made it difficult for Moscow to sow confusion in the public. (Schwirtz 2017). Second, the only clear beneficiary of these campaigns was the Alliance for Germany (AfD)—the rest of parties supported the sanction regime against Moscow. But when AfD entered the race, they only had between eight and ten percent of vote, which was not enough to gain the majority. Third, the use of old-fashioned paper ballots on the local level afforded Germany with an accurate recount in the event that digitized votes used on the federal level were compromised. Lastly, high-level deterrent rhetoric by German politicians referencing a deterioration of the relationship between the two countries if interference occurred likely played a part.²² Although Putin and Merkel's relationship has eroded over time, alienating Germany—an important bridge between the West and Russia—was not in Russia's interest.\nIf not these factors, what other factors could have stopped Russia from election interference? Brattberg and Maurer (2018) and Schwirtz (2017) suggest that a failure to influence the 2017 French presidential elections made the Kremlin re-think its approach, since it lost the element of surprise. While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives (Galante and EE 2018).\n## 2017 FRENCH ELECTION: UNDETERRED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 French elections provide an illustrative example for the equilibrium in which the defender's PCIs have no effect on the challenger because it is undeterred—the interference value significantly outweighs its costs (Region I in Figure 2). Given this high value, we argue that the Russian government was like an unstoppable tank moving towards its\ntarget and no French PCIs could have stopped the Kremlin from executing its plan.\nWhat was the value from interfering into the 2017 French elections? The lowest value was undermining faith in the democratic process whereas the highest value was electing a pro-Kremlin candidate that could have resulted in a change in French foreign policy. We argue that even the lowest value of the interference campaign was far greater than any costs Russia could envision paying.\nIf caught, Moscow knew that it faced potential (cyber and non-cyber) retaliation. Diplomatic retaliation was the least of Russia's worries considering some existing tension between the two countries. Moscow expected that, if elected, Emmanuel Macron—as the only unequivocal critic of Putin's Russia out of all presidential candidates—would only exacerbate this tension. The cost of additional economic sanctions—in addition to those that the country already faced for the Ukrainian conflict—was marginal. Nuclear and military responses to COs and information operations were off the table.\nGiven these rather low costs from non-cyber foreign policy options, what additional cyber costs could have Russia anticipated? French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations (Brattberg and Maurer 2018). Deterrence by punishment was unlikely to work either. Even if Paris targeted Russia's critical infrastructure (even though it is quite unlikely), the damage that Russia experienced would have been limited. For example, it is impossible to hack Russia's entire power grid system at once because most stations are manually controlled and can be restored by flipping a switch. Similarly, Paris was unlikely to attempt information operations because of the Kremlin's tight control of Russia's print, online, and social media and because of Russia's treatment of information as a weapon, allowing its military to respond to such information threats (Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space 2011).\nIn short, the potential worst-case scenario costs that Moscow faced were lower than the value it would gain by election interference. Thus, the Kremlin's interference campaign was never going to be deterred by French PCIs.\n## Discussion and Implications\nAs scholars and policymakers continue debating cyber deterrence using COs, attribution, and non-cyber threats, we explore the feasibility of cyber deterrence using means that have been largely overlooked by the international relations literature—public cyberinstitutions which signal organizational capacity to produce and use cybercapability to achieve strategic objectives.\nOur main contribution is to identify the precise conditions under which PCIs can deter strategic cyberattacks, which cause significant damage to a country's economy and security. Since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though different types attacks are deterred by different types of PCIs, the results do not change. Specifically, we reveal several important patterns of the strategic use of PCIs to deter challengers that differ by type. PCIs have no effect on disinterested challengers because they have no interest in attacking the defender and undeterred challengers because they have decided to attack even before observing the defender's PCIs. Both scenarios demonstrate that states are wasting their resources if they\n²⁰ A troll is someone who argues for extreme views without credible sources.\n²¹ An automated program that runs over the Internet.\n²² During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).\nNADIYA KOSTYUK\n1161\nuse PCIs as their deterrent strategy against disinterested and undeterred challengers.\nPCIs, however, can deter opportunistic challengers that only attack defenders that they perceive as cyber weak and avoid attacking those defenders that they perceive as cyber strong. To deter opportunistic challengers, weak cyber nations might choose to over-invest their limited resources into PCIs to appear strong. Strong cyber nations, in their turn, over-invest their limited resources into PCIs to distinguish themselves from weak cyber nations pretending to be cyber strong. This sub-optimal resource allocation, which makes the defender weaker in its overall cybercapacity, is worthwhile for weak cyber nations because it deters opportunistic challengers. These results have important theoretical and policy implications.\nOur findings shed light on a theoretical debate surrounding cyber deterrence (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). Similar to Tor (2017), this article stresses the need to re-think our reference to absolute nuclear deterrence as a matrix of deterrence success for cyberoperations. Countries do not create cybercapacity to deter low-level COs; instead, their goal is to stop adversaries from executing strategic cyberattacks, which can cause detrimental damage to the country's economy, prosperity, and security.\nWhat constitutes strategic cyberattacks, however, continues to evolve with changes in global cyberthreat landscape; countries only focused on critical infrastructure protection less than a decade ago and added election protection to their top national security priorities following the 2016 US elections. As countries re-define what constitutes strategic cyberattacks, adversaries find more creative ways to achieve their strategic goals using cyber means that operate below the strategic cyberattack threshold. For example, in response to Russia's meddling in the 2016 US elections, the US government took significant steps to protect its 2018 elections. In response to this stern measure, Russian bots and trolls adjusted their behavior and started operating during the election off-season. These influence campaigns, even if conducted during election off-seasons, shape public opinion and might affect public voting behavior. Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace (Murray and Mansoor 2012).\nOur results also show that states should take the signaling of cybercapacity via PCIs with a grain of salt. While PCIs serve as a cyberthreat assessment barometer because they allow a challenger to estimate a defender's ability to conduct COs, the defender's willingness to use these operations, and the scope of the defender's potential retaliation, this assessment is not precise. To better estimate the defender's cybercapacity, challengers should also examine other indicators, such as economic and technological achievements and the defender's reliance on the private sector for cybercapacity. This cumulative approach used to estimate cybercapacity will help governments better evaluate options that minimize the risk of escalation.\nFurthermore, our results speak to the scholarship in international relations theory that focuses on deterrence.[23] Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence.[24] We show that the challenger's\nchoice to cyberattack the defender is independent of the defender's PCIs in two equilibria. In the first one, the challenger has no interest in attacking the defender, giving a false impression of deterrence success. In the second one, the challenger has already decided to attack the defender, despite its PCIs, giving a false impression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios (Danilovic 2002; Snyder 1977). Before concluding the ineffectiveness of PCIs or other means of deterrence, researchers and policy-makers should consider these variables in their estimations. Moreover, since our model is limited to states that have limited cyber arsenals and are not able to burn their exploits to send deterrent signals, we expect to see more investment in PCIs among relatively weaker cyber nations or middle powers. But as more nations invest in PCIs, this deterrent approach might be less effective.\nWhile we take the first stab at understanding deterrence by PCIs, future research should further investigate this important mechanism. Here, we highlight a few venues that future research could explore. First, our model oversimplifies real-world scenarios by making assumptions to identify the causal effect of PCIs on deterrence chances. We view the challenger's choice to attack and the defender's choice to establish PCIs as a one-time decision. In practice, PCIs present a state's cumulative effort to boost its cybercapacity. Similarly, cyber and influence campaigns are composed of many, often low-level activities that span an extended period. Future research should explore how much updating-of-beliefs takes place during different stages of strategic cyberattacks and a state's cumulative efforts to build PCIs. Second, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities (Schneider 2019). Future iterations of this model should explore scenarios when it is not the case. For instance, when PCIs only signal an increase in offensive cybercapability, the threat of cyber retaliation might not deter a country that does not have many cyber targets, like North Korea. PCIs that only signal an increase in cyber defenses might deter countries that view attacking well-protected targets as too costly.\nThird, our model does not distinguish the defender by regime type. Democratic leaders are more transparent, responsive to constituents, and willing to provide public goods in the form of security to satisfy voters and secure their reelection (De Mesquita 2005). While autocracies might be less likely to create PCIs because they face a lesser demand to respond to their domestic audience, they, in fact, might be more likely to exaggerate their PCIs because of this lesser demand. Future research should investigate how these tendencies among different regime types affect model equilibria.\nAs Schelling (2008, 44) puts it, \"If deterrence fails, it is usually because someone thought he saw an 'option' that the... government had failed to dispose of, a loophole that it hadn't closed against itself.\" By building cybercapabilities, governments seem to assume that these capabilities alone have a deterrent effect. As my model demonstrates, successful deterrence depends on a defender's cybercapacity, its willingness to use it, and a challenger's type. Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or\n[23] For an overview of this scholarship, see Lupovici (2010).\n[24] We can describe undeterred challengers as resolute, opportunistic challengers as semi-resolute, and disinterested challengers as resolute.\n1162\nDeterrence in the Cyber Realm\nChina. In these cases, states might perceive potential consequences of entering an escalation cycle with such adversaries as too great to risk. To maximize the desired deterrent effect of publicly flexing their cyber muscles, nations' strategies should demonstrate their willingness to hold assets at risk and face consequences in cases of escalation. Only then, states will be able to close some of the loopholes that adversaries can exploit. Until that is done, the pessimistic view of cyber deterrence will persist.\n## Funding\nNadiya Kostyuk's work was partially supported by the William and Flora Hewlett Foundation under grant 2018-7727.",
  "references": [
    "## REFERENCES\nARENA, PHILIP, AND SCOTT WOLFORD. 2012. \"Arms, Intelligence, and War.\" *International Studies Quarterly* 56 (2): 351-65.\nAXELROU, ROBERT, AND RUBEN ILIFF. 2014. \"Timing of Cyber Conflict.\" *Proceedings of the National Academy of Sciences* 111 (4): 1298-303.\nBALIGA, SANDEEP, ETHAN BUENO DE MESQUITA, AND ALEXANDER WOLITZKY. 2020. \"Deterrence with Imperfect Attribution.\" *American Political Science Review* 114 (4): 1155-78.\nBEUTH, PATRICK, KAI BIERMANN, MARTIN KLINGST, AND HOLGER STARK. 2017. \"Merkel and the Fancy Bear.\" *ZEIT Online*.\nBORGHARD, ERICA D., AND SHAWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452-81.\nBRATTBERG, ERIK, AND TIM MAURER. 2018. *Russian Election Interference: Europe's Counter to Fake News and Cyber Attacks*. Vol. 23 Carnegie Endowment for International Peace.\nBUENO DE MESQUITA, ETHAN. 2007. \"Politics and the Suboptimal Provision of Counterterror.\" *International Organization* 61 (01): 9-36.\nCEDERBERG, GABRIEL. 2018. *Catching Swedish Phish: How Sweden is Protecting its 2018 Elections*. Cambridge, MA: Defending Digital Democracy Project, Belfer Center for Science and International Security.\nCHOUCHI, NAZLI., 2012. *Cyberpolitics in International Relations*. Cambridge, MA: MIT Press.\nCLARK, DAVID D., AND SUSAN LANDAU. 2011. \"Untangling Attribution.\" *Harvard Law School National Security Journal* 2: 323.\n*Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space*. 2011. Moscow: Ministry of Defence of the Russian Federation.\nDANILOVIC, VESNA. 2002. *When the Stakes Are High: Deterrence and Conflict Among Major Powers*. Ann Arbor, MI: University of Michigan Press.\nDE MESQUITA, BRUCE BUENO. 2005. *The Logic of Political Survival*. Cambridge, MA: MIT Press.\nDEBS, ALEXANDRE, AND NUNO P. MONTEIRO. 2014. \"Known Unknowns: Power Shifts, Uncertainty, and War.\" *International Organization* 68 (1): 1-31.\nDEMCHAK, CHRIS C. 2011. *Wars of Disruption and Resilience: Cybered Conflict, Power, and National Security*. Athens, GA: University of Georgia Press.\nDRAGU, TIBERIU. 2011. \"Is There a Trade-Off between Security and Liberty? Executive Bias, Privacy Protections, and Terrorism Prevention.\" *American Political Science Review* 105 (1): 64-78.\nEGLOFF, FLORIAN J., AND ANDREAS WENGER. 2019. *Public Attribution of Cyber Incidents*. Zurich: Center for Security Studies.\nFEARON, JAMES. 2002. \"Selection Effects and Deterrence.\" *International Interactions* 28 (1): 5-29.\nFEARON, JAMES D. 2018. \"Cooperation, Conflict, and the Costs of Anarchy.\" *International Organization* 72 (3): 523-59.\nFERNANDINO, LISA. 2018. *Cybercom to Elevate to Combatant Command*. Arlington, VA: US Department of Defense.\nGALANTE, LAURA, AND E. E. SHAUN. 2018. *Defining Russian Election Interference: An Analysis of Select 2014 to 2018 Cyber Enabled Incidents*. Washington, DC: Atlantic Council.\nGARTZKE, ERIK. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace back Down to Earth.\" *International Security* 38 (2): 41-73.\nGARTZKE, ERIK, AND JON R. LINDSAY. 2019. *Cross-Domain Deterrence: Strategy in an Era of Complexity*. Oxford, UK: Oxford University Press.\nGEORGE, ALEXANDER L. 2019. \"Case Studies and Theory Development: The Method of Structured, Focused Comparison.\" In *Alexander L. George: A Pioneer in Political and Social Sciences*, edited by D. Caldwell, 191-214. New York, NY: Springer.\nJOHNSON, SIMON, AND CATHERINE EVANS. 2018. \"Anti-Immigration Sweden Democrats Poll Record High ahead of September Election.\" *Reuters*.\nKELLO, LUCAS. 2013. \"The Meaning of the Cyber Revolution: Perils to Theory and Statecraft.\" *International Security* 38 (2): 7-40.\nKUNZ, BARBARA. 2015. \"Sweden's NATO Workaround: Swedish Security and Defense Policy against the Backdrop of Russian Revisionism.\" *Enote. Focus Strateguque*.\nKEDD, ANDREW. 2000. \"Arms Races and Arms Control: Modeling the Hawk Perspective.\" *American Journal of Political Science* 44 (2): 228-44.\nLINDAW, JON R. 2013. \"Stuxnet and the Limits of Cyber Warfare.\" *Security Studies* 22 (3): 365-404.\nLUPOVICI, AMS. 2010. \"The Emerging Fourth Wave of Deterrence theory-toward a New Research Agenda.\" *International Studies Quarterly* 54 (3): 705-32.\nMEROWITZ, ADAM, AND ANNE E. SARTORI. 2008. \"Strategic Uncertainty as a Cause of War.\" *Quarterly Journal of Political Science* 3 (4): 327-52.\nMORROW, JAMES D. 1989. \"Capabilities, Uncertainty, and Resolve: A Limited Information Model of Crisis Bargaining.\" *American Journal of Political Science* 33 (4): 941-72.\nMURRAY, WILLIAMSON, AND PETER R. MANSOOK. 2012. *Hybrid Warfare: Fighting Complex Opponents from the Ancient World to the Present*. Cambridge, UK: Cambridge University Press.\n*National Cybersecurity Policy*. 2017.\nNEWMAN, LILY HAY. 2019. \"What Israel's Strike on Hamas Hackers Means for Cyberwar.\" *Wired*. https://www.wired.com/story/israel-hamas-cyberattack-air-strike-cyberwar/\nNYE, JOSEPH S., JR. 2017. \"Deterrence and Dissuasion in Cyberspace.\" *International Security* 41 (3): 44-71.\nO'Dwyer, GERARD. 2018. \"Sweden Steps up Cyber Defence Measures.\" *ComputerWeekly.com*.\nPRESS, DARIY. GRAYSON. 2005. *Calculating Credibility: How Leaders Assess Military Threats*. Ithaca, NY: Cornell University Press.\n*Putin's Asymmetric Assault on Democracy in Russia and Europe*. 2018.\nREITER, DAN. 2003. \"Exploring the Bargaining Model of War.\" *Perspectives on Politics* 1 (1): 27-43.\nRETTMAN, ANDREW, AND LIBBETH KIRK. 2018. \"Sweden Raises Alarm on Election Meddling.\" *EU Observer*.\n*Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister*. 2018.\nSCHELLING, THOMAS C. 2008. *Arms and Influence: With a New Preface and Afterword*. New Haven, CT: Yale University Press.\nSCHNEIDER, JACQUELYN. 2019. \"Cyber and Cross Domain Deterrence: Deterring within and from Cyberspace.\" In *Cross-Domain Deterrence: Strategy in an Era of Complexity*, edited by LINDSAY, JON R., AND ERIK GARTZKE, chapter 5. Oxford, UK: Oxford University Press.\nSCHUITZ, KENNETH A. 1998. \"Domestic Opposition and Signaling in International Crises.\" *American Political Science Review* 92 (4): 829-44.\nSCHWIRTZ, MICHAEL. 2017. \"German Election Mystery: Why No Russian Meddling?\" *New York Times*.\nSLANTSCHEY, BRANISLAV L. 2003. \"The Power to Hurt: Costly Conflict with Completely Informed States.\" *American Political Science Review* 97 (1): 123-33.\nSLANTSCHEY, BRANISLAV L. 2005. \"Military Coercion in Interstate Crises.\" *American Political Science Review* 99 (4): 533-47.\nSLANTSCHEY, BRANISLAV L. 2010. \"Feigning Weakness.\" *International Organization* 64 (3): 357-88.\nSLATTON, REBECCA. 2017. \"What Is the Cyber Offense-Defense Balance? Conceptions, Causes, and Assessment.\" *International Security* 41 (3): 72-109.\nSANDER, JACK L. 1977. \"The Soviet Strategic Culture. Implications for Limited Nuclear Operations.\" *RAND Technical Report*, R-2154-AF, 1-38.\nSVERIGES RADIO. 2017. \"Swedish PM Warns of Foreign Influence ahead of 2018 Poll.\" *Radio Sweden*.\n*The US Department of Defense Cyber Strategy*. 2015.\nTOR, URI. 2017. \"Cumulative Deterrence' as a New Paradigm for Cyber Deterrence.\" *Journal of Strategic Studies* 40 (1-2): 92-117.\nVALERIANO, BRANDON, BENJAMIN JENSEN, AND RYAN C. MANESS. 2018. *Cyber Strategy: The Evolving Character of Power and Coercion*. Oxford, UK: Oxford University Press.\nWELBURN, JONATHAN WILLIAM, JUSTIN GRANA, AND KAREN SCHWINDT. 2019. \"Cyber Deterrence or: How We Learned to Stop Worrying and Love the Signal.\" RAND Technical Report, WR-1294-OSD, 1-46."
  ],
  "flat_text": "International Studies Quarterly (2021) 65, 1151-1162\n# Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\nNADIYA KOSTYUK\nSchool of Public Policy, Georgia Institute of Technology, USA\nCan cyber deterrence work? Existing scholarly works argue that deterrence by punishment using cyberattacks is ineffective because the difficulty of attributing the origin of cyberattacks makes the threat of future attacks less credible. However, these works have told us relatively little about the deterrence ability of public cyberinstitutions (PCIs), defined as publicly observable proactive efforts aimed at signaling a country's level of cyber offensive and defensive capability. This research shows that middle powers (that have scarce cyber arsenals) can use PCIs to deter cyber attacks that cause significant damage to their economy and prosperity; however, this deterrent capability is rather limited. Using an incomplete-information model, we demonstrate that PCIs only deter adversaries that are susceptible to the costs created by these institutions. Despite this limited deterrence ability, middle powers tend to over-invest resources in these cyberinstitutions: Weak cyber states tend to over-invest to convince strong cyber adversaries that they are strong, whereas strong cyber states over-invest so that adversaries do not believe that they are weak states pretending to be strong. By doing so, states reduce their overall cybercapacity. We establish the empirical plausibility of these results using election interference campaigns as examples of strategic attacks. Our focus on the strategic use of PCIs as a deterrent represents a departure from existing literature—which has focused only on cyberoperations—and has important policy implications.\nPuede funcionar la ciberdisuasión? Los trabajos académicos existentes sostienen que la disuasión mediante el castigo de los ciberataques es ineficaz porque la dificultad de atribuir el origen de los ciberataques hace menos creíble la amenaza de futuros ataques. Sin embargo, estos trabajos nos han aportado relativamente poco sobre la capacidad de disuasión de las ciberinstituciones públicas (Public Cyberinstitutions, PCI), definidas como esfuerzos proactivos públicamente observables destinados a señalar el nivel de capacidad ciberofensiva y defensiva de un país. Esta investigación muestra que las potencias medias (que disponen de escasos arsenales cibernéticos) pueden utilizar las PCI para disuadir los ciberataques que causan un daño importante a su economía y prosperidad; pero esta capacidad de disuasión es bastante limitada. Mediante un modelo de información incompleta, demostramos que las PCI solo disuaden a los adversarios que son susceptibles a los costos creados por estas instituciones. A pesar de esta limitada capacidad de disuasión, las potencias intermedias tienden a invertir en exceso sus recursos en estas instituciones cibernéticas: los ciberestados vulnerables tienden a invertir en exceso para convencer a los ciberadversarios fuertes de que son fuertes, mientras que los ciberestados fuertes invierten en exceso para que los adversarios no crean que son estados vulnerables que fingen ser poderosos. Al hacerlo, los estados reducen su cibercapacidad general. Determinamos la credibilidad empírica de estos resultados utilizando campañas de interferencia electoral como ejemplos de ataques estratégicos. Nuestro enfoque en el uso estratégico de las PCI como elemento de disuasión representa un cambio respecto a la literatura existente, que se ha centrado únicamente en las ciberoperaciones, y tiene importantes implicaciones políticas.\nLa cyber-dissuasion peut-elle fonctionner? Les travaux de recherche existants soutiennent que la dissuasion par une sanction reposant sur des cyber-attaques est inefficace car la difficulté de détermination de l'origine des cyber-attaques rend la menace de futures attaques moins crédible. Toutefois, ces travaux ne nous ont donné que relativement peu d'informations sur la capacité de dissuasion des cyber-institutions publiques, qui est définie comme étant constituée des efforts proactifs publiquement observables visant à signaler le niveau des cyber-capacités offensives et défensives d'un pays. Cette recherche montre que les puissances intermédiaires (qui disposent de cyber-arsenaux limités) peuvent avoir recours aux cyber-institutions publiques pour dissuader les auteurs de cyber-attaques nuisant considérablement à leur économie et à leur prospérité, mais cette capacité de dissuasion est plutôt limitée. Nous nous appuyons sur un modèle d'information incomplète et nous démontrons que les cyber-institutions publiques ne dissuadent que les adversaires qui sont sensibles aux coûts engendrés par ces institutions. Malgré cette capacité de dissuasion limitée, les puissances intermédiaires tendent à surinvestir des ressources dans ces cyber-institutions : les cyber-États faibles tendent en effet à surinvestir pour convaincre leurs puissants cyber-adversaires qu'ils sont forts, tandis que les cyber-États forts tendent à le faire afin que leurs adversaires ne croient pas qu'ils sont faibles alors qu'ils se prétendent forts. Ce faisant, les États réduisent leur cyber-capacité globale. Nous établissons la plausibilité empirique de ces résultats en nous basant sur les campagnes d'ingérence électorale comme exemples d'attaques stratégiques. Notre concentration sur l'utilisation stratégique des cyber-institutions publiques comme dissuasion diverge de la littérature existante qui s'est uniquement concentrée sur les cyber-opérations et a d'importantes implications politiques.\n\"To those thinking about trying to influence the outcome of the elections in our country: Stay away!\" (as quoted in Cederberg 2018, 11). Sweden's Prime Minister Stefan Löfven articulated this warning and the country's willingness to act in the event of election interference at a security conference in January 2018. The Swedish government\nNadiya Kostyuk is an Assistant Professor, School of Public Policy, Georgia Institute of Technology.\nAuthor's note: I would like to thank Erica Borghard, Aaron Brantly, Ben Buchanan, John Ciorciari, Fiona Cunningham, Tiberiu Dragu, Mathias Frendem, Andres Gannon, Erik Gartzke, John Leahy, Susan Landau, Herb Lin, Jon Lindsay, Shawn Lonergan, Carla Martinez Machain, Tamar Mitts, James D. Morrow, Jacquelyn Schneider, Jeffrey W. Taliaferro, Brandon Valeriano, Ketian Zhang, Yuri M. Zhukov, and the participants of the Peace and Science Society International pre-conference workshop, of the Student Cybersecurity Symposium at Tufts University, of the International Security Seminar at the Belfer Center for Science and Technology at Harvard Kennedy School, of the Peace Science OPSC, and of the Cybersecurity Series at the Stanford Center for International Security and Cooperation. This paper was presented at the 2019 International Studies Association Conference.\nKostyuk, Nadiya (2021) Deterrence in the Cyber Realm: Public versus Private Cyber Capacity. International Studies Quarterly, doi: 10.1093/isq/sqab039\n© The Author(s) (2021). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nDeterrence in the Cyber Realm\nsubstantiated this rather bold statement with a number of measures meant to deter potential intruders. Specifically, in preparation to its September 2018 election, the country created a number of public cyberinstitutions (PCIs)—publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities.\nSome of these measures aimed at creating better cyber defenses to “raise the threshold [of] attacking Sweden” (National Cybersecurity Policy 2017, 19). Specifically, the government increased the budgets of existing agencies to include election protection into their scope, and it established new agencies, forums, and programs to protect against election interference and disinformation campaigns. For instance, the Swedish government’s crisis preparation and response agency became the main authority for election coordination. The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’” (SverigesRadio 2017). Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats (Cederberg 2018). Media, political parties, and schools ran similar education campaigns. To prepare for total defense awareness, including cases of cyber emergencies, MSB also sent a pamphlet titled “If Crisis or War Comes” to all 4.7 million households.\nIn addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats (Rettman and Kirk 2018). The National Defense Radio Establishment and the Military Intelligence and Security Service installed special detection and warning systems to guard against foreign powers hacking into sensitive agencies. The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators” (O’Dwyer 2018).\nWe argue that these PCIs established by the Swedish government in order to protect its 2018 elections convinced the Russian government that an interference campaign would have been too costly. Why were PCIs successful in deterring a potential interference campaign? Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy (Fernandino 2018)—under what conditions can PCIs deter any strategic cyberattack?\nTo answer these questions, we develop an incomplete-information model in which a challenger considers attacking a defender. The defender in this case is a middle power, since these nations have scarce cyber arsenals and are more likely to invest in PCIs for deterrence. The challenger is not certain about the defender’s cybercapacity—how cyber “strong” or “weak” it is—and can only infer it from the defender’s observable PCIs. Thus, the challenger’s decision to attack depends on the defender’s type, and the defender has an incentive to over-invest in public cybercapacity in order to signal that it is stronger that it actually is.\nThis model leads to several insights. First, there is a large number of equilibria for which PCIs have no influence on the challenger. Second, we show that the defender’s strategic use of PCIs to deter the challenger works only when two conditions are met: (1) the challenger believes that the defender possesses significant cybercapabilities and that it would therefore be too costly to attack the defender; and (2) the challenger is susceptible to the cost exacted by PCIs. This finding shows that PCIs influence the challenger’s decision to attack only in limited cases. Despite that, weaker defenders over-invest in PCIs to signal higher cybercapacity than they possess, and strong defenders over-invest so that their adversaries do not believe that they are weak states pretending to be strong.\nThis paper makes a number of theoretical contributions to the existing international-relations literature. First, it helps us better understand the nature of deterrence in the information age. Our unique strategic logic of PCIs as a proxy for a country’s cybercapacity represents a departure from existing literature. While most scholarly works on cyber-to-cyber deterrence focuses on deterrence by punishment using cyberoperations (Baliga, de Mesquita, and Wolitzky 2020; Valeriano, Jensen, and Maness 2018), this project presents a new theory that explains how PCIs can deter by both prevention and by threat of punishment, by signaling an increase in both defensive and offensive cybercapabilities. This project also contributes to the literature on cross-domain deterrence (Gartzke and Lindsay 2019) by explaining situations in which countries use PCIs to deter their adversaries instead of non-cyber foreign policy options (i.e., economic sanctions, or diplomatic or military responses) that are ineffective and/or costly.\nSecond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). We, instead, seek to explain the strategic behavior of weaker cyber states or middle powers that suspect a cyberattack. In these situations, middle powers often must rely on their own cybercapabilities because their allies are unlikely to help. Cyberdefenses are unique to each country and not easily transferable; close allies are often reluctant to disclose information about their offensive cybercapabilities and/or commit cyberattacks on an ally’s behalf (as compared with their willingness to offer military assistance during territorial invasions).\nThe literature on the “bargaining model of war” focuses on how private information and incentives to misrepresent, and commitment problems affected by power shifts, explain costly armed conflict (e.g., Schultz 1998; Slantchev 2003, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power (Morrow 1989); states also tend to keep certain capabilities secret to obtain military advantage (Reiter 2003).\nWhat is new about our model then? First, a different theoretical foundation drives how nations signal their cybercapacities. Unlike in the case of military capacity, a state cannot launch a parade to signal its cybercapacity. Satellite images are also unlikely to be useful to adversaries seeking to estimate a state’s cyberstrength. An executed cyberattack may provide a target with a good estimate of the attacker’s capabilities, but such an attack de-values capability because it provides the target with instructions on how to fix flaws in their own networks and systems. The time-limited life-span and the dynamic nature of cyberoperations further complicate their signaling potential. While the basic parameters for most traditional weapons remain relatively static,\n\nNADIYA KOSTYUK\n\nSecond, existing models focus only on whether and how investment in military capacity can deter a future attack or affect the likelihood of winning a war. Our theoretical foundation instead explains that sources of state cybercapacity are more diverse, lie beyond military and government, and extend to a state's private sector and even public-opinion management. While investing in military cybercapacity is important for deterrence by the threat of punishment, to deter adversaries by prevention, states might, for example, invest significant resources into building public awareness about the danger of cyberoperations and information operations, making potential election-interference campaigns harder.\nRegarding the model, the closest work, which focuses on the relative impact of scarce resource allocation on the likelihood of attack, is Arena and Wolford (2012). Unlike Arena and Wolford (2012), which examines a state's decision to allocate its resources between armaments and intelligence gathering capabilities in order to reduce uncertainty over its opponent's military strength, our model explores a state's decision to allocate its resources between public and private cybercapacity in order to deter its strong opponent from executing a cyberattack against the state. Similarly to works on counter-terrorism policies (Bueno de Mesquita 2007; Dragu 2011), our model explains why nations over-invest in public capacity and that such policies are generally ineffective in deterring adversaries.\nBaliga, de Mesquita, and Wolitzky (2020) and Welburn, Grana, and Schwindt (2019) are the only two other models that focus on cyberdeterrence; they explore how a state's inability to correctly attribute the origin of cyber operations and to detect cyberattacks affects the state's chances of deterring potential attackers. Unlike these models, our model focuses on organizational capability which signals the state's ability to readily produce and use covert cybercapacity. Unlike Baliga, de Mesquita, and Wolitzky (2020)'s model, in which there is uncertainty over the signal's sender (i.e., the attacker's identity) while the signal's quality (i.e., the strength of cybercapacity) is clear, our model investigates situations in which the signal's sender is known but the signal's quality is unclear. Unlike Welburn, Grana, and Schwindt (2019)'s model, in which a defender can signal any cybercapability with no cost, our model explains how the defender's choice to allocate its limited resources translates into observable cybercapacity.\nThe paper proceeds as follows. We start with explaining how a state can signal its cybercapacity. Then, we explain when and how public cyberinstitutions can deter strategic cyberattacks. Next, we introduce the model and derive the model equilibria. We use illustrative examples from elections to establish the empirical plausibility of our theory. We conclude with a discussion of our study's implications.\n## Signaling Cybercapacity\nStates can signal their cybercapability by (1) attributing cyber operations (COs) to attackers; (2) executing COs against adversaries; and (3) establishing public cyberinstitutions—publicly observable efforts aimed at demonstrating a country's level of offensive and defensive cybercapability. Each of these methods has its pros and cons.\nSignaling cybercapacity via attribution is a recent trend, as demonstrated by the number of US indictments. Attribution is a powerful deterrent because it signals to both the attacker and future perpetrators that they are not as invisible as they would like to be in cyberspace. But cyber attribution is difficult and costly: Not only does cyber attribution require significant resources and technical expertise to correctly attribute an attack to a specific computer, but it also demands intelligence to connect the used computer to a perpetrator. Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources (Clark and Landau 2011; Egloff and Wenger 2019). As a result, only a few nations have the resources, technical expertise, and political will to use attribution as a way to signal their cybercapability.\nSignaling cybercapacity via covert COs provides the target with an accurate estimate of the attacker's capability. However, the difficulty of attributing the origin of COs and the time it takes to do so diminish the signal's value, which is further reduced by the time-limited life-span and the dynamic nature of COs. Moreover, if a victim is not able to attribute the attack or remains quiet about the attack, the signaling value of COs is either zero or quite low. Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons (Gartzke 2013); only a few nations have a large enough cyber arsenal that they can burn some of their exploits for signaling purposes.\nWhile cybercapacity cannot be revealed because it depends on secret access and vulnerabilities, the state can reveal its ability to find such vulnerabilities by establishing PCIs, defined as publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities. PCIs signal an increase in organizational cybercapability, which demonstrates the state's ability to readily produce cybercapability and use cyberoperations for political purposes. As a result, signaling via PCIs provides the state's allies, adversaries, and domestic and international audiences with an immediate, often rough proxy for the state's cybercapacity and preserves the value of the state's covert COs.\nFor simplicity, I distinguish two ways in which a state can establish its PCIs: It can (1) create a new agency program, initiative, doctrine, strategy, or policy to address some aspect of cybersecurity; and/or (2) add new cyber roles to existing agencies or new cyber provisions to existing policies. For instance, to deter election interference campaigns, Sweden established an agency responsible for psychological defense. When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time (Schwirtz 2017).\n5Some of these works include Debs and Monteiro (2014), Fearon (2018), Kydd (2000), Meirowitz and Sartori (2008), and Slantchev (2005).\n4Germany's hack-back strategy is a PCI even though the government does not give any details regarding the scope of this strategy. Since they publicly discussed its development (instead of only privately executing it), we have an idea of the steps that the German government considers adopting in order to deter election interference. If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage (Schwirtz 2017). For instance, in response to the attack against the parliament, the German government could remove servers on which stolen parliament data were located.\n\nEven though these two options differ in how governments created their PCIs, they both might involve a similar set of measures. Specifically, a new agency and a new strategy might require additional budget, stuff, training, and expertise. While PCIs often do not reveal all the details about created cybercapacity, unlike covert cyberactivity they allow an adversary to estimate the scope of the change and the potential resulting increase in the target state's cybercapacity. The Swedish and German actions, for instance, signaled that both countries prioritized spending their resources on building better cyber defensive and offensive capabilities to deter potential election interference campaigns.\nBefore we explain how PCIs can deter adversaries, we would like to clarify that our theory focuses on middle powers—the nations that have scarce cyber arsenals and are more likely to invest in PCIs as a means of deterrence. Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by \"burning\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities.\n## The Theory of Cyber Deterrence\nThe theory presented in this section examines the specific context in which a strong challenger (including cyber powers) contemplates a strategic cyberattack against a defender.\nWhen the challenger considers a cyberattack, he calculates the value he can gain from this attack (e.g., undermining democratic processes, in the case of election interference) and the cost he can incur. There are two types of costs. First is the cost of the defender's potential retaliation (e.g., using economic sanctions, military operations or cyberoperations). Second is the tendency of cyberoperations—unlike military operations—to diminish in value after their first use. A tank, for example, can be successfully deployed many times over many years. Cyberattacks, on the other hand, often lose their effectiveness after their first use, even if the attack fails due to the defender's defenses. In using cyberattacks, the challenger risks the possibility that the defender might be able to develop protection against similar attacks in the future.\nWe argue that, for a challenger to decide to use a cyberattack against a defender, it must believe that the attack's value will outweigh its cost. What can change this cost-benefit calculation? Specifically, what can raise the cost enough to deter the challenger?\nWe assume that the costs from non-cyber foreign policy tools (i.e., diplomatic or military responses, or economic sanctions) will not change the cost-benefit calculation because the challenger has considered them initially. These costs are easy to estimate using the defender's past history and are highly predictable based on the challenger's \"prior beliefs about the defender's willingness\" to use one\nSome anecdotal evidence suggests that even though the US government could not hack back in response to the election, it went into Russian servers and left non-malicious code that had \"U.S. Cyber Command\" in the comments. They did so to signal to the Russians, in a covert way, that they had the ability to strike whenever they wanted.\nI employ the language from the traditional deterrence literature and refer to an adversary as a challenger and a defending state as a defender. The model makes the assumption that the defender attempts to deter her strongest challenger, which is the challenger that can potentially cause the most significant damage. If she is able to deter her strongest challenger, then all her other challengers will be deterred by default. Because the model focuses only on the strong challenger, I have omitted \"strong\" and refer only to a \"challenger\" for the remainder of the paper.\nof these options (Fearon 2002, 6). Moreover, given that the defender's capability in non-cyber foreign policy domains is unlikely to change rapidly, the challenger's estimate of the costs imposed by diplomatic responses and economic sanctions is likely to be fairly accurate. The challenger is also aware that military responses are costly and that the defender is unlikely to launch a military strike in response to information operations or cyberoperations.\nEven though these non-cyber foreign policy tools cannot change the challenger's cost-benefit calculation, the challenger considers the defender's capability in these non-cyber domains when forming its opinion of the defender's cybercapacity. Since nations with significant resources and expertise can build sophisticated cyber weapons (Gartzke 2013), the challenger can accurately conclude that the most powerful military nations have impressive cyber arsenals. While the country's military capability might often be correlated with its cybercapacity, it is not always the case because some nations might choose to purchase cyber weapons from third parties or work with proxy groups to execute attacks on their behalf. Despite that we argue that both the defender's capability in non-cyber and the defender's capability in cyber domains form the challenger's prior belief of the defender's cybercapacity.\nGiven that the challenger is quite certain about the costs associated with non-cyber responses and, as a result, is unlikely to be deterred by them, the defender is left with cyber foreign policy tools to deter the challenger from executing cyberattacks. We argue that cyber foreign policy tools may raise the cost of a cyberattack for the challenger because the challenger remains uncertain about the defender's cybercapacity. Even if the challenger has a rough estimate of the defender's cybercapacity, the dynamic, time-limited nature of cyber tools makes it difficult for the challenger to determine the defender's cybercapacity with precision or certainty. Specifically, while the basic parameters for most traditional weapons remain relatively static, strategically relevant features of certain cyber weapons can change significantly over a short period of time. Moreover, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it (Axelrod and Iliev 2014). We explore this challenger's uncertainty over the defender's cybercapacity as the main mechanism that affects the probability of successful deterrence. How can the defender signal its cybercapacity\nThe Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations (Newman 2019).\nFor deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity (Schelling 2008). Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high (Press 2005). Moreover, as earlier explained, many nations cannot afford to \"burn\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities, and those that do send a rather costly signal about their sophisticated cyber arsenal. Furthermore, many countries conduct cyber espionage to observe other countries' cyberattack plans and capabilities. As a result, cyber powers that consider challenging other nations probably know enough about other countries' covert cyber strength to know whether they face another cyber power or not, though they do not necessarily know its precise capabilities. Thus, there is no uncertainty about the capabilities of these cyber powers; instead, this theory explores uncertainty over the capabilities of weaker nations—middle powers—and specifically how cyber \"strong\" or \"weak\" they are. These nations tend to have a rather scarce cyber arsenal and are more likely to invest in PCIs as a means of deterrence. However, the better a challenger's cyber-intelligence, the less uncertainty the challenger has about the defender's cybercapacity.\nNADIYA KOSTYUK\n\n## Deterrence by PCIs\nPCIs can leave the challenger uncertain about the defender's cybercapacity because they demonstrate the defender's ability to produce cybercapability without revealing any concrete details about this capability. PCIs can deter by prevention and/or by threat of punishment. These two types of deterrence are associated with the two types of costs that PCIs can inflict on the challenger, increasing the cost of its cyberattack. PCIs can deter by prevention because adversaries may infer that their attacks are likely to fail against the defenses implied by a PCI. Firewalls, updated computer software, programs aimed at educating public about cyberthreats, and policies that outline a set of measure to provide better security of critical infrastructure are examples of PCIs that can deter by prevention because they make hacking more difficult. While the challenger can keep using conventional weapons even if a conventional attack fails, the challenger often burns its cyber exploits in the case of an unsuccessful cyberattack. This is because having discovered an attempted hack, the defender can close the existing vulnerability making the future use of this exploit impossible. PCIs can also deter by the threat of punishment; for instance, new military doctrines and units signal the state's ability to use its cyber weapons in response to cyberthreats.\nWe investigate situations in which both deterrence mechanisms are at play for the following two reasons. First, one cyberinstitution can signal both cyber offensive and defensive capability, making it hard to separate deterrence by the threat of punishment from deterrence by prevention. The US Department of Defense Cyber Strategy (2015, 3), for instance, uses deterrence by prevention by specifying the Department of Defense's role in defending its information networks, and it uses the threat of punishment by establishing a Cyber Mission Force to be used to defend the United States against cyberattacks of \"significant consequence\". Second, when facing a strategic cyberthreat, states tend to respond with multiple PCIs and, as a result, implement both types of deterrence at the same time to maximize their chances of success.\nSince PCIs can increase uncertainty about the defender's cybercapacity raising the probability of successful deterrence, the defender might want to invest most, if not all, of its resources into PCIs. But such a strategy takes valuable resources away from covert cyberactivity (CCA) or private cybercapacity, which involves secret development of cybercapabilities and ongoing cyberoperations. For instance, a polished strategy document, newly-constructed headquarters, or a new initiative meant to bring public awareness of cyberthreats is a poor substitute for a CCA aimed at penetrating the challenger's electricity grid and preparing for a future attack that could be used for retaliation.\nWe argue that this trade-off between PCIs and CCAs is important. Even though some PCIs involve the development of private cybercapability (e.g., the German's hack-back strategy), such PCIs give a high-level view on what capacity a government develops whereas CCAs remain truly covert and only signal capability after being discovered and correctly attributed. The Stuxnet worm, which the US and Israeli governments developed and deployed in 2005 against an Iranian nuclear enrichment facility, was an example of such a CCA, until it was discovered in 2010. Even though the US government created a number of PCIs between 2005 and 2010 to signal an increase in its cybercapacity, none of them signaled the tremendous potential of the US cybercapability. Only the attributed Stuxnet worm signaled the true scope of the US cyber arsenal. Unlike PCIs, which send an immediate, although often imprecise signal about a state's level of cybercapabilities, the Stuxnet example demonstrates that CCAs send a more accurate signal of a state's cybercapabilities but this signal might be delayed.\nSince an investment in both PCIs and CCAs is important for overall cyber capacity, over-investment in PCIs at the expense of investment in CCAs can make a defender weaker. However, the relationship between the defender's overall cybercapacity and its chances at deterrence is not linear—i.e., an increase in one does not necessarily mean an increase in the other. Therefore, a defender with weak cybercapabilities might strategically invest more in PCIs if such an investment maximizes its chances at deterrence, even if it decreases its overall cybercapacity.\nWe argue that the effectiveness of this deterrent strategy depends on the type of the challenger. Specifically, it only works against a challenger that is susceptible to the costs created by PCIs. We call this challenger opportunistic. During the 2018 Swedish elections, Russia was an example of an opportunistic challenger. Having considered a potential interference campaign, the Kremlin realized that the rather small marginal value from this campaign was not worth the additional potential costs imposed by the improved defenses and offenses that Sweden created in the form of PCIs prior to the elections. But an over-investment in PCIs as a deterrent strategy does not work against an disinterested challenger; such challengers never attack, even if they give the impression that they are considering attacking. During the 2017 German elections, Russia was an example of a disinterested challenger. PCIs put in place prior to the 2017 elections had no\n It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.\n Given that early scholarly works perpetuated the offense dominance in cyberspace (Choucri 2012; Demchak 2011; Kello 2013), prevention is often seen as somewhat futile as it is nearly impossible to protect all vulnerable targets; thus, preemption may be a more cost-effective tactic. Recent works, however, refute the offense-dominance thesis (Gartzke 2013; Lindsay 2013). While it is easier to find a vulnerability in an adversary's network/system than to defend its own networks/systems from hundreds of possible cyberattacks, Slayton (2017) stresses the importance of looking at the cumulative effort required for building cyber offense or defense. Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\" (Slayton 2017, 74). Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense (Borghard and Lonergan 2017).\n\nFigure 1. Defender’s cybercapacity: (a) relationship between defender’s observed and overall cybercapacity; and (b) relationship between defender’s type and her overall cybercapacity as a function of $I_{\\theta}$. Note: $I$: PCIs that $D$ can develop with $r$ units of resources; $N$: CCAs that $D$ can develop with $r$ units of resources; $I + N$: $D$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}$: the level of PCIs at which $D$’s overall cybercapability is maximized (point Max). Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $\\text{Max}_{S}(\\text{Max}_{W})$).\neffect on Russia’s decision to stay away from these elections because a combination of non-cyber factors shifted Russia’s cost-benefit calculus towards not attacking even before Germany establish its PCIs. Lastly, an over-investment in PCIs is also a waste of resources when the defender faces a undeterred challenger; such challengers always attack because the value of attacking is much higher than any additional costs created by PCIs. During the 2017 French elections, Russia was an example of an undeterred challenger. Having witnessed the worldwide impact of the mass disclosures of private data prior to the 2016 US elections, Moscow was willing to pay any cost and to risk any potential French (cyber or non-) retaliation for its influence campaign, which could help elect a pro-Kremlin candidate.\nThe next section models cyber deterrence by PCIs explicitly. It is worth noting that since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though the type of an attempted attack requires different types of PCIs, this does not affect the model logic and the obtained results.\n## Model\nThis section provides the intuition behind the game and the Online Appendix includes the detailed explanation and mathematical proofs.\n**Game Overview.** This is a game between a challenger ($C$, “he”) and a defender ($D$, “she”). $C$ considers executing a cyberattack against $D$. To deter $C$, $D$ decides how to signal her cybercapacity by allocating her resources between public and private cybercapacity and, as a result, which level of PCIs to implement. $D$ has a type $\\theta \\in [S, W]$ that differs in the amount of resources $a_{\\theta}$ available to her. The strong defender $D_{S}$ has many more resources available to her than the weak defender $D_{W}$. $\\theta$ is unobservable to the challenger.\nThe game starts with Nature’s choice. Nature selects that $\\theta = S$ with probability $\\pi$ and that $\\theta = W$ with probability $1 - \\pi$. The model assumes that both players have a common prior belief and that $\\pi$ is the true probability that the defender is strong. Then $D$ decides how to allocate her resources between PCIs and CCA. After $D$ implements PCIs, $C$ observes it, (possibly) updates his beliefs about $D$’s type, and decides whether he wants to attack $D$. When $C$ chooses whether to attack, $C$ observes $D$’s move but not $D$’s type. If $C$ does not attack, $D_{\\theta}$ successfully deters $C$ and the game\nends. If $C$ decides to attack $D_{\\theta}$, Nature selects that his attack is successful with probability $Q_{\\alpha}$, and unsuccessful with probability $1 - Q_{\\alpha}$. The probability of a successful attack is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. If $C$’s attack succeeds, $D_{\\theta}$ must decide whether to retaliate against $C$. If $D_{\\theta}$ does not retaliate against $C$, the game ends. If $D_{\\theta}$ retaliates against $C$, Nature selects that her retaliation is successful with probability $P_{\\theta}$ and is unsuccessful with probability $1 - P_{\\theta}$. The probability of a successful retaliation is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.[12]\n**Signaling Cyber Capacity.** To understand how $D$ can deter strategic cyberattacks, we must first understand how she can create her cybercapacity because $D$’s cybercapacity is a proxy for $D$’s ability to deter $C$. The higher $D$’s capacity is, the higher the likelihood that $D$ deters $C$. To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA.[13] Both PCIs and CCA create $D$’s overall cybercapability. As mentioned earlier, $D$’s overall cybercapability does not necessarily increase simply by investing more in her PCIs because such a strategy takes valuable resources away from CCA. As a result, it makes $D$ weaker.\nFigure 1(a) explains the intuition of how this works graphically. $C$ has a prior belief of $D$’s cybercapability, given COs attributed to $D$ or using various indicators of $D$’s technological development. Given the public nature of PCIs, $C$ can only observe PCIs and estimate $D$’s cybercapability. We call it $D$’s observed cybercapability and place it on the x-axis in Figure 1(a). The y-axis in Figure 1(a) represents $D$’s overall cybercapability that we receive by adding the resources that $D$ invests into PCIs and CCAs. Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.[14] The\n[12] We display this two-player game with incomplete information concerning $D$’s type in Online Appendix Section 1.1.\n[13] Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.\n[14] I assume that both $I$ and $N$ are increasing in $r$ and that there are diminishing returns to investment in each (i.e. $I'(r), N'(r) &gt; 0$ and $I''(r), N''(r) &lt; 0$).\nNADIYA KOSTYUK\nFigure 2. Equilibria and challenger's types. Note:  $C$ : a challenger;  $D_W$ : a weak type of the defender;  $D_S$ : a strong type of the defender;  $\\pi$ : a prior probability that  $D$  is strong;  $1 - \\pi$ : a prior probability that  $D$  is weak; and  $\\tilde{I}_S$ : the level of PCIs at which overall cybercapability is maximized for the strong type of the defender. 1:  $C$ 's gains from attacking  $D_S$ , given the probability of this attack is successful; 2:  $C$ 's gains from attacking  $D$ , given that with  $\\pi$  probability he is facing  $D_S$  and with  $1 - \\pi$  probability, he is facing  $D_W$  that pools with  $D_S$  and implements  $\\tilde{I}_S$ ; and 3:  $C$ 's gains from attacking  $D_W$ , given the probability of this attack is successful.\nfunction  $I + N$  stands for  $D$ 's overall cybercapability when the resources are distributed between PCIs and CCAs. We define  $\\tilde{I}$  to be the level of PCIs at which  $D$ 's overall cybercapability is maximized (point Max in Figure 1a).\nBefore  $D$  creates her PCIs, often she already has some existing cybercapabilities. For instance, before the Swedish Civil Contingencies Agency (MSB) became responsible for election protection, it dealt with civil protection; MSB could use these expertise to provide public safety during the time of elections. This existing level of cybercapability determines  $D$ 's type. We distinguish two types of  $D$ -strong  $(D_S)$  and weak  $(D_W)$ .  $D_S$ , depicted by the black line in figure 1(b), has a higher level of existing cybercapability, thus she can implement a higher level of PCIs and have higher chances of deterrence than  $D_W$ , depicted by a gray line in figure 1(b). Similarly,  $\\tilde{I}_S$  and  $\\tilde{I}_W$  are the levels of PCIs at which overall cybercapability is maximized for the defender's weak and strong types, respectively.\nWe assume that the costs of producing public  $(I)$  and private  $(N)$  cybercapacity are the same for the strong and weak type of the defender because we primarily focus on explaining the behavior of middle powers. Some nations that have developed technological expertise in this area—cyber powers, for instance—can develop \"more\" capability for a given budget. In such cases, it might be difficult for other nations to imitate PCIs developed by these cyber powers. For these reasons, our model excludes these powerful nations and primarily focuses on the behavior of middle powers that can imitate each other's behavior in order to deter their challengers.\n# Model Equilibria\nNext we discuss the intuition behind the model equilibria.\nAs explained earlier, the effectiveness of the defender's PCIs on deterring the challenger, depends on the challenger's type. We distinguish three types of the challenger that depend on the three cut-off points depicted in figure 2. If  $C$  is undeterred and always attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region I in figure 2). If  $C$  is disinterested and never attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region IV in figure 2). In these two equilibria,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. Proposition 1 summarizes both equilibria.\nProposition 1. Challenger's decision to attack is independent of defender's PCIs.\n(a) If  $C$  is undeterred and always attacks (Region I in Figure 2),  $D_{0}$  maximizes her cybercapacity and  $C$  always attacks.\n(b) If  $C$  is disinterested and never attacks (Region IV in Figure 2),  $D_0$  maximizes her cybercapacity and  $C$  never attacks.\nIn both equilibria in Proposition 1,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. But what happens if they do? We argue that different types of the defender would invest their resources differently to maximize their chances of deterring adversaries that are susceptible to the costs created by PCIs. Specifically, the strategic use of PCIs to deter  $C$  occurs in the signaling region where there is both the need for and the possibility of deterrence. Here  $D_0$ 's PCIs can influence  $C$ , which will take different actions depending on the defender's true type. Specifically, the challenger will attack the defender if he knows that the defender is weak and will avoid attacking if he knows the defender is strong. We call this challenger opportunistic. In this region, depicted by Regions II and III in Figure 2, there are two pure strategy equilibria (Propositions 2-3) and one mixed strategy equilibrium. We focus on the pure strategy equilibria in the main manuscript and present the mixed equilibria in the Online Appendix.\nIf  $C$  prefers attacking a defender that he thinks is weak and avoiding attacking a defender that he thinks is strong due to the fear of retaliation or attack failure,  $D_W$ 's natural response is to increase her investment into PCIs to appear strong. Specifically, instead of redistributing her resources so that her overall cybercapability achieves its maximum (Max  $W$  in Figure 3 (a)),  $D_W$  distributes them so they are her overall cybercapability is at point A in Figure 3(a). By doing so,  $D_W$  creates the same level of PCIs  $(\\tilde{I}_S)$  as  $D_S$  (i.e.,  $D_W$  pools with  $D_S$ ), so when  $C$  observes these institutions, he concludes that he is dealing with a strong defender and does not attack. Because this deterrent strategy decreases  $D_W$ 's overall cybercapability, by appearing strong,  $D_W$ , in fact, hides her actual weakness. This pooling equilibrium holds only when  $D$ 's gain of appearing strong outweighs  $D$ 's loss to inefficiently allocating her resources and when  $C$ 's prior belief that  $D$  is strong is high. Proposition 2 presents this pooling equilibrium.\n# Proposition 2. Pooling Equilibrium.\nSuppose  $C$  is opportunistic and prefers attacking  $D$  only if he believes that  $D$  is weak. If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.[15]\n\nFigure 3. Defender's pure strategy actions when facing an opportunistic challenger: (a) pooling strategy; and (b) strategic separation strategy. Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$'s overall cybercapability when the resources are distributed between PCIs and CCAs; $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $Max_{S}(Max_{W})$); $\\hat{I}$: the level of PCIs that $D_{W}$ cannot attain; $A$: $D_{W}$ imitates PCIs of $D_{S}$; and $B$: $D_{S}$ strategically separates herself from $D_{W}$ by implementing PCIs that $D_{W}$ cannot implement.\nIf $C$'s prior belief that $D$ is strong is low, then $C$ interprets pooling as weak and attacks if $D$ implements $\\hat{I}_S$ (Region II of figure 2). $D_S$ is aware that $D_W$ is trying to imitate her PCIs and takes one of the two actions. Not wanting to be confused with $D_W$, $D_S$ can alter her behavior to clearly distinguish herself (i.e., separate) from $D_W$ to ensure that $C$ is deterred. Specifically, $D_S$ spends enough resources to reach a level of PCIs that $D_W$ cannot attain—$\\hat{I}$ (point B in Figure 3(b)). Observing $\\hat{I}$, $C$ knows that the defender is strong as $D_W$ could not implement $\\hat{I}$, as Figure 3(b) shows. Since $D_W$ cannot imitate $D_S$ and implement PCIs to reach $\\hat{I}$ in Figure 3(b), $D_W$ implements her optimal strategy $\\hat{I}_W$. Since separation is costly as it reduces $D_S$'s overall capacity, for this equilibrium to hold, $C$ should not attack when he sees $\\hat{I}$ even though he knows that $D_S$'s overall capacity is reduced. Proposition 3 summarizes this separating equilibrium.\n**Proposition 3.** Separating Equilibrium. Suppose $C$ is opportunistic and prefers attacking $D$ only if he believes that $D$ is weak. If $C$'s prior belief that $D$ is strong is low, then (1) $D_S$ implements a level of PCIs that $D_W$ cannot imitate $(\\hat{I} &gt; \\hat{I}_S)$, (2) $D_W$ is not able to pool with $D_S$ and implements $\\hat{I}_W$, and (3) $C$ attacks only when he sees $\\hat{I}_W$. [16]\nAlternatively, $D_{S}$ can decide not to implement PCIs that $D_{W}$ is not able to mimic because this will weaken her overall cybercapacity and invite an attack. In this case, a pure strategy equilibrium does not exist in Region II of Figure 2. But there exists a mixed strategy equilibrium where $D_{W}$ mixes between $\\hat{I}_{W}$ and $\\hat{I}_{S}$ and $C$ is indifferent between attacking and not. The Online Appendix presents this mixed strategy equilibrium.\n## Illustrative Examples of Elections\nThe novelty, secrecy, and sensitivity of the topic of cyber deterrence prevents us from conducting a rigorous empirical test of our findings. Instead, we aim at demonstrating the empirical plausibility of our theory of deterrence of strategic cyberattacks using PCIs. Since our theory is agnostic towards the type of a strategic cyberattack that a\nnation prefers to deter, we use illustrative examples from elections to provide support for our model equilibria. [17] Specifically, we focus on Kremlin-directed attempts to influence electoral campaigns in Western democracies: the 2016 US elections, the 2017 German elections, and the 2018 Swedish elections. We choose the most similar examples for our comparison (George 2019); they share the same cyber-capable attacker (Russia), have similar targets (Western democracies), use the same methods (cyber and information operations), have the same purpose (election interference), and have similar timeframes (2016–2018). They differ, however, in (1) the stakes involved in each campaign (e.g., a challenger's type); and (2) the level of PCIs that the targets implement (e.g., strong versus weak). As a result, these examples help demonstrate (1) under what conditions the challenger's uncertainty over the defender's cybercapacity increases the probability of successful deterrence; and (2) when this uncertainty has no effect.\nWe focus on the three different illustrative examples because they match the model's scope conditions that must be met if PCIs deter the challenger. First, there must be a difference in how different types of defenders allocate their resources to signal their cybercapacity. As we shortly demonstrate, the Swedish government, a weak cyber nation, prioritized investing in PCIs to appear that it had strong cyber defenses and offenses. Second, the challenger must face uncertainty about the defender's cybercapacity and its type. The time-limited and dynamic nature of COs generally raises uncertainty about cybercapacity, but this uncertainty over the defender's type does not play a role when facing an undeterred or disinterested challenger. But it is important when facing an opportunistic challenger: By investing more of its resources into PCIs, a weak defender can deter the challenger by pretending that it is strong. Uncertain about Sweden's actual cybercapacity, Russia observed the overwhelming number of PCIs that Sweden created prior its 2018 election that are typical of strong types; it is conceivable that based on these observations, the Kremlin chose not to attack. Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In\n[16] This equilibrium relies on the off-the-equilibrium beliefs that the defender is weak \"enough\" if it plays $\\hat{I}_S$.\n[17] We use an illustrative example to provide support only for the pooling equilibrium when the challenger is opportunistic (Region III in figure 2) because it provides the most interesting result by demonstrating when PCIs can, in fact, deter the challenger.\nNADIYA KOSTYUK\nthe elections we are considering, the cost-benefit calculations differ. In the 2018 Swedish elections, the additional costs created by Swedish PCIs outweighed the low value of Russia's interference campaign and deterred Russia from interfering. In the 2017 German elections, the Kremlin did not consider the extra costs created by PCIs because they were irrelevant—a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place. In the 2017 French elections, benefits outweighed the costs.\n# 2018 SWEDISH NATIONAL ELECTIONS: OPPORTUNISTIC CHALLENGER AND POOLING EQUILIBRIUM\nThe 2018 Swedish national elections provide support for the pooling equilibrium in which the weak defender over-invests in PCIs to appear strong and, as a result, deters the opportunistic challenger (Region III in Figure 2). To show that this is the case, we need to demonstrate that the Russian government was opportunistic and additional PCIs that Sweden created prior to the elections changed the Kremlin's cost-benefit calculation of the election interference campaign.\nTo understand how PCIs as a deterrent strategy worked in this case, we first explain why the Kremlin even considered interfering in the Swedish electoral process. Sweden's nonalignment policy has always served as a guarantee of Russia's security. Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO) (Kunz 2015). In response, Russia's Defense Minister Sergei Shoigu described Sweden's involvement in NATO activities as \"worrying\" and added that \"such steps...[were] forcing us to take response measures\" (Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister 2018). Military actions and/or economic sanctions are possible response measures, although to date, Russia has pursued neither of these. The Ukrainian and Syrian conflicts, combined with NATO-Swedish defense cooperation (even if it falls short of collective defense), are most likely responsible for preventing Russia from taking a military approach.\nRussia is, on the other hand, a mastermind of influence campaigns and had been preparing a strong foundation for such a campaign on the Swedish population for some time. Starting in 2014, the Swedish information landscape witnessed an increase in disinformation campaigns, led by trolls, bots, and Kremlin-sponsored media outlets, such as Sputnik International. In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\" (Cederberg 2018, 5) and Sweden remained one of the few \"favorite target[s] of the Kremlin's propaganda machine\" at the beginning of 2018 (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018, 109). Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks[18] against Swedish news sites and a disinformation campaign about NATO in the Swedish media.[19]\nAn anti-immigration sentiment in both the Swedish parliament and the populace bolstered these ongoing COs and information operations. Immigration has always been a contentious issue in Swedish politics, recently exacerbated by the Syrian refugee crisis. Over the last five years, Sweden, a country of 10 million, has welcomed 165,000 asylum-seekers from the Middle East. Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010 (Johnson and Evans 2018). The party's anti-immigration stance and the divide in the general population over the immigration issue presented the perfect environment for the Kremlin's influence campaigns.\nHowever, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference (Cederberg 2018). Why? What stopped Russia from interfering in the Swedish elections?\nLet us look at Russia's cost-benefit calculus. While Sweden had a favorable political climate and Russia had some ongoing COs and information operations, the value of a potential interference campaign was quite low, compared to, for instance, the interference into the US elections that we will discuss below. We argue that the low interference value, combined with additional costs created by PCIs that Sweden established prior to its elections, deterred Russia from interfering into the 2018 Swedish elections.\nIn addition to the PCIs outlined in the introduction, there are many others that the Swedish government established in order to raise the cost of election interference. Here are just a few examples. The government reiterated the protection of democracy as one of the country's top security objectives and designated its election systems as critical infrastructure. It tasked the Civil Contingencies Agency (MSB) and the Security Services and the Election Authority with coordinating election protection and made MSB responsible for countering Russian disinformation. Most importantly, Sweden's Prime Minister Stefan Lofven emphasized the country's military offensive cybercapability and the government's willingness to use it. When discussing a three-point plan to stop foreign powers from influencing the 2018 Swedish elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities (SverigesRadio 2017). Some might argue that factors other than PCIs deterred Russia. First is NATO's military capabilities. The NATO-Sweden cooperation defense pact that prioritizes security in the Baltic Sea region protects Sweden from a physical invasion by Russia (akin to those in Ukraine and Georgia) but not from election interference. Second is the threat of Western economic sanctions. The ineffectiveness of these sanctions in changing Moscow's behavior in Ukraine and Syria suggest that they are unlikely to have deterred the Kremlin from executing its plan. Third is Russia's lack of interest in interfering. While the interference value was low, preparatory influence operations aimed at undermining the 2018 Swedish elections demonstrate that the interest was, in fact, present (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018). Having ruled out the above factors, we have further evidence that Sweden's PCIs, put in place before elections, raised the cost of a potential election interference campaign and deterred Russia from interfering into the 2018 Swedish elections.\n# 2017 GERMAN FEDERAL ELECTION: DISINTERESTED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 German federal election provides support for the equilibrium in which the defender's PCIs have no effect on the challenger because the challenger is\n\ndisinterested—the interference value is already so low that the challenger has no interest in interfering in the elections (Region IV in figure 2). We argue that German PCIs had no effect on Russia's decision to stay away from the 2017 German federal election. Instead, a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place.\nThe history of COs and information operations attributed to the Kremlin a few years prior to the election demonstrate that the Russian state had interest in German election interference. Information operations started in 2013, when three key German-language Kremlin-linked propaganda outlets—Sputnik Deutsch, RT Deutsch, and NewsFront Deutsch—entered the German market and were later joined by trolls and bots. The 2015 and 2016 COs against the parliament and political parties demonstrate that Moscow was also eager to obtain sensitive information for potential future use. But the value of an effective influence campaign were overwhelmed by potential costs resulting from the following factors.\nFirst, Germany's balanced media systems, the lack of polarization among the German public, Germany's multiparty and proportional system, and a \"gentleman's agreement\" between major political parties not to use any information leaked as a result of cyberattacks made it difficult for Moscow to sow confusion in the public. (Schwirtz 2017). Second, the only clear beneficiary of these campaigns was the Alliance for Germany (AfD)—the rest of parties supported the sanction regime against Moscow. But when AfD entered the race, they only had between eight and ten percent of vote, which was not enough to gain the majority. Third, the use of old-fashioned paper ballots on the local level afforded Germany with an accurate recount in the event that digitized votes used on the federal level were compromised. Lastly, high-level deterrent rhetoric by German politicians referencing a deterioration of the relationship between the two countries if interference occurred likely played a part. Although Putin and Merkel's relationship has eroded over time, alienating Germany—an important bridge between the West and Russia—was not in Russia's interest.\nIf not these factors, what other factors could have stopped Russia from election interference? Brattberg and Maurer (2018) and Schwirtz (2017) suggest that a failure to influence the 2017 French presidential elections made the Kremlin re-think its approach, since it lost the element of surprise. While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives (Galante and EE 2018).\n## 2017 FRENCH ELECTION: UNDETERRED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 French elections provide an illustrative example for the equilibrium in which the defender's PCIs have no effect on the challenger because it is undeterred—the interference value significantly outweighs its costs (Region I in Figure 2). Given this high value, we argue that the Russian government was like an unstoppable tank moving towards its\ntarget and no French PCIs could have stopped the Kremlin from executing its plan.\nWhat was the value from interfering into the 2017 French elections? The lowest value was undermining faith in the democratic process whereas the highest value was electing a pro-Kremlin candidate that could have resulted in a change in French foreign policy. We argue that even the lowest value of the interference campaign was far greater than any costs Russia could envision paying.\nIf caught, Moscow knew that it faced potential (cyber and non-cyber) retaliation. Diplomatic retaliation was the least of Russia's worries considering some existing tension between the two countries. Moscow expected that, if elected, Emmanuel Macron—as the only unequivocal critic of Putin's Russia out of all presidential candidates—would only exacerbate this tension. The cost of additional economic sanctions—in addition to those that the country already faced for the Ukrainian conflict—was marginal. Nuclear and military responses to COs and information operations were off the table.\nGiven these rather low costs from non-cyber foreign policy options, what additional cyber costs could have Russia anticipated? French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations (Brattberg and Maurer 2018). Deterrence by punishment was unlikely to work either. Even if Paris targeted Russia's critical infrastructure (even though it is quite unlikely), the damage that Russia experienced would have been limited. For example, it is impossible to hack Russia's entire power grid system at once because most stations are manually controlled and can be restored by flipping a switch. Similarly, Paris was unlikely to attempt information operations because of the Kremlin's tight control of Russia's print, online, and social media and because of Russia's treatment of information as a weapon, allowing its military to respond to such information threats (Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space 2011).\nIn short, the potential worst-case scenario costs that Moscow faced were lower than the value it would gain by election interference. Thus, the Kremlin's interference campaign was never going to be deterred by French PCIs.\n## Discussion and Implications\nAs scholars and policymakers continue debating cyber deterrence using COs, attribution, and non-cyber threats, we explore the feasibility of cyber deterrence using means that have been largely overlooked by the international relations literature—public cyberinstitutions which signal organizational capacity to produce and use cybercapability to achieve strategic objectives.\nOur main contribution is to identify the precise conditions under which PCIs can deter strategic cyberattacks, which cause significant damage to a country's economy and security. Since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though different types attacks are deterred by different types of PCIs, the results do not change. Specifically, we reveal several important patterns of the strategic use of PCIs to deter challengers that differ by type. PCIs have no effect on disinterested challengers because they have no interest in attacking the defender and undeterred challengers because they have decided to attack even before observing the defender's PCIs. Both scenarios demonstrate that states are wasting their resources if they\n A troll is someone who argues for extreme views without credible sources.\n An automated program that runs over the Internet.\n During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).\nNADIYA KOSTYUK\n\nPCIs, however, can deter opportunistic challengers that only attack defenders that they perceive as cyber weak and avoid attacking those defenders that they perceive as cyber strong. To deter opportunistic challengers, weak cyber nations might choose to over-invest their limited resources into PCIs to appear strong. Strong cyber nations, in their turn, over-invest their limited resources into PCIs to distinguish themselves from weak cyber nations pretending to be cyber strong. This sub-optimal resource allocation, which makes the defender weaker in its overall cybercapacity, is worthwhile for weak cyber nations because it deters opportunistic challengers. These results have important theoretical and policy implications.\nOur findings shed light on a theoretical debate surrounding cyber deterrence (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). Similar to Tor (2017), this article stresses the need to re-think our reference to absolute nuclear deterrence as a matrix of deterrence success for cyberoperations. Countries do not create cybercapacity to deter low-level COs; instead, their goal is to stop adversaries from executing strategic cyberattacks, which can cause detrimental damage to the country's economy, prosperity, and security.\nWhat constitutes strategic cyberattacks, however, continues to evolve with changes in global cyberthreat landscape; countries only focused on critical infrastructure protection less than a decade ago and added election protection to their top national security priorities following the 2016 US elections. As countries re-define what constitutes strategic cyberattacks, adversaries find more creative ways to achieve their strategic goals using cyber means that operate below the strategic cyberattack threshold. For example, in response to Russia's meddling in the 2016 US elections, the US government took significant steps to protect its 2018 elections. In response to this stern measure, Russian bots and trolls adjusted their behavior and started operating during the election off-season. These influence campaigns, even if conducted during election off-seasons, shape public opinion and might affect public voting behavior. Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace (Murray and Mansoor 2012).\nOur results also show that states should take the signaling of cybercapacity via PCIs with a grain of salt. While PCIs serve as a cyberthreat assessment barometer because they allow a challenger to estimate a defender's ability to conduct COs, the defender's willingness to use these operations, and the scope of the defender's potential retaliation, this assessment is not precise. To better estimate the defender's cybercapacity, challengers should also examine other indicators, such as economic and technological achievements and the defender's reliance on the private sector for cybercapacity. This cumulative approach used to estimate cybercapacity will help governments better evaluate options that minimize the risk of escalation.\nFurthermore, our results speak to the scholarship in international relations theory that focuses on deterrence.[23] Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence.[24] We show that the challenger's\nchoice to cyberattack the defender is independent of the defender's PCIs in two equilibria. In the first one, the challenger has no interest in attacking the defender, giving a false impression of deterrence success. In the second one, the challenger has already decided to attack the defender, despite its PCIs, giving a false impression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios (Danilovic 2002; Snyder 1977). Before concluding the ineffectiveness of PCIs or other means of deterrence, researchers and policy-makers should consider these variables in their estimations. Moreover, since our model is limited to states that have limited cyber arsenals and are not able to burn their exploits to send deterrent signals, we expect to see more investment in PCIs among relatively weaker cyber nations or middle powers. But as more nations invest in PCIs, this deterrent approach might be less effective.\nWhile we take the first stab at understanding deterrence by PCIs, future research should further investigate this important mechanism. Here, we highlight a few venues that future research could explore. First, our model oversimplifies real-world scenarios by making assumptions to identify the causal effect of PCIs on deterrence chances. We view the challenger's choice to attack and the defender's choice to establish PCIs as a one-time decision. In practice, PCIs present a state's cumulative effort to boost its cybercapacity. Similarly, cyber and influence campaigns are composed of many, often low-level activities that span an extended period. Future research should explore how much updating-of-beliefs takes place during different stages of strategic cyberattacks and a state's cumulative efforts to build PCIs. Second, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities (Schneider 2019). Future iterations of this model should explore scenarios when it is not the case. For instance, when PCIs only signal an increase in offensive cybercapability, the threat of cyber retaliation might not deter a country that does not have many cyber targets, like North Korea. PCIs that only signal an increase in cyber defenses might deter countries that view attacking well-protected targets as too costly.\nThird, our model does not distinguish the defender by regime type. Democratic leaders are more transparent, responsive to constituents, and willing to provide public goods in the form of security to satisfy voters and secure their reelection (De Mesquita 2005). While autocracies might be less likely to create PCIs because they face a lesser demand to respond to their domestic audience, they, in fact, might be more likely to exaggerate their PCIs because of this lesser demand. Future research should investigate how these tendencies among different regime types affect model equilibria.\nAs Schelling (2008, 44) puts it, \"If deterrence fails, it is usually because someone thought he saw an 'option' that the... government had failed to dispose of, a loophole that it hadn't closed against itself.\" By building cybercapabilities, governments seem to assume that these capabilities alone have a deterrent effect. As my model demonstrates, successful deterrence depends on a defender's cybercapacity, its willingness to use it, and a challenger's type. Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or\n[23] For an overview of this scholarship, see Lupovici (2010).\n[24] We can describe undeterred challengers as resolute, opportunistic challengers as semi-resolute, and disinterested challengers as resolute.\n\nChina. In these cases, states might perceive potential consequences of entering an escalation cycle with such adversaries as too great to risk. To maximize the desired deterrent effect of publicly flexing their cyber muscles, nations' strategies should demonstrate their willingness to hold assets at risk and face consequences in cases of escalation. Only then, states will be able to close some of the loopholes that adversaries can exploit. Until that is done, the pessimistic view of cyber deterrence will persist.\n## Funding\nNadiya Kostyuk's work was partially supported by the William and Flora Hewlett Foundation under grant 2018-7727.",
  "citations": {
    "style": "superscript",
    "flat_text": "International Studies Quarterly (2021) 65, 1151-1162\n# Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\nNADIYA KOSTYUK\nSchool of Public Policy, Georgia Institute of Technology, USA\nCan cyber deterrence work? Existing scholarly works argue that deterrence by punishment using cyberattacks is ineffective because the difficulty of attributing the origin of cyberattacks makes the threat of future attacks less credible. However, these works have told us relatively little about the deterrence ability of public cyberinstitutions (PCIs), defined as publicly observable proactive efforts aimed at signaling a country's level of cyber offensive and defensive capability. This research shows that middle powers (that have scarce cyber arsenals) can use PCIs to deter cyber attacks that cause significant damage to their economy and prosperity; however, this deterrent capability is rather limited. Using an incomplete-information model, we demonstrate that PCIs only deter adversaries that are susceptible to the costs created by these institutions. Despite this limited deterrence ability, middle powers tend to over-invest resources in these cyberinstitutions: Weak cyber states tend to over-invest to convince strong cyber adversaries that they are strong, whereas strong cyber states over-invest so that adversaries do not believe that they are weak states pretending to be strong. By doing so, states reduce their overall cybercapacity. We establish the empirical plausibility of these results using election interference campaigns as examples of strategic attacks. Our focus on the strategic use of PCIs as a deterrent represents a departure from existing literature—which has focused only on cyberoperations—and has important policy implications.\nPuede funcionar la ciberdisuasión? Los trabajos académicos existentes sostienen que la disuasión mediante el castigo de los ciberataques es ineficaz porque la dificultad de atribuir el origen de los ciberataques hace menos creíble la amenaza de futuros ataques. Sin embargo, estos trabajos nos han aportado relativamente poco sobre la capacidad de disuasión de las ciberinstituciones públicas (Public Cyberinstitutions, PCI), definidas como esfuerzos proactivos públicamente observables destinados a señalar el nivel de capacidad ciberofensiva y defensiva de un país. Esta investigación muestra que las potencias medias (que disponen de escasos arsenales cibernéticos) pueden utilizar las PCI para disuadir los ciberataques que causan un daño importante a su economía y prosperidad; pero esta capacidad de disuasión es bastante limitada. Mediante un modelo de información incompleta, demostramos que las PCI solo disuaden a los adversarios que son susceptibles a los costos creados por estas instituciones. A pesar de esta limitada capacidad de disuasión, las potencias intermedias tienden a invertir en exceso sus recursos en estas instituciones cibernéticas: los ciberestados vulnerables tienden a invertir en exceso para convencer a los ciberadversarios fuertes de que son fuertes, mientras que los ciberestados fuertes invierten en exceso para que los adversarios no crean que son estados vulnerables que fingen ser poderosos. Al hacerlo, los estados reducen su cibercapacidad general. Determinamos la credibilidad empírica de estos resultados utilizando campañas de interferencia electoral como ejemplos de ataques estratégicos. Nuestro enfoque en el uso estratégico de las PCI como elemento de disuasión representa un cambio respecto a la literatura existente, que se ha centrado únicamente en las ciberoperaciones, y tiene importantes implicaciones políticas.\nLa cyber-dissuasion peut-elle fonctionner? Les travaux de recherche existants soutiennent que la dissuasion par une sanction reposant sur des cyber-attaques est inefficace car la difficulté de détermination de l'origine des cyber-attaques rend la menace de futures attaques moins crédible. Toutefois, ces travaux ne nous ont donné que relativement peu d'informations sur la capacité de dissuasion des cyber-institutions publiques, qui est définie comme étant constituée des efforts proactifs publiquement observables visant à signaler le niveau des cyber-capacités offensives et défensives d'un pays. Cette recherche montre que les puissances intermédiaires (qui disposent de cyber-arsenaux limités) peuvent avoir recours aux cyber-institutions publiques pour dissuader les auteurs de cyber-attaques nuisant considérablement à leur économie et à leur prospérité, mais cette capacité de dissuasion est plutôt limitée. Nous nous appuyons sur un modèle d'information incomplète et nous démontrons que les cyber-institutions publiques ne dissuadent que les adversaires qui sont sensibles aux coûts engendrés par ces institutions. Malgré cette capacité de dissuasion limitée, les puissances intermédiaires tendent à surinvestir des ressources dans ces cyber-institutions : les cyber-États faibles tendent en effet à surinvestir pour convaincre leurs puissants cyber-adversaires qu'ils sont forts, tandis que les cyber-États forts tendent à le faire afin que leurs adversaires ne croient pas qu'ils sont faibles alors qu'ils se prétendent forts. Ce faisant, les États réduisent leur cyber-capacité globale. Nous établissons la plausibilité empirique de ces résultats en nous basant sur les campagnes d'ingérence électorale comme exemples d'attaques stratégiques. Notre concentration sur l'utilisation stratégique des cyber-institutions publiques comme dissuasion diverge de la littérature existante qui s'est uniquement concentrée sur les cyber-opérations et a d'importantes implications politiques.\n\"To those thinking about trying to influence the outcome of the elections in our country: Stay away!\" (as quoted in Cederberg 2018, 11). Sweden's Prime Minister Stefan Löfven articulated this warning and the country's willingness to act in the event of election interference at a security conference in January 2018. The Swedish government\nNadiya Kostyuk is an Assistant Professor, School of Public Policy, Georgia Institute of Technology.\nAuthor's note: I would like to thank Erica Borghard, Aaron Brantly, Ben Buchanan, John Ciorciari, Fiona Cunningham, Tiberiu Dragu, Mathias Frendem, Andres Gannon, Erik Gartzke, John Leahy, Susan Landau, Herb Lin, Jon Lindsay, Shawn Lonergan, Carla Martinez Machain, Tamar Mitts, James D. Morrow, Jacquelyn Schneider, Jeffrey W. Taliaferro, Brandon Valeriano, Ketian Zhang, Yuri M. Zhukov, and the participants of the Peace and Science Society International pre-conference workshop, of the Student Cybersecurity Symposium at Tufts University, of the International Security Seminar at the Belfer Center for Science and Technology at Harvard Kennedy School, of the Peace Science OPSC, and of the Cybersecurity Series at the Stanford Center for International Security and Cooperation. This paper was presented at the 2019 International Studies Association Conference.\nKostyuk, Nadiya (2021) Deterrence in the Cyber Realm: Public versus Private Cyber Capacity. International Studies Quarterly, doi: 10.1093/isq/sqab039\n© The Author(s) (2021). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nDeterrence in the Cyber Realm\nsubstantiated this rather bold statement with a number of measures meant to deter potential intruders. Specifically, in preparation to its September 2018 election, the country created a number of public cyberinstitutions (PCIs)—publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities.\nSome of these measures aimed at creating better cyber defenses to “raise the threshold [of] attacking Sweden” (National Cybersecurity Policy 2017, 19). Specifically, the government increased the budgets of existing agencies to include election protection into their scope, and it established new agencies, forums, and programs to protect against election interference and disinformation campaigns. For instance, the Swedish government’s crisis preparation and response agency became the main authority for election coordination. The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’” (SverigesRadio 2017). Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats (Cederberg 2018). Media, political parties, and schools ran similar education campaigns. To prepare for total defense awareness, including cases of cyber emergencies, MSB also sent a pamphlet titled “If Crisis or War Comes” to all 4.7 million households.\nIn addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats (Rettman and Kirk 2018). The National Defense Radio Establishment and the Military Intelligence and Security Service installed special detection and warning systems to guard against foreign powers hacking into sensitive agencies. The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators” (O’Dwyer 2018).\nWe argue that these PCIs established by the Swedish government in order to protect its 2018 elections convinced the Russian government that an interference campaign would have been too costly. Why were PCIs successful in deterring a potential interference campaign? Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy (Fernandino 2018)—under what conditions can PCIs deter any strategic cyberattack?\nTo answer these questions, we develop an incomplete-information model in which a challenger considers attacking a defender. The defender in this case is a middle power, since these nations have scarce cyber arsenals and are more likely to invest in PCIs for deterrence. The challenger is not certain about the defender’s cybercapacity—how cyber “strong” or “weak” it is—and can only infer it from the defender’s observable PCIs. Thus, the challenger’s decision to attack depends on the defender’s type, and the defender has an incentive to over-invest in public cybercapacity in order to signal that it is stronger that it actually is.\nThis model leads to several insights. First, there is a large number of equilibria for which PCIs have no influence on the challenger. Second, we show that the defender’s strategic use of PCIs to deter the challenger works only when two conditions are met: (1) the challenger believes that the defender possesses significant cybercapabilities and that it would therefore be too costly to attack the defender; and (2) the challenger is susceptible to the cost exacted by PCIs. This finding shows that PCIs influence the challenger’s decision to attack only in limited cases. Despite that, weaker defenders over-invest in PCIs to signal higher cybercapacity than they possess, and strong defenders over-invest so that their adversaries do not believe that they are weak states pretending to be strong.\nThis paper makes a number of theoretical contributions to the existing international-relations literature. First, it helps us better understand the nature of deterrence in the information age. Our unique strategic logic of PCIs as a proxy for a country’s cybercapacity represents a departure from existing literature. While most scholarly works on cyber-to-cyber deterrence focuses on deterrence by punishment using cyberoperations (Baliga, de Mesquita, and Wolitzky 2020; Valeriano, Jensen, and Maness 2018), this project presents a new theory that explains how PCIs can deter by both prevention and by threat of punishment, by signaling an increase in both defensive and offensive cybercapabilities. This project also contributes to the literature on cross-domain deterrence (Gartzke and Lindsay 2019) by explaining situations in which countries use PCIs to deter their adversaries instead of non-cyber foreign policy options (i.e., economic sanctions, or diplomatic or military responses) that are ineffective and/or costly.\nSecond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). We, instead, seek to explain the strategic behavior of weaker cyber states or middle powers that suspect a cyberattack. In these situations, middle powers often must rely on their own cybercapabilities because their allies are unlikely to help. Cyberdefenses are unique to each country and not easily transferable; close allies are often reluctant to disclose information about their offensive cybercapabilities and/or commit cyberattacks on an ally’s behalf (as compared with their willingness to offer military assistance during territorial invasions).\nThe literature on the “bargaining model of war” focuses on how private information and incentives to misrepresent, and commitment problems affected by power shifts, explain costly armed conflict (e.g., Schultz 1998; Slantchev 2003, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power (Morrow 1989); states also tend to keep certain capabilities secret to obtain military advantage (Reiter 2003).\nWhat is new about our model then? First, a different theoretical foundation drives how nations signal their cybercapacities. Unlike in the case of military capacity, a state cannot launch a parade to signal its cybercapacity. Satellite images are also unlikely to be useful to adversaries seeking to estimate a state’s cyberstrength. An executed cyberattack may provide a target with a good estimate of the attacker’s capabilities, but such an attack de-values capability because it provides the target with instructions on how to fix flaws in their own networks and systems. The time-limited life-span and the dynamic nature of cyberoperations further complicate their signaling potential. While the basic parameters for most traditional weapons remain relatively static,\n\nNADIYA KOSTYUK\n\nSecond, existing models focus only on whether and how investment in military capacity can deter a future attack or affect the likelihood of winning a war. Our theoretical foundation instead explains that sources of state cybercapacity are more diverse, lie beyond military and government, and extend to a state's private sector and even public-opinion management. While investing in military cybercapacity is important for deterrence by the threat of punishment, to deter adversaries by prevention, states might, for example, invest significant resources into building public awareness about the danger of cyberoperations and information operations, making potential election-interference campaigns harder.\nRegarding the model, the closest work, which focuses on the relative impact of scarce resource allocation on the likelihood of attack, is Arena and Wolford (2012). Unlike Arena and Wolford (2012), which examines a state's decision to allocate its resources between armaments and intelligence gathering capabilities in order to reduce uncertainty over its opponent's military strength, our model explores a state's decision to allocate its resources between public and private cybercapacity in order to deter its strong opponent from executing a cyberattack against the state. Similarly to works on counter-terrorism policies (Bueno de Mesquita 2007; Dragu 2011), our model explains why nations over-invest in public capacity and that such policies are generally ineffective in deterring adversaries.\nBaliga, de Mesquita, and Wolitzky (2020) and Welburn, Grana, and Schwindt (2019) are the only two other models that focus on cyberdeterrence; they explore how a state's inability to correctly attribute the origin of cyber operations and to detect cyberattacks affects the state's chances of deterring potential attackers. Unlike these models, our model focuses on organizational capability which signals the state's ability to readily produce and use covert cybercapacity. Unlike Baliga, de Mesquita, and Wolitzky (2020)'s model, in which there is uncertainty over the signal's sender (i.e., the attacker's identity) while the signal's quality (i.e., the strength of cybercapacity) is clear, our model investigates situations in which the signal's sender is known but the signal's quality is unclear. Unlike Welburn, Grana, and Schwindt (2019)'s model, in which a defender can signal any cybercapability with no cost, our model explains how the defender's choice to allocate its limited resources translates into observable cybercapacity.\nThe paper proceeds as follows. We start with explaining how a state can signal its cybercapacity. Then, we explain when and how public cyberinstitutions can deter strategic cyberattacks. Next, we introduce the model and derive the model equilibria. We use illustrative examples from elections to establish the empirical plausibility of our theory. We conclude with a discussion of our study's implications.\n## Signaling Cybercapacity\nStates can signal their cybercapability by (1) attributing cyber operations (COs) to attackers; (2) executing COs against adversaries; and (3) establishing public cyberinstitutions—publicly observable efforts aimed at demonstrating a country's level of offensive and defensive cybercapability. Each of these methods has its pros and cons.\nSignaling cybercapacity via attribution is a recent trend, as demonstrated by the number of US indictments. Attribution is a powerful deterrent because it signals to both the attacker and future perpetrators that they are not as invisible as they would like to be in cyberspace. But cyber attribution is difficult and costly: Not only does cyber attribution require significant resources and technical expertise to correctly attribute an attack to a specific computer, but it also demands intelligence to connect the used computer to a perpetrator. Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources (Clark and Landau 2011; Egloff and Wenger 2019). As a result, only a few nations have the resources, technical expertise, and political will to use attribution as a way to signal their cybercapability.\nSignaling cybercapacity via covert COs provides the target with an accurate estimate of the attacker's capability. However, the difficulty of attributing the origin of COs and the time it takes to do so diminish the signal's value, which is further reduced by the time-limited life-span and the dynamic nature of COs. Moreover, if a victim is not able to attribute the attack or remains quiet about the attack, the signaling value of COs is either zero or quite low. Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons (Gartzke 2013); only a few nations have a large enough cyber arsenal that they can burn some of their exploits for signaling purposes.\nWhile cybercapacity cannot be revealed because it depends on secret access and vulnerabilities, the state can reveal its ability to find such vulnerabilities by establishing PCIs, defined as publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities. PCIs signal an increase in organizational cybercapability, which demonstrates the state's ability to readily produce cybercapability and use cyberoperations for political purposes. As a result, signaling via PCIs provides the state's allies, adversaries, and domestic and international audiences with an immediate, often rough proxy for the state's cybercapacity and preserves the value of the state's covert COs.\nFor simplicity, I distinguish two ways in which a state can establish its PCIs: It can (1) create a new agency program, initiative, doctrine, strategy, or policy to address some aspect of cybersecurity; and/or (2) add new cyber roles to existing agencies or new cyber provisions to existing policies. For instance, to deter election interference campaigns, Sweden established an agency responsible for psychological defense. When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time (Schwirtz 2017).\n5Some of these works include Debs and Monteiro (2014), Fearon (2018), Kydd (2000), Meirowitz and Sartori (2008), and Slantchev (2005).\n4Germany's hack-back strategy is a PCI even though the government does not give any details regarding the scope of this strategy. Since they publicly discussed its development (instead of only privately executing it), we have an idea of the steps that the German government considers adopting in order to deter election interference. If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage (Schwirtz 2017). For instance, in response to the attack against the parliament, the German government could remove servers on which stolen parliament data were located.\n\nEven though these two options differ in how governments created their PCIs, they both might involve a similar set of measures. Specifically, a new agency and a new strategy might require additional budget, stuff, training, and expertise. While PCIs often do not reveal all the details about created cybercapacity, unlike covert cyberactivity they allow an adversary to estimate the scope of the change and the potential resulting increase in the target state's cybercapacity. The Swedish and German actions, for instance, signaled that both countries prioritized spending their resources on building better cyber defensive and offensive capabilities to deter potential election interference campaigns.\nBefore we explain how PCIs can deter adversaries, we would like to clarify that our theory focuses on middle powers—the nations that have scarce cyber arsenals and are more likely to invest in PCIs as a means of deterrence. Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by \"burning\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities.\n## The Theory of Cyber Deterrence\nThe theory presented in this section examines the specific context in which a strong challenger (including cyber powers) contemplates a strategic cyberattack against a defender.\nWhen the challenger considers a cyberattack, he calculates the value he can gain from this attack (e.g., undermining democratic processes, in the case of election interference) and the cost he can incur. There are two types of costs. First is the cost of the defender's potential retaliation (e.g., using economic sanctions, military operations or cyberoperations). Second is the tendency of cyberoperations—unlike military operations—to diminish in value after their first use. A tank, for example, can be successfully deployed many times over many years. Cyberattacks, on the other hand, often lose their effectiveness after their first use, even if the attack fails due to the defender's defenses. In using cyberattacks, the challenger risks the possibility that the defender might be able to develop protection against similar attacks in the future.\nWe argue that, for a challenger to decide to use a cyberattack against a defender, it must believe that the attack's value will outweigh its cost. What can change this cost-benefit calculation? Specifically, what can raise the cost enough to deter the challenger?\nWe assume that the costs from non-cyber foreign policy tools (i.e., diplomatic or military responses, or economic sanctions) will not change the cost-benefit calculation because the challenger has considered them initially. These costs are easy to estimate using the defender's past history and are highly predictable based on the challenger's \"prior beliefs about the defender's willingness\" to use one\nSome anecdotal evidence suggests that even though the US government could not hack back in response to the election, it went into Russian servers and left non-malicious code that had \"U.S. Cyber Command\" in the comments. They did so to signal to the Russians, in a covert way, that they had the ability to strike whenever they wanted.\nI employ the language from the traditional deterrence literature and refer to an adversary as a challenger and a defending state as a defender. The model makes the assumption that the defender attempts to deter her strongest challenger, which is the challenger that can potentially cause the most significant damage. If she is able to deter her strongest challenger, then all her other challengers will be deterred by default. Because the model focuses only on the strong challenger, I have omitted \"strong\" and refer only to a \"challenger\" for the remainder of the paper.\nof these options (Fearon 2002, 6). Moreover, given that the defender's capability in non-cyber foreign policy domains is unlikely to change rapidly, the challenger's estimate of the costs imposed by diplomatic responses and economic sanctions is likely to be fairly accurate. The challenger is also aware that military responses are costly and that the defender is unlikely to launch a military strike in response to information operations or cyberoperations.\nEven though these non-cyber foreign policy tools cannot change the challenger's cost-benefit calculation, the challenger considers the defender's capability in these non-cyber domains when forming its opinion of the defender's cybercapacity. Since nations with significant resources and expertise can build sophisticated cyber weapons (Gartzke 2013), the challenger can accurately conclude that the most powerful military nations have impressive cyber arsenals. While the country's military capability might often be correlated with its cybercapacity, it is not always the case because some nations might choose to purchase cyber weapons from third parties or work with proxy groups to execute attacks on their behalf. Despite that we argue that both the defender's capability in non-cyber and the defender's capability in cyber domains form the challenger's prior belief of the defender's cybercapacity.\nGiven that the challenger is quite certain about the costs associated with non-cyber responses and, as a result, is unlikely to be deterred by them, the defender is left with cyber foreign policy tools to deter the challenger from executing cyberattacks. We argue that cyber foreign policy tools may raise the cost of a cyberattack for the challenger because the challenger remains uncertain about the defender's cybercapacity. Even if the challenger has a rough estimate of the defender's cybercapacity, the dynamic, time-limited nature of cyber tools makes it difficult for the challenger to determine the defender's cybercapacity with precision or certainty. Specifically, while the basic parameters for most traditional weapons remain relatively static, strategically relevant features of certain cyber weapons can change significantly over a short period of time. Moreover, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it (Axelrod and Iliev 2014). We explore this challenger's uncertainty over the defender's cybercapacity as the main mechanism that affects the probability of successful deterrence. How can the defender signal its cybercapacity\nThe Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations (Newman 2019).\nFor deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity (Schelling 2008). Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high (Press 2005). Moreover, as earlier explained, many nations cannot afford to \"burn\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities, and those that do send a rather costly signal about their sophisticated cyber arsenal. Furthermore, many countries conduct cyber espionage to observe other countries' cyberattack plans and capabilities. As a result, cyber powers that consider challenging other nations probably know enough about other countries' covert cyber strength to know whether they face another cyber power or not, though they do not necessarily know its precise capabilities. Thus, there is no uncertainty about the capabilities of these cyber powers; instead, this theory explores uncertainty over the capabilities of weaker nations—middle powers—and specifically how cyber \"strong\" or \"weak\" they are. These nations tend to have a rather scarce cyber arsenal and are more likely to invest in PCIs as a means of deterrence. However, the better a challenger's cyber-intelligence, the less uncertainty the challenger has about the defender's cybercapacity.\nNADIYA KOSTYUK\n\n## Deterrence by PCIs\nPCIs can leave the challenger uncertain about the defender's cybercapacity because they demonstrate the defender's ability to produce cybercapability without revealing any concrete details about this capability. PCIs can deter by prevention and/or by threat of punishment. These two types of deterrence are associated with the two types of costs that PCIs can inflict on the challenger, increasing the cost of its cyberattack. PCIs can deter by prevention because adversaries may infer that their attacks are likely to fail against the defenses implied by a PCI. Firewalls, updated computer software, programs aimed at educating public about cyberthreats, and policies that outline a set of measure to provide better security of critical infrastructure are examples of PCIs that can deter by prevention because they make hacking more difficult. While the challenger can keep using conventional weapons even if a conventional attack fails, the challenger often burns its cyber exploits in the case of an unsuccessful cyberattack. This is because having discovered an attempted hack, the defender can close the existing vulnerability making the future use of this exploit impossible. PCIs can also deter by the threat of punishment; for instance, new military doctrines and units signal the state's ability to use its cyber weapons in response to cyberthreats.\nWe investigate situations in which both deterrence mechanisms are at play for the following two reasons. First, one cyberinstitution can signal both cyber offensive and defensive capability, making it hard to separate deterrence by the threat of punishment from deterrence by prevention. The US Department of Defense Cyber Strategy (2015, 3), for instance, uses deterrence by prevention by specifying the Department of Defense's role in defending its information networks, and it uses the threat of punishment by establishing a Cyber Mission Force to be used to defend the United States against cyberattacks of \"significant consequence\". Second, when facing a strategic cyberthreat, states tend to respond with multiple PCIs and, as a result, implement both types of deterrence at the same time to maximize their chances of success.\nSince PCIs can increase uncertainty about the defender's cybercapacity raising the probability of successful deterrence, the defender might want to invest most, if not all, of its resources into PCIs. But such a strategy takes valuable resources away from covert cyberactivity (CCA) or private cybercapacity, which involves secret development of cybercapabilities and ongoing cyberoperations. For instance, a polished strategy document, newly-constructed headquarters, or a new initiative meant to bring public awareness of cyberthreats is a poor substitute for a CCA aimed at penetrating the challenger's electricity grid and preparing for a future attack that could be used for retaliation.\nWe argue that this trade-off between PCIs and CCAs is important. Even though some PCIs involve the development of private cybercapability (e.g., the German's hack-back strategy), such PCIs give a high-level view on what capacity a government develops whereas CCAs remain truly covert and only signal capability after being discovered and correctly attributed. The Stuxnet worm, which the US and Israeli governments developed and deployed in 2005 against an Iranian nuclear enrichment facility, was an example of such a CCA, until it was discovered in 2010. Even though the US government created a number of PCIs between 2005 and 2010 to signal an increase in its cybercapacity, none of them signaled the tremendous potential of the US cybercapability. Only the attributed Stuxnet worm signaled the true scope of the US cyber arsenal. Unlike PCIs, which send an immediate, although often imprecise signal about a state's level of cybercapabilities, the Stuxnet example demonstrates that CCAs send a more accurate signal of a state's cybercapabilities but this signal might be delayed.\nSince an investment in both PCIs and CCAs is important for overall cyber capacity, over-investment in PCIs at the expense of investment in CCAs can make a defender weaker. However, the relationship between the defender's overall cybercapacity and its chances at deterrence is not linear—i.e., an increase in one does not necessarily mean an increase in the other. Therefore, a defender with weak cybercapabilities might strategically invest more in PCIs if such an investment maximizes its chances at deterrence, even if it decreases its overall cybercapacity.\nWe argue that the effectiveness of this deterrent strategy depends on the type of the challenger. Specifically, it only works against a challenger that is susceptible to the costs created by PCIs. We call this challenger opportunistic. During the 2018 Swedish elections, Russia was an example of an opportunistic challenger. Having considered a potential interference campaign, the Kremlin realized that the rather small marginal value from this campaign was not worth the additional potential costs imposed by the improved defenses and offenses that Sweden created in the form of PCIs prior to the elections. But an over-investment in PCIs as a deterrent strategy does not work against an disinterested challenger; such challengers never attack, even if they give the impression that they are considering attacking. During the 2017 German elections, Russia was an example of a disinterested challenger. PCIs put in place prior to the 2017 elections had no\n It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.\n Given that early scholarly works perpetuated the offense dominance in cyberspace (Choucri 2012; Demchak 2011; Kello 2013), prevention is often seen as somewhat futile as it is nearly impossible to protect all vulnerable targets; thus, preemption may be a more cost-effective tactic. Recent works, however, refute the offense-dominance thesis (Gartzke 2013; Lindsay 2013). While it is easier to find a vulnerability in an adversary's network/system than to defend its own networks/systems from hundreds of possible cyberattacks, Slayton (2017) stresses the importance of looking at the cumulative effort required for building cyber offense or defense. Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\" (Slayton 2017, 74). Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense (Borghard and Lonergan 2017).\n\nFigure 1. Defender’s cybercapacity: (a) relationship between defender’s observed and overall cybercapacity; and (b) relationship between defender’s type and her overall cybercapacity as a function of $I_{\\theta}$. Note: $I$: PCIs that $D$ can develop with $r$ units of resources; $N$: CCAs that $D$ can develop with $r$ units of resources; $I + N$: $D$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}$: the level of PCIs at which $D$’s overall cybercapability is maximized (point Max). Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $\\text{Max}_{S}(\\text{Max}_{W})$).\neffect on Russia’s decision to stay away from these elections because a combination of non-cyber factors shifted Russia’s cost-benefit calculus towards not attacking even before Germany establish its PCIs. Lastly, an over-investment in PCIs is also a waste of resources when the defender faces a undeterred challenger; such challengers always attack because the value of attacking is much higher than any additional costs created by PCIs. During the 2017 French elections, Russia was an example of an undeterred challenger. Having witnessed the worldwide impact of the mass disclosures of private data prior to the 2016 US elections, Moscow was willing to pay any cost and to risk any potential French (cyber or non-) retaliation for its influence campaign, which could help elect a pro-Kremlin candidate.\nThe next section models cyber deterrence by PCIs explicitly. It is worth noting that since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though the type of an attempted attack requires different types of PCIs, this does not affect the model logic and the obtained results.\n## Model\nThis section provides the intuition behind the game and the Online Appendix includes the detailed explanation and mathematical proofs.\n**Game Overview.** This is a game between a challenger ($C$, “he”) and a defender ($D$, “she”). $C$ considers executing a cyberattack against $D$. To deter $C$, $D$ decides how to signal her cybercapacity by allocating her resources between public and private cybercapacity and, as a result, which level of PCIs to implement. $D$ has a type $\\theta \\in [S, W]$ that differs in the amount of resources $a_{\\theta}$ available to her. The strong defender $D_{S}$ has many more resources available to her than the weak defender $D_{W}$. $\\theta$ is unobservable to the challenger.\nThe game starts with Nature’s choice. Nature selects that $\\theta = S$ with probability $\\pi$ and that $\\theta = W$ with probability $1 - \\pi$. The model assumes that both players have a common prior belief and that $\\pi$ is the true probability that the defender is strong. Then $D$ decides how to allocate her resources between PCIs and CCA. After $D$ implements PCIs, $C$ observes it, (possibly) updates his beliefs about $D$’s type, and decides whether he wants to attack $D$. When $C$ chooses whether to attack, $C$ observes $D$’s move but not $D$’s type. If $C$ does not attack, $D_{\\theta}$ successfully deters $C$ and the game\nends. If $C$ decides to attack $D_{\\theta}$, Nature selects that his attack is successful with probability $Q_{\\alpha}$, and unsuccessful with probability $1 - Q_{\\alpha}$. The probability of a successful attack is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. If $C$’s attack succeeds, $D_{\\theta}$ must decide whether to retaliate against $C$. If $D_{\\theta}$ does not retaliate against $C$, the game ends. If $D_{\\theta}$ retaliates against $C$, Nature selects that her retaliation is successful with probability $P_{\\theta}$ and is unsuccessful with probability $1 - P_{\\theta}$. The probability of a successful retaliation is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.[12]\n**Signaling Cyber Capacity.** To understand how $D$ can deter strategic cyberattacks, we must first understand how she can create her cybercapacity because $D$’s cybercapacity is a proxy for $D$’s ability to deter $C$. The higher $D$’s capacity is, the higher the likelihood that $D$ deters $C$. To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA.[13] Both PCIs and CCA create $D$’s overall cybercapability. As mentioned earlier, $D$’s overall cybercapability does not necessarily increase simply by investing more in her PCIs because such a strategy takes valuable resources away from CCA. As a result, it makes $D$ weaker.\nFigure 1(a) explains the intuition of how this works graphically. $C$ has a prior belief of $D$’s cybercapability, given COs attributed to $D$ or using various indicators of $D$’s technological development. Given the public nature of PCIs, $C$ can only observe PCIs and estimate $D$’s cybercapability. We call it $D$’s observed cybercapability and place it on the x-axis in Figure 1(a). The y-axis in Figure 1(a) represents $D$’s overall cybercapability that we receive by adding the resources that $D$ invests into PCIs and CCAs. Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.[14] The\n[12] We display this two-player game with incomplete information concerning $D$’s type in Online Appendix Section 1.1.\n[13] Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.\n[14] I assume that both $I$ and $N$ are increasing in $r$ and that there are diminishing returns to investment in each (i.e. $I'(r), N'(r) &gt; 0$ and $I''(r), N''(r) &lt; 0$).\nNADIYA KOSTYUK\nFigure 2. Equilibria and challenger's types. Note:  $C$ : a challenger;  $D_W$ : a weak type of the defender;  $D_S$ : a strong type of the defender;  $\\pi$ : a prior probability that  $D$  is strong;  $1 - \\pi$ : a prior probability that  $D$  is weak; and  $\\tilde{I}_S$ : the level of PCIs at which overall cybercapability is maximized for the strong type of the defender. 1:  $C$ 's gains from attacking  $D_S$ , given the probability of this attack is successful; 2:  $C$ 's gains from attacking  $D$ , given that with  $\\pi$  probability he is facing  $D_S$  and with  $1 - \\pi$  probability, he is facing  $D_W$  that pools with  $D_S$  and implements  $\\tilde{I}_S$ ; and 3:  $C$ 's gains from attacking  $D_W$ , given the probability of this attack is successful.\nfunction  $I + N$  stands for  $D$ 's overall cybercapability when the resources are distributed between PCIs and CCAs. We define  $\\tilde{I}$  to be the level of PCIs at which  $D$ 's overall cybercapability is maximized (point Max in Figure 1a).\nBefore  $D$  creates her PCIs, often she already has some existing cybercapabilities. For instance, before the Swedish Civil Contingencies Agency (MSB) became responsible for election protection, it dealt with civil protection; MSB could use these expertise to provide public safety during the time of elections. This existing level of cybercapability determines  $D$ 's type. We distinguish two types of  $D$ -strong  $(D_S)$  and weak  $(D_W)$ .  $D_S$ , depicted by the black line in figure 1(b), has a higher level of existing cybercapability, thus she can implement a higher level of PCIs and have higher chances of deterrence than  $D_W$ , depicted by a gray line in figure 1(b). Similarly,  $\\tilde{I}_S$  and  $\\tilde{I}_W$  are the levels of PCIs at which overall cybercapability is maximized for the defender's weak and strong types, respectively.\nWe assume that the costs of producing public  $(I)$  and private  $(N)$  cybercapacity are the same for the strong and weak type of the defender because we primarily focus on explaining the behavior of middle powers. Some nations that have developed technological expertise in this area—cyber powers, for instance—can develop \"more\" capability for a given budget. In such cases, it might be difficult for other nations to imitate PCIs developed by these cyber powers. For these reasons, our model excludes these powerful nations and primarily focuses on the behavior of middle powers that can imitate each other's behavior in order to deter their challengers.\n# Model Equilibria\nNext we discuss the intuition behind the model equilibria.\nAs explained earlier, the effectiveness of the defender's PCIs on deterring the challenger, depends on the challenger's type. We distinguish three types of the challenger that depend on the three cut-off points depicted in figure 2. If  $C$  is undeterred and always attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region I in figure 2). If  $C$  is disinterested and never attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region IV in figure 2). In these two equilibria,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. Proposition 1 summarizes both equilibria.\nProposition 1. Challenger's decision to attack is independent of defender's PCIs.\n(a) If  $C$  is undeterred and always attacks (Region I in Figure 2),  $D_{0}$  maximizes her cybercapacity and  $C$  always attacks.\n(b) If  $C$  is disinterested and never attacks (Region IV in Figure 2),  $D_0$  maximizes her cybercapacity and  $C$  never attacks.\nIn both equilibria in Proposition 1,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. But what happens if they do? We argue that different types of the defender would invest their resources differently to maximize their chances of deterring adversaries that are susceptible to the costs created by PCIs. Specifically, the strategic use of PCIs to deter  $C$  occurs in the signaling region where there is both the need for and the possibility of deterrence. Here  $D_0$ 's PCIs can influence  $C$ , which will take different actions depending on the defender's true type. Specifically, the challenger will attack the defender if he knows that the defender is weak and will avoid attacking if he knows the defender is strong. We call this challenger opportunistic. In this region, depicted by Regions II and III in Figure 2, there are two pure strategy equilibria (Propositions 2-3) and one mixed strategy equilibrium. We focus on the pure strategy equilibria in the main manuscript and present the mixed equilibria in the Online Appendix.\nIf  $C$  prefers attacking a defender that he thinks is weak and avoiding attacking a defender that he thinks is strong due to the fear of retaliation or attack failure,  $D_W$ 's natural response is to increase her investment into PCIs to appear strong. Specifically, instead of redistributing her resources so that her overall cybercapability achieves its maximum (Max  $W$  in Figure 3 (a)),  $D_W$  distributes them so they are her overall cybercapability is at point A in Figure 3(a). By doing so,  $D_W$  creates the same level of PCIs  $(\\tilde{I}_S)$  as  $D_S$  (i.e.,  $D_W$  pools with  $D_S$ ), so when  $C$  observes these institutions, he concludes that he is dealing with a strong defender and does not attack. Because this deterrent strategy decreases  $D_W$ 's overall cybercapability, by appearing strong,  $D_W$ , in fact, hides her actual weakness. This pooling equilibrium holds only when  $D$ 's gain of appearing strong outweighs  $D$ 's loss to inefficiently allocating her resources and when  $C$ 's prior belief that  $D$  is strong is high. Proposition 2 presents this pooling equilibrium.\n# Proposition 2. Pooling Equilibrium.\nSuppose  $C$  is opportunistic and prefers attacking  $D$  only if he believes that  $D$  is weak. If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.[15]\n\nFigure 3. Defender's pure strategy actions when facing an opportunistic challenger: (a) pooling strategy; and (b) strategic separation strategy. Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$'s overall cybercapability when the resources are distributed between PCIs and CCAs; $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $Max_{S}(Max_{W})$); $\\hat{I}$: the level of PCIs that $D_{W}$ cannot attain; $A$: $D_{W}$ imitates PCIs of $D_{S}$; and $B$: $D_{S}$ strategically separates herself from $D_{W}$ by implementing PCIs that $D_{W}$ cannot implement.\nIf $C$'s prior belief that $D$ is strong is low, then $C$ interprets pooling as weak and attacks if $D$ implements $\\hat{I}_S$ (Region II of figure 2). $D_S$ is aware that $D_W$ is trying to imitate her PCIs and takes one of the two actions. Not wanting to be confused with $D_W$, $D_S$ can alter her behavior to clearly distinguish herself (i.e., separate) from $D_W$ to ensure that $C$ is deterred. Specifically, $D_S$ spends enough resources to reach a level of PCIs that $D_W$ cannot attain—$\\hat{I}$ (point B in Figure 3(b)). Observing $\\hat{I}$, $C$ knows that the defender is strong as $D_W$ could not implement $\\hat{I}$, as Figure 3(b) shows. Since $D_W$ cannot imitate $D_S$ and implement PCIs to reach $\\hat{I}$ in Figure 3(b), $D_W$ implements her optimal strategy $\\hat{I}_W$. Since separation is costly as it reduces $D_S$'s overall capacity, for this equilibrium to hold, $C$ should not attack when he sees $\\hat{I}$ even though he knows that $D_S$'s overall capacity is reduced. Proposition 3 summarizes this separating equilibrium.\n**Proposition 3.** Separating Equilibrium. Suppose $C$ is opportunistic and prefers attacking $D$ only if he believes that $D$ is weak. If $C$'s prior belief that $D$ is strong is low, then (1) $D_S$ implements a level of PCIs that $D_W$ cannot imitate $(\\hat{I} &gt; \\hat{I}_S)$, (2) $D_W$ is not able to pool with $D_S$ and implements $\\hat{I}_W$, and (3) $C$ attacks only when he sees $\\hat{I}_W$. [16]\nAlternatively, $D_{S}$ can decide not to implement PCIs that $D_{W}$ is not able to mimic because this will weaken her overall cybercapacity and invite an attack. In this case, a pure strategy equilibrium does not exist in Region II of Figure 2. But there exists a mixed strategy equilibrium where $D_{W}$ mixes between $\\hat{I}_{W}$ and $\\hat{I}_{S}$ and $C$ is indifferent between attacking and not. The Online Appendix presents this mixed strategy equilibrium.\n## Illustrative Examples of Elections\nThe novelty, secrecy, and sensitivity of the topic of cyber deterrence prevents us from conducting a rigorous empirical test of our findings. Instead, we aim at demonstrating the empirical plausibility of our theory of deterrence of strategic cyberattacks using PCIs. Since our theory is agnostic towards the type of a strategic cyberattack that a\nnation prefers to deter, we use illustrative examples from elections to provide support for our model equilibria. [17] Specifically, we focus on Kremlin-directed attempts to influence electoral campaigns in Western democracies: the 2016 US elections, the 2017 German elections, and the 2018 Swedish elections. We choose the most similar examples for our comparison (George 2019); they share the same cyber-capable attacker (Russia), have similar targets (Western democracies), use the same methods (cyber and information operations), have the same purpose (election interference), and have similar timeframes (2016–2018). They differ, however, in (1) the stakes involved in each campaign (e.g., a challenger's type); and (2) the level of PCIs that the targets implement (e.g., strong versus weak). As a result, these examples help demonstrate (1) under what conditions the challenger's uncertainty over the defender's cybercapacity increases the probability of successful deterrence; and (2) when this uncertainty has no effect.\nWe focus on the three different illustrative examples because they match the model's scope conditions that must be met if PCIs deter the challenger. First, there must be a difference in how different types of defenders allocate their resources to signal their cybercapacity. As we shortly demonstrate, the Swedish government, a weak cyber nation, prioritized investing in PCIs to appear that it had strong cyber defenses and offenses. Second, the challenger must face uncertainty about the defender's cybercapacity and its type. The time-limited and dynamic nature of COs generally raises uncertainty about cybercapacity, but this uncertainty over the defender's type does not play a role when facing an undeterred or disinterested challenger. But it is important when facing an opportunistic challenger: By investing more of its resources into PCIs, a weak defender can deter the challenger by pretending that it is strong. Uncertain about Sweden's actual cybercapacity, Russia observed the overwhelming number of PCIs that Sweden created prior its 2018 election that are typical of strong types; it is conceivable that based on these observations, the Kremlin chose not to attack. Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In\n[16] This equilibrium relies on the off-the-equilibrium beliefs that the defender is weak \"enough\" if it plays $\\hat{I}_S$.\n[17] We use an illustrative example to provide support only for the pooling equilibrium when the challenger is opportunistic (Region III in figure 2) because it provides the most interesting result by demonstrating when PCIs can, in fact, deter the challenger.\nNADIYA KOSTYUK\nthe elections we are considering, the cost-benefit calculations differ. In the 2018 Swedish elections, the additional costs created by Swedish PCIs outweighed the low value of Russia's interference campaign and deterred Russia from interfering. In the 2017 German elections, the Kremlin did not consider the extra costs created by PCIs because they were irrelevant—a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place. In the 2017 French elections, benefits outweighed the costs.\n# 2018 SWEDISH NATIONAL ELECTIONS: OPPORTUNISTIC CHALLENGER AND POOLING EQUILIBRIUM\nThe 2018 Swedish national elections provide support for the pooling equilibrium in which the weak defender over-invests in PCIs to appear strong and, as a result, deters the opportunistic challenger (Region III in Figure 2). To show that this is the case, we need to demonstrate that the Russian government was opportunistic and additional PCIs that Sweden created prior to the elections changed the Kremlin's cost-benefit calculation of the election interference campaign.\nTo understand how PCIs as a deterrent strategy worked in this case, we first explain why the Kremlin even considered interfering in the Swedish electoral process. Sweden's nonalignment policy has always served as a guarantee of Russia's security. Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO) (Kunz 2015). In response, Russia's Defense Minister Sergei Shoigu described Sweden's involvement in NATO activities as \"worrying\" and added that \"such steps...[were] forcing us to take response measures\" (Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister 2018). Military actions and/or economic sanctions are possible response measures, although to date, Russia has pursued neither of these. The Ukrainian and Syrian conflicts, combined with NATO-Swedish defense cooperation (even if it falls short of collective defense), are most likely responsible for preventing Russia from taking a military approach.\nRussia is, on the other hand, a mastermind of influence campaigns and had been preparing a strong foundation for such a campaign on the Swedish population for some time. Starting in 2014, the Swedish information landscape witnessed an increase in disinformation campaigns, led by trolls, bots, and Kremlin-sponsored media outlets, such as Sputnik International. In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\" (Cederberg 2018, 5) and Sweden remained one of the few \"favorite target[s] of the Kremlin's propaganda machine\" at the beginning of 2018 (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018, 109). Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks[18] against Swedish news sites and a disinformation campaign about NATO in the Swedish media.[19]\nAn anti-immigration sentiment in both the Swedish parliament and the populace bolstered these ongoing COs and information operations. Immigration has always been a contentious issue in Swedish politics, recently exacerbated by the Syrian refugee crisis. Over the last five years, Sweden, a country of 10 million, has welcomed 165,000 asylum-seekers from the Middle East. Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010 (Johnson and Evans 2018). The party's anti-immigration stance and the divide in the general population over the immigration issue presented the perfect environment for the Kremlin's influence campaigns.\nHowever, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference (Cederberg 2018). Why? What stopped Russia from interfering in the Swedish elections?\nLet us look at Russia's cost-benefit calculus. While Sweden had a favorable political climate and Russia had some ongoing COs and information operations, the value of a potential interference campaign was quite low, compared to, for instance, the interference into the US elections that we will discuss below. We argue that the low interference value, combined with additional costs created by PCIs that Sweden established prior to its elections, deterred Russia from interfering into the 2018 Swedish elections.\nIn addition to the PCIs outlined in the introduction, there are many others that the Swedish government established in order to raise the cost of election interference. Here are just a few examples. The government reiterated the protection of democracy as one of the country's top security objectives and designated its election systems as critical infrastructure. It tasked the Civil Contingencies Agency (MSB) and the Security Services and the Election Authority with coordinating election protection and made MSB responsible for countering Russian disinformation. Most importantly, Sweden's Prime Minister Stefan Lofven emphasized the country's military offensive cybercapability and the government's willingness to use it. When discussing a three-point plan to stop foreign powers from influencing the 2018 Swedish elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities (SverigesRadio 2017). Some might argue that factors other than PCIs deterred Russia. First is NATO's military capabilities. The NATO-Sweden cooperation defense pact that prioritizes security in the Baltic Sea region protects Sweden from a physical invasion by Russia (akin to those in Ukraine and Georgia) but not from election interference. Second is the threat of Western economic sanctions. The ineffectiveness of these sanctions in changing Moscow's behavior in Ukraine and Syria suggest that they are unlikely to have deterred the Kremlin from executing its plan. Third is Russia's lack of interest in interfering. While the interference value was low, preparatory influence operations aimed at undermining the 2018 Swedish elections demonstrate that the interest was, in fact, present (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018). Having ruled out the above factors, we have further evidence that Sweden's PCIs, put in place before elections, raised the cost of a potential election interference campaign and deterred Russia from interfering into the 2018 Swedish elections.\n# 2017 GERMAN FEDERAL ELECTION: DISINTERESTED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 German federal election provides support for the equilibrium in which the defender's PCIs have no effect on the challenger because the challenger is\n\ndisinterested—the interference value is already so low that the challenger has no interest in interfering in the elections (Region IV in figure 2). We argue that German PCIs had no effect on Russia's decision to stay away from the 2017 German federal election. Instead, a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place.\nThe history of COs and information operations attributed to the Kremlin a few years prior to the election demonstrate that the Russian state had interest in German election interference. Information operations started in 2013, when three key German-language Kremlin-linked propaganda outlets—Sputnik Deutsch, RT Deutsch, and NewsFront Deutsch—entered the German market and were later joined by trolls and bots. The 2015 and 2016 COs against the parliament and political parties demonstrate that Moscow was also eager to obtain sensitive information for potential future use. But the value of an effective influence campaign were overwhelmed by potential costs resulting from the following factors.\nFirst, Germany's balanced media systems, the lack of polarization among the German public, Germany's multiparty and proportional system, and a \"gentleman's agreement\" between major political parties not to use any information leaked as a result of cyberattacks made it difficult for Moscow to sow confusion in the public. (Schwirtz 2017). Second, the only clear beneficiary of these campaigns was the Alliance for Germany (AfD)—the rest of parties supported the sanction regime against Moscow. But when AfD entered the race, they only had between eight and ten percent of vote, which was not enough to gain the majority. Third, the use of old-fashioned paper ballots on the local level afforded Germany with an accurate recount in the event that digitized votes used on the federal level were compromised. Lastly, high-level deterrent rhetoric by German politicians referencing a deterioration of the relationship between the two countries if interference occurred likely played a part. Although Putin and Merkel's relationship has eroded over time, alienating Germany—an important bridge between the West and Russia—was not in Russia's interest.\nIf not these factors, what other factors could have stopped Russia from election interference? Brattberg and Maurer (2018) and Schwirtz (2017) suggest that a failure to influence the 2017 French presidential elections made the Kremlin re-think its approach, since it lost the element of surprise. While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives (Galante and EE 2018).\n## 2017 FRENCH ELECTION: UNDETERRED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 French elections provide an illustrative example for the equilibrium in which the defender's PCIs have no effect on the challenger because it is undeterred—the interference value significantly outweighs its costs (Region I in Figure 2). Given this high value, we argue that the Russian government was like an unstoppable tank moving towards its\ntarget and no French PCIs could have stopped the Kremlin from executing its plan.\nWhat was the value from interfering into the 2017 French elections? The lowest value was undermining faith in the democratic process whereas the highest value was electing a pro-Kremlin candidate that could have resulted in a change in French foreign policy. We argue that even the lowest value of the interference campaign was far greater than any costs Russia could envision paying.\nIf caught, Moscow knew that it faced potential (cyber and non-cyber) retaliation. Diplomatic retaliation was the least of Russia's worries considering some existing tension between the two countries. Moscow expected that, if elected, Emmanuel Macron—as the only unequivocal critic of Putin's Russia out of all presidential candidates—would only exacerbate this tension. The cost of additional economic sanctions—in addition to those that the country already faced for the Ukrainian conflict—was marginal. Nuclear and military responses to COs and information operations were off the table.\nGiven these rather low costs from non-cyber foreign policy options, what additional cyber costs could have Russia anticipated? French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations (Brattberg and Maurer 2018). Deterrence by punishment was unlikely to work either. Even if Paris targeted Russia's critical infrastructure (even though it is quite unlikely), the damage that Russia experienced would have been limited. For example, it is impossible to hack Russia's entire power grid system at once because most stations are manually controlled and can be restored by flipping a switch. Similarly, Paris was unlikely to attempt information operations because of the Kremlin's tight control of Russia's print, online, and social media and because of Russia's treatment of information as a weapon, allowing its military to respond to such information threats (Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space 2011).\nIn short, the potential worst-case scenario costs that Moscow faced were lower than the value it would gain by election interference. Thus, the Kremlin's interference campaign was never going to be deterred by French PCIs.\n## Discussion and Implications\nAs scholars and policymakers continue debating cyber deterrence using COs, attribution, and non-cyber threats, we explore the feasibility of cyber deterrence using means that have been largely overlooked by the international relations literature—public cyberinstitutions which signal organizational capacity to produce and use cybercapability to achieve strategic objectives.\nOur main contribution is to identify the precise conditions under which PCIs can deter strategic cyberattacks, which cause significant damage to a country's economy and security. Since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though different types attacks are deterred by different types of PCIs, the results do not change. Specifically, we reveal several important patterns of the strategic use of PCIs to deter challengers that differ by type. PCIs have no effect on disinterested challengers because they have no interest in attacking the defender and undeterred challengers because they have decided to attack even before observing the defender's PCIs. Both scenarios demonstrate that states are wasting their resources if they\n A troll is someone who argues for extreme views without credible sources.\n An automated program that runs over the Internet.\n During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).\nNADIYA KOSTYUK\n\nPCIs, however, can deter opportunistic challengers that only attack defenders that they perceive as cyber weak and avoid attacking those defenders that they perceive as cyber strong. To deter opportunistic challengers, weak cyber nations might choose to over-invest their limited resources into PCIs to appear strong. Strong cyber nations, in their turn, over-invest their limited resources into PCIs to distinguish themselves from weak cyber nations pretending to be cyber strong. This sub-optimal resource allocation, which makes the defender weaker in its overall cybercapacity, is worthwhile for weak cyber nations because it deters opportunistic challengers. These results have important theoretical and policy implications.\nOur findings shed light on a theoretical debate surrounding cyber deterrence (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). Similar to Tor (2017), this article stresses the need to re-think our reference to absolute nuclear deterrence as a matrix of deterrence success for cyberoperations. Countries do not create cybercapacity to deter low-level COs; instead, their goal is to stop adversaries from executing strategic cyberattacks, which can cause detrimental damage to the country's economy, prosperity, and security.\nWhat constitutes strategic cyberattacks, however, continues to evolve with changes in global cyberthreat landscape; countries only focused on critical infrastructure protection less than a decade ago and added election protection to their top national security priorities following the 2016 US elections. As countries re-define what constitutes strategic cyberattacks, adversaries find more creative ways to achieve their strategic goals using cyber means that operate below the strategic cyberattack threshold. For example, in response to Russia's meddling in the 2016 US elections, the US government took significant steps to protect its 2018 elections. In response to this stern measure, Russian bots and trolls adjusted their behavior and started operating during the election off-season. These influence campaigns, even if conducted during election off-seasons, shape public opinion and might affect public voting behavior. Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace (Murray and Mansoor 2012).\nOur results also show that states should take the signaling of cybercapacity via PCIs with a grain of salt. While PCIs serve as a cyberthreat assessment barometer because they allow a challenger to estimate a defender's ability to conduct COs, the defender's willingness to use these operations, and the scope of the defender's potential retaliation, this assessment is not precise. To better estimate the defender's cybercapacity, challengers should also examine other indicators, such as economic and technological achievements and the defender's reliance on the private sector for cybercapacity. This cumulative approach used to estimate cybercapacity will help governments better evaluate options that minimize the risk of escalation.\nFurthermore, our results speak to the scholarship in international relations theory that focuses on deterrence.[23] Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence.[24] We show that the challenger's\nchoice to cyberattack the defender is independent of the defender's PCIs in two equilibria. In the first one, the challenger has no interest in attacking the defender, giving a false impression of deterrence success. In the second one, the challenger has already decided to attack the defender, despite its PCIs, giving a false impression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios (Danilovic 2002; Snyder 1977). Before concluding the ineffectiveness of PCIs or other means of deterrence, researchers and policy-makers should consider these variables in their estimations. Moreover, since our model is limited to states that have limited cyber arsenals and are not able to burn their exploits to send deterrent signals, we expect to see more investment in PCIs among relatively weaker cyber nations or middle powers. But as more nations invest in PCIs, this deterrent approach might be less effective.\nWhile we take the first stab at understanding deterrence by PCIs, future research should further investigate this important mechanism. Here, we highlight a few venues that future research could explore. First, our model oversimplifies real-world scenarios by making assumptions to identify the causal effect of PCIs on deterrence chances. We view the challenger's choice to attack and the defender's choice to establish PCIs as a one-time decision. In practice, PCIs present a state's cumulative effort to boost its cybercapacity. Similarly, cyber and influence campaigns are composed of many, often low-level activities that span an extended period. Future research should explore how much updating-of-beliefs takes place during different stages of strategic cyberattacks and a state's cumulative efforts to build PCIs. Second, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities (Schneider 2019). Future iterations of this model should explore scenarios when it is not the case. For instance, when PCIs only signal an increase in offensive cybercapability, the threat of cyber retaliation might not deter a country that does not have many cyber targets, like North Korea. PCIs that only signal an increase in cyber defenses might deter countries that view attacking well-protected targets as too costly.\nThird, our model does not distinguish the defender by regime type. Democratic leaders are more transparent, responsive to constituents, and willing to provide public goods in the form of security to satisfy voters and secure their reelection (De Mesquita 2005). While autocracies might be less likely to create PCIs because they face a lesser demand to respond to their domestic audience, they, in fact, might be more likely to exaggerate their PCIs because of this lesser demand. Future research should investigate how these tendencies among different regime types affect model equilibria.\nAs Schelling (2008, 44) puts it, \"If deterrence fails, it is usually because someone thought he saw an 'option' that the... government had failed to dispose of, a loophole that it hadn't closed against itself.\" By building cybercapabilities, governments seem to assume that these capabilities alone have a deterrent effect. As my model demonstrates, successful deterrence depends on a defender's cybercapacity, its willingness to use it, and a challenger's type. Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or\n[23] For an overview of this scholarship, see Lupovici (2010).\n[24] We can describe undeterred challengers as resolute, opportunistic challengers as semi-resolute, and disinterested challengers as resolute.\n\nChina. In these cases, states might perceive potential consequences of entering an escalation cycle with such adversaries as too great to risk. To maximize the desired deterrent effect of publicly flexing their cyber muscles, nations' strategies should demonstrate their willingness to hold assets at risk and face consequences in cases of escalation. Only then, states will be able to close some of the loopholes that adversaries can exploit. Until that is done, the pessimistic view of cyber deterrence will persist.\n## Funding\nNadiya Kostyuk's work was partially supported by the William and Flora Hewlett Foundation under grant 2018-7727.",
    "footnotes": {
      "items": {},
      "intext": [],
      "stats": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 10,
        "success_occurrences": 10,
        "success_unique": 5,
        "bib_unique_total": 15,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.3333333333333333,
        "success_percentage": 100.0,
        "style": "superscript"
      },
      "results": [
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": "",
          "footnote": "It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.",
          "position": 31848
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": "",
          "footnote": "See https://www.documentcloud.org/documents/4627057-16-2517-CKK-2017-09-15-State-Production-3.html.",
          "position": 32144
        },
        {
          "index": 9,
          "intext_citation": "⁹",
          "preceding_text": " to the 2017 elections had no\n",
          "footnote": "It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.",
          "position": 37363
        },
        {
          "index": 10,
          "intext_citation": "¹⁰",
          "preceding_text": "",
          "footnote": "See https://www.documentcloud.org/documents/4627057-16-2517-CKK-2017-09-15-State-Production-3.html.",
          "position": 37746
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "nd were later joined by trolls",
          "footnote": "A troll is someone who argues for extreme views without credible sources.",
          "position": 65294
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "An automated program that runs over the Internet.",
          "position": 65306
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "",
          "footnote": "During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).",
          "position": 66582
        },
        {
          "index": 20,
          "intext_citation": "²⁰",
          "preceding_text": "sting their resources if they\n",
          "footnote": "A troll is someone who argues for extreme views without credible sources.",
          "position": 71247
        },
        {
          "index": 21,
          "intext_citation": "²¹",
          "preceding_text": "",
          "footnote": "An automated program that runs over the Internet.",
          "position": 71324
        },
        {
          "index": 22,
          "intext_citation": "²²",
          "preceding_text": "",
          "footnote": "During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).",
          "position": 71377
        }
      ],
      "flat_text": "International Studies Quarterly (2021) 65, 1151-1162\n# Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\nNADIYA KOSTYUK\nSchool of Public Policy, Georgia Institute of Technology, USA\nCan cyber deterrence work? Existing scholarly works argue that deterrence by punishment using cyberattacks is ineffective because the difficulty of attributing the origin of cyberattacks makes the threat of future attacks less credible. However, these works have told us relatively little about the deterrence ability of public cyberinstitutions (PCIs), defined as publicly observable proactive efforts aimed at signaling a country's level of cyber offensive and defensive capability. This research shows that middle powers (that have scarce cyber arsenals) can use PCIs to deter cyber attacks that cause significant damage to their economy and prosperity; however, this deterrent capability is rather limited. Using an incomplete-information model, we demonstrate that PCIs only deter adversaries that are susceptible to the costs created by these institutions. Despite this limited deterrence ability, middle powers tend to over-invest resources in these cyberinstitutions: Weak cyber states tend to over-invest to convince strong cyber adversaries that they are strong, whereas strong cyber states over-invest so that adversaries do not believe that they are weak states pretending to be strong. By doing so, states reduce their overall cybercapacity. We establish the empirical plausibility of these results using election interference campaigns as examples of strategic attacks. Our focus on the strategic use of PCIs as a deterrent represents a departure from existing literature—which has focused only on cyberoperations—and has important policy implications.\nPuede funcionar la ciberdisuasión? Los trabajos académicos existentes sostienen que la disuasión mediante el castigo de los ciberataques es ineficaz porque la dificultad de atribuir el origen de los ciberataques hace menos creíble la amenaza de futuros ataques. Sin embargo, estos trabajos nos han aportado relativamente poco sobre la capacidad de disuasión de las ciberinstituciones públicas (Public Cyberinstitutions, PCI), definidas como esfuerzos proactivos públicamente observables destinados a señalar el nivel de capacidad ciberofensiva y defensiva de un país. Esta investigación muestra que las potencias medias (que disponen de escasos arsenales cibernéticos) pueden utilizar las PCI para disuadir los ciberataques que causan un daño importante a su economía y prosperidad; pero esta capacidad de disuasión es bastante limitada. Mediante un modelo de información incompleta, demostramos que las PCI solo disuaden a los adversarios que son susceptibles a los costos creados por estas instituciones. A pesar de esta limitada capacidad de disuasión, las potencias intermedias tienden a invertir en exceso sus recursos en estas instituciones cibernéticas: los ciberestados vulnerables tienden a invertir en exceso para convencer a los ciberadversarios fuertes de que son fuertes, mientras que los ciberestados fuertes invierten en exceso para que los adversarios no crean que son estados vulnerables que fingen ser poderosos. Al hacerlo, los estados reducen su cibercapacidad general. Determinamos la credibilidad empírica de estos resultados utilizando campañas de interferencia electoral como ejemplos de ataques estratégicos. Nuestro enfoque en el uso estratégico de las PCI como elemento de disuasión representa un cambio respecto a la literatura existente, que se ha centrado únicamente en las ciberoperaciones, y tiene importantes implicaciones políticas.\nLa cyber-dissuasion peut-elle fonctionner? Les travaux de recherche existants soutiennent que la dissuasion par une sanction reposant sur des cyber-attaques est inefficace car la difficulté de détermination de l'origine des cyber-attaques rend la menace de futures attaques moins crédible. Toutefois, ces travaux ne nous ont donné que relativement peu d'informations sur la capacité de dissuasion des cyber-institutions publiques, qui est définie comme étant constituée des efforts proactifs publiquement observables visant à signaler le niveau des cyber-capacités offensives et défensives d'un pays. Cette recherche montre que les puissances intermédiaires (qui disposent de cyber-arsenaux limités) peuvent avoir recours aux cyber-institutions publiques pour dissuader les auteurs de cyber-attaques nuisant considérablement à leur économie et à leur prospérité, mais cette capacité de dissuasion est plutôt limitée. Nous nous appuyons sur un modèle d'information incomplète et nous démontrons que les cyber-institutions publiques ne dissuadent que les adversaires qui sont sensibles aux coûts engendrés par ces institutions. Malgré cette capacité de dissuasion limitée, les puissances intermédiaires tendent à surinvestir des ressources dans ces cyber-institutions : les cyber-États faibles tendent en effet à surinvestir pour convaincre leurs puissants cyber-adversaires qu'ils sont forts, tandis que les cyber-États forts tendent à le faire afin que leurs adversaires ne croient pas qu'ils sont faibles alors qu'ils se prétendent forts. Ce faisant, les États réduisent leur cyber-capacité globale. Nous établissons la plausibilité empirique de ces résultats en nous basant sur les campagnes d'ingérence électorale comme exemples d'attaques stratégiques. Notre concentration sur l'utilisation stratégique des cyber-institutions publiques comme dissuasion diverge de la littérature existante qui s'est uniquement concentrée sur les cyber-opérations et a d'importantes implications politiques.\n\"To those thinking about trying to influence the outcome of the elections in our country: Stay away!\" (as quoted in Cederberg 2018, 11). Sweden's Prime Minister Stefan Löfven articulated this warning and the country's willingness to act in the event of election interference at a security conference in January 2018. The Swedish government\nNadiya Kostyuk is an Assistant Professor, School of Public Policy, Georgia Institute of Technology.\nAuthor's note: I would like to thank Erica Borghard, Aaron Brantly, Ben Buchanan, John Ciorciari, Fiona Cunningham, Tiberiu Dragu, Mathias Frendem, Andres Gannon, Erik Gartzke, John Leahy, Susan Landau, Herb Lin, Jon Lindsay, Shawn Lonergan, Carla Martinez Machain, Tamar Mitts, James D. Morrow, Jacquelyn Schneider, Jeffrey W. Taliaferro, Brandon Valeriano, Ketian Zhang, Yuri M. Zhukov, and the participants of the Peace and Science Society International pre-conference workshop, of the Student Cybersecurity Symposium at Tufts University, of the International Security Seminar at the Belfer Center for Science and Technology at Harvard Kennedy School, of the Peace Science OPSC, and of the Cybersecurity Series at the Stanford Center for International Security and Cooperation. This paper was presented at the 2019 International Studies Association Conference.\nKostyuk, Nadiya (2021) Deterrence in the Cyber Realm: Public versus Private Cyber Capacity. International Studies Quarterly, doi: 10.1093/isq/sqab039\n© The Author(s) (2021). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nDeterrence in the Cyber Realm\nsubstantiated this rather bold statement with a number of measures meant to deter potential intruders. Specifically, in preparation to its September 2018 election, the country created a number of public cyberinstitutions (PCIs)—publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities.\nSome of these measures aimed at creating better cyber defenses to “raise the threshold [of] attacking Sweden” (National Cybersecurity Policy 2017, 19). Specifically, the government increased the budgets of existing agencies to include election protection into their scope, and it established new agencies, forums, and programs to protect against election interference and disinformation campaigns. For instance, the Swedish government’s crisis preparation and response agency became the main authority for election coordination. The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’” (SverigesRadio 2017). Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats (Cederberg 2018). Media, political parties, and schools ran similar education campaigns. To prepare for total defense awareness, including cases of cyber emergencies, MSB also sent a pamphlet titled “If Crisis or War Comes” to all 4.7 million households.\nIn addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats (Rettman and Kirk 2018). The National Defense Radio Establishment and the Military Intelligence and Security Service installed special detection and warning systems to guard against foreign powers hacking into sensitive agencies. The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators” (O’Dwyer 2018).\nWe argue that these PCIs established by the Swedish government in order to protect its 2018 elections convinced the Russian government that an interference campaign would have been too costly. Why were PCIs successful in deterring a potential interference campaign? Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy (Fernandino 2018)—under what conditions can PCIs deter any strategic cyberattack?\nTo answer these questions, we develop an incomplete-information model in which a challenger considers attacking a defender. The defender in this case is a middle power, since these nations have scarce cyber arsenals and are more likely to invest in PCIs for deterrence. The challenger is not certain about the defender’s cybercapacity—how cyber “strong” or “weak” it is—and can only infer it from the defender’s observable PCIs. Thus, the challenger’s decision to attack depends on the defender’s type, and the defender has an incentive to over-invest in public cybercapacity in order to signal that it is stronger that it actually is.\nThis model leads to several insights. First, there is a large number of equilibria for which PCIs have no influence on the challenger. Second, we show that the defender’s strategic use of PCIs to deter the challenger works only when two conditions are met: (1) the challenger believes that the defender possesses significant cybercapabilities and that it would therefore be too costly to attack the defender; and (2) the challenger is susceptible to the cost exacted by PCIs. This finding shows that PCIs influence the challenger’s decision to attack only in limited cases. Despite that, weaker defenders over-invest in PCIs to signal higher cybercapacity than they possess, and strong defenders over-invest so that their adversaries do not believe that they are weak states pretending to be strong.\nThis paper makes a number of theoretical contributions to the existing international-relations literature. First, it helps us better understand the nature of deterrence in the information age. Our unique strategic logic of PCIs as a proxy for a country’s cybercapacity represents a departure from existing literature. While most scholarly works on cyber-to-cyber deterrence focuses on deterrence by punishment using cyberoperations (Baliga, de Mesquita, and Wolitzky 2020; Valeriano, Jensen, and Maness 2018), this project presents a new theory that explains how PCIs can deter by both prevention and by threat of punishment, by signaling an increase in both defensive and offensive cybercapabilities. This project also contributes to the literature on cross-domain deterrence (Gartzke and Lindsay 2019) by explaining situations in which countries use PCIs to deter their adversaries instead of non-cyber foreign policy options (i.e., economic sanctions, or diplomatic or military responses) that are ineffective and/or costly.\nSecond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). We, instead, seek to explain the strategic behavior of weaker cyber states or middle powers that suspect a cyberattack. In these situations, middle powers often must rely on their own cybercapabilities because their allies are unlikely to help. Cyberdefenses are unique to each country and not easily transferable; close allies are often reluctant to disclose information about their offensive cybercapabilities and/or commit cyberattacks on an ally’s behalf (as compared with their willingness to offer military assistance during territorial invasions).\nThe literature on the “bargaining model of war” focuses on how private information and incentives to misrepresent, and commitment problems affected by power shifts, explain costly armed conflict (e.g., Schultz 1998; Slantchev 2003, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power (Morrow 1989); states also tend to keep certain capabilities secret to obtain military advantage (Reiter 2003).\nWhat is new about our model then? First, a different theoretical foundation drives how nations signal their cybercapacities. Unlike in the case of military capacity, a state cannot launch a parade to signal its cybercapacity. Satellite images are also unlikely to be useful to adversaries seeking to estimate a state’s cyberstrength. An executed cyberattack may provide a target with a good estimate of the attacker’s capabilities, but such an attack de-values capability because it provides the target with instructions on how to fix flaws in their own networks and systems. The time-limited life-span and the dynamic nature of cyberoperations further complicate their signaling potential. While the basic parameters for most traditional weapons remain relatively static,\n\nNADIYA KOSTYUK\n\nSecond, existing models focus only on whether and how investment in military capacity can deter a future attack or affect the likelihood of winning a war. Our theoretical foundation instead explains that sources of state cybercapacity are more diverse, lie beyond military and government, and extend to a state's private sector and even public-opinion management. While investing in military cybercapacity is important for deterrence by the threat of punishment, to deter adversaries by prevention, states might, for example, invest significant resources into building public awareness about the danger of cyberoperations and information operations, making potential election-interference campaigns harder.\nRegarding the model, the closest work, which focuses on the relative impact of scarce resource allocation on the likelihood of attack, is Arena and Wolford (2012). Unlike Arena and Wolford (2012), which examines a state's decision to allocate its resources between armaments and intelligence gathering capabilities in order to reduce uncertainty over its opponent's military strength, our model explores a state's decision to allocate its resources between public and private cybercapacity in order to deter its strong opponent from executing a cyberattack against the state. Similarly to works on counter-terrorism policies (Bueno de Mesquita 2007; Dragu 2011), our model explains why nations over-invest in public capacity and that such policies are generally ineffective in deterring adversaries.\nBaliga, de Mesquita, and Wolitzky (2020) and Welburn, Grana, and Schwindt (2019) are the only two other models that focus on cyberdeterrence; they explore how a state's inability to correctly attribute the origin of cyber operations and to detect cyberattacks affects the state's chances of deterring potential attackers. Unlike these models, our model focuses on organizational capability which signals the state's ability to readily produce and use covert cybercapacity. Unlike Baliga, de Mesquita, and Wolitzky (2020)'s model, in which there is uncertainty over the signal's sender (i.e., the attacker's identity) while the signal's quality (i.e., the strength of cybercapacity) is clear, our model investigates situations in which the signal's sender is known but the signal's quality is unclear. Unlike Welburn, Grana, and Schwindt (2019)'s model, in which a defender can signal any cybercapability with no cost, our model explains how the defender's choice to allocate its limited resources translates into observable cybercapacity.\nThe paper proceeds as follows. We start with explaining how a state can signal its cybercapacity. Then, we explain when and how public cyberinstitutions can deter strategic cyberattacks. Next, we introduce the model and derive the model equilibria. We use illustrative examples from elections to establish the empirical plausibility of our theory. We conclude with a discussion of our study's implications.\n## Signaling Cybercapacity\nStates can signal their cybercapability by (1) attributing cyber operations (COs) to attackers; (2) executing COs against adversaries; and (3) establishing public cyberinstitutions—publicly observable efforts aimed at demonstrating a country's level of offensive and defensive cybercapability. Each of these methods has its pros and cons.\nSignaling cybercapacity via attribution is a recent trend, as demonstrated by the number of US indictments. Attribution is a powerful deterrent because it signals to both the attacker and future perpetrators that they are not as invisible as they would like to be in cyberspace. But cyber attribution is difficult and costly: Not only does cyber attribution require significant resources and technical expertise to correctly attribute an attack to a specific computer, but it also demands intelligence to connect the used computer to a perpetrator. Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources (Clark and Landau 2011; Egloff and Wenger 2019). As a result, only a few nations have the resources, technical expertise, and political will to use attribution as a way to signal their cybercapability.\nSignaling cybercapacity via covert COs provides the target with an accurate estimate of the attacker's capability. However, the difficulty of attributing the origin of COs and the time it takes to do so diminish the signal's value, which is further reduced by the time-limited life-span and the dynamic nature of COs. Moreover, if a victim is not able to attribute the attack or remains quiet about the attack, the signaling value of COs is either zero or quite low. Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons (Gartzke 2013); only a few nations have a large enough cyber arsenal that they can burn some of their exploits for signaling purposes.\nWhile cybercapacity cannot be revealed because it depends on secret access and vulnerabilities, the state can reveal its ability to find such vulnerabilities by establishing PCIs, defined as publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities. PCIs signal an increase in organizational cybercapability, which demonstrates the state's ability to readily produce cybercapability and use cyberoperations for political purposes. As a result, signaling via PCIs provides the state's allies, adversaries, and domestic and international audiences with an immediate, often rough proxy for the state's cybercapacity and preserves the value of the state's covert COs.\nFor simplicity, I distinguish two ways in which a state can establish its PCIs: It can (1) create a new agency program, initiative, doctrine, strategy, or policy to address some aspect of cybersecurity; and/or (2) add new cyber roles to existing agencies or new cyber provisions to existing policies. For instance, to deter election interference campaigns, Sweden established an agency responsible for psychological defense. When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time (Schwirtz 2017).\n5Some of these works include Debs and Monteiro (2014), Fearon (2018), Kydd (2000), Meirowitz and Sartori (2008), and Slantchev (2005).\n4Germany's hack-back strategy is a PCI even though the government does not give any details regarding the scope of this strategy. Since they publicly discussed its development (instead of only privately executing it), we have an idea of the steps that the German government considers adopting in order to deter election interference. If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage (Schwirtz 2017). For instance, in response to the attack against the parliament, the German government could remove servers on which stolen parliament data were located.\n\nEven though these two options differ in how governments created their PCIs, they both might involve a similar set of measures. Specifically, a new agency and a new strategy might require additional budget, stuff, training, and expertise. While PCIs often do not reveal all the details about created cybercapacity, unlike covert cyberactivity they allow an adversary to estimate the scope of the change and the potential resulting increase in the target state's cybercapacity. The Swedish and German actions, for instance, signaled that both countries prioritized spending their resources on building better cyber defensive and offensive capabilities to deter potential election interference campaigns.\nBefore we explain how PCIs can deter adversaries, we would like to clarify that our theory focuses on middle powers—the nations that have scarce cyber arsenals and are more likely to invest in PCIs as a means of deterrence. Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by \"burning\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities.\n## The Theory of Cyber Deterrence\nThe theory presented in this section examines the specific context in which a strong challenger (including cyber powers) contemplates a strategic cyberattack against a defender.\nWhen the challenger considers a cyberattack, he calculates the value he can gain from this attack (e.g., undermining democratic processes, in the case of election interference) and the cost he can incur. There are two types of costs. First is the cost of the defender's potential retaliation (e.g., using economic sanctions, military operations or cyberoperations). Second is the tendency of cyberoperations—unlike military operations—to diminish in value after their first use. A tank, for example, can be successfully deployed many times over many years. Cyberattacks, on the other hand, often lose their effectiveness after their first use, even if the attack fails due to the defender's defenses. In using cyberattacks, the challenger risks the possibility that the defender might be able to develop protection against similar attacks in the future.\nWe argue that, for a challenger to decide to use a cyberattack against a defender, it must believe that the attack's value will outweigh its cost. What can change this cost-benefit calculation? Specifically, what can raise the cost enough to deter the challenger?\nWe assume that the costs from non-cyber foreign policy tools (i.e., diplomatic or military responses, or economic sanctions) will not change the cost-benefit calculation because the challenger has considered them initially. These costs are easy to estimate using the defender's past history and are highly predictable based on the challenger's \"prior beliefs about the defender's willingness\" to use one\nSome anecdotal evidence suggests that even though the US government could not hack back in response to the election, it went into Russian servers and left non-malicious code that had \"U.S. Cyber Command\" in the comments. They did so to signal to the Russians, in a covert way, that they had the ability to strike whenever they wanted.\nI employ the language from the traditional deterrence literature and refer to an adversary as a challenger and a defending state as a defender. The model makes the assumption that the defender attempts to deter her strongest challenger, which is the challenger that can potentially cause the most significant damage. If she is able to deter her strongest challenger, then all her other challengers will be deterred by default. Because the model focuses only on the strong challenger, I have omitted \"strong\" and refer only to a \"challenger\" for the remainder of the paper.\nof these options (Fearon 2002, 6). Moreover, given that the defender's capability in non-cyber foreign policy domains is unlikely to change rapidly, the challenger's estimate of the costs imposed by diplomatic responses and economic sanctions is likely to be fairly accurate. The challenger is also aware that military responses are costly and that the defender is unlikely to launch a military strike in response to information operations or cyberoperations.\nEven though these non-cyber foreign policy tools cannot change the challenger's cost-benefit calculation, the challenger considers the defender's capability in these non-cyber domains when forming its opinion of the defender's cybercapacity. Since nations with significant resources and expertise can build sophisticated cyber weapons (Gartzke 2013), the challenger can accurately conclude that the most powerful military nations have impressive cyber arsenals. While the country's military capability might often be correlated with its cybercapacity, it is not always the case because some nations might choose to purchase cyber weapons from third parties or work with proxy groups to execute attacks on their behalf. Despite that we argue that both the defender's capability in non-cyber and the defender's capability in cyber domains form the challenger's prior belief of the defender's cybercapacity.\nGiven that the challenger is quite certain about the costs associated with non-cyber responses and, as a result, is unlikely to be deterred by them, the defender is left with cyber foreign policy tools to deter the challenger from executing cyberattacks. We argue that cyber foreign policy tools may raise the cost of a cyberattack for the challenger because the challenger remains uncertain about the defender's cybercapacity. Even if the challenger has a rough estimate of the defender's cybercapacity, the dynamic, time-limited nature of cyber tools makes it difficult for the challenger to determine the defender's cybercapacity with precision or certainty. Specifically, while the basic parameters for most traditional weapons remain relatively static, strategically relevant features of certain cyber weapons can change significantly over a short period of time. Moreover, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it (Axelrod and Iliev 2014). We explore this challenger's uncertainty over the defender's cybercapacity as the main mechanism that affects the probability of successful deterrence. How can the defender signal its cybercapacity\nThe Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations (Newman 2019).\nFor deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity (Schelling 2008). Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high (Press 2005). Moreover, as earlier explained, many nations cannot afford to \"burn\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities, and those that do send a rather costly signal about their sophisticated cyber arsenal. Furthermore, many countries conduct cyber espionage to observe other countries' cyberattack plans and capabilities. As a result, cyber powers that consider challenging other nations probably know enough about other countries' covert cyber strength to know whether they face another cyber power or not, though they do not necessarily know its precise capabilities. Thus, there is no uncertainty about the capabilities of these cyber powers; instead, this theory explores uncertainty over the capabilities of weaker nations—middle powers—and specifically how cyber \"strong\" or \"weak\" they are. These nations tend to have a rather scarce cyber arsenal and are more likely to invest in PCIs as a means of deterrence. However, the better a challenger's cyber-intelligence, the less uncertainty the challenger has about the defender's cybercapacity.\nNADIYA KOSTYUK\n\n## Deterrence by PCIs\nPCIs can leave the challenger uncertain about the defender's cybercapacity because they demonstrate the defender's ability to produce cybercapability without revealing any concrete details about this capability. PCIs can deter by prevention and/or by threat of punishment. These two types of deterrence are associated with the two types of costs that PCIs can inflict on the challenger, increasing the cost of its cyberattack. PCIs can deter by prevention because adversaries may infer that their attacks are likely to fail against the defenses implied by a PCI. Firewalls, updated computer software, programs aimed at educating public about cyberthreats, and policies that outline a set of measure to provide better security of critical infrastructure are examples of PCIs that can deter by prevention because they make hacking more difficult. While the challenger can keep using conventional weapons even if a conventional attack fails, the challenger often burns its cyber exploits in the case of an unsuccessful cyberattack. This is because having discovered an attempted hack, the defender can close the existing vulnerability making the future use of this exploit impossible. PCIs can also deter by the threat of punishment; for instance, new military doctrines and units signal the state's ability to use its cyber weapons in response to cyberthreats.\nWe investigate situations in which both deterrence mechanisms are at play for the following two reasons. First, one cyberinstitution can signal both cyber offensive and defensive capability, making it hard to separate deterrence by the threat of punishment from deterrence by prevention. The US Department of Defense Cyber Strategy (2015, 3), for instance, uses deterrence by prevention by specifying the Department of Defense's role in defending its information networks, and it uses the threat of punishment by establishing a Cyber Mission Force to be used to defend the United States against cyberattacks of \"significant consequence\". Second, when facing a strategic cyberthreat, states tend to respond with multiple PCIs and, as a result, implement both types of deterrence at the same time to maximize their chances of success.\nSince PCIs can increase uncertainty about the defender's cybercapacity raising the probability of successful deterrence, the defender might want to invest most, if not all, of its resources into PCIs. But such a strategy takes valuable resources away from covert cyberactivity (CCA) or private cybercapacity, which involves secret development of cybercapabilities and ongoing cyberoperations. For instance, a polished strategy document, newly-constructed headquarters, or a new initiative meant to bring public awareness of cyberthreats is a poor substitute for a CCA aimed at penetrating the challenger's electricity grid and preparing for a future attack that could be used for retaliation.\nWe argue that this trade-off between PCIs and CCAs is important. Even though some PCIs involve the development of private cybercapability (e.g., the German's hack-back strategy), such PCIs give a high-level view on what capacity a government develops whereas CCAs remain truly covert and only signal capability after being discovered and correctly attributed. The Stuxnet worm, which the US and Israeli governments developed and deployed in 2005 against an Iranian nuclear enrichment facility, was an example of such a CCA, until it was discovered in 2010. Even though the US government created a number of PCIs between 2005 and 2010 to signal an increase in its cybercapacity, none of them signaled the tremendous potential of the US cybercapability. Only the attributed Stuxnet worm signaled the true scope of the US cyber arsenal. Unlike PCIs, which send an immediate, although often imprecise signal about a state's level of cybercapabilities, the Stuxnet example demonstrates that CCAs send a more accurate signal of a state's cybercapabilities but this signal might be delayed.\nSince an investment in both PCIs and CCAs is important for overall cyber capacity, over-investment in PCIs at the expense of investment in CCAs can make a defender weaker. However, the relationship between the defender's overall cybercapacity and its chances at deterrence is not linear—i.e., an increase in one does not necessarily mean an increase in the other. Therefore, a defender with weak cybercapabilities might strategically invest more in PCIs if such an investment maximizes its chances at deterrence, even if it decreases its overall cybercapacity.\nWe argue that the effectiveness of this deterrent strategy depends on the type of the challenger. Specifically, it only works against a challenger that is susceptible to the costs created by PCIs. We call this challenger opportunistic. During the 2018 Swedish elections, Russia was an example of an opportunistic challenger. Having considered a potential interference campaign, the Kremlin realized that the rather small marginal value from this campaign was not worth the additional potential costs imposed by the improved defenses and offenses that Sweden created in the form of PCIs prior to the elections. But an over-investment in PCIs as a deterrent strategy does not work against an disinterested challenger; such challengers never attack, even if they give the impression that they are considering attacking. During the 2017 German elections, Russia was an example of a disinterested challenger. PCIs put in place prior to the 2017 elections had no\n It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.\n Given that early scholarly works perpetuated the offense dominance in cyberspace (Choucri 2012; Demchak 2011; Kello 2013), prevention is often seen as somewhat futile as it is nearly impossible to protect all vulnerable targets; thus, preemption may be a more cost-effective tactic. Recent works, however, refute the offense-dominance thesis (Gartzke 2013; Lindsay 2013). While it is easier to find a vulnerability in an adversary's network/system than to defend its own networks/systems from hundreds of possible cyberattacks, Slayton (2017) stresses the importance of looking at the cumulative effort required for building cyber offense or defense. Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\" (Slayton 2017, 74). Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense (Borghard and Lonergan 2017).\n\nFigure 1. Defender’s cybercapacity: (a) relationship between defender’s observed and overall cybercapacity; and (b) relationship between defender’s type and her overall cybercapacity as a function of $I_{\\theta}$. Note: $I$: PCIs that $D$ can develop with $r$ units of resources; $N$: CCAs that $D$ can develop with $r$ units of resources; $I + N$: $D$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}$: the level of PCIs at which $D$’s overall cybercapability is maximized (point Max). Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $\\text{Max}_{S}(\\text{Max}_{W})$).\neffect on Russia’s decision to stay away from these elections because a combination of non-cyber factors shifted Russia’s cost-benefit calculus towards not attacking even before Germany establish its PCIs. Lastly, an over-investment in PCIs is also a waste of resources when the defender faces a undeterred challenger; such challengers always attack because the value of attacking is much higher than any additional costs created by PCIs. During the 2017 French elections, Russia was an example of an undeterred challenger. Having witnessed the worldwide impact of the mass disclosures of private data prior to the 2016 US elections, Moscow was willing to pay any cost and to risk any potential French (cyber or non-) retaliation for its influence campaign, which could help elect a pro-Kremlin candidate.\nThe next section models cyber deterrence by PCIs explicitly. It is worth noting that since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though the type of an attempted attack requires different types of PCIs, this does not affect the model logic and the obtained results.\n## Model\nThis section provides the intuition behind the game and the Online Appendix includes the detailed explanation and mathematical proofs.\n**Game Overview.** This is a game between a challenger ($C$, “he”) and a defender ($D$, “she”). $C$ considers executing a cyberattack against $D$. To deter $C$, $D$ decides how to signal her cybercapacity by allocating her resources between public and private cybercapacity and, as a result, which level of PCIs to implement. $D$ has a type $\\theta \\in [S, W]$ that differs in the amount of resources $a_{\\theta}$ available to her. The strong defender $D_{S}$ has many more resources available to her than the weak defender $D_{W}$. $\\theta$ is unobservable to the challenger.\nThe game starts with Nature’s choice. Nature selects that $\\theta = S$ with probability $\\pi$ and that $\\theta = W$ with probability $1 - \\pi$. The model assumes that both players have a common prior belief and that $\\pi$ is the true probability that the defender is strong. Then $D$ decides how to allocate her resources between PCIs and CCA. After $D$ implements PCIs, $C$ observes it, (possibly) updates his beliefs about $D$’s type, and decides whether he wants to attack $D$. When $C$ chooses whether to attack, $C$ observes $D$’s move but not $D$’s type. If $C$ does not attack, $D_{\\theta}$ successfully deters $C$ and the game\nends. If $C$ decides to attack $D_{\\theta}$, Nature selects that his attack is successful with probability $Q_{\\alpha}$, and unsuccessful with probability $1 - Q_{\\alpha}$. The probability of a successful attack is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. If $C$’s attack succeeds, $D_{\\theta}$ must decide whether to retaliate against $C$. If $D_{\\theta}$ does not retaliate against $C$, the game ends. If $D_{\\theta}$ retaliates against $C$, Nature selects that her retaliation is successful with probability $P_{\\theta}$ and is unsuccessful with probability $1 - P_{\\theta}$. The probability of a successful retaliation is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.[12]\n**Signaling Cyber Capacity.** To understand how $D$ can deter strategic cyberattacks, we must first understand how she can create her cybercapacity because $D$’s cybercapacity is a proxy for $D$’s ability to deter $C$. The higher $D$’s capacity is, the higher the likelihood that $D$ deters $C$. To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA.[13] Both PCIs and CCA create $D$’s overall cybercapability. As mentioned earlier, $D$’s overall cybercapability does not necessarily increase simply by investing more in her PCIs because such a strategy takes valuable resources away from CCA. As a result, it makes $D$ weaker.\nFigure 1(a) explains the intuition of how this works graphically. $C$ has a prior belief of $D$’s cybercapability, given COs attributed to $D$ or using various indicators of $D$’s technological development. Given the public nature of PCIs, $C$ can only observe PCIs and estimate $D$’s cybercapability. We call it $D$’s observed cybercapability and place it on the x-axis in Figure 1(a). The y-axis in Figure 1(a) represents $D$’s overall cybercapability that we receive by adding the resources that $D$ invests into PCIs and CCAs. Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.[14] The\n[12] We display this two-player game with incomplete information concerning $D$’s type in Online Appendix Section 1.1.\n[13] Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.\n[14] I assume that both $I$ and $N$ are increasing in $r$ and that there are diminishing returns to investment in each (i.e. $I'(r), N'(r) &gt; 0$ and $I''(r), N''(r) &lt; 0$).\nNADIYA KOSTYUK\nFigure 2. Equilibria and challenger's types. Note:  $C$ : a challenger;  $D_W$ : a weak type of the defender;  $D_S$ : a strong type of the defender;  $\\pi$ : a prior probability that  $D$  is strong;  $1 - \\pi$ : a prior probability that  $D$  is weak; and  $\\tilde{I}_S$ : the level of PCIs at which overall cybercapability is maximized for the strong type of the defender. 1:  $C$ 's gains from attacking  $D_S$ , given the probability of this attack is successful; 2:  $C$ 's gains from attacking  $D$ , given that with  $\\pi$  probability he is facing  $D_S$  and with  $1 - \\pi$  probability, he is facing  $D_W$  that pools with  $D_S$  and implements  $\\tilde{I}_S$ ; and 3:  $C$ 's gains from attacking  $D_W$ , given the probability of this attack is successful.\nfunction  $I + N$  stands for  $D$ 's overall cybercapability when the resources are distributed between PCIs and CCAs. We define  $\\tilde{I}$  to be the level of PCIs at which  $D$ 's overall cybercapability is maximized (point Max in Figure 1a).\nBefore  $D$  creates her PCIs, often she already has some existing cybercapabilities. For instance, before the Swedish Civil Contingencies Agency (MSB) became responsible for election protection, it dealt with civil protection; MSB could use these expertise to provide public safety during the time of elections. This existing level of cybercapability determines  $D$ 's type. We distinguish two types of  $D$ -strong  $(D_S)$  and weak  $(D_W)$ .  $D_S$ , depicted by the black line in figure 1(b), has a higher level of existing cybercapability, thus she can implement a higher level of PCIs and have higher chances of deterrence than  $D_W$ , depicted by a gray line in figure 1(b). Similarly,  $\\tilde{I}_S$  and  $\\tilde{I}_W$  are the levels of PCIs at which overall cybercapability is maximized for the defender's weak and strong types, respectively.\nWe assume that the costs of producing public  $(I)$  and private  $(N)$  cybercapacity are the same for the strong and weak type of the defender because we primarily focus on explaining the behavior of middle powers. Some nations that have developed technological expertise in this area—cyber powers, for instance—can develop \"more\" capability for a given budget. In such cases, it might be difficult for other nations to imitate PCIs developed by these cyber powers. For these reasons, our model excludes these powerful nations and primarily focuses on the behavior of middle powers that can imitate each other's behavior in order to deter their challengers.\n# Model Equilibria\nNext we discuss the intuition behind the model equilibria.\nAs explained earlier, the effectiveness of the defender's PCIs on deterring the challenger, depends on the challenger's type. We distinguish three types of the challenger that depend on the three cut-off points depicted in figure 2. If  $C$  is undeterred and always attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region I in figure 2). If  $C$  is disinterested and never attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region IV in figure 2). In these two equilibria,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. Proposition 1 summarizes both equilibria.\nProposition 1. Challenger's decision to attack is independent of defender's PCIs.\n(a) If  $C$  is undeterred and always attacks (Region I in Figure 2),  $D_{0}$  maximizes her cybercapacity and  $C$  always attacks.\n(b) If  $C$  is disinterested and never attacks (Region IV in Figure 2),  $D_0$  maximizes her cybercapacity and  $C$  never attacks.\nIn both equilibria in Proposition 1,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. But what happens if they do? We argue that different types of the defender would invest their resources differently to maximize their chances of deterring adversaries that are susceptible to the costs created by PCIs. Specifically, the strategic use of PCIs to deter  $C$  occurs in the signaling region where there is both the need for and the possibility of deterrence. Here  $D_0$ 's PCIs can influence  $C$ , which will take different actions depending on the defender's true type. Specifically, the challenger will attack the defender if he knows that the defender is weak and will avoid attacking if he knows the defender is strong. We call this challenger opportunistic. In this region, depicted by Regions II and III in Figure 2, there are two pure strategy equilibria (Propositions 2-3) and one mixed strategy equilibrium. We focus on the pure strategy equilibria in the main manuscript and present the mixed equilibria in the Online Appendix.\nIf  $C$  prefers attacking a defender that he thinks is weak and avoiding attacking a defender that he thinks is strong due to the fear of retaliation or attack failure,  $D_W$ 's natural response is to increase her investment into PCIs to appear strong. Specifically, instead of redistributing her resources so that her overall cybercapability achieves its maximum (Max  $W$  in Figure 3 (a)),  $D_W$  distributes them so they are her overall cybercapability is at point A in Figure 3(a). By doing so,  $D_W$  creates the same level of PCIs  $(\\tilde{I}_S)$  as  $D_S$  (i.e.,  $D_W$  pools with  $D_S$ ), so when  $C$  observes these institutions, he concludes that he is dealing with a strong defender and does not attack. Because this deterrent strategy decreases  $D_W$ 's overall cybercapability, by appearing strong,  $D_W$ , in fact, hides her actual weakness. This pooling equilibrium holds only when  $D$ 's gain of appearing strong outweighs  $D$ 's loss to inefficiently allocating her resources and when  $C$ 's prior belief that  $D$  is strong is high. Proposition 2 presents this pooling equilibrium.\n# Proposition 2. Pooling Equilibrium.\nSuppose  $C$  is opportunistic and prefers attacking  $D$  only if he believes that  $D$  is weak. If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.[15]\n\nFigure 3. Defender's pure strategy actions when facing an opportunistic challenger: (a) pooling strategy; and (b) strategic separation strategy. Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$'s overall cybercapability when the resources are distributed between PCIs and CCAs; $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $Max_{S}(Max_{W})$); $\\hat{I}$: the level of PCIs that $D_{W}$ cannot attain; $A$: $D_{W}$ imitates PCIs of $D_{S}$; and $B$: $D_{S}$ strategically separates herself from $D_{W}$ by implementing PCIs that $D_{W}$ cannot implement.\nIf $C$'s prior belief that $D$ is strong is low, then $C$ interprets pooling as weak and attacks if $D$ implements $\\hat{I}_S$ (Region II of figure 2). $D_S$ is aware that $D_W$ is trying to imitate her PCIs and takes one of the two actions. Not wanting to be confused with $D_W$, $D_S$ can alter her behavior to clearly distinguish herself (i.e., separate) from $D_W$ to ensure that $C$ is deterred. Specifically, $D_S$ spends enough resources to reach a level of PCIs that $D_W$ cannot attain—$\\hat{I}$ (point B in Figure 3(b)). Observing $\\hat{I}$, $C$ knows that the defender is strong as $D_W$ could not implement $\\hat{I}$, as Figure 3(b) shows. Since $D_W$ cannot imitate $D_S$ and implement PCIs to reach $\\hat{I}$ in Figure 3(b), $D_W$ implements her optimal strategy $\\hat{I}_W$. Since separation is costly as it reduces $D_S$'s overall capacity, for this equilibrium to hold, $C$ should not attack when he sees $\\hat{I}$ even though he knows that $D_S$'s overall capacity is reduced. Proposition 3 summarizes this separating equilibrium.\n**Proposition 3.** Separating Equilibrium. Suppose $C$ is opportunistic and prefers attacking $D$ only if he believes that $D$ is weak. If $C$'s prior belief that $D$ is strong is low, then (1) $D_S$ implements a level of PCIs that $D_W$ cannot imitate $(\\hat{I} &gt; \\hat{I}_S)$, (2) $D_W$ is not able to pool with $D_S$ and implements $\\hat{I}_W$, and (3) $C$ attacks only when he sees $\\hat{I}_W$. [16]\nAlternatively, $D_{S}$ can decide not to implement PCIs that $D_{W}$ is not able to mimic because this will weaken her overall cybercapacity and invite an attack. In this case, a pure strategy equilibrium does not exist in Region II of Figure 2. But there exists a mixed strategy equilibrium where $D_{W}$ mixes between $\\hat{I}_{W}$ and $\\hat{I}_{S}$ and $C$ is indifferent between attacking and not. The Online Appendix presents this mixed strategy equilibrium.\n## Illustrative Examples of Elections\nThe novelty, secrecy, and sensitivity of the topic of cyber deterrence prevents us from conducting a rigorous empirical test of our findings. Instead, we aim at demonstrating the empirical plausibility of our theory of deterrence of strategic cyberattacks using PCIs. Since our theory is agnostic towards the type of a strategic cyberattack that a\nnation prefers to deter, we use illustrative examples from elections to provide support for our model equilibria. [17] Specifically, we focus on Kremlin-directed attempts to influence electoral campaigns in Western democracies: the 2016 US elections, the 2017 German elections, and the 2018 Swedish elections. We choose the most similar examples for our comparison (George 2019); they share the same cyber-capable attacker (Russia), have similar targets (Western democracies), use the same methods (cyber and information operations), have the same purpose (election interference), and have similar timeframes (2016–2018). They differ, however, in (1) the stakes involved in each campaign (e.g., a challenger's type); and (2) the level of PCIs that the targets implement (e.g., strong versus weak). As a result, these examples help demonstrate (1) under what conditions the challenger's uncertainty over the defender's cybercapacity increases the probability of successful deterrence; and (2) when this uncertainty has no effect.\nWe focus on the three different illustrative examples because they match the model's scope conditions that must be met if PCIs deter the challenger. First, there must be a difference in how different types of defenders allocate their resources to signal their cybercapacity. As we shortly demonstrate, the Swedish government, a weak cyber nation, prioritized investing in PCIs to appear that it had strong cyber defenses and offenses. Second, the challenger must face uncertainty about the defender's cybercapacity and its type. The time-limited and dynamic nature of COs generally raises uncertainty about cybercapacity, but this uncertainty over the defender's type does not play a role when facing an undeterred or disinterested challenger. But it is important when facing an opportunistic challenger: By investing more of its resources into PCIs, a weak defender can deter the challenger by pretending that it is strong. Uncertain about Sweden's actual cybercapacity, Russia observed the overwhelming number of PCIs that Sweden created prior its 2018 election that are typical of strong types; it is conceivable that based on these observations, the Kremlin chose not to attack. Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In\n[16] This equilibrium relies on the off-the-equilibrium beliefs that the defender is weak \"enough\" if it plays $\\hat{I}_S$.\n[17] We use an illustrative example to provide support only for the pooling equilibrium when the challenger is opportunistic (Region III in figure 2) because it provides the most interesting result by demonstrating when PCIs can, in fact, deter the challenger.\nNADIYA KOSTYUK\nthe elections we are considering, the cost-benefit calculations differ. In the 2018 Swedish elections, the additional costs created by Swedish PCIs outweighed the low value of Russia's interference campaign and deterred Russia from interfering. In the 2017 German elections, the Kremlin did not consider the extra costs created by PCIs because they were irrelevant—a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place. In the 2017 French elections, benefits outweighed the costs.\n# 2018 SWEDISH NATIONAL ELECTIONS: OPPORTUNISTIC CHALLENGER AND POOLING EQUILIBRIUM\nThe 2018 Swedish national elections provide support for the pooling equilibrium in which the weak defender over-invests in PCIs to appear strong and, as a result, deters the opportunistic challenger (Region III in Figure 2). To show that this is the case, we need to demonstrate that the Russian government was opportunistic and additional PCIs that Sweden created prior to the elections changed the Kremlin's cost-benefit calculation of the election interference campaign.\nTo understand how PCIs as a deterrent strategy worked in this case, we first explain why the Kremlin even considered interfering in the Swedish electoral process. Sweden's nonalignment policy has always served as a guarantee of Russia's security. Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO) (Kunz 2015). In response, Russia's Defense Minister Sergei Shoigu described Sweden's involvement in NATO activities as \"worrying\" and added that \"such steps...[were] forcing us to take response measures\" (Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister 2018). Military actions and/or economic sanctions are possible response measures, although to date, Russia has pursued neither of these. The Ukrainian and Syrian conflicts, combined with NATO-Swedish defense cooperation (even if it falls short of collective defense), are most likely responsible for preventing Russia from taking a military approach.\nRussia is, on the other hand, a mastermind of influence campaigns and had been preparing a strong foundation for such a campaign on the Swedish population for some time. Starting in 2014, the Swedish information landscape witnessed an increase in disinformation campaigns, led by trolls, bots, and Kremlin-sponsored media outlets, such as Sputnik International. In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\" (Cederberg 2018, 5) and Sweden remained one of the few \"favorite target[s] of the Kremlin's propaganda machine\" at the beginning of 2018 (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018, 109). Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks[18] against Swedish news sites and a disinformation campaign about NATO in the Swedish media.[19]\nAn anti-immigration sentiment in both the Swedish parliament and the populace bolstered these ongoing COs and information operations. Immigration has always been a contentious issue in Swedish politics, recently exacerbated by the Syrian refugee crisis. Over the last five years, Sweden, a country of 10 million, has welcomed 165,000 asylum-seekers from the Middle East. Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010 (Johnson and Evans 2018). The party's anti-immigration stance and the divide in the general population over the immigration issue presented the perfect environment for the Kremlin's influence campaigns.\nHowever, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference (Cederberg 2018). Why? What stopped Russia from interfering in the Swedish elections?\nLet us look at Russia's cost-benefit calculus. While Sweden had a favorable political climate and Russia had some ongoing COs and information operations, the value of a potential interference campaign was quite low, compared to, for instance, the interference into the US elections that we will discuss below. We argue that the low interference value, combined with additional costs created by PCIs that Sweden established prior to its elections, deterred Russia from interfering into the 2018 Swedish elections.\nIn addition to the PCIs outlined in the introduction, there are many others that the Swedish government established in order to raise the cost of election interference. Here are just a few examples. The government reiterated the protection of democracy as one of the country's top security objectives and designated its election systems as critical infrastructure. It tasked the Civil Contingencies Agency (MSB) and the Security Services and the Election Authority with coordinating election protection and made MSB responsible for countering Russian disinformation. Most importantly, Sweden's Prime Minister Stefan Lofven emphasized the country's military offensive cybercapability and the government's willingness to use it. When discussing a three-point plan to stop foreign powers from influencing the 2018 Swedish elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities (SverigesRadio 2017). Some might argue that factors other than PCIs deterred Russia. First is NATO's military capabilities. The NATO-Sweden cooperation defense pact that prioritizes security in the Baltic Sea region protects Sweden from a physical invasion by Russia (akin to those in Ukraine and Georgia) but not from election interference. Second is the threat of Western economic sanctions. The ineffectiveness of these sanctions in changing Moscow's behavior in Ukraine and Syria suggest that they are unlikely to have deterred the Kremlin from executing its plan. Third is Russia's lack of interest in interfering. While the interference value was low, preparatory influence operations aimed at undermining the 2018 Swedish elections demonstrate that the interest was, in fact, present (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018). Having ruled out the above factors, we have further evidence that Sweden's PCIs, put in place before elections, raised the cost of a potential election interference campaign and deterred Russia from interfering into the 2018 Swedish elections.\n# 2017 GERMAN FEDERAL ELECTION: DISINTERESTED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 German federal election provides support for the equilibrium in which the defender's PCIs have no effect on the challenger because the challenger is\n\ndisinterested—the interference value is already so low that the challenger has no interest in interfering in the elections (Region IV in figure 2). We argue that German PCIs had no effect on Russia's decision to stay away from the 2017 German federal election. Instead, a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place.\nThe history of COs and information operations attributed to the Kremlin a few years prior to the election demonstrate that the Russian state had interest in German election interference. Information operations started in 2013, when three key German-language Kremlin-linked propaganda outlets—Sputnik Deutsch, RT Deutsch, and NewsFront Deutsch—entered the German market and were later joined by trolls and bots. The 2015 and 2016 COs against the parliament and political parties demonstrate that Moscow was also eager to obtain sensitive information for potential future use. But the value of an effective influence campaign were overwhelmed by potential costs resulting from the following factors.\nFirst, Germany's balanced media systems, the lack of polarization among the German public, Germany's multiparty and proportional system, and a \"gentleman's agreement\" between major political parties not to use any information leaked as a result of cyberattacks made it difficult for Moscow to sow confusion in the public. (Schwirtz 2017). Second, the only clear beneficiary of these campaigns was the Alliance for Germany (AfD)—the rest of parties supported the sanction regime against Moscow. But when AfD entered the race, they only had between eight and ten percent of vote, which was not enough to gain the majority. Third, the use of old-fashioned paper ballots on the local level afforded Germany with an accurate recount in the event that digitized votes used on the federal level were compromised. Lastly, high-level deterrent rhetoric by German politicians referencing a deterioration of the relationship between the two countries if interference occurred likely played a part. Although Putin and Merkel's relationship has eroded over time, alienating Germany—an important bridge between the West and Russia—was not in Russia's interest.\nIf not these factors, what other factors could have stopped Russia from election interference? Brattberg and Maurer (2018) and Schwirtz (2017) suggest that a failure to influence the 2017 French presidential elections made the Kremlin re-think its approach, since it lost the element of surprise. While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives (Galante and EE 2018).\n## 2017 FRENCH ELECTION: UNDETERRED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 French elections provide an illustrative example for the equilibrium in which the defender's PCIs have no effect on the challenger because it is undeterred—the interference value significantly outweighs its costs (Region I in Figure 2). Given this high value, we argue that the Russian government was like an unstoppable tank moving towards its\ntarget and no French PCIs could have stopped the Kremlin from executing its plan.\nWhat was the value from interfering into the 2017 French elections? The lowest value was undermining faith in the democratic process whereas the highest value was electing a pro-Kremlin candidate that could have resulted in a change in French foreign policy. We argue that even the lowest value of the interference campaign was far greater than any costs Russia could envision paying.\nIf caught, Moscow knew that it faced potential (cyber and non-cyber) retaliation. Diplomatic retaliation was the least of Russia's worries considering some existing tension between the two countries. Moscow expected that, if elected, Emmanuel Macron—as the only unequivocal critic of Putin's Russia out of all presidential candidates—would only exacerbate this tension. The cost of additional economic sanctions—in addition to those that the country already faced for the Ukrainian conflict—was marginal. Nuclear and military responses to COs and information operations were off the table.\nGiven these rather low costs from non-cyber foreign policy options, what additional cyber costs could have Russia anticipated? French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations (Brattberg and Maurer 2018). Deterrence by punishment was unlikely to work either. Even if Paris targeted Russia's critical infrastructure (even though it is quite unlikely), the damage that Russia experienced would have been limited. For example, it is impossible to hack Russia's entire power grid system at once because most stations are manually controlled and can be restored by flipping a switch. Similarly, Paris was unlikely to attempt information operations because of the Kremlin's tight control of Russia's print, online, and social media and because of Russia's treatment of information as a weapon, allowing its military to respond to such information threats (Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space 2011).\nIn short, the potential worst-case scenario costs that Moscow faced were lower than the value it would gain by election interference. Thus, the Kremlin's interference campaign was never going to be deterred by French PCIs.\n## Discussion and Implications\nAs scholars and policymakers continue debating cyber deterrence using COs, attribution, and non-cyber threats, we explore the feasibility of cyber deterrence using means that have been largely overlooked by the international relations literature—public cyberinstitutions which signal organizational capacity to produce and use cybercapability to achieve strategic objectives.\nOur main contribution is to identify the precise conditions under which PCIs can deter strategic cyberattacks, which cause significant damage to a country's economy and security. Since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though different types attacks are deterred by different types of PCIs, the results do not change. Specifically, we reveal several important patterns of the strategic use of PCIs to deter challengers that differ by type. PCIs have no effect on disinterested challengers because they have no interest in attacking the defender and undeterred challengers because they have decided to attack even before observing the defender's PCIs. Both scenarios demonstrate that states are wasting their resources if they\n A troll is someone who argues for extreme views without credible sources.\n An automated program that runs over the Internet.\n During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).\nNADIYA KOSTYUK\n\nPCIs, however, can deter opportunistic challengers that only attack defenders that they perceive as cyber weak and avoid attacking those defenders that they perceive as cyber strong. To deter opportunistic challengers, weak cyber nations might choose to over-invest their limited resources into PCIs to appear strong. Strong cyber nations, in their turn, over-invest their limited resources into PCIs to distinguish themselves from weak cyber nations pretending to be cyber strong. This sub-optimal resource allocation, which makes the defender weaker in its overall cybercapacity, is worthwhile for weak cyber nations because it deters opportunistic challengers. These results have important theoretical and policy implications.\nOur findings shed light on a theoretical debate surrounding cyber deterrence (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). Similar to Tor (2017), this article stresses the need to re-think our reference to absolute nuclear deterrence as a matrix of deterrence success for cyberoperations. Countries do not create cybercapacity to deter low-level COs; instead, their goal is to stop adversaries from executing strategic cyberattacks, which can cause detrimental damage to the country's economy, prosperity, and security.\nWhat constitutes strategic cyberattacks, however, continues to evolve with changes in global cyberthreat landscape; countries only focused on critical infrastructure protection less than a decade ago and added election protection to their top national security priorities following the 2016 US elections. As countries re-define what constitutes strategic cyberattacks, adversaries find more creative ways to achieve their strategic goals using cyber means that operate below the strategic cyberattack threshold. For example, in response to Russia's meddling in the 2016 US elections, the US government took significant steps to protect its 2018 elections. In response to this stern measure, Russian bots and trolls adjusted their behavior and started operating during the election off-season. These influence campaigns, even if conducted during election off-seasons, shape public opinion and might affect public voting behavior. Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace (Murray and Mansoor 2012).\nOur results also show that states should take the signaling of cybercapacity via PCIs with a grain of salt. While PCIs serve as a cyberthreat assessment barometer because they allow a challenger to estimate a defender's ability to conduct COs, the defender's willingness to use these operations, and the scope of the defender's potential retaliation, this assessment is not precise. To better estimate the defender's cybercapacity, challengers should also examine other indicators, such as economic and technological achievements and the defender's reliance on the private sector for cybercapacity. This cumulative approach used to estimate cybercapacity will help governments better evaluate options that minimize the risk of escalation.\nFurthermore, our results speak to the scholarship in international relations theory that focuses on deterrence.[23] Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence.[24] We show that the challenger's\nchoice to cyberattack the defender is independent of the defender's PCIs in two equilibria. In the first one, the challenger has no interest in attacking the defender, giving a false impression of deterrence success. In the second one, the challenger has already decided to attack the defender, despite its PCIs, giving a false impression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios (Danilovic 2002; Snyder 1977). Before concluding the ineffectiveness of PCIs or other means of deterrence, researchers and policy-makers should consider these variables in their estimations. Moreover, since our model is limited to states that have limited cyber arsenals and are not able to burn their exploits to send deterrent signals, we expect to see more investment in PCIs among relatively weaker cyber nations or middle powers. But as more nations invest in PCIs, this deterrent approach might be less effective.\nWhile we take the first stab at understanding deterrence by PCIs, future research should further investigate this important mechanism. Here, we highlight a few venues that future research could explore. First, our model oversimplifies real-world scenarios by making assumptions to identify the causal effect of PCIs on deterrence chances. We view the challenger's choice to attack and the defender's choice to establish PCIs as a one-time decision. In practice, PCIs present a state's cumulative effort to boost its cybercapacity. Similarly, cyber and influence campaigns are composed of many, often low-level activities that span an extended period. Future research should explore how much updating-of-beliefs takes place during different stages of strategic cyberattacks and a state's cumulative efforts to build PCIs. Second, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities (Schneider 2019). Future iterations of this model should explore scenarios when it is not the case. For instance, when PCIs only signal an increase in offensive cybercapability, the threat of cyber retaliation might not deter a country that does not have many cyber targets, like North Korea. PCIs that only signal an increase in cyber defenses might deter countries that view attacking well-protected targets as too costly.\nThird, our model does not distinguish the defender by regime type. Democratic leaders are more transparent, responsive to constituents, and willing to provide public goods in the form of security to satisfy voters and secure their reelection (De Mesquita 2005). While autocracies might be less likely to create PCIs because they face a lesser demand to respond to their domestic audience, they, in fact, might be more likely to exaggerate their PCIs because of this lesser demand. Future research should investigate how these tendencies among different regime types affect model equilibria.\nAs Schelling (2008, 44) puts it, \"If deterrence fails, it is usually because someone thought he saw an 'option' that the... government had failed to dispose of, a loophole that it hadn't closed against itself.\" By building cybercapabilities, governments seem to assume that these capabilities alone have a deterrent effect. As my model demonstrates, successful deterrence depends on a defender's cybercapacity, its willingness to use it, and a challenger's type. Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or\n[23] For an overview of this scholarship, see Lupovici (2010).\n[24] We can describe undeterred challengers as resolute, opportunistic challengers as semi-resolute, and disinterested challengers as resolute.\n\nChina. In these cases, states might perceive potential consequences of entering an escalation cycle with such adversaries as too great to risk. To maximize the desired deterrent effect of publicly flexing their cyber muscles, nations' strategies should demonstrate their willingness to hold assets at risk and face consequences in cases of escalation. Only then, states will be able to close some of the loopholes that adversaries can exploit. Until that is done, the pessimistic view of cyber deterrence will persist.\n## Funding\nNadiya Kostyuk's work was partially supported by the William and Flora Hewlett Foundation under grant 2018-7727."
    },
    "numeric": {
      "total": {
        "intext_total": 17,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [
        {
          "index": "12",
          "intext_citation": "[12]",
          "preceding_text": "Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.",
          "footnote": null
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA.",
          "footnote": null
        },
        {
          "index": "14",
          "intext_citation": "[14]",
          "preceding_text": "Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.",
          "footnote": null
        },
        {
          "index": "12",
          "intext_citation": "[12]",
          "preceding_text": "Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.[14] The",
          "footnote": null
        },
        {
          "index": "13",
          "intext_citation": "[13]",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "14",
          "intext_citation": "[14]",
          "preceding_text": "[13] Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.",
          "footnote": null
        },
        {
          "index": "15",
          "intext_citation": "[15]",
          "preceding_text": "If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.",
          "footnote": null
        },
        {
          "index": "16",
          "intext_citation": "[16]",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "17",
          "intext_citation": "[17]",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "16",
          "intext_citation": "[16]",
          "preceding_text": "Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In",
          "footnote": null
        },
        {
          "index": "17",
          "intext_citation": "[17]",
          "preceding_text": "",
          "footnote": null
        },
        {
          "index": "18",
          "intext_citation": "[18]",
          "preceding_text": "Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks",
          "footnote": null
        },
        {
          "index": "19",
          "intext_citation": "[19]",
          "preceding_text": "Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks[18] against Swedish news sites and a disinformation campaign about NATO in the Swedish media.",
          "footnote": null
        },
        {
          "index": "23",
          "intext_citation": "[23]",
          "preceding_text": "Furthermore, our results speak to the scholarship in international relations theory that focuses on deterrence.",
          "footnote": null
        },
        {
          "index": "24",
          "intext_citation": "[24]",
          "preceding_text": "rship in international relations theory that focuses on deterrence.[23] Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence.",
          "footnote": null
        },
        {
          "index": "23",
          "intext_citation": "[23]",
          "preceding_text": "Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or",
          "footnote": null
        },
        {
          "index": "24",
          "intext_citation": "[24]",
          "preceding_text": "",
          "footnote": null
        }
      ],
      "flat_text": "International Studies Quarterly (2021) 65, 1151-1162\n# Deterrence in the Cyber Realm: Public versus Private Cyber Capacity\nNADIYA KOSTYUK\nSchool of Public Policy, Georgia Institute of Technology, USA\nCan cyber deterrence work? Existing scholarly works argue that deterrence by punishment using cyberattacks is ineffective because the difficulty of attributing the origin of cyberattacks makes the threat of future attacks less credible. However, these works have told us relatively little about the deterrence ability of public cyberinstitutions (PCIs), defined as publicly observable proactive efforts aimed at signaling a country's level of cyber offensive and defensive capability. This research shows that middle powers (that have scarce cyber arsenals) can use PCIs to deter cyber attacks that cause significant damage to their economy and prosperity; however, this deterrent capability is rather limited. Using an incomplete-information model, we demonstrate that PCIs only deter adversaries that are susceptible to the costs created by these institutions. Despite this limited deterrence ability, middle powers tend to over-invest resources in these cyberinstitutions: Weak cyber states tend to over-invest to convince strong cyber adversaries that they are strong, whereas strong cyber states over-invest so that adversaries do not believe that they are weak states pretending to be strong. By doing so, states reduce their overall cybercapacity. We establish the empirical plausibility of these results using election interference campaigns as examples of strategic attacks. Our focus on the strategic use of PCIs as a deterrent represents a departure from existing literature—which has focused only on cyberoperations—and has important policy implications.\nPuede funcionar la ciberdisuasión? Los trabajos académicos existentes sostienen que la disuasión mediante el castigo de los ciberataques es ineficaz porque la dificultad de atribuir el origen de los ciberataques hace menos creíble la amenaza de futuros ataques. Sin embargo, estos trabajos nos han aportado relativamente poco sobre la capacidad de disuasión de las ciberinstituciones públicas (Public Cyberinstitutions, PCI), definidas como esfuerzos proactivos públicamente observables destinados a señalar el nivel de capacidad ciberofensiva y defensiva de un país. Esta investigación muestra que las potencias medias (que disponen de escasos arsenales cibernéticos) pueden utilizar las PCI para disuadir los ciberataques que causan un daño importante a su economía y prosperidad; pero esta capacidad de disuasión es bastante limitada. Mediante un modelo de información incompleta, demostramos que las PCI solo disuaden a los adversarios que son susceptibles a los costos creados por estas instituciones. A pesar de esta limitada capacidad de disuasión, las potencias intermedias tienden a invertir en exceso sus recursos en estas instituciones cibernéticas: los ciberestados vulnerables tienden a invertir en exceso para convencer a los ciberadversarios fuertes de que son fuertes, mientras que los ciberestados fuertes invierten en exceso para que los adversarios no crean que son estados vulnerables que fingen ser poderosos. Al hacerlo, los estados reducen su cibercapacidad general. Determinamos la credibilidad empírica de estos resultados utilizando campañas de interferencia electoral como ejemplos de ataques estratégicos. Nuestro enfoque en el uso estratégico de las PCI como elemento de disuasión representa un cambio respecto a la literatura existente, que se ha centrado únicamente en las ciberoperaciones, y tiene importantes implicaciones políticas.\nLa cyber-dissuasion peut-elle fonctionner? Les travaux de recherche existants soutiennent que la dissuasion par une sanction reposant sur des cyber-attaques est inefficace car la difficulté de détermination de l'origine des cyber-attaques rend la menace de futures attaques moins crédible. Toutefois, ces travaux ne nous ont donné que relativement peu d'informations sur la capacité de dissuasion des cyber-institutions publiques, qui est définie comme étant constituée des efforts proactifs publiquement observables visant à signaler le niveau des cyber-capacités offensives et défensives d'un pays. Cette recherche montre que les puissances intermédiaires (qui disposent de cyber-arsenaux limités) peuvent avoir recours aux cyber-institutions publiques pour dissuader les auteurs de cyber-attaques nuisant considérablement à leur économie et à leur prospérité, mais cette capacité de dissuasion est plutôt limitée. Nous nous appuyons sur un modèle d'information incomplète et nous démontrons que les cyber-institutions publiques ne dissuadent que les adversaires qui sont sensibles aux coûts engendrés par ces institutions. Malgré cette capacité de dissuasion limitée, les puissances intermédiaires tendent à surinvestir des ressources dans ces cyber-institutions : les cyber-États faibles tendent en effet à surinvestir pour convaincre leurs puissants cyber-adversaires qu'ils sont forts, tandis que les cyber-États forts tendent à le faire afin que leurs adversaires ne croient pas qu'ils sont faibles alors qu'ils se prétendent forts. Ce faisant, les États réduisent leur cyber-capacité globale. Nous établissons la plausibilité empirique de ces résultats en nous basant sur les campagnes d'ingérence électorale comme exemples d'attaques stratégiques. Notre concentration sur l'utilisation stratégique des cyber-institutions publiques comme dissuasion diverge de la littérature existante qui s'est uniquement concentrée sur les cyber-opérations et a d'importantes implications politiques.\n\"To those thinking about trying to influence the outcome of the elections in our country: Stay away!\" (as quoted in Cederberg 2018, 11). Sweden's Prime Minister Stefan Löfven articulated this warning and the country's willingness to act in the event of election interference at a security conference in January 2018. The Swedish government\nNadiya Kostyuk is an Assistant Professor, School of Public Policy, Georgia Institute of Technology.\nAuthor's note: I would like to thank Erica Borghard, Aaron Brantly, Ben Buchanan, John Ciorciari, Fiona Cunningham, Tiberiu Dragu, Mathias Frendem, Andres Gannon, Erik Gartzke, John Leahy, Susan Landau, Herb Lin, Jon Lindsay, Shawn Lonergan, Carla Martinez Machain, Tamar Mitts, James D. Morrow, Jacquelyn Schneider, Jeffrey W. Taliaferro, Brandon Valeriano, Ketian Zhang, Yuri M. Zhukov, and the participants of the Peace and Science Society International pre-conference workshop, of the Student Cybersecurity Symposium at Tufts University, of the International Security Seminar at the Belfer Center for Science and Technology at Harvard Kennedy School, of the Peace Science OPSC, and of the Cybersecurity Series at the Stanford Center for International Security and Cooperation. This paper was presented at the 2019 International Studies Association Conference.\nKostyuk, Nadiya (2021) Deterrence in the Cyber Realm: Public versus Private Cyber Capacity. International Studies Quarterly, doi: 10.1093/isq/sqab039\n© The Author(s) (2021). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com\nDeterrence in the Cyber Realm\nsubstantiated this rather bold statement with a number of measures meant to deter potential intruders. Specifically, in preparation to its September 2018 election, the country created a number of public cyberinstitutions (PCIs)—publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities.\nSome of these measures aimed at creating better cyber defenses to “raise the threshold [of] attacking Sweden” (National Cybersecurity Policy 2017, 19). Specifically, the government increased the budgets of existing agencies to include election protection into their scope, and it established new agencies, forums, and programs to protect against election interference and disinformation campaigns. For instance, the Swedish government’s crisis preparation and response agency became the main authority for election coordination. The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’” (SverigesRadio 2017). Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats (Cederberg 2018). Media, political parties, and schools ran similar education campaigns. To prepare for total defense awareness, including cases of cyber emergencies, MSB also sent a pamphlet titled “If Crisis or War Comes” to all 4.7 million households.\nIn addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats (Rettman and Kirk 2018). The National Defense Radio Establishment and the Military Intelligence and Security Service installed special detection and warning systems to guard against foreign powers hacking into sensitive agencies. The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators” (O’Dwyer 2018).\nWe argue that these PCIs established by the Swedish government in order to protect its 2018 elections convinced the Russian government that an interference campaign would have been too costly. Why were PCIs successful in deterring a potential interference campaign? Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy (Fernandino 2018)—under what conditions can PCIs deter any strategic cyberattack?\nTo answer these questions, we develop an incomplete-information model in which a challenger considers attacking a defender. The defender in this case is a middle power, since these nations have scarce cyber arsenals and are more likely to invest in PCIs for deterrence. The challenger is not certain about the defender’s cybercapacity—how cyber “strong” or “weak” it is—and can only infer it from the defender’s observable PCIs. Thus, the challenger’s decision to attack depends on the defender’s type, and the defender has an incentive to over-invest in public cybercapacity in order to signal that it is stronger that it actually is.\nThis model leads to several insights. First, there is a large number of equilibria for which PCIs have no influence on the challenger. Second, we show that the defender’s strategic use of PCIs to deter the challenger works only when two conditions are met: (1) the challenger believes that the defender possesses significant cybercapabilities and that it would therefore be too costly to attack the defender; and (2) the challenger is susceptible to the cost exacted by PCIs. This finding shows that PCIs influence the challenger’s decision to attack only in limited cases. Despite that, weaker defenders over-invest in PCIs to signal higher cybercapacity than they possess, and strong defenders over-invest so that their adversaries do not believe that they are weak states pretending to be strong.\nThis paper makes a number of theoretical contributions to the existing international-relations literature. First, it helps us better understand the nature of deterrence in the information age. Our unique strategic logic of PCIs as a proxy for a country’s cybercapacity represents a departure from existing literature. While most scholarly works on cyber-to-cyber deterrence focuses on deterrence by punishment using cyberoperations (Baliga, de Mesquita, and Wolitzky 2020; Valeriano, Jensen, and Maness 2018), this project presents a new theory that explains how PCIs can deter by both prevention and by threat of punishment, by signaling an increase in both defensive and offensive cybercapabilities. This project also contributes to the literature on cross-domain deterrence (Gartzke and Lindsay 2019) by explaining situations in which countries use PCIs to deter their adversaries instead of non-cyber foreign policy options (i.e., economic sanctions, or diplomatic or military responses) that are ineffective and/or costly.\nSecond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). We, instead, seek to explain the strategic behavior of weaker cyber states or middle powers that suspect a cyberattack. In these situations, middle powers often must rely on their own cybercapabilities because their allies are unlikely to help. Cyberdefenses are unique to each country and not easily transferable; close allies are often reluctant to disclose information about their offensive cybercapabilities and/or commit cyberattacks on an ally’s behalf (as compared with their willingness to offer military assistance during territorial invasions).\nThe literature on the “bargaining model of war” focuses on how private information and incentives to misrepresent, and commitment problems affected by power shifts, explain costly armed conflict (e.g., Schultz 1998; Slantchev 2003, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power (Morrow 1989); states also tend to keep certain capabilities secret to obtain military advantage (Reiter 2003).\nWhat is new about our model then? First, a different theoretical foundation drives how nations signal their cybercapacities. Unlike in the case of military capacity, a state cannot launch a parade to signal its cybercapacity. Satellite images are also unlikely to be useful to adversaries seeking to estimate a state’s cyberstrength. An executed cyberattack may provide a target with a good estimate of the attacker’s capabilities, but such an attack de-values capability because it provides the target with instructions on how to fix flaws in their own networks and systems. The time-limited life-span and the dynamic nature of cyberoperations further complicate their signaling potential. While the basic parameters for most traditional weapons remain relatively static,\n1 In addition to election interference campaigns, attacks against critical infrastructure are other examples of strategic cyberattacks.\n2 Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by “burning” their covert cybercapabilities to demonstrate their ability to acquire such capabilities.\nNADIYA KOSTYUK\n1153\nstrategically relevant features of certain cyberweapons might look quite different tomorrow. Signaling cybercapacity via PCIs, on the other hand, (1) preserves the value of a state's cyberoperations, which diminishes after use; (2) signals organizational capability that is not about specific secret vulnerabilities, which are ephemeral and easily compromised, but the ability to readily produce and use those vulnerabilities in complex operations for political ends; and (3) provides the adversary with an immediate, often rough proxy for the state's cybercapacity.\nSecond, existing models focus only on whether and how investment in military capacity can deter a future attack or affect the likelihood of winning a war. Our theoretical foundation instead explains that sources of state cybercapacity are more diverse, lie beyond military and government, and extend to a state's private sector and even public-opinion management. While investing in military cybercapacity is important for deterrence by the threat of punishment, to deter adversaries by prevention, states might, for example, invest significant resources into building public awareness about the danger of cyberoperations and information operations, making potential election-interference campaigns harder.\nRegarding the model, the closest work, which focuses on the relative impact of scarce resource allocation on the likelihood of attack, is Arena and Wolford (2012). Unlike Arena and Wolford (2012), which examines a state's decision to allocate its resources between armaments and intelligence gathering capabilities in order to reduce uncertainty over its opponent's military strength, our model explores a state's decision to allocate its resources between public and private cybercapacity in order to deter its strong opponent from executing a cyberattack against the state. Similarly to works on counter-terrorism policies (Bueno de Mesquita 2007; Dragu 2011), our model explains why nations over-invest in public capacity and that such policies are generally ineffective in deterring adversaries.\nBaliga, de Mesquita, and Wolitzky (2020) and Welburn, Grana, and Schwindt (2019) are the only two other models that focus on cyberdeterrence; they explore how a state's inability to correctly attribute the origin of cyber operations and to detect cyberattacks affects the state's chances of deterring potential attackers. Unlike these models, our model focuses on organizational capability which signals the state's ability to readily produce and use covert cybercapacity. Unlike Baliga, de Mesquita, and Wolitzky (2020)'s model, in which there is uncertainty over the signal's sender (i.e., the attacker's identity) while the signal's quality (i.e., the strength of cybercapacity) is clear, our model investigates situations in which the signal's sender is known but the signal's quality is unclear. Unlike Welburn, Grana, and Schwindt (2019)'s model, in which a defender can signal any cybercapability with no cost, our model explains how the defender's choice to allocate its limited resources translates into observable cybercapacity.\nThe paper proceeds as follows. We start with explaining how a state can signal its cybercapacity. Then, we explain when and how public cyberinstitutions can deter strategic cyberattacks. Next, we introduce the model and derive the model equilibria. We use illustrative examples from elections to establish the empirical plausibility of our theory. We conclude with a discussion of our study's implications.\n## Signaling Cybercapacity\nStates can signal their cybercapability by (1) attributing cyber operations (COs) to attackers; (2) executing COs against adversaries; and (3) establishing public cyberinstitutions—publicly observable efforts aimed at demonstrating a country's level of offensive and defensive cybercapability. Each of these methods has its pros and cons.\nSignaling cybercapacity via attribution is a recent trend, as demonstrated by the number of US indictments. Attribution is a powerful deterrent because it signals to both the attacker and future perpetrators that they are not as invisible as they would like to be in cyberspace. But cyber attribution is difficult and costly: Not only does cyber attribution require significant resources and technical expertise to correctly attribute an attack to a specific computer, but it also demands intelligence to connect the used computer to a perpetrator. Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources (Clark and Landau 2011; Egloff and Wenger 2019). As a result, only a few nations have the resources, technical expertise, and political will to use attribution as a way to signal their cybercapability.\nSignaling cybercapacity via covert COs provides the target with an accurate estimate of the attacker's capability. However, the difficulty of attributing the origin of COs and the time it takes to do so diminish the signal's value, which is further reduced by the time-limited life-span and the dynamic nature of COs. Moreover, if a victim is not able to attribute the attack or remains quiet about the attack, the signaling value of COs is either zero or quite low. Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons (Gartzke 2013); only a few nations have a large enough cyber arsenal that they can burn some of their exploits for signaling purposes.\nWhile cybercapacity cannot be revealed because it depends on secret access and vulnerabilities, the state can reveal its ability to find such vulnerabilities by establishing PCIs, defined as publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities. PCIs signal an increase in organizational cybercapability, which demonstrates the state's ability to readily produce cybercapability and use cyberoperations for political purposes. As a result, signaling via PCIs provides the state's allies, adversaries, and domestic and international audiences with an immediate, often rough proxy for the state's cybercapacity and preserves the value of the state's covert COs.\nFor simplicity, I distinguish two ways in which a state can establish its PCIs: It can (1) create a new agency program, initiative, doctrine, strategy, or policy to address some aspect of cybersecurity; and/or (2) add new cyber roles to existing agencies or new cyber provisions to existing policies. For instance, to deter election interference campaigns, Sweden established an agency responsible for psychological defense. When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time (Schwirtz 2017).\n5Some of these works include Debs and Monteiro (2014), Fearon (2018), Kydd (2000), Meirowitz and Sartori (2008), and Slantchev (2005).\n4Germany's hack-back strategy is a PCI even though the government does not give any details regarding the scope of this strategy. Since they publicly discussed its development (instead of only privately executing it), we have an idea of the steps that the German government considers adopting in order to deter election interference. If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage (Schwirtz 2017). For instance, in response to the attack against the parliament, the German government could remove servers on which stolen parliament data were located.\n1154\nDeterrence in the Cyber Realm\nEven though these two options differ in how governments created their PCIs, they both might involve a similar set of measures. Specifically, a new agency and a new strategy might require additional budget, stuff, training, and expertise. While PCIs often do not reveal all the details about created cybercapacity, unlike covert cyberactivity they allow an adversary to estimate the scope of the change and the potential resulting increase in the target state's cybercapacity. The Swedish and German actions, for instance, signaled that both countries prioritized spending their resources on building better cyber defensive and offensive capabilities to deter potential election interference campaigns.\nBefore we explain how PCIs can deter adversaries, we would like to clarify that our theory focuses on middle powers—the nations that have scarce cyber arsenals and are more likely to invest in PCIs as a means of deterrence. Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by \"burning\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities.⁵\n## The Theory of Cyber Deterrence\nThe theory presented in this section examines the specific context in which a strong challenger (including cyber powers) contemplates a strategic cyberattack against a defender.⁶\nWhen the challenger considers a cyberattack, he calculates the value he can gain from this attack (e.g., undermining democratic processes, in the case of election interference) and the cost he can incur. There are two types of costs. First is the cost of the defender's potential retaliation (e.g., using economic sanctions, military operations or cyberoperations). Second is the tendency of cyberoperations—unlike military operations—to diminish in value after their first use. A tank, for example, can be successfully deployed many times over many years. Cyberattacks, on the other hand, often lose their effectiveness after their first use, even if the attack fails due to the defender's defenses. In using cyberattacks, the challenger risks the possibility that the defender might be able to develop protection against similar attacks in the future.\nWe argue that, for a challenger to decide to use a cyberattack against a defender, it must believe that the attack's value will outweigh its cost. What can change this cost-benefit calculation? Specifically, what can raise the cost enough to deter the challenger?\nWe assume that the costs from non-cyber foreign policy tools (i.e., diplomatic or military responses, or economic sanctions) will not change the cost-benefit calculation because the challenger has considered them initially. These costs are easy to estimate using the defender's past history and are highly predictable based on the challenger's \"prior beliefs about the defender's willingness\" to use one\n⁵Some anecdotal evidence suggests that even though the US government could not hack back in response to the election, it went into Russian servers and left non-malicious code that had \"U.S. Cyber Command\" in the comments. They did so to signal to the Russians, in a covert way, that they had the ability to strike whenever they wanted.\n⁶I employ the language from the traditional deterrence literature and refer to an adversary as a challenger and a defending state as a defender. The model makes the assumption that the defender attempts to deter her strongest challenger, which is the challenger that can potentially cause the most significant damage. If she is able to deter her strongest challenger, then all her other challengers will be deterred by default. Because the model focuses only on the strong challenger, I have omitted \"strong\" and refer only to a \"challenger\" for the remainder of the paper.\nof these options (Fearon 2002, 6). Moreover, given that the defender's capability in non-cyber foreign policy domains is unlikely to change rapidly, the challenger's estimate of the costs imposed by diplomatic responses and economic sanctions is likely to be fairly accurate. The challenger is also aware that military responses are costly and that the defender is unlikely to launch a military strike in response to information operations or cyberoperations.⁷\nEven though these non-cyber foreign policy tools cannot change the challenger's cost-benefit calculation, the challenger considers the defender's capability in these non-cyber domains when forming its opinion of the defender's cybercapacity. Since nations with significant resources and expertise can build sophisticated cyber weapons (Gartzke 2013), the challenger can accurately conclude that the most powerful military nations have impressive cyber arsenals. While the country's military capability might often be correlated with its cybercapacity, it is not always the case because some nations might choose to purchase cyber weapons from third parties or work with proxy groups to execute attacks on their behalf. Despite that we argue that both the defender's capability in non-cyber and the defender's capability in cyber domains form the challenger's prior belief of the defender's cybercapacity.\nGiven that the challenger is quite certain about the costs associated with non-cyber responses and, as a result, is unlikely to be deterred by them, the defender is left with cyber foreign policy tools to deter the challenger from executing cyberattacks. We argue that cyber foreign policy tools may raise the cost of a cyberattack for the challenger because the challenger remains uncertain about the defender's cybercapacity. Even if the challenger has a rough estimate of the defender's cybercapacity, the dynamic, time-limited nature of cyber tools makes it difficult for the challenger to determine the defender's cybercapacity with precision or certainty. Specifically, while the basic parameters for most traditional weapons remain relatively static, strategically relevant features of certain cyber weapons can change significantly over a short period of time. Moreover, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it (Axelrod and Iliev 2014). We explore this challenger's uncertainty over the defender's cybercapacity as the main mechanism that affects the probability of successful deterrence.⁸ How can the defender signal its cybercapacity\n⁷The Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations (Newman 2019).\n⁸For deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity (Schelling 2008). Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high (Press 2005). Moreover, as earlier explained, many nations cannot afford to \"burn\" their covert cybercapabilities to demonstrate their ability to acquire such capabilities, and those that do send a rather costly signal about their sophisticated cyber arsenal. Furthermore, many countries conduct cyber espionage to observe other countries' cyberattack plans and capabilities. As a result, cyber powers that consider challenging other nations probably know enough about other countries' covert cyber strength to know whether they face another cyber power or not, though they do not necessarily know its precise capabilities. Thus, there is no uncertainty about the capabilities of these cyber powers; instead, this theory explores uncertainty over the capabilities of weaker nations—middle powers—and specifically how cyber \"strong\" or \"weak\" they are. These nations tend to have a rather scarce cyber arsenal and are more likely to invest in PCIs as a means of deterrence. However, the better a challenger's cyber-intelligence, the less uncertainty the challenger has about the defender's cybercapacity.\nNADIYA KOSTYUK\n1155\nso it increases the challenger's uncertainty about the defender's cybercapacity? By attributing COs to the challenger, the defender reveals some of its capabilities, reducing uncertainty about its capacity. Signaling by executing COs against the challenger does not help achieve the desired result either. If COs are correctly attributed to the defender, COs quite accurately signal the defender's cybercapacity, improving the challenger's estimates of the defender's cybercapacity. If COs are incorrectly attributed to a third party or not attributed at all, the defender uselessly burns its exploits without changing the challenger's beliefs about the defender's cybercapacity. Since signaling via attribution and signaling via COs are unlikely to increase the challenger's uncertainty about the defender's cybercapacity, the defender is left with PCIs to deter strategic cyberattacks.⁹\n## Deterrence by PCIs\nPCIs can leave the challenger uncertain about the defender's cybercapacity because they demonstrate the defender's ability to produce cybercapability without revealing any concrete details about this capability. PCIs can deter by prevention and/or by threat of punishment.¹⁰ These two types of deterrence are associated with the two types of costs that PCIs can inflict on the challenger, increasing the cost of its cyberattack. PCIs can deter by prevention because adversaries may infer that their attacks are likely to fail against the defenses implied by a PCI. Firewalls, updated computer software, programs aimed at educating public about cyberthreats, and policies that outline a set of measure to provide better security of critical infrastructure are examples of PCIs that can deter by prevention because they make hacking more difficult. While the challenger can keep using conventional weapons even if a conventional attack fails, the challenger often burns its cyber exploits in the case of an unsuccessful cyberattack. This is because having discovered an attempted hack, the defender can close the existing vulnerability making the future use of this exploit impossible. PCIs can also deter by the threat of punishment; for instance, new military doctrines and units signal the state's ability to use its cyber weapons in response to cyberthreats.\nWe investigate situations in which both deterrence mechanisms are at play for the following two reasons. First, one cyberinstitution can signal both cyber offensive and defensive capability, making it hard to separate deterrence by the threat of punishment from deterrence by prevention. The US Department of Defense Cyber Strategy (2015, 3), for instance, uses deterrence by prevention by specifying the Department of Defense's role in defending its information networks, and it uses the threat of punishment by establishing a Cyber Mission Force to be used to defend the United States against cyberattacks of \"significant consequence\". Second, when facing a strategic cyberthreat, states tend to respond with multiple PCIs and, as a result, implement both types of deterrence at the same time to maximize their chances of success.\nSince PCIs can increase uncertainty about the defender's cybercapacity raising the probability of successful deterrence, the defender might want to invest most, if not all, of its resources into PCIs. But such a strategy takes valuable resources away from covert cyberactivity (CCA) or private cybercapacity, which involves secret development of cybercapabilities and ongoing cyberoperations.¹¹ For instance, a polished strategy document, newly-constructed headquarters, or a new initiative meant to bring public awareness of cyberthreats is a poor substitute for a CCA aimed at penetrating the challenger's electricity grid and preparing for a future attack that could be used for retaliation.\nWe argue that this trade-off between PCIs and CCAs is important. Even though some PCIs involve the development of private cybercapability (e.g., the German's hack-back strategy), such PCIs give a high-level view on what capacity a government develops whereas CCAs remain truly covert and only signal capability after being discovered and correctly attributed. The Stuxnet worm, which the US and Israeli governments developed and deployed in 2005 against an Iranian nuclear enrichment facility, was an example of such a CCA, until it was discovered in 2010. Even though the US government created a number of PCIs between 2005 and 2010 to signal an increase in its cybercapacity, none of them signaled the tremendous potential of the US cybercapability. Only the attributed Stuxnet worm signaled the true scope of the US cyber arsenal. Unlike PCIs, which send an immediate, although often imprecise signal about a state's level of cybercapabilities, the Stuxnet example demonstrates that CCAs send a more accurate signal of a state's cybercapabilities but this signal might be delayed.\nSince an investment in both PCIs and CCAs is important for overall cyber capacity, over-investment in PCIs at the expense of investment in CCAs can make a defender weaker. However, the relationship between the defender's overall cybercapacity and its chances at deterrence is not linear—i.e., an increase in one does not necessarily mean an increase in the other. Therefore, a defender with weak cybercapabilities might strategically invest more in PCIs if such an investment maximizes its chances at deterrence, even if it decreases its overall cybercapacity.\nWe argue that the effectiveness of this deterrent strategy depends on the type of the challenger. Specifically, it only works against a challenger that is susceptible to the costs created by PCIs. We call this challenger opportunistic. During the 2018 Swedish elections, Russia was an example of an opportunistic challenger. Having considered a potential interference campaign, the Kremlin realized that the rather small marginal value from this campaign was not worth the additional potential costs imposed by the improved defenses and offenses that Sweden created in the form of PCIs prior to the elections. But an over-investment in PCIs as a deterrent strategy does not work against an disinterested challenger; such challengers never attack, even if they give the impression that they are considering attacking. During the 2017 German elections, Russia was an example of a disinterested challenger. PCIs put in place prior to the 2017 elections had no\n⁹ It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.\n¹⁰ Given that early scholarly works perpetuated the offense dominance in cyberspace (Choucri 2012; Demchak 2011; Kello 2013), prevention is often seen as somewhat futile as it is nearly impossible to protect all vulnerable targets; thus, preemption may be a more cost-effective tactic. Recent works, however, refute the offense-dominance thesis (Gartzke 2013; Lindsay 2013). While it is easier to find a vulnerability in an adversary's network/system than to defend its own networks/systems from hundreds of possible cyberattacks, Slayton (2017) stresses the importance of looking at the cumulative effort required for building cyber offense or defense. Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\" (Slayton 2017, 74). Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense (Borghard and Lonergan 2017).\n1156\nDeterrence in the Cyber Realm\nFigure 1. Defender’s cybercapacity: (a) relationship between defender’s observed and overall cybercapacity; and (b) relationship between defender’s type and her overall cybercapacity as a function of $I_{\\theta}$. Note: $I$: PCIs that $D$ can develop with $r$ units of resources; $N$: CCAs that $D$ can develop with $r$ units of resources; $I + N$: $D$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}$: the level of PCIs at which $D$’s overall cybercapability is maximized (point Max). Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $\\text{Max}_{S}(\\text{Max}_{W})$).\neffect on Russia’s decision to stay away from these elections because a combination of non-cyber factors shifted Russia’s cost-benefit calculus towards not attacking even before Germany establish its PCIs. Lastly, an over-investment in PCIs is also a waste of resources when the defender faces a undeterred challenger; such challengers always attack because the value of attacking is much higher than any additional costs created by PCIs. During the 2017 French elections, Russia was an example of an undeterred challenger. Having witnessed the worldwide impact of the mass disclosures of private data prior to the 2016 US elections, Moscow was willing to pay any cost and to risk any potential French (cyber or non-) retaliation for its influence campaign, which could help elect a pro-Kremlin candidate.\nThe next section models cyber deterrence by PCIs explicitly. It is worth noting that since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though the type of an attempted attack requires different types of PCIs, this does not affect the model logic and the obtained results.\n## Model\nThis section provides the intuition behind the game and the Online Appendix includes the detailed explanation and mathematical proofs.\n**Game Overview.** This is a game between a challenger ($C$, “he”) and a defender ($D$, “she”). $C$ considers executing a cyberattack against $D$. To deter $C$, $D$ decides how to signal her cybercapacity by allocating her resources between public and private cybercapacity and, as a result, which level of PCIs to implement. $D$ has a type $\\theta \\in [S, W]$ that differs in the amount of resources $a_{\\theta}$ available to her. The strong defender $D_{S}$ has many more resources available to her than the weak defender $D_{W}$. $\\theta$ is unobservable to the challenger.\nThe game starts with Nature’s choice. Nature selects that $\\theta = S$ with probability $\\pi$ and that $\\theta = W$ with probability $1 - \\pi$. The model assumes that both players have a common prior belief and that $\\pi$ is the true probability that the defender is strong. Then $D$ decides how to allocate her resources between PCIs and CCA. After $D$ implements PCIs, $C$ observes it, (possibly) updates his beliefs about $D$’s type, and decides whether he wants to attack $D$. When $C$ chooses whether to attack, $C$ observes $D$’s move but not $D$’s type. If $C$ does not attack, $D_{\\theta}$ successfully deters $C$ and the game\nends. If $C$ decides to attack $D_{\\theta}$, Nature selects that his attack is successful with probability $Q_{\\alpha}$, and unsuccessful with probability $1 - Q_{\\alpha}$. The probability of a successful attack is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. If $C$’s attack succeeds, $D_{\\theta}$ must decide whether to retaliate against $C$. If $D_{\\theta}$ does not retaliate against $C$, the game ends. If $D_{\\theta}$ retaliates against $C$, Nature selects that her retaliation is successful with probability $P_{\\theta}$ and is unsuccessful with probability $1 - P_{\\theta}$. The probability of a successful retaliation is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.\n**Signaling Cyber Capacity.** To understand how $D$ can deter strategic cyberattacks, we must first understand how she can create her cybercapacity because $D$’s cybercapacity is a proxy for $D$’s ability to deter $C$. The higher $D$’s capacity is, the higher the likelihood that $D$ deters $C$. To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA. Both PCIs and CCA create $D$’s overall cybercapability. As mentioned earlier, $D$’s overall cybercapability does not necessarily increase simply by investing more in her PCIs because such a strategy takes valuable resources away from CCA. As a result, it makes $D$ weaker.\nFigure 1(a) explains the intuition of how this works graphically. $C$ has a prior belief of $D$’s cybercapability, given COs attributed to $D$ or using various indicators of $D$’s technological development. Given the public nature of PCIs, $C$ can only observe PCIs and estimate $D$’s cybercapability. We call it $D$’s observed cybercapability and place it on the x-axis in Figure 1(a). The y-axis in Figure 1(a) represents $D$’s overall cybercapability that we receive by adding the resources that $D$ invests into PCIs and CCAs. Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources. The\n We display this two-player game with incomplete information concerning $D$’s type in Online Appendix Section 1.1.\n Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.\n I assume that both $I$ and $N$ are increasing in $r$ and that there are diminishing returns to investment in each (i.e. $I'(r), N'(r) &gt; 0$ and $I''(r), N''(r) &lt; 0$).\nNADIYA KOSTYUK\nFigure 2. Equilibria and challenger's types. Note:  $C$ : a challenger;  $D_W$ : a weak type of the defender;  $D_S$ : a strong type of the defender;  $\\pi$ : a prior probability that  $D$  is strong;  $1 - \\pi$ : a prior probability that  $D$  is weak; and  $\\tilde{I}_S$ : the level of PCIs at which overall cybercapability is maximized for the strong type of the defender. 1:  $C$ 's gains from attacking  $D_S$ , given the probability of this attack is successful; 2:  $C$ 's gains from attacking  $D$ , given that with  $\\pi$  probability he is facing  $D_S$  and with  $1 - \\pi$  probability, he is facing  $D_W$  that pools with  $D_S$  and implements  $\\tilde{I}_S$ ; and 3:  $C$ 's gains from attacking  $D_W$ , given the probability of this attack is successful.\nfunction  $I + N$  stands for  $D$ 's overall cybercapability when the resources are distributed between PCIs and CCAs. We define  $\\tilde{I}$  to be the level of PCIs at which  $D$ 's overall cybercapability is maximized (point Max in Figure 1a).\nBefore  $D$  creates her PCIs, often she already has some existing cybercapabilities. For instance, before the Swedish Civil Contingencies Agency (MSB) became responsible for election protection, it dealt with civil protection; MSB could use these expertise to provide public safety during the time of elections. This existing level of cybercapability determines  $D$ 's type. We distinguish two types of  $D$ -strong  $(D_S)$  and weak  $(D_W)$ .  $D_S$ , depicted by the black line in figure 1(b), has a higher level of existing cybercapability, thus she can implement a higher level of PCIs and have higher chances of deterrence than  $D_W$ , depicted by a gray line in figure 1(b). Similarly,  $\\tilde{I}_S$  and  $\\tilde{I}_W$  are the levels of PCIs at which overall cybercapability is maximized for the defender's weak and strong types, respectively.\nWe assume that the costs of producing public  $(I)$  and private  $(N)$  cybercapacity are the same for the strong and weak type of the defender because we primarily focus on explaining the behavior of middle powers. Some nations that have developed technological expertise in this area—cyber powers, for instance—can develop \"more\" capability for a given budget. In such cases, it might be difficult for other nations to imitate PCIs developed by these cyber powers. For these reasons, our model excludes these powerful nations and primarily focuses on the behavior of middle powers that can imitate each other's behavior in order to deter their challengers.\n# Model Equilibria\nNext we discuss the intuition behind the model equilibria.\nAs explained earlier, the effectiveness of the defender's PCIs on deterring the challenger, depends on the challenger's type. We distinguish three types of the challenger that depend on the three cut-off points depicted in figure 2. If  $C$  is undeterred and always attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region I in figure 2). If  $C$  is disinterested and never attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region IV in figure 2). In these two equilibria,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. Proposition 1 summarizes both equilibria.\nProposition 1. Challenger's decision to attack is independent of defender's PCIs.\n(a) If  $C$  is undeterred and always attacks (Region I in Figure 2),  $D_{0}$  maximizes her cybercapacity and  $C$  always attacks.\n(b) If  $C$  is disinterested and never attacks (Region IV in Figure 2),  $D_0$  maximizes her cybercapacity and  $C$  never attacks.\nIn both equilibria in Proposition 1,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. But what happens if they do? We argue that different types of the defender would invest their resources differently to maximize their chances of deterring adversaries that are susceptible to the costs created by PCIs. Specifically, the strategic use of PCIs to deter  $C$  occurs in the signaling region where there is both the need for and the possibility of deterrence. Here  $D_0$ 's PCIs can influence  $C$ , which will take different actions depending on the defender's true type. Specifically, the challenger will attack the defender if he knows that the defender is weak and will avoid attacking if he knows the defender is strong. We call this challenger opportunistic. In this region, depicted by Regions II and III in Figure 2, there are two pure strategy equilibria (Propositions 2-3) and one mixed strategy equilibrium. We focus on the pure strategy equilibria in the main manuscript and present the mixed equilibria in the Online Appendix.\nIf  $C$  prefers attacking a defender that he thinks is weak and avoiding attacking a defender that he thinks is strong due to the fear of retaliation or attack failure,  $D_W$ 's natural response is to increase her investment into PCIs to appear strong. Specifically, instead of redistributing her resources so that her overall cybercapability achieves its maximum (Max  $W$  in Figure 3 (a)),  $D_W$  distributes them so they are her overall cybercapability is at point A in Figure 3(a). By doing so,  $D_W$  creates the same level of PCIs  $(\\tilde{I}_S)$  as  $D_S$  (i.e.,  $D_W$  pools with  $D_S$ ), so when  $C$  observes these institutions, he concludes that he is dealing with a strong defender and does not attack. Because this deterrent strategy decreases  $D_W$ 's overall cybercapability, by appearing strong,  $D_W$ , in fact, hides her actual weakness. This pooling equilibrium holds only when  $D$ 's gain of appearing strong outweighs  $D$ 's loss to inefficiently allocating her resources and when  $C$ 's prior belief that  $D$  is strong is high. Proposition 2 presents this pooling equilibrium.\n# Proposition 2. Pooling Equilibrium.\nSuppose  $C$  is opportunistic and prefers attacking  $D$  only if he believes that  $D$  is weak. If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.\n1158\nDeterrence in the Cyber Realm\nFigure 3. Defender's pure strategy actions when facing an opportunistic challenger: (a) pooling strategy; and (b) strategic separation strategy. Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$'s overall cybercapability when the resources are distributed between PCIs and CCAs; $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $Max_{S}(Max_{W})$); $\\hat{I}$: the level of PCIs that $D_{W}$ cannot attain; $A$: $D_{W}$ imitates PCIs of $D_{S}$; and $B$: $D_{S}$ strategically separates herself from $D_{W}$ by implementing PCIs that $D_{W}$ cannot implement.\nIf $C$'s prior belief that $D$ is strong is low, then $C$ interprets pooling as weak and attacks if $D$ implements $\\hat{I}_S$ (Region II of figure 2). $D_S$ is aware that $D_W$ is trying to imitate her PCIs and takes one of the two actions. Not wanting to be confused with $D_W$, $D_S$ can alter her behavior to clearly distinguish herself (i.e., separate) from $D_W$ to ensure that $C$ is deterred. Specifically, $D_S$ spends enough resources to reach a level of PCIs that $D_W$ cannot attain—$\\hat{I}$ (point B in Figure 3(b)). Observing $\\hat{I}$, $C$ knows that the defender is strong as $D_W$ could not implement $\\hat{I}$, as Figure 3(b) shows. Since $D_W$ cannot imitate $D_S$ and implement PCIs to reach $\\hat{I}$ in Figure 3(b), $D_W$ implements her optimal strategy $\\hat{I}_W$. Since separation is costly as it reduces $D_S$'s overall capacity, for this equilibrium to hold, $C$ should not attack when he sees $\\hat{I}$ even though he knows that $D_S$'s overall capacity is reduced. Proposition 3 summarizes this separating equilibrium.\n**Proposition 3.** Separating Equilibrium. Suppose $C$ is opportunistic and prefers attacking $D$ only if he believes that $D$ is weak. If $C$'s prior belief that $D$ is strong is low, then (1) $D_S$ implements a level of PCIs that $D_W$ cannot imitate $(\\hat{I} &gt; \\hat{I}_S)$, (2) $D_W$ is not able to pool with $D_S$ and implements $\\hat{I}_W$, and (3) $C$ attacks only when he sees $\\hat{I}_W$.\nAlternatively, $D_{S}$ can decide not to implement PCIs that $D_{W}$ is not able to mimic because this will weaken her overall cybercapacity and invite an attack. In this case, a pure strategy equilibrium does not exist in Region II of Figure 2. But there exists a mixed strategy equilibrium where $D_{W}$ mixes between $\\hat{I}_{W}$ and $\\hat{I}_{S}$ and $C$ is indifferent between attacking and not. The Online Appendix presents this mixed strategy equilibrium.\n## Illustrative Examples of Elections\nThe novelty, secrecy, and sensitivity of the topic of cyber deterrence prevents us from conducting a rigorous empirical test of our findings. Instead, we aim at demonstrating the empirical plausibility of our theory of deterrence of strategic cyberattacks using PCIs. Since our theory is agnostic towards the type of a strategic cyberattack that a\nnation prefers to deter, we use illustrative examples from elections to provide support for our model equilibria.  Specifically, we focus on Kremlin-directed attempts to influence electoral campaigns in Western democracies: the 2016 US elections, the 2017 German elections, and the 2018 Swedish elections. We choose the most similar examples for our comparison (George 2019); they share the same cyber-capable attacker (Russia), have similar targets (Western democracies), use the same methods (cyber and information operations), have the same purpose (election interference), and have similar timeframes (2016–2018). They differ, however, in (1) the stakes involved in each campaign (e.g., a challenger's type); and (2) the level of PCIs that the targets implement (e.g., strong versus weak). As a result, these examples help demonstrate (1) under what conditions the challenger's uncertainty over the defender's cybercapacity increases the probability of successful deterrence; and (2) when this uncertainty has no effect.\nWe focus on the three different illustrative examples because they match the model's scope conditions that must be met if PCIs deter the challenger. First, there must be a difference in how different types of defenders allocate their resources to signal their cybercapacity. As we shortly demonstrate, the Swedish government, a weak cyber nation, prioritized investing in PCIs to appear that it had strong cyber defenses and offenses. Second, the challenger must face uncertainty about the defender's cybercapacity and its type. The time-limited and dynamic nature of COs generally raises uncertainty about cybercapacity, but this uncertainty over the defender's type does not play a role when facing an undeterred or disinterested challenger. But it is important when facing an opportunistic challenger: By investing more of its resources into PCIs, a weak defender can deter the challenger by pretending that it is strong. Uncertain about Sweden's actual cybercapacity, Russia observed the overwhelming number of PCIs that Sweden created prior its 2018 election that are typical of strong types; it is conceivable that based on these observations, the Kremlin chose not to attack. Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In\n This equilibrium relies on the off-the-equilibrium beliefs that the defender is weak \"enough\" if it plays $\\hat{I}_S$.\n We use an illustrative example to provide support only for the pooling equilibrium when the challenger is opportunistic (Region III in figure 2) because it provides the most interesting result by demonstrating when PCIs can, in fact, deter the challenger.\nNADIYA KOSTYUK\nthe elections we are considering, the cost-benefit calculations differ. In the 2018 Swedish elections, the additional costs created by Swedish PCIs outweighed the low value of Russia's interference campaign and deterred Russia from interfering. In the 2017 German elections, the Kremlin did not consider the extra costs created by PCIs because they were irrelevant—a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place. In the 2017 French elections, benefits outweighed the costs.\n# 2018 SWEDISH NATIONAL ELECTIONS: OPPORTUNISTIC CHALLENGER AND POOLING EQUILIBRIUM\nThe 2018 Swedish national elections provide support for the pooling equilibrium in which the weak defender over-invests in PCIs to appear strong and, as a result, deters the opportunistic challenger (Region III in Figure 2). To show that this is the case, we need to demonstrate that the Russian government was opportunistic and additional PCIs that Sweden created prior to the elections changed the Kremlin's cost-benefit calculation of the election interference campaign.\nTo understand how PCIs as a deterrent strategy worked in this case, we first explain why the Kremlin even considered interfering in the Swedish electoral process. Sweden's nonalignment policy has always served as a guarantee of Russia's security. Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO) (Kunz 2015). In response, Russia's Defense Minister Sergei Shoigu described Sweden's involvement in NATO activities as \"worrying\" and added that \"such steps...[were] forcing us to take response measures\" (Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister 2018). Military actions and/or economic sanctions are possible response measures, although to date, Russia has pursued neither of these. The Ukrainian and Syrian conflicts, combined with NATO-Swedish defense cooperation (even if it falls short of collective defense), are most likely responsible for preventing Russia from taking a military approach.\nRussia is, on the other hand, a mastermind of influence campaigns and had been preparing a strong foundation for such a campaign on the Swedish population for some time. Starting in 2014, the Swedish information landscape witnessed an increase in disinformation campaigns, led by trolls, bots, and Kremlin-sponsored media outlets, such as Sputnik International. In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\" (Cederberg 2018, 5) and Sweden remained one of the few \"favorite target[s] of the Kremlin's propaganda machine\" at the beginning of 2018 (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018, 109). Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks against Swedish news sites and a disinformation campaign about NATO in the Swedish media.\nAn anti-immigration sentiment in both the Swedish parliament and the populace bolstered these ongoing COs and information operations. Immigration has always been a contentious issue in Swedish politics, recently exacerbated by the Syrian refugee crisis. Over the last five years, Sweden, a country of 10 million, has welcomed 165,000 asylum-seekers from the Middle East. Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010 (Johnson and Evans 2018). The party's anti-immigration stance and the divide in the general population over the immigration issue presented the perfect environment for the Kremlin's influence campaigns.\nHowever, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference (Cederberg 2018). Why? What stopped Russia from interfering in the Swedish elections?\nLet us look at Russia's cost-benefit calculus. While Sweden had a favorable political climate and Russia had some ongoing COs and information operations, the value of a potential interference campaign was quite low, compared to, for instance, the interference into the US elections that we will discuss below. We argue that the low interference value, combined with additional costs created by PCIs that Sweden established prior to its elections, deterred Russia from interfering into the 2018 Swedish elections.\nIn addition to the PCIs outlined in the introduction, there are many others that the Swedish government established in order to raise the cost of election interference. Here are just a few examples. The government reiterated the protection of democracy as one of the country's top security objectives and designated its election systems as critical infrastructure. It tasked the Civil Contingencies Agency (MSB) and the Security Services and the Election Authority with coordinating election protection and made MSB responsible for countering Russian disinformation. Most importantly, Sweden's Prime Minister Stefan Lofven emphasized the country's military offensive cybercapability and the government's willingness to use it. When discussing a three-point plan to stop foreign powers from influencing the 2018 Swedish elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities (SverigesRadio 2017). Some might argue that factors other than PCIs deterred Russia. First is NATO's military capabilities. The NATO-Sweden cooperation defense pact that prioritizes security in the Baltic Sea region protects Sweden from a physical invasion by Russia (akin to those in Ukraine and Georgia) but not from election interference. Second is the threat of Western economic sanctions. The ineffectiveness of these sanctions in changing Moscow's behavior in Ukraine and Syria suggest that they are unlikely to have deterred the Kremlin from executing its plan. Third is Russia's lack of interest in interfering. While the interference value was low, preparatory influence operations aimed at undermining the 2018 Swedish elections demonstrate that the interest was, in fact, present (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018). Having ruled out the above factors, we have further evidence that Sweden's PCIs, put in place before elections, raised the cost of a potential election interference campaign and deterred Russia from interfering into the 2018 Swedish elections.\n# 2017 GERMAN FEDERAL ELECTION: DISINTERESTED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 German federal election provides support for the equilibrium in which the defender's PCIs have no effect on the challenger because the challenger is\n10 These attacks flood a website with multiple requests, making it crash.\n10 See https://www.documentcloud.org/documents/4627057-16-2517-CKK-2017-09-15-State-Production-3.html.\n1160\nDeterrence in the Cyber Realm\ndisinterested—the interference value is already so low that the challenger has no interest in interfering in the elections (Region IV in figure 2). We argue that German PCIs had no effect on Russia's decision to stay away from the 2017 German federal election. Instead, a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place.\nThe history of COs and information operations attributed to the Kremlin a few years prior to the election demonstrate that the Russian state had interest in German election interference. Information operations started in 2013, when three key German-language Kremlin-linked propaganda outlets—Sputnik Deutsch, RT Deutsch, and NewsFront Deutsch—entered the German market and were later joined by trolls²⁰ and bots.²¹ The 2015 and 2016 COs against the parliament and political parties demonstrate that Moscow was also eager to obtain sensitive information for potential future use. But the value of an effective influence campaign were overwhelmed by potential costs resulting from the following factors.\nFirst, Germany's balanced media systems, the lack of polarization among the German public, Germany's multiparty and proportional system, and a \"gentleman's agreement\" between major political parties not to use any information leaked as a result of cyberattacks made it difficult for Moscow to sow confusion in the public. (Schwirtz 2017). Second, the only clear beneficiary of these campaigns was the Alliance for Germany (AfD)—the rest of parties supported the sanction regime against Moscow. But when AfD entered the race, they only had between eight and ten percent of vote, which was not enough to gain the majority. Third, the use of old-fashioned paper ballots on the local level afforded Germany with an accurate recount in the event that digitized votes used on the federal level were compromised. Lastly, high-level deterrent rhetoric by German politicians referencing a deterioration of the relationship between the two countries if interference occurred likely played a part.²² Although Putin and Merkel's relationship has eroded over time, alienating Germany—an important bridge between the West and Russia—was not in Russia's interest.\nIf not these factors, what other factors could have stopped Russia from election interference? Brattberg and Maurer (2018) and Schwirtz (2017) suggest that a failure to influence the 2017 French presidential elections made the Kremlin re-think its approach, since it lost the element of surprise. While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives (Galante and EE 2018).\n## 2017 FRENCH ELECTION: UNDETERRED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 French elections provide an illustrative example for the equilibrium in which the defender's PCIs have no effect on the challenger because it is undeterred—the interference value significantly outweighs its costs (Region I in Figure 2). Given this high value, we argue that the Russian government was like an unstoppable tank moving towards its\ntarget and no French PCIs could have stopped the Kremlin from executing its plan.\nWhat was the value from interfering into the 2017 French elections? The lowest value was undermining faith in the democratic process whereas the highest value was electing a pro-Kremlin candidate that could have resulted in a change in French foreign policy. We argue that even the lowest value of the interference campaign was far greater than any costs Russia could envision paying.\nIf caught, Moscow knew that it faced potential (cyber and non-cyber) retaliation. Diplomatic retaliation was the least of Russia's worries considering some existing tension between the two countries. Moscow expected that, if elected, Emmanuel Macron—as the only unequivocal critic of Putin's Russia out of all presidential candidates—would only exacerbate this tension. The cost of additional economic sanctions—in addition to those that the country already faced for the Ukrainian conflict—was marginal. Nuclear and military responses to COs and information operations were off the table.\nGiven these rather low costs from non-cyber foreign policy options, what additional cyber costs could have Russia anticipated? French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations (Brattberg and Maurer 2018). Deterrence by punishment was unlikely to work either. Even if Paris targeted Russia's critical infrastructure (even though it is quite unlikely), the damage that Russia experienced would have been limited. For example, it is impossible to hack Russia's entire power grid system at once because most stations are manually controlled and can be restored by flipping a switch. Similarly, Paris was unlikely to attempt information operations because of the Kremlin's tight control of Russia's print, online, and social media and because of Russia's treatment of information as a weapon, allowing its military to respond to such information threats (Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space 2011).\nIn short, the potential worst-case scenario costs that Moscow faced were lower than the value it would gain by election interference. Thus, the Kremlin's interference campaign was never going to be deterred by French PCIs.\n## Discussion and Implications\nAs scholars and policymakers continue debating cyber deterrence using COs, attribution, and non-cyber threats, we explore the feasibility of cyber deterrence using means that have been largely overlooked by the international relations literature—public cyberinstitutions which signal organizational capacity to produce and use cybercapability to achieve strategic objectives.\nOur main contribution is to identify the precise conditions under which PCIs can deter strategic cyberattacks, which cause significant damage to a country's economy and security. Since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though different types attacks are deterred by different types of PCIs, the results do not change. Specifically, we reveal several important patterns of the strategic use of PCIs to deter challengers that differ by type. PCIs have no effect on disinterested challengers because they have no interest in attacking the defender and undeterred challengers because they have decided to attack even before observing the defender's PCIs. Both scenarios demonstrate that states are wasting their resources if they\n²⁰ A troll is someone who argues for extreme views without credible sources.\n²¹ An automated program that runs over the Internet.\n²² During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\" (Beuth et al. 2017); and in June, German President Frank-Walter Steinmeier warned Moscow that \"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\" (as quoted in Brattberg and Maurer 2018, 18).\nNADIYA KOSTYUK\n1161\nuse PCIs as their deterrent strategy against disinterested and undeterred challengers.\nPCIs, however, can deter opportunistic challengers that only attack defenders that they perceive as cyber weak and avoid attacking those defenders that they perceive as cyber strong. To deter opportunistic challengers, weak cyber nations might choose to over-invest their limited resources into PCIs to appear strong. Strong cyber nations, in their turn, over-invest their limited resources into PCIs to distinguish themselves from weak cyber nations pretending to be cyber strong. This sub-optimal resource allocation, which makes the defender weaker in its overall cybercapacity, is worthwhile for weak cyber nations because it deters opportunistic challengers. These results have important theoretical and policy implications.\nOur findings shed light on a theoretical debate surrounding cyber deterrence (Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018). Similar to Tor (2017), this article stresses the need to re-think our reference to absolute nuclear deterrence as a matrix of deterrence success for cyberoperations. Countries do not create cybercapacity to deter low-level COs; instead, their goal is to stop adversaries from executing strategic cyberattacks, which can cause detrimental damage to the country's economy, prosperity, and security.\nWhat constitutes strategic cyberattacks, however, continues to evolve with changes in global cyberthreat landscape; countries only focused on critical infrastructure protection less than a decade ago and added election protection to their top national security priorities following the 2016 US elections. As countries re-define what constitutes strategic cyberattacks, adversaries find more creative ways to achieve their strategic goals using cyber means that operate below the strategic cyberattack threshold. For example, in response to Russia's meddling in the 2016 US elections, the US government took significant steps to protect its 2018 elections. In response to this stern measure, Russian bots and trolls adjusted their behavior and started operating during the election off-season. These influence campaigns, even if conducted during election off-seasons, shape public opinion and might affect public voting behavior. Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace (Murray and Mansoor 2012).\nOur results also show that states should take the signaling of cybercapacity via PCIs with a grain of salt. While PCIs serve as a cyberthreat assessment barometer because they allow a challenger to estimate a defender's ability to conduct COs, the defender's willingness to use these operations, and the scope of the defender's potential retaliation, this assessment is not precise. To better estimate the defender's cybercapacity, challengers should also examine other indicators, such as economic and technological achievements and the defender's reliance on the private sector for cybercapacity. This cumulative approach used to estimate cybercapacity will help governments better evaluate options that minimize the risk of escalation.\nFurthermore, our results speak to the scholarship in international relations theory that focuses on deterrence. Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence. We show that the challenger's\nchoice to cyberattack the defender is independent of the defender's PCIs in two equilibria. In the first one, the challenger has no interest in attacking the defender, giving a false impression of deterrence success. In the second one, the challenger has already decided to attack the defender, despite its PCIs, giving a false impression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios (Danilovic 2002; Snyder 1977). Before concluding the ineffectiveness of PCIs or other means of deterrence, researchers and policy-makers should consider these variables in their estimations. Moreover, since our model is limited to states that have limited cyber arsenals and are not able to burn their exploits to send deterrent signals, we expect to see more investment in PCIs among relatively weaker cyber nations or middle powers. But as more nations invest in PCIs, this deterrent approach might be less effective.\nWhile we take the first stab at understanding deterrence by PCIs, future research should further investigate this important mechanism. Here, we highlight a few venues that future research could explore. First, our model oversimplifies real-world scenarios by making assumptions to identify the causal effect of PCIs on deterrence chances. We view the challenger's choice to attack and the defender's choice to establish PCIs as a one-time decision. In practice, PCIs present a state's cumulative effort to boost its cybercapacity. Similarly, cyber and influence campaigns are composed of many, often low-level activities that span an extended period. Future research should explore how much updating-of-beliefs takes place during different stages of strategic cyberattacks and a state's cumulative efforts to build PCIs. Second, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities (Schneider 2019). Future iterations of this model should explore scenarios when it is not the case. For instance, when PCIs only signal an increase in offensive cybercapability, the threat of cyber retaliation might not deter a country that does not have many cyber targets, like North Korea. PCIs that only signal an increase in cyber defenses might deter countries that view attacking well-protected targets as too costly.\nThird, our model does not distinguish the defender by regime type. Democratic leaders are more transparent, responsive to constituents, and willing to provide public goods in the form of security to satisfy voters and secure their reelection (De Mesquita 2005). While autocracies might be less likely to create PCIs because they face a lesser demand to respond to their domestic audience, they, in fact, might be more likely to exaggerate their PCIs because of this lesser demand. Future research should investigate how these tendencies among different regime types affect model equilibria.\nAs Schelling (2008, 44) puts it, \"If deterrence fails, it is usually because someone thought he saw an 'option' that the... government had failed to dispose of, a loophole that it hadn't closed against itself.\" By building cybercapabilities, governments seem to assume that these capabilities alone have a deterrent effect. As my model demonstrates, successful deterrence depends on a defender's cybercapacity, its willingness to use it, and a challenger's type. Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or\n For an overview of this scholarship, see Lupovici (2010).\n We can describe undeterred challengers as resolute, opportunistic challengers as semi-resolute, and disinterested challengers as resolute.\n1162\nDeterrence in the Cyber Realm\nChina. In these cases, states might perceive potential consequences of entering an escalation cycle with such adversaries as too great to risk. To maximize the desired deterrent effect of publicly flexing their cyber muscles, nations' strategies should demonstrate their willingness to hold assets at risk and face consequences in cases of escalation. Only then, states will be able to close some of the loopholes that adversaries can exploit. Until that is done, the pessimistic view of cyber deterrence will persist.\n## Funding\nNadiya Kostyuk's work was partially supported by the William and Flora Hewlett Foundation under grant 2018-7727."
    },
    "author_year": {
      "total": {
        "intext_total": 37,
        "success_occurrences": 36,
        "success_unique": 27,
        "bib_unique_total": 75,
        "occurrence_match_rate": 0.972972972972973,
        "bib_coverage_rate": 0.36,
        "success_percentage": 97.3,
        "style": "author_year"
      },
      "results": [
        {
          "index": "sverigesradio|2017",
          "intext_citation": "(SverigesRadio 2017)",
          "preceding_text": "The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’”",
          "footnote": "SVERIGES RADIO. 2017. \"Swedish PM Warns of Foreign Influence ahead of 2018 Poll.\" *Radio Sweden*."
        },
        {
          "index": "cederberg|2018",
          "intext_citation": "(Cederberg 2018)",
          "preceding_text": "(SverigesRadio 2017). Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats",
          "footnote": "CEDERBERG, GABRIEL. 2018. *Catching Swedish Phish: How Sweden is Protecting its 2018 Elections*. Cambridge, MA: Defending Digital Democracy Project, Belfer Center for Science and International Security."
        },
        {
          "index": "rettman|2018",
          "intext_citation": "(Rettman and Kirk 2018)",
          "preceding_text": "In addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats",
          "footnote": "RETTMAN, ANDREW, AND LIBBETH KIRK. 2018. \"Sweden Raises Alarm on Election Meddling.\" *EU Observer*."
        },
        {
          "index": "odwyer|2018",
          "intext_citation": "(O’Dwyer 2018)",
          "preceding_text": "The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators”",
          "footnote": "O'Dwyer, GERARD. 2018. \"Sweden Steps up Cyber Defence Measures.\" *ComputerWeekly.com*."
        },
        {
          "index": "fernandino|2018",
          "intext_citation": "(Fernandino 2018)",
          "preceding_text": "Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy",
          "footnote": "FERNANDINO, LISA. 2018. *Cybercom to Elevate to Combatant Command*. Arlington, VA: US Department of Defense."
        },
        {
          "index": "gartzke|2019",
          "intext_citation": "(Gartzke and Lindsay 2019)",
          "preceding_text": "This project also contributes to the literature on cross-domain deterrence",
          "footnote": "GARTZKE, ERIK, AND JON R. LINDSAY. 2019. *Cross-Domain Deterrence: Strategy in an Era of Complexity*. Oxford, UK: Oxford University Press."
        },
        {
          "index": "borghard|2017",
          "intext_citation": "(Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018)",
          "preceding_text": "cond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace",
          "footnote": "BORGHARD, ERICA D., AND SHAWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452-81."
        },
        {
          "index": "morrow|1989",
          "intext_citation": "(Morrow 1989)",
          "preceding_text": "Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power",
          "footnote": "MORROW, JAMES D. 1989. \"Capabilities, Uncertainty, and Resolve: A Limited Information Model of Crisis Bargaining.\" *American Journal of Political Science* 33 (4): 941-72."
        },
        {
          "index": "reiter|2003",
          "intext_citation": "(Reiter 2003)",
          "preceding_text": "3, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power (Morrow 1989); states also tend to keep certain capabilities secret to obtain military advantage",
          "footnote": "REITER, DAN. 2003. \"Exploring the Bargaining Model of War.\" *Perspectives on Politics* 1 (1): 27-43."
        },
        {
          "index": "clark|2011",
          "intext_citation": "(Clark and Landau 2011; Egloff and Wenger 2019)",
          "preceding_text": "Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources",
          "footnote": "CLARK, DAVID D., AND SUSAN LANDAU. 2011. \"Untangling Attribution.\" *Harvard Law School National Security Journal* 2: 323."
        },
        {
          "index": "gartzke|2013",
          "intext_citation": "(Gartzke 2013)",
          "preceding_text": "Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons",
          "footnote": "GARTZKE, ERIK. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace back Down to Earth.\" *International Security* 38 (2): 41-73."
        },
        {
          "index": "schwirtz|2017",
          "intext_citation": "(Schwirtz 2017)",
          "preceding_text": "When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time",
          "footnote": "SCHWIRTZ, MICHAEL. 2017. \"German Election Mystery: Why No Russian Meddling?\" *New York Times*."
        },
        {
          "index": "schwirtz|2017",
          "intext_citation": "(Schwirtz 2017)",
          "preceding_text": "If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage",
          "footnote": "SCHWIRTZ, MICHAEL. 2017. \"German Election Mystery: Why No Russian Meddling?\" *New York Times*."
        },
        {
          "index": "fearon|2002",
          "intext_citation": "(Fearon 2002, 6)",
          "preceding_text": "of these options",
          "footnote": "FEARON, JAMES. 2002. \"Selection Effects and Deterrence.\" *International Interactions* 28 (1): 5-29."
        },
        {
          "index": "gartzke|2013",
          "intext_citation": "(Gartzke 2013)",
          "preceding_text": "Since nations with significant resources and expertise can build sophisticated cyber weapons",
          "footnote": "GARTZKE, ERIK. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace back Down to Earth.\" *International Security* 38 (2): 41-73."
        },
        {
          "index": "axelrod|2014",
          "intext_citation": "(Axelrod and Iliev 2014)",
          "preceding_text": "r, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it",
          "footnote": "AXELROU, ROBERT, AND RUBEN ILIFF. 2014. \"Timing of Cyber Conflict.\" *Proceedings of the National Academy of Sciences* 111 (4): 1298-303."
        },
        {
          "index": "newman|2019",
          "intext_citation": "(Newman 2019)",
          "preceding_text": "⁷The Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations",
          "footnote": "NEWMAN, LILY HAY. 2019. \"What Israel's Strike on Hamas Hackers Means for Cyberwar.\" *Wired*. https://www.wired.com/story/israel-hamas-cyberattack-air-strike-cyberwar/"
        },
        {
          "index": "schelling|2008",
          "intext_citation": "(Schelling 2008)",
          "preceding_text": "⁸For deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity",
          "footnote": "SCHELLING, THOMAS C. 2008. *Arms and Influence: With a New Preface and Afterword*. New Haven, CT: Yale University Press."
        },
        {
          "index": "press|2005",
          "intext_citation": "(Press 2005)",
          "preceding_text": "Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high",
          "footnote": "PRESS, DARIY. GRAYSON. 2005. *Calculating Credibility: How Leaders Assess Military Threats*. Ithaca, NY: Cornell University Press."
        },
        {
          "index": "choucri|2012",
          "intext_citation": "(Choucri 2012; Demchak 2011; Kello 2013)",
          "preceding_text": "¹⁰ Given that early scholarly works perpetuated the offense dominance in cyberspace",
          "footnote": "CHOUCHI, NAZLI., 2012. *Cyberpolitics in International Relations*. Cambridge, MA: MIT Press."
        },
        {
          "index": "gartzke|2013",
          "intext_citation": "(Gartzke 2013; Lindsay 2013)",
          "preceding_text": "Recent works, however, refute the offense-dominance thesis",
          "footnote": "GARTZKE, ERIK. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace back Down to Earth.\" *International Security* 38 (2): 41-73."
        },
        {
          "index": "slayton|2017",
          "intext_citation": "(Slayton 2017, 74)",
          "preceding_text": "Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\"",
          "footnote": null
        },
        {
          "index": "borghard|2017",
          "intext_citation": "(Borghard and Lonergan 2017)",
          "preceding_text": "rs\" (Slayton 2017, 74). Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense",
          "footnote": "BORGHARD, ERICA D., AND SHAWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452-81."
        },
        {
          "index": "george|2019",
          "intext_citation": "(George 2019)",
          "preceding_text": "We choose the most similar examples for our comparison",
          "footnote": "GEORGE, ALEXANDER L. 2019. \"Case Studies and Theory Development: The Method of Structured, Focused Comparison.\" In *Alexander L. George: A Pioneer in Political and Social Sciences*, edited by D. Caldwell, 191-214. New York, NY: Springer."
        },
        {
          "index": "kunz|2015",
          "intext_citation": "(Kunz 2015)",
          "preceding_text": "Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO)",
          "footnote": "KUNZ, BARBARA. 2015. \"Sweden's NATO Workaround: Swedish Security and Defense Policy against the Backdrop of Russian Revisionism.\" *Enote. Focus Strateguque*."
        },
        {
          "index": "cederberg|2018",
          "intext_citation": "(Cederberg 2018, 5)",
          "preceding_text": "In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\"",
          "footnote": "CEDERBERG, GABRIEL. 2018. *Catching Swedish Phish: How Sweden is Protecting its 2018 Elections*. Cambridge, MA: Defending Digital Democracy Project, Belfer Center for Science and International Security."
        },
        {
          "index": "johnson|2018",
          "intext_citation": "(Johnson and Evans 2018)",
          "preceding_text": "Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010",
          "footnote": "JOHNSON, SIMON, AND CATHERINE EVANS. 2018. \"Anti-Immigration Sweden Democrats Poll Record High ahead of September Election.\" *Reuters*."
        },
        {
          "index": "cederberg|2018",
          "intext_citation": "(Cederberg 2018)",
          "preceding_text": "However, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference",
          "footnote": "CEDERBERG, GABRIEL. 2018. *Catching Swedish Phish: How Sweden is Protecting its 2018 Elections*. Cambridge, MA: Defending Digital Democracy Project, Belfer Center for Science and International Security."
        },
        {
          "index": "sverigesradio|2017",
          "intext_citation": "(SverigesRadio 2017)",
          "preceding_text": "h elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities",
          "footnote": "SVERIGES RADIO. 2017. \"Swedish PM Warns of Foreign Influence ahead of 2018 Poll.\" *Radio Sweden*."
        },
        {
          "index": "schwirtz|2017",
          "intext_citation": "(Schwirtz 2017)",
          "preceding_text": "",
          "footnote": "SCHWIRTZ, MICHAEL. 2017. \"German Election Mystery: Why No Russian Meddling?\" *New York Times*."
        },
        {
          "index": "galante|2018",
          "intext_citation": "(Galante and EE 2018)",
          "preceding_text": "While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives",
          "footnote": "GALANTE, LAURA, AND E. E. SHAUN. 2018. *Defining Russian Election Interference: An Analysis of Select 2014 to 2018 Cyber Enabled Incidents*. Washington, DC: Atlantic Council."
        },
        {
          "index": "brattberg|2018",
          "intext_citation": "(Brattberg and Maurer 2018)",
          "preceding_text": "French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations",
          "footnote": "BRATTBERG, ERIK, AND TIM MAURER. 2018. *Russian Election Interference: Europe's Counter to Fake News and Cyber Attacks*. Vol. 23 Carnegie Endowment for International Peace."
        },
        {
          "index": "beuth|2017",
          "intext_citation": "(Beuth et al. 2017)",
          "preceding_text": "²² During its spring 2017 visit to Moscow, the \"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying, \"she assumes 'German parties will be able to decide their election campaign among themselves'\"",
          "footnote": "BEUTH, PATRICK, KAI BIERMANN, MARTIN KLINGST, AND HOLGER STARK. 2017. \"Merkel and the Fancy Bear.\" *ZEIT Online*."
        },
        {
          "index": "borghard|2017",
          "intext_citation": "(Borghard and Lonergan 2017; Gartzke 2013; Nye 2017; Valeriano, Jensen, and Maness 2018)",
          "preceding_text": "Our findings shed light on a theoretical debate surrounding cyber deterrence",
          "footnote": "BORGHARD, ERICA D., AND SHAWN W. LONERGAN. 2017. \"The Logic of Coercion in Cyberspace.\" *Security Studies* 26 (3): 452-81."
        },
        {
          "index": "murray|2012",
          "intext_citation": "(Murray and Mansoor 2012)",
          "preceding_text": "Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace",
          "footnote": "MURRAY, WILLIAMSON, AND PETER R. MANSOOK. 2012. *Hybrid Warfare: Fighting Complex Opponents from the Ancient World to the Present*. Cambridge, UK: Cambridge University Press."
        },
        {
          "index": "danilovic|2002",
          "intext_citation": "(Danilovic 2002; Snyder 1977)",
          "preceding_text": "ression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios",
          "footnote": "DANILOVIC, VESNA. 2002. *When the Stakes Are High: Deterrence and Conflict Among Major Powers*. Ann Arbor, MI: University of Michigan Press."
        },
        {
          "index": "schneider|2019",
          "intext_citation": "(Schneider 2019)",
          "preceding_text": "cond, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities",
          "footnote": "SCHNEIDER, JACQUELYN. 2019. \"Cyber and Cross Domain Deterrence: Deterring within and from Cyberspace.\" In *Cross-Domain Deterrence: Strategy in an Era of Complexity*, edited by LINDSAY, JON R., AND ERIK GARTZKE, chapter 5. Oxford, UK: Oxford University Press."
        }
      ],
      "flat_text": "International Studies Quarterly (2021) 65, 1151-1162 # Deterrence in the Cyber Realm: Public versus Private Cyber Capacity NADIYA KOSTYUK School of Public Policy, Georgia Institute of Technology, USA Can cyber deterrence work? Existing scholarly works argue that deterrence by punishment using cyberattacks is ineffective because the difficulty of attributing the origin of cyberattacks makes the threat of future attacks less credible. However, these works have told us relatively little about the deterrence ability of public cyberinstitutions (PCIs), defined as publicly observable proactive efforts aimed at signaling a country's level of cyber offensive and defensive capability. This research shows that middle powers (that have scarce cyber arsenals) can use PCIs to deter cyber attacks that cause significant damage to their economy and prosperity; however, this deterrent capability is rather limited. Using an incomplete-information model, we demonstrate that PCIs only deter adversaries that are susceptible to the costs created by these institutions. Despite this limited deterrence ability, middle powers tend to over-invest resources in these cyberinstitutions: Weak cyber states tend to over-invest to convince strong cyber adversaries that they are strong, whereas strong cyber states over-invest so that adversaries do not believe that they are weak states pretending to be strong. By doing so, states reduce their overall cybercapacity. We establish the empirical plausibility of these results using election interference campaigns as examples of strategic attacks. Our focus on the strategic use of PCIs as a deterrent represents a departure from existing literature—which has focused only on cyberoperations—and has important policy implications.\nPuede funcionar la ciberdisuasión? Los trabajos académicos existentes sostienen que la disuasión mediante el castigo de los ciberataques es ineficaz porque la dificultad de atribuir el origen de los ciberataques hace menos creíble la amenaza de futuros ataques. Sin embargo, estos trabajos nos han aportado relativamente poco sobre la capacidad de disuasión de las ciberinstituciones públicas (Public Cyberinstitutions, PCI), definidas como esfuerzos proactivos públicamente observables destinados a señalar el nivel de capacidad ciberofensiva y defensiva de un país. Esta investigación muestra que las potencias medias (que disponen de escasos arsenales cibernéticos) pueden utilizar las PCI para disuadir los ciberataques que causan un daño importante a su economía y prosperidad; pero esta capacidad de disuasión es bastante limitada. Mediante un modelo de información incompleta, demostramos que las PCI solo disuaden a los adversarios que son susceptibles a los costos creados por estas instituciones. A pesar de esta limitada capacidad de disuasión, las potencias intermedias tienden a invertir en exceso sus recursos en estas instituciones cibernéticas: los ciberestados vulnerables tienden a invertir en exceso para convencer a los ciberadversarios fuertes de que son fuertes, mientras que los ciberestados fuertes invierten en exceso para que los adversarios no crean que son estados vulnerables que fingen ser poderosos. Al hacerlo, los estados reducen su cibercapacidad general. Determinamos la credibilidad empírica de estos resultados utilizando campañas de interferencia electoral como ejemplos de ataques estratégicos. Nuestro enfoque en el uso estratégico de las PCI como elemento de disuasión representa un cambio respecto a la literatura existente, que se ha centrado únicamente en las ciberoperaciones, y tiene importantes implicaciones políticas.\nLa cyber-dissuasion peut-elle fonctionner? Les travaux de recherche existants soutiennent que la dissuasion par une sanction reposant sur des cyber-attaques est inefficace car la difficulté de détermination de l'origine des cyber-attaques rend la menace de futures attaques moins crédible. Toutefois, ces travaux ne nous ont donné que relativement peu d'informations sur la capacité de dissuasion des cyber-institutions publiques, qui est définie comme étant constituée des efforts proactifs publiquement observables visant à signaler le niveau des cyber-capacités offensives et défensives d'un pays. Cette recherche montre que les puissances intermédiaires (qui disposent de cyber-arsenaux limités) peuvent avoir recours aux cyber-institutions publiques pour dissuader les auteurs de cyber-attaques nuisant considérablement à leur économie et à leur prospérité, mais cette capacité de dissuasion est plutôt limitée. Nous nous appuyons sur un modèle d'information incomplète et nous démontrons que les cyber-institutions publiques ne dissuadent que les adversaires qui sont sensibles aux coûts engendrés par ces institutions. Malgré cette capacité de dissuasion limitée, les puissances intermédiaires tendent à surinvestir des ressources dans ces cyber-institutions: les cyber-États faibles tendent en effet à surinvestir pour convaincre leurs puissants cyber-adversaires qu'ils sont forts, tandis que les cyber-États forts tendent à le faire afin que leurs adversaires ne croient pas qu'ils sont faibles alors qu'ils se prétendent forts. Ce faisant, les États réduisent leur cyber-capacité globale. Nous établissons la plausibilité empirique de ces résultats en nous basant sur les campagnes d'ingérence électorale comme exemples d'attaques stratégiques. Notre concentration sur l'utilisation stratégique des cyber-institutions publiques comme dissuasion diverge de la littérature existante qui s'est uniquement concentrée sur les cyber-opérations et a d'importantes implications politiques.\"To those thinking about trying to influence the outcome of the elections in our country: Stay away!\"(as quoted in Cederberg 2018, 11). Sweden's Prime Minister Stefan Löfven articulated this warning and the country's willingness to act in the event of election interference at a security conference in January 2018. The Swedish government Nadiya Kostyuk is an Assistant Professor, School of Public Policy, Georgia Institute of Technology.\nAuthor's note: I would like to thank Erica Borghard, Aaron Brantly, Ben Buchanan, John Ciorciari, Fiona Cunningham, Tiberiu Dragu, Mathias Frendem, Andres Gannon, Erik Gartzke, John Leahy, Susan Landau, Herb Lin, Jon Lindsay, Shawn Lonergan, Carla Martinez Machain, Tamar Mitts, James D. Morrow, Jacquelyn Schneider, Jeffrey W. Taliaferro, Brandon Valeriano, Ketian Zhang, Yuri M. Zhukov, and the participants of the Peace and Science Society International pre-conference workshop, of the Student Cybersecurity Symposium at Tufts University, of the International Security Seminar at the Belfer Center for Science and Technology at Harvard Kennedy School, of the Peace Science OPSC, and of the Cybersecurity Series at the Stanford Center for International Security and Cooperation. This paper was presented at the 2019 International Studies Association Conference.\nKostyuk, Nadiya (2021) Deterrence in the Cyber Realm: Public versus Private Cyber Capacity. International Studies Quarterly, doi: 10.1093/isq/sqab039 © The Author(s) (2021). Published by Oxford University Press on behalf of the International Studies Association.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oup.com Deterrence in the Cyber Realm substantiated this rather bold statement with a number of measures meant to deter potential intruders. Specifically, in preparation to its September 2018 election, the country created a number of public cyberinstitutions (PCIs)—publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities.\nSome of these measures aimed at creating better cyber defenses to “raise the threshold [of] attacking Sweden” (National Cybersecurity Policy 2017, 19). Specifically, the government increased the budgets of existing agencies to include election protection into their scope, and it established new agencies, forums, and programs to protect against election interference and disinformation campaigns. For instance, the Swedish government’s crisis preparation and response agency became the main authority for election coordination. The Swedish Agency for Public Management became responsible for “coordinating Swedish public agencies which could carry out ‘psychological defense’”. Swedish security services, the Swedish Police Authority, the Election Authority, and Swedish Civil Contingencies Agency (MSB) established a high-level national forum, responsible for briefing election administrators on potential threats. Media, political parties, and schools ran similar education campaigns. To prepare for total defense awareness, including cases of cyber emergencies, MSB also sent a pamphlet titled “If Crisis or War Comes” to all 4.7 million households.\nIn addition to building better defenses, Sweden invested significant resources in improving the cybercapabilities of its intelligence agencies in detecting external threats and of its military forces to respond to such threats. The National Defense Radio Establishment and the Military Intelligence and Security Service installed special detection and warning systems to guard against foreign powers hacking into sensitive agencies. The government also developed “advanced offensive smart technologies and tools that have the capacity to weaponize counter-strike actions against...perpetrators”.\nWe argue that these PCIs established by the Swedish government in order to protect its 2018 elections convinced the Russian government that an interference campaign would have been too costly. Why were PCIs successful in deterring a potential interference campaign? Since election interference campaigns are an example of “strategic” cyberattacks—those that cause significant damage to a country’s prosperity and economy —under what conditions can PCIs deter any strategic cyberattack?\nTo answer these questions, we develop an incomplete-information model in which a challenger considers attacking a defender. The defender in this case is a middle power, since these nations have scarce cyber arsenals and are more likely to invest in PCIs for deterrence. The challenger is not certain about the defender’s cybercapacity—how cyber “strong” or “weak” it is—and can only infer it from the defender’s observable PCIs. Thus, the challenger’s decision to attack depends on the defender’s type, and the defender has an incentive to over-invest in public cybercapacity in order to signal that it is stronger that it actually is.\nThis model leads to several insights. First, there is a large number of equilibria for which PCIs have no influence on the challenger. Second, we show that the defender’s strategic use of PCIs to deter the challenger works only when two conditions are met: (1) the challenger believes that the defender possesses significant cybercapabilities and that it would therefore be too costly to attack the defender; and (2) the challenger is susceptible to the cost exacted by PCIs. This finding shows that PCIs influence the challenger’s decision to attack only in limited cases. Despite that, weaker defenders over-invest in PCIs to signal higher cybercapacity than they possess, and strong defenders over-invest so that their adversaries do not believe that they are weak states pretending to be strong.\nThis paper makes a number of theoretical contributions to the existing international-relations literature. First, it helps us better understand the nature of deterrence in the information age. Our unique strategic logic of PCIs as a proxy for a country’s cybercapacity represents a departure from existing literature. While most scholarly works on cyber-to-cyber deterrence focuses on deterrence by punishment using cyberoperations (Baliga, de Mesquita, and Wolitzky 2020; Valeriano, Jensen, and Maness 2018), this project presents a new theory that explains how PCIs can deter by both prevention and by threat of punishment, by signaling an increase in both defensive and offensive cybercapabilities. This project also contributes to the literature on cross-domain deterrence by explaining situations in which countries use PCIs to deter their adversaries instead of non-cyber foreign policy options (i.e., economic sanctions, or diplomatic or military responses) that are ineffective and/or costly.\nSecond, much of the literature on cyber coercion either focuses on intelligence and policy dilemmas confronting major powers or seeks to adapt existing theories of coercive diplomacy and deterrence to explain the strategic behavior of major powers in cyberspace. We, instead, seek to explain the strategic behavior of weaker cyber states or middle powers that suspect a cyberattack. In these situations, middle powers often must rely on their own cybercapabilities because their allies are unlikely to help. Cyberdefenses are unique to each country and not easily transferable; close allies are often reluctant to disclose information about their offensive cybercapabilities and/or commit cyberattacks on an ally’s behalf (as compared with their willingness to offer military assistance during territorial invasions).\nThe literature on the “bargaining model of war” focuses on how private information and incentives to misrepresent, and commitment problems affected by power shifts, explain costly armed conflict (e.g., Schultz 1998; Slantchev 2003, 2010). Like this literature, our model demonstrates that states tend to use costly signals to make their adversaries misinterpret the existing balance of power; states also tend to keep certain capabilities secret to obtain military advantage.\nWhat is new about our model then? First, a different theoretical foundation drives how nations signal their cybercapacities. Unlike in the case of military capacity, a state cannot launch a parade to signal its cybercapacity. Satellite images are also unlikely to be useful to adversaries seeking to estimate a state’s cyberstrength. An executed cyberattack may provide a target with a good estimate of the attacker’s capabilities, but such an attack de-values capability because it provides the target with instructions on how to fix flaws in their own networks and systems. The time-limited life-span and the dynamic nature of cyberoperations further complicate their signaling potential. While the basic parameters for most traditional weapons remain relatively static,\n\nNADIYA KOSTYUK\n\nSecond, existing models focus only on whether and how investment in military capacity can deter a future attack or affect the likelihood of winning a war. Our theoretical foundation instead explains that sources of state cybercapacity are more diverse, lie beyond military and government, and extend to a state's private sector and even public-opinion management. While investing in military cybercapacity is important for deterrence by the threat of punishment, to deter adversaries by prevention, states might, for example, invest significant resources into building public awareness about the danger of cyberoperations and information operations, making potential election-interference campaigns harder.\nRegarding the model, the closest work, which focuses on the relative impact of scarce resource allocation on the likelihood of attack, is Arena and Wolford (2012). Unlike Arena and Wolford (2012), which examines a state's decision to allocate its resources between armaments and intelligence gathering capabilities in order to reduce uncertainty over its opponent's military strength, our model explores a state's decision to allocate its resources between public and private cybercapacity in order to deter its strong opponent from executing a cyberattack against the state. Similarly to works on counter-terrorism policies (Bueno de Mesquita 2007; Dragu 2011), our model explains why nations over-invest in public capacity and that such policies are generally ineffective in deterring adversaries.\nBaliga, de Mesquita, and Wolitzky (2020) and Welburn, Grana, and Schwindt (2019) are the only two other models that focus on cyberdeterrence; they explore how a state's inability to correctly attribute the origin of cyber operations and to detect cyberattacks affects the state's chances of deterring potential attackers. Unlike these models, our model focuses on organizational capability which signals the state's ability to readily produce and use covert cybercapacity. Unlike Baliga, de Mesquita, and Wolitzky (2020)'s model, in which there is uncertainty over the signal's sender (i.e., the attacker's identity) while the signal's quality (i.e., the strength of cybercapacity) is clear, our model investigates situations in which the signal's sender is known but the signal's quality is unclear. Unlike Welburn, Grana, and Schwindt (2019)'s model, in which a defender can signal any cybercapability with no cost, our model explains how the defender's choice to allocate its limited resources translates into observable cybercapacity.\nThe paper proceeds as follows. We start with explaining how a state can signal its cybercapacity. Then, we explain when and how public cyberinstitutions can deter strategic cyberattacks. Next, we introduce the model and derive the model equilibria. We use illustrative examples from elections to establish the empirical plausibility of our theory. We conclude with a discussion of our study's implications.\n## Signaling Cybercapacity States can signal their cybercapability by (1) attributing cyber operations (COs) to attackers; (2) executing COs against adversaries; and (3) establishing public cyberinstitutions—publicly observable efforts aimed at demonstrating a country's level of offensive and defensive cybercapability. Each of these methods has its pros and cons.\nSignaling cybercapacity via attribution is a recent trend, as demonstrated by the number of US indictments. Attribution is a powerful deterrent because it signals to both the attacker and future perpetrators that they are not as invisible as they would like to be in cyberspace. But cyber attribution is difficult and costly: Not only does cyber attribution require significant resources and technical expertise to correctly attribute an attack to a specific computer, but it also demands intelligence to connect the used computer to a perpetrator. Attribution is also a political decision because it requires a nation to reveal its own capabilities and compromise its intelligence sources. As a result, only a few nations have the resources, technical expertise, and political will to use attribution as a way to signal their cybercapability.\nSignaling cybercapacity via covert COs provides the target with an accurate estimate of the attacker's capability. However, the difficulty of attributing the origin of COs and the time it takes to do so diminish the signal's value, which is further reduced by the time-limited life-span and the dynamic nature of COs. Moreover, if a victim is not able to attribute the attack or remains quiet about the attack, the signaling value of COs is either zero or quite low. Furthermore, while many primitive exploits are available for purchase, it takes significant time and resources to develop sophisticated cyber weapons; only a few nations have a large enough cyber arsenal that they can burn some of their exploits for signaling purposes.\nWhile cybercapacity cannot be revealed because it depends on secret access and vulnerabilities, the state can reveal its ability to find such vulnerabilities by establishing PCIs, defined as publicly observable proactive efforts aimed at signaling its offensive and defensive cybercapabilities. PCIs signal an increase in organizational cybercapability, which demonstrates the state's ability to readily produce cybercapability and use cyberoperations for political purposes. As a result, signaling via PCIs provides the state's allies, adversaries, and domestic and international audiences with an immediate, often rough proxy for the state's cybercapacity and preserves the value of the state's covert COs.\nFor simplicity, I distinguish two ways in which a state can establish its PCIs: It can (1) create a new agency program, initiative, doctrine, strategy, or policy to address some aspect of cybersecurity; and/or (2) add new cyber roles to existing agencies or new cyber provisions to existing policies. For instance, to deter election interference campaigns, Sweden established an agency responsible for psychological defense. When preparing for its 2017 elections, Germany, on the contrary, considered using the hack-back strategy that would allow the country to respond to a potential cyberattack in a real time.\n5Some of these works include Debs and Monteiro (2014), Fearon (2018), Kydd (2000), Meirowitz and Sartori (2008), and Slantchev (2005).\n4Germany's hack-back strategy is a PCI even though the government does not give any details regarding the scope of this strategy. Since they publicly discussed its development (instead of only privately executing it), we have an idea of the steps that the German government considers adopting in order to deter election interference. If implemented, this strategy would allow the German government to launch offensive cyberattacks against attackers before they could do any real damage. For instance, in response to the attack against the parliament, the German government could remove servers on which stolen parliament data were located.\n\nEven though these two options differ in how governments created their PCIs, they both might involve a similar set of measures. Specifically, a new agency and a new strategy might require additional budget, stuff, training, and expertise. While PCIs often do not reveal all the details about created cybercapacity, unlike covert cyberactivity they allow an adversary to estimate the scope of the change and the potential resulting increase in the target state's cybercapacity. The Swedish and German actions, for instance, signaled that both countries prioritized spending their resources on building better cyber defensive and offensive capabilities to deter potential election interference campaigns.\nBefore we explain how PCIs can deter adversaries, we would like to clarify that our theory focuses on middle powers—the nations that have scarce cyber arsenals and are more likely to invest in PCIs as a means of deterrence. Cyber powers, such as the United States, China, and Russia, can also use PCIs to deter, but they are more willing to send a stronger, costlier deterrent signal by\"burning\"their covert cybercapabilities to demonstrate their ability to acquire such capabilities.⁵ ## The Theory of Cyber Deterrence The theory presented in this section examines the specific context in which a strong challenger (including cyber powers) contemplates a strategic cyberattack against a defender.⁶ When the challenger considers a cyberattack, he calculates the value he can gain from this attack (e.g., undermining democratic processes, in the case of election interference) and the cost he can incur. There are two types of costs. First is the cost of the defender's potential retaliation (e.g., using economic sanctions, military operations or cyberoperations). Second is the tendency of cyberoperations—unlike military operations—to diminish in value after their first use. A tank, for example, can be successfully deployed many times over many years. Cyberattacks, on the other hand, often lose their effectiveness after their first use, even if the attack fails due to the defender's defenses. In using cyberattacks, the challenger risks the possibility that the defender might be able to develop protection against similar attacks in the future.\nWe argue that, for a challenger to decide to use a cyberattack against a defender, it must believe that the attack's value will outweigh its cost. What can change this cost-benefit calculation? Specifically, what can raise the cost enough to deter the challenger?\nWe assume that the costs from non-cyber foreign policy tools (i.e., diplomatic or military responses, or economic sanctions) will not change the cost-benefit calculation because the challenger has considered them initially. These costs are easy to estimate using the defender's past history and are highly predictable based on the challenger's\"prior beliefs about the defender's willingness\"to use one ⁵Some anecdotal evidence suggests that even though the US government could not hack back in response to the election, it went into Russian servers and left non-malicious code that had\"U.S. Cyber Command\"in the comments. They did so to signal to the Russians, in a covert way, that they had the ability to strike whenever they wanted.\n⁶I employ the language from the traditional deterrence literature and refer to an adversary as a challenger and a defending state as a defender. The model makes the assumption that the defender attempts to deter her strongest challenger, which is the challenger that can potentially cause the most significant damage. If she is able to deter her strongest challenger, then all her other challengers will be deterred by default. Because the model focuses only on the strong challenger, I have omitted\"strong\"and refer only to a\"challenger\"for the remainder of the paper.\nof these options. Moreover, given that the defender's capability in non-cyber foreign policy domains is unlikely to change rapidly, the challenger's estimate of the costs imposed by diplomatic responses and economic sanctions is likely to be fairly accurate. The challenger is also aware that military responses are costly and that the defender is unlikely to launch a military strike in response to information operations or cyberoperations.⁷ Even though these non-cyber foreign policy tools cannot change the challenger's cost-benefit calculation, the challenger considers the defender's capability in these non-cyber domains when forming its opinion of the defender's cybercapacity. Since nations with significant resources and expertise can build sophisticated cyber weapons, the challenger can accurately conclude that the most powerful military nations have impressive cyber arsenals. While the country's military capability might often be correlated with its cybercapacity, it is not always the case because some nations might choose to purchase cyber weapons from third parties or work with proxy groups to execute attacks on their behalf. Despite that we argue that both the defender's capability in non-cyber and the defender's capability in cyber domains form the challenger's prior belief of the defender's cybercapacity.\nGiven that the challenger is quite certain about the costs associated with non-cyber responses and, as a result, is unlikely to be deterred by them, the defender is left with cyber foreign policy tools to deter the challenger from executing cyberattacks. We argue that cyber foreign policy tools may raise the cost of a cyberattack for the challenger because the challenger remains uncertain about the defender's cybercapacity. Even if the challenger has a rough estimate of the defender's cybercapacity, the dynamic, time-limited nature of cyber tools makes it difficult for the challenger to determine the defender's cybercapacity with precision or certainty. Specifically, while the basic parameters for most traditional weapons remain relatively static, strategically relevant features of certain cyber weapons can change significantly over a short period of time. Moreover, even though conventional platforms become obsolete over time, the lifespans of COs are much shorter because they depreciate after their first use and because the defender might recognize and fix the vulnerability before the challenger is able to exploit it. We explore this challenger's uncertainty over the defender's cybercapacity as the main mechanism that affects the probability of successful deterrence.⁸ How can the defender signal its cybercapacity ⁷The Israeli Defense Force bombing a building where the Hamas group allegedly operated is the first example when a state used a physical attack in response to cyberoperations.\n⁸For deterrence to be successful, in addition to capacity, a defender must demonstrate its resolve or willingness to use this capacity. Given that the defender knows it is facing a challenger contemplating a cyberattack, we assume the defender's resolve to use its capability against the challenger in this high-stakes scenario is high. Moreover, as earlier explained, many nations cannot afford to\"burn\"their covert cybercapabilities to demonstrate their ability to acquire such capabilities, and those that do send a rather costly signal about their sophisticated cyber arsenal. Furthermore, many countries conduct cyber espionage to observe other countries' cyberattack plans and capabilities. As a result, cyber powers that consider challenging other nations probably know enough about other countries' covert cyber strength to know whether they face another cyber power or not, though they do not necessarily know its precise capabilities. Thus, there is no uncertainty about the capabilities of these cyber powers; instead, this theory explores uncertainty over the capabilities of weaker nations—middle powers—and specifically how cyber\"strong\"or\"weak\"they are. These nations tend to have a rather scarce cyber arsenal and are more likely to invest in PCIs as a means of deterrence. However, the better a challenger's cyber-intelligence, the less uncertainty the challenger has about the defender's cybercapacity.\nNADIYA KOSTYUK\n\n## Deterrence by PCIs\nPCIs can leave the challenger uncertain about the defender's cybercapacity because they demonstrate the defender's ability to produce cybercapability without revealing any concrete details about this capability. PCIs can deter by prevention and/or by threat of punishment.¹⁰ These two types of deterrence are associated with the two types of costs that PCIs can inflict on the challenger, increasing the cost of its cyberattack. PCIs can deter by prevention because adversaries may infer that their attacks are likely to fail against the defenses implied by a PCI. Firewalls, updated computer software, programs aimed at educating public about cyberthreats, and policies that outline a set of measure to provide better security of critical infrastructure are examples of PCIs that can deter by prevention because they make hacking more difficult. While the challenger can keep using conventional weapons even if a conventional attack fails, the challenger often burns its cyber exploits in the case of an unsuccessful cyberattack. This is because having discovered an attempted hack, the defender can close the existing vulnerability making the future use of this exploit impossible. PCIs can also deter by the threat of punishment; for instance, new military doctrines and units signal the state's ability to use its cyber weapons in response to cyberthreats.\nWe investigate situations in which both deterrence mechanisms are at play for the following two reasons. First, one cyberinstitution can signal both cyber offensive and defensive capability, making it hard to separate deterrence by the threat of punishment from deterrence by prevention. The US Department of Defense Cyber Strategy (2015, 3), for instance, uses deterrence by prevention by specifying the Department of Defense's role in defending its information networks, and it uses the threat of punishment by establishing a Cyber Mission Force to be used to defend the United States against cyberattacks of \"significant consequence\". Second, when facing a strategic cyberthreat, states tend to respond with multiple PCIs and, as a result, implement both types of deterrence at the same time to maximize their chances of success.\nSince PCIs can increase uncertainty about the defender's cybercapacity raising the probability of successful deterrence, the defender might want to invest most, if not all, of its resources into PCIs. But such a strategy takes valuable resources away from covert cyberactivity (CCA) or private cybercapacity, which involves secret development of cybercapabilities and ongoing cyberoperations.¹¹ For instance, a polished strategy document, newly-constructed headquarters, or a new initiative meant to bring public awareness of cyberthreats is a poor substitute for a CCA aimed at penetrating the challenger's electricity grid and preparing for a future attack that could be used for retaliation.\nWe argue that this trade-off between PCIs and CCAs is important. Even though some PCIs involve the development of private cybercapability (e.g., the German's hack-back strategy), such PCIs give a high-level view on what capacity a government develops whereas CCAs remain truly covert and only signal capability after being discovered and correctly attributed. The Stuxnet worm, which the US and Israeli governments developed and deployed in 2005 against an Iranian nuclear enrichment facility, was an example of such a CCA, until it was discovered in 2010. Even though the US government created a number of PCIs between 2005 and 2010 to signal an increase in its cybercapacity, none of them signaled the tremendous potential of the US cybercapability. Only the attributed Stuxnet worm signaled the true scope of the US cyber arsenal. Unlike PCIs, which send an immediate, although often imprecise signal about a state's level of cybercapabilities, the Stuxnet example demonstrates that CCAs send a more accurate signal of a state's cybercapabilities but this signal might be delayed.\nSince an investment in both PCIs and CCAs is important for overall cyber capacity, over-investment in PCIs at the expense of investment in CCAs can make a defender weaker. However, the relationship between the defender's overall cybercapacity and its chances at deterrence is not linear—i.e., an increase in one does not necessarily mean an increase in the other. Therefore, a defender with weak cybercapabilities might strategically invest more in PCIs if such an investment maximizes its chances at deterrence, even if it decreases its overall cybercapacity.\nWe argue that the effectiveness of this deterrent strategy depends on the type of the challenger. Specifically, it only works against a challenger that is susceptible to the costs created by PCIs. We call this challenger opportunistic. During the 2018 Swedish elections, Russia was an example of an opportunistic challenger. Having considered a potential interference campaign, the Kremlin realized that the rather small marginal value from this campaign was not worth the additional potential costs imposed by the improved defenses and offenses that Sweden created in the form of PCIs prior to the elections. But an over-investment in PCIs as a deterrent strategy does not work against an disinterested challenger; such challengers never attack, even if they give the impression that they are considering attacking. During the 2017 German elections, Russia was an example of a disinterested challenger. PCIs put in place prior to the 2017 elections had no\n⁹ It is important to note that we do not exclude the possibility that countries can use cyberoperations or attribution to signal their capacity to an adversary. We assume that such signaling techniques have already taken place at the start of the game. As a result, they contribute to the formation of the challenger's prior beliefs regarding the defender's overall cybercapability.\n¹⁰ Given that early scholarly works perpetuated the offense dominance in cyberspace , prevention is often seen as somewhat futile as it is nearly impossible to protect all vulnerable targets; thus, preemption may be a more cost-effective tactic. Recent works, however, refute the offense-dominance thesis . While it is easier to find a vulnerability in an adversary's network/system than to defend its own networks/systems from hundreds of possible cyberattacks, Slayton (2017) stresses the importance of looking at the cumulative effort required for building cyber offense or defense. Besides technology, the author argues we should evaluate the costs of changing organizational processes that \"govern interactions between technology and skilled actors\" . Moreover, because the effectiveness of cybercapabilities is a function of the target's characteristics, high-value targets require significant time, resources, skill, and human capital to penetrate, increasing the cost of cyber offense .\n\nFigure 1. Defender’s cybercapacity: (a) relationship between defender’s observed and overall cybercapacity; and (b) relationship between defender’s type and her overall cybercapacity as a function of $I_{\\theta}$. Note: $I$: PCIs that $D$ can develop with $r$ units of resources; $N$: CCAs that $D$ can develop with $r$ units of resources; $I + N$: $D$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}$: the level of PCIs at which $D$’s overall cybercapability is maximized (point Max). Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$’s overall cybercapability when the resources are distributed between PCIs and CCAs; and $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $\\text{Max}_{S}(\\text{Max}_{W})$).\neffect on Russia’s decision to stay away from these elections because a combination of non-cyber factors shifted Russia’s cost-benefit calculus towards not attacking even before Germany establish its PCIs. Lastly, an over-investment in PCIs is also a waste of resources when the defender faces a undeterred challenger; such challengers always attack because the value of attacking is much higher than any additional costs created by PCIs. During the 2017 French elections, Russia was an example of an undeterred challenger. Having witnessed the worldwide impact of the mass disclosures of private data prior to the 2016 US elections, Moscow was willing to pay any cost and to risk any potential French (cyber or non-) retaliation for its influence campaign, which could help elect a pro-Kremlin candidate.\nThe next section models cyber deterrence by PCIs explicitly. It is worth noting that since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though the type of an attempted attack requires different types of PCIs, this does not affect the model logic and the obtained results.\n## Model\nThis section provides the intuition behind the game and the Online Appendix includes the detailed explanation and mathematical proofs.\n**Game Overview.** This is a game between a challenger ($C$, “he”) and a defender ($D$, “she”). $C$ considers executing a cyberattack against $D$. To deter $C$, $D$ decides how to signal her cybercapacity by allocating her resources between public and private cybercapacity and, as a result, which level of PCIs to implement. $D$ has a type $\\theta \\in [S, W]$ that differs in the amount of resources $a_{\\theta}$ available to her. The strong defender $D_{S}$ has many more resources available to her than the weak defender $D_{W}$. $\\theta$ is unobservable to the challenger.\nThe game starts with Nature’s choice. Nature selects that $\\theta = S$ with probability $\\pi$ and that $\\theta = W$ with probability $1 - \\pi$. The model assumes that both players have a common prior belief and that $\\pi$ is the true probability that the defender is strong. Then $D$ decides how to allocate her resources between PCIs and CCA. After $D$ implements PCIs, $C$ observes it, (possibly) updates his beliefs about $D$’s type, and decides whether he wants to attack $D$. When $C$ chooses whether to attack, $C$ observes $D$’s move but not $D$’s type. If $C$ does not attack, $D_{\\theta}$ successfully deters $C$ and the game\nends. If $C$ decides to attack $D_{\\theta}$, Nature selects that his attack is successful with probability $Q_{\\alpha}$, and unsuccessful with probability $1 - Q_{\\alpha}$. The probability of a successful attack is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. If $C$’s attack succeeds, $D_{\\theta}$ must decide whether to retaliate against $C$. If $D_{\\theta}$ does not retaliate against $C$, the game ends. If $D_{\\theta}$ retaliates against $C$, Nature selects that her retaliation is successful with probability $P_{\\theta}$ and is unsuccessful with probability $1 - P_{\\theta}$. The probability of a successful retaliation is determined by $D_{\\theta}$’s overall cybercapability and how she distributes her resources at the beginning of the game. Regardless of whether or not $D_{\\theta}$’s retaliation is successful, the game ends.[12]\n**Signaling Cyber Capacity.** To understand how $D$ can deter strategic cyberattacks, we must first understand how she can create her cybercapacity because $D$’s cybercapacity is a proxy for $D$’s ability to deter $C$. The higher $D$’s capacity is, the higher the likelihood that $D$ deters $C$. To maximize her cybercapability, $D$ decides how to divide her limited resources between PCIs that publicly signal her offensive and defensive cybercapability and CCA.[13] Both PCIs and CCA create $D$’s overall cybercapability. As mentioned earlier, $D$’s overall cybercapability does not necessarily increase simply by investing more in her PCIs because such a strategy takes valuable resources away from CCA. As a result, it makes $D$ weaker.\nFigure 1(a) explains the intuition of how this works graphically. $C$ has a prior belief of $D$’s cybercapability, given COs attributed to $D$ or using various indicators of $D$’s technological development. Given the public nature of PCIs, $C$ can only observe PCIs and estimate $D$’s cybercapability. We call it $D$’s observed cybercapability and place it on the x-axis in Figure 1(a). The y-axis in Figure 1(a) represents $D$’s overall cybercapability that we receive by adding the resources that $D$ invests into PCIs and CCAs. Let $I$ denote the PCIs that $D$ can develop with $r$ units of resources and let $N$ denote the CCA that $D$ can develop with $r$ units of resources.[14] The\n[12] We display this two-player game with incomplete information concerning $D$’s type in Online Appendix Section 1.1.\n[13] Even though it is not always the case in the world, the model simplification assumes that the defender has to invest all its resources in one or the other, and there is no cost of investing.\n[14] I assume that both $I$ and $N$ are increasing in $r$ and that there are diminishing returns to investment in each (i.e. $I'(r), N'(r) &gt; 0$ and $I''(r), N''(r) &lt; 0$).\nNADIYA KOSTYUK\nFigure 2. Equilibria and challenger's types. Note:  $C$ : a challenger;  $D_W$ : a weak type of the defender;  $D_S$ : a strong type of the defender;  $\\pi$ : a prior probability that  $D$  is strong;  $1 - \\pi$ : a prior probability that  $D$  is weak; and  $\\tilde{I}_S$ : the level of PCIs at which overall cybercapability is maximized for the strong type of the defender. 1:  $C$ 's gains from attacking  $D_S$ , given the probability of this attack is successful; 2:  $C$ 's gains from attacking  $D$ , given that with  $\\pi$  probability he is facing  $D_S$  and with  $1 - \\pi$  probability, he is facing  $D_W$  that pools with  $D_S$  and implements  $\\tilde{I}_S$ ; and 3:  $C$ 's gains from attacking  $D_W$ , given the probability of this attack is successful.\nfunction  $I + N$  stands for  $D$ 's overall cybercapability when the resources are distributed between PCIs and CCAs. We define  $\\tilde{I}$  to be the level of PCIs at which  $D$ 's overall cybercapability is maximized (point Max in Figure 1a).\nBefore  $D$  creates her PCIs, often she already has some existing cybercapabilities. For instance, before the Swedish Civil Contingencies Agency (MSB) became responsible for election protection, it dealt with civil protection; MSB could use these expertise to provide public safety during the time of elections. This existing level of cybercapability determines  $D$ 's type. We distinguish two types of  $D$ -strong  $(D_S)$  and weak  $(D_W)$ .  $D_S$ , depicted by the black line in figure 1(b), has a higher level of existing cybercapability, thus she can implement a higher level of PCIs and have higher chances of deterrence than  $D_W$ , depicted by a gray line in figure 1(b). Similarly,  $\\tilde{I}_S$  and  $\\tilde{I}_W$  are the levels of PCIs at which overall cybercapability is maximized for the defender's weak and strong types, respectively.\nWe assume that the costs of producing public  $(I)$  and private  $(N)$  cybercapacity are the same for the strong and weak type of the defender because we primarily focus on explaining the behavior of middle powers. Some nations that have developed technological expertise in this area—cyber powers, for instance—can develop \"more\" capability for a given budget. In such cases, it might be difficult for other nations to imitate PCIs developed by these cyber powers. For these reasons, our model excludes these powerful nations and primarily focuses on the behavior of middle powers that can imitate each other's behavior in order to deter their challengers.\n# Model Equilibria\nNext we discuss the intuition behind the model equilibria.\nAs explained earlier, the effectiveness of the defender's PCIs on deterring the challenger, depends on the challenger's type. We distinguish three types of the challenger that depend on the three cut-off points depicted in figure 2. If  $C$  is undeterred and always attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region I in figure 2). If  $C$  is disinterested and never attacks, both types of the defender have nothing to do but to maximize their cybercapacity (Region IV in figure 2). In these two equilibria,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. Proposition 1 summarizes both equilibria.\nProposition 1. Challenger's decision to attack is independent of defender's PCIs.\n(a) If  $C$  is undeterred and always attacks (Region I in Figure 2),  $D_{0}$  maximizes her cybercapacity and  $C$  always attacks.\n(b) If  $C$  is disinterested and never attacks (Region IV in Figure 2),  $D_0$  maximizes her cybercapacity and  $C$  never attacks.\nIn both equilibria in Proposition 1,  $D$ 's PCIs have no effect on  $C$ 's decision to attack. But what happens if they do? We argue that different types of the defender would invest their resources differently to maximize their chances of deterring adversaries that are susceptible to the costs created by PCIs. Specifically, the strategic use of PCIs to deter  $C$  occurs in the signaling region where there is both the need for and the possibility of deterrence. Here  $D_0$ 's PCIs can influence  $C$ , which will take different actions depending on the defender's true type. Specifically, the challenger will attack the defender if he knows that the defender is weak and will avoid attacking if he knows the defender is strong. We call this challenger opportunistic. In this region, depicted by Regions II and III in Figure 2, there are two pure strategy equilibria (Propositions 2-3) and one mixed strategy equilibrium. We focus on the pure strategy equilibria in the main manuscript and present the mixed equilibria in the Online Appendix.\nIf  $C$  prefers attacking a defender that he thinks is weak and avoiding attacking a defender that he thinks is strong due to the fear of retaliation or attack failure,  $D_W$ 's natural response is to increase her investment into PCIs to appear strong. Specifically, instead of redistributing her resources so that her overall cybercapability achieves its maximum (Max  $W$  in Figure 3 (a)),  $D_W$  distributes them so they are her overall cybercapability is at point A in Figure 3(a). By doing so,  $D_W$  creates the same level of PCIs  $(\\tilde{I}_S)$  as  $D_S$  (i.e.,  $D_W$  pools with  $D_S$ ), so when  $C$  observes these institutions, he concludes that he is dealing with a strong defender and does not attack. Because this deterrent strategy decreases  $D_W$ 's overall cybercapability, by appearing strong,  $D_W$ , in fact, hides her actual weakness. This pooling equilibrium holds only when  $D$ 's gain of appearing strong outweighs  $D$ 's loss to inefficiently allocating her resources and when  $C$ 's prior belief that  $D$  is strong is high. Proposition 2 presents this pooling equilibrium.\n# Proposition 2. Pooling Equilibrium.\nSuppose  $C$  is opportunistic and prefers attacking  $D$  only if he believes that  $D$  is weak. If  $C$ 's prior belief that  $D$  is strong is high, then (1)  $D_W$  pools with  $D_S$  and they both implement  $\\tilde{I}_S$  and (2)  $C$  is deterred and does not attack.[15]\n\nFigure 3. Defender's pure strategy actions when facing an opportunistic challenger: (a) pooling strategy; and (b) strategic separation strategy. Note: $I_{S}(I_{W})$: PCIs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $N_{S}(N_{W})$: CCAs that $D_{S}(D_{W})$ can develop with $r$ units of resources; $I_{S} + N_{S}(I_{W} + N_{W})$: $D_{S}(D_{W})$'s overall cybercapability when the resources are distributed between PCIs and CCAs; $\\hat{I}_{S}(\\hat{I}_{W})$: the level of PCIs at which overall cybercapability is maximized for $D_{S}(D_{W})$ (point $Max_{S}(Max_{W})$); $\\hat{I}$: the level of PCIs that $D_{W}$ cannot attain; $A$: $D_{W}$ imitates PCIs of $D_{S}$; and $B$: $D_{S}$ strategically separates herself from $D_{W}$ by implementing PCIs that $D_{W}$ cannot implement.\nIf $C$'s prior belief that $D$ is strong is low, then $C$ interprets pooling as weak and attacks if $D$ implements $\\hat{I}_S$ (Region II of figure 2). $D_S$ is aware that $D_W$ is trying to imitate her PCIs and takes one of the two actions. Not wanting to be confused with $D_W$, $D_S$ can alter her behavior to clearly distinguish herself (i.e., separate) from $D_W$ to ensure that $C$ is deterred. Specifically, $D_S$ spends enough resources to reach a level of PCIs that $D_W$ cannot attain—$\\hat{I}$ (point B in Figure 3(b)). Observing $\\hat{I}$, $C$ knows that the defender is strong as $D_W$ could not implement $\\hat{I}$, as Figure 3(b) shows. Since $D_W$ cannot imitate $D_S$ and implement PCIs to reach $\\hat{I}$ in Figure 3(b), $D_W$ implements her optimal strategy $\\hat{I}_W$. Since separation is costly as it reduces $D_S$'s overall capacity, for this equilibrium to hold, $C$ should not attack when he sees $\\hat{I}$ even though he knows that $D_S$'s overall capacity is reduced. Proposition 3 summarizes this separating equilibrium.\n**Proposition 3.** Separating Equilibrium. Suppose $C$ is opportunistic and prefers attacking $D$ only if he believes that $D$ is weak. If $C$'s prior belief that $D$ is strong is low, then (1) $D_S$ implements a level of PCIs that $D_W$ cannot imitate $(\\hat{I} &gt; \\hat{I}_S)$, (2) $D_W$ is not able to pool with $D_S$ and implements $\\hat{I}_W$, and (3) $C$ attacks only when he sees $\\hat{I}_W$. [16]\nAlternatively, $D_{S}$ can decide not to implement PCIs that $D_{W}$ is not able to mimic because this will weaken her overall cybercapacity and invite an attack. In this case, a pure strategy equilibrium does not exist in Region II of Figure 2. But there exists a mixed strategy equilibrium where $D_{W}$ mixes between $\\hat{I}_{W}$ and $\\hat{I}_{S}$ and $C$ is indifferent between attacking and not. The Online Appendix presents this mixed strategy equilibrium.\n## Illustrative Examples of Elections\nThe novelty, secrecy, and sensitivity of the topic of cyber deterrence prevents us from conducting a rigorous empirical test of our findings. Instead, we aim at demonstrating the empirical plausibility of our theory of deterrence of strategic cyberattacks using PCIs. Since our theory is agnostic towards the type of a strategic cyberattack that a\nnation prefers to deter, we use illustrative examples from elections to provide support for our model equilibria. [17] Specifically, we focus on Kremlin-directed attempts to influence electoral campaigns in Western democracies: the 2016 US elections, the 2017 German elections, and the 2018 Swedish elections. We choose the most similar examples for our comparison ; they share the same cyber-capable attacker (Russia), have similar targets (Western democracies), use the same methods (cyber and information operations), have the same purpose (election interference), and have similar timeframes (2016–2018). They differ, however, in (1) the stakes involved in each campaign (e.g., a challenger's type); and (2) the level of PCIs that the targets implement (e.g., strong versus weak). As a result, these examples help demonstrate (1) under what conditions the challenger's uncertainty over the defender's cybercapacity increases the probability of successful deterrence; and (2) when this uncertainty has no effect.\nWe focus on the three different illustrative examples because they match the model's scope conditions that must be met if PCIs deter the challenger. First, there must be a difference in how different types of defenders allocate their resources to signal their cybercapacity. As we shortly demonstrate, the Swedish government, a weak cyber nation, prioritized investing in PCIs to appear that it had strong cyber defenses and offenses. Second, the challenger must face uncertainty about the defender's cybercapacity and its type. The time-limited and dynamic nature of COs generally raises uncertainty about cybercapacity, but this uncertainty over the defender's type does not play a role when facing an undeterred or disinterested challenger. But it is important when facing an opportunistic challenger: By investing more of its resources into PCIs, a weak defender can deter the challenger by pretending that it is strong. Uncertain about Sweden's actual cybercapacity, Russia observed the overwhelming number of PCIs that Sweden created prior its 2018 election that are typical of strong types; it is conceivable that based on these observations, the Kremlin chose not to attack. Third, the challenger's benefit from attacking should outweigh its costs for deterrence to be successful. In\n[16] This equilibrium relies on the off-the-equilibrium beliefs that the defender is weak \"enough\" if it plays $\\hat{I}_S$.\n[17] We use an illustrative example to provide support only for the pooling equilibrium when the challenger is opportunistic (Region III in figure 2) because it provides the most interesting result by demonstrating when PCIs can, in fact, deter the challenger.\nNADIYA KOSTYUK\nthe elections we are considering, the cost-benefit calculations differ. In the 2018 Swedish elections, the additional costs created by Swedish PCIs outweighed the low value of Russia's interference campaign and deterred Russia from interfering. In the 2017 German elections, the Kremlin did not consider the extra costs created by PCIs because they were irrelevant—a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place. In the 2017 French elections, benefits outweighed the costs.\n# 2018 SWEDISH NATIONAL ELECTIONS: OPPORTUNISTIC CHALLENGER AND POOLING EQUILIBRIUM\nThe 2018 Swedish national elections provide support for the pooling equilibrium in which the weak defender over-invests in PCIs to appear strong and, as a result, deters the opportunistic challenger (Region III in Figure 2). To show that this is the case, we need to demonstrate that the Russian government was opportunistic and additional PCIs that Sweden created prior to the elections changed the Kremlin's cost-benefit calculation of the election interference campaign.\nTo understand how PCIs as a deterrent strategy worked in this case, we first explain why the Kremlin even considered interfering in the Swedish electoral process. Sweden's nonalignment policy has always served as a guarantee of Russia's security. Recently, however, Sweden shifted its military nonalignment position by strengthening its international defense cooperation with North Atlantic Treaty Organization (NATO) . In response, Russia's Defense Minister Sergei Shoigu described Sweden's involvement in NATO activities as \"worrying\" and added that \"such steps...[were] forcing us to take response measures\" (Russia Concerned by Efforts to Draw Finland, Sweden into NATO—Defense Minister 2018). Military actions and/or economic sanctions are possible response measures, although to date, Russia has pursued neither of these. The Ukrainian and Syrian conflicts, combined with NATO-Swedish defense cooperation (even if it falls short of collective defense), are most likely responsible for preventing Russia from taking a military approach.\nRussia is, on the other hand, a mastermind of influence campaigns and had been preparing a strong foundation for such a campaign on the Swedish population for some time. Starting in 2014, the Swedish information landscape witnessed an increase in disinformation campaigns, led by trolls, bots, and Kremlin-sponsored media outlets, such as Sputnik International. In 2016, the Swedish authorities reported an increase in information campaigns aimed at \"polarizing Swedish society, undermining stability, and spreading falsehoods\"  and Sweden remained one of the few \"favorite target[s] of the Kremlin's propaganda machine\" at the beginning of 2018 (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018, 109). Russian actors were also behind a series of distributed denial-of-service (DDoS) attacks[18] against Swedish news sites and a disinformation campaign about NATO in the Swedish media.[19]\nAn anti-immigration sentiment in both the Swedish parliament and the populace bolstered these ongoing COs and information operations. Immigration has always been a contentious issue in Swedish politics, recently exacerbated by the Syrian refugee crisis. Over the last five years, Sweden, a country of 10 million, has welcomed 165,000 asylum-seekers from the Middle East. Using immigration as one of its agenda items, the far-right Sweden Democrats became the third largest party in the Swedish parliament in 2018 after having occupied only two seats in 2010 . The party's anti-immigration stance and the divide in the general population over the immigration issue presented the perfect environment for the Kremlin's influence campaigns.\nHowever, by 2018, in the immediate lead-up to the election, Kremlin-linked disinformation campaigns seemed to fade, and there was no outright election interference . Why? What stopped Russia from interfering in the Swedish elections?\nLet us look at Russia's cost-benefit calculus. While Sweden had a favorable political climate and Russia had some ongoing COs and information operations, the value of a potential interference campaign was quite low, compared to, for instance, the interference into the US elections that we will discuss below. We argue that the low interference value, combined with additional costs created by PCIs that Sweden established prior to its elections, deterred Russia from interfering into the 2018 Swedish elections.\nIn addition to the PCIs outlined in the introduction, there are many others that the Swedish government established in order to raise the cost of election interference. Here are just a few examples. The government reiterated the protection of democracy as one of the country's top security objectives and designated its election systems as critical infrastructure. It tasked the Civil Contingencies Agency (MSB) and the Security Services and the Election Authority with coordinating election protection and made MSB responsible for countering Russian disinformation. Most importantly, Sweden's Prime Minister Stefan Lofven emphasized the country's military offensive cybercapability and the government's willingness to use it. When discussing a three-point plan to stop foreign powers from influencing the 2018 Swedish elections, Lofven publicly claimed that the Swedish Armed Forces were capable of carrying out \"active operations in the cyber environment\"—an important statement given that Sweden has not been publicly admitting its possession of offensive cybercapabilities . Some might argue that factors other than PCIs deterred Russia. First is NATO's military capabilities. The NATO-Sweden cooperation defense pact that prioritizes security in the Baltic Sea region protects Sweden from a physical invasion by Russia (akin to those in Ukraine and Georgia) but not from election interference. Second is the threat of Western economic sanctions. The ineffectiveness of these sanctions in changing Moscow's behavior in Ukraine and Syria suggest that they are unlikely to have deterred the Kremlin from executing its plan. Third is Russia's lack of interest in interfering. While the interference value was low, preparatory influence operations aimed at undermining the 2018 Swedish elections demonstrate that the interest was, in fact, present (Putin's Assymmetric Assault on Democracy in Russia and Europe 2018). Having ruled out the above factors, we have further evidence that Sweden's PCIs, put in place before elections, raised the cost of a potential election interference campaign and deterred Russia from interfering into the 2018 Swedish elections.\n# 2017 GERMAN FEDERAL ELECTION: DISINTERESTED CHALLENGER AND PCIs HAVE NO EFFECT\nThe 2017 German federal election provides support for the equilibrium in which the defender's PCIs have no effect on the challenger because the challenger is\n\ndisinterested—the interference value is already so low that the challenger has no interest in interfering in the elections (Region IV in figure 2). We argue that German PCIs had no effect on Russia's decision to stay away from the 2017 German federal election. Instead, a combination of non-cyber factors shifted Russia's cost-benefit calculus in favor of not attacking even before PCIs were put in place.\nThe history of COs and information operations attributed to the Kremlin a few years prior to the election demonstrate that the Russian state had interest in German election interference. Information operations started in 2013, when three key German-language Kremlin-linked propaganda outlets—Sputnik Deutsch, RT Deutsch, and NewsFront Deutsch—entered the German market and were later joined by trolls²⁰ and bots.²¹ The 2015 and 2016 COs against the parliament and political parties demonstrate that Moscow was also eager to obtain sensitive information for potential future use. But the value of an effective influence campaign were overwhelmed by potential costs resulting from the following factors.\nFirst, Germany's balanced media systems, the lack of polarization among the German public, Germany's multiparty and proportional system, and a\"gentleman's agreement\"between major political parties not to use any information leaked as a result of cyberattacks made it difficult for Moscow to sow confusion in the public.. Second, the only clear beneficiary of these campaigns was the Alliance for Germany (AfD)—the rest of parties supported the sanction regime against Moscow. But when AfD entered the race, they only had between eight and ten percent of vote, which was not enough to gain the majority. Third, the use of old-fashioned paper ballots on the local level afforded Germany with an accurate recount in the event that digitized votes used on the federal level were compromised. Lastly, high-level deterrent rhetoric by German politicians referencing a deterioration of the relationship between the two countries if interference occurred likely played a part.²² Although Putin and Merkel's relationship has eroded over time, alienating Germany—an important bridge between the West and Russia—was not in Russia's interest.\nIf not these factors, what other factors could have stopped Russia from election interference? Brattberg and Maurer (2018) and Schwirtz (2017) suggest that a failure to influence the 2017 French presidential elections made the Kremlin re-think its approach, since it lost the element of surprise. While quite plausible, the evidence later revealed interference into the French elections was not directed by the Kremlin, although it was aligned with its objectives.\n## 2017 FRENCH ELECTION: UNDETERRED CHALLENGER AND PCIs HAVE NO EFFECT The 2017 French elections provide an illustrative example for the equilibrium in which the defender's PCIs have no effect on the challenger because it is undeterred—the interference value significantly outweighs its costs (Region I in Figure 2). Given this high value, we argue that the Russian government was like an unstoppable tank moving towards its target and no French PCIs could have stopped the Kremlin from executing its plan.\nWhat was the value from interfering into the 2017 French elections? The lowest value was undermining faith in the democratic process whereas the highest value was electing a pro-Kremlin candidate that could have resulted in a change in French foreign policy. We argue that even the lowest value of the interference campaign was far greater than any costs Russia could envision paying.\nIf caught, Moscow knew that it faced potential (cyber and non-cyber) retaliation. Diplomatic retaliation was the least of Russia's worries considering some existing tension between the two countries. Moscow expected that, if elected, Emmanuel Macron—as the only unequivocal critic of Putin's Russia out of all presidential candidates—would only exacerbate this tension. The cost of additional economic sanctions—in addition to those that the country already faced for the Ukrainian conflict—was marginal. Nuclear and military responses to COs and information operations were off the table.\nGiven these rather low costs from non-cyber foreign policy options, what additional cyber costs could have Russia anticipated? French cyber defenses were not strong enough to deter Russia by prevention, given the government's ad hoc preparation against disinformation operations. Deterrence by punishment was unlikely to work either. Even if Paris targeted Russia's critical infrastructure (even though it is quite unlikely), the damage that Russia experienced would have been limited. For example, it is impossible to hack Russia's entire power grid system at once because most stations are manually controlled and can be restored by flipping a switch. Similarly, Paris was unlikely to attempt information operations because of the Kremlin's tight control of Russia's print, online, and social media and because of Russia's treatment of information as a weapon, allowing its military to respond to such information threats (Conceptual Views Regarding the Activities of the Armed Forces of the Russian Federation in the Information Space 2011).\nIn short, the potential worst-case scenario costs that Moscow faced were lower than the value it would gain by election interference. Thus, the Kremlin's interference campaign was never going to be deterred by French PCIs.\n## Discussion and Implications As scholars and policymakers continue debating cyber deterrence using COs, attribution, and non-cyber threats, we explore the feasibility of cyber deterrence using means that have been largely overlooked by the international relations literature—public cyberinstitutions which signal organizational capacity to produce and use cybercapability to achieve strategic objectives.\nOur main contribution is to identify the precise conditions under which PCIs can deter strategic cyberattacks, which cause significant damage to a country's economy and security. Since our theory focuses on deterring any strategic cyberoperation, it is agnostic to the type of operations that the challenger attempts. Even though different types attacks are deterred by different types of PCIs, the results do not change. Specifically, we reveal several important patterns of the strategic use of PCIs to deter challengers that differ by type. PCIs have no effect on disinterested challengers because they have no interest in attacking the defender and undeterred challengers because they have decided to attack even before observing the defender's PCIs. Both scenarios demonstrate that states are wasting their resources if they ²⁰ A troll is someone who argues for extreme views without credible sources.\n²¹ An automated program that runs over the Internet.\n²² During its spring 2017 visit to Moscow, the\"Chancellery emissary delivered a stern warning\"; in May, Merkel herself issues a warning to Putin, by saying,\"she assumes 'German parties will be able to decide their election campaign among themselves'\"; and in June, German President Frank-Walter Steinmeier warned Moscow that\"Were [it] to interfere in the election of the Bundestag, then the share of commonalities will necessarily decrease further. That would be damaging for both sides\"(as quoted in Brattberg and Maurer 2018, 18).\nNADIYA KOSTYUK PCIs, however, can deter opportunistic challengers that only attack defenders that they perceive as cyber weak and avoid attacking those defenders that they perceive as cyber strong. To deter opportunistic challengers, weak cyber nations might choose to over-invest their limited resources into PCIs to appear strong. Strong cyber nations, in their turn, over-invest their limited resources into PCIs to distinguish themselves from weak cyber nations pretending to be cyber strong. This sub-optimal resource allocation, which makes the defender weaker in its overall cybercapacity, is worthwhile for weak cyber nations because it deters opportunistic challengers. These results have important theoretical and policy implications.\nOur findings shed light on a theoretical debate surrounding cyber deterrence. Similar to Tor (2017), this article stresses the need to re-think our reference to absolute nuclear deterrence as a matrix of deterrence success for cyberoperations. Countries do not create cybercapacity to deter low-level COs; instead, their goal is to stop adversaries from executing strategic cyberattacks, which can cause detrimental damage to the country's economy, prosperity, and security.\nWhat constitutes strategic cyberattacks, however, continues to evolve with changes in global cyberthreat landscape; countries only focused on critical infrastructure protection less than a decade ago and added election protection to their top national security priorities following the 2016 US elections. As countries re-define what constitutes strategic cyberattacks, adversaries find more creative ways to achieve their strategic goals using cyber means that operate below the strategic cyberattack threshold. For example, in response to Russia's meddling in the 2016 US elections, the US government took significant steps to protect its 2018 elections. In response to this stern measure, Russian bots and trolls adjusted their behavior and started operating during the election off-season. These influence campaigns, even if conducted during election off-seasons, shape public opinion and might affect public voting behavior. Scholarship on how to deal with adversaries that maneuver around red lines that prohibit the use of force could shed light on how to address this upcoming challenge in cyberspace.\nOur results also show that states should take the signaling of cybercapacity via PCIs with a grain of salt. While PCIs serve as a cyberthreat assessment barometer because they allow a challenger to estimate a defender's ability to conduct COs, the defender's willingness to use these operations, and the scope of the defender's potential retaliation, this assessment is not precise. To better estimate the defender's cybercapacity, challengers should also examine other indicators, such as economic and technological achievements and the defender's reliance on the private sector for cybercapacity. This cumulative approach used to estimate cybercapacity will help governments better evaluate options that minimize the risk of escalation.\nFurthermore, our results speak to the scholarship in international relations theory that focuses on deterrence.[23] Our study further confirms the importance of considering the challenger's type or its resolve prior to concluding the ineffectiveness of deterrence.[24] We show that the challenger's choice to cyberattack the defender is independent of the defender's PCIs in two equilibria. In the first one, the challenger has no interest in attacking the defender, giving a false impression of deterrence success. In the second one, the challenger has already decided to attack the defender, despite its PCIs, giving a false impression of deterrence failure. Inadequate signaling or effects of factors, such as domestic politics, budgetary and legal constraints, and organizational and strategic culture, might explain why the challenger attacks or does not attack in these two scenarios. Before concluding the ineffectiveness of PCIs or other means of deterrence, researchers and policy-makers should consider these variables in their estimations. Moreover, since our model is limited to states that have limited cyber arsenals and are not able to burn their exploits to send deterrent signals, we expect to see more investment in PCIs among relatively weaker cyber nations or middle powers. But as more nations invest in PCIs, this deterrent approach might be less effective.\nWhile we take the first stab at understanding deterrence by PCIs, future research should further investigate this important mechanism. Here, we highlight a few venues that future research could explore. First, our model oversimplifies real-world scenarios by making assumptions to identify the causal effect of PCIs on deterrence chances. We view the challenger's choice to attack and the defender's choice to establish PCIs as a one-time decision. In practice, PCIs present a state's cumulative effort to boost its cybercapacity. Similarly, cyber and influence campaigns are composed of many, often low-level activities that span an extended period. Future research should explore how much updating-of-beliefs takes place during different stages of strategic cyberattacks and a state's cumulative efforts to build PCIs. Second, our model equates the defender's probability of successfully retaliating against the challenger with the probability that the defender's cyber defenses hold because PCIs often tend to signal an increase in both offensive and defensive cyber capabilities. Future iterations of this model should explore scenarios when it is not the case. For instance, when PCIs only signal an increase in offensive cybercapability, the threat of cyber retaliation might not deter a country that does not have many cyber targets, like North Korea. PCIs that only signal an increase in cyber defenses might deter countries that view attacking well-protected targets as too costly.\nThird, our model does not distinguish the defender by regime type. Democratic leaders are more transparent, responsive to constituents, and willing to provide public goods in the form of security to satisfy voters and secure their reelection (De Mesquita 2005). While autocracies might be less likely to create PCIs because they face a lesser demand to respond to their domestic audience, they, in fact, might be more likely to exaggerate their PCIs because of this lesser demand. Future research should investigate how these tendencies among different regime types affect model equilibria.\nAs Schelling (2008, 44) puts it,\"If deterrence fails, it is usually because someone thought he saw an 'option' that the... government had failed to dispose of, a loophole that it hadn't closed against itself.\"By building cybercapabilities, governments seem to assume that these capabilities alone have a deterrent effect. As my model demonstrates, successful deterrence depends on a defender's cybercapacity, its willingness to use it, and a challenger's type. Some challengers may remain undeterred due to a lack of political will in the defending nation to launch a retaliatory cyberattack against an adversary as formidable as, say, Russia or [23] For an overview of this scholarship, see Lupovici (2010).\n[24] We can describe undeterred challengers as resolute, opportunistic challengers as semi-resolute, and disinterested challengers as resolute.\n\nChina. In these cases, states might perceive potential consequences of entering an escalation cycle with such adversaries as too great to risk. To maximize the desired deterrent effect of publicly flexing their cyber muscles, nations' strategies should demonstrate their willingness to hold assets at risk and face consequences in cases of escalation. Only then, states will be able to close some of the loopholes that adversaries can exploit. Until that is done, the pessimistic view of cyber deterrence will persist.\n## Funding Nadiya Kostyuk's work was partially supported by the William and Flora Hewlett Foundation under grant 2018-7727."
    }
  },
  "citation_summary": {
    "style": "superscript",
    "dominant_bucket": "tex",
    "dominant": {
      "intext_total": 10.0,
      "success_occurrences": 10.0,
      "success_unique": 5.0,
      "bib_unique_total": 15.0,
      "occurrence_match_rate": 1.0,
      "bib_coverage_rate": 0.3333333333333333,
      "success_percentage": 100.0,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "superscript"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 10.0,
        "success_occurrences": 10.0,
        "success_unique": 5.0,
        "bib_unique_total": 15.0,
        "occurrence_match_rate": 1.0,
        "bib_coverage_rate": 0.3333333333333333,
        "success_percentage": 100.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "superscript"
      },
      "numeric": {
        "intext_total": 17.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 37.0,
        "success_occurrences": 36.0,
        "success_unique": 27.0,
        "bib_unique_total": 75.0,
        "occurrence_match_rate": 0.972972972972973,
        "bib_coverage_rate": 0.36,
        "success_percentage": 97.3,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "Deterrence in the Cyber Realm: Public versus Private Cyber Capacity",
    "subtitle": "School of Public Policy, Georgia Institute of Technology, USA",
    "document_type": "unknown",
    "venue": "",
    "publication_year": 2021,
    "authors": [
      "NADIYA KOSTYUK"
    ],
    "affiliations": [
      "School of Public Policy, Georgia Institute of Technology, USA"
    ],
    "emails": [
      "journals.permissions@oup.com"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "",
    "keywords": [],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1093/isq/sqab039"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": []
    },
    "references_block_count": 1,
    "references_entries_estimated": 48,
    "heading_count": 14,
    "max_heading_level": 2,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [
        "no_abstract"
      ],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 10,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.3,
      "footnote_coverage": 1.0,
      "unique_index_count": 5
    },
    "footnotes_quality": {
      "intext_total": 0,
      "index_coverage": 0.0,
      "intext_citation_coverage": 0.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 0,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "superscript",
      "recommended_style": "superscript",
      "aligned": true,
      "signals": {
        "superscript_hits": 19,
        "superscript_definition_lines": 5,
        "numeric_bracket_hits": 17,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 15.0,
      "dominant_bib_coverage_rate": 0.3333333333333333,
      "dominant_link_target": "footnotes",
      "dominant_unresolved_flag": "unresolved_footnote_links"
    },
    "heading_validation": {
      "heading_count": 14,
      "max_heading_level": 2,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": true,
        "emails": true,
        "orcids": false,
        "abstract": false,
        "keywords": false,
        "venue": false,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 1,
        "affiliations": 1,
        "emails": 1,
        "orcids": 0,
        "keywords": 0,
        "doi": 1,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 0
      },
      "coverage": {
        "core_coverage": 0.8333333333333334,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [
          "no_abstract"
        ],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_abstract_and_keywords",
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "missing_preceding_text",
      "low_bib_coverage",
      "meta_missing_abstract_and_keywords",
      "meta_low_email_author_link_rate"
    ]
  },
  "updated_at_utc": "2026-02-14T08:28:54.463256+00:00"
}