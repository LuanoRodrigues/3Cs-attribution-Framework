{
  "pdf_path": "C:\\Users\\luano\\Zotero\\storage\\PLFJFG5R\\Kostyuk and Zhukov - 2019 - Invisible digital front can cyber attacks shape battlefield events.pdf",
  "custom_id": "378",
  "response": {
    "id": "batch-b6235e9e-379-e1eddc98-8460-408d-8f4b-01156fae0b5b",
    "custom_id": "378",
    "response": {
      "status_code": 200,
      "body": {
        "pages": [
          {
            "index": 0,
            "markdown": "Check for updates\n\nArticle\n\n# Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\n\nJournal of Conflict Resolution\n2019, Vol. 63(2) 317-347\n© The Author(s) 2017\nArticle reuse guidelines:\nsagepub.com/journals-permissions\nDOI: 10.1177/0022002717737138\njournals.sagepub.com/home/jcr\nSAGE\n\nNadiya Kostyuk¹, and Yuri M. Zhukov¹\n\n## Abstract\n\nRecent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.\n\n## Keywords\n\ncompellence, coercion, physical violence, conflict, cyber attacks\n\nOn December 23, 2015, hackers attacked Ukraine’s power grid, disabling control systems used to coordinate remote electrical substations, and leaving people in the capital and western part of the country without power for several hours. The Security\n\n¹Department of Political Science, University of Michigan, Ann Arbor, MI, USA\n\n## Corresponding Author:\n\nNadiya Kostyuk, Department of Political Science, University of Michigan, 505 S State Street, Ann Arbor, MI 48109, USA.\nEmail: nadiya@umich.edu",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 1,
            "markdown": "Service of Ukraine (SBU) blamed the Russian government for the cyber attack, an accusation that later found support in malware analysis by a private computer security firm. The Ukrainian hack was the first publicly acknowledged case of a cyber attack successfully causing a power outage. It is also just one of thousands of cyber activities, mostly diffuse and low level, that have occurred alongside physical fighting in Ukraine. Attacks launched through the digital realm are playing an increasingly visible role in civil and interstate conflict—in Ukraine, Syria, Israel, Estonia, Georgia, and beyond. Yet it remains unknown whether such activities have a real coercive impact on the battlefield.\n\nRecent years have seen growing concern over the coercive potential of cyber capabilities in war, but little evidence that these new tools are yet making a difference. Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence (Libicki 2009; Sharma 2010; Andres 2012). Yet the logic of coercion entails distinct challenges in peace and war, with potentially different implications for the cyber domain. Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist (Valeriano and Maness 2014) privilege massive cyber catastrophes over less sophisticated low-intensity attacks, like distributed denial of service (DDoS). The latter category, however, is far more common.\n\nThis article asks whether cyber attacks can compel short-term changes in battlefield behavior, using new event data on cyber and kinetic operations from armed conflicts in Ukraine and Syria. We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides (Geers 2015), and—uniquely—overt claims of responsibility, public damage assessments, and other releases of information that reduce uncertainty over timing and attribution. Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques” (Zetter 2017). If cyber attacks can yet make a difference on the battlefield, Ukraine is one a few cases where we are most likely to observe such an effect. Our data include 1,841 unique cyber attacks and 26,289 kinetic operations by government and prorebel forces between 2014 and 2016. We supplement this quantitative analysis with fourteen primary source interviews with participants in the cyber campaign as well as Ukrainian, Russian, and Western cyber security experts with direct knowledge of these operations.\n\nTo evaluate the generalizability of the Ukrainian experience to other conflicts, we replicate our results with data from Syria's civil war. Like Ukraine, Syria has seen the extensive use of low-level cyber attacks by factions fighting for and against the incumbent regime. Because this war has gone on significantly longer than the conflict in Ukraine—giving hackers more time to organize and develop their capabilities—Syria offers a glimpse at cyber activities in a more protracted, higher intensity context. If we uncover similar patterns in two conflicts of such different scale and complexity, we can have greater confidence that our results are not artifacts of a single idiosyncratic case. Our data include 682 cyber attacks and 9,282 acts of violence by pro- and anti-Assad forces between 2011 and 2016.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 2,
            "markdown": "Evidence from both conflicts suggests that cyber attacks have not created forms of harm and coercion that visibly affect their targets' actions. Short of mounting synchronized, coordinated cyber campaigns, each group of hackers has seemed to operate in its own “bubble,” disengaged from unfolding events in both cyberspace and the physical world. The lack of discernible reciprocity between cyber and kinetic operations—and between the cyber actors themselves—questions whether cyber attacks can (yet) be successfully deployed in support of military operations.\n\nThis disconnect may be temporary, as joint planning and execution concepts continue to evolve. Many countries, for instance, still struggle in coordinating air-power for ground combat support, a century after World War I. Our study highlights some of the difficulties that countries will need to overcome in integrating and synchronizing these new capabilities.\n\nOur contribution is fourfold. We offer the first disaggregated analysis of cyber activities in war and take stock of the empirical relationship between the cyber and kinetic dimensions of modern battle. To do so, we collect the first microlevel data on wartime cyber attacks, using both open media sources and anonymous attack traffic data. Theoretically, our analysis addresses an important question on the coercive impact of low-level cyber attacks, advancing a literature that has been heavy on deductive argumentation, but light on evidence. Finally, from a policy standpoint, our findings should temper the popular tendency to overhype the transformative potential of cyber attacks. At present, interaction between cyber and kinetic operations is similar to that between airpower and ground operations in World War I—when armies began to use aircraft for reconnaissance but had not realized their full potential to shape battlefield outcomes.\n\n## Varieties of Cyber Activity\n\nThe term “cyber activities” captures a diverse assortment of tactics and procedures, directed against different types of targets, in pursuit of disparate objectives. Not all of these activities seek to achieve battlefield effects in the same way. Before proceeding further, we differentiate between two broad goals these actions tend to pursue: propaganda and disruption.\n\nCyber activities in the propaganda category seek to influence public opinion and indirectly undermine an opponent's financing or recruitment. Operations in this group include leaks of compromising private information, online publication of partisan content (e.g. “trolling” on comments pages), and the establishment of dedicated websites and forums to promote an armed group's message. Unless it openly incites or discourages violence, propaganda affects kinetic operations only indirectly by undermining an opponent's support base or obfuscating perceptions of events.\n\nIn the Ukrainian conflict, the importance of both groups attach to online propaganda is evident from the time and resources pro-Kyiv fighters spend updating Wikipedia, and pro-Russia groups devote to creating and running dedicated",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 3,
            "markdown": "YouTube channels and social media accounts. Russian military doctrine places a heavy emphasis on the strategic use of information in warfare, as does US cyberspace joint planning doctrine.\n\nThe second category of cyber attacks—disruption—seeks to directly sabotage opponents' ability to operate in the physical or electronic realm. These mostly low-intensity activities include denial of service attacks, which make targeted resources unavailable through a flood of requests from a single source, and DDoS attacks, where requests originate from multiple compromised systems. Related efforts include inundating communications systems with floods of text messages or phone calls and using fire walls and proxies to block access to websites. At the extreme end of the scale is the use of malicious code to inflict physical damage or otherwise compromise infrastructure and military objects. Examples include interception of drones, communications and surveillance systems, control of Wi-Fi access points, and collection of protected information via phishing.\n\nThe most sophisticated known attack of this type is the Stuxnet worm, which—before its discovery in 2010—targeted industrial control systems critical to uranium enrichment in Iran. In Ukraine, notable disruptive activities have included attacks on the Central Election Committee's website during the 2014 presidential elections and attacks on the country's power grid in 2015 and 2016. Other examples include the use of malware to collect operational intelligence, like X-Agent, which retrieved locational data from mobile devices used by Ukrainian artillery troops, and the hacking of closed-circuit television (CCTV) cameras behind enemy lines.\n\nPropaganda and disruption are not mutually exclusive, and many cyber activities serve both purposes—shaping public opinion through disruption or disrupting an opponent's operations by shaping public opinion. For example, altering the visual appearance of websites can have the dual effect of embarrassing the target and limiting its ability to communicate. Leaks of private information also have dual implications for targets' public image and physical security.\n\nRecent examples of hybrid activities include the defacement of US Central Command's Twitter and Facebook pages by the Islamic State's (IS) Cyber Caliphate and operations by US Cyber Command against IS beginning in April 2016. In Ukraine, the pro-rebel group CyberBerkut (CB) has leaked private communications from senior United States, European Union, and Ukrainian officials and disclosed identities of pro-Kyiv field commanders—simultaneously creating a media scandal and forcing targets to commit more resources to personal security. Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations (Il'chenko 2016).\n\nIn the following, we limit the scope of our inquiry to cyber actions that are either purely disruptive (e.g. DDoS-style attacks) or are hybrids of the two approaches (e.g. web defacements). We do so for two reasons. First, most purely propagandistic operations, like comment-board trolling, do not aspire to influence the course of",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 4,
            "markdown": "military operations in the short term. Second, it is hard to separate the disruptive and propaganda effects of hybrid cyber activities because they depend on each other.\n\n## Cyber Coercion in Wartime\n\nOver the last two decades, cyber attacks have become an increasingly common tool of coercion, used by state and nonstate actors, independently and jointly with physical, kinetic operations. Like other instruments of coercion, cyber actions inflict costs on a target to compel a change in its behavior—either by punishing past misdeeds or by putting pressure on decision makers in real time.\n\nThe role of cyber compellence in wartime is not unlike that of airpower or terrorism (Pape 2003, 2014). Cyber attacks cannot take or hold territory on their own, but they can support operations on the ground by disrupting opponents' command and control, collecting operational intelligence, and creating opportunities for conventional forces to exploit. If combatants use the Internet for coordination, recruitment, or training, low-level cyber disruption may prevent them from running these vital functions smoothly. Alternatively, cyber attacks can indirectly pressure an opponent by targeting civilian economy and infrastructure, similarly to strategic bombing. Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties (Ottis 2010). Unlike terrorism, the individual attacker is rarely at risk of direct physical harm.\n\nDespite the apparent promise of these “weapons of the future” (Schmitt 1999; Rios 2009; Clarke and Knake 2010; McGraw 2013; Eun and Aßmann 2014), some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion (Liff 2012; Rid 2012; Gartzke 2013; Junio 2013). There is little doubt that large numbers of low-level attacks can cumulatively produce large-scale damage, bringing “death by a thousand cuts” (Lemay, Fernandeza, and Knight 2010). Yet successful coercion also requires punishment to be both anticipated and avoidable (Schelling 1966), and these criteria can be difficult to meet in cyberspace.\n\nCyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities (Axelrod and Iliev 2014). Since the destructiveness of malicious code depreciates quickly after first use, cyber attacks are often most damaging when they are least anticipated.\n\nTargets also have many reasons to doubt that cyber attacks are avoidable by accommodation. For the attacker, cyber actions present a trade-off between plausible deniability—which helps prevent retaliation—and the credibility of coercive promises and threats. Any uncertainty over the source of an attack will also create uncertainty over the nature of compliance—what sort of actions will prevent future attacks and by whom.\n\nBeyond attribution uncertainty, cyber attacks may not generate sufficient costs to elicit compliance from. Because administrators can quickly fix or contain many",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 5,
            "markdown": "exploited vulnerabilities, even successful attacks cause only temporary disruption (Axelrod and Iliev 2014). Unless the attacker continues to develop new methods and identify new vulnerabilities, a protracted campaign may quickly lose its coercive impact. As a result, targets may see compliance as insufficient and unnecessary to stop the damage (Hare 2012; Lynn 2010; Nye 2010).\n\nForce synchronization challenges may also render the timing of cyber attacks suboptimal for compellence. Hackers—especially those not integrated with military forces—may not observe battlefield events on a tactically relevant time line. Even if they did, the lead time required to plan and implement a successful attack—studying the target system, collecting intelligence on its vulnerabilities, and writing code that exploits them—can make these efforts difficult to synchronize with conventional operations.\n\nThese challenges are not insurmountable. Lead time is a greater barrier for high-level attacks (e.g. targeting major infrastructure) than for more routine, DDoS-style attacks. Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower (Atran 2003; Pape 2003, 2014). The ability of contemporary hackers to overcome these difficulties, however, remains unknown.\n\n### Previous Research\n\nThe question of whether low-level cyber attacks compel has deep implications for the theory and practice of national security. Yet the public and academic debate on this topic has unfolded largely in the absence of rigorous empirical evidence in either direction. Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare (Cha 2000; Griniaiev 2004; Libicki 2007, 2011; Czosseck and Geers 2009; Clarke and Knake 2010; Axelrod and Iliev 2014), the overlap between cyber and kinetic capabilities (Healey 2013; Kello 2013; Libicki 2015; Andress and Winterfeld 2013; Axelrod 2014), and the effect of information and communication technology on conflict (Martin-Shields 2013; Pierskalla and Hollenbach 2013; Crabtree, Darmofal, and Kern 2014; Gohdes 2014; Bailard 2015).\n\nMost research in the first category has focused on the implications of cyber activities for peacetime deterrence or the offense--defense balance rather than wartime compellence. While the second group focuses more directly on cyber attacks during conflict, its empirical approach has been mostly qualitative, relying on evidence from descriptive case studies, macrohistorical surveys, and stylized facts. Some large-n analyses do exist (Valeriano and Maness 2014), but their scope has remained on large-scale cyber attacks rather than the far more numerous low-intensity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action (Weidmann 2015) rather than military compellence.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 6,
            "markdown": "Our study bridges the gap between these areas of inquiry. Our goal is to assess the coercive potential of low-level cyber actions during an armed conflict. We pursue this goal by studying the magnitude and direction of the relationship between cyber attacks and physical violence, using microlevel data from ongoing conflicts in Ukraine and Syria.\n\n### Empirical Expectations\n\nCyber attacks by actor A can affect physical violence by B in one of the three ways: negatively, positively, or not at all. If cyber compellence is successful, we should expect a short-term decrease in violence after a spike in cyber attacks. A positive response would suggest failure, where cyber attacks actually escalate violence by the opponent. If no relationship exists, cyber actions are either ineffective or irrelevant to fighting in the physical world.\n\nIn addition to compellence across domains, cyber attacks by actor A may impact cyber attacks by actor B. As before, only a negative relationship would imply coercive success, while a null or positive response would suggest that these actions are either ineffective or counterproductive.\n\n## Data Analysis\n\nTo evaluate whether and how cyber actions affect physical violence in war, we analyze new micro-level data from Ukraine and Syria. We begin with an in-depth study of the Ukrainian case, as one of few conflicts where both sides have used cyber attacks as a means of coercion. Due to the sophistication of hackers on both sides, the public nature of many attacks, and an abundance of data, the Ukrainian conflict allows us to observe the short-term coercive impact of cyber attacks. We then use analogous event data on Syria to evaluate the generalizability of our results. While a more systematic analysis of cross-national patterns lies beyond the scope of our article, micro-level evidence from these two conflicts might be suggestive of general patterns of modern warfare—particularly where combatants with asymmetric capabilities use cyberspace along with traditional tools of war.\n\nIn assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets (Baum and Zhukov 2015; Davenport and Stam 2006; Woolley 2000), we draw data from multiple open sources—including press reports and anonymous attack traffic data. To reduce potential false positives, we include only those events that have been reported by more than one source.\n\n### Ukraine Cyber Attacks Data\n\nOur cyber event data on Ukraine include 1,841 unique, mostly low-level, cyber attacks from August 27, 2013, to February 29, 2016, drawn from two sets of sources.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 7,
            "markdown": "First are media reports of cyber attacks from rebel, Russian, Ukrainian, and Western news outlets, press releases and blogs along with social media platforms used by the involved nonstate actors. Second is the private cyber security firm Arbor Networks' Digital Attack Map (DAM; see http://www.digitalattackmap.com/about/). Unlike media sources—which include only cyber attacks publicly reported by news organizations or claimed by governments and hacker groups directly—DAM draws on anonymous attack traffic data and network outage reports to enumerate the top 2 percent of reported attacks that generate unusually high Internet traffic for each country. Including these “higher-visibility” attacks should make it easier to find a coercive effect.\n\nWe supplemented these data with fourteen primary source interviews with participants in the cyber campaign, as well as Russian, Ukrainian, and Western cyber security experts with direct knowledge of these operations, from the private and public sectors, academia, and journalism. We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix (Kostyuk and Zhukov 2017).\n\nWe grouped cyber attacks in our data set according to the partisanship of alleged perpetrators (pro-Ukrainian vs. prorebel) and the type of operation they conducted (propaganda vs. disruption). Table 1 list all actors conducting cyber activitiess in the Ukrainian conflict, their targets, and the reported frequency of their activities.\n\nUkrainian cyber actions include specific attacks by pro-Kyiv hackers like Anonymous Ukraine and Ukrainian Cyber Forces (UCFs). The latter is the most active group on the pro-Ukrainian side. In an interview, UCF leader Eugene Dokukin claimed to have established the nonstate group in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine (Kostyuk and Zhukov 2017, # 1). Pro-Kyiv hackers' most common targets are the communications and finances of rebel units as well as media firms and private companies in rebel-held areas.\n\nProrebel cyber actions include specific attacks by proseparatist or pro-Russian cyber actors, like CB, Cyber Riot Novorossiya, Green Dragon, and the Russian government. The first of these takes its name from Ukraine's disbanded Berkut riot police and claims to fight “neofascism” in Ukraine. Ukrainian and Russian cyber experts we interviewed offered contradictory assessments on CB's organizational structure. One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution (Kostyuk and Zhukov 2017, # 12). Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB (Kostyuk and Zhukov 2017, #7 & #8). These groups' most popular targets include Ukrainian government officials, media, and private citizens.\n\nWe further disaggregated these events into the two categories previously defined—propaganda or disruption—as well as a third, hybrid, category of incidents",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 8,
            "markdown": "Table I. Actors and Targets (Ukraine and Syria).\n\n|  Ukraine  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Pro-Kyiv | Actor/target | Frequency (%) | Prorebel | Actor/target | Frequency (%)  |\n|  Anonymous Ukraine | A | 6 (<1) | CyberBerkut | A | 134 (7)  |\n|  Ukrainian Cyber Forces | A | 1,392 (76) | Cyber Riot Novorossiya | A | 41 (2)  |\n|  Ukrainian governmental units and officials | A/T | 3 (<1)/326 (18) | Green Dragon | A | 1 (<1)  |\n|  Ukrainian army units | T | 1 (<1) | Quedagh | A | 1 (<1)  |\n|  Western governments and organizations | T | 15 (1) | Crimean government officials | T | 6 (<1)  |\n|  Western non-state actors | T | 7 (<1) | Russian army units | A/T | 1 (<1)/14 (1)  |\n|  Non-state supporters | T | 91 (5) | Non-state supporters | T | 444 (24)  |\n|   |  |  | Rebel groups | A/T | 2 (<1)/926 (50)  |\n|   |  |  | Russian state units and government officials | A/T | 2 (<1)/14 (1)  |\n|   |  |  | Russian state-sponsored groups | A | 237 (13)  |\n|  Total |  | 1,841 (100) |  |  | 1,841 (100)  |\n|  Syria  |   |   |   |   |   |\n|  Anti-Assad | Actor/target | Frequency (%) | Pro-Assad | Frequency (%) | Actor/target  |\n|  Anonymous/anonymous-sponsored units | A | 93 (14) | ISIL/ISIL-sponsored units | A | 54 (8)  |\n|  Anti-Assad non-state actors | A/T | 297 (44)/18 (3) | Russian government units | A | 3 (<1)  |\n|  Jabhat al-Nusra-sponsored units | A | 1 (<1) | Syrian government units and officials | A/T | 2 (<1)/272 (40)  |\n|  Kurdish non-state opposition | A | 11 (<2) | Syrian state-sponsored units | A/T | 102 (15)/2 (<1)  |\n|  Free Syrian Army | T | 1 (<1) | Pro-Assad non-state actors | T | 179 (26)  |\n|  Pro-ISIL social media and websites | T | 140 (21) |  |  |   |\n|  Total |  | 682 (100) |  |  | 682 (100)  |\n\nNote: ISIL = The Islamic State of Iraq and the Levant.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 9,
            "markdown": "that potentially serve both purposes. The most common cyber actions in Ukraine have been DDoS-style attacks, followed by hacks of CCTV cameras and other communications. Website blockages have also proven popular, as have spearphishing e-mails targeting specific individuals. Table 2 provides a full breakdown.\n\nTo reduce false positives due to unconfirmed reports or dubious claims of responsibility, we only include attacks reported by more than one source. To account for uncertainty of attribution, we marked as “disputed” all cases where no one claimed responsibility and labeled as “nondisputed” those operations for which actors directly claimed responsibility in press releases, on social media, or in interviews. To focus on daily dynamics, we excluded activities whose intensity did not vary over time.\n\nFigure 1a depicts the temporal dynamics of pro-Ukrainian (Cyber U) and pro-Russian rebel (Cyber R) cyber operations. In early March 2014, about a week after the revolution in Kyiv, Figure 1 shows a spike in attacks by CB. The same month saw the establishment of the pro-Kyiv Ukrainian Cyber Forces, partly in response to CB's attacks. However, UCF operations do not become visible until May 2014, following an influx of volunteers to the group. May 2014 is also notable for a rise in activities by another pro-Russian cyber group, Cyber Riot Novorossiya—named after the czarist-era term (“New Russia”) for territories in southeastern Ukraine. After the first Minsk cease-fire agreement in September 2014, operations by pro-Ukrainian hackers converge to a steady rate of two to four per day, with occasional flare-ups, as in December 2014. Activities by pro-Russian hackers, by contrast, declined after the summer 2014.\n\n### Ukraine Violent Events Data\n\nOur data on kinetic operations include 26,289 violent events from Ukraine's Donbas region, recorded between February 28, 2014, and February 29, 2016. To offset reporting biases in any one source, while guarding against potential disruptions in media coverage due to cyber attacks, these data draw on seventeen Ukrainian, Russian, rebel, and international sources. As before, we include only events that appeared in more than one source.\n\nTo extract information on dates, locations, participants, and other event details, we relied on a combination of supervised machine learning (Support Vector Machine) and dictionary-based coding. The Online Appendix describes our measurement strategy and provides summary statistics.\n\nFigure 1b shows the temporal distribution of pro-Ukrainian (Kinetic U) and pro-Russian rebel (Kinetic R) physical violence. The plot shows several notable flare-ups of fighting—during a government offensive in late June 2014 and a rebel offensive in January 2015—as well as lulls following cease-fire agreements in September 2014, February 2015, and September 2015. Compared to the cyber operations in Figure 1, this plot reveals a clear correlation between kinetic operations",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 10,
            "markdown": "Table 2. Types of Cyber Operations (Ukraine and Syria).\n\n|  Propaganda | Ukraine (%) | Syria (%) | Disruption | Ukraine (%) | Syria (%) | Both | Ukraine (%) | Syria (%)  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  PPI—publishing online private information of the members of the conflicting parties | 47 (2) | 59 (9) | AVG— audio-, video-, and geo-intelligence collection | 423 (23) | 1 (<1) | WDT—website defacement | 51 (3) | 389 (57)  |\n|  PRM/PUM—posting pro-rebel and pro-Ukrainian messages online | 54 (3)/5 (<1) | — | CPI—collecting private information via open sources | 13 (<1) | 10 (<2) |  |  |   |\n|  UWP—updating online pages | 6 (<1) | — | DDoS—distributed denial-of-service attack | 499 (27) | 78 (11) |  |  |   |\n|   |   |   |  ODS—other attacks with a purpose of disruption or espionage | 9 (1) | 10 (<2) |  |  |   |\n|   |   |   |  SPE—spear-phishing e-mail | 234 (13) | 17 (2.5) |  |  |   |\n|   |   |   |  STM—sending massive text messages or calling phones non-stop | 40 (2) | 1 (<1) |  |  |   |\n|   |   |   |  WBG—website blockage | 257 (14) | 376 (55) |  |  |   |\n|  Total | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100)  |\n|   |   |   |  |   |   |   |   |   |",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 11,
            "markdown": "Journal of Conflict Resolution 63(2)\n\n![img-0.jpeg](img-0.jpeg)\n(a) cyber\n\n![img-1.jpeg](img-1.jpeg)\n(b) kinetic\nFigure 1. Cyber and kinetic operations in Ukraine (March 2014–February 2016). U (blue) indicates operations by Ukrainian government forces; R (red) indicates operations by pro-Russian rebel groups.\n\nby the two sides, with government and rebel attacks rising and falling in tandem. $^{15}$  Although this interdependence is not surprising, the data suggest that—with few exceptions—physical violence in Ukraine has been a reciprocal affair.\n\nFrom a brief glance at the timing of cyber and physical operations (Figure 1a and b), there are relatively few signs of a compelling effect—changes in the former do not appear to drive changes in the latter. However, a visual comparison can be misleading. Some of the variation may be due to fighting on the ground or in cyberspace, but other changes may reflect secular trends or shocks due to elections and other events not directly related to conflict. To account for these potential confounding factors and to gauge whether there is a stronger cyber-kinetic relationship than we would expect by chance, we conduct a series of more rigorous tests.",
            "images": [
              {
                "id": "img-0.jpeg",
                "top_left_x": 136,
                "top_left_y": 207,
                "bottom_right_x": 1056,
                "bottom_right_y": 581,
                "image_base64": null,
                "image_annotation": null
              },
              {
                "id": "img-1.jpeg",
                "top_left_x": 136,
                "top_left_y": 637,
                "bottom_right_x": 1045,
                "bottom_right_y": 1000,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 12,
            "markdown": "Empirical Strategy\n\nTo evaluate the relationship between cyber and kinetic operations in Ukraine, we estimate a series of vector autoregressive models\n\n$Y_{t} = \\sum\\limits_{j}^{p}B_{j}Y_{t - j} + GX_{t} + \\mu_{0} + \\mu_{1}t + \\mathbf{\\epsilon_{t}},$ (1)\n\nwhere $Y_{t} = \\left[y_{t}^{\\text{Kinetic(U)}}, y_{t}^{\\text{Kinetic(R)}}, y_{t}^{\\text{Cyber(U)}}, y_{t}^{\\text{Cyber(R)}}\\right]^{\\prime}$ is a matrix of endogenous variables, and $X_{t} = \\left[x_{1t},\\ldots,x_{kt}\\right]^{\\prime}$ is a matrix of k exogenous variables, which includes indicators for key dates and events during the war, like presidential and parliamentary electoral campaigns in Ukraine and breakaway territories; cease-fire agreements; and Ukrainian, Russian, and Soviet holidays. Deterministic components include a constant term (μ_{0}) and trend (μ_{1}t). p is the lag order, selected via Bayesian information criterion, and $\\mathbf{\\epsilon_{t}}$ is a vector of serially uncorrelated errors.\n\nWe control for Ukrainian, Russian, and Soviet holidays because anecdotal accounts suggest significant increases in cyber activity during such times. The UCF, for instance, had an operation called “Happy New Year,” which sought to print pro-Ukrainian messages from hacked printers in Crimea, Russia, and Donbas. National election campaigns represent another time when such activities may spike. Before and during the presidential elections, for instance, hackers bombarded Ukraine's Central Electoral Committee website with DDoS attacks. Finally, we may expect cease-fire agreements aimed at reducing physical violence to also have an effect in the cyber domain. For example, the cyber espionage operation “Armageddon”—directed against Ukrainian government websites—intensified before the Minsk I agreement went into force but then rapidly declined.\n\nBecause we are interested in the relationship between cyber attacks and physical violence during war, we limit our primary analysis to the active phase of military operations between May 11, 2014, and February 15, 2015—the period following independence referendums organized by the self-proclaimed Donetsk and Luhansk People's Republics and the second Minsk cease-fire agreement. In the Online Appendix, we present additional analyses of the full data set, which produced similar results.\n\n## Results\n\nData from Ukraine support the skeptical view of cyber coercion. The impulse--response curves in Figure 2 show a strong, escalatory dynamic between kinetic operations by the two sides (Kinetic U, Kinetic R), but no tangible links in either direction between kinetic and cyber operations, and no reciprocity between cyber actions (Cyber U, Cyber R).\n\nFollowing a standard deviation increase in kinetic rebel attacks, government violence sees a delayed rise, peaking around two days after the shock and gradually",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 13,
            "markdown": "|  Response: |   |\n| --- | --- |\n|  Kinetic (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  |\n|  Kinetic (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  |\n|  Cyber (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  |\n|  Cyber (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  |\n\nFigure 2. Impulse response matrix, daily time series (Ukraine). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"U\" indicates reported kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 14,
            "markdown": "declining back to zero (top row, second column). Rebel operations also rise after shocks to government operations (second row, first column), but the response here is immediate, without the delay we observe in government operations. This pattern may reflect command and control inefficiencies in the Ukrainian army, particularly early in the conflict, when indecision and leadership turnover lengthened decision cycles.\n\nThe relationship between cyber and kinetic operations is far weaker than that between rebel and government violence on the ground. Cyber attacks by pro-Ukrainian forces see no increase after shocks in kinetic government operations, and a positive, but uncertain increase after shocks in kinetic rebel operations (third row, first and second columns).\n\nThere is even less evidence that cyber attacks drive kinetic operations. The impulse--response function (IRF) curve for pro-Ukrainian government violence is, in fact, negative after shocks to rebel cyber operations (top row, two rightmost columns). Although this negative response might otherwise suggest that cyber attacks compel a decline in violence—consistent with coercive success—the estimate is also highly uncertain. Following shocks to pro-Ukrainian cyber activities, meanwhile, the main change in rebel kinetic operations is a short-term increase in volatility (second row, third column). In sum, the data suggest that cyber attacks may make violence less predictable but do not systematically change its intensity.\n\nPerhaps most surprisingly, there is little or no apparent strategic interaction between “cyber-warriors” on each side of the conflict. A shock in pro-Ukrainian cyber attacks yields no discernible change in pro-rebel cyber attacks (bottom row, third column) and vice versa (third row, fourth column). The two cyber campaigns, the data suggest, have unfolded independently of each other and independently of events on the ground.\n\nAs the diagonal elements in Figure 2 suggest, there is strong autocorrelation in each series. For each of the four categories, past shocks in operations yield a significant spike in subsequent operations. To evaluate whether the other categories of events can help us predict future values of each series, after we take this autocorrelation into account, Table 3 reports the results of Granger causality tests. The tests confirm that past levels of prorebel and pro-Kyiv kinetic operations help predict each other's future values. Kinetic operations, however, do not appear to “Granger cause”—or be “Granger caused” by—cyber attacks on either side.\n\nTable 4 reports the forecasting error variance decomposition, representing the proportion of variation in each series (rows) due to shocks in each endogenous variable (columns). For most variables, their own time-series account for almost all variation at the outset, but this dependency gradually decreases. As before, there is far more dependence within kinetic operations than between kinetic and cyber or within cyber actions. By the thirty-day point in the daily time series, shocks in rebel attacks account for 7 percent of variation in Ukrainian government operations, while shocks in government operations explain 12 percent of variation in rebel violence.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 15,
            "markdown": "Journal of Conflict Resolution 63(2)\n\nTable 3. Granger Causality Test, Daily Time Series (Ukraine).\n\n|  Effects | F statistic | p value  |\n| --- | --- | --- |\n|  Kinetic (R) → Kinetic (U) | 40.26 | .00  |\n|  Cyber (U) → Kinetic (U) | 0.50 | .48  |\n|  Cyber (R) → Kinetic (U) | 0.09 | .76  |\n|  Kinetic (U) → Kinetic (R) | 12.29 | .00  |\n|  Cyber (U) → Kinetic (R) | 1.44 | .23  |\n|  Cyber (R) → Kinetic (R) | 2.70 | .10  |\n|  Kinetic (U) → Cyber (U) | 1.40 | .24  |\n|  Kinetic (R) → Cyber (U) | 1.88 | .17  |\n|  Cyber (R) → Cyber (U) | 0.00 | .95  |\n|  Kinetic (U) → Cyber (R) | 1.74 | .19  |\n|  Kinetic (R) → Cyber (R) | 0.14 | .71  |\n|  Cyber (U) → Cyber (R) | 0.89 | .35  |\n\nNote: \"U\" indicates reported kinetic and cyber operations by Pro-Ukrainian government forces, and \"R\" indicates operations by Pro-Russian rebel forces.\n\nTable 4. Variance Decomposition, Daily Time Series (Ukraine).\n\n|  Operation type | Kinetic (U) | Kinetic (R) | Cyber (U) | Cyber (R)  |\n| --- | --- | --- | --- | --- |\n|  Kinetic (U) |  |  |  |   |\n|  1 Day | 1.000 | .000 | .000 | .000  |\n|  2 Days | 0.920 | .060 | .002 | .018  |\n|  7 Days | 0.906 | .071 | .002 | .020  |\n|  30 Days | 0.906 | .071 | .002 | .020  |\n|  Kinetic (R) |  |  |  |   |\n|  1 Day | 0.108 | .892 | .000 | .000  |\n|  2 Days | 0.121 | .873 | .000 | .006  |\n|  7 Days | 0.122 | .870 | .000 | .008  |\n|  30 Days | 0.122 | .870 | .000 | .008  |\n|  Cyber (U) |  |  |  |   |\n|  1 Day | 0.000 | .002 | .998 | .000  |\n|  2 Days | 0.000 | .002 | .997 | .000  |\n|  7 Days | 0.000 | .003 | .997 | .000  |\n|  30 Days | 0.000 | .003 | .997 | .000  |\n|  Cyber (R) |  |  |  |   |\n|  1 Day | 0.012 | .023 | .000 | .964  |\n|  2 Days | 0.014 | .023 | .001 | .962  |\n|  7 Days | 0.015 | .023 | .001 | .961  |\n|  30 Days | 0.015 | .023 | .001 | .961  |\n\nNote: \"U\" indicates kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 16,
            "markdown": "By contrast, shocks to cyber activities account for very little variation in kinetic operations. The highest value is for pro-Russian rebel cyber activities, which account for 2 percent of short-term variation in government violence. Cyber attacks by each side also have a relatively small impact on each other. Indeed, rebel kinetic operations explain more of the variation in cyber attacks by each actor than do cyber attacks by the other side.\n\nIn sum, our analysis suggests that low-level cyber attacks in Ukraine have had no effect on the timing of physical violence. Not only is there no evidence that cyber attacks have compelled opponents to de-escalate fighting, there is no discernible reciprocity between the cyber actors themselves. Each group of hackers seems to operate in its own bubble, disengaged from unfolding events in both cyberspace and the physical world.\n\n### Robustness Checks\n\nTo gauge the sensitivity of our results to various modeling and measurement choices, we conducted extensive robustness checks. We summarize their results briefly here (Table 5) and more fully in the Online Appendix.\n\nThe first set of tests considers vector autoregression models with alternative orderings of the four endogenous variables, which affects estimation of impulse responses. We find no substantive differences across the twenty-four permutations.\n\nIn a second set of robustness checks, we account for systematic differences in the kinds of conflict events that Ukrainian and Russian media report, which may bias statistical estimates—for example, by underreporting violence by a given actor. Using kinetic data from exclusively Russian or exclusively Ukrainian sources does not change the results.\n\nA third set of robustness tests examines different subsets of cyber attacks. Because purely disruptive activities may impose greater immediate costs than quasi-propagandistic hybrid attacks, pooling these events may dilute their coercive effect. Our results are consistent for all three subsets.\n\nThe last set of robustness checks examines different time periods of the conflict, since some cyber attacks predated military activity. In particular, we compare the period of intense fighting previously analyzed (May 11, 2014--February 15, 2015) to the entire date range for which we have data (February 28, 2014--February 29, 2016). Our results remain unchanged.\n\n## Evidence from Interviews\n\nIn interviews, Russian and Ukrainian cyber security experts highlighted five potential explanations for the apparent failure of cyber coercion in Ukraine: (1) lack of resources, (2) lack of coordination, (3) lack of targets, (4) lack of audience, and (5) lack of effort.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 17,
            "markdown": "Table 5. Robustness Checks (Ukraine and Syria).\n\n|  Ukraine (main results; May 11, 2014–February 15, 2015)  |   |   |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n|  I | Disruption and both | Kin(R) ↔ Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) ↔ Kin(R) | Kin(U) ↔ Kin(R) | Kin(U) → Kin(G)  |\n|  ID | Cyber | GCT(w) | VD(d) (30 day) | VD(w) (12 week) |  |  |   |\n|  I | Disruption and both |  | Kin(R) → 7%Kin(U) | Kin(R) → 10%Cyb(R) |  |  |   |\n|   |   |   | Kin(R) → 2%Cyb(R) | Kin(U) → 21%Kin(R) |  |  |   |\n|   |   |   | Kin(U) → 12%Kin(R) | Kin(U) → 17%Cyb(R) |  |  |   |\n|   |   |   | Kin(U) → 2%Cyb(R) | Cyb(U) → 4%Cyb(R) |  |  |   |\n|  ID | Cyber | IRF(d) | IRF(w) | GCT(d) | GCT(w) | VD(d) (30 day) | VD(w) (12 week)  |\n|  Ukraine (March 22, 2014–February 29, 16)  |   |   |   |   |   |   |   |\n|  2 | All | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U/R) ↔ Kin(U) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Cyb(U) ↔ Kin(R) |  |  | Kin(U) → 3%Cyb(R)  |\n|  3 | Propaganda | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin(U)/Cyb(R) | Kin(R) → 3%Kin(U) | Kin(R) → 9%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) → Kin/Cyb(R) | Kin(U) → Cyb(R) | Kin(U) → 18%Kin(R) | Kin(R) → 3%Cyb(R)  |\n|   |   |   | Cyb(U) → Kin(U) | Kin(U) → Cyb(R) |  |  | Kin(U) → 46%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(R)  |\n|  4 | Disruption | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(U/R) |  | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|  5 | Disruption and both | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(R) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Kin(U) → Cyb(U) |  |  |   |\n\n(continued)",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 18,
            "markdown": "Table 5. (continued)\n\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) Ukraine (May 11, 2014-February 11, 2015) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  6 | All | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) |  | Kin(R) → 7%Kin(U) | Kin(R) → 2%Cyb(U)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(U) → 13%Kin(R) | Kin(R) → 18%Cyb(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 30%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(U/R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 4%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(U)  |\n|  7 | Propaganda | Kin(R) → Kin(U) | Cyb(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Cyb(R) | Kin(R) → 7%Kin(U) | Kin(U) → 27%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) |  |  | Kin(U) → 13%Kin(R) | Kin(U) → 4%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 3%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 9%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 20%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 5%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(R) → 2%Cyb(U)  |\n|  8 | Disruption | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → Cyb(U) | Kin(R) → 7%Kin(U) | Kin(U) → 29%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(R) → 2%Cyb(R) | Kin(U) → 34%Cyb(U)  |\n|   |   |   |  |  |  | Kin(U) → 12%Kin(R) | Kin(U) → 22%Cyb(R)  |\n|   |   |   |  |  |  | Cyb(R) → 2%Kin(U) | Kin(R) → 3%Kin(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 10%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 13%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 6%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 7%Cyb(U)  |\n\nSyria (March 17, 2011-July 10, 2016)\n\n|  9 | Disruption and both | Kin(G) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → 2%Kin(R)  |\n| --- | --- | --- | --- | --- |\n\nNote: IRF = impulse response functions; GCT = Granger causality tests; VD = variance decomposition; d = daily; w = weekly; o = alternative orderings; RU = Russian; U = Ukrainian.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 19,
            "markdown": "The first explanation for coercive failure emphasizes limited resources and capabilities, particularly for the Ukrainian government. Ten years ago, the SBU briefly had a cyber department but shut it down after a year (Kostyuk and Zhukov 2017, #3). This unit has recently reopened but continues to lack funding and personnel (Kostyuk and Zhukov 2017, #3, #9). It is possible that, with adequate resources, capabilities, and human capital, the Ukrainian cyber campaign might have been more effective. Resource constraints, however, do not explain coercive failure on the pro-Russian side, where investment in cyber capabilities is more robust.\n\nA second explanation is lack of government coordination with hackers, especially in Kyiv (Maurer and Geers 2015). UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success (Kostyuk and Zhukov 2017, #1). The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place (Kostyuk and Zhukov 2017, #1, #3, #9). Yet again, this explanation is less plausible on the pro-Russian side, where the Kremlin has cultivated extensive ties with non-state hacktivists.\n\nA third explanation is that—even with requisite capabilities and coordination—there are few opportune targets for disruption in Ukraine. Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult (Geers 2015; Kostyuk and Zhukov 2017, #3, #13). Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack” (Kostyuk and Zhukov 2017, #11). The 2015 and 2016 hacks of Ukraine's power grid also seem to challenge this explanation.\n\nThe peculiarities of Ukraine's online population represent a fourth explanation for the indecisiveness of cyber attacks. Since only 44.1 percent of Ukrainians have Internet access—compared to 88.5 percent in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses (Kostyuk and Zhukov 2017, #3). Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones (Kostyuk and Zhukov 2017, #7, #11). Our data suggest that, even if this were the case, propagandistic attacks still had no effect on violence.\n\nThe final explanation is that cyber compellence failed because it was never seriously attempted. At first, our interviews with individual hackers revealed no shortage of coercive intent. UCF leader Eugene Dokukin claimed to conduct low-level attacks daily and vowed to continue until pro-Russian rebels lay down their arms. Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns (Kostyuk and Zhukov 2017, #1).\n\nWhile UCF and other nonstate groups have explicitly sought to affect battlefield outcomes, some interviewees questioned whether this intent extended to the Russian",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 20,
            "markdown": "government. Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place (Kostyuk and Zhukov 2017, #5, #12). This access, along with vigorous cyber espionage—some of it ongoing since 2010—may create incentives against more aggressive actions, which could compromise valuable sources of intelligence.\n\nConsistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda (Kostyuk and Zhukov 2017, #11). When in 2011 Vyacheslav Volodin replaced Vladislav Surkov as head of the Presidential Administration, he toughened existing laws against Russia's opposition and promoted the use of mass media and online platforms—tools already mostly under state control—to conduct information campaigns. If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising (Kostyuk and Zhukov 2017, #2, #14).\n\n## Evidence beyond Ukraine: Syria's Digital Front\n\nAccording to evidence from microlevel data and interviews, cyber attacks did not affect battlefield events in Ukraine. During one of the first armed conflicts where both sides used low-level cyber actions extensively, events in the digital realm have unfolded independently of—and have had no discernible effect on—events on the ground. Conditions in Ukraine were in many ways optimal to observe the coercive impact of cyber actions, for reasons we already discussed (i.e. visibility of major attacks, regular claims of responsibility, less uncertainty over attribution). Yet we found no evidence that low-level cyber attacks affected physical violence. Nor did hackers on each side even affect each other's activities.\n\nWhile important, Ukraine is not the only contemporary conflict with a significant cyber dimension. In Syria, state and nonstate actors have employed low-level cyber actions extensively for propaganda and disruption, complementing traditional tools of warfare in the deadliest conflict ongoing today. Syria's war has also lasted three years longer than Ukraine's. Over this time, its digital front has expanded in scope and sophistication, offering a glimpse of cyber coercion in a more protracted setting.\n\nAn in-depth study of Syria's digital front lies beyond the scope of this article. A brief analysis of the data, however, suggests that our findings from Ukraine may be part of a broader pattern: cyber capabilities have not yet evolved to the point of having an impact on physical violence.\n\nTo evaluate the effectiveness of cyber compellence in this second case, we replicated the model in (equation 1), using an analogous daily time series of cyber attacks and violent events in Syria. Our data comprise 9,282 kinetic and 682 low-level cyber attacks ranging from March 2011 until July 2016. Table 2 provides a breakdown of cyber techniques used in the Syrian conflict, their brief description, and frequency. Our data on kinetic operations rely on human-assisted machine",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 21,
            "markdown": "Journal of Conflict Resolution 63(2)\n\n![img-2.jpeg](img-2.jpeg)\n\n![img-3.jpeg](img-3.jpeg)\nFigure 3. Cyber and kinetic operations in Syria (March 2011-July 2016). G (blue) indicates operations by pro-Assad government forces; R (red) indicates operations by anti-Assad rebel groups.\n\ncoding of event reports from the International Institute for Strategic Studies Armed Conflict Database (see Online Appendix for details).\n\nGiven the complex nature of the Syrian conflict and the multiple parties involved, we restrict our analysis only to operations by progovernment forces (i.e., Syrian Army, Hezbollah and pro-Assad militias) and the main rebel opposition (i.e., Free Syrian Army, Jaish al-Fatah, including Al Nusra Front). Table 1 provides a list of cyber actors in the Syrian conflict, their targets, and frequency of their activities.\n\nThe dynamics of cyber and kinetic operations in Syria exhibit similar patterns to what we saw in Ukraine. Raw data (Figure 3a and b) suggest relatively little overlap in timing, especially at the beginning of the conflict. The IRF curves in Figure 4 show a rise in rebel operations following shocks to government operations (second row, first column), and mostly negligible (though negative) links between cyber and kinetic operations, and across cyber attacks by each actor. Links between kinetic",
            "images": [
              {
                "id": "img-2.jpeg",
                "top_left_x": 138,
                "top_left_y": 207,
                "bottom_right_x": 1057,
                "bottom_right_y": 612,
                "image_base64": null,
                "image_annotation": null
              },
              {
                "id": "img-3.jpeg",
                "top_left_x": 138,
                "top_left_y": 626,
                "bottom_right_x": 1047,
                "bottom_right_y": 1029,
                "image_base64": null,
                "image_annotation": null
              }
            ],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 22,
            "markdown": "|  Response: |   |\n| --- | --- |\n|  Kinetic (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380 385 390 395  |\n|  Kinetic (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295  |\n|  Cyber (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 260 270 275  |\n|  Cyber (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230  |\n|  Impulse: | Kinetic (G) Kinetic (R) Cyber (G) Cyber (R)  |\n\nFigure 4. Impulse response matrix, daily time series (Syria). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"G\" indicates reported kinetic and cyber operations by pro-Assad government forces, and \"R\" indicates operations by anti-Assad rebel forces.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 23,
            "markdown": "operations—and their disconnect from cyber attacks—are also evident in variance decomposition results, and Granger tests, provided in the Online Appendix.\n\nThere are several reasons for caution in interpreting these results. The Syrian conflict involves a larger constellation of actors than Ukraine, and our dyadic analysis may overlook significant interactions elsewhere, particularly between actors with more developed cyber capabilities (e.g. Russia, United States). We also lack interview evidence that might help contextualize the null effect. However tentative, these results do align with what we saw in Ukraine: low-level cyber attacks have had little or no impact on violence.\n\n## Conclusion\n\nThe evidence we presented in this article—based on analysis of new data and expert interviews—suggests that cyber attacks are ineffective as a tool of coercion in war. Although kinetic operations explain the timing of other kinetic operations, low-level cyber attacks have no discernible effect on violence in the physical world. In Ukraine and Syria, the “cyberwar” has unfolded in isolation from the rest of the conflict.\n\nThis finding has several implications for theory and policy. First, by providing the first statistical analysis of modern low-level cyber campaigns, our study complements the qualitative focus of previous empirical work. Second, our research sheds light on a theoretical question about the strength and direction of the cyber--kinetic relationship and—in so doing—begins to fill an empirical gap in political science literature on this topic. Third, to the extent that policymakers might overestimate the importance of cyber actions due to a lack of empirical evidence to the contrary, our findings can potentially help correct this misperception. Finally, and more worryingly, our results suggest that—due to their disconnect from physical violence—low-level cyber attacks are very difficult to predict.\n\nFurther research is needed to understand the dynamics of low-level cyber attacks. One such area of research is cyber coercion in the context of symmetric, conventional war. While our study helps illuminate dynamics of cyber compellence between parties with asymmetric capabilities, we may well observe different patterns when major powers use cyberspace against peer competitors. Thankfully, no armed conflict has yet provided researchers with the data needed to evaluate this possibility.\n\nSecond, our scope in this article has been exclusively on short-term military consequences rather than long-term political effects. The latter are no less theoretically significant, but—unlike simple counts of violent events—potentially more difficult to measure and analyze. A study of long-term political effects would also need to more systematically incorporate purely propagandistic cyber activities and their impact on public opinion, which we omitted here due to our focus on short-term military compellence.\n\nAlthough the secretive nature of many ongoing physical and digital operations is a challenge for this research, questions over the coercive potential of cyber attacks",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 24,
            "markdown": "will become only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” (Sabah 2016)—have yielded few tangible successes (Sanger and Schmitt 2017). Our data from Ukraine indicate that the US experience may be part of a broader pattern.\n\nAt best, coordination between low-level cyber and kinetic operations today is on roughly the same level as that between airpower and ground operations in World War I. Back then, armies were increasingly using aircraft for reconnaissance and surveillance on the front but were not yet able to fully exploit their potential for ground combat support and strategic bombing. That revolution appeared on the battlefield twenty-five years later, with devastating effect. As cyber capabilities develop and synchronization challenges become less severe, there will be a growing need for assessments of how far we have come. We hope that analyses of the sort we provided in these pages can serve as an early benchmark.\n\n## Authors' Note\n\nA previous version of this article was presented at the 2015 Peace Science Society International annual meeting, Oxford, MS, and at the Association for the Study of Nationalities Convention at New York, NY.\n\nWe are grateful to Maura Drabik, Paulina Knoblock, Neil Schwartz, and Alyssa Wallace for excellent research assistance. Robert Axelrod, Myriam Dunn-Cavelty, Eric Gartzke, Miguel Gomez, Todd Lehmann, Jon Lindsay, Tim Maurer, Brandon Valeriano, Christopher Whyte, and workshop participants of the Conflict & Peace, Research & Development workshop at the University of Michigan, of the Bridging the Gap Workshop on Cyber Conflict at Columbia University, of the Cross-Domain Deterrence lab at the University of California, San Diego, and of the Center for Security Studies at ETH Zurich provided helpful comments on the earlier drafts of this article.\n\n## Declaration of Conflicting Interests\n\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n## Funding\n\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.\n\n## Supplemental Material\n\nSupplemental material for this article is available online.\n\n## Notes\n\n1. We define coercion as an attempt to influence a target's behavior by increasing the costs associated with an unwanted action. Cyber activities apply these costs through the",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 25,
            "markdown": "disruption, destruction, malicious control, or surveillance of a computing environment or infrastructure (Kissel 2013). Kinetic or physical operations apply costs through physical force. Low-level cyber attacks cause minor disruptions and include web-page defacements, phishing, distributed denial of service attacks. High-level cyber attacks include serious disruption with loss of life and extensive infrastructure disruption.Deterrence seeks to convince a target to not start an unwanted action. Compellence seeks to convince the target to stop an ongoing unwanted action.We use propaganda when referring to the propaganda category, cyber attacks when referring to disruption (Cartwright and James 2010), and hybrid cyber operations when referring to hybrids of the two.For example, US Cyber Command has used low-level cyber operations to “disrupt the ability of the Islamic State to spread its message, attract new adherents, circulate orders from commanders and [pay] its fighters” (Sanger 2016).A zero-day vulnerability is a security hole previously unknown to the target.This trade-off is not unique to the cyber domain. In civil conflict, for example, pro-government militias pose a similar dilemma for state repression (Gohdes and Carey 2017).Another potentially illuminating case, which we are unable to analyze here, is the Russian--Georgian War of 2008. This earlier conflict laid much of the groundwork for the crisis in Ukraine. For the first time in history, cyberspace played a highly visible role in armed conflict, facilitating strategic communication between civilian and military leadership, disabling or degrading key infrastructure, exploiting or hijacking government computer systems, while also serving as a tool for propaganda (Deibert, Rohozinski, and Crete-Nishihata 2012). While some of the lessons of the Russian--Georgian War might well run counter to our claims in this article, its short duration (five days) complicates analysis, for three reasons. First is a lack of sufficient variation in cyber attacks over this abbreviated period. Second is the difficulty of differentiating the “cyber effect” from the near-simultaneous effects of conventional military operations. Third is the problem of generalizability: its five-day duration is an extreme outlier among interstate and civil wars (interstate wars, on average, tend to last a few years; the average civil war lasts between seven and twelve years post-1945). For these reasons, we are unable to quantitatively establish whether synchronized usage of cyberspace, along with traditional tools of war, had a tangible coercive impact in Georgia.Sections 3.1 and 3.2 along with the Online Appendix provide an overview of these sources.Rebel sources include Donetsk News Agency. Russian sources include RIA Novosti, Sputnik, and Vesti.ru. Ukrainian sources include Interfax-Ukraine, Segodnya, and RBK-Ukraina. Western sources include technical (Arstechnica, Digital Dao, Information Week, F-Secure, Graham Cluley, and TechWeek Europe) and mainstream news (Die Welt, Newsweek, New York Times, Politico, Postimees (Estonia), Security Affairs, and The Christian Science Monitor).Our Ukrainian interviewees included experts from the Ukrainian Cyber Forces, Computer Emergency Response Team of Ukraine, StopFake, InfoPulse, Luxoft, Berezha Security,",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 26,
            "markdown": "Open Ukraine Foundation, and the Ukrainian Central Election Committee. Western experts' affiliations include New York University, Chatham House, the Center for Strategic and International Studies, RAND Corporation, The Economist, Mashable, New America Foundation, and the North Atlantic Treaty Organization Cyber Center of Excellence. Due to the complicated political situation in Russia at the time, many of our contacts there refused to speak on record, with the exception of a journalist from Agentura.ru. However, many Western interviewees have lived in Russia, speak the language, and are knowledgeable on Russia's information security issues.This is a very conservative standard of attribution, since it includes only direct claims of responsibility and not accusations by others—even if the latter are substantiated by evidence. For instance, we marked as “disputed” the cyber espionage operation Armageddon—which multiple governments and private security firms have attributed to the Russian state—because Moscow never claimed responsibility.Excluded operations included the malware Blackenergy, first launched by Quedagh in 2010; Operation Potao Express, a targeted espionage campaign launched in 2011 against the Ukrainian government, military, and news agencies; and Snake, a cyber espionage campaign against Ukrainian computer systems.We aggregated these data to daily time series because geolocation is not possible. Although some individual cyber attacks could, in theory, be tracked to their targets, they represent a small proportion of events. As a result, our cyber data are national-level time series. Even if we could geolocate all targets of cyber attacks, the diffuse nature of the target set makes spatial matching difficult—servers do not need to be physically located in the war zone for service disruptions to have an effect in the war zone.Ukrainian sources include Channel 5, Espresso.tv, Information Resistance, 112 Ukraina, and the newswire services Interfax-Ukraine and Ukrinform. Russian sources include the state-owned television news channel Russia-24; the independent TV station Dozhd; nongovernment news websites Gazeta.ru, Lenta.ru, and BFM.ru; and the Interfax newswire service. Pro-rebel sources include Donetsk News Agency, NewsFront, and Rusvesna.su. Also included are the Russian language edition of Wikipedia and daily briefings from the Organization for Security and Co-operation in Europe Special Monitoring Mission to Ukraine. Since these are mostly online resources, cyber disruptions can potentially cause underreporting of violence. Our approach helps ensure that if, for instance, a Ukrainian media firms' servers went down, information could still reach the outside world through one of the sixteen other sources. While unlikely, such endogenous disruptions should increase our chances of finding a coercive cyber effect.Because geolocation is not possible for cyber attacks, we aggregate the physical violence data to daily time series to merge and analyze the data sets.Vector autoregression is a common method to study interdependence among multiple time series in economics and political science. Previous applications to conflict research include studies of reciprocity in civil conflicts (Pevehouse and Goldstein 1999) and the dynamics of terrorism (Enders and Sandler 2000; Bejan and Parkin 2015).An example is Russia's Sistema operativno-rozysknykh meropriyatiy (system for operational investigative activities), which searches and monitors electronic communications.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 27,
            "markdown": "18. Sources of cyber operations include social media accounts of anonymous or anonymous-supported groups (e.g. New World Hacking); Syrian Electronic Army's social media accounts; reports by tech companies (e.g. risk-based security, Electronic Frontier Foundation); computer-security news sources including Graham Cluley, TechWeek Europe, Arstechnica, Information Week, Digital Dao, Computer Weekly, Tech News, Wired, and Security Affairs; Middle Eastern mass media sources (e.g. Turkish News, Arabiya, Doha News); Russian mass media and social media (e.g. RT.com, Yahoo.com); and Western news sources (e.g. Security Affairs, The Christian Science Monitor, Politico, Die Welt, Reuters, International Business Times, Mashable, Washington Times, The Guardian, British Broadcasting Corporation, etc.).Since propaganda operations are not a major focus of our article, we collected only a small sample of such events during the Syrian conflict.\n\n## References\n\nAndres, Richard. 2012. “The Emerging Structure of Strategic Cyber Offense, Cyber Defense, and Cyber Deterrence.” In Array Cyberspace and National Security: Threats, Opportunities, and Power in a Virtual World, 1st ed. translated by Derek S. Reveron, 89-104. Washington, DC: Georgetown University Press.\n\nAndress, Jason, and Steve Winterfeld. 2013. Cyber Warfare: Techniques, Tactics and Tools for Security Practitioners. Boston, MA: Elsevier.\n\nAtran, Scott. 2003. “Genesis of Suicide Terrorism.” Science 299 (5612): 1534-39.\n\nAxelrod, Robert. 2014. “A Repertory of Cyber Analogies.” In Cyber Analogies, edited by Emily O. Goldman and John Arquilla. Monterey, CA: Department of Defense Information Operations Center for Research.\n\nAxelrod, Robert, and Rumen Iliev. 2014. “Timing of Cyber Conflict.” Proceedings of the National Academy of Sciences 111 (4): 1298-303.\n\nBailard, Catie Snow. 2015. “Ethnic Conflict Goes Mobile: Mobile Technology's Effect on the Opportunities and Motivations for Violent Collective Action.” Journal of Peace Research 52 (3): 1-15.\n\nBaum, Matthew A. and Yuri M. Zhukov. 2015. “Filtering Revolution: Reporting Bias in International Newspaper Coverage of the Libyan Civil War.” Journal of Peace Research 9:10-11.\n\nBejan, Vladimir, and William S. Parkin. 2015. “Examining the Effect of Repressive and Conciliatory Government Actions on Terrorism Activity in Israel.” Economics Letters 133:55-58.\n\nCartwright, James, and W. James. 2010. Joint Terminology for Cyberspace Operations. Memorandum. Washington, DC: Joint Chiefs of Staff (JCS).\n\nCha, Victor D. 2000. “Globalization and the Study of International Security.” Journal of Peace Research 37 (3): 391-403.\n\nClarke, Richard A. and Robert K. Knake. 2010. Cyber War: The Next Threat to National Security and What to Do about It. The Library of Congress. New York: Harper Collins.\n\nCrabtree, Charles, David Darmofal, and Holger L Kern. 2014. “A Spatial Analysis of the Impact of West German Television on Protest Mobilization during the East German Revolution.” Journal of Peace Research 52: 269-84.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 28,
            "markdown": "Kostyuk and Zhukov\n345\n\nCzosseck, Christian, and Kenneth Geers. 2009. The Virtual Battlefield: Perspectives on Cyber Warfare, vol. 3. Amsterdam, the Netherlands: IOS Press.\n\nDavenport, Christian, and Allan Stam. 2006. \"Rashomon Goes to Rwanda: Alternative Accounts of Political Violence and Their Implications for Policy and Analysis.\" Unpublished manuscript. Accessed January 15, 2017. http://www.gvpt.umd.edu/davenport/dcawcp/paper/mar3104.pdf.\n\nDeibert, Ronald J., Rafal Rohozinski, and Masashi Crete-Nishihata. 2012. \"Cyclones in Cyberspace: Information Shaping and Denial in the 2008 Russia-Georgia War.\" *Security Dialogue* 43 (1): 3-24.\n\nEnders, Walter, and Todd Sandler. 2000. \"Is Transnational Terrorism Becoming More Threatening? A Time-series Investigation.\" *Journal of Conflict Resolution* 44 (3): 307-32.\n\nEun, Yong-Soo, and Judith Sita Aßmann. 2014. \"Cyberwar: Taking Stock of Security and Warfare in the Digital Age.\" *International Studies Perspectives* 17:343-60.\n\nGartzke, Erik. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.\" *International Security* 38 (2): 41-73.\n\nGeers, Kenneth. 2015. Cyber War in Perspective: Russian Aggression against Ukraine. Tallinn, Estonia: CCDCOE.\n\nGohdes, Anita R. 2014. \"Pulling the Plug: Network Disruptions and Violence in Civil Conflict?\" *Journal of Peace Research* 52 (3): 352-67.\n\nGohdes, Anita R., and Sabine C. Carey. 2017. \"Canaries in a Coal-mine? What the Killings of Journalists Tell Us about Future Repression.\" *Journal of Peace Research* 54 (2): 157-74.\n\nGriniaiev, Sergei. 2004. \"Pole bitvy: kiberprostranstvo [The battlefield is cyberspace].\" (Po materialam inostrannoj pechati /) Mn: Harvest.\n\nHare, Forrest. 2012. \"The Significance of Attribution to Cyberspace Coercion: A Political Perspective.\" In 2012 4th International Conference on Cyber Conflict (CYCON 2012, edited by C. Czosseck, R. Ottis, and K. Ziolkowski, 1-15. Tallinn, Estonia: NATO CCD COE\n\nHealey, Jason. 2013. A Fierce Domain: Conflict in Cyberspace, 1986 to 2012. Arlington, VA: Cyber Conflict Studies Association.\n\nIl'chenko, Oleksandr. 2016. \"Rozstily Oleha Kalashnikova i Olesya Buzyny - rik potomu [Shootings of Oleg Kalashnikov of Oles Buzina—a year later].\" Segodnya.\n\nJunio, Timothy J. 2013. \"How Probable Is Cyber War? Bringing IR Theory Back In to the Cyber Conflict Debate.\" *Journal of Strategic Studies* 36 (1): 125-33.\n\nKello, Lucas. 2013. \"The Meaning of the Cyber Revolution: Perils to Theory and Statecraft.\" *International Security* 38 (2): 7-40.\n\nKissel, Richard. 2013. Glossary of Key Information Security Terms. NISTIR 7298, Revision 2. Gaithersburg, MD: National Institute of Standards and Technology, the US Department of Commerce.\n\nKostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*.\n\nLemay, Antoine, José M. Fernandez, and Scott Knight. 2010. \"Pinprick Attacks, A Lesser Included Case.\" In Conference on Cyber Conflict Proceedings, edited by C. Czosseck and K. Podins, 183-94. Tallinn, Estonia: CCD COE.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 29,
            "markdown": "Journal of Conflict Resolution 63(2)\n\nLibicki, Martin C. 2007. Conquest in Cyberspace: National Security and Information Warfare. Cambridge, MA: Cambridge University Press.\nLibicki, Martin C. 2009. Cyberdeterrence and Cyberwar. Santa Monica, CA: Rand Corporation.\nLibicki, Martin C. 2011. \"Cyberwar as a Confidence Game.\" Strategic Studies Quarterly 5 (1): 132-46.\nLibicki, Martin C. 2015. \"The Cyberwar that Wasn't.\" In Cyber War in Perspective: Russian Aggression against Ukraine, edited by Kenneth Geers, 49-54. Tallinn, Estonia: NATO Cyber Center of Excellence, NATO CCD COE.\nLiff, Adam P. 2012. \"Cyberwar: A New 'Absolute Weapon'? The Proliferation of Cyberwarfare Capabilities and Interstate War.\" Journal of Strategic Studies 35 (3): 401-28.\nLynn, William J. 2010. \"Defending a New Domain: The Pentagon's Cyberstrategy.\" *Foreign Affairs* 89 (5): 97-108.\nMartin-Shields, Charles Patrick. 2013. \"Inter-ethnic Cooperation Revisited: Why Mobile Phones can Help Prevent Discrete Events of Violence, Using the Kenyan Case Study.\" Stability: International Journal of Security and Development 2 (3): Art. 58.\nMaurer, Tim, and Kenneth Geers. 2015. \"Cyber Proxies and the Crisis in Ukraine.\" In Cyber War in Perspective: Russian Aggression against Ukraine, edited by Kenneth Geers, 79-86. Tallinn, Estonia: NATO Cyber Center of Excellence, NATO CCD COE.\nMcGraw, Gary. 2013. \"Cyber War is Inevitable (Unless We Build Security In).\" Journal of Strategic Studies 36 (1): 109-19.\nNye, Joseph S., Jr. 2010. Cyber Power. Cambridge, MA: Belfer Center for Science and International Affairs, Harvard Kennedy School.\nOttis, Rain. 2010. \"From Pitch Forks to Laptops: Volunteers in Cyber Conflicts.\" In Conference on Cyber Conflict Proceedings 2010, edited by C. Czosseck and K. Podins, 97-109. Tallinn, Estonia: CCD COE.\nPape, Robert A. 2003. \"The Strategic Logic of Suicide Terrorism.\" American Political Science Review 97 (03): 343-61.\nPape, Robert A. 2014. Bombing to Win: Air Power and Coercion in War. Ithaca, NY: Cornell University Press.\nPevehouse, Jon C., and Joshua S. Goldstein. 1999. \"Serbian Compliance or Defiance in Kosovo? Statistical Analysis and Real-time Predictions.\" Journal of Conflict Resolution 43:538-46.\nPierskalla, Jan H., and Florian M. Hollenbach. 2013. \"Technology and Collective Action: The Effect of Cell Phone Coverage on Political Violence in Africa.\" American Political Science Review 107 (02): 207-24.\nRid, Thomas. 2012. \"Cyber War Will Not Take Place.\" Journal of Strategic Studies 35 (1): 5-32.\nRios, Billy K. 2009. \"Sun Tzu was a Hacker: An Examination of the Tactics and Operations from a Real World Cyber Attack.\" The Virtual Battlefield: Perspectives on Cyber Warfare 3:143.\nSabah, Daily. 2016. \"Cyber Bombs Being Used to Destroy Daesh: US Defense Chief.\" February 29, 2016. Accessed March 15, 2017. https://www.dailysabah.com/mideast/2016/02/29/cyber-bombs-being-used-to-destroy-daesh-us-defense-chief.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          },
          {
            "index": 30,
            "markdown": "Kostyuk and Zhukov\n347\n\nSanger, David E. 2016. \"U.S. Cyberattacks Target ISIS in a New Line of Combat.\" The New York Times. Accessed March 15, 2017. https://www.nytimes.com/2016/04/25/us/politics/us-directs-cyberweapons-at-isis-for-first-time.html?_r=0.\n\nSanger, David E., and Eric Schmitt. 2017. \"U.S. Cyberweapons, Used Against Iran and North Korea, Are a Disappointment Against ISIS.\" New York Times, p. A5. Accessed June 15, 2017. https://www.nytimes.com/2017/06/12/world/middleeast/isis-cyber.html.\n\nSchelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale.\n\nSchmitt, Michael N. 1999. \"Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework.\" *Columbia Journal of Transnational Law* 37: 1998-99.\n\nSharma, Amit. 2010. \"Cyber Wars: A Paradigm Shift from Means to Ends.\" *Strategic Analysis* 34 (1): 62-73.\n\nValeriano, Brandon, and Ryan C. Maness. 2014. \"The Dynamics of Cyber Conflict between Rival Antagonists, 2001-11.\" *Journal of Peace Research* 51 (3): 347-60.\n\nWeidmann, Nils B. 2015. \"Communication, Technology, and Political Conflict Introduction to the Special Issue.\" *Journal of Peace Research* 52 (3): 263-68.\n\nWoolley, John T. 2000. \"Using Media-based Data in Studies of Politics.\" *American Journal of Political Science* 44:156-73.\n\nZetter, Kim. 2017. \"The Ukrainian Power Grid Was Hacked Again.\" *Motherboard*. Accessed June 15, 2017. http://bit.ly/2jEUqW3.",
            "images": [],
            "dimensions": {
              "dpi": 200,
              "height": 1800,
              "width": 1200
            }
          }
        ],
        "model": "mistral-ocr-latest",
        "usage_info": {
          "pages_processed": 31,
          "doc_size_bytes": 512575
        },
        "document_annotation": null
      }
    },
    "error": null
  },
  "full_text": "Check for updates\nArticle\n# Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\nJournal of Conflict Resolution\n2019, Vol. 63(2) 317-347\n© The Author(s) 2017\nArticle reuse guidelines:\nsagepub.com/journals-permissions\nDOI: 10.1177/0022002717737138\njournals.sagepub.com/home/jcr\nSAGE\nNadiya Kostyuk¹, and Yuri M. Zhukov¹\n## Abstract\nRecent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.\n## Keywords\ncompellence, coercion, physical violence, conflict, cyber attacks\nOn December 23, 2015, hackers attacked Ukraine’s power grid, disabling control systems used to coordinate remote electrical substations, and leaving people in the capital and western part of the country without power for several hours. The Security\n¹Department of Political Science, University of Michigan, Ann Arbor, MI, USA\n## Corresponding Author:\nNadiya Kostyuk, Department of Political Science, University of Michigan, 505 S State Street, Ann Arbor, MI 48109, USA.\nEmail: nadiya@umich.edu\nService of Ukraine (SBU) blamed the Russian government for the cyber attack, an accusation that later found support in malware analysis by a private computer security firm. The Ukrainian hack was the first publicly acknowledged case of a cyber attack successfully causing a power outage. It is also just one of thousands of cyber activities, mostly diffuse and low level, that have occurred alongside physical fighting in Ukraine. Attacks launched through the digital realm are playing an increasingly visible role in civil and interstate conflict—in Ukraine, Syria, Israel, Estonia, Georgia, and beyond. Yet it remains unknown whether such activities have a real coercive impact on the battlefield.\nRecent years have seen growing concern over the coercive potential of cyber capabilities in war, but little evidence that these new tools are yet making a difference. Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence (Libicki 2009; Sharma 2010; Andres 2012). Yet the logic of coercion entails distinct challenges in peace and war, with potentially different implications for the cyber domain. Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist (Valeriano and Maness 2014) privilege massive cyber catastrophes over less sophisticated low-intensity attacks, like distributed denial of service (DDoS). The latter category, however, is far more common.\nThis article asks whether cyber attacks can compel short-term changes in battlefield behavior, using new event data on cyber and kinetic operations from armed conflicts in Ukraine and Syria. We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides (Geers 2015), and—uniquely—overt claims of responsibility, public damage assessments, and other releases of information that reduce uncertainty over timing and attribution. Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques” (Zetter 2017). If cyber attacks can yet make a difference on the battlefield, Ukraine is one a few cases where we are most likely to observe such an effect. Our data include 1,841 unique cyber attacks and 26,289 kinetic operations by government and prorebel forces between 2014 and 2016. We supplement this quantitative analysis with fourteen primary source interviews with participants in the cyber campaign as well as Ukrainian, Russian, and Western cyber security experts with direct knowledge of these operations.\nTo evaluate the generalizability of the Ukrainian experience to other conflicts, we replicate our results with data from Syria's civil war. Like Ukraine, Syria has seen the extensive use of low-level cyber attacks by factions fighting for and against the incumbent regime. Because this war has gone on significantly longer than the conflict in Ukraine—giving hackers more time to organize and develop their capabilities—Syria offers a glimpse at cyber activities in a more protracted, higher intensity context. If we uncover similar patterns in two conflicts of such different scale and complexity, we can have greater confidence that our results are not artifacts of a single idiosyncratic case. Our data include 682 cyber attacks and 9,282 acts of violence by pro- and anti-Assad forces between 2011 and 2016.\nEvidence from both conflicts suggests that cyber attacks have not created forms of harm and coercion that visibly affect their targets' actions. Short of mounting synchronized, coordinated cyber campaigns, each group of hackers has seemed to operate in its own “bubble,” disengaged from unfolding events in both cyberspace and the physical world. The lack of discernible reciprocity between cyber and kinetic operations—and between the cyber actors themselves—questions whether cyber attacks can (yet) be successfully deployed in support of military operations.\nThis disconnect may be temporary, as joint planning and execution concepts continue to evolve. Many countries, for instance, still struggle in coordinating air-power for ground combat support, a century after World War I. Our study highlights some of the difficulties that countries will need to overcome in integrating and synchronizing these new capabilities.\nOur contribution is fourfold. We offer the first disaggregated analysis of cyber activities in war and take stock of the empirical relationship between the cyber and kinetic dimensions of modern battle. To do so, we collect the first microlevel data on wartime cyber attacks, using both open media sources and anonymous attack traffic data. Theoretically, our analysis addresses an important question on the coercive impact of low-level cyber attacks, advancing a literature that has been heavy on deductive argumentation, but light on evidence. Finally, from a policy standpoint, our findings should temper the popular tendency to overhype the transformative potential of cyber attacks. At present, interaction between cyber and kinetic operations is similar to that between airpower and ground operations in World War I—when armies began to use aircraft for reconnaissance but had not realized their full potential to shape battlefield outcomes.\n## Varieties of Cyber Activity\nThe term “cyber activities” captures a diverse assortment of tactics and procedures, directed against different types of targets, in pursuit of disparate objectives. Not all of these activities seek to achieve battlefield effects in the same way. Before proceeding further, we differentiate between two broad goals these actions tend to pursue: propaganda and disruption.\nCyber activities in the propaganda category seek to influence public opinion and indirectly undermine an opponent's financing or recruitment. Operations in this group include leaks of compromising private information, online publication of partisan content (e.g. “trolling” on comments pages), and the establishment of dedicated websites and forums to promote an armed group's message. Unless it openly incites or discourages violence, propaganda affects kinetic operations only indirectly by undermining an opponent's support base or obfuscating perceptions of events.\nIn the Ukrainian conflict, the importance of both groups attach to online propaganda is evident from the time and resources pro-Kyiv fighters spend updating Wikipedia, and pro-Russia groups devote to creating and running dedicated\nYouTube channels and social media accounts. Russian military doctrine places a heavy emphasis on the strategic use of information in warfare, as does US cyberspace joint planning doctrine.\nThe second category of cyber attacks—disruption—seeks to directly sabotage opponents' ability to operate in the physical or electronic realm. These mostly low-intensity activities include denial of service attacks, which make targeted resources unavailable through a flood of requests from a single source, and DDoS attacks, where requests originate from multiple compromised systems. Related efforts include inundating communications systems with floods of text messages or phone calls and using fire walls and proxies to block access to websites. At the extreme end of the scale is the use of malicious code to inflict physical damage or otherwise compromise infrastructure and military objects. Examples include interception of drones, communications and surveillance systems, control of Wi-Fi access points, and collection of protected information via phishing.\nThe most sophisticated known attack of this type is the Stuxnet worm, which—before its discovery in 2010—targeted industrial control systems critical to uranium enrichment in Iran. In Ukraine, notable disruptive activities have included attacks on the Central Election Committee's website during the 2014 presidential elections and attacks on the country's power grid in 2015 and 2016. Other examples include the use of malware to collect operational intelligence, like X-Agent, which retrieved locational data from mobile devices used by Ukrainian artillery troops, and the hacking of closed-circuit television (CCTV) cameras behind enemy lines.\nPropaganda and disruption are not mutually exclusive, and many cyber activities serve both purposes—shaping public opinion through disruption or disrupting an opponent's operations by shaping public opinion. For example, altering the visual appearance of websites can have the dual effect of embarrassing the target and limiting its ability to communicate. Leaks of private information also have dual implications for targets' public image and physical security.\nRecent examples of hybrid activities include the defacement of US Central Command's Twitter and Facebook pages by the Islamic State's (IS) Cyber Caliphate and operations by US Cyber Command against IS beginning in April 2016. In Ukraine, the pro-rebel group CyberBerkut (CB) has leaked private communications from senior United States, European Union, and Ukrainian officials and disclosed identities of pro-Kyiv field commanders—simultaneously creating a media scandal and forcing targets to commit more resources to personal security. Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations (Il'chenko 2016).\nIn the following, we limit the scope of our inquiry to cyber actions that are either purely disruptive (e.g. DDoS-style attacks) or are hybrids of the two approaches (e.g. web defacements). We do so for two reasons. First, most purely propagandistic operations, like comment-board trolling, do not aspire to influence the course of\nmilitary operations in the short term. Second, it is hard to separate the disruptive and propaganda effects of hybrid cyber activities because they depend on each other.\n## Cyber Coercion in Wartime\nOver the last two decades, cyber attacks have become an increasingly common tool of coercion, used by state and nonstate actors, independently and jointly with physical, kinetic operations. Like other instruments of coercion, cyber actions inflict costs on a target to compel a change in its behavior—either by punishing past misdeeds or by putting pressure on decision makers in real time.\nThe role of cyber compellence in wartime is not unlike that of airpower or terrorism (Pape 2003, 2014). Cyber attacks cannot take or hold territory on their own, but they can support operations on the ground by disrupting opponents' command and control, collecting operational intelligence, and creating opportunities for conventional forces to exploit. If combatants use the Internet for coordination, recruitment, or training, low-level cyber disruption may prevent them from running these vital functions smoothly. Alternatively, cyber attacks can indirectly pressure an opponent by targeting civilian economy and infrastructure, similarly to strategic bombing. Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties (Ottis 2010). Unlike terrorism, the individual attacker is rarely at risk of direct physical harm.\nDespite the apparent promise of these “weapons of the future” (Schmitt 1999; Rios 2009; Clarke and Knake 2010; McGraw 2013; Eun and Aßmann 2014), some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion (Liff 2012; Rid 2012; Gartzke 2013; Junio 2013). There is little doubt that large numbers of low-level attacks can cumulatively produce large-scale damage, bringing “death by a thousand cuts” (Lemay, Fernandeza, and Knight 2010). Yet successful coercion also requires punishment to be both anticipated and avoidable (Schelling 1966), and these criteria can be difficult to meet in cyberspace.\nCyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities (Axelrod and Iliev 2014). Since the destructiveness of malicious code depreciates quickly after first use, cyber attacks are often most damaging when they are least anticipated.\nTargets also have many reasons to doubt that cyber attacks are avoidable by accommodation. For the attacker, cyber actions present a trade-off between plausible deniability—which helps prevent retaliation—and the credibility of coercive promises and threats. Any uncertainty over the source of an attack will also create uncertainty over the nature of compliance—what sort of actions will prevent future attacks and by whom.\nBeyond attribution uncertainty, cyber attacks may not generate sufficient costs to elicit compliance from. Because administrators can quickly fix or contain many\nexploited vulnerabilities, even successful attacks cause only temporary disruption (Axelrod and Iliev 2014). Unless the attacker continues to develop new methods and identify new vulnerabilities, a protracted campaign may quickly lose its coercive impact. As a result, targets may see compliance as insufficient and unnecessary to stop the damage (Hare 2012; Lynn 2010; Nye 2010).\nForce synchronization challenges may also render the timing of cyber attacks suboptimal for compellence. Hackers—especially those not integrated with military forces—may not observe battlefield events on a tactically relevant time line. Even if they did, the lead time required to plan and implement a successful attack—studying the target system, collecting intelligence on its vulnerabilities, and writing code that exploits them—can make these efforts difficult to synchronize with conventional operations.\nThese challenges are not insurmountable. Lead time is a greater barrier for high-level attacks (e.g. targeting major infrastructure) than for more routine, DDoS-style attacks. Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower (Atran 2003; Pape 2003, 2014). The ability of contemporary hackers to overcome these difficulties, however, remains unknown.\n### Previous Research\nThe question of whether low-level cyber attacks compel has deep implications for the theory and practice of national security. Yet the public and academic debate on this topic has unfolded largely in the absence of rigorous empirical evidence in either direction. Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare (Cha 2000; Griniaiev 2004; Libicki 2007, 2011; Czosseck and Geers 2009; Clarke and Knake 2010; Axelrod and Iliev 2014), the overlap between cyber and kinetic capabilities (Healey 2013; Kello 2013; Libicki 2015; Andress and Winterfeld 2013; Axelrod 2014), and the effect of information and communication technology on conflict (Martin-Shields 2013; Pierskalla and Hollenbach 2013; Crabtree, Darmofal, and Kern 2014; Gohdes 2014; Bailard 2015).\nMost research in the first category has focused on the implications of cyber activities for peacetime deterrence or the offense--defense balance rather than wartime compellence. While the second group focuses more directly on cyber attacks during conflict, its empirical approach has been mostly qualitative, relying on evidence from descriptive case studies, macrohistorical surveys, and stylized facts. Some large-n analyses do exist (Valeriano and Maness 2014), but their scope has remained on large-scale cyber attacks rather than the far more numerous low-intensity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action (Weidmann 2015) rather than military compellence.\nOur study bridges the gap between these areas of inquiry. Our goal is to assess the coercive potential of low-level cyber actions during an armed conflict. We pursue this goal by studying the magnitude and direction of the relationship between cyber attacks and physical violence, using microlevel data from ongoing conflicts in Ukraine and Syria.\n### Empirical Expectations\nCyber attacks by actor A can affect physical violence by B in one of the three ways: negatively, positively, or not at all. If cyber compellence is successful, we should expect a short-term decrease in violence after a spike in cyber attacks. A positive response would suggest failure, where cyber attacks actually escalate violence by the opponent. If no relationship exists, cyber actions are either ineffective or irrelevant to fighting in the physical world.\nIn addition to compellence across domains, cyber attacks by actor A may impact cyber attacks by actor B. As before, only a negative relationship would imply coercive success, while a null or positive response would suggest that these actions are either ineffective or counterproductive.\n## Data Analysis\nTo evaluate whether and how cyber actions affect physical violence in war, we analyze new micro-level data from Ukraine and Syria. We begin with an in-depth study of the Ukrainian case, as one of few conflicts where both sides have used cyber attacks as a means of coercion. Due to the sophistication of hackers on both sides, the public nature of many attacks, and an abundance of data, the Ukrainian conflict allows us to observe the short-term coercive impact of cyber attacks. We then use analogous event data on Syria to evaluate the generalizability of our results. While a more systematic analysis of cross-national patterns lies beyond the scope of our article, micro-level evidence from these two conflicts might be suggestive of general patterns of modern warfare—particularly where combatants with asymmetric capabilities use cyberspace along with traditional tools of war.\nIn assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets (Baum and Zhukov 2015; Davenport and Stam 2006; Woolley 2000), we draw data from multiple open sources—including press reports and anonymous attack traffic data. To reduce potential false positives, we include only those events that have been reported by more than one source.\n### Ukraine Cyber Attacks Data\nOur cyber event data on Ukraine include 1,841 unique, mostly low-level, cyber attacks from August 27, 2013, to February 29, 2016, drawn from two sets of sources.\nFirst are media reports of cyber attacks from rebel, Russian, Ukrainian, and Western news outlets, press releases and blogs along with social media platforms used by the involved nonstate actors. Second is the private cyber security firm Arbor Networks' Digital Attack Map (DAM; see http://www.digitalattackmap.com/about/). Unlike media sources—which include only cyber attacks publicly reported by news organizations or claimed by governments and hacker groups directly—DAM draws on anonymous attack traffic data and network outage reports to enumerate the top 2 percent of reported attacks that generate unusually high Internet traffic for each country. Including these “higher-visibility” attacks should make it easier to find a coercive effect.\nWe supplemented these data with fourteen primary source interviews with participants in the cyber campaign, as well as Russian, Ukrainian, and Western cyber security experts with direct knowledge of these operations, from the private and public sectors, academia, and journalism. We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix (Kostyuk and Zhukov 2017).\nWe grouped cyber attacks in our data set according to the partisanship of alleged perpetrators (pro-Ukrainian vs. prorebel) and the type of operation they conducted (propaganda vs. disruption). Table 1 list all actors conducting cyber activitiess in the Ukrainian conflict, their targets, and the reported frequency of their activities.\nUkrainian cyber actions include specific attacks by pro-Kyiv hackers like Anonymous Ukraine and Ukrainian Cyber Forces (UCFs). The latter is the most active group on the pro-Ukrainian side. In an interview, UCF leader Eugene Dokukin claimed to have established the nonstate group in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine (Kostyuk and Zhukov 2017, # 1). Pro-Kyiv hackers' most common targets are the communications and finances of rebel units as well as media firms and private companies in rebel-held areas.\nProrebel cyber actions include specific attacks by proseparatist or pro-Russian cyber actors, like CB, Cyber Riot Novorossiya, Green Dragon, and the Russian government. The first of these takes its name from Ukraine's disbanded Berkut riot police and claims to fight “neofascism” in Ukraine. Ukrainian and Russian cyber experts we interviewed offered contradictory assessments on CB's organizational structure. One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution (Kostyuk and Zhukov 2017, # 12). Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB (Kostyuk and Zhukov 2017, #7 & #8). These groups' most popular targets include Ukrainian government officials, media, and private citizens.\nWe further disaggregated these events into the two categories previously defined—propaganda or disruption—as well as a third, hybrid, category of incidents\nTable I. Actors and Targets (Ukraine and Syria).\n|  Ukraine  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Pro-Kyiv | Actor/target | Frequency (%) | Prorebel | Actor/target | Frequency (%)  |\n|  Anonymous Ukraine | A | 6 (<1) | CyberBerkut | A | 134 (7)  |\n|  Ukrainian Cyber Forces | A | 1,392 (76) | Cyber Riot Novorossiya | A | 41 (2)  |\n|  Ukrainian governmental units and officials | A/T | 3 (<1)/326 (18) | Green Dragon | A | 1 (<1)  |\n|  Ukrainian army units | T | 1 (<1) | Quedagh | A | 1 (<1)  |\n|  Western governments and organizations | T | 15 (1) | Crimean government officials | T | 6 (<1)  |\n|  Western non-state actors | T | 7 (<1) | Russian army units | A/T | 1 (<1)/14 (1)  |\n|  Non-state supporters | T | 91 (5) | Non-state supporters | T | 444 (24)  |\n|   |  |  | Rebel groups | A/T | 2 (<1)/926 (50)  |\n|   |  |  | Russian state units and government officials | A/T | 2 (<1)/14 (1)  |\n|   |  |  | Russian state-sponsored groups | A | 237 (13)  |\n|  Total |  | 1,841 (100) |  |  | 1,841 (100)  |\n|  Syria  |   |   |   |   |   |\n|  Anti-Assad | Actor/target | Frequency (%) | Pro-Assad | Frequency (%) | Actor/target  |\n|  Anonymous/anonymous-sponsored units | A | 93 (14) | ISIL/ISIL-sponsored units | A | 54 (8)  |\n|  Anti-Assad non-state actors | A/T | 297 (44)/18 (3) | Russian government units | A | 3 (<1)  |\n|  Jabhat al-Nusra-sponsored units | A | 1 (<1) | Syrian government units and officials | A/T | 2 (<1)/272 (40)  |\n|  Kurdish non-state opposition | A | 11 (<2) | Syrian state-sponsored units | A/T | 102 (15)/2 (<1)  |\n|  Free Syrian Army | T | 1 (<1) | Pro-Assad non-state actors | T | 179 (26)  |\n|  Pro-ISIL social media and websites | T | 140 (21) |  |  |   |\n|  Total |  | 682 (100) |  |  | 682 (100)  |\nNote: ISIL = The Islamic State of Iraq and the Levant.\nthat potentially serve both purposes. The most common cyber actions in Ukraine have been DDoS-style attacks, followed by hacks of CCTV cameras and other communications. Website blockages have also proven popular, as have spearphishing e-mails targeting specific individuals. Table 2 provides a full breakdown.\nTo reduce false positives due to unconfirmed reports or dubious claims of responsibility, we only include attacks reported by more than one source. To account for uncertainty of attribution, we marked as “disputed” all cases where no one claimed responsibility and labeled as “nondisputed” those operations for which actors directly claimed responsibility in press releases, on social media, or in interviews. To focus on daily dynamics, we excluded activities whose intensity did not vary over time.\nFigure 1a depicts the temporal dynamics of pro-Ukrainian (Cyber U) and pro-Russian rebel (Cyber R) cyber operations. In early March 2014, about a week after the revolution in Kyiv, Figure 1 shows a spike in attacks by CB. The same month saw the establishment of the pro-Kyiv Ukrainian Cyber Forces, partly in response to CB's attacks. However, UCF operations do not become visible until May 2014, following an influx of volunteers to the group. May 2014 is also notable for a rise in activities by another pro-Russian cyber group, Cyber Riot Novorossiya—named after the czarist-era term (“New Russia”) for territories in southeastern Ukraine. After the first Minsk cease-fire agreement in September 2014, operations by pro-Ukrainian hackers converge to a steady rate of two to four per day, with occasional flare-ups, as in December 2014. Activities by pro-Russian hackers, by contrast, declined after the summer 2014.\n### Ukraine Violent Events Data\nOur data on kinetic operations include 26,289 violent events from Ukraine's Donbas region, recorded between February 28, 2014, and February 29, 2016. To offset reporting biases in any one source, while guarding against potential disruptions in media coverage due to cyber attacks, these data draw on seventeen Ukrainian, Russian, rebel, and international sources. As before, we include only events that appeared in more than one source.\nTo extract information on dates, locations, participants, and other event details, we relied on a combination of supervised machine learning (Support Vector Machine) and dictionary-based coding. The Online Appendix describes our measurement strategy and provides summary statistics.\nFigure 1b shows the temporal distribution of pro-Ukrainian (Kinetic U) and pro-Russian rebel (Kinetic R) physical violence. The plot shows several notable flare-ups of fighting—during a government offensive in late June 2014 and a rebel offensive in January 2015—as well as lulls following cease-fire agreements in September 2014, February 2015, and September 2015. Compared to the cyber operations in Figure 1, this plot reveals a clear correlation between kinetic operations\nTable 2. Types of Cyber Operations (Ukraine and Syria).\n|  Propaganda | Ukraine (%) | Syria (%) | Disruption | Ukraine (%) | Syria (%) | Both | Ukraine (%) | Syria (%)  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  PPI—publishing online private information of the members of the conflicting parties | 47 (2) | 59 (9) | AVG— audio-, video-, and geo-intelligence collection | 423 (23) | 1 (<1) | WDT—website defacement | 51 (3) | 389 (57)  |\n|  PRM/PUM—posting pro-rebel and pro-Ukrainian messages online | 54 (3)/5 (<1) | — | CPI—collecting private information via open sources | 13 (<1) | 10 (<2) |  |  |   |\n|  UWP—updating online pages | 6 (<1) | — | DDoS—distributed denial-of-service attack | 499 (27) | 78 (11) |  |  |   |\n|   |   |   |  ODS—other attacks with a purpose of disruption or espionage | 9 (1) | 10 (<2) |  |  |   |\n|   |   |   |  SPE—spear-phishing e-mail | 234 (13) | 17 (2.5) |  |  |   |\n|   |   |   |  STM—sending massive text messages or calling phones non-stop | 40 (2) | 1 (<1) |  |  |   |\n|   |   |   |  WBG—website blockage | 257 (14) | 376 (55) |  |  |   |\n|  Total | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100)  |\n|   |   |   |  |   |   |   |   |   |\nJournal of Conflict Resolution 63(2)\n(a) cyber\n(b) kinetic\nFigure 1. Cyber and kinetic operations in Ukraine (March 2014–February 2016). U (blue) indicates operations by Ukrainian government forces; R (red) indicates operations by pro-Russian rebel groups.\nby the two sides, with government and rebel attacks rising and falling in tandem. $^{15}$  Although this interdependence is not surprising, the data suggest that—with few exceptions—physical violence in Ukraine has been a reciprocal affair.\nFrom a brief glance at the timing of cyber and physical operations (Figure 1a and b), there are relatively few signs of a compelling effect—changes in the former do not appear to drive changes in the latter. However, a visual comparison can be misleading. Some of the variation may be due to fighting on the ground or in cyberspace, but other changes may reflect secular trends or shocks due to elections and other events not directly related to conflict. To account for these potential confounding factors and to gauge whether there is a stronger cyber-kinetic relationship than we would expect by chance, we conduct a series of more rigorous tests.\nEmpirical Strategy\nTo evaluate the relationship between cyber and kinetic operations in Ukraine, we estimate a series of vector autoregressive models\n$Y_{t} = \\sum\\limits_{j}^{p}B_{j}Y_{t - j} + GX_{t} + \\mu_{0} + \\mu_{1}t + \\mathbf{\\epsilon_{t}},$ (1)\nwhere $Y_{t} = \\left[y_{t}^{\\text{Kinetic(U)}}, y_{t}^{\\text{Kinetic(R)}}, y_{t}^{\\text{Cyber(U)}}, y_{t}^{\\text{Cyber(R)}}\\right]^{\\prime}$ is a matrix of endogenous variables, and $X_{t} = \\left[x_{1t},\\ldots,x_{kt}\\right]^{\\prime}$ is a matrix of k exogenous variables, which includes indicators for key dates and events during the war, like presidential and parliamentary electoral campaigns in Ukraine and breakaway territories; cease-fire agreements; and Ukrainian, Russian, and Soviet holidays. Deterministic components include a constant term (μ_{0}) and trend (μ_{1}t). p is the lag order, selected via Bayesian information criterion, and $\\mathbf{\\epsilon_{t}}$ is a vector of serially uncorrelated errors.\nWe control for Ukrainian, Russian, and Soviet holidays because anecdotal accounts suggest significant increases in cyber activity during such times. The UCF, for instance, had an operation called “Happy New Year,” which sought to print pro-Ukrainian messages from hacked printers in Crimea, Russia, and Donbas. National election campaigns represent another time when such activities may spike. Before and during the presidential elections, for instance, hackers bombarded Ukraine's Central Electoral Committee website with DDoS attacks. Finally, we may expect cease-fire agreements aimed at reducing physical violence to also have an effect in the cyber domain. For example, the cyber espionage operation “Armageddon”—directed against Ukrainian government websites—intensified before the Minsk I agreement went into force but then rapidly declined.\nBecause we are interested in the relationship between cyber attacks and physical violence during war, we limit our primary analysis to the active phase of military operations between May 11, 2014, and February 15, 2015—the period following independence referendums organized by the self-proclaimed Donetsk and Luhansk People's Republics and the second Minsk cease-fire agreement. In the Online Appendix, we present additional analyses of the full data set, which produced similar results.\n## Results\nData from Ukraine support the skeptical view of cyber coercion. The impulse--response curves in Figure 2 show a strong, escalatory dynamic between kinetic operations by the two sides (Kinetic U, Kinetic R), but no tangible links in either direction between kinetic and cyber operations, and no reciprocity between cyber actions (Cyber U, Cyber R).\nFollowing a standard deviation increase in kinetic rebel attacks, government violence sees a delayed rise, peaking around two days after the shock and gradually\n|  Response: |   |\n| --- | --- |\n|  Kinetic (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  |\n|  Kinetic (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  |\n|  Cyber (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  |\n|  Cyber (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  |\nFigure 2. Impulse response matrix, daily time series (Ukraine). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"U\" indicates reported kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\ndeclining back to zero (top row, second column). Rebel operations also rise after shocks to government operations (second row, first column), but the response here is immediate, without the delay we observe in government operations. This pattern may reflect command and control inefficiencies in the Ukrainian army, particularly early in the conflict, when indecision and leadership turnover lengthened decision cycles.\nThe relationship between cyber and kinetic operations is far weaker than that between rebel and government violence on the ground. Cyber attacks by pro-Ukrainian forces see no increase after shocks in kinetic government operations, and a positive, but uncertain increase after shocks in kinetic rebel operations (third row, first and second columns).\nThere is even less evidence that cyber attacks drive kinetic operations. The impulse--response function (IRF) curve for pro-Ukrainian government violence is, in fact, negative after shocks to rebel cyber operations (top row, two rightmost columns). Although this negative response might otherwise suggest that cyber attacks compel a decline in violence—consistent with coercive success—the estimate is also highly uncertain. Following shocks to pro-Ukrainian cyber activities, meanwhile, the main change in rebel kinetic operations is a short-term increase in volatility (second row, third column). In sum, the data suggest that cyber attacks may make violence less predictable but do not systematically change its intensity.\nPerhaps most surprisingly, there is little or no apparent strategic interaction between “cyber-warriors” on each side of the conflict. A shock in pro-Ukrainian cyber attacks yields no discernible change in pro-rebel cyber attacks (bottom row, third column) and vice versa (third row, fourth column). The two cyber campaigns, the data suggest, have unfolded independently of each other and independently of events on the ground.\nAs the diagonal elements in Figure 2 suggest, there is strong autocorrelation in each series. For each of the four categories, past shocks in operations yield a significant spike in subsequent operations. To evaluate whether the other categories of events can help us predict future values of each series, after we take this autocorrelation into account, Table 3 reports the results of Granger causality tests. The tests confirm that past levels of prorebel and pro-Kyiv kinetic operations help predict each other's future values. Kinetic operations, however, do not appear to “Granger cause”—or be “Granger caused” by—cyber attacks on either side.\nTable 4 reports the forecasting error variance decomposition, representing the proportion of variation in each series (rows) due to shocks in each endogenous variable (columns). For most variables, their own time-series account for almost all variation at the outset, but this dependency gradually decreases. As before, there is far more dependence within kinetic operations than between kinetic and cyber or within cyber actions. By the thirty-day point in the daily time series, shocks in rebel attacks account for 7 percent of variation in Ukrainian government operations, while shocks in government operations explain 12 percent of variation in rebel violence.\nJournal of Conflict Resolution 63(2)\nTable 3. Granger Causality Test, Daily Time Series (Ukraine).\n|  Effects | F statistic | p value  |\n| --- | --- | --- |\n|  Kinetic (R) → Kinetic (U) | 40.26 | .00  |\n|  Cyber (U) → Kinetic (U) | 0.50 | .48  |\n|  Cyber (R) → Kinetic (U) | 0.09 | .76  |\n|  Kinetic (U) → Kinetic (R) | 12.29 | .00  |\n|  Cyber (U) → Kinetic (R) | 1.44 | .23  |\n|  Cyber (R) → Kinetic (R) | 2.70 | .10  |\n|  Kinetic (U) → Cyber (U) | 1.40 | .24  |\n|  Kinetic (R) → Cyber (U) | 1.88 | .17  |\n|  Cyber (R) → Cyber (U) | 0.00 | .95  |\n|  Kinetic (U) → Cyber (R) | 1.74 | .19  |\n|  Kinetic (R) → Cyber (R) | 0.14 | .71  |\n|  Cyber (U) → Cyber (R) | 0.89 | .35  |\nNote: \"U\" indicates reported kinetic and cyber operations by Pro-Ukrainian government forces, and \"R\" indicates operations by Pro-Russian rebel forces.\nTable 4. Variance Decomposition, Daily Time Series (Ukraine).\n|  Operation type | Kinetic (U) | Kinetic (R) | Cyber (U) | Cyber (R)  |\n| --- | --- | --- | --- | --- |\n|  Kinetic (U) |  |  |  |   |\n|  1 Day | 1.000 | .000 | .000 | .000  |\n|  2 Days | 0.920 | .060 | .002 | .018  |\n|  7 Days | 0.906 | .071 | .002 | .020  |\n|  30 Days | 0.906 | .071 | .002 | .020  |\n|  Kinetic (R) |  |  |  |   |\n|  1 Day | 0.108 | .892 | .000 | .000  |\n|  2 Days | 0.121 | .873 | .000 | .006  |\n|  7 Days | 0.122 | .870 | .000 | .008  |\n|  30 Days | 0.122 | .870 | .000 | .008  |\n|  Cyber (U) |  |  |  |   |\n|  1 Day | 0.000 | .002 | .998 | .000  |\n|  2 Days | 0.000 | .002 | .997 | .000  |\n|  7 Days | 0.000 | .003 | .997 | .000  |\n|  30 Days | 0.000 | .003 | .997 | .000  |\n|  Cyber (R) |  |  |  |   |\n|  1 Day | 0.012 | .023 | .000 | .964  |\n|  2 Days | 0.014 | .023 | .001 | .962  |\n|  7 Days | 0.015 | .023 | .001 | .961  |\n|  30 Days | 0.015 | .023 | .001 | .961  |\nNote: \"U\" indicates kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\nBy contrast, shocks to cyber activities account for very little variation in kinetic operations. The highest value is for pro-Russian rebel cyber activities, which account for 2 percent of short-term variation in government violence. Cyber attacks by each side also have a relatively small impact on each other. Indeed, rebel kinetic operations explain more of the variation in cyber attacks by each actor than do cyber attacks by the other side.\nIn sum, our analysis suggests that low-level cyber attacks in Ukraine have had no effect on the timing of physical violence. Not only is there no evidence that cyber attacks have compelled opponents to de-escalate fighting, there is no discernible reciprocity between the cyber actors themselves. Each group of hackers seems to operate in its own bubble, disengaged from unfolding events in both cyberspace and the physical world.\n### Robustness Checks\nTo gauge the sensitivity of our results to various modeling and measurement choices, we conducted extensive robustness checks. We summarize their results briefly here (Table 5) and more fully in the Online Appendix.\nThe first set of tests considers vector autoregression models with alternative orderings of the four endogenous variables, which affects estimation of impulse responses. We find no substantive differences across the twenty-four permutations.\nIn a second set of robustness checks, we account for systematic differences in the kinds of conflict events that Ukrainian and Russian media report, which may bias statistical estimates—for example, by underreporting violence by a given actor. Using kinetic data from exclusively Russian or exclusively Ukrainian sources does not change the results.\nA third set of robustness tests examines different subsets of cyber attacks. Because purely disruptive activities may impose greater immediate costs than quasi-propagandistic hybrid attacks, pooling these events may dilute their coercive effect. Our results are consistent for all three subsets.\nThe last set of robustness checks examines different time periods of the conflict, since some cyber attacks predated military activity. In particular, we compare the period of intense fighting previously analyzed (May 11, 2014--February 15, 2015) to the entire date range for which we have data (February 28, 2014--February 29, 2016). Our results remain unchanged.\n## Evidence from Interviews\nIn interviews, Russian and Ukrainian cyber security experts highlighted five potential explanations for the apparent failure of cyber coercion in Ukraine: (1) lack of resources, (2) lack of coordination, (3) lack of targets, (4) lack of audience, and (5) lack of effort.\nTable 5. Robustness Checks (Ukraine and Syria).\n|  Ukraine (main results; May 11, 2014–February 15, 2015)  |   |   |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n|  I | Disruption and both | Kin(R) ↔ Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) ↔ Kin(R) | Kin(U) ↔ Kin(R) | Kin(U) → Kin(G)  |\n|  ID | Cyber | GCT(w) | VD(d) (30 day) | VD(w) (12 week) |  |  |   |\n|  I | Disruption and both |  | Kin(R) → 7%Kin(U) | Kin(R) → 10%Cyb(R) |  |  |   |\n|   |   |   | Kin(R) → 2%Cyb(R) | Kin(U) → 21%Kin(R) |  |  |   |\n|   |   |   | Kin(U) → 12%Kin(R) | Kin(U) → 17%Cyb(R) |  |  |   |\n|   |   |   | Kin(U) → 2%Cyb(R) | Cyb(U) → 4%Cyb(R) |  |  |   |\n|  ID | Cyber | IRF(d) | IRF(w) | GCT(d) | GCT(w) | VD(d) (30 day) | VD(w) (12 week)  |\n|  Ukraine (March 22, 2014–February 29, 16)  |   |   |   |   |   |   |   |\n|  2 | All | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U/R) ↔ Kin(U) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Cyb(U) ↔ Kin(R) |  |  | Kin(U) → 3%Cyb(R)  |\n|  3 | Propaganda | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin(U)/Cyb(R) | Kin(R) → 3%Kin(U) | Kin(R) → 9%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) → Kin/Cyb(R) | Kin(U) → Cyb(R) | Kin(U) → 18%Kin(R) | Kin(R) → 3%Cyb(R)  |\n|   |   |   | Cyb(U) → Kin(U) | Kin(U) → Cyb(R) |  |  | Kin(U) → 46%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(R)  |\n|  4 | Disruption | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(U/R) |  | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|  5 | Disruption and both | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(R) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Kin(U) → Cyb(U) |  |  |   |\n(continued)\nTable 5. (continued)\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) Ukraine (May 11, 2014-February 11, 2015) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  6 | All | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) |  | Kin(R) → 7%Kin(U) | Kin(R) → 2%Cyb(U)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(U) → 13%Kin(R) | Kin(R) → 18%Cyb(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 30%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(U/R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 4%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(U)  |\n|  7 | Propaganda | Kin(R) → Kin(U) | Cyb(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Cyb(R) | Kin(R) → 7%Kin(U) | Kin(U) → 27%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) |  |  | Kin(U) → 13%Kin(R) | Kin(U) → 4%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 3%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 9%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 20%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 5%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(R) → 2%Cyb(U)  |\n|  8 | Disruption | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → Cyb(U) | Kin(R) → 7%Kin(U) | Kin(U) → 29%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(R) → 2%Cyb(R) | Kin(U) → 34%Cyb(U)  |\n|   |   |   |  |  |  | Kin(U) → 12%Kin(R) | Kin(U) → 22%Cyb(R)  |\n|   |   |   |  |  |  | Cyb(R) → 2%Kin(U) | Kin(R) → 3%Kin(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 10%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 13%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 6%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 7%Cyb(U)  |\nSyria (March 17, 2011-July 10, 2016)\n|  9 | Disruption and both | Kin(G) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → 2%Kin(R)  |\n| --- | --- | --- | --- | --- |\nNote: IRF = impulse response functions; GCT = Granger causality tests; VD = variance decomposition; d = daily; w = weekly; o = alternative orderings; RU = Russian; U = Ukrainian.\nThe first explanation for coercive failure emphasizes limited resources and capabilities, particularly for the Ukrainian government. Ten years ago, the SBU briefly had a cyber department but shut it down after a year (Kostyuk and Zhukov 2017, #3). This unit has recently reopened but continues to lack funding and personnel (Kostyuk and Zhukov 2017, #3, #9). It is possible that, with adequate resources, capabilities, and human capital, the Ukrainian cyber campaign might have been more effective. Resource constraints, however, do not explain coercive failure on the pro-Russian side, where investment in cyber capabilities is more robust.\nA second explanation is lack of government coordination with hackers, especially in Kyiv (Maurer and Geers 2015). UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success (Kostyuk and Zhukov 2017, #1). The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place (Kostyuk and Zhukov 2017, #1, #3, #9). Yet again, this explanation is less plausible on the pro-Russian side, where the Kremlin has cultivated extensive ties with non-state hacktivists.\nA third explanation is that—even with requisite capabilities and coordination—there are few opportune targets for disruption in Ukraine. Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult (Geers 2015; Kostyuk and Zhukov 2017, #3, #13). Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack” (Kostyuk and Zhukov 2017, #11). The 2015 and 2016 hacks of Ukraine's power grid also seem to challenge this explanation.\nThe peculiarities of Ukraine's online population represent a fourth explanation for the indecisiveness of cyber attacks. Since only 44.1 percent of Ukrainians have Internet access—compared to 88.5 percent in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses (Kostyuk and Zhukov 2017, #3). Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones (Kostyuk and Zhukov 2017, #7, #11). Our data suggest that, even if this were the case, propagandistic attacks still had no effect on violence.\nThe final explanation is that cyber compellence failed because it was never seriously attempted. At first, our interviews with individual hackers revealed no shortage of coercive intent. UCF leader Eugene Dokukin claimed to conduct low-level attacks daily and vowed to continue until pro-Russian rebels lay down their arms. Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns (Kostyuk and Zhukov 2017, #1).\nWhile UCF and other nonstate groups have explicitly sought to affect battlefield outcomes, some interviewees questioned whether this intent extended to the Russian\ngovernment. Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place (Kostyuk and Zhukov 2017, #5, #12). This access, along with vigorous cyber espionage—some of it ongoing since 2010—may create incentives against more aggressive actions, which could compromise valuable sources of intelligence.\nConsistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda (Kostyuk and Zhukov 2017, #11). When in 2011 Vyacheslav Volodin replaced Vladislav Surkov as head of the Presidential Administration, he toughened existing laws against Russia's opposition and promoted the use of mass media and online platforms—tools already mostly under state control—to conduct information campaigns. If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising (Kostyuk and Zhukov 2017, #2, #14).\n## Evidence beyond Ukraine: Syria's Digital Front\nAccording to evidence from microlevel data and interviews, cyber attacks did not affect battlefield events in Ukraine. During one of the first armed conflicts where both sides used low-level cyber actions extensively, events in the digital realm have unfolded independently of—and have had no discernible effect on—events on the ground. Conditions in Ukraine were in many ways optimal to observe the coercive impact of cyber actions, for reasons we already discussed (i.e. visibility of major attacks, regular claims of responsibility, less uncertainty over attribution). Yet we found no evidence that low-level cyber attacks affected physical violence. Nor did hackers on each side even affect each other's activities.\nWhile important, Ukraine is not the only contemporary conflict with a significant cyber dimension. In Syria, state and nonstate actors have employed low-level cyber actions extensively for propaganda and disruption, complementing traditional tools of warfare in the deadliest conflict ongoing today. Syria's war has also lasted three years longer than Ukraine's. Over this time, its digital front has expanded in scope and sophistication, offering a glimpse of cyber coercion in a more protracted setting.\nAn in-depth study of Syria's digital front lies beyond the scope of this article. A brief analysis of the data, however, suggests that our findings from Ukraine may be part of a broader pattern: cyber capabilities have not yet evolved to the point of having an impact on physical violence.\nTo evaluate the effectiveness of cyber compellence in this second case, we replicated the model in (equation 1), using an analogous daily time series of cyber attacks and violent events in Syria. Our data comprise 9,282 kinetic and 682 low-level cyber attacks ranging from March 2011 until July 2016. Table 2 provides a breakdown of cyber techniques used in the Syrian conflict, their brief description, and frequency. Our data on kinetic operations rely on human-assisted machine\nJournal of Conflict Resolution 63(2)\nFigure 3. Cyber and kinetic operations in Syria (March 2011-July 2016). G (blue) indicates operations by pro-Assad government forces; R (red) indicates operations by anti-Assad rebel groups.\ncoding of event reports from the International Institute for Strategic Studies Armed Conflict Database (see Online Appendix for details).\nGiven the complex nature of the Syrian conflict and the multiple parties involved, we restrict our analysis only to operations by progovernment forces (i.e., Syrian Army, Hezbollah and pro-Assad militias) and the main rebel opposition (i.e., Free Syrian Army, Jaish al-Fatah, including Al Nusra Front). Table 1 provides a list of cyber actors in the Syrian conflict, their targets, and frequency of their activities.\nThe dynamics of cyber and kinetic operations in Syria exhibit similar patterns to what we saw in Ukraine. Raw data (Figure 3a and b) suggest relatively little overlap in timing, especially at the beginning of the conflict. The IRF curves in Figure 4 show a rise in rebel operations following shocks to government operations (second row, first column), and mostly negligible (though negative) links between cyber and kinetic operations, and across cyber attacks by each actor. Links between kinetic\n|  Response: |   |\n| --- | --- |\n|  Kinetic (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380 385 390 395  |\n|  Kinetic (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295  |\n|  Cyber (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 260 270 275  |\n|  Cyber (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230  |\n|  Impulse: | Kinetic (G) Kinetic (R) Cyber (G) Cyber (R)  |\nFigure 4. Impulse response matrix, daily time series (Syria). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"G\" indicates reported kinetic and cyber operations by pro-Assad government forces, and \"R\" indicates operations by anti-Assad rebel forces.\noperations—and their disconnect from cyber attacks—are also evident in variance decomposition results, and Granger tests, provided in the Online Appendix.\nThere are several reasons for caution in interpreting these results. The Syrian conflict involves a larger constellation of actors than Ukraine, and our dyadic analysis may overlook significant interactions elsewhere, particularly between actors with more developed cyber capabilities (e.g. Russia, United States). We also lack interview evidence that might help contextualize the null effect. However tentative, these results do align with what we saw in Ukraine: low-level cyber attacks have had little or no impact on violence.\n## Conclusion\nThe evidence we presented in this article—based on analysis of new data and expert interviews—suggests that cyber attacks are ineffective as a tool of coercion in war. Although kinetic operations explain the timing of other kinetic operations, low-level cyber attacks have no discernible effect on violence in the physical world. In Ukraine and Syria, the “cyberwar” has unfolded in isolation from the rest of the conflict.\nThis finding has several implications for theory and policy. First, by providing the first statistical analysis of modern low-level cyber campaigns, our study complements the qualitative focus of previous empirical work. Second, our research sheds light on a theoretical question about the strength and direction of the cyber--kinetic relationship and—in so doing—begins to fill an empirical gap in political science literature on this topic. Third, to the extent that policymakers might overestimate the importance of cyber actions due to a lack of empirical evidence to the contrary, our findings can potentially help correct this misperception. Finally, and more worryingly, our results suggest that—due to their disconnect from physical violence—low-level cyber attacks are very difficult to predict.\nFurther research is needed to understand the dynamics of low-level cyber attacks. One such area of research is cyber coercion in the context of symmetric, conventional war. While our study helps illuminate dynamics of cyber compellence between parties with asymmetric capabilities, we may well observe different patterns when major powers use cyberspace against peer competitors. Thankfully, no armed conflict has yet provided researchers with the data needed to evaluate this possibility.\nSecond, our scope in this article has been exclusively on short-term military consequences rather than long-term political effects. The latter are no less theoretically significant, but—unlike simple counts of violent events—potentially more difficult to measure and analyze. A study of long-term political effects would also need to more systematically incorporate purely propagandistic cyber activities and their impact on public opinion, which we omitted here due to our focus on short-term military compellence.\nAlthough the secretive nature of many ongoing physical and digital operations is a challenge for this research, questions over the coercive potential of cyber attacks\nwill become only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” (Sabah 2016)—have yielded few tangible successes (Sanger and Schmitt 2017). Our data from Ukraine indicate that the US experience may be part of a broader pattern.\nAt best, coordination between low-level cyber and kinetic operations today is on roughly the same level as that between airpower and ground operations in World War I. Back then, armies were increasingly using aircraft for reconnaissance and surveillance on the front but were not yet able to fully exploit their potential for ground combat support and strategic bombing. That revolution appeared on the battlefield twenty-five years later, with devastating effect. As cyber capabilities develop and synchronization challenges become less severe, there will be a growing need for assessments of how far we have come. We hope that analyses of the sort we provided in these pages can serve as an early benchmark.\n## Authors' Note\nA previous version of this article was presented at the 2015 Peace Science Society International annual meeting, Oxford, MS, and at the Association for the Study of Nationalities Convention at New York, NY.\nWe are grateful to Maura Drabik, Paulina Knoblock, Neil Schwartz, and Alyssa Wallace for excellent research assistance. Robert Axelrod, Myriam Dunn-Cavelty, Eric Gartzke, Miguel Gomez, Todd Lehmann, Jon Lindsay, Tim Maurer, Brandon Valeriano, Christopher Whyte, and workshop participants of the Conflict & Peace, Research & Development workshop at the University of Michigan, of the Bridging the Gap Workshop on Cyber Conflict at Columbia University, of the Cross-Domain Deterrence lab at the University of California, San Diego, and of the Center for Security Studies at ETH Zurich provided helpful comments on the earlier drafts of this article.\n## Declaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n## Funding\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.\n## Supplemental Material\nSupplemental material for this article is available online.",
  "references": [
    "## Notes\n1. We define coercion as an attempt to influence a target's behavior by increasing the costs associated with an unwanted action. Cyber activities apply these costs through the\ndisruption, destruction, malicious control, or surveillance of a computing environment or infrastructure (Kissel 2013). Kinetic or physical operations apply costs through physical force. Low-level cyber attacks cause minor disruptions and include web-page defacements, phishing, distributed denial of service attacks. High-level cyber attacks include serious disruption with loss of life and extensive infrastructure disruption.Deterrence seeks to convince a target to not start an unwanted action. Compellence seeks to convince the target to stop an ongoing unwanted action.We use propaganda when referring to the propaganda category, cyber attacks when referring to disruption (Cartwright and James 2010), and hybrid cyber operations when referring to hybrids of the two.For example, US Cyber Command has used low-level cyber operations to “disrupt the ability of the Islamic State to spread its message, attract new adherents, circulate orders from commanders and [pay] its fighters” (Sanger 2016).A zero-day vulnerability is a security hole previously unknown to the target.This trade-off is not unique to the cyber domain. In civil conflict, for example, pro-government militias pose a similar dilemma for state repression (Gohdes and Carey 2017).Another potentially illuminating case, which we are unable to analyze here, is the Russian--Georgian War of 2008. This earlier conflict laid much of the groundwork for the crisis in Ukraine. For the first time in history, cyberspace played a highly visible role in armed conflict, facilitating strategic communication between civilian and military leadership, disabling or degrading key infrastructure, exploiting or hijacking government computer systems, while also serving as a tool for propaganda (Deibert, Rohozinski, and Crete-Nishihata 2012). While some of the lessons of the Russian--Georgian War might well run counter to our claims in this article, its short duration (five days) complicates analysis, for three reasons. First is a lack of sufficient variation in cyber attacks over this abbreviated period. Second is the difficulty of differentiating the “cyber effect” from the near-simultaneous effects of conventional military operations. Third is the problem of generalizability: its five-day duration is an extreme outlier among interstate and civil wars (interstate wars, on average, tend to last a few years; the average civil war lasts between seven and twelve years post-1945). For these reasons, we are unable to quantitatively establish whether synchronized usage of cyberspace, along with traditional tools of war, had a tangible coercive impact in Georgia.Sections 3.1 and 3.2 along with the Online Appendix provide an overview of these sources.Rebel sources include Donetsk News Agency. Russian sources include RIA Novosti, Sputnik, and Vesti.ru. Ukrainian sources include Interfax-Ukraine, Segodnya, and RBK-Ukraina. Western sources include technical (Arstechnica, Digital Dao, Information Week, F-Secure, Graham Cluley, and TechWeek Europe) and mainstream news (Die Welt, Newsweek, New York Times, Politico, Postimees (Estonia), Security Affairs, and The Christian Science Monitor).Our Ukrainian interviewees included experts from the Ukrainian Cyber Forces, Computer Emergency Response Team of Ukraine, StopFake, InfoPulse, Luxoft, Berezha Security,\nOpen Ukraine Foundation, and the Ukrainian Central Election Committee. Western experts' affiliations include New York University, Chatham House, the Center for Strategic and International Studies, RAND Corporation, The Economist, Mashable, New America Foundation, and the North Atlantic Treaty Organization Cyber Center of Excellence. Due to the complicated political situation in Russia at the time, many of our contacts there refused to speak on record, with the exception of a journalist from Agentura.ru. However, many Western interviewees have lived in Russia, speak the language, and are knowledgeable on Russia's information security issues.This is a very conservative standard of attribution, since it includes only direct claims of responsibility and not accusations by others—even if the latter are substantiated by evidence. For instance, we marked as “disputed” the cyber espionage operation Armageddon—which multiple governments and private security firms have attributed to the Russian state—because Moscow never claimed responsibility.Excluded operations included the malware Blackenergy, first launched by Quedagh in 2010; Operation Potao Express, a targeted espionage campaign launched in 2011 against the Ukrainian government, military, and news agencies; and Snake, a cyber espionage campaign against Ukrainian computer systems.We aggregated these data to daily time series because geolocation is not possible. Although some individual cyber attacks could, in theory, be tracked to their targets, they represent a small proportion of events. As a result, our cyber data are national-level time series. Even if we could geolocate all targets of cyber attacks, the diffuse nature of the target set makes spatial matching difficult—servers do not need to be physically located in the war zone for service disruptions to have an effect in the war zone.Ukrainian sources include Channel 5, Espresso.tv, Information Resistance, 112 Ukraina, and the newswire services Interfax-Ukraine and Ukrinform. Russian sources include the state-owned television news channel Russia-24; the independent TV station Dozhd; nongovernment news websites Gazeta.ru, Lenta.ru, and BFM.ru; and the Interfax newswire service. Pro-rebel sources include Donetsk News Agency, NewsFront, and Rusvesna.su. Also included are the Russian language edition of Wikipedia and daily briefings from the Organization for Security and Co-operation in Europe Special Monitoring Mission to Ukraine. Since these are mostly online resources, cyber disruptions can potentially cause underreporting of violence. Our approach helps ensure that if, for instance, a Ukrainian media firms' servers went down, information could still reach the outside world through one of the sixteen other sources. While unlikely, such endogenous disruptions should increase our chances of finding a coercive cyber effect.Because geolocation is not possible for cyber attacks, we aggregate the physical violence data to daily time series to merge and analyze the data sets.Vector autoregression is a common method to study interdependence among multiple time series in economics and political science. Previous applications to conflict research include studies of reciprocity in civil conflicts (Pevehouse and Goldstein 1999) and the dynamics of terrorism (Enders and Sandler 2000; Bejan and Parkin 2015).An example is Russia's Sistema operativno-rozysknykh meropriyatiy (system for operational investigative activities), which searches and monitors electronic communications.\n18. Sources of cyber operations include social media accounts of anonymous or anonymous-supported groups (e.g. New World Hacking); Syrian Electronic Army's social media accounts; reports by tech companies (e.g. risk-based security, Electronic Frontier Foundation); computer-security news sources including Graham Cluley, TechWeek Europe, Arstechnica, Information Week, Digital Dao, Computer Weekly, Tech News, Wired, and Security Affairs; Middle Eastern mass media sources (e.g. Turkish News, Arabiya, Doha News); Russian mass media and social media (e.g. RT.com, Yahoo.com); and Western news sources (e.g. Security Affairs, The Christian Science Monitor, Politico, Die Welt, Reuters, International Business Times, Mashable, Washington Times, The Guardian, British Broadcasting Corporation, etc.).Since propaganda operations are not a major focus of our article, we collected only a small sample of such events during the Syrian conflict.\n## References\nAndres, Richard. 2012. “The Emerging Structure of Strategic Cyber Offense, Cyber Defense, and Cyber Deterrence.” In Array Cyberspace and National Security: Threats, Opportunities, and Power in a Virtual World, 1st ed. translated by Derek S. Reveron, 89-104. Washington, DC: Georgetown University Press.\nAndress, Jason, and Steve Winterfeld. 2013. Cyber Warfare: Techniques, Tactics and Tools for Security Practitioners. Boston, MA: Elsevier.\nAtran, Scott. 2003. “Genesis of Suicide Terrorism.” Science 299 (5612): 1534-39.\nAxelrod, Robert. 2014. “A Repertory of Cyber Analogies.” In Cyber Analogies, edited by Emily O. Goldman and John Arquilla. Monterey, CA: Department of Defense Information Operations Center for Research.\nAxelrod, Robert, and Rumen Iliev. 2014. “Timing of Cyber Conflict.” Proceedings of the National Academy of Sciences 111 (4): 1298-303.\nBailard, Catie Snow. 2015. “Ethnic Conflict Goes Mobile: Mobile Technology's Effect on the Opportunities and Motivations for Violent Collective Action.” Journal of Peace Research 52 (3): 1-15.\nBaum, Matthew A. and Yuri M. Zhukov. 2015. “Filtering Revolution: Reporting Bias in International Newspaper Coverage of the Libyan Civil War.” Journal of Peace Research 9:10-11.\nBejan, Vladimir, and William S. Parkin. 2015. “Examining the Effect of Repressive and Conciliatory Government Actions on Terrorism Activity in Israel.” Economics Letters 133:55-58.\nCartwright, James, and W. James. 2010. Joint Terminology for Cyberspace Operations. Memorandum. Washington, DC: Joint Chiefs of Staff (JCS).\nCha, Victor D. 2000. “Globalization and the Study of International Security.” Journal of Peace Research 37 (3): 391-403.\nClarke, Richard A. and Robert K. Knake. 2010. Cyber War: The Next Threat to National Security and What to Do about It. The Library of Congress. New York: Harper Collins.\nCrabtree, Charles, David Darmofal, and Holger L Kern. 2014. “A Spatial Analysis of the Impact of West German Television on Protest Mobilization during the East German Revolution.” Journal of Peace Research 52: 269-84.\nKostyuk and Zhukov\n345\nCzosseck, Christian, and Kenneth Geers. 2009. The Virtual Battlefield: Perspectives on Cyber Warfare, vol. 3. Amsterdam, the Netherlands: IOS Press.\nDavenport, Christian, and Allan Stam. 2006. \"Rashomon Goes to Rwanda: Alternative Accounts of Political Violence and Their Implications for Policy and Analysis.\" Unpublished manuscript. Accessed January 15, 2017. http://www.gvpt.umd.edu/davenport/dcawcp/paper/mar3104.pdf.\nDeibert, Ronald J., Rafal Rohozinski, and Masashi Crete-Nishihata. 2012. \"Cyclones in Cyberspace: Information Shaping and Denial in the 2008 Russia-Georgia War.\" *Security Dialogue* 43 (1): 3-24.\nEnders, Walter, and Todd Sandler. 2000. \"Is Transnational Terrorism Becoming More Threatening? A Time-series Investigation.\" *Journal of Conflict Resolution* 44 (3): 307-32.\nEun, Yong-Soo, and Judith Sita Aßmann. 2014. \"Cyberwar: Taking Stock of Security and Warfare in the Digital Age.\" *International Studies Perspectives* 17:343-60.\nGartzke, Erik. 2013. \"The Myth of Cyberwar: Bringing War in Cyberspace Back Down to Earth.\" *International Security* 38 (2): 41-73.\nGeers, Kenneth. 2015. Cyber War in Perspective: Russian Aggression against Ukraine. Tallinn, Estonia: CCDCOE.\nGohdes, Anita R. 2014. \"Pulling the Plug: Network Disruptions and Violence in Civil Conflict?\" *Journal of Peace Research* 52 (3): 352-67.\nGohdes, Anita R., and Sabine C. Carey. 2017. \"Canaries in a Coal-mine? What the Killings of Journalists Tell Us about Future Repression.\" *Journal of Peace Research* 54 (2): 157-74.\nGriniaiev, Sergei. 2004. \"Pole bitvy: kiberprostranstvo [The battlefield is cyberspace].\" (Po materialam inostrannoj pechati /) Mn: Harvest.\nHare, Forrest. 2012. \"The Significance of Attribution to Cyberspace Coercion: A Political Perspective.\" In 2012 4th International Conference on Cyber Conflict (CYCON 2012, edited by C. Czosseck, R. Ottis, and K. Ziolkowski, 1-15. Tallinn, Estonia: NATO CCD COE\nHealey, Jason. 2013. A Fierce Domain: Conflict in Cyberspace, 1986 to 2012. Arlington, VA: Cyber Conflict Studies Association.\nIl'chenko, Oleksandr. 2016. \"Rozstily Oleha Kalashnikova i Olesya Buzyny - rik potomu [Shootings of Oleg Kalashnikov of Oles Buzina—a year later].\" Segodnya.\nJunio, Timothy J. 2013. \"How Probable Is Cyber War? Bringing IR Theory Back In to the Cyber Conflict Debate.\" *Journal of Strategic Studies* 36 (1): 125-33.\nKello, Lucas. 2013. \"The Meaning of the Cyber Revolution: Perils to Theory and Statecraft.\" *International Security* 38 (2): 7-40.\nKissel, Richard. 2013. Glossary of Key Information Security Terms. NISTIR 7298, Revision 2. Gaithersburg, MD: National Institute of Standards and Technology, the US Department of Commerce.\nKostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*.\nLemay, Antoine, José M. Fernandez, and Scott Knight. 2010. \"Pinprick Attacks, A Lesser Included Case.\" In Conference on Cyber Conflict Proceedings, edited by C. Czosseck and K. Podins, 183-94. Tallinn, Estonia: CCD COE.\nJournal of Conflict Resolution 63(2)\nLibicki, Martin C. 2007. Conquest in Cyberspace: National Security and Information Warfare. Cambridge, MA: Cambridge University Press.\nLibicki, Martin C. 2009. Cyberdeterrence and Cyberwar. Santa Monica, CA: Rand Corporation.\nLibicki, Martin C. 2011. \"Cyberwar as a Confidence Game.\" Strategic Studies Quarterly 5 (1): 132-46.\nLibicki, Martin C. 2015. \"The Cyberwar that Wasn't.\" In Cyber War in Perspective: Russian Aggression against Ukraine, edited by Kenneth Geers, 49-54. Tallinn, Estonia: NATO Cyber Center of Excellence, NATO CCD COE.\nLiff, Adam P. 2012. \"Cyberwar: A New 'Absolute Weapon'? The Proliferation of Cyberwarfare Capabilities and Interstate War.\" Journal of Strategic Studies 35 (3): 401-28.\nLynn, William J. 2010. \"Defending a New Domain: The Pentagon's Cyberstrategy.\" *Foreign Affairs* 89 (5): 97-108.\nMartin-Shields, Charles Patrick. 2013. \"Inter-ethnic Cooperation Revisited: Why Mobile Phones can Help Prevent Discrete Events of Violence, Using the Kenyan Case Study.\" Stability: International Journal of Security and Development 2 (3): Art. 58.\nMaurer, Tim, and Kenneth Geers. 2015. \"Cyber Proxies and the Crisis in Ukraine.\" In Cyber War in Perspective: Russian Aggression against Ukraine, edited by Kenneth Geers, 79-86. Tallinn, Estonia: NATO Cyber Center of Excellence, NATO CCD COE.\nMcGraw, Gary. 2013. \"Cyber War is Inevitable (Unless We Build Security In).\" Journal of Strategic Studies 36 (1): 109-19.\nNye, Joseph S., Jr. 2010. Cyber Power. Cambridge, MA: Belfer Center for Science and International Affairs, Harvard Kennedy School.\nOttis, Rain. 2010. \"From Pitch Forks to Laptops: Volunteers in Cyber Conflicts.\" In Conference on Cyber Conflict Proceedings 2010, edited by C. Czosseck and K. Podins, 97-109. Tallinn, Estonia: CCD COE.\nPape, Robert A. 2003. \"The Strategic Logic of Suicide Terrorism.\" American Political Science Review 97 (03): 343-61.\nPape, Robert A. 2014. Bombing to Win: Air Power and Coercion in War. Ithaca, NY: Cornell University Press.\nPevehouse, Jon C., and Joshua S. Goldstein. 1999. \"Serbian Compliance or Defiance in Kosovo? Statistical Analysis and Real-time Predictions.\" Journal of Conflict Resolution 43:538-46.\nPierskalla, Jan H., and Florian M. Hollenbach. 2013. \"Technology and Collective Action: The Effect of Cell Phone Coverage on Political Violence in Africa.\" American Political Science Review 107 (02): 207-24.\nRid, Thomas. 2012. \"Cyber War Will Not Take Place.\" Journal of Strategic Studies 35 (1): 5-32.\nRios, Billy K. 2009. \"Sun Tzu was a Hacker: An Examination of the Tactics and Operations from a Real World Cyber Attack.\" The Virtual Battlefield: Perspectives on Cyber Warfare 3:143.\nSabah, Daily. 2016. \"Cyber Bombs Being Used to Destroy Daesh: US Defense Chief.\" February 29, 2016. Accessed March 15, 2017. https://www.dailysabah.com/mideast/2016/02/29/cyber-bombs-being-used-to-destroy-daesh-us-defense-chief.\nKostyuk and Zhukov\n347\nSanger, David E. 2016. \"U.S. Cyberattacks Target ISIS in a New Line of Combat.\" The New York Times. Accessed March 15, 2017. https://www.nytimes.com/2016/04/25/us/politics/us-directs-cyberweapons-at-isis-for-first-time.html?_r=0.\nSanger, David E., and Eric Schmitt. 2017. \"U.S. Cyberweapons, Used Against Iran and North Korea, Are a Disappointment Against ISIS.\" New York Times, p. A5. Accessed June 15, 2017. https://www.nytimes.com/2017/06/12/world/middleeast/isis-cyber.html.\nSchelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale.\nSchmitt, Michael N. 1999. \"Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework.\" *Columbia Journal of Transnational Law* 37: 1998-99.\nSharma, Amit. 2010. \"Cyber Wars: A Paradigm Shift from Means to Ends.\" *Strategic Analysis* 34 (1): 62-73.\nValeriano, Brandon, and Ryan C. Maness. 2014. \"The Dynamics of Cyber Conflict between Rival Antagonists, 2001-11.\" *Journal of Peace Research* 51 (3): 347-60.\nWeidmann, Nils B. 2015. \"Communication, Technology, and Political Conflict Introduction to the Special Issue.\" *Journal of Peace Research* 52 (3): 263-68.\nWoolley, John T. 2000. \"Using Media-based Data in Studies of Politics.\" *American Journal of Political Science* 44:156-73.\nZetter, Kim. 2017. \"The Ukrainian Power Grid Was Hacked Again.\" *Motherboard*. Accessed June 15, 2017. http://bit.ly/2jEUqW3."
  ],
  "flat_text": "Check for updates\nArticle\n# Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\nJournal of Conflict Resolution\n2019, Vol. 63(2) 317-347\n© The Author(s) 2017\nArticle reuse guidelines:\nsagepub.com/journals-permissions\nDOI: 10.1177/0022002717737138\njournals.sagepub.com/home/jcr\nSAGE\nNadiya Kostyuk¹, and Yuri M. Zhukov¹\n## Abstract\nRecent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.\n## Keywords\ncompellence, coercion, physical violence, conflict, cyber attacks\nOn December 23, 2015, hackers attacked Ukraine’s power grid, disabling control systems used to coordinate remote electrical substations, and leaving people in the capital and western part of the country without power for several hours. The Security\n¹Department of Political Science, University of Michigan, Ann Arbor, MI, USA\n## Corresponding Author:\nNadiya Kostyuk, Department of Political Science, University of Michigan, 505 S State Street, Ann Arbor, MI 48109, USA.\nEmail: nadiya@umich.edu\nService of Ukraine (SBU) blamed the Russian government for the cyber attack, an accusation that later found support in malware analysis by a private computer security firm. The Ukrainian hack was the first publicly acknowledged case of a cyber attack successfully causing a power outage. It is also just one of thousands of cyber activities, mostly diffuse and low level, that have occurred alongside physical fighting in Ukraine. Attacks launched through the digital realm are playing an increasingly visible role in civil and interstate conflict—in Ukraine, Syria, Israel, Estonia, Georgia, and beyond. Yet it remains unknown whether such activities have a real coercive impact on the battlefield.\nRecent years have seen growing concern over the coercive potential of cyber capabilities in war, but little evidence that these new tools are yet making a difference. Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence . Yet the logic of coercion entails distinct challenges in peace and war, with potentially different implications for the cyber domain. Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist  privilege massive cyber catastrophes over less sophisticated low-intensity attacks, like distributed denial of service (DDoS). The latter category, however, is far more common.\nThis article asks whether cyber attacks can compel short-term changes in battlefield behavior, using new event data on cyber and kinetic operations from armed conflicts in Ukraine and Syria. We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides , and—uniquely—overt claims of responsibility, public damage assessments, and other releases of information that reduce uncertainty over timing and attribution. Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques” . If cyber attacks can yet make a difference on the battlefield, Ukraine is one a few cases where we are most likely to observe such an effect. Our data include 1,841 unique cyber attacks and 26,289 kinetic operations by government and prorebel forces between 2014 and 2016. We supplement this quantitative analysis with fourteen primary source interviews with participants in the cyber campaign as well as Ukrainian, Russian, and Western cyber security experts with direct knowledge of these operations.\nTo evaluate the generalizability of the Ukrainian experience to other conflicts, we replicate our results with data from Syria's civil war. Like Ukraine, Syria has seen the extensive use of low-level cyber attacks by factions fighting for and against the incumbent regime. Because this war has gone on significantly longer than the conflict in Ukraine—giving hackers more time to organize and develop their capabilities—Syria offers a glimpse at cyber activities in a more protracted, higher intensity context. If we uncover similar patterns in two conflicts of such different scale and complexity, we can have greater confidence that our results are not artifacts of a single idiosyncratic case. Our data include 682 cyber attacks and 9,282 acts of violence by pro- and anti-Assad forces between 2011 and 2016.\nEvidence from both conflicts suggests that cyber attacks have not created forms of harm and coercion that visibly affect their targets' actions. Short of mounting synchronized, coordinated cyber campaigns, each group of hackers has seemed to operate in its own “bubble,” disengaged from unfolding events in both cyberspace and the physical world. The lack of discernible reciprocity between cyber and kinetic operations—and between the cyber actors themselves—questions whether cyber attacks can (yet) be successfully deployed in support of military operations.\nThis disconnect may be temporary, as joint planning and execution concepts continue to evolve. Many countries, for instance, still struggle in coordinating air-power for ground combat support, a century after World War I. Our study highlights some of the difficulties that countries will need to overcome in integrating and synchronizing these new capabilities.\nOur contribution is fourfold. We offer the first disaggregated analysis of cyber activities in war and take stock of the empirical relationship between the cyber and kinetic dimensions of modern battle. To do so, we collect the first microlevel data on wartime cyber attacks, using both open media sources and anonymous attack traffic data. Theoretically, our analysis addresses an important question on the coercive impact of low-level cyber attacks, advancing a literature that has been heavy on deductive argumentation, but light on evidence. Finally, from a policy standpoint, our findings should temper the popular tendency to overhype the transformative potential of cyber attacks. At present, interaction between cyber and kinetic operations is similar to that between airpower and ground operations in World War I—when armies began to use aircraft for reconnaissance but had not realized their full potential to shape battlefield outcomes.\n## Varieties of Cyber Activity\nThe term “cyber activities” captures a diverse assortment of tactics and procedures, directed against different types of targets, in pursuit of disparate objectives. Not all of these activities seek to achieve battlefield effects in the same way. Before proceeding further, we differentiate between two broad goals these actions tend to pursue: propaganda and disruption.\nCyber activities in the propaganda category seek to influence public opinion and indirectly undermine an opponent's financing or recruitment. Operations in this group include leaks of compromising private information, online publication of partisan content (e.g. “trolling” on comments pages), and the establishment of dedicated websites and forums to promote an armed group's message. Unless it openly incites or discourages violence, propaganda affects kinetic operations only indirectly by undermining an opponent's support base or obfuscating perceptions of events.\nIn the Ukrainian conflict, the importance of both groups attach to online propaganda is evident from the time and resources pro-Kyiv fighters spend updating Wikipedia, and pro-Russia groups devote to creating and running dedicated\nYouTube channels and social media accounts. Russian military doctrine places a heavy emphasis on the strategic use of information in warfare, as does US cyberspace joint planning doctrine.\nThe second category of cyber attacks—disruption—seeks to directly sabotage opponents' ability to operate in the physical or electronic realm. These mostly low-intensity activities include denial of service attacks, which make targeted resources unavailable through a flood of requests from a single source, and DDoS attacks, where requests originate from multiple compromised systems. Related efforts include inundating communications systems with floods of text messages or phone calls and using fire walls and proxies to block access to websites. At the extreme end of the scale is the use of malicious code to inflict physical damage or otherwise compromise infrastructure and military objects. Examples include interception of drones, communications and surveillance systems, control of Wi-Fi access points, and collection of protected information via phishing.\nThe most sophisticated known attack of this type is the Stuxnet worm, which—before its discovery in 2010—targeted industrial control systems critical to uranium enrichment in Iran. In Ukraine, notable disruptive activities have included attacks on the Central Election Committee's website during the 2014 presidential elections and attacks on the country's power grid in 2015 and 2016. Other examples include the use of malware to collect operational intelligence, like X-Agent, which retrieved locational data from mobile devices used by Ukrainian artillery troops, and the hacking of closed-circuit television (CCTV) cameras behind enemy lines.\nPropaganda and disruption are not mutually exclusive, and many cyber activities serve both purposes—shaping public opinion through disruption or disrupting an opponent's operations by shaping public opinion. For example, altering the visual appearance of websites can have the dual effect of embarrassing the target and limiting its ability to communicate. Leaks of private information also have dual implications for targets' public image and physical security.\nRecent examples of hybrid activities include the defacement of US Central Command's Twitter and Facebook pages by the Islamic State's (IS) Cyber Caliphate and operations by US Cyber Command against IS beginning in April 2016. In Ukraine, the pro-rebel group CyberBerkut (CB) has leaked private communications from senior United States, European Union, and Ukrainian officials and disclosed identities of pro-Kyiv field commanders—simultaneously creating a media scandal and forcing targets to commit more resources to personal security. Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations .\nIn the following, we limit the scope of our inquiry to cyber actions that are either purely disruptive (e.g. DDoS-style attacks) or are hybrids of the two approaches (e.g. web defacements). We do so for two reasons. First, most purely propagandistic operations, like comment-board trolling, do not aspire to influence the course of\nmilitary operations in the short term. Second, it is hard to separate the disruptive and propaganda effects of hybrid cyber activities because they depend on each other.\n## Cyber Coercion in Wartime\nOver the last two decades, cyber attacks have become an increasingly common tool of coercion, used by state and nonstate actors, independently and jointly with physical, kinetic operations. Like other instruments of coercion, cyber actions inflict costs on a target to compel a change in its behavior—either by punishing past misdeeds or by putting pressure on decision makers in real time.\nThe role of cyber compellence in wartime is not unlike that of airpower or terrorism . Cyber attacks cannot take or hold territory on their own, but they can support operations on the ground by disrupting opponents' command and control, collecting operational intelligence, and creating opportunities for conventional forces to exploit. If combatants use the Internet for coordination, recruitment, or training, low-level cyber disruption may prevent them from running these vital functions smoothly. Alternatively, cyber attacks can indirectly pressure an opponent by targeting civilian economy and infrastructure, similarly to strategic bombing. Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties . Unlike terrorism, the individual attacker is rarely at risk of direct physical harm.\nDespite the apparent promise of these “weapons of the future” , some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion . There is little doubt that large numbers of low-level attacks can cumulatively produce large-scale damage, bringing “death by a thousand cuts” (Lemay, Fernandeza, and Knight 2010). Yet successful coercion also requires punishment to be both anticipated and avoidable , and these criteria can be difficult to meet in cyberspace.\nCyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities . Since the destructiveness of malicious code depreciates quickly after first use, cyber attacks are often most damaging when they are least anticipated.\nTargets also have many reasons to doubt that cyber attacks are avoidable by accommodation. For the attacker, cyber actions present a trade-off between plausible deniability—which helps prevent retaliation—and the credibility of coercive promises and threats. Any uncertainty over the source of an attack will also create uncertainty over the nature of compliance—what sort of actions will prevent future attacks and by whom.\nBeyond attribution uncertainty, cyber attacks may not generate sufficient costs to elicit compliance from. Because administrators can quickly fix or contain many\nexploited vulnerabilities, even successful attacks cause only temporary disruption . Unless the attacker continues to develop new methods and identify new vulnerabilities, a protracted campaign may quickly lose its coercive impact. As a result, targets may see compliance as insufficient and unnecessary to stop the damage .\nForce synchronization challenges may also render the timing of cyber attacks suboptimal for compellence. Hackers—especially those not integrated with military forces—may not observe battlefield events on a tactically relevant time line. Even if they did, the lead time required to plan and implement a successful attack—studying the target system, collecting intelligence on its vulnerabilities, and writing code that exploits them—can make these efforts difficult to synchronize with conventional operations.\nThese challenges are not insurmountable. Lead time is a greater barrier for high-level attacks (e.g. targeting major infrastructure) than for more routine, DDoS-style attacks. Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower . The ability of contemporary hackers to overcome these difficulties, however, remains unknown.\n### Previous Research\nThe question of whether low-level cyber attacks compel has deep implications for the theory and practice of national security. Yet the public and academic debate on this topic has unfolded largely in the absence of rigorous empirical evidence in either direction. Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare , the overlap between cyber and kinetic capabilities , and the effect of information and communication technology on conflict .\nMost research in the first category has focused on the implications of cyber activities for peacetime deterrence or the offense--defense balance rather than wartime compellence. While the second group focuses more directly on cyber attacks during conflict, its empirical approach has been mostly qualitative, relying on evidence from descriptive case studies, macrohistorical surveys, and stylized facts. Some large-n analyses do exist , but their scope has remained on large-scale cyber attacks rather than the far more numerous low-intensity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action  rather than military compellence.\nOur study bridges the gap between these areas of inquiry. Our goal is to assess the coercive potential of low-level cyber actions during an armed conflict. We pursue this goal by studying the magnitude and direction of the relationship between cyber attacks and physical violence, using microlevel data from ongoing conflicts in Ukraine and Syria.\n### Empirical Expectations\nCyber attacks by actor A can affect physical violence by B in one of the three ways: negatively, positively, or not at all. If cyber compellence is successful, we should expect a short-term decrease in violence after a spike in cyber attacks. A positive response would suggest failure, where cyber attacks actually escalate violence by the opponent. If no relationship exists, cyber actions are either ineffective or irrelevant to fighting in the physical world.\nIn addition to compellence across domains, cyber attacks by actor A may impact cyber attacks by actor B. As before, only a negative relationship would imply coercive success, while a null or positive response would suggest that these actions are either ineffective or counterproductive.\n## Data Analysis\nTo evaluate whether and how cyber actions affect physical violence in war, we analyze new micro-level data from Ukraine and Syria. We begin with an in-depth study of the Ukrainian case, as one of few conflicts where both sides have used cyber attacks as a means of coercion. Due to the sophistication of hackers on both sides, the public nature of many attacks, and an abundance of data, the Ukrainian conflict allows us to observe the short-term coercive impact of cyber attacks. We then use analogous event data on Syria to evaluate the generalizability of our results. While a more systematic analysis of cross-national patterns lies beyond the scope of our article, micro-level evidence from these two conflicts might be suggestive of general patterns of modern warfare—particularly where combatants with asymmetric capabilities use cyberspace along with traditional tools of war.\nIn assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets , we draw data from multiple open sources—including press reports and anonymous attack traffic data. To reduce potential false positives, we include only those events that have been reported by more than one source.\n### Ukraine Cyber Attacks Data\nOur cyber event data on Ukraine include 1,841 unique, mostly low-level, cyber attacks from August 27, 2013, to February 29, 2016, drawn from two sets of sources.\nFirst are media reports of cyber attacks from rebel, Russian, Ukrainian, and Western news outlets, press releases and blogs along with social media platforms used by the involved nonstate actors. Second is the private cyber security firm Arbor Networks' Digital Attack Map (DAM; see http://www.digitalattackmap.com/about/). Unlike media sources—which include only cyber attacks publicly reported by news organizations or claimed by governments and hacker groups directly—DAM draws on anonymous attack traffic data and network outage reports to enumerate the top 2 percent of reported attacks that generate unusually high Internet traffic for each country. Including these “higher-visibility” attacks should make it easier to find a coercive effect.\nWe supplemented these data with fourteen primary source interviews with participants in the cyber campaign, as well as Russian, Ukrainian, and Western cyber security experts with direct knowledge of these operations, from the private and public sectors, academia, and journalism. We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix .\nWe grouped cyber attacks in our data set according to the partisanship of alleged perpetrators (pro-Ukrainian vs. prorebel) and the type of operation they conducted (propaganda vs. disruption). Table 1 list all actors conducting cyber activitiess in the Ukrainian conflict, their targets, and the reported frequency of their activities.\nUkrainian cyber actions include specific attacks by pro-Kyiv hackers like Anonymous Ukraine and Ukrainian Cyber Forces (UCFs). The latter is the most active group on the pro-Ukrainian side. In an interview, UCF leader Eugene Dokukin claimed to have established the nonstate group in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine . Pro-Kyiv hackers' most common targets are the communications and finances of rebel units as well as media firms and private companies in rebel-held areas.\nProrebel cyber actions include specific attacks by proseparatist or pro-Russian cyber actors, like CB, Cyber Riot Novorossiya, Green Dragon, and the Russian government. The first of these takes its name from Ukraine's disbanded Berkut riot police and claims to fight “neofascism” in Ukraine. Ukrainian and Russian cyber experts we interviewed offered contradictory assessments on CB's organizational structure. One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution . Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB . These groups' most popular targets include Ukrainian government officials, media, and private citizens.\nWe further disaggregated these events into the two categories previously defined—propaganda or disruption—as well as a third, hybrid, category of incidents\nTable I. Actors and Targets (Ukraine and Syria).\n|  Ukraine  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Pro-Kyiv | Actor/target | Frequency (%) | Prorebel | Actor/target | Frequency (%)  |\n|  Anonymous Ukraine | A | 6 (<1) | CyberBerkut | A | 134 (7)  |\n|  Ukrainian Cyber Forces | A | 1,392 (76) | Cyber Riot Novorossiya | A | 41 (2)  |\n|  Ukrainian governmental units and officials | A/T | 3 (<1)/326 (18) | Green Dragon | A | 1 (<1)  |\n|  Ukrainian army units | T | 1 (<1) | Quedagh | A | 1 (<1)  |\n|  Western governments and organizations | T | 15 (1) | Crimean government officials | T | 6 (<1)  |\n|  Western non-state actors | T | 7 (<1) | Russian army units | A/T | 1 (<1)/14 (1)  |\n|  Non-state supporters | T | 91 (5) | Non-state supporters | T | 444 (24)  |\n|   |  |  | Rebel groups | A/T | 2 (<1)/926 (50)  |\n|   |  |  | Russian state units and government officials | A/T | 2 (<1)/14 (1)  |\n|   |  |  | Russian state-sponsored groups | A | 237 (13)  |\n|  Total |  | 1,841 (100) |  |  | 1,841 (100)  |\n|  Syria  |   |   |   |   |   |\n|  Anti-Assad | Actor/target | Frequency (%) | Pro-Assad | Frequency (%) | Actor/target  |\n|  Anonymous/anonymous-sponsored units | A | 93 (14) | ISIL/ISIL-sponsored units | A | 54 (8)  |\n|  Anti-Assad non-state actors | A/T | 297 (44)/18 (3) | Russian government units | A | 3 (<1)  |\n|  Jabhat al-Nusra-sponsored units | A | 1 (<1) | Syrian government units and officials | A/T | 2 (<1)/272 (40)  |\n|  Kurdish non-state opposition | A | 11 (<2) | Syrian state-sponsored units | A/T | 102 (15)/2 (<1)  |\n|  Free Syrian Army | T | 1 (<1) | Pro-Assad non-state actors | T | 179 (26)  |\n|  Pro-ISIL social media and websites | T | 140 (21) |  |  |   |\n|  Total |  | 682 (100) |  |  | 682 (100)  |\nNote: ISIL = The Islamic State of Iraq and the Levant.\nthat potentially serve both purposes. The most common cyber actions in Ukraine have been DDoS-style attacks, followed by hacks of CCTV cameras and other communications. Website blockages have also proven popular, as have spearphishing e-mails targeting specific individuals. Table 2 provides a full breakdown.\nTo reduce false positives due to unconfirmed reports or dubious claims of responsibility, we only include attacks reported by more than one source. To account for uncertainty of attribution, we marked as “disputed” all cases where no one claimed responsibility and labeled as “nondisputed” those operations for which actors directly claimed responsibility in press releases, on social media, or in interviews. To focus on daily dynamics, we excluded activities whose intensity did not vary over time.\nFigure 1a depicts the temporal dynamics of pro-Ukrainian (Cyber U) and pro-Russian rebel (Cyber R) cyber operations. In early March 2014, about a week after the revolution in Kyiv, Figure 1 shows a spike in attacks by CB. The same month saw the establishment of the pro-Kyiv Ukrainian Cyber Forces, partly in response to CB's attacks. However, UCF operations do not become visible until May 2014, following an influx of volunteers to the group. May 2014 is also notable for a rise in activities by another pro-Russian cyber group, Cyber Riot Novorossiya—named after the czarist-era term (“New Russia”) for territories in southeastern Ukraine. After the first Minsk cease-fire agreement in September 2014, operations by pro-Ukrainian hackers converge to a steady rate of two to four per day, with occasional flare-ups, as in December 2014. Activities by pro-Russian hackers, by contrast, declined after the summer 2014.\n### Ukraine Violent Events Data\nOur data on kinetic operations include 26,289 violent events from Ukraine's Donbas region, recorded between February 28, 2014, and February 29, 2016. To offset reporting biases in any one source, while guarding against potential disruptions in media coverage due to cyber attacks, these data draw on seventeen Ukrainian, Russian, rebel, and international sources. As before, we include only events that appeared in more than one source.\nTo extract information on dates, locations, participants, and other event details, we relied on a combination of supervised machine learning (Support Vector Machine) and dictionary-based coding. The Online Appendix describes our measurement strategy and provides summary statistics.\nFigure 1b shows the temporal distribution of pro-Ukrainian (Kinetic U) and pro-Russian rebel (Kinetic R) physical violence. The plot shows several notable flare-ups of fighting—during a government offensive in late June 2014 and a rebel offensive in January 2015—as well as lulls following cease-fire agreements in September 2014, February 2015, and September 2015. Compared to the cyber operations in Figure 1, this plot reveals a clear correlation between kinetic operations\nTable 2. Types of Cyber Operations (Ukraine and Syria).\n|  Propaganda | Ukraine (%) | Syria (%) | Disruption | Ukraine (%) | Syria (%) | Both | Ukraine (%) | Syria (%)  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  PPI—publishing online private information of the members of the conflicting parties | 47 (2) | 59 (9) | AVG— audio-, video-, and geo-intelligence collection | 423 (23) | 1 (<1) | WDT—website defacement | 51 (3) | 389 (57)  |\n|  PRM/PUM—posting pro-rebel and pro-Ukrainian messages online | 54 (3)/5 (<1) | — | CPI—collecting private information via open sources | 13 (<1) | 10 (<2) |  |  |   |\n|  UWP—updating online pages | 6 (<1) | — | DDoS—distributed denial-of-service attack | 499 (27) | 78 (11) |  |  |   |\n|   |   |   |  ODS—other attacks with a purpose of disruption or espionage | 9 (1) | 10 (<2) |  |  |   |\n|   |   |   |  SPE—spear-phishing e-mail | 234 (13) | 17 (2.5) |  |  |   |\n|   |   |   |  STM—sending massive text messages or calling phones non-stop | 40 (2) | 1 (<1) |  |  |   |\n|   |   |   |  WBG—website blockage | 257 (14) | 376 (55) |  |  |   |\n|  Total | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100)  |\n|   |   |   |  |   |   |   |   |   |\nJournal of Conflict Resolution 63(2)\n(a) cyber\n(b) kinetic\nFigure 1. Cyber and kinetic operations in Ukraine . U (blue) indicates operations by Ukrainian government forces; R (red) indicates operations by pro-Russian rebel groups.\nby the two sides, with government and rebel attacks rising and falling in tandem. $^{15}$  Although this interdependence is not surprising, the data suggest that—with few exceptions—physical violence in Ukraine has been a reciprocal affair.\nFrom a brief glance at the timing of cyber and physical operations (Figure 1a and b), there are relatively few signs of a compelling effect—changes in the former do not appear to drive changes in the latter. However, a visual comparison can be misleading. Some of the variation may be due to fighting on the ground or in cyberspace, but other changes may reflect secular trends or shocks due to elections and other events not directly related to conflict. To account for these potential confounding factors and to gauge whether there is a stronger cyber-kinetic relationship than we would expect by chance, we conduct a series of more rigorous tests.\nEmpirical Strategy\nTo evaluate the relationship between cyber and kinetic operations in Ukraine, we estimate a series of vector autoregressive models\n$Y_{t} = \\sum\\limits_{j}^{p}B_{j}Y_{t - j} + GX_{t} + \\mu_{0} + \\mu_{1}t + \\mathbf{\\epsilon_{t}},$ (1)\nwhere $Y_{t} = \\left[y_{t}^{\\text{Kinetic(U)}}, y_{t}^{\\text{Kinetic(R)}}, y_{t}^{\\text{Cyber(U)}}, y_{t}^{\\text{Cyber(R)}}\\right]^{\\prime}$ is a matrix of endogenous variables, and $X_{t} = \\left[x_{1t},\\ldots,x_{kt}\\right]^{\\prime}$ is a matrix of k exogenous variables, which includes indicators for key dates and events during the war, like presidential and parliamentary electoral campaigns in Ukraine and breakaway territories; cease-fire agreements; and Ukrainian, Russian, and Soviet holidays. Deterministic components include a constant term (μ_{0}) and trend (μ_{1}t). p is the lag order, selected via Bayesian information criterion, and $\\mathbf{\\epsilon_{t}}$ is a vector of serially uncorrelated errors.\nWe control for Ukrainian, Russian, and Soviet holidays because anecdotal accounts suggest significant increases in cyber activity during such times. The UCF, for instance, had an operation called “Happy New Year,” which sought to print pro-Ukrainian messages from hacked printers in Crimea, Russia, and Donbas. National election campaigns represent another time when such activities may spike. Before and during the presidential elections, for instance, hackers bombarded Ukraine's Central Electoral Committee website with DDoS attacks. Finally, we may expect cease-fire agreements aimed at reducing physical violence to also have an effect in the cyber domain. For example, the cyber espionage operation “Armageddon”—directed against Ukrainian government websites—intensified before the Minsk I agreement went into force but then rapidly declined.\nBecause we are interested in the relationship between cyber attacks and physical violence during war, we limit our primary analysis to the active phase of military operations between May 11, 2014, and February 15, 2015—the period following independence referendums organized by the self-proclaimed Donetsk and Luhansk People's Republics and the second Minsk cease-fire agreement. In the Online Appendix, we present additional analyses of the full data set, which produced similar results.\n## Results\nData from Ukraine support the skeptical view of cyber coercion. The impulse--response curves in Figure 2 show a strong, escalatory dynamic between kinetic operations by the two sides (Kinetic U, Kinetic R), but no tangible links in either direction between kinetic and cyber operations, and no reciprocity between cyber actions (Cyber U, Cyber R).\nFollowing a standard deviation increase in kinetic rebel attacks, government violence sees a delayed rise, peaking around two days after the shock and gradually\n|  Response: |   |\n| --- | --- |\n|  Kinetic (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  |\n|  Kinetic (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  |\n|  Cyber (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  |\n|  Cyber (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  |\nFigure 2. Impulse response matrix, daily time series (Ukraine). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"U\" indicates reported kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\ndeclining back to zero (top row, second column). Rebel operations also rise after shocks to government operations (second row, first column), but the response here is immediate, without the delay we observe in government operations. This pattern may reflect command and control inefficiencies in the Ukrainian army, particularly early in the conflict, when indecision and leadership turnover lengthened decision cycles.\nThe relationship between cyber and kinetic operations is far weaker than that between rebel and government violence on the ground. Cyber attacks by pro-Ukrainian forces see no increase after shocks in kinetic government operations, and a positive, but uncertain increase after shocks in kinetic rebel operations (third row, first and second columns).\nThere is even less evidence that cyber attacks drive kinetic operations. The impulse--response function (IRF) curve for pro-Ukrainian government violence is, in fact, negative after shocks to rebel cyber operations (top row, two rightmost columns). Although this negative response might otherwise suggest that cyber attacks compel a decline in violence—consistent with coercive success—the estimate is also highly uncertain. Following shocks to pro-Ukrainian cyber activities, meanwhile, the main change in rebel kinetic operations is a short-term increase in volatility (second row, third column). In sum, the data suggest that cyber attacks may make violence less predictable but do not systematically change its intensity.\nPerhaps most surprisingly, there is little or no apparent strategic interaction between “cyber-warriors” on each side of the conflict. A shock in pro-Ukrainian cyber attacks yields no discernible change in pro-rebel cyber attacks (bottom row, third column) and vice versa (third row, fourth column). The two cyber campaigns, the data suggest, have unfolded independently of each other and independently of events on the ground.\nAs the diagonal elements in Figure 2 suggest, there is strong autocorrelation in each series. For each of the four categories, past shocks in operations yield a significant spike in subsequent operations. To evaluate whether the other categories of events can help us predict future values of each series, after we take this autocorrelation into account, Table 3 reports the results of Granger causality tests. The tests confirm that past levels of prorebel and pro-Kyiv kinetic operations help predict each other's future values. Kinetic operations, however, do not appear to “Granger cause”—or be “Granger caused” by—cyber attacks on either side.\nTable 4 reports the forecasting error variance decomposition, representing the proportion of variation in each series (rows) due to shocks in each endogenous variable (columns). For most variables, their own time-series account for almost all variation at the outset, but this dependency gradually decreases. As before, there is far more dependence within kinetic operations than between kinetic and cyber or within cyber actions. By the thirty-day point in the daily time series, shocks in rebel attacks account for 7 percent of variation in Ukrainian government operations, while shocks in government operations explain 12 percent of variation in rebel violence.\nJournal of Conflict Resolution 63(2)\nTable 3. Granger Causality Test, Daily Time Series (Ukraine).\n|  Effects | F statistic | p value  |\n| --- | --- | --- |\n|  Kinetic (R) → Kinetic (U) | 40.26 | .00  |\n|  Cyber (U) → Kinetic (U) | 0.50 | .48  |\n|  Cyber (R) → Kinetic (U) | 0.09 | .76  |\n|  Kinetic (U) → Kinetic (R) | 12.29 | .00  |\n|  Cyber (U) → Kinetic (R) | 1.44 | .23  |\n|  Cyber (R) → Kinetic (R) | 2.70 | .10  |\n|  Kinetic (U) → Cyber (U) | 1.40 | .24  |\n|  Kinetic (R) → Cyber (U) | 1.88 | .17  |\n|  Cyber (R) → Cyber (U) | 0.00 | .95  |\n|  Kinetic (U) → Cyber (R) | 1.74 | .19  |\n|  Kinetic (R) → Cyber (R) | 0.14 | .71  |\n|  Cyber (U) → Cyber (R) | 0.89 | .35  |\nNote: \"U\" indicates reported kinetic and cyber operations by Pro-Ukrainian government forces, and \"R\" indicates operations by Pro-Russian rebel forces.\nTable 4. Variance Decomposition, Daily Time Series (Ukraine).\n|  Operation type | Kinetic (U) | Kinetic (R) | Cyber (U) | Cyber (R)  |\n| --- | --- | --- | --- | --- |\n|  Kinetic (U) |  |  |  |   |\n|  1 Day | 1.000 | .000 | .000 | .000  |\n|  2 Days | 0.920 | .060 | .002 | .018  |\n|  7 Days | 0.906 | .071 | .002 | .020  |\n|  30 Days | 0.906 | .071 | .002 | .020  |\n|  Kinetic (R) |  |  |  |   |\n|  1 Day | 0.108 | .892 | .000 | .000  |\n|  2 Days | 0.121 | .873 | .000 | .006  |\n|  7 Days | 0.122 | .870 | .000 | .008  |\n|  30 Days | 0.122 | .870 | .000 | .008  |\n|  Cyber (U) |  |  |  |   |\n|  1 Day | 0.000 | .002 | .998 | .000  |\n|  2 Days | 0.000 | .002 | .997 | .000  |\n|  7 Days | 0.000 | .003 | .997 | .000  |\n|  30 Days | 0.000 | .003 | .997 | .000  |\n|  Cyber (R) |  |  |  |   |\n|  1 Day | 0.012 | .023 | .000 | .964  |\n|  2 Days | 0.014 | .023 | .001 | .962  |\n|  7 Days | 0.015 | .023 | .001 | .961  |\n|  30 Days | 0.015 | .023 | .001 | .961  |\nNote: \"U\" indicates kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\nBy contrast, shocks to cyber activities account for very little variation in kinetic operations. The highest value is for pro-Russian rebel cyber activities, which account for 2 percent of short-term variation in government violence. Cyber attacks by each side also have a relatively small impact on each other. Indeed, rebel kinetic operations explain more of the variation in cyber attacks by each actor than do cyber attacks by the other side.\nIn sum, our analysis suggests that low-level cyber attacks in Ukraine have had no effect on the timing of physical violence. Not only is there no evidence that cyber attacks have compelled opponents to de-escalate fighting, there is no discernible reciprocity between the cyber actors themselves. Each group of hackers seems to operate in its own bubble, disengaged from unfolding events in both cyberspace and the physical world.\n### Robustness Checks\nTo gauge the sensitivity of our results to various modeling and measurement choices, we conducted extensive robustness checks. We summarize their results briefly here (Table 5) and more fully in the Online Appendix.\nThe first set of tests considers vector autoregression models with alternative orderings of the four endogenous variables, which affects estimation of impulse responses. We find no substantive differences across the twenty-four permutations.\nIn a second set of robustness checks, we account for systematic differences in the kinds of conflict events that Ukrainian and Russian media report, which may bias statistical estimates—for example, by underreporting violence by a given actor. Using kinetic data from exclusively Russian or exclusively Ukrainian sources does not change the results.\nA third set of robustness tests examines different subsets of cyber attacks. Because purely disruptive activities may impose greater immediate costs than quasi-propagandistic hybrid attacks, pooling these events may dilute their coercive effect. Our results are consistent for all three subsets.\nThe last set of robustness checks examines different time periods of the conflict, since some cyber attacks predated military activity. In particular, we compare the period of intense fighting previously analyzed (May 11, 2014--February 15, 2015) to the entire date range for which we have data (February 28, 2014--February 29, 2016). Our results remain unchanged.\n## Evidence from Interviews\nIn interviews, Russian and Ukrainian cyber security experts highlighted five potential explanations for the apparent failure of cyber coercion in Ukraine: (1) lack of resources, (2) lack of coordination, (3) lack of targets, (4) lack of audience, and (5) lack of effort.\nTable 5. Robustness Checks (Ukraine and Syria).\n|  Ukraine (main results; May 11, 2014–February 15, 2015)  |   |   |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n|  I | Disruption and both | Kin(R) ↔ Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) ↔ Kin(R) | Kin(U) ↔ Kin(R) | Kin(U) → Kin(G)  |\n|  ID | Cyber | GCT(w) | VD(d) (30 day) | VD(w) (12 week) |  |  |   |\n|  I | Disruption and both |  | Kin(R) → 7%Kin(U) | Kin(R) → 10%Cyb(R) |  |  |   |\n|   |   |   | Kin(R) → 2%Cyb(R) | Kin(U) → 21%Kin(R) |  |  |   |\n|   |   |   | Kin(U) → 12%Kin(R) | Kin(U) → 17%Cyb(R) |  |  |   |\n|   |   |   | Kin(U) → 2%Cyb(R) | Cyb(U) → 4%Cyb(R) |  |  |   |\n|  ID | Cyber | IRF(d) | IRF(w) | GCT(d) | GCT(w) | VD(d) (30 day) | VD(w) (12 week)  |\n|  Ukraine (March 22, 2014–February 29, 16)  |   |   |   |   |   |   |   |\n|  2 | All | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U/R) ↔ Kin(U) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Cyb(U) ↔ Kin(R) |  |  | Kin(U) → 3%Cyb(R)  |\n|  3 | Propaganda | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin(U)/Cyb(R) | Kin(R) → 3%Kin(U) | Kin(R) → 9%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) → Kin/Cyb(R) | Kin(U) → Cyb(R) | Kin(U) → 18%Kin(R) | Kin(R) → 3%Cyb(R)  |\n|   |   |   | Cyb(U) → Kin(U) | Kin(U) → Cyb(R) |  |  | Kin(U) → 46%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(R)  |\n|  4 | Disruption | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(U/R) |  | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|  5 | Disruption and both | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(R) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Kin(U) → Cyb(U) |  |  |   |\n(continued)\nTable 5. (continued)\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) Ukraine (May 11, 2014-February 11, 2015) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  6 | All | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) |  | Kin(R) → 7%Kin(U) | Kin(R) → 2%Cyb(U)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(U) → 13%Kin(R) | Kin(R) → 18%Cyb(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 30%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(U/R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 4%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(U)  |\n|  7 | Propaganda | Kin(R) → Kin(U) | Cyb(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Cyb(R) | Kin(R) → 7%Kin(U) | Kin(U) → 27%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) |  |  | Kin(U) → 13%Kin(R) | Kin(U) → 4%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 3%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 9%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 20%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 5%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(R) → 2%Cyb(U)  |\n|  8 | Disruption | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → Cyb(U) | Kin(R) → 7%Kin(U) | Kin(U) → 29%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(R) → 2%Cyb(R) | Kin(U) → 34%Cyb(U)  |\n|   |   |   |  |  |  | Kin(U) → 12%Kin(R) | Kin(U) → 22%Cyb(R)  |\n|   |   |   |  |  |  | Cyb(R) → 2%Kin(U) | Kin(R) → 3%Kin(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 10%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 13%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 6%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 7%Cyb(U)  |\nSyria (March 17, 2011-July 10, 2016)\n|  9 | Disruption and both | Kin(G) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → 2%Kin(R)  |\n| --- | --- | --- | --- | --- |\nNote: IRF = impulse response functions; GCT = Granger causality tests; VD = variance decomposition; d = daily; w = weekly; o = alternative orderings; RU = Russian; U = Ukrainian.\nThe first explanation for coercive failure emphasizes limited resources and capabilities, particularly for the Ukrainian government. Ten years ago, the SBU briefly had a cyber department but shut it down after a year . This unit has recently reopened but continues to lack funding and personnel . It is possible that, with adequate resources, capabilities, and human capital, the Ukrainian cyber campaign might have been more effective. Resource constraints, however, do not explain coercive failure on the pro-Russian side, where investment in cyber capabilities is more robust.\nA second explanation is lack of government coordination with hackers, especially in Kyiv . UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success . The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place . Yet again, this explanation is less plausible on the pro-Russian side, where the Kremlin has cultivated extensive ties with non-state hacktivists.\nA third explanation is that—even with requisite capabilities and coordination—there are few opportune targets for disruption in Ukraine. Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult . Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack” . The 2015 and 2016 hacks of Ukraine's power grid also seem to challenge this explanation.\nThe peculiarities of Ukraine's online population represent a fourth explanation for the indecisiveness of cyber attacks. Since only 44.1 percent of Ukrainians have Internet access—compared to 88.5 percent in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses . Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones . Our data suggest that, even if this were the case, propagandistic attacks still had no effect on violence.\nThe final explanation is that cyber compellence failed because it was never seriously attempted. At first, our interviews with individual hackers revealed no shortage of coercive intent. UCF leader Eugene Dokukin claimed to conduct low-level attacks daily and vowed to continue until pro-Russian rebels lay down their arms. Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns .\nWhile UCF and other nonstate groups have explicitly sought to affect battlefield outcomes, some interviewees questioned whether this intent extended to the Russian\ngovernment. Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place . This access, along with vigorous cyber espionage—some of it ongoing since 2010—may create incentives against more aggressive actions, which could compromise valuable sources of intelligence.\nConsistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda . When in 2011 Vyacheslav Volodin replaced Vladislav Surkov as head of the Presidential Administration, he toughened existing laws against Russia's opposition and promoted the use of mass media and online platforms—tools already mostly under state control—to conduct information campaigns. If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising .\n## Evidence beyond Ukraine: Syria's Digital Front\nAccording to evidence from microlevel data and interviews, cyber attacks did not affect battlefield events in Ukraine. During one of the first armed conflicts where both sides used low-level cyber actions extensively, events in the digital realm have unfolded independently of—and have had no discernible effect on—events on the ground. Conditions in Ukraine were in many ways optimal to observe the coercive impact of cyber actions, for reasons we already discussed (i.e. visibility of major attacks, regular claims of responsibility, less uncertainty over attribution). Yet we found no evidence that low-level cyber attacks affected physical violence. Nor did hackers on each side even affect each other's activities.\nWhile important, Ukraine is not the only contemporary conflict with a significant cyber dimension. In Syria, state and nonstate actors have employed low-level cyber actions extensively for propaganda and disruption, complementing traditional tools of warfare in the deadliest conflict ongoing today. Syria's war has also lasted three years longer than Ukraine's. Over this time, its digital front has expanded in scope and sophistication, offering a glimpse of cyber coercion in a more protracted setting.\nAn in-depth study of Syria's digital front lies beyond the scope of this article. A brief analysis of the data, however, suggests that our findings from Ukraine may be part of a broader pattern: cyber capabilities have not yet evolved to the point of having an impact on physical violence.\nTo evaluate the effectiveness of cyber compellence in this second case, we replicated the model in (equation 1), using an analogous daily time series of cyber attacks and violent events in Syria. Our data comprise 9,282 kinetic and 682 low-level cyber attacks ranging from March 2011 until July 2016. Table 2 provides a breakdown of cyber techniques used in the Syrian conflict, their brief description, and frequency. Our data on kinetic operations rely on human-assisted machine\nJournal of Conflict Resolution 63(2)\nFigure 3. Cyber and kinetic operations in Syria . G (blue) indicates operations by pro-Assad government forces; R (red) indicates operations by anti-Assad rebel groups.\ncoding of event reports from the International Institute for Strategic Studies Armed Conflict Database (see Online Appendix for details).\nGiven the complex nature of the Syrian conflict and the multiple parties involved, we restrict our analysis only to operations by progovernment forces (i.e., Syrian Army, Hezbollah and pro-Assad militias) and the main rebel opposition (i.e., Free Syrian Army, Jaish al-Fatah, including Al Nusra Front). Table 1 provides a list of cyber actors in the Syrian conflict, their targets, and frequency of their activities.\nThe dynamics of cyber and kinetic operations in Syria exhibit similar patterns to what we saw in Ukraine. Raw data (Figure 3a and b) suggest relatively little overlap in timing, especially at the beginning of the conflict. The IRF curves in Figure 4 show a rise in rebel operations following shocks to government operations (second row, first column), and mostly negligible (though negative) links between cyber and kinetic operations, and across cyber attacks by each actor. Links between kinetic\n|  Response: |   |\n| --- | --- |\n|  Kinetic (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380 385 390 395  |\n|  Kinetic (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295  |\n|  Cyber (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 260 270 275  |\n|  Cyber (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230  |\n|  Impulse: | Kinetic (G) Kinetic (R) Cyber (G) Cyber (R)  |\nFigure 4. Impulse response matrix, daily time series (Syria). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"G\" indicates reported kinetic and cyber operations by pro-Assad government forces, and \"R\" indicates operations by anti-Assad rebel forces.\noperations—and their disconnect from cyber attacks—are also evident in variance decomposition results, and Granger tests, provided in the Online Appendix.\nThere are several reasons for caution in interpreting these results. The Syrian conflict involves a larger constellation of actors than Ukraine, and our dyadic analysis may overlook significant interactions elsewhere, particularly between actors with more developed cyber capabilities (e.g. Russia, United States). We also lack interview evidence that might help contextualize the null effect. However tentative, these results do align with what we saw in Ukraine: low-level cyber attacks have had little or no impact on violence.\n## Conclusion\nThe evidence we presented in this article—based on analysis of new data and expert interviews—suggests that cyber attacks are ineffective as a tool of coercion in war. Although kinetic operations explain the timing of other kinetic operations, low-level cyber attacks have no discernible effect on violence in the physical world. In Ukraine and Syria, the “cyberwar” has unfolded in isolation from the rest of the conflict.\nThis finding has several implications for theory and policy. First, by providing the first statistical analysis of modern low-level cyber campaigns, our study complements the qualitative focus of previous empirical work. Second, our research sheds light on a theoretical question about the strength and direction of the cyber--kinetic relationship and—in so doing—begins to fill an empirical gap in political science literature on this topic. Third, to the extent that policymakers might overestimate the importance of cyber actions due to a lack of empirical evidence to the contrary, our findings can potentially help correct this misperception. Finally, and more worryingly, our results suggest that—due to their disconnect from physical violence—low-level cyber attacks are very difficult to predict.\nFurther research is needed to understand the dynamics of low-level cyber attacks. One such area of research is cyber coercion in the context of symmetric, conventional war. While our study helps illuminate dynamics of cyber compellence between parties with asymmetric capabilities, we may well observe different patterns when major powers use cyberspace against peer competitors. Thankfully, no armed conflict has yet provided researchers with the data needed to evaluate this possibility.\nSecond, our scope in this article has been exclusively on short-term military consequences rather than long-term political effects. The latter are no less theoretically significant, but—unlike simple counts of violent events—potentially more difficult to measure and analyze. A study of long-term political effects would also need to more systematically incorporate purely propagandistic cyber activities and their impact on public opinion, which we omitted here due to our focus on short-term military compellence.\nAlthough the secretive nature of many ongoing physical and digital operations is a challenge for this research, questions over the coercive potential of cyber attacks\nwill become only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” —have yielded few tangible successes . Our data from Ukraine indicate that the US experience may be part of a broader pattern.\nAt best, coordination between low-level cyber and kinetic operations today is on roughly the same level as that between airpower and ground operations in World War I. Back then, armies were increasingly using aircraft for reconnaissance and surveillance on the front but were not yet able to fully exploit their potential for ground combat support and strategic bombing. That revolution appeared on the battlefield twenty-five years later, with devastating effect. As cyber capabilities develop and synchronization challenges become less severe, there will be a growing need for assessments of how far we have come. We hope that analyses of the sort we provided in these pages can serve as an early benchmark.\n## Authors' Note\nA previous version of this article was presented at the 2015 Peace Science Society International annual meeting, Oxford, MS, and at the Association for the Study of Nationalities Convention at New York, NY.\nWe are grateful to Maura Drabik, Paulina Knoblock, Neil Schwartz, and Alyssa Wallace for excellent research assistance. Robert Axelrod, Myriam Dunn-Cavelty, Eric Gartzke, Miguel Gomez, Todd Lehmann, Jon Lindsay, Tim Maurer, Brandon Valeriano, Christopher Whyte, and workshop participants of the Conflict & Peace, Research & Development workshop at the University of Michigan, of the Bridging the Gap Workshop on Cyber Conflict at Columbia University, of the Cross-Domain Deterrence lab at the University of California, San Diego, and of the Center for Security Studies at ETH Zurich provided helpful comments on the earlier drafts of this article.\n## Declaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n## Funding\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.\n## Supplemental Material\nSupplemental material for this article is available online.",
  "citations": {
    "style": "author_year",
    "flat_text": "Check for updates\nArticle\n# Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\nJournal of Conflict Resolution\n2019, Vol. 63(2) 317-347\n© The Author(s) 2017\nArticle reuse guidelines:\nsagepub.com/journals-permissions\nDOI: 10.1177/0022002717737138\njournals.sagepub.com/home/jcr\nSAGE\nNadiya Kostyuk¹, and Yuri M. Zhukov¹\n## Abstract\nRecent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.\n## Keywords\ncompellence, coercion, physical violence, conflict, cyber attacks\nOn December 23, 2015, hackers attacked Ukraine’s power grid, disabling control systems used to coordinate remote electrical substations, and leaving people in the capital and western part of the country without power for several hours. The Security\n¹Department of Political Science, University of Michigan, Ann Arbor, MI, USA\n## Corresponding Author:\nNadiya Kostyuk, Department of Political Science, University of Michigan, 505 S State Street, Ann Arbor, MI 48109, USA.\nEmail: nadiya@umich.edu\nService of Ukraine (SBU) blamed the Russian government for the cyber attack, an accusation that later found support in malware analysis by a private computer security firm. The Ukrainian hack was the first publicly acknowledged case of a cyber attack successfully causing a power outage. It is also just one of thousands of cyber activities, mostly diffuse and low level, that have occurred alongside physical fighting in Ukraine. Attacks launched through the digital realm are playing an increasingly visible role in civil and interstate conflict—in Ukraine, Syria, Israel, Estonia, Georgia, and beyond. Yet it remains unknown whether such activities have a real coercive impact on the battlefield.\nRecent years have seen growing concern over the coercive potential of cyber capabilities in war, but little evidence that these new tools are yet making a difference. Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence . Yet the logic of coercion entails distinct challenges in peace and war, with potentially different implications for the cyber domain. Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist  privilege massive cyber catastrophes over less sophisticated low-intensity attacks, like distributed denial of service (DDoS). The latter category, however, is far more common.\nThis article asks whether cyber attacks can compel short-term changes in battlefield behavior, using new event data on cyber and kinetic operations from armed conflicts in Ukraine and Syria. We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides , and—uniquely—overt claims of responsibility, public damage assessments, and other releases of information that reduce uncertainty over timing and attribution. Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques” . If cyber attacks can yet make a difference on the battlefield, Ukraine is one a few cases where we are most likely to observe such an effect. Our data include 1,841 unique cyber attacks and 26,289 kinetic operations by government and prorebel forces between 2014 and 2016. We supplement this quantitative analysis with fourteen primary source interviews with participants in the cyber campaign as well as Ukrainian, Russian, and Western cyber security experts with direct knowledge of these operations.\nTo evaluate the generalizability of the Ukrainian experience to other conflicts, we replicate our results with data from Syria's civil war. Like Ukraine, Syria has seen the extensive use of low-level cyber attacks by factions fighting for and against the incumbent regime. Because this war has gone on significantly longer than the conflict in Ukraine—giving hackers more time to organize and develop their capabilities—Syria offers a glimpse at cyber activities in a more protracted, higher intensity context. If we uncover similar patterns in two conflicts of such different scale and complexity, we can have greater confidence that our results are not artifacts of a single idiosyncratic case. Our data include 682 cyber attacks and 9,282 acts of violence by pro- and anti-Assad forces between 2011 and 2016.\nEvidence from both conflicts suggests that cyber attacks have not created forms of harm and coercion that visibly affect their targets' actions. Short of mounting synchronized, coordinated cyber campaigns, each group of hackers has seemed to operate in its own “bubble,” disengaged from unfolding events in both cyberspace and the physical world. The lack of discernible reciprocity between cyber and kinetic operations—and between the cyber actors themselves—questions whether cyber attacks can (yet) be successfully deployed in support of military operations.\nThis disconnect may be temporary, as joint planning and execution concepts continue to evolve. Many countries, for instance, still struggle in coordinating air-power for ground combat support, a century after World War I. Our study highlights some of the difficulties that countries will need to overcome in integrating and synchronizing these new capabilities.\nOur contribution is fourfold. We offer the first disaggregated analysis of cyber activities in war and take stock of the empirical relationship between the cyber and kinetic dimensions of modern battle. To do so, we collect the first microlevel data on wartime cyber attacks, using both open media sources and anonymous attack traffic data. Theoretically, our analysis addresses an important question on the coercive impact of low-level cyber attacks, advancing a literature that has been heavy on deductive argumentation, but light on evidence. Finally, from a policy standpoint, our findings should temper the popular tendency to overhype the transformative potential of cyber attacks. At present, interaction between cyber and kinetic operations is similar to that between airpower and ground operations in World War I—when armies began to use aircraft for reconnaissance but had not realized their full potential to shape battlefield outcomes.\n## Varieties of Cyber Activity\nThe term “cyber activities” captures a diverse assortment of tactics and procedures, directed against different types of targets, in pursuit of disparate objectives. Not all of these activities seek to achieve battlefield effects in the same way. Before proceeding further, we differentiate between two broad goals these actions tend to pursue: propaganda and disruption.\nCyber activities in the propaganda category seek to influence public opinion and indirectly undermine an opponent's financing or recruitment. Operations in this group include leaks of compromising private information, online publication of partisan content (e.g. “trolling” on comments pages), and the establishment of dedicated websites and forums to promote an armed group's message. Unless it openly incites or discourages violence, propaganda affects kinetic operations only indirectly by undermining an opponent's support base or obfuscating perceptions of events.\nIn the Ukrainian conflict, the importance of both groups attach to online propaganda is evident from the time and resources pro-Kyiv fighters spend updating Wikipedia, and pro-Russia groups devote to creating and running dedicated\nYouTube channels and social media accounts. Russian military doctrine places a heavy emphasis on the strategic use of information in warfare, as does US cyberspace joint planning doctrine.\nThe second category of cyber attacks—disruption—seeks to directly sabotage opponents' ability to operate in the physical or electronic realm. These mostly low-intensity activities include denial of service attacks, which make targeted resources unavailable through a flood of requests from a single source, and DDoS attacks, where requests originate from multiple compromised systems. Related efforts include inundating communications systems with floods of text messages or phone calls and using fire walls and proxies to block access to websites. At the extreme end of the scale is the use of malicious code to inflict physical damage or otherwise compromise infrastructure and military objects. Examples include interception of drones, communications and surveillance systems, control of Wi-Fi access points, and collection of protected information via phishing.\nThe most sophisticated known attack of this type is the Stuxnet worm, which—before its discovery in 2010—targeted industrial control systems critical to uranium enrichment in Iran. In Ukraine, notable disruptive activities have included attacks on the Central Election Committee's website during the 2014 presidential elections and attacks on the country's power grid in 2015 and 2016. Other examples include the use of malware to collect operational intelligence, like X-Agent, which retrieved locational data from mobile devices used by Ukrainian artillery troops, and the hacking of closed-circuit television (CCTV) cameras behind enemy lines.\nPropaganda and disruption are not mutually exclusive, and many cyber activities serve both purposes—shaping public opinion through disruption or disrupting an opponent's operations by shaping public opinion. For example, altering the visual appearance of websites can have the dual effect of embarrassing the target and limiting its ability to communicate. Leaks of private information also have dual implications for targets' public image and physical security.\nRecent examples of hybrid activities include the defacement of US Central Command's Twitter and Facebook pages by the Islamic State's (IS) Cyber Caliphate and operations by US Cyber Command against IS beginning in April 2016. In Ukraine, the pro-rebel group CyberBerkut (CB) has leaked private communications from senior United States, European Union, and Ukrainian officials and disclosed identities of pro-Kyiv field commanders—simultaneously creating a media scandal and forcing targets to commit more resources to personal security. Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations .\nIn the following, we limit the scope of our inquiry to cyber actions that are either purely disruptive (e.g. DDoS-style attacks) or are hybrids of the two approaches (e.g. web defacements). We do so for two reasons. First, most purely propagandistic operations, like comment-board trolling, do not aspire to influence the course of\nmilitary operations in the short term. Second, it is hard to separate the disruptive and propaganda effects of hybrid cyber activities because they depend on each other.\n## Cyber Coercion in Wartime\nOver the last two decades, cyber attacks have become an increasingly common tool of coercion, used by state and nonstate actors, independently and jointly with physical, kinetic operations. Like other instruments of coercion, cyber actions inflict costs on a target to compel a change in its behavior—either by punishing past misdeeds or by putting pressure on decision makers in real time.\nThe role of cyber compellence in wartime is not unlike that of airpower or terrorism . Cyber attacks cannot take or hold territory on their own, but they can support operations on the ground by disrupting opponents' command and control, collecting operational intelligence, and creating opportunities for conventional forces to exploit. If combatants use the Internet for coordination, recruitment, or training, low-level cyber disruption may prevent them from running these vital functions smoothly. Alternatively, cyber attacks can indirectly pressure an opponent by targeting civilian economy and infrastructure, similarly to strategic bombing. Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties . Unlike terrorism, the individual attacker is rarely at risk of direct physical harm.\nDespite the apparent promise of these “weapons of the future” , some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion . There is little doubt that large numbers of low-level attacks can cumulatively produce large-scale damage, bringing “death by a thousand cuts” (Lemay, Fernandeza, and Knight 2010). Yet successful coercion also requires punishment to be both anticipated and avoidable , and these criteria can be difficult to meet in cyberspace.\nCyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities . Since the destructiveness of malicious code depreciates quickly after first use, cyber attacks are often most damaging when they are least anticipated.\nTargets also have many reasons to doubt that cyber attacks are avoidable by accommodation. For the attacker, cyber actions present a trade-off between plausible deniability—which helps prevent retaliation—and the credibility of coercive promises and threats. Any uncertainty over the source of an attack will also create uncertainty over the nature of compliance—what sort of actions will prevent future attacks and by whom.\nBeyond attribution uncertainty, cyber attacks may not generate sufficient costs to elicit compliance from. Because administrators can quickly fix or contain many\nexploited vulnerabilities, even successful attacks cause only temporary disruption . Unless the attacker continues to develop new methods and identify new vulnerabilities, a protracted campaign may quickly lose its coercive impact. As a result, targets may see compliance as insufficient and unnecessary to stop the damage .\nForce synchronization challenges may also render the timing of cyber attacks suboptimal for compellence. Hackers—especially those not integrated with military forces—may not observe battlefield events on a tactically relevant time line. Even if they did, the lead time required to plan and implement a successful attack—studying the target system, collecting intelligence on its vulnerabilities, and writing code that exploits them—can make these efforts difficult to synchronize with conventional operations.\nThese challenges are not insurmountable. Lead time is a greater barrier for high-level attacks (e.g. targeting major infrastructure) than for more routine, DDoS-style attacks. Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower . The ability of contemporary hackers to overcome these difficulties, however, remains unknown.\n### Previous Research\nThe question of whether low-level cyber attacks compel has deep implications for the theory and practice of national security. Yet the public and academic debate on this topic has unfolded largely in the absence of rigorous empirical evidence in either direction. Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare , the overlap between cyber and kinetic capabilities , and the effect of information and communication technology on conflict .\nMost research in the first category has focused on the implications of cyber activities for peacetime deterrence or the offense--defense balance rather than wartime compellence. While the second group focuses more directly on cyber attacks during conflict, its empirical approach has been mostly qualitative, relying on evidence from descriptive case studies, macrohistorical surveys, and stylized facts. Some large-n analyses do exist , but their scope has remained on large-scale cyber attacks rather than the far more numerous low-intensity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action  rather than military compellence.\nOur study bridges the gap between these areas of inquiry. Our goal is to assess the coercive potential of low-level cyber actions during an armed conflict. We pursue this goal by studying the magnitude and direction of the relationship between cyber attacks and physical violence, using microlevel data from ongoing conflicts in Ukraine and Syria.\n### Empirical Expectations\nCyber attacks by actor A can affect physical violence by B in one of the three ways: negatively, positively, or not at all. If cyber compellence is successful, we should expect a short-term decrease in violence after a spike in cyber attacks. A positive response would suggest failure, where cyber attacks actually escalate violence by the opponent. If no relationship exists, cyber actions are either ineffective or irrelevant to fighting in the physical world.\nIn addition to compellence across domains, cyber attacks by actor A may impact cyber attacks by actor B. As before, only a negative relationship would imply coercive success, while a null or positive response would suggest that these actions are either ineffective or counterproductive.\n## Data Analysis\nTo evaluate whether and how cyber actions affect physical violence in war, we analyze new micro-level data from Ukraine and Syria. We begin with an in-depth study of the Ukrainian case, as one of few conflicts where both sides have used cyber attacks as a means of coercion. Due to the sophistication of hackers on both sides, the public nature of many attacks, and an abundance of data, the Ukrainian conflict allows us to observe the short-term coercive impact of cyber attacks. We then use analogous event data on Syria to evaluate the generalizability of our results. While a more systematic analysis of cross-national patterns lies beyond the scope of our article, micro-level evidence from these two conflicts might be suggestive of general patterns of modern warfare—particularly where combatants with asymmetric capabilities use cyberspace along with traditional tools of war.\nIn assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets , we draw data from multiple open sources—including press reports and anonymous attack traffic data. To reduce potential false positives, we include only those events that have been reported by more than one source.\n### Ukraine Cyber Attacks Data\nOur cyber event data on Ukraine include 1,841 unique, mostly low-level, cyber attacks from August 27, 2013, to February 29, 2016, drawn from two sets of sources.\nFirst are media reports of cyber attacks from rebel, Russian, Ukrainian, and Western news outlets, press releases and blogs along with social media platforms used by the involved nonstate actors. Second is the private cyber security firm Arbor Networks' Digital Attack Map (DAM; see http://www.digitalattackmap.com/about/). Unlike media sources—which include only cyber attacks publicly reported by news organizations or claimed by governments and hacker groups directly—DAM draws on anonymous attack traffic data and network outage reports to enumerate the top 2 percent of reported attacks that generate unusually high Internet traffic for each country. Including these “higher-visibility” attacks should make it easier to find a coercive effect.\nWe supplemented these data with fourteen primary source interviews with participants in the cyber campaign, as well as Russian, Ukrainian, and Western cyber security experts with direct knowledge of these operations, from the private and public sectors, academia, and journalism. We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix .\nWe grouped cyber attacks in our data set according to the partisanship of alleged perpetrators (pro-Ukrainian vs. prorebel) and the type of operation they conducted (propaganda vs. disruption). Table 1 list all actors conducting cyber activitiess in the Ukrainian conflict, their targets, and the reported frequency of their activities.\nUkrainian cyber actions include specific attacks by pro-Kyiv hackers like Anonymous Ukraine and Ukrainian Cyber Forces (UCFs). The latter is the most active group on the pro-Ukrainian side. In an interview, UCF leader Eugene Dokukin claimed to have established the nonstate group in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine . Pro-Kyiv hackers' most common targets are the communications and finances of rebel units as well as media firms and private companies in rebel-held areas.\nProrebel cyber actions include specific attacks by proseparatist or pro-Russian cyber actors, like CB, Cyber Riot Novorossiya, Green Dragon, and the Russian government. The first of these takes its name from Ukraine's disbanded Berkut riot police and claims to fight “neofascism” in Ukraine. Ukrainian and Russian cyber experts we interviewed offered contradictory assessments on CB's organizational structure. One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution . Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB . These groups' most popular targets include Ukrainian government officials, media, and private citizens.\nWe further disaggregated these events into the two categories previously defined—propaganda or disruption—as well as a third, hybrid, category of incidents\nTable I. Actors and Targets (Ukraine and Syria).\n|  Ukraine  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Pro-Kyiv | Actor/target | Frequency (%) | Prorebel | Actor/target | Frequency (%)  |\n|  Anonymous Ukraine | A | 6 (<1) | CyberBerkut | A | 134 (7)  |\n|  Ukrainian Cyber Forces | A | 1,392 (76) | Cyber Riot Novorossiya | A | 41 (2)  |\n|  Ukrainian governmental units and officials | A/T | 3 (<1)/326 (18) | Green Dragon | A | 1 (<1)  |\n|  Ukrainian army units | T | 1 (<1) | Quedagh | A | 1 (<1)  |\n|  Western governments and organizations | T | 15 (1) | Crimean government officials | T | 6 (<1)  |\n|  Western non-state actors | T | 7 (<1) | Russian army units | A/T | 1 (<1)/14 (1)  |\n|  Non-state supporters | T | 91 (5) | Non-state supporters | T | 444 (24)  |\n|   |  |  | Rebel groups | A/T | 2 (<1)/926 (50)  |\n|   |  |  | Russian state units and government officials | A/T | 2 (<1)/14 (1)  |\n|   |  |  | Russian state-sponsored groups | A | 237 (13)  |\n|  Total |  | 1,841 (100) |  |  | 1,841 (100)  |\n|  Syria  |   |   |   |   |   |\n|  Anti-Assad | Actor/target | Frequency (%) | Pro-Assad | Frequency (%) | Actor/target  |\n|  Anonymous/anonymous-sponsored units | A | 93 (14) | ISIL/ISIL-sponsored units | A | 54 (8)  |\n|  Anti-Assad non-state actors | A/T | 297 (44)/18 (3) | Russian government units | A | 3 (<1)  |\n|  Jabhat al-Nusra-sponsored units | A | 1 (<1) | Syrian government units and officials | A/T | 2 (<1)/272 (40)  |\n|  Kurdish non-state opposition | A | 11 (<2) | Syrian state-sponsored units | A/T | 102 (15)/2 (<1)  |\n|  Free Syrian Army | T | 1 (<1) | Pro-Assad non-state actors | T | 179 (26)  |\n|  Pro-ISIL social media and websites | T | 140 (21) |  |  |   |\n|  Total |  | 682 (100) |  |  | 682 (100)  |\nNote: ISIL = The Islamic State of Iraq and the Levant.\nthat potentially serve both purposes. The most common cyber actions in Ukraine have been DDoS-style attacks, followed by hacks of CCTV cameras and other communications. Website blockages have also proven popular, as have spearphishing e-mails targeting specific individuals. Table 2 provides a full breakdown.\nTo reduce false positives due to unconfirmed reports or dubious claims of responsibility, we only include attacks reported by more than one source. To account for uncertainty of attribution, we marked as “disputed” all cases where no one claimed responsibility and labeled as “nondisputed” those operations for which actors directly claimed responsibility in press releases, on social media, or in interviews. To focus on daily dynamics, we excluded activities whose intensity did not vary over time.\nFigure 1a depicts the temporal dynamics of pro-Ukrainian (Cyber U) and pro-Russian rebel (Cyber R) cyber operations. In early March 2014, about a week after the revolution in Kyiv, Figure 1 shows a spike in attacks by CB. The same month saw the establishment of the pro-Kyiv Ukrainian Cyber Forces, partly in response to CB's attacks. However, UCF operations do not become visible until May 2014, following an influx of volunteers to the group. May 2014 is also notable for a rise in activities by another pro-Russian cyber group, Cyber Riot Novorossiya—named after the czarist-era term (“New Russia”) for territories in southeastern Ukraine. After the first Minsk cease-fire agreement in September 2014, operations by pro-Ukrainian hackers converge to a steady rate of two to four per day, with occasional flare-ups, as in December 2014. Activities by pro-Russian hackers, by contrast, declined after the summer 2014.\n### Ukraine Violent Events Data\nOur data on kinetic operations include 26,289 violent events from Ukraine's Donbas region, recorded between February 28, 2014, and February 29, 2016. To offset reporting biases in any one source, while guarding against potential disruptions in media coverage due to cyber attacks, these data draw on seventeen Ukrainian, Russian, rebel, and international sources. As before, we include only events that appeared in more than one source.\nTo extract information on dates, locations, participants, and other event details, we relied on a combination of supervised machine learning (Support Vector Machine) and dictionary-based coding. The Online Appendix describes our measurement strategy and provides summary statistics.\nFigure 1b shows the temporal distribution of pro-Ukrainian (Kinetic U) and pro-Russian rebel (Kinetic R) physical violence. The plot shows several notable flare-ups of fighting—during a government offensive in late June 2014 and a rebel offensive in January 2015—as well as lulls following cease-fire agreements in September 2014, February 2015, and September 2015. Compared to the cyber operations in Figure 1, this plot reveals a clear correlation between kinetic operations\nTable 2. Types of Cyber Operations (Ukraine and Syria).\n|  Propaganda | Ukraine (%) | Syria (%) | Disruption | Ukraine (%) | Syria (%) | Both | Ukraine (%) | Syria (%)  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  PPI—publishing online private information of the members of the conflicting parties | 47 (2) | 59 (9) | AVG— audio-, video-, and geo-intelligence collection | 423 (23) | 1 (<1) | WDT—website defacement | 51 (3) | 389 (57)  |\n|  PRM/PUM—posting pro-rebel and pro-Ukrainian messages online | 54 (3)/5 (<1) | — | CPI—collecting private information via open sources | 13 (<1) | 10 (<2) |  |  |   |\n|  UWP—updating online pages | 6 (<1) | — | DDoS—distributed denial-of-service attack | 499 (27) | 78 (11) |  |  |   |\n|   |   |   |  ODS—other attacks with a purpose of disruption or espionage | 9 (1) | 10 (<2) |  |  |   |\n|   |   |   |  SPE—spear-phishing e-mail | 234 (13) | 17 (2.5) |  |  |   |\n|   |   |   |  STM—sending massive text messages or calling phones non-stop | 40 (2) | 1 (<1) |  |  |   |\n|   |   |   |  WBG—website blockage | 257 (14) | 376 (55) |  |  |   |\n|  Total | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100)  |\n|   |   |   |  |   |   |   |   |   |\nJournal of Conflict Resolution 63(2)\n(a) cyber\n(b) kinetic\nFigure 1. Cyber and kinetic operations in Ukraine . U (blue) indicates operations by Ukrainian government forces; R (red) indicates operations by pro-Russian rebel groups.\nby the two sides, with government and rebel attacks rising and falling in tandem. $^{15}$  Although this interdependence is not surprising, the data suggest that—with few exceptions—physical violence in Ukraine has been a reciprocal affair.\nFrom a brief glance at the timing of cyber and physical operations (Figure 1a and b), there are relatively few signs of a compelling effect—changes in the former do not appear to drive changes in the latter. However, a visual comparison can be misleading. Some of the variation may be due to fighting on the ground or in cyberspace, but other changes may reflect secular trends or shocks due to elections and other events not directly related to conflict. To account for these potential confounding factors and to gauge whether there is a stronger cyber-kinetic relationship than we would expect by chance, we conduct a series of more rigorous tests.\nEmpirical Strategy\nTo evaluate the relationship between cyber and kinetic operations in Ukraine, we estimate a series of vector autoregressive models\n$Y_{t} = \\sum\\limits_{j}^{p}B_{j}Y_{t - j} + GX_{t} + \\mu_{0} + \\mu_{1}t + \\mathbf{\\epsilon_{t}},$ (1)\nwhere $Y_{t} = \\left[y_{t}^{\\text{Kinetic(U)}}, y_{t}^{\\text{Kinetic(R)}}, y_{t}^{\\text{Cyber(U)}}, y_{t}^{\\text{Cyber(R)}}\\right]^{\\prime}$ is a matrix of endogenous variables, and $X_{t} = \\left[x_{1t},\\ldots,x_{kt}\\right]^{\\prime}$ is a matrix of k exogenous variables, which includes indicators for key dates and events during the war, like presidential and parliamentary electoral campaigns in Ukraine and breakaway territories; cease-fire agreements; and Ukrainian, Russian, and Soviet holidays. Deterministic components include a constant term (μ_{0}) and trend (μ_{1}t). p is the lag order, selected via Bayesian information criterion, and $\\mathbf{\\epsilon_{t}}$ is a vector of serially uncorrelated errors.\nWe control for Ukrainian, Russian, and Soviet holidays because anecdotal accounts suggest significant increases in cyber activity during such times. The UCF, for instance, had an operation called “Happy New Year,” which sought to print pro-Ukrainian messages from hacked printers in Crimea, Russia, and Donbas. National election campaigns represent another time when such activities may spike. Before and during the presidential elections, for instance, hackers bombarded Ukraine's Central Electoral Committee website with DDoS attacks. Finally, we may expect cease-fire agreements aimed at reducing physical violence to also have an effect in the cyber domain. For example, the cyber espionage operation “Armageddon”—directed against Ukrainian government websites—intensified before the Minsk I agreement went into force but then rapidly declined.\nBecause we are interested in the relationship between cyber attacks and physical violence during war, we limit our primary analysis to the active phase of military operations between May 11, 2014, and February 15, 2015—the period following independence referendums organized by the self-proclaimed Donetsk and Luhansk People's Republics and the second Minsk cease-fire agreement. In the Online Appendix, we present additional analyses of the full data set, which produced similar results.\n## Results\nData from Ukraine support the skeptical view of cyber coercion. The impulse--response curves in Figure 2 show a strong, escalatory dynamic between kinetic operations by the two sides (Kinetic U, Kinetic R), but no tangible links in either direction between kinetic and cyber operations, and no reciprocity between cyber actions (Cyber U, Cyber R).\nFollowing a standard deviation increase in kinetic rebel attacks, government violence sees a delayed rise, peaking around two days after the shock and gradually\n|  Response: |   |\n| --- | --- |\n|  Kinetic (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  |\n|  Kinetic (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  |\n|  Cyber (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  |\n|  Cyber (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  |\nFigure 2. Impulse response matrix, daily time series (Ukraine). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"U\" indicates reported kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\ndeclining back to zero (top row, second column). Rebel operations also rise after shocks to government operations (second row, first column), but the response here is immediate, without the delay we observe in government operations. This pattern may reflect command and control inefficiencies in the Ukrainian army, particularly early in the conflict, when indecision and leadership turnover lengthened decision cycles.\nThe relationship between cyber and kinetic operations is far weaker than that between rebel and government violence on the ground. Cyber attacks by pro-Ukrainian forces see no increase after shocks in kinetic government operations, and a positive, but uncertain increase after shocks in kinetic rebel operations (third row, first and second columns).\nThere is even less evidence that cyber attacks drive kinetic operations. The impulse--response function (IRF) curve for pro-Ukrainian government violence is, in fact, negative after shocks to rebel cyber operations (top row, two rightmost columns). Although this negative response might otherwise suggest that cyber attacks compel a decline in violence—consistent with coercive success—the estimate is also highly uncertain. Following shocks to pro-Ukrainian cyber activities, meanwhile, the main change in rebel kinetic operations is a short-term increase in volatility (second row, third column). In sum, the data suggest that cyber attacks may make violence less predictable but do not systematically change its intensity.\nPerhaps most surprisingly, there is little or no apparent strategic interaction between “cyber-warriors” on each side of the conflict. A shock in pro-Ukrainian cyber attacks yields no discernible change in pro-rebel cyber attacks (bottom row, third column) and vice versa (third row, fourth column). The two cyber campaigns, the data suggest, have unfolded independently of each other and independently of events on the ground.\nAs the diagonal elements in Figure 2 suggest, there is strong autocorrelation in each series. For each of the four categories, past shocks in operations yield a significant spike in subsequent operations. To evaluate whether the other categories of events can help us predict future values of each series, after we take this autocorrelation into account, Table 3 reports the results of Granger causality tests. The tests confirm that past levels of prorebel and pro-Kyiv kinetic operations help predict each other's future values. Kinetic operations, however, do not appear to “Granger cause”—or be “Granger caused” by—cyber attacks on either side.\nTable 4 reports the forecasting error variance decomposition, representing the proportion of variation in each series (rows) due to shocks in each endogenous variable (columns). For most variables, their own time-series account for almost all variation at the outset, but this dependency gradually decreases. As before, there is far more dependence within kinetic operations than between kinetic and cyber or within cyber actions. By the thirty-day point in the daily time series, shocks in rebel attacks account for 7 percent of variation in Ukrainian government operations, while shocks in government operations explain 12 percent of variation in rebel violence.\nJournal of Conflict Resolution 63(2)\nTable 3. Granger Causality Test, Daily Time Series (Ukraine).\n|  Effects | F statistic | p value  |\n| --- | --- | --- |\n|  Kinetic (R) → Kinetic (U) | 40.26 | .00  |\n|  Cyber (U) → Kinetic (U) | 0.50 | .48  |\n|  Cyber (R) → Kinetic (U) | 0.09 | .76  |\n|  Kinetic (U) → Kinetic (R) | 12.29 | .00  |\n|  Cyber (U) → Kinetic (R) | 1.44 | .23  |\n|  Cyber (R) → Kinetic (R) | 2.70 | .10  |\n|  Kinetic (U) → Cyber (U) | 1.40 | .24  |\n|  Kinetic (R) → Cyber (U) | 1.88 | .17  |\n|  Cyber (R) → Cyber (U) | 0.00 | .95  |\n|  Kinetic (U) → Cyber (R) | 1.74 | .19  |\n|  Kinetic (R) → Cyber (R) | 0.14 | .71  |\n|  Cyber (U) → Cyber (R) | 0.89 | .35  |\nNote: \"U\" indicates reported kinetic and cyber operations by Pro-Ukrainian government forces, and \"R\" indicates operations by Pro-Russian rebel forces.\nTable 4. Variance Decomposition, Daily Time Series (Ukraine).\n|  Operation type | Kinetic (U) | Kinetic (R) | Cyber (U) | Cyber (R)  |\n| --- | --- | --- | --- | --- |\n|  Kinetic (U) |  |  |  |   |\n|  1 Day | 1.000 | .000 | .000 | .000  |\n|  2 Days | 0.920 | .060 | .002 | .018  |\n|  7 Days | 0.906 | .071 | .002 | .020  |\n|  30 Days | 0.906 | .071 | .002 | .020  |\n|  Kinetic (R) |  |  |  |   |\n|  1 Day | 0.108 | .892 | .000 | .000  |\n|  2 Days | 0.121 | .873 | .000 | .006  |\n|  7 Days | 0.122 | .870 | .000 | .008  |\n|  30 Days | 0.122 | .870 | .000 | .008  |\n|  Cyber (U) |  |  |  |   |\n|  1 Day | 0.000 | .002 | .998 | .000  |\n|  2 Days | 0.000 | .002 | .997 | .000  |\n|  7 Days | 0.000 | .003 | .997 | .000  |\n|  30 Days | 0.000 | .003 | .997 | .000  |\n|  Cyber (R) |  |  |  |   |\n|  1 Day | 0.012 | .023 | .000 | .964  |\n|  2 Days | 0.014 | .023 | .001 | .962  |\n|  7 Days | 0.015 | .023 | .001 | .961  |\n|  30 Days | 0.015 | .023 | .001 | .961  |\nNote: \"U\" indicates kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\nBy contrast, shocks to cyber activities account for very little variation in kinetic operations. The highest value is for pro-Russian rebel cyber activities, which account for 2 percent of short-term variation in government violence. Cyber attacks by each side also have a relatively small impact on each other. Indeed, rebel kinetic operations explain more of the variation in cyber attacks by each actor than do cyber attacks by the other side.\nIn sum, our analysis suggests that low-level cyber attacks in Ukraine have had no effect on the timing of physical violence. Not only is there no evidence that cyber attacks have compelled opponents to de-escalate fighting, there is no discernible reciprocity between the cyber actors themselves. Each group of hackers seems to operate in its own bubble, disengaged from unfolding events in both cyberspace and the physical world.\n### Robustness Checks\nTo gauge the sensitivity of our results to various modeling and measurement choices, we conducted extensive robustness checks. We summarize their results briefly here (Table 5) and more fully in the Online Appendix.\nThe first set of tests considers vector autoregression models with alternative orderings of the four endogenous variables, which affects estimation of impulse responses. We find no substantive differences across the twenty-four permutations.\nIn a second set of robustness checks, we account for systematic differences in the kinds of conflict events that Ukrainian and Russian media report, which may bias statistical estimates—for example, by underreporting violence by a given actor. Using kinetic data from exclusively Russian or exclusively Ukrainian sources does not change the results.\nA third set of robustness tests examines different subsets of cyber attacks. Because purely disruptive activities may impose greater immediate costs than quasi-propagandistic hybrid attacks, pooling these events may dilute their coercive effect. Our results are consistent for all three subsets.\nThe last set of robustness checks examines different time periods of the conflict, since some cyber attacks predated military activity. In particular, we compare the period of intense fighting previously analyzed (May 11, 2014--February 15, 2015) to the entire date range for which we have data (February 28, 2014--February 29, 2016). Our results remain unchanged.\n## Evidence from Interviews\nIn interviews, Russian and Ukrainian cyber security experts highlighted five potential explanations for the apparent failure of cyber coercion in Ukraine: (1) lack of resources, (2) lack of coordination, (3) lack of targets, (4) lack of audience, and (5) lack of effort.\nTable 5. Robustness Checks (Ukraine and Syria).\n|  Ukraine (main results; May 11, 2014–February 15, 2015)  |   |   |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n|  I | Disruption and both | Kin(R) ↔ Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) ↔ Kin(R) | Kin(U) ↔ Kin(R) | Kin(U) → Kin(G)  |\n|  ID | Cyber | GCT(w) | VD(d) (30 day) | VD(w) (12 week) |  |  |   |\n|  I | Disruption and both |  | Kin(R) → 7%Kin(U) | Kin(R) → 10%Cyb(R) |  |  |   |\n|   |   |   | Kin(R) → 2%Cyb(R) | Kin(U) → 21%Kin(R) |  |  |   |\n|   |   |   | Kin(U) → 12%Kin(R) | Kin(U) → 17%Cyb(R) |  |  |   |\n|   |   |   | Kin(U) → 2%Cyb(R) | Cyb(U) → 4%Cyb(R) |  |  |   |\n|  ID | Cyber | IRF(d) | IRF(w) | GCT(d) | GCT(w) | VD(d) (30 day) | VD(w) (12 week)  |\n|  Ukraine (March 22, 2014–February 29, 16)  |   |   |   |   |   |   |   |\n|  2 | All | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U/R) ↔ Kin(U) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Cyb(U) ↔ Kin(R) |  |  | Kin(U) → 3%Cyb(R)  |\n|  3 | Propaganda | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin(U)/Cyb(R) | Kin(R) → 3%Kin(U) | Kin(R) → 9%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) → Kin/Cyb(R) | Kin(U) → Cyb(R) | Kin(U) → 18%Kin(R) | Kin(R) → 3%Cyb(R)  |\n|   |   |   | Cyb(U) → Kin(U) | Kin(U) → Cyb(R) |  |  | Kin(U) → 46%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(R)  |\n|  4 | Disruption | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(U/R) |  | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|  5 | Disruption and both | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(R) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Kin(U) → Cyb(U) |  |  |   |\n(continued)\nTable 5. (continued)\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) Ukraine (May 11, 2014-February 11, 2015) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  6 | All | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) |  | Kin(R) → 7%Kin(U) | Kin(R) → 2%Cyb(U)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(U) → 13%Kin(R) | Kin(R) → 18%Cyb(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 30%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(U/R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 4%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(U)  |\n|  7 | Propaganda | Kin(R) → Kin(U) | Cyb(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Cyb(R) | Kin(R) → 7%Kin(U) | Kin(U) → 27%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) |  |  | Kin(U) → 13%Kin(R) | Kin(U) → 4%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 3%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 9%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 20%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 5%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(R) → 2%Cyb(U)  |\n|  8 | Disruption | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → Cyb(U) | Kin(R) → 7%Kin(U) | Kin(U) → 29%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(R) → 2%Cyb(R) | Kin(U) → 34%Cyb(U)  |\n|   |   |   |  |  |  | Kin(U) → 12%Kin(R) | Kin(U) → 22%Cyb(R)  |\n|   |   |   |  |  |  | Cyb(R) → 2%Kin(U) | Kin(R) → 3%Kin(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 10%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 13%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 6%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 7%Cyb(U)  |\nSyria (March 17, 2011-July 10, 2016)\n|  9 | Disruption and both | Kin(G) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → 2%Kin(R)  |\n| --- | --- | --- | --- | --- |\nNote: IRF = impulse response functions; GCT = Granger causality tests; VD = variance decomposition; d = daily; w = weekly; o = alternative orderings; RU = Russian; U = Ukrainian.\nThe first explanation for coercive failure emphasizes limited resources and capabilities, particularly for the Ukrainian government. Ten years ago, the SBU briefly had a cyber department but shut it down after a year . This unit has recently reopened but continues to lack funding and personnel . It is possible that, with adequate resources, capabilities, and human capital, the Ukrainian cyber campaign might have been more effective. Resource constraints, however, do not explain coercive failure on the pro-Russian side, where investment in cyber capabilities is more robust.\nA second explanation is lack of government coordination with hackers, especially in Kyiv . UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success . The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place . Yet again, this explanation is less plausible on the pro-Russian side, where the Kremlin has cultivated extensive ties with non-state hacktivists.\nA third explanation is that—even with requisite capabilities and coordination—there are few opportune targets for disruption in Ukraine. Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult . Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack” . The 2015 and 2016 hacks of Ukraine's power grid also seem to challenge this explanation.\nThe peculiarities of Ukraine's online population represent a fourth explanation for the indecisiveness of cyber attacks. Since only 44.1 percent of Ukrainians have Internet access—compared to 88.5 percent in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses . Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones . Our data suggest that, even if this were the case, propagandistic attacks still had no effect on violence.\nThe final explanation is that cyber compellence failed because it was never seriously attempted. At first, our interviews with individual hackers revealed no shortage of coercive intent. UCF leader Eugene Dokukin claimed to conduct low-level attacks daily and vowed to continue until pro-Russian rebels lay down their arms. Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns .\nWhile UCF and other nonstate groups have explicitly sought to affect battlefield outcomes, some interviewees questioned whether this intent extended to the Russian\ngovernment. Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place . This access, along with vigorous cyber espionage—some of it ongoing since 2010—may create incentives against more aggressive actions, which could compromise valuable sources of intelligence.\nConsistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda . When in 2011 Vyacheslav Volodin replaced Vladislav Surkov as head of the Presidential Administration, he toughened existing laws against Russia's opposition and promoted the use of mass media and online platforms—tools already mostly under state control—to conduct information campaigns. If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising .\n## Evidence beyond Ukraine: Syria's Digital Front\nAccording to evidence from microlevel data and interviews, cyber attacks did not affect battlefield events in Ukraine. During one of the first armed conflicts where both sides used low-level cyber actions extensively, events in the digital realm have unfolded independently of—and have had no discernible effect on—events on the ground. Conditions in Ukraine were in many ways optimal to observe the coercive impact of cyber actions, for reasons we already discussed (i.e. visibility of major attacks, regular claims of responsibility, less uncertainty over attribution). Yet we found no evidence that low-level cyber attacks affected physical violence. Nor did hackers on each side even affect each other's activities.\nWhile important, Ukraine is not the only contemporary conflict with a significant cyber dimension. In Syria, state and nonstate actors have employed low-level cyber actions extensively for propaganda and disruption, complementing traditional tools of warfare in the deadliest conflict ongoing today. Syria's war has also lasted three years longer than Ukraine's. Over this time, its digital front has expanded in scope and sophistication, offering a glimpse of cyber coercion in a more protracted setting.\nAn in-depth study of Syria's digital front lies beyond the scope of this article. A brief analysis of the data, however, suggests that our findings from Ukraine may be part of a broader pattern: cyber capabilities have not yet evolved to the point of having an impact on physical violence.\nTo evaluate the effectiveness of cyber compellence in this second case, we replicated the model in (equation 1), using an analogous daily time series of cyber attacks and violent events in Syria. Our data comprise 9,282 kinetic and 682 low-level cyber attacks ranging from March 2011 until July 2016. Table 2 provides a breakdown of cyber techniques used in the Syrian conflict, their brief description, and frequency. Our data on kinetic operations rely on human-assisted machine\nJournal of Conflict Resolution 63(2)\nFigure 3. Cyber and kinetic operations in Syria . G (blue) indicates operations by pro-Assad government forces; R (red) indicates operations by anti-Assad rebel groups.\ncoding of event reports from the International Institute for Strategic Studies Armed Conflict Database (see Online Appendix for details).\nGiven the complex nature of the Syrian conflict and the multiple parties involved, we restrict our analysis only to operations by progovernment forces (i.e., Syrian Army, Hezbollah and pro-Assad militias) and the main rebel opposition (i.e., Free Syrian Army, Jaish al-Fatah, including Al Nusra Front). Table 1 provides a list of cyber actors in the Syrian conflict, their targets, and frequency of their activities.\nThe dynamics of cyber and kinetic operations in Syria exhibit similar patterns to what we saw in Ukraine. Raw data (Figure 3a and b) suggest relatively little overlap in timing, especially at the beginning of the conflict. The IRF curves in Figure 4 show a rise in rebel operations following shocks to government operations (second row, first column), and mostly negligible (though negative) links between cyber and kinetic operations, and across cyber attacks by each actor. Links between kinetic\n|  Response: |   |\n| --- | --- |\n|  Kinetic (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380 385 390 395  |\n|  Kinetic (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295  |\n|  Cyber (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 260 270 275  |\n|  Cyber (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230  |\n|  Impulse: | Kinetic (G) Kinetic (R) Cyber (G) Cyber (R)  |\nFigure 4. Impulse response matrix, daily time series (Syria). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"G\" indicates reported kinetic and cyber operations by pro-Assad government forces, and \"R\" indicates operations by anti-Assad rebel forces.\noperations—and their disconnect from cyber attacks—are also evident in variance decomposition results, and Granger tests, provided in the Online Appendix.\nThere are several reasons for caution in interpreting these results. The Syrian conflict involves a larger constellation of actors than Ukraine, and our dyadic analysis may overlook significant interactions elsewhere, particularly between actors with more developed cyber capabilities (e.g. Russia, United States). We also lack interview evidence that might help contextualize the null effect. However tentative, these results do align with what we saw in Ukraine: low-level cyber attacks have had little or no impact on violence.\n## Conclusion\nThe evidence we presented in this article—based on analysis of new data and expert interviews—suggests that cyber attacks are ineffective as a tool of coercion in war. Although kinetic operations explain the timing of other kinetic operations, low-level cyber attacks have no discernible effect on violence in the physical world. In Ukraine and Syria, the “cyberwar” has unfolded in isolation from the rest of the conflict.\nThis finding has several implications for theory and policy. First, by providing the first statistical analysis of modern low-level cyber campaigns, our study complements the qualitative focus of previous empirical work. Second, our research sheds light on a theoretical question about the strength and direction of the cyber--kinetic relationship and—in so doing—begins to fill an empirical gap in political science literature on this topic. Third, to the extent that policymakers might overestimate the importance of cyber actions due to a lack of empirical evidence to the contrary, our findings can potentially help correct this misperception. Finally, and more worryingly, our results suggest that—due to their disconnect from physical violence—low-level cyber attacks are very difficult to predict.\nFurther research is needed to understand the dynamics of low-level cyber attacks. One such area of research is cyber coercion in the context of symmetric, conventional war. While our study helps illuminate dynamics of cyber compellence between parties with asymmetric capabilities, we may well observe different patterns when major powers use cyberspace against peer competitors. Thankfully, no armed conflict has yet provided researchers with the data needed to evaluate this possibility.\nSecond, our scope in this article has been exclusively on short-term military consequences rather than long-term political effects. The latter are no less theoretically significant, but—unlike simple counts of violent events—potentially more difficult to measure and analyze. A study of long-term political effects would also need to more systematically incorporate purely propagandistic cyber activities and their impact on public opinion, which we omitted here due to our focus on short-term military compellence.\nAlthough the secretive nature of many ongoing physical and digital operations is a challenge for this research, questions over the coercive potential of cyber attacks\nwill become only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” —have yielded few tangible successes . Our data from Ukraine indicate that the US experience may be part of a broader pattern.\nAt best, coordination between low-level cyber and kinetic operations today is on roughly the same level as that between airpower and ground operations in World War I. Back then, armies were increasingly using aircraft for reconnaissance and surveillance on the front but were not yet able to fully exploit their potential for ground combat support and strategic bombing. That revolution appeared on the battlefield twenty-five years later, with devastating effect. As cyber capabilities develop and synchronization challenges become less severe, there will be a growing need for assessments of how far we have come. We hope that analyses of the sort we provided in these pages can serve as an early benchmark.\n## Authors' Note\nA previous version of this article was presented at the 2015 Peace Science Society International annual meeting, Oxford, MS, and at the Association for the Study of Nationalities Convention at New York, NY.\nWe are grateful to Maura Drabik, Paulina Knoblock, Neil Schwartz, and Alyssa Wallace for excellent research assistance. Robert Axelrod, Myriam Dunn-Cavelty, Eric Gartzke, Miguel Gomez, Todd Lehmann, Jon Lindsay, Tim Maurer, Brandon Valeriano, Christopher Whyte, and workshop participants of the Conflict & Peace, Research & Development workshop at the University of Michigan, of the Bridging the Gap Workshop on Cyber Conflict at Columbia University, of the Cross-Domain Deterrence lab at the University of California, San Diego, and of the Center for Security Studies at ETH Zurich provided helpful comments on the earlier drafts of this article.\n## Declaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n## Funding\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.\n## Supplemental Material\nSupplemental material for this article is available online.",
    "footnotes": {
      "items": {},
      "intext": [
        {
          "index": "15",
          "intext_citation": "$^{15}$",
          "preceding_text": "",
          "footnote": null
        }
      ],
      "stats": {
        "intext_total": 1,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 14,
        "missing_intext_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
        ],
        "highest_intext_index": 15,
        "missing_footnotes_for_seen_total": 1,
        "missing_footnotes_for_seen_intext": [
          15
        ],
        "uncited_footnote_total": 0,
        "uncited_footnote_indices": [],
        "style": "footnotes"
      }
    },
    "tex": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 6,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "missing_intext_indices": [],
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "missing_footnotes_for_seen_intext": [],
        "uncited_footnote_total": 3,
        "uncited_footnote_indices": [
          1,
          3,
          18
        ],
        "style": "tex_superscript"
      },
      "results": [],
      "flat_text": "Check for updates\nArticle\n# Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\nJournal of Conflict Resolution\n2019, Vol. 63(2) 317-347\n© The Author(s) 2017\nArticle reuse guidelines:\nsagepub.com/journals-permissions\nDOI: 10.1177/0022002717737138\njournals.sagepub.com/home/jcr\nSAGE\nNadiya Kostyuk¹, and Yuri M. Zhukov¹\n## Abstract\nRecent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.\n## Keywords\ncompellence, coercion, physical violence, conflict, cyber attacks\nOn December 23, 2015, hackers attacked Ukraine’s power grid, disabling control systems used to coordinate remote electrical substations, and leaving people in the capital and western part of the country without power for several hours. The Security\n¹Department of Political Science, University of Michigan, Ann Arbor, MI, USA\n## Corresponding Author:\nNadiya Kostyuk, Department of Political Science, University of Michigan, 505 S State Street, Ann Arbor, MI 48109, USA.\nEmail: nadiya@umich.edu\nService of Ukraine (SBU) blamed the Russian government for the cyber attack, an accusation that later found support in malware analysis by a private computer security firm. The Ukrainian hack was the first publicly acknowledged case of a cyber attack successfully causing a power outage. It is also just one of thousands of cyber activities, mostly diffuse and low level, that have occurred alongside physical fighting in Ukraine. Attacks launched through the digital realm are playing an increasingly visible role in civil and interstate conflict—in Ukraine, Syria, Israel, Estonia, Georgia, and beyond. Yet it remains unknown whether such activities have a real coercive impact on the battlefield.\nRecent years have seen growing concern over the coercive potential of cyber capabilities in war, but little evidence that these new tools are yet making a difference. Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence (Libicki 2009; Sharma 2010; Andres 2012). Yet the logic of coercion entails distinct challenges in peace and war, with potentially different implications for the cyber domain. Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist (Valeriano and Maness 2014) privilege massive cyber catastrophes over less sophisticated low-intensity attacks, like distributed denial of service (DDoS). The latter category, however, is far more common.\nThis article asks whether cyber attacks can compel short-term changes in battlefield behavior, using new event data on cyber and kinetic operations from armed conflicts in Ukraine and Syria. We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides (Geers 2015), and—uniquely—overt claims of responsibility, public damage assessments, and other releases of information that reduce uncertainty over timing and attribution. Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques” (Zetter 2017). If cyber attacks can yet make a difference on the battlefield, Ukraine is one a few cases where we are most likely to observe such an effect. Our data include 1,841 unique cyber attacks and 26,289 kinetic operations by government and prorebel forces between 2014 and 2016. We supplement this quantitative analysis with fourteen primary source interviews with participants in the cyber campaign as well as Ukrainian, Russian, and Western cyber security experts with direct knowledge of these operations.\nTo evaluate the generalizability of the Ukrainian experience to other conflicts, we replicate our results with data from Syria's civil war. Like Ukraine, Syria has seen the extensive use of low-level cyber attacks by factions fighting for and against the incumbent regime. Because this war has gone on significantly longer than the conflict in Ukraine—giving hackers more time to organize and develop their capabilities—Syria offers a glimpse at cyber activities in a more protracted, higher intensity context. If we uncover similar patterns in two conflicts of such different scale and complexity, we can have greater confidence that our results are not artifacts of a single idiosyncratic case. Our data include 682 cyber attacks and 9,282 acts of violence by pro- and anti-Assad forces between 2011 and 2016.\nEvidence from both conflicts suggests that cyber attacks have not created forms of harm and coercion that visibly affect their targets' actions. Short of mounting synchronized, coordinated cyber campaigns, each group of hackers has seemed to operate in its own “bubble,” disengaged from unfolding events in both cyberspace and the physical world. The lack of discernible reciprocity between cyber and kinetic operations—and between the cyber actors themselves—questions whether cyber attacks can (yet) be successfully deployed in support of military operations.\nThis disconnect may be temporary, as joint planning and execution concepts continue to evolve. Many countries, for instance, still struggle in coordinating air-power for ground combat support, a century after World War I. Our study highlights some of the difficulties that countries will need to overcome in integrating and synchronizing these new capabilities.\nOur contribution is fourfold. We offer the first disaggregated analysis of cyber activities in war and take stock of the empirical relationship between the cyber and kinetic dimensions of modern battle. To do so, we collect the first microlevel data on wartime cyber attacks, using both open media sources and anonymous attack traffic data. Theoretically, our analysis addresses an important question on the coercive impact of low-level cyber attacks, advancing a literature that has been heavy on deductive argumentation, but light on evidence. Finally, from a policy standpoint, our findings should temper the popular tendency to overhype the transformative potential of cyber attacks. At present, interaction between cyber and kinetic operations is similar to that between airpower and ground operations in World War I—when armies began to use aircraft for reconnaissance but had not realized their full potential to shape battlefield outcomes.\n## Varieties of Cyber Activity\nThe term “cyber activities” captures a diverse assortment of tactics and procedures, directed against different types of targets, in pursuit of disparate objectives. Not all of these activities seek to achieve battlefield effects in the same way. Before proceeding further, we differentiate between two broad goals these actions tend to pursue: propaganda and disruption.\nCyber activities in the propaganda category seek to influence public opinion and indirectly undermine an opponent's financing or recruitment. Operations in this group include leaks of compromising private information, online publication of partisan content (e.g. “trolling” on comments pages), and the establishment of dedicated websites and forums to promote an armed group's message. Unless it openly incites or discourages violence, propaganda affects kinetic operations only indirectly by undermining an opponent's support base or obfuscating perceptions of events.\nIn the Ukrainian conflict, the importance of both groups attach to online propaganda is evident from the time and resources pro-Kyiv fighters spend updating Wikipedia, and pro-Russia groups devote to creating and running dedicated\nYouTube channels and social media accounts. Russian military doctrine places a heavy emphasis on the strategic use of information in warfare, as does US cyberspace joint planning doctrine.\nThe second category of cyber attacks—disruption—seeks to directly sabotage opponents' ability to operate in the physical or electronic realm. These mostly low-intensity activities include denial of service attacks, which make targeted resources unavailable through a flood of requests from a single source, and DDoS attacks, where requests originate from multiple compromised systems. Related efforts include inundating communications systems with floods of text messages or phone calls and using fire walls and proxies to block access to websites. At the extreme end of the scale is the use of malicious code to inflict physical damage or otherwise compromise infrastructure and military objects. Examples include interception of drones, communications and surveillance systems, control of Wi-Fi access points, and collection of protected information via phishing.\nThe most sophisticated known attack of this type is the Stuxnet worm, which—before its discovery in 2010—targeted industrial control systems critical to uranium enrichment in Iran. In Ukraine, notable disruptive activities have included attacks on the Central Election Committee's website during the 2014 presidential elections and attacks on the country's power grid in 2015 and 2016. Other examples include the use of malware to collect operational intelligence, like X-Agent, which retrieved locational data from mobile devices used by Ukrainian artillery troops, and the hacking of closed-circuit television (CCTV) cameras behind enemy lines.\nPropaganda and disruption are not mutually exclusive, and many cyber activities serve both purposes—shaping public opinion through disruption or disrupting an opponent's operations by shaping public opinion. For example, altering the visual appearance of websites can have the dual effect of embarrassing the target and limiting its ability to communicate. Leaks of private information also have dual implications for targets' public image and physical security.\nRecent examples of hybrid activities include the defacement of US Central Command's Twitter and Facebook pages by the Islamic State's (IS) Cyber Caliphate and operations by US Cyber Command against IS beginning in April 2016. In Ukraine, the pro-rebel group CyberBerkut (CB) has leaked private communications from senior United States, European Union, and Ukrainian officials and disclosed identities of pro-Kyiv field commanders—simultaneously creating a media scandal and forcing targets to commit more resources to personal security. Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations (Il'chenko 2016).\nIn the following, we limit the scope of our inquiry to cyber actions that are either purely disruptive (e.g. DDoS-style attacks) or are hybrids of the two approaches (e.g. web defacements). We do so for two reasons. First, most purely propagandistic operations, like comment-board trolling, do not aspire to influence the course of\nmilitary operations in the short term. Second, it is hard to separate the disruptive and propaganda effects of hybrid cyber activities because they depend on each other.\n## Cyber Coercion in Wartime\nOver the last two decades, cyber attacks have become an increasingly common tool of coercion, used by state and nonstate actors, independently and jointly with physical, kinetic operations. Like other instruments of coercion, cyber actions inflict costs on a target to compel a change in its behavior—either by punishing past misdeeds or by putting pressure on decision makers in real time.\nThe role of cyber compellence in wartime is not unlike that of airpower or terrorism (Pape 2003, 2014). Cyber attacks cannot take or hold territory on their own, but they can support operations on the ground by disrupting opponents' command and control, collecting operational intelligence, and creating opportunities for conventional forces to exploit. If combatants use the Internet for coordination, recruitment, or training, low-level cyber disruption may prevent them from running these vital functions smoothly. Alternatively, cyber attacks can indirectly pressure an opponent by targeting civilian economy and infrastructure, similarly to strategic bombing. Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties (Ottis 2010). Unlike terrorism, the individual attacker is rarely at risk of direct physical harm.\nDespite the apparent promise of these “weapons of the future” (Schmitt 1999; Rios 2009; Clarke and Knake 2010; McGraw 2013; Eun and Aßmann 2014), some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion (Liff 2012; Rid 2012; Gartzke 2013; Junio 2013). There is little doubt that large numbers of low-level attacks can cumulatively produce large-scale damage, bringing “death by a thousand cuts” (Lemay, Fernandeza, and Knight 2010). Yet successful coercion also requires punishment to be both anticipated and avoidable (Schelling 1966), and these criteria can be difficult to meet in cyberspace.\nCyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities (Axelrod and Iliev 2014). Since the destructiveness of malicious code depreciates quickly after first use, cyber attacks are often most damaging when they are least anticipated.\nTargets also have many reasons to doubt that cyber attacks are avoidable by accommodation. For the attacker, cyber actions present a trade-off between plausible deniability—which helps prevent retaliation—and the credibility of coercive promises and threats. Any uncertainty over the source of an attack will also create uncertainty over the nature of compliance—what sort of actions will prevent future attacks and by whom.\nBeyond attribution uncertainty, cyber attacks may not generate sufficient costs to elicit compliance from. Because administrators can quickly fix or contain many\nexploited vulnerabilities, even successful attacks cause only temporary disruption (Axelrod and Iliev 2014). Unless the attacker continues to develop new methods and identify new vulnerabilities, a protracted campaign may quickly lose its coercive impact. As a result, targets may see compliance as insufficient and unnecessary to stop the damage (Hare 2012; Lynn 2010; Nye 2010).\nForce synchronization challenges may also render the timing of cyber attacks suboptimal for compellence. Hackers—especially those not integrated with military forces—may not observe battlefield events on a tactically relevant time line. Even if they did, the lead time required to plan and implement a successful attack—studying the target system, collecting intelligence on its vulnerabilities, and writing code that exploits them—can make these efforts difficult to synchronize with conventional operations.\nThese challenges are not insurmountable. Lead time is a greater barrier for high-level attacks (e.g. targeting major infrastructure) than for more routine, DDoS-style attacks. Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower (Atran 2003; Pape 2003, 2014). The ability of contemporary hackers to overcome these difficulties, however, remains unknown.\n### Previous Research\nThe question of whether low-level cyber attacks compel has deep implications for the theory and practice of national security. Yet the public and academic debate on this topic has unfolded largely in the absence of rigorous empirical evidence in either direction. Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare (Cha 2000; Griniaiev 2004; Libicki 2007, 2011; Czosseck and Geers 2009; Clarke and Knake 2010; Axelrod and Iliev 2014), the overlap between cyber and kinetic capabilities (Healey 2013; Kello 2013; Libicki 2015; Andress and Winterfeld 2013; Axelrod 2014), and the effect of information and communication technology on conflict (Martin-Shields 2013; Pierskalla and Hollenbach 2013; Crabtree, Darmofal, and Kern 2014; Gohdes 2014; Bailard 2015).\nMost research in the first category has focused on the implications of cyber activities for peacetime deterrence or the offense--defense balance rather than wartime compellence. While the second group focuses more directly on cyber attacks during conflict, its empirical approach has been mostly qualitative, relying on evidence from descriptive case studies, macrohistorical surveys, and stylized facts. Some large-n analyses do exist (Valeriano and Maness 2014), but their scope has remained on large-scale cyber attacks rather than the far more numerous low-intensity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action (Weidmann 2015) rather than military compellence.\nOur study bridges the gap between these areas of inquiry. Our goal is to assess the coercive potential of low-level cyber actions during an armed conflict. We pursue this goal by studying the magnitude and direction of the relationship between cyber attacks and physical violence, using microlevel data from ongoing conflicts in Ukraine and Syria.\n### Empirical Expectations\nCyber attacks by actor A can affect physical violence by B in one of the three ways: negatively, positively, or not at all. If cyber compellence is successful, we should expect a short-term decrease in violence after a spike in cyber attacks. A positive response would suggest failure, where cyber attacks actually escalate violence by the opponent. If no relationship exists, cyber actions are either ineffective or irrelevant to fighting in the physical world.\nIn addition to compellence across domains, cyber attacks by actor A may impact cyber attacks by actor B. As before, only a negative relationship would imply coercive success, while a null or positive response would suggest that these actions are either ineffective or counterproductive.\n## Data Analysis\nTo evaluate whether and how cyber actions affect physical violence in war, we analyze new micro-level data from Ukraine and Syria. We begin with an in-depth study of the Ukrainian case, as one of few conflicts where both sides have used cyber attacks as a means of coercion. Due to the sophistication of hackers on both sides, the public nature of many attacks, and an abundance of data, the Ukrainian conflict allows us to observe the short-term coercive impact of cyber attacks. We then use analogous event data on Syria to evaluate the generalizability of our results. While a more systematic analysis of cross-national patterns lies beyond the scope of our article, micro-level evidence from these two conflicts might be suggestive of general patterns of modern warfare—particularly where combatants with asymmetric capabilities use cyberspace along with traditional tools of war.\nIn assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets (Baum and Zhukov 2015; Davenport and Stam 2006; Woolley 2000), we draw data from multiple open sources—including press reports and anonymous attack traffic data. To reduce potential false positives, we include only those events that have been reported by more than one source.\n### Ukraine Cyber Attacks Data\nOur cyber event data on Ukraine include 1,841 unique, mostly low-level, cyber attacks from August 27, 2013, to February 29, 2016, drawn from two sets of sources.\nFirst are media reports of cyber attacks from rebel, Russian, Ukrainian, and Western news outlets, press releases and blogs along with social media platforms used by the involved nonstate actors. Second is the private cyber security firm Arbor Networks' Digital Attack Map (DAM; see http://www.digitalattackmap.com/about/). Unlike media sources—which include only cyber attacks publicly reported by news organizations or claimed by governments and hacker groups directly—DAM draws on anonymous attack traffic data and network outage reports to enumerate the top 2 percent of reported attacks that generate unusually high Internet traffic for each country. Including these “higher-visibility” attacks should make it easier to find a coercive effect.\nWe supplemented these data with fourteen primary source interviews with participants in the cyber campaign, as well as Russian, Ukrainian, and Western cyber security experts with direct knowledge of these operations, from the private and public sectors, academia, and journalism. We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix (Kostyuk and Zhukov 2017).\nWe grouped cyber attacks in our data set according to the partisanship of alleged perpetrators (pro-Ukrainian vs. prorebel) and the type of operation they conducted (propaganda vs. disruption). Table 1 list all actors conducting cyber activitiess in the Ukrainian conflict, their targets, and the reported frequency of their activities.\nUkrainian cyber actions include specific attacks by pro-Kyiv hackers like Anonymous Ukraine and Ukrainian Cyber Forces (UCFs). The latter is the most active group on the pro-Ukrainian side. In an interview, UCF leader Eugene Dokukin claimed to have established the nonstate group in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine (Kostyuk and Zhukov 2017, # 1). Pro-Kyiv hackers' most common targets are the communications and finances of rebel units as well as media firms and private companies in rebel-held areas.\nProrebel cyber actions include specific attacks by proseparatist or pro-Russian cyber actors, like CB, Cyber Riot Novorossiya, Green Dragon, and the Russian government. The first of these takes its name from Ukraine's disbanded Berkut riot police and claims to fight “neofascism” in Ukraine. Ukrainian and Russian cyber experts we interviewed offered contradictory assessments on CB's organizational structure. One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution (Kostyuk and Zhukov 2017, # 12). Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB (Kostyuk and Zhukov 2017, #7 & #8). These groups' most popular targets include Ukrainian government officials, media, and private citizens.\nWe further disaggregated these events into the two categories previously defined—propaganda or disruption—as well as a third, hybrid, category of incidents\nTable I. Actors and Targets (Ukraine and Syria).\n|  Ukraine  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Pro-Kyiv | Actor/target | Frequency (%) | Prorebel | Actor/target | Frequency (%)  |\n|  Anonymous Ukraine | A | 6 (<1) | CyberBerkut | A | 134 (7)  |\n|  Ukrainian Cyber Forces | A | 1,392 (76) | Cyber Riot Novorossiya | A | 41 (2)  |\n|  Ukrainian governmental units and officials | A/T | 3 (<1)/326 (18) | Green Dragon | A | 1 (<1)  |\n|  Ukrainian army units | T | 1 (<1) | Quedagh | A | 1 (<1)  |\n|  Western governments and organizations | T | 15 (1) | Crimean government officials | T | 6 (<1)  |\n|  Western non-state actors | T | 7 (<1) | Russian army units | A/T | 1 (<1)/14 (1)  |\n|  Non-state supporters | T | 91 (5) | Non-state supporters | T | 444 (24)  |\n|   |  |  | Rebel groups | A/T | 2 (<1)/926 (50)  |\n|   |  |  | Russian state units and government officials | A/T | 2 (<1)/14 (1)  |\n|   |  |  | Russian state-sponsored groups | A | 237 (13)  |\n|  Total |  | 1,841 (100) |  |  | 1,841 (100)  |\n|  Syria  |   |   |   |   |   |\n|  Anti-Assad | Actor/target | Frequency (%) | Pro-Assad | Frequency (%) | Actor/target  |\n|  Anonymous/anonymous-sponsored units | A | 93 (14) | ISIL/ISIL-sponsored units | A | 54 (8)  |\n|  Anti-Assad non-state actors | A/T | 297 (44)/18 (3) | Russian government units | A | 3 (<1)  |\n|  Jabhat al-Nusra-sponsored units | A | 1 (<1) | Syrian government units and officials | A/T | 2 (<1)/272 (40)  |\n|  Kurdish non-state opposition | A | 11 (<2) | Syrian state-sponsored units | A/T | 102 (15)/2 (<1)  |\n|  Free Syrian Army | T | 1 (<1) | Pro-Assad non-state actors | T | 179 (26)  |\n|  Pro-ISIL social media and websites | T | 140 (21) |  |  |   |\n|  Total |  | 682 (100) |  |  | 682 (100)  |\nNote: ISIL = The Islamic State of Iraq and the Levant.\nthat potentially serve both purposes. The most common cyber actions in Ukraine have been DDoS-style attacks, followed by hacks of CCTV cameras and other communications. Website blockages have also proven popular, as have spearphishing e-mails targeting specific individuals. Table 2 provides a full breakdown.\nTo reduce false positives due to unconfirmed reports or dubious claims of responsibility, we only include attacks reported by more than one source. To account for uncertainty of attribution, we marked as “disputed” all cases where no one claimed responsibility and labeled as “nondisputed” those operations for which actors directly claimed responsibility in press releases, on social media, or in interviews. To focus on daily dynamics, we excluded activities whose intensity did not vary over time.\nFigure 1a depicts the temporal dynamics of pro-Ukrainian (Cyber U) and pro-Russian rebel (Cyber R) cyber operations. In early March 2014, about a week after the revolution in Kyiv, Figure 1 shows a spike in attacks by CB. The same month saw the establishment of the pro-Kyiv Ukrainian Cyber Forces, partly in response to CB's attacks. However, UCF operations do not become visible until May 2014, following an influx of volunteers to the group. May 2014 is also notable for a rise in activities by another pro-Russian cyber group, Cyber Riot Novorossiya—named after the czarist-era term (“New Russia”) for territories in southeastern Ukraine. After the first Minsk cease-fire agreement in September 2014, operations by pro-Ukrainian hackers converge to a steady rate of two to four per day, with occasional flare-ups, as in December 2014. Activities by pro-Russian hackers, by contrast, declined after the summer 2014.\n### Ukraine Violent Events Data\nOur data on kinetic operations include 26,289 violent events from Ukraine's Donbas region, recorded between February 28, 2014, and February 29, 2016. To offset reporting biases in any one source, while guarding against potential disruptions in media coverage due to cyber attacks, these data draw on seventeen Ukrainian, Russian, rebel, and international sources. As before, we include only events that appeared in more than one source.\nTo extract information on dates, locations, participants, and other event details, we relied on a combination of supervised machine learning (Support Vector Machine) and dictionary-based coding. The Online Appendix describes our measurement strategy and provides summary statistics.\nFigure 1b shows the temporal distribution of pro-Ukrainian (Kinetic U) and pro-Russian rebel (Kinetic R) physical violence. The plot shows several notable flare-ups of fighting—during a government offensive in late June 2014 and a rebel offensive in January 2015—as well as lulls following cease-fire agreements in September 2014, February 2015, and September 2015. Compared to the cyber operations in Figure 1, this plot reveals a clear correlation between kinetic operations\nTable 2. Types of Cyber Operations (Ukraine and Syria).\n|  Propaganda | Ukraine (%) | Syria (%) | Disruption | Ukraine (%) | Syria (%) | Both | Ukraine (%) | Syria (%)  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  PPI—publishing online private information of the members of the conflicting parties | 47 (2) | 59 (9) | AVG— audio-, video-, and geo-intelligence collection | 423 (23) | 1 (<1) | WDT—website defacement | 51 (3) | 389 (57)  |\n|  PRM/PUM—posting pro-rebel and pro-Ukrainian messages online | 54 (3)/5 (<1) | — | CPI—collecting private information via open sources | 13 (<1) | 10 (<2) |  |  |   |\n|  UWP—updating online pages | 6 (<1) | — | DDoS—distributed denial-of-service attack | 499 (27) | 78 (11) |  |  |   |\n|   |   |   |  ODS—other attacks with a purpose of disruption or espionage | 9 (1) | 10 (<2) |  |  |   |\n|   |   |   |  SPE—spear-phishing e-mail | 234 (13) | 17 (2.5) |  |  |   |\n|   |   |   |  STM—sending massive text messages or calling phones non-stop | 40 (2) | 1 (<1) |  |  |   |\n|   |   |   |  WBG—website blockage | 257 (14) | 376 (55) |  |  |   |\n|  Total | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100)  |\n|   |   |   |  |   |   |   |   |   |\nJournal of Conflict Resolution 63(2)\n(a) cyber\n(b) kinetic\nFigure 1. Cyber and kinetic operations in Ukraine (March 2014–February 2016). U (blue) indicates operations by Ukrainian government forces; R (red) indicates operations by pro-Russian rebel groups.\nby the two sides, with government and rebel attacks rising and falling in tandem. $^{15}$  Although this interdependence is not surprising, the data suggest that—with few exceptions—physical violence in Ukraine has been a reciprocal affair.\nFrom a brief glance at the timing of cyber and physical operations (Figure 1a and b), there are relatively few signs of a compelling effect—changes in the former do not appear to drive changes in the latter. However, a visual comparison can be misleading. Some of the variation may be due to fighting on the ground or in cyberspace, but other changes may reflect secular trends or shocks due to elections and other events not directly related to conflict. To account for these potential confounding factors and to gauge whether there is a stronger cyber-kinetic relationship than we would expect by chance, we conduct a series of more rigorous tests.\nEmpirical Strategy\nTo evaluate the relationship between cyber and kinetic operations in Ukraine, we estimate a series of vector autoregressive models\n$Y_{t} = \\sum\\limits_{j}^{p}B_{j}Y_{t - j} + GX_{t} + \\mu_{0} + \\mu_{1}t + \\mathbf{\\epsilon_{t}},$ (1)\nwhere $Y_{t} = \\left[y_{t}^{\\text{Kinetic(U)}}, y_{t}^{\\text{Kinetic(R)}}, y_{t}^{\\text{Cyber(U)}}, y_{t}^{\\text{Cyber(R)}}\\right]^{\\prime}$ is a matrix of endogenous variables, and $X_{t} = \\left[x_{1t},\\ldots,x_{kt}\\right]^{\\prime}$ is a matrix of k exogenous variables, which includes indicators for key dates and events during the war, like presidential and parliamentary electoral campaigns in Ukraine and breakaway territories; cease-fire agreements; and Ukrainian, Russian, and Soviet holidays. Deterministic components include a constant term (μ_{0}) and trend (μ_{1}t). p is the lag order, selected via Bayesian information criterion, and $\\mathbf{\\epsilon_{t}}$ is a vector of serially uncorrelated errors.\nWe control for Ukrainian, Russian, and Soviet holidays because anecdotal accounts suggest significant increases in cyber activity during such times. The UCF, for instance, had an operation called “Happy New Year,” which sought to print pro-Ukrainian messages from hacked printers in Crimea, Russia, and Donbas. National election campaigns represent another time when such activities may spike. Before and during the presidential elections, for instance, hackers bombarded Ukraine's Central Electoral Committee website with DDoS attacks. Finally, we may expect cease-fire agreements aimed at reducing physical violence to also have an effect in the cyber domain. For example, the cyber espionage operation “Armageddon”—directed against Ukrainian government websites—intensified before the Minsk I agreement went into force but then rapidly declined.\nBecause we are interested in the relationship between cyber attacks and physical violence during war, we limit our primary analysis to the active phase of military operations between May 11, 2014, and February 15, 2015—the period following independence referendums organized by the self-proclaimed Donetsk and Luhansk People's Republics and the second Minsk cease-fire agreement. In the Online Appendix, we present additional analyses of the full data set, which produced similar results.\n## Results\nData from Ukraine support the skeptical view of cyber coercion. The impulse--response curves in Figure 2 show a strong, escalatory dynamic between kinetic operations by the two sides (Kinetic U, Kinetic R), but no tangible links in either direction between kinetic and cyber operations, and no reciprocity between cyber actions (Cyber U, Cyber R).\nFollowing a standard deviation increase in kinetic rebel attacks, government violence sees a delayed rise, peaking around two days after the shock and gradually\n|  Response: |   |\n| --- | --- |\n|  Kinetic (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  |\n|  Kinetic (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  |\n|  Cyber (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  |\n|  Cyber (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  |\nFigure 2. Impulse response matrix, daily time series (Ukraine). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"U\" indicates reported kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\ndeclining back to zero (top row, second column). Rebel operations also rise after shocks to government operations (second row, first column), but the response here is immediate, without the delay we observe in government operations. This pattern may reflect command and control inefficiencies in the Ukrainian army, particularly early in the conflict, when indecision and leadership turnover lengthened decision cycles.\nThe relationship between cyber and kinetic operations is far weaker than that between rebel and government violence on the ground. Cyber attacks by pro-Ukrainian forces see no increase after shocks in kinetic government operations, and a positive, but uncertain increase after shocks in kinetic rebel operations (third row, first and second columns).\nThere is even less evidence that cyber attacks drive kinetic operations. The impulse--response function (IRF) curve for pro-Ukrainian government violence is, in fact, negative after shocks to rebel cyber operations (top row, two rightmost columns). Although this negative response might otherwise suggest that cyber attacks compel a decline in violence—consistent with coercive success—the estimate is also highly uncertain. Following shocks to pro-Ukrainian cyber activities, meanwhile, the main change in rebel kinetic operations is a short-term increase in volatility (second row, third column). In sum, the data suggest that cyber attacks may make violence less predictable but do not systematically change its intensity.\nPerhaps most surprisingly, there is little or no apparent strategic interaction between “cyber-warriors” on each side of the conflict. A shock in pro-Ukrainian cyber attacks yields no discernible change in pro-rebel cyber attacks (bottom row, third column) and vice versa (third row, fourth column). The two cyber campaigns, the data suggest, have unfolded independently of each other and independently of events on the ground.\nAs the diagonal elements in Figure 2 suggest, there is strong autocorrelation in each series. For each of the four categories, past shocks in operations yield a significant spike in subsequent operations. To evaluate whether the other categories of events can help us predict future values of each series, after we take this autocorrelation into account, Table 3 reports the results of Granger causality tests. The tests confirm that past levels of prorebel and pro-Kyiv kinetic operations help predict each other's future values. Kinetic operations, however, do not appear to “Granger cause”—or be “Granger caused” by—cyber attacks on either side.\nTable 4 reports the forecasting error variance decomposition, representing the proportion of variation in each series (rows) due to shocks in each endogenous variable (columns). For most variables, their own time-series account for almost all variation at the outset, but this dependency gradually decreases. As before, there is far more dependence within kinetic operations than between kinetic and cyber or within cyber actions. By the thirty-day point in the daily time series, shocks in rebel attacks account for 7 percent of variation in Ukrainian government operations, while shocks in government operations explain 12 percent of variation in rebel violence.\nJournal of Conflict Resolution 63(2)\nTable 3. Granger Causality Test, Daily Time Series (Ukraine).\n|  Effects | F statistic | p value  |\n| --- | --- | --- |\n|  Kinetic (R) → Kinetic (U) | 40.26 | .00  |\n|  Cyber (U) → Kinetic (U) | 0.50 | .48  |\n|  Cyber (R) → Kinetic (U) | 0.09 | .76  |\n|  Kinetic (U) → Kinetic (R) | 12.29 | .00  |\n|  Cyber (U) → Kinetic (R) | 1.44 | .23  |\n|  Cyber (R) → Kinetic (R) | 2.70 | .10  |\n|  Kinetic (U) → Cyber (U) | 1.40 | .24  |\n|  Kinetic (R) → Cyber (U) | 1.88 | .17  |\n|  Cyber (R) → Cyber (U) | 0.00 | .95  |\n|  Kinetic (U) → Cyber (R) | 1.74 | .19  |\n|  Kinetic (R) → Cyber (R) | 0.14 | .71  |\n|  Cyber (U) → Cyber (R) | 0.89 | .35  |\nNote: \"U\" indicates reported kinetic and cyber operations by Pro-Ukrainian government forces, and \"R\" indicates operations by Pro-Russian rebel forces.\nTable 4. Variance Decomposition, Daily Time Series (Ukraine).\n|  Operation type | Kinetic (U) | Kinetic (R) | Cyber (U) | Cyber (R)  |\n| --- | --- | --- | --- | --- |\n|  Kinetic (U) |  |  |  |   |\n|  1 Day | 1.000 | .000 | .000 | .000  |\n|  2 Days | 0.920 | .060 | .002 | .018  |\n|  7 Days | 0.906 | .071 | .002 | .020  |\n|  30 Days | 0.906 | .071 | .002 | .020  |\n|  Kinetic (R) |  |  |  |   |\n|  1 Day | 0.108 | .892 | .000 | .000  |\n|  2 Days | 0.121 | .873 | .000 | .006  |\n|  7 Days | 0.122 | .870 | .000 | .008  |\n|  30 Days | 0.122 | .870 | .000 | .008  |\n|  Cyber (U) |  |  |  |   |\n|  1 Day | 0.000 | .002 | .998 | .000  |\n|  2 Days | 0.000 | .002 | .997 | .000  |\n|  7 Days | 0.000 | .003 | .997 | .000  |\n|  30 Days | 0.000 | .003 | .997 | .000  |\n|  Cyber (R) |  |  |  |   |\n|  1 Day | 0.012 | .023 | .000 | .964  |\n|  2 Days | 0.014 | .023 | .001 | .962  |\n|  7 Days | 0.015 | .023 | .001 | .961  |\n|  30 Days | 0.015 | .023 | .001 | .961  |\nNote: \"U\" indicates kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\nBy contrast, shocks to cyber activities account for very little variation in kinetic operations. The highest value is for pro-Russian rebel cyber activities, which account for 2 percent of short-term variation in government violence. Cyber attacks by each side also have a relatively small impact on each other. Indeed, rebel kinetic operations explain more of the variation in cyber attacks by each actor than do cyber attacks by the other side.\nIn sum, our analysis suggests that low-level cyber attacks in Ukraine have had no effect on the timing of physical violence. Not only is there no evidence that cyber attacks have compelled opponents to de-escalate fighting, there is no discernible reciprocity between the cyber actors themselves. Each group of hackers seems to operate in its own bubble, disengaged from unfolding events in both cyberspace and the physical world.\n### Robustness Checks\nTo gauge the sensitivity of our results to various modeling and measurement choices, we conducted extensive robustness checks. We summarize their results briefly here (Table 5) and more fully in the Online Appendix.\nThe first set of tests considers vector autoregression models with alternative orderings of the four endogenous variables, which affects estimation of impulse responses. We find no substantive differences across the twenty-four permutations.\nIn a second set of robustness checks, we account for systematic differences in the kinds of conflict events that Ukrainian and Russian media report, which may bias statistical estimates—for example, by underreporting violence by a given actor. Using kinetic data from exclusively Russian or exclusively Ukrainian sources does not change the results.\nA third set of robustness tests examines different subsets of cyber attacks. Because purely disruptive activities may impose greater immediate costs than quasi-propagandistic hybrid attacks, pooling these events may dilute their coercive effect. Our results are consistent for all three subsets.\nThe last set of robustness checks examines different time periods of the conflict, since some cyber attacks predated military activity. In particular, we compare the period of intense fighting previously analyzed (May 11, 2014--February 15, 2015) to the entire date range for which we have data (February 28, 2014--February 29, 2016). Our results remain unchanged.\n## Evidence from Interviews\nIn interviews, Russian and Ukrainian cyber security experts highlighted five potential explanations for the apparent failure of cyber coercion in Ukraine: (1) lack of resources, (2) lack of coordination, (3) lack of targets, (4) lack of audience, and (5) lack of effort.\nTable 5. Robustness Checks (Ukraine and Syria).\n|  Ukraine (main results; May 11, 2014–February 15, 2015)  |   |   |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n|  I | Disruption and both | Kin(R) ↔ Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) ↔ Kin(R) | Kin(U) ↔ Kin(R) | Kin(U) → Kin(G)  |\n|  ID | Cyber | GCT(w) | VD(d) (30 day) | VD(w) (12 week) |  |  |   |\n|  I | Disruption and both |  | Kin(R) → 7%Kin(U) | Kin(R) → 10%Cyb(R) |  |  |   |\n|   |   |   | Kin(R) → 2%Cyb(R) | Kin(U) → 21%Kin(R) |  |  |   |\n|   |   |   | Kin(U) → 12%Kin(R) | Kin(U) → 17%Cyb(R) |  |  |   |\n|   |   |   | Kin(U) → 2%Cyb(R) | Cyb(U) → 4%Cyb(R) |  |  |   |\n|  ID | Cyber | IRF(d) | IRF(w) | GCT(d) | GCT(w) | VD(d) (30 day) | VD(w) (12 week)  |\n|  Ukraine (March 22, 2014–February 29, 16)  |   |   |   |   |   |   |   |\n|  2 | All | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U/R) ↔ Kin(U) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Cyb(U) ↔ Kin(R) |  |  | Kin(U) → 3%Cyb(R)  |\n|  3 | Propaganda | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin(U)/Cyb(R) | Kin(R) → 3%Kin(U) | Kin(R) → 9%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) → Kin/Cyb(R) | Kin(U) → Cyb(R) | Kin(U) → 18%Kin(R) | Kin(R) → 3%Cyb(R)  |\n|   |   |   | Cyb(U) → Kin(U) | Kin(U) → Cyb(R) |  |  | Kin(U) → 46%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(R)  |\n|  4 | Disruption | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(U/R) |  | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|  5 | Disruption and both | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(R) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Kin(U) → Cyb(U) |  |  |   |\n(continued)\nTable 5. (continued)\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) Ukraine (May 11, 2014-February 11, 2015) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  6 | All | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) |  | Kin(R) → 7%Kin(U) | Kin(R) → 2%Cyb(U)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(U) → 13%Kin(R) | Kin(R) → 18%Cyb(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 30%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(U/R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 4%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(U)  |\n|  7 | Propaganda | Kin(R) → Kin(U) | Cyb(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Cyb(R) | Kin(R) → 7%Kin(U) | Kin(U) → 27%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) |  |  | Kin(U) → 13%Kin(R) | Kin(U) → 4%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 3%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 9%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 20%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 5%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(R) → 2%Cyb(U)  |\n|  8 | Disruption | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → Cyb(U) | Kin(R) → 7%Kin(U) | Kin(U) → 29%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(R) → 2%Cyb(R) | Kin(U) → 34%Cyb(U)  |\n|   |   |   |  |  |  | Kin(U) → 12%Kin(R) | Kin(U) → 22%Cyb(R)  |\n|   |   |   |  |  |  | Cyb(R) → 2%Kin(U) | Kin(R) → 3%Kin(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 10%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 13%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 6%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 7%Cyb(U)  |\nSyria (March 17, 2011-July 10, 2016)\n|  9 | Disruption and both | Kin(G) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → 2%Kin(R)  |\n| --- | --- | --- | --- | --- |\nNote: IRF = impulse response functions; GCT = Granger causality tests; VD = variance decomposition; d = daily; w = weekly; o = alternative orderings; RU = Russian; U = Ukrainian.\nThe first explanation for coercive failure emphasizes limited resources and capabilities, particularly for the Ukrainian government. Ten years ago, the SBU briefly had a cyber department but shut it down after a year (Kostyuk and Zhukov 2017, #3). This unit has recently reopened but continues to lack funding and personnel (Kostyuk and Zhukov 2017, #3, #9). It is possible that, with adequate resources, capabilities, and human capital, the Ukrainian cyber campaign might have been more effective. Resource constraints, however, do not explain coercive failure on the pro-Russian side, where investment in cyber capabilities is more robust.\nA second explanation is lack of government coordination with hackers, especially in Kyiv (Maurer and Geers 2015). UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success (Kostyuk and Zhukov 2017, #1). The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place (Kostyuk and Zhukov 2017, #1, #3, #9). Yet again, this explanation is less plausible on the pro-Russian side, where the Kremlin has cultivated extensive ties with non-state hacktivists.\nA third explanation is that—even with requisite capabilities and coordination—there are few opportune targets for disruption in Ukraine. Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult (Geers 2015; Kostyuk and Zhukov 2017, #3, #13). Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack” (Kostyuk and Zhukov 2017, #11). The 2015 and 2016 hacks of Ukraine's power grid also seem to challenge this explanation.\nThe peculiarities of Ukraine's online population represent a fourth explanation for the indecisiveness of cyber attacks. Since only 44.1 percent of Ukrainians have Internet access—compared to 88.5 percent in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses (Kostyuk and Zhukov 2017, #3). Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones (Kostyuk and Zhukov 2017, #7, #11). Our data suggest that, even if this were the case, propagandistic attacks still had no effect on violence.\nThe final explanation is that cyber compellence failed because it was never seriously attempted. At first, our interviews with individual hackers revealed no shortage of coercive intent. UCF leader Eugene Dokukin claimed to conduct low-level attacks daily and vowed to continue until pro-Russian rebels lay down their arms. Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns (Kostyuk and Zhukov 2017, #1).\nWhile UCF and other nonstate groups have explicitly sought to affect battlefield outcomes, some interviewees questioned whether this intent extended to the Russian\ngovernment. Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place (Kostyuk and Zhukov 2017, #5, #12). This access, along with vigorous cyber espionage—some of it ongoing since 2010—may create incentives against more aggressive actions, which could compromise valuable sources of intelligence.\nConsistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda (Kostyuk and Zhukov 2017, #11). When in 2011 Vyacheslav Volodin replaced Vladislav Surkov as head of the Presidential Administration, he toughened existing laws against Russia's opposition and promoted the use of mass media and online platforms—tools already mostly under state control—to conduct information campaigns. If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising (Kostyuk and Zhukov 2017, #2, #14).\n## Evidence beyond Ukraine: Syria's Digital Front\nAccording to evidence from microlevel data and interviews, cyber attacks did not affect battlefield events in Ukraine. During one of the first armed conflicts where both sides used low-level cyber actions extensively, events in the digital realm have unfolded independently of—and have had no discernible effect on—events on the ground. Conditions in Ukraine were in many ways optimal to observe the coercive impact of cyber actions, for reasons we already discussed (i.e. visibility of major attacks, regular claims of responsibility, less uncertainty over attribution). Yet we found no evidence that low-level cyber attacks affected physical violence. Nor did hackers on each side even affect each other's activities.\nWhile important, Ukraine is not the only contemporary conflict with a significant cyber dimension. In Syria, state and nonstate actors have employed low-level cyber actions extensively for propaganda and disruption, complementing traditional tools of warfare in the deadliest conflict ongoing today. Syria's war has also lasted three years longer than Ukraine's. Over this time, its digital front has expanded in scope and sophistication, offering a glimpse of cyber coercion in a more protracted setting.\nAn in-depth study of Syria's digital front lies beyond the scope of this article. A brief analysis of the data, however, suggests that our findings from Ukraine may be part of a broader pattern: cyber capabilities have not yet evolved to the point of having an impact on physical violence.\nTo evaluate the effectiveness of cyber compellence in this second case, we replicated the model in (equation 1), using an analogous daily time series of cyber attacks and violent events in Syria. Our data comprise 9,282 kinetic and 682 low-level cyber attacks ranging from March 2011 until July 2016. Table 2 provides a breakdown of cyber techniques used in the Syrian conflict, their brief description, and frequency. Our data on kinetic operations rely on human-assisted machine\nJournal of Conflict Resolution 63(2)\nFigure 3. Cyber and kinetic operations in Syria (March 2011-July 2016). G (blue) indicates operations by pro-Assad government forces; R (red) indicates operations by anti-Assad rebel groups.\ncoding of event reports from the International Institute for Strategic Studies Armed Conflict Database (see Online Appendix for details).\nGiven the complex nature of the Syrian conflict and the multiple parties involved, we restrict our analysis only to operations by progovernment forces (i.e., Syrian Army, Hezbollah and pro-Assad militias) and the main rebel opposition (i.e., Free Syrian Army, Jaish al-Fatah, including Al Nusra Front). Table 1 provides a list of cyber actors in the Syrian conflict, their targets, and frequency of their activities.\nThe dynamics of cyber and kinetic operations in Syria exhibit similar patterns to what we saw in Ukraine. Raw data (Figure 3a and b) suggest relatively little overlap in timing, especially at the beginning of the conflict. The IRF curves in Figure 4 show a rise in rebel operations following shocks to government operations (second row, first column), and mostly negligible (though negative) links between cyber and kinetic operations, and across cyber attacks by each actor. Links between kinetic\n|  Response: |   |\n| --- | --- |\n|  Kinetic (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380 385 390 395  |\n|  Kinetic (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295  |\n|  Cyber (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 260 270 275  |\n|  Cyber (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230  |\n|  Impulse: | Kinetic (G) Kinetic (R) Cyber (G) Cyber (R)  |\nFigure 4. Impulse response matrix, daily time series (Syria). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"G\" indicates reported kinetic and cyber operations by pro-Assad government forces, and \"R\" indicates operations by anti-Assad rebel forces.\noperations—and their disconnect from cyber attacks—are also evident in variance decomposition results, and Granger tests, provided in the Online Appendix.\nThere are several reasons for caution in interpreting these results. The Syrian conflict involves a larger constellation of actors than Ukraine, and our dyadic analysis may overlook significant interactions elsewhere, particularly between actors with more developed cyber capabilities (e.g. Russia, United States). We also lack interview evidence that might help contextualize the null effect. However tentative, these results do align with what we saw in Ukraine: low-level cyber attacks have had little or no impact on violence.\n## Conclusion\nThe evidence we presented in this article—based on analysis of new data and expert interviews—suggests that cyber attacks are ineffective as a tool of coercion in war. Although kinetic operations explain the timing of other kinetic operations, low-level cyber attacks have no discernible effect on violence in the physical world. In Ukraine and Syria, the “cyberwar” has unfolded in isolation from the rest of the conflict.\nThis finding has several implications for theory and policy. First, by providing the first statistical analysis of modern low-level cyber campaigns, our study complements the qualitative focus of previous empirical work. Second, our research sheds light on a theoretical question about the strength and direction of the cyber--kinetic relationship and—in so doing—begins to fill an empirical gap in political science literature on this topic. Third, to the extent that policymakers might overestimate the importance of cyber actions due to a lack of empirical evidence to the contrary, our findings can potentially help correct this misperception. Finally, and more worryingly, our results suggest that—due to their disconnect from physical violence—low-level cyber attacks are very difficult to predict.\nFurther research is needed to understand the dynamics of low-level cyber attacks. One such area of research is cyber coercion in the context of symmetric, conventional war. While our study helps illuminate dynamics of cyber compellence between parties with asymmetric capabilities, we may well observe different patterns when major powers use cyberspace against peer competitors. Thankfully, no armed conflict has yet provided researchers with the data needed to evaluate this possibility.\nSecond, our scope in this article has been exclusively on short-term military consequences rather than long-term political effects. The latter are no less theoretically significant, but—unlike simple counts of violent events—potentially more difficult to measure and analyze. A study of long-term political effects would also need to more systematically incorporate purely propagandistic cyber activities and their impact on public opinion, which we omitted here due to our focus on short-term military compellence.\nAlthough the secretive nature of many ongoing physical and digital operations is a challenge for this research, questions over the coercive potential of cyber attacks\nwill become only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” (Sabah 2016)—have yielded few tangible successes (Sanger and Schmitt 2017). Our data from Ukraine indicate that the US experience may be part of a broader pattern.\nAt best, coordination between low-level cyber and kinetic operations today is on roughly the same level as that between airpower and ground operations in World War I. Back then, armies were increasingly using aircraft for reconnaissance and surveillance on the front but were not yet able to fully exploit their potential for ground combat support and strategic bombing. That revolution appeared on the battlefield twenty-five years later, with devastating effect. As cyber capabilities develop and synchronization challenges become less severe, there will be a growing need for assessments of how far we have come. We hope that analyses of the sort we provided in these pages can serve as an early benchmark.\n## Authors' Note\nA previous version of this article was presented at the 2015 Peace Science Society International annual meeting, Oxford, MS, and at the Association for the Study of Nationalities Convention at New York, NY.\nWe are grateful to Maura Drabik, Paulina Knoblock, Neil Schwartz, and Alyssa Wallace for excellent research assistance. Robert Axelrod, Myriam Dunn-Cavelty, Eric Gartzke, Miguel Gomez, Todd Lehmann, Jon Lindsay, Tim Maurer, Brandon Valeriano, Christopher Whyte, and workshop participants of the Conflict & Peace, Research & Development workshop at the University of Michigan, of the Bridging the Gap Workshop on Cyber Conflict at Columbia University, of the Cross-Domain Deterrence lab at the University of California, San Diego, and of the Center for Security Studies at ETH Zurich provided helpful comments on the earlier drafts of this article.\n## Declaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n## Funding\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.\n## Supplemental Material\nSupplemental material for this article is available online."
    },
    "numeric": {
      "total": {
        "intext_total": 0,
        "success_occurrences": 0,
        "success_unique": 0,
        "bib_unique_total": 0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "style": "numeric"
      },
      "results": [],
      "flat_text": "Check for updates\nArticle\n# Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\nJournal of Conflict Resolution\n2019, Vol. 63(2) 317-347\n© The Author(s) 2017\nArticle reuse guidelines:\nsagepub.com/journals-permissions\nDOI: 10.1177/0022002717737138\njournals.sagepub.com/home/jcr\nSAGE\nNadiya Kostyuk¹, and Yuri M. Zhukov¹\n## Abstract\nRecent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.\n## Keywords\ncompellence, coercion, physical violence, conflict, cyber attacks\nOn December 23, 2015, hackers attacked Ukraine’s power grid, disabling control systems used to coordinate remote electrical substations, and leaving people in the capital and western part of the country without power for several hours. The Security\n¹Department of Political Science, University of Michigan, Ann Arbor, MI, USA\n## Corresponding Author:\nNadiya Kostyuk, Department of Political Science, University of Michigan, 505 S State Street, Ann Arbor, MI 48109, USA.\nEmail: nadiya@umich.edu\nService of Ukraine (SBU) blamed the Russian government for the cyber attack, an accusation that later found support in malware analysis by a private computer security firm. The Ukrainian hack was the first publicly acknowledged case of a cyber attack successfully causing a power outage. It is also just one of thousands of cyber activities, mostly diffuse and low level, that have occurred alongside physical fighting in Ukraine. Attacks launched through the digital realm are playing an increasingly visible role in civil and interstate conflict—in Ukraine, Syria, Israel, Estonia, Georgia, and beyond. Yet it remains unknown whether such activities have a real coercive impact on the battlefield.\nRecent years have seen growing concern over the coercive potential of cyber capabilities in war, but little evidence that these new tools are yet making a difference. Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence (Libicki 2009; Sharma 2010; Andres 2012). Yet the logic of coercion entails distinct challenges in peace and war, with potentially different implications for the cyber domain. Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist (Valeriano and Maness 2014) privilege massive cyber catastrophes over less sophisticated low-intensity attacks, like distributed denial of service (DDoS). The latter category, however, is far more common.\nThis article asks whether cyber attacks can compel short-term changes in battlefield behavior, using new event data on cyber and kinetic operations from armed conflicts in Ukraine and Syria. We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides (Geers 2015), and—uniquely—overt claims of responsibility, public damage assessments, and other releases of information that reduce uncertainty over timing and attribution. Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques” (Zetter 2017). If cyber attacks can yet make a difference on the battlefield, Ukraine is one a few cases where we are most likely to observe such an effect. Our data include 1,841 unique cyber attacks and 26,289 kinetic operations by government and prorebel forces between 2014 and 2016. We supplement this quantitative analysis with fourteen primary source interviews with participants in the cyber campaign as well as Ukrainian, Russian, and Western cyber security experts with direct knowledge of these operations.\nTo evaluate the generalizability of the Ukrainian experience to other conflicts, we replicate our results with data from Syria's civil war. Like Ukraine, Syria has seen the extensive use of low-level cyber attacks by factions fighting for and against the incumbent regime. Because this war has gone on significantly longer than the conflict in Ukraine—giving hackers more time to organize and develop their capabilities—Syria offers a glimpse at cyber activities in a more protracted, higher intensity context. If we uncover similar patterns in two conflicts of such different scale and complexity, we can have greater confidence that our results are not artifacts of a single idiosyncratic case. Our data include 682 cyber attacks and 9,282 acts of violence by pro- and anti-Assad forces between 2011 and 2016.\nEvidence from both conflicts suggests that cyber attacks have not created forms of harm and coercion that visibly affect their targets' actions. Short of mounting synchronized, coordinated cyber campaigns, each group of hackers has seemed to operate in its own “bubble,” disengaged from unfolding events in both cyberspace and the physical world. The lack of discernible reciprocity between cyber and kinetic operations—and between the cyber actors themselves—questions whether cyber attacks can (yet) be successfully deployed in support of military operations.\nThis disconnect may be temporary, as joint planning and execution concepts continue to evolve. Many countries, for instance, still struggle in coordinating air-power for ground combat support, a century after World War I. Our study highlights some of the difficulties that countries will need to overcome in integrating and synchronizing these new capabilities.\nOur contribution is fourfold. We offer the first disaggregated analysis of cyber activities in war and take stock of the empirical relationship between the cyber and kinetic dimensions of modern battle. To do so, we collect the first microlevel data on wartime cyber attacks, using both open media sources and anonymous attack traffic data. Theoretically, our analysis addresses an important question on the coercive impact of low-level cyber attacks, advancing a literature that has been heavy on deductive argumentation, but light on evidence. Finally, from a policy standpoint, our findings should temper the popular tendency to overhype the transformative potential of cyber attacks. At present, interaction between cyber and kinetic operations is similar to that between airpower and ground operations in World War I—when armies began to use aircraft for reconnaissance but had not realized their full potential to shape battlefield outcomes.\n## Varieties of Cyber Activity\nThe term “cyber activities” captures a diverse assortment of tactics and procedures, directed against different types of targets, in pursuit of disparate objectives. Not all of these activities seek to achieve battlefield effects in the same way. Before proceeding further, we differentiate between two broad goals these actions tend to pursue: propaganda and disruption.\nCyber activities in the propaganda category seek to influence public opinion and indirectly undermine an opponent's financing or recruitment. Operations in this group include leaks of compromising private information, online publication of partisan content (e.g. “trolling” on comments pages), and the establishment of dedicated websites and forums to promote an armed group's message. Unless it openly incites or discourages violence, propaganda affects kinetic operations only indirectly by undermining an opponent's support base or obfuscating perceptions of events.\nIn the Ukrainian conflict, the importance of both groups attach to online propaganda is evident from the time and resources pro-Kyiv fighters spend updating Wikipedia, and pro-Russia groups devote to creating and running dedicated\nYouTube channels and social media accounts. Russian military doctrine places a heavy emphasis on the strategic use of information in warfare, as does US cyberspace joint planning doctrine.\nThe second category of cyber attacks—disruption—seeks to directly sabotage opponents' ability to operate in the physical or electronic realm. These mostly low-intensity activities include denial of service attacks, which make targeted resources unavailable through a flood of requests from a single source, and DDoS attacks, where requests originate from multiple compromised systems. Related efforts include inundating communications systems with floods of text messages or phone calls and using fire walls and proxies to block access to websites. At the extreme end of the scale is the use of malicious code to inflict physical damage or otherwise compromise infrastructure and military objects. Examples include interception of drones, communications and surveillance systems, control of Wi-Fi access points, and collection of protected information via phishing.\nThe most sophisticated known attack of this type is the Stuxnet worm, which—before its discovery in 2010—targeted industrial control systems critical to uranium enrichment in Iran. In Ukraine, notable disruptive activities have included attacks on the Central Election Committee's website during the 2014 presidential elections and attacks on the country's power grid in 2015 and 2016. Other examples include the use of malware to collect operational intelligence, like X-Agent, which retrieved locational data from mobile devices used by Ukrainian artillery troops, and the hacking of closed-circuit television (CCTV) cameras behind enemy lines.\nPropaganda and disruption are not mutually exclusive, and many cyber activities serve both purposes—shaping public opinion through disruption or disrupting an opponent's operations by shaping public opinion. For example, altering the visual appearance of websites can have the dual effect of embarrassing the target and limiting its ability to communicate. Leaks of private information also have dual implications for targets' public image and physical security.\nRecent examples of hybrid activities include the defacement of US Central Command's Twitter and Facebook pages by the Islamic State's (IS) Cyber Caliphate and operations by US Cyber Command against IS beginning in April 2016. In Ukraine, the pro-rebel group CyberBerkut (CB) has leaked private communications from senior United States, European Union, and Ukrainian officials and disclosed identities of pro-Kyiv field commanders—simultaneously creating a media scandal and forcing targets to commit more resources to personal security. Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations (Il'chenko 2016).\nIn the following, we limit the scope of our inquiry to cyber actions that are either purely disruptive (e.g. DDoS-style attacks) or are hybrids of the two approaches (e.g. web defacements). We do so for two reasons. First, most purely propagandistic operations, like comment-board trolling, do not aspire to influence the course of\nmilitary operations in the short term. Second, it is hard to separate the disruptive and propaganda effects of hybrid cyber activities because they depend on each other.\n## Cyber Coercion in Wartime\nOver the last two decades, cyber attacks have become an increasingly common tool of coercion, used by state and nonstate actors, independently and jointly with physical, kinetic operations. Like other instruments of coercion, cyber actions inflict costs on a target to compel a change in its behavior—either by punishing past misdeeds or by putting pressure on decision makers in real time.\nThe role of cyber compellence in wartime is not unlike that of airpower or terrorism (Pape 2003, 2014). Cyber attacks cannot take or hold territory on their own, but they can support operations on the ground by disrupting opponents' command and control, collecting operational intelligence, and creating opportunities for conventional forces to exploit. If combatants use the Internet for coordination, recruitment, or training, low-level cyber disruption may prevent them from running these vital functions smoothly. Alternatively, cyber attacks can indirectly pressure an opponent by targeting civilian economy and infrastructure, similarly to strategic bombing. Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties (Ottis 2010). Unlike terrorism, the individual attacker is rarely at risk of direct physical harm.\nDespite the apparent promise of these “weapons of the future” (Schmitt 1999; Rios 2009; Clarke and Knake 2010; McGraw 2013; Eun and Aßmann 2014), some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion (Liff 2012; Rid 2012; Gartzke 2013; Junio 2013). There is little doubt that large numbers of low-level attacks can cumulatively produce large-scale damage, bringing “death by a thousand cuts” (Lemay, Fernandeza, and Knight 2010). Yet successful coercion also requires punishment to be both anticipated and avoidable (Schelling 1966), and these criteria can be difficult to meet in cyberspace.\nCyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities (Axelrod and Iliev 2014). Since the destructiveness of malicious code depreciates quickly after first use, cyber attacks are often most damaging when they are least anticipated.\nTargets also have many reasons to doubt that cyber attacks are avoidable by accommodation. For the attacker, cyber actions present a trade-off between plausible deniability—which helps prevent retaliation—and the credibility of coercive promises and threats. Any uncertainty over the source of an attack will also create uncertainty over the nature of compliance—what sort of actions will prevent future attacks and by whom.\nBeyond attribution uncertainty, cyber attacks may not generate sufficient costs to elicit compliance from. Because administrators can quickly fix or contain many\nexploited vulnerabilities, even successful attacks cause only temporary disruption (Axelrod and Iliev 2014). Unless the attacker continues to develop new methods and identify new vulnerabilities, a protracted campaign may quickly lose its coercive impact. As a result, targets may see compliance as insufficient and unnecessary to stop the damage (Hare 2012; Lynn 2010; Nye 2010).\nForce synchronization challenges may also render the timing of cyber attacks suboptimal for compellence. Hackers—especially those not integrated with military forces—may not observe battlefield events on a tactically relevant time line. Even if they did, the lead time required to plan and implement a successful attack—studying the target system, collecting intelligence on its vulnerabilities, and writing code that exploits them—can make these efforts difficult to synchronize with conventional operations.\nThese challenges are not insurmountable. Lead time is a greater barrier for high-level attacks (e.g. targeting major infrastructure) than for more routine, DDoS-style attacks. Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower (Atran 2003; Pape 2003, 2014). The ability of contemporary hackers to overcome these difficulties, however, remains unknown.\n### Previous Research\nThe question of whether low-level cyber attacks compel has deep implications for the theory and practice of national security. Yet the public and academic debate on this topic has unfolded largely in the absence of rigorous empirical evidence in either direction. Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare (Cha 2000; Griniaiev 2004; Libicki 2007, 2011; Czosseck and Geers 2009; Clarke and Knake 2010; Axelrod and Iliev 2014), the overlap between cyber and kinetic capabilities (Healey 2013; Kello 2013; Libicki 2015; Andress and Winterfeld 2013; Axelrod 2014), and the effect of information and communication technology on conflict (Martin-Shields 2013; Pierskalla and Hollenbach 2013; Crabtree, Darmofal, and Kern 2014; Gohdes 2014; Bailard 2015).\nMost research in the first category has focused on the implications of cyber activities for peacetime deterrence or the offense--defense balance rather than wartime compellence. While the second group focuses more directly on cyber attacks during conflict, its empirical approach has been mostly qualitative, relying on evidence from descriptive case studies, macrohistorical surveys, and stylized facts. Some large-n analyses do exist (Valeriano and Maness 2014), but their scope has remained on large-scale cyber attacks rather than the far more numerous low-intensity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action (Weidmann 2015) rather than military compellence.\nOur study bridges the gap between these areas of inquiry. Our goal is to assess the coercive potential of low-level cyber actions during an armed conflict. We pursue this goal by studying the magnitude and direction of the relationship between cyber attacks and physical violence, using microlevel data from ongoing conflicts in Ukraine and Syria.\n### Empirical Expectations\nCyber attacks by actor A can affect physical violence by B in one of the three ways: negatively, positively, or not at all. If cyber compellence is successful, we should expect a short-term decrease in violence after a spike in cyber attacks. A positive response would suggest failure, where cyber attacks actually escalate violence by the opponent. If no relationship exists, cyber actions are either ineffective or irrelevant to fighting in the physical world.\nIn addition to compellence across domains, cyber attacks by actor A may impact cyber attacks by actor B. As before, only a negative relationship would imply coercive success, while a null or positive response would suggest that these actions are either ineffective or counterproductive.\n## Data Analysis\nTo evaluate whether and how cyber actions affect physical violence in war, we analyze new micro-level data from Ukraine and Syria. We begin with an in-depth study of the Ukrainian case, as one of few conflicts where both sides have used cyber attacks as a means of coercion. Due to the sophistication of hackers on both sides, the public nature of many attacks, and an abundance of data, the Ukrainian conflict allows us to observe the short-term coercive impact of cyber attacks. We then use analogous event data on Syria to evaluate the generalizability of our results. While a more systematic analysis of cross-national patterns lies beyond the scope of our article, micro-level evidence from these two conflicts might be suggestive of general patterns of modern warfare—particularly where combatants with asymmetric capabilities use cyberspace along with traditional tools of war.\nIn assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets (Baum and Zhukov 2015; Davenport and Stam 2006; Woolley 2000), we draw data from multiple open sources—including press reports and anonymous attack traffic data. To reduce potential false positives, we include only those events that have been reported by more than one source.\n### Ukraine Cyber Attacks Data\nOur cyber event data on Ukraine include 1,841 unique, mostly low-level, cyber attacks from August 27, 2013, to February 29, 2016, drawn from two sets of sources.\nFirst are media reports of cyber attacks from rebel, Russian, Ukrainian, and Western news outlets, press releases and blogs along with social media platforms used by the involved nonstate actors. Second is the private cyber security firm Arbor Networks' Digital Attack Map (DAM; see http://www.digitalattackmap.com/about/). Unlike media sources—which include only cyber attacks publicly reported by news organizations or claimed by governments and hacker groups directly—DAM draws on anonymous attack traffic data and network outage reports to enumerate the top 2 percent of reported attacks that generate unusually high Internet traffic for each country. Including these “higher-visibility” attacks should make it easier to find a coercive effect.\nWe supplemented these data with fourteen primary source interviews with participants in the cyber campaign, as well as Russian, Ukrainian, and Western cyber security experts with direct knowledge of these operations, from the private and public sectors, academia, and journalism. We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix (Kostyuk and Zhukov 2017).\nWe grouped cyber attacks in our data set according to the partisanship of alleged perpetrators (pro-Ukrainian vs. prorebel) and the type of operation they conducted (propaganda vs. disruption). Table 1 list all actors conducting cyber activitiess in the Ukrainian conflict, their targets, and the reported frequency of their activities.\nUkrainian cyber actions include specific attacks by pro-Kyiv hackers like Anonymous Ukraine and Ukrainian Cyber Forces (UCFs). The latter is the most active group on the pro-Ukrainian side. In an interview, UCF leader Eugene Dokukin claimed to have established the nonstate group in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine (Kostyuk and Zhukov 2017, # 1). Pro-Kyiv hackers' most common targets are the communications and finances of rebel units as well as media firms and private companies in rebel-held areas.\nProrebel cyber actions include specific attacks by proseparatist or pro-Russian cyber actors, like CB, Cyber Riot Novorossiya, Green Dragon, and the Russian government. The first of these takes its name from Ukraine's disbanded Berkut riot police and claims to fight “neofascism” in Ukraine. Ukrainian and Russian cyber experts we interviewed offered contradictory assessments on CB's organizational structure. One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution (Kostyuk and Zhukov 2017, # 12). Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB (Kostyuk and Zhukov 2017, #7 & #8). These groups' most popular targets include Ukrainian government officials, media, and private citizens.\nWe further disaggregated these events into the two categories previously defined—propaganda or disruption—as well as a third, hybrid, category of incidents\nTable I. Actors and Targets (Ukraine and Syria).\n|  Ukraine  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Pro-Kyiv | Actor/target | Frequency (%) | Prorebel | Actor/target | Frequency (%)  |\n|  Anonymous Ukraine | A | 6 (<1) | CyberBerkut | A | 134 (7)  |\n|  Ukrainian Cyber Forces | A | 1,392 (76) | Cyber Riot Novorossiya | A | 41 (2)  |\n|  Ukrainian governmental units and officials | A/T | 3 (<1)/326 (18) | Green Dragon | A | 1 (<1)  |\n|  Ukrainian army units | T | 1 (<1) | Quedagh | A | 1 (<1)  |\n|  Western governments and organizations | T | 15 (1) | Crimean government officials | T | 6 (<1)  |\n|  Western non-state actors | T | 7 (<1) | Russian army units | A/T | 1 (<1)/14 (1)  |\n|  Non-state supporters | T | 91 (5) | Non-state supporters | T | 444 (24)  |\n|   |  |  | Rebel groups | A/T | 2 (<1)/926 (50)  |\n|   |  |  | Russian state units and government officials | A/T | 2 (<1)/14 (1)  |\n|   |  |  | Russian state-sponsored groups | A | 237 (13)  |\n|  Total |  | 1,841 (100) |  |  | 1,841 (100)  |\n|  Syria  |   |   |   |   |   |\n|  Anti-Assad | Actor/target | Frequency (%) | Pro-Assad | Frequency (%) | Actor/target  |\n|  Anonymous/anonymous-sponsored units | A | 93 (14) | ISIL/ISIL-sponsored units | A | 54 (8)  |\n|  Anti-Assad non-state actors | A/T | 297 (44)/18 (3) | Russian government units | A | 3 (<1)  |\n|  Jabhat al-Nusra-sponsored units | A | 1 (<1) | Syrian government units and officials | A/T | 2 (<1)/272 (40)  |\n|  Kurdish non-state opposition | A | 11 (<2) | Syrian state-sponsored units | A/T | 102 (15)/2 (<1)  |\n|  Free Syrian Army | T | 1 (<1) | Pro-Assad non-state actors | T | 179 (26)  |\n|  Pro-ISIL social media and websites | T | 140 (21) |  |  |   |\n|  Total |  | 682 (100) |  |  | 682 (100)  |\nNote: ISIL = The Islamic State of Iraq and the Levant.\nthat potentially serve both purposes. The most common cyber actions in Ukraine have been DDoS-style attacks, followed by hacks of CCTV cameras and other communications. Website blockages have also proven popular, as have spearphishing e-mails targeting specific individuals. Table 2 provides a full breakdown.\nTo reduce false positives due to unconfirmed reports or dubious claims of responsibility, we only include attacks reported by more than one source. To account for uncertainty of attribution, we marked as “disputed” all cases where no one claimed responsibility and labeled as “nondisputed” those operations for which actors directly claimed responsibility in press releases, on social media, or in interviews. To focus on daily dynamics, we excluded activities whose intensity did not vary over time.\nFigure 1a depicts the temporal dynamics of pro-Ukrainian (Cyber U) and pro-Russian rebel (Cyber R) cyber operations. In early March 2014, about a week after the revolution in Kyiv, Figure 1 shows a spike in attacks by CB. The same month saw the establishment of the pro-Kyiv Ukrainian Cyber Forces, partly in response to CB's attacks. However, UCF operations do not become visible until May 2014, following an influx of volunteers to the group. May 2014 is also notable for a rise in activities by another pro-Russian cyber group, Cyber Riot Novorossiya—named after the czarist-era term (“New Russia”) for territories in southeastern Ukraine. After the first Minsk cease-fire agreement in September 2014, operations by pro-Ukrainian hackers converge to a steady rate of two to four per day, with occasional flare-ups, as in December 2014. Activities by pro-Russian hackers, by contrast, declined after the summer 2014.\n### Ukraine Violent Events Data\nOur data on kinetic operations include 26,289 violent events from Ukraine's Donbas region, recorded between February 28, 2014, and February 29, 2016. To offset reporting biases in any one source, while guarding against potential disruptions in media coverage due to cyber attacks, these data draw on seventeen Ukrainian, Russian, rebel, and international sources. As before, we include only events that appeared in more than one source.\nTo extract information on dates, locations, participants, and other event details, we relied on a combination of supervised machine learning (Support Vector Machine) and dictionary-based coding. The Online Appendix describes our measurement strategy and provides summary statistics.\nFigure 1b shows the temporal distribution of pro-Ukrainian (Kinetic U) and pro-Russian rebel (Kinetic R) physical violence. The plot shows several notable flare-ups of fighting—during a government offensive in late June 2014 and a rebel offensive in January 2015—as well as lulls following cease-fire agreements in September 2014, February 2015, and September 2015. Compared to the cyber operations in Figure 1, this plot reveals a clear correlation between kinetic operations\nTable 2. Types of Cyber Operations (Ukraine and Syria).\n|  Propaganda | Ukraine (%) | Syria (%) | Disruption | Ukraine (%) | Syria (%) | Both | Ukraine (%) | Syria (%)  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  PPI—publishing online private information of the members of the conflicting parties | 47 (2) | 59 (9) | AVG— audio-, video-, and geo-intelligence collection | 423 (23) | 1 (<1) | WDT—website defacement | 51 (3) | 389 (57)  |\n|  PRM/PUM—posting pro-rebel and pro-Ukrainian messages online | 54 (3)/5 (<1) | — | CPI—collecting private information via open sources | 13 (<1) | 10 (<2) |  |  |   |\n|  UWP—updating online pages | 6 (<1) | — | DDoS—distributed denial-of-service attack | 499 (27) | 78 (11) |  |  |   |\n|   |   |   |  ODS—other attacks with a purpose of disruption or espionage | 9 (1) | 10 (<2) |  |  |   |\n|   |   |   |  SPE—spear-phishing e-mail | 234 (13) | 17 (2.5) |  |  |   |\n|   |   |   |  STM—sending massive text messages or calling phones non-stop | 40 (2) | 1 (<1) |  |  |   |\n|   |   |   |  WBG—website blockage | 257 (14) | 376 (55) |  |  |   |\n|  Total | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100)  |\n|   |   |   |  |   |   |   |   |   |\nJournal of Conflict Resolution 63(2)\n(a) cyber\n(b) kinetic\nFigure 1. Cyber and kinetic operations in Ukraine (March 2014–February 2016). U (blue) indicates operations by Ukrainian government forces; R (red) indicates operations by pro-Russian rebel groups.\nby the two sides, with government and rebel attacks rising and falling in tandem. $^{15}$  Although this interdependence is not surprising, the data suggest that—with few exceptions—physical violence in Ukraine has been a reciprocal affair.\nFrom a brief glance at the timing of cyber and physical operations (Figure 1a and b), there are relatively few signs of a compelling effect—changes in the former do not appear to drive changes in the latter. However, a visual comparison can be misleading. Some of the variation may be due to fighting on the ground or in cyberspace, but other changes may reflect secular trends or shocks due to elections and other events not directly related to conflict. To account for these potential confounding factors and to gauge whether there is a stronger cyber-kinetic relationship than we would expect by chance, we conduct a series of more rigorous tests.\nEmpirical Strategy\nTo evaluate the relationship between cyber and kinetic operations in Ukraine, we estimate a series of vector autoregressive models\n$Y_{t} = \\sum\\limits_{j}^{p}B_{j}Y_{t - j} + GX_{t} + \\mu_{0} + \\mu_{1}t + \\mathbf{\\epsilon_{t}},$ (1)\nwhere $Y_{t} = \\left[y_{t}^{\\text{Kinetic(U)}}, y_{t}^{\\text{Kinetic(R)}}, y_{t}^{\\text{Cyber(U)}}, y_{t}^{\\text{Cyber(R)}}\\right]^{\\prime}$ is a matrix of endogenous variables, and $X_{t} = \\left[x_{1t},\\ldots,x_{kt}\\right]^{\\prime}$ is a matrix of k exogenous variables, which includes indicators for key dates and events during the war, like presidential and parliamentary electoral campaigns in Ukraine and breakaway territories; cease-fire agreements; and Ukrainian, Russian, and Soviet holidays. Deterministic components include a constant term (μ_{0}) and trend (μ_{1}t). p is the lag order, selected via Bayesian information criterion, and $\\mathbf{\\epsilon_{t}}$ is a vector of serially uncorrelated errors.\nWe control for Ukrainian, Russian, and Soviet holidays because anecdotal accounts suggest significant increases in cyber activity during such times. The UCF, for instance, had an operation called “Happy New Year,” which sought to print pro-Ukrainian messages from hacked printers in Crimea, Russia, and Donbas. National election campaigns represent another time when such activities may spike. Before and during the presidential elections, for instance, hackers bombarded Ukraine's Central Electoral Committee website with DDoS attacks. Finally, we may expect cease-fire agreements aimed at reducing physical violence to also have an effect in the cyber domain. For example, the cyber espionage operation “Armageddon”—directed against Ukrainian government websites—intensified before the Minsk I agreement went into force but then rapidly declined.\nBecause we are interested in the relationship between cyber attacks and physical violence during war, we limit our primary analysis to the active phase of military operations between May 11, 2014, and February 15, 2015—the period following independence referendums organized by the self-proclaimed Donetsk and Luhansk People's Republics and the second Minsk cease-fire agreement. In the Online Appendix, we present additional analyses of the full data set, which produced similar results.\n## Results\nData from Ukraine support the skeptical view of cyber coercion. The impulse--response curves in Figure 2 show a strong, escalatory dynamic between kinetic operations by the two sides (Kinetic U, Kinetic R), but no tangible links in either direction between kinetic and cyber operations, and no reciprocity between cyber actions (Cyber U, Cyber R).\nFollowing a standard deviation increase in kinetic rebel attacks, government violence sees a delayed rise, peaking around two days after the shock and gradually\n|  Response: |   |\n| --- | --- |\n|  Kinetic (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  |\n|  Kinetic (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  |\n|  Cyber (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  |\n|  Cyber (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  |\nFigure 2. Impulse response matrix, daily time series (Ukraine). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"U\" indicates reported kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\ndeclining back to zero (top row, second column). Rebel operations also rise after shocks to government operations (second row, first column), but the response here is immediate, without the delay we observe in government operations. This pattern may reflect command and control inefficiencies in the Ukrainian army, particularly early in the conflict, when indecision and leadership turnover lengthened decision cycles.\nThe relationship between cyber and kinetic operations is far weaker than that between rebel and government violence on the ground. Cyber attacks by pro-Ukrainian forces see no increase after shocks in kinetic government operations, and a positive, but uncertain increase after shocks in kinetic rebel operations (third row, first and second columns).\nThere is even less evidence that cyber attacks drive kinetic operations. The impulse--response function (IRF) curve for pro-Ukrainian government violence is, in fact, negative after shocks to rebel cyber operations (top row, two rightmost columns). Although this negative response might otherwise suggest that cyber attacks compel a decline in violence—consistent with coercive success—the estimate is also highly uncertain. Following shocks to pro-Ukrainian cyber activities, meanwhile, the main change in rebel kinetic operations is a short-term increase in volatility (second row, third column). In sum, the data suggest that cyber attacks may make violence less predictable but do not systematically change its intensity.\nPerhaps most surprisingly, there is little or no apparent strategic interaction between “cyber-warriors” on each side of the conflict. A shock in pro-Ukrainian cyber attacks yields no discernible change in pro-rebel cyber attacks (bottom row, third column) and vice versa (third row, fourth column). The two cyber campaigns, the data suggest, have unfolded independently of each other and independently of events on the ground.\nAs the diagonal elements in Figure 2 suggest, there is strong autocorrelation in each series. For each of the four categories, past shocks in operations yield a significant spike in subsequent operations. To evaluate whether the other categories of events can help us predict future values of each series, after we take this autocorrelation into account, Table 3 reports the results of Granger causality tests. The tests confirm that past levels of prorebel and pro-Kyiv kinetic operations help predict each other's future values. Kinetic operations, however, do not appear to “Granger cause”—or be “Granger caused” by—cyber attacks on either side.\nTable 4 reports the forecasting error variance decomposition, representing the proportion of variation in each series (rows) due to shocks in each endogenous variable (columns). For most variables, their own time-series account for almost all variation at the outset, but this dependency gradually decreases. As before, there is far more dependence within kinetic operations than between kinetic and cyber or within cyber actions. By the thirty-day point in the daily time series, shocks in rebel attacks account for 7 percent of variation in Ukrainian government operations, while shocks in government operations explain 12 percent of variation in rebel violence.\nJournal of Conflict Resolution 63(2)\nTable 3. Granger Causality Test, Daily Time Series (Ukraine).\n|  Effects | F statistic | p value  |\n| --- | --- | --- |\n|  Kinetic (R) → Kinetic (U) | 40.26 | .00  |\n|  Cyber (U) → Kinetic (U) | 0.50 | .48  |\n|  Cyber (R) → Kinetic (U) | 0.09 | .76  |\n|  Kinetic (U) → Kinetic (R) | 12.29 | .00  |\n|  Cyber (U) → Kinetic (R) | 1.44 | .23  |\n|  Cyber (R) → Kinetic (R) | 2.70 | .10  |\n|  Kinetic (U) → Cyber (U) | 1.40 | .24  |\n|  Kinetic (R) → Cyber (U) | 1.88 | .17  |\n|  Cyber (R) → Cyber (U) | 0.00 | .95  |\n|  Kinetic (U) → Cyber (R) | 1.74 | .19  |\n|  Kinetic (R) → Cyber (R) | 0.14 | .71  |\n|  Cyber (U) → Cyber (R) | 0.89 | .35  |\nNote: \"U\" indicates reported kinetic and cyber operations by Pro-Ukrainian government forces, and \"R\" indicates operations by Pro-Russian rebel forces.\nTable 4. Variance Decomposition, Daily Time Series (Ukraine).\n|  Operation type | Kinetic (U) | Kinetic (R) | Cyber (U) | Cyber (R)  |\n| --- | --- | --- | --- | --- |\n|  Kinetic (U) |  |  |  |   |\n|  1 Day | 1.000 | .000 | .000 | .000  |\n|  2 Days | 0.920 | .060 | .002 | .018  |\n|  7 Days | 0.906 | .071 | .002 | .020  |\n|  30 Days | 0.906 | .071 | .002 | .020  |\n|  Kinetic (R) |  |  |  |   |\n|  1 Day | 0.108 | .892 | .000 | .000  |\n|  2 Days | 0.121 | .873 | .000 | .006  |\n|  7 Days | 0.122 | .870 | .000 | .008  |\n|  30 Days | 0.122 | .870 | .000 | .008  |\n|  Cyber (U) |  |  |  |   |\n|  1 Day | 0.000 | .002 | .998 | .000  |\n|  2 Days | 0.000 | .002 | .997 | .000  |\n|  7 Days | 0.000 | .003 | .997 | .000  |\n|  30 Days | 0.000 | .003 | .997 | .000  |\n|  Cyber (R) |  |  |  |   |\n|  1 Day | 0.012 | .023 | .000 | .964  |\n|  2 Days | 0.014 | .023 | .001 | .962  |\n|  7 Days | 0.015 | .023 | .001 | .961  |\n|  30 Days | 0.015 | .023 | .001 | .961  |\nNote: \"U\" indicates kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\nBy contrast, shocks to cyber activities account for very little variation in kinetic operations. The highest value is for pro-Russian rebel cyber activities, which account for 2 percent of short-term variation in government violence. Cyber attacks by each side also have a relatively small impact on each other. Indeed, rebel kinetic operations explain more of the variation in cyber attacks by each actor than do cyber attacks by the other side.\nIn sum, our analysis suggests that low-level cyber attacks in Ukraine have had no effect on the timing of physical violence. Not only is there no evidence that cyber attacks have compelled opponents to de-escalate fighting, there is no discernible reciprocity between the cyber actors themselves. Each group of hackers seems to operate in its own bubble, disengaged from unfolding events in both cyberspace and the physical world.\n### Robustness Checks\nTo gauge the sensitivity of our results to various modeling and measurement choices, we conducted extensive robustness checks. We summarize their results briefly here (Table 5) and more fully in the Online Appendix.\nThe first set of tests considers vector autoregression models with alternative orderings of the four endogenous variables, which affects estimation of impulse responses. We find no substantive differences across the twenty-four permutations.\nIn a second set of robustness checks, we account for systematic differences in the kinds of conflict events that Ukrainian and Russian media report, which may bias statistical estimates—for example, by underreporting violence by a given actor. Using kinetic data from exclusively Russian or exclusively Ukrainian sources does not change the results.\nA third set of robustness tests examines different subsets of cyber attacks. Because purely disruptive activities may impose greater immediate costs than quasi-propagandistic hybrid attacks, pooling these events may dilute their coercive effect. Our results are consistent for all three subsets.\nThe last set of robustness checks examines different time periods of the conflict, since some cyber attacks predated military activity. In particular, we compare the period of intense fighting previously analyzed (May 11, 2014--February 15, 2015) to the entire date range for which we have data (February 28, 2014--February 29, 2016). Our results remain unchanged.\n## Evidence from Interviews\nIn interviews, Russian and Ukrainian cyber security experts highlighted five potential explanations for the apparent failure of cyber coercion in Ukraine: (1) lack of resources, (2) lack of coordination, (3) lack of targets, (4) lack of audience, and (5) lack of effort.\nTable 5. Robustness Checks (Ukraine and Syria).\n|  Ukraine (main results; May 11, 2014–February 15, 2015)  |   |   |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n|  I | Disruption and both | Kin(R) ↔ Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) ↔ Kin(R) | Kin(U) ↔ Kin(R) | Kin(U) → Kin(G)  |\n|  ID | Cyber | GCT(w) | VD(d) (30 day) | VD(w) (12 week) |  |  |   |\n|  I | Disruption and both |  | Kin(R) → 7%Kin(U) | Kin(R) → 10%Cyb(R) |  |  |   |\n|   |   |   | Kin(R) → 2%Cyb(R) | Kin(U) → 21%Kin(R) |  |  |   |\n|   |   |   | Kin(U) → 12%Kin(R) | Kin(U) → 17%Cyb(R) |  |  |   |\n|   |   |   | Kin(U) → 2%Cyb(R) | Cyb(U) → 4%Cyb(R) |  |  |   |\n|  ID | Cyber | IRF(d) | IRF(w) | GCT(d) | GCT(w) | VD(d) (30 day) | VD(w) (12 week)  |\n|  Ukraine (March 22, 2014–February 29, 16)  |   |   |   |   |   |   |   |\n|  2 | All | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U/R) ↔ Kin(U) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Cyb(U) ↔ Kin(R) |  |  | Kin(U) → 3%Cyb(R)  |\n|  3 | Propaganda | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin(U)/Cyb(R) | Kin(R) → 3%Kin(U) | Kin(R) → 9%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) → Kin/Cyb(R) | Kin(U) → Cyb(R) | Kin(U) → 18%Kin(R) | Kin(R) → 3%Cyb(R)  |\n|   |   |   | Cyb(U) → Kin(U) | Kin(U) → Cyb(R) |  |  | Kin(U) → 46%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(R)  |\n|  4 | Disruption | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(U/R) |  | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|  5 | Disruption and both | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(R) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Kin(U) → Cyb(U) |  |  |   |\n(continued)\nTable 5. (continued)\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) Ukraine (May 11, 2014-February 11, 2015) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  6 | All | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) |  | Kin(R) → 7%Kin(U) | Kin(R) → 2%Cyb(U)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(U) → 13%Kin(R) | Kin(R) → 18%Cyb(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 30%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(U/R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 4%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(U)  |\n|  7 | Propaganda | Kin(R) → Kin(U) | Cyb(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Cyb(R) | Kin(R) → 7%Kin(U) | Kin(U) → 27%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) |  |  | Kin(U) → 13%Kin(R) | Kin(U) → 4%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 3%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 9%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 20%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 5%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(R) → 2%Cyb(U)  |\n|  8 | Disruption | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → Cyb(U) | Kin(R) → 7%Kin(U) | Kin(U) → 29%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(R) → 2%Cyb(R) | Kin(U) → 34%Cyb(U)  |\n|   |   |   |  |  |  | Kin(U) → 12%Kin(R) | Kin(U) → 22%Cyb(R)  |\n|   |   |   |  |  |  | Cyb(R) → 2%Kin(U) | Kin(R) → 3%Kin(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 10%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 13%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 6%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 7%Cyb(U)  |\nSyria (March 17, 2011-July 10, 2016)\n|  9 | Disruption and both | Kin(G) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → 2%Kin(R)  |\n| --- | --- | --- | --- | --- |\nNote: IRF = impulse response functions; GCT = Granger causality tests; VD = variance decomposition; d = daily; w = weekly; o = alternative orderings; RU = Russian; U = Ukrainian.\nThe first explanation for coercive failure emphasizes limited resources and capabilities, particularly for the Ukrainian government. Ten years ago, the SBU briefly had a cyber department but shut it down after a year (Kostyuk and Zhukov 2017, #3). This unit has recently reopened but continues to lack funding and personnel (Kostyuk and Zhukov 2017, #3, #9). It is possible that, with adequate resources, capabilities, and human capital, the Ukrainian cyber campaign might have been more effective. Resource constraints, however, do not explain coercive failure on the pro-Russian side, where investment in cyber capabilities is more robust.\nA second explanation is lack of government coordination with hackers, especially in Kyiv (Maurer and Geers 2015). UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success (Kostyuk and Zhukov 2017, #1). The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place (Kostyuk and Zhukov 2017, #1, #3, #9). Yet again, this explanation is less plausible on the pro-Russian side, where the Kremlin has cultivated extensive ties with non-state hacktivists.\nA third explanation is that—even with requisite capabilities and coordination—there are few opportune targets for disruption in Ukraine. Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult (Geers 2015; Kostyuk and Zhukov 2017, #3, #13). Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack” (Kostyuk and Zhukov 2017, #11). The 2015 and 2016 hacks of Ukraine's power grid also seem to challenge this explanation.\nThe peculiarities of Ukraine's online population represent a fourth explanation for the indecisiveness of cyber attacks. Since only 44.1 percent of Ukrainians have Internet access—compared to 88.5 percent in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses (Kostyuk and Zhukov 2017, #3). Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones (Kostyuk and Zhukov 2017, #7, #11). Our data suggest that, even if this were the case, propagandistic attacks still had no effect on violence.\nThe final explanation is that cyber compellence failed because it was never seriously attempted. At first, our interviews with individual hackers revealed no shortage of coercive intent. UCF leader Eugene Dokukin claimed to conduct low-level attacks daily and vowed to continue until pro-Russian rebels lay down their arms. Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns (Kostyuk and Zhukov 2017, #1).\nWhile UCF and other nonstate groups have explicitly sought to affect battlefield outcomes, some interviewees questioned whether this intent extended to the Russian\ngovernment. Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place (Kostyuk and Zhukov 2017, #5, #12). This access, along with vigorous cyber espionage—some of it ongoing since 2010—may create incentives against more aggressive actions, which could compromise valuable sources of intelligence.\nConsistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda (Kostyuk and Zhukov 2017, #11). When in 2011 Vyacheslav Volodin replaced Vladislav Surkov as head of the Presidential Administration, he toughened existing laws against Russia's opposition and promoted the use of mass media and online platforms—tools already mostly under state control—to conduct information campaigns. If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising (Kostyuk and Zhukov 2017, #2, #14).\n## Evidence beyond Ukraine: Syria's Digital Front\nAccording to evidence from microlevel data and interviews, cyber attacks did not affect battlefield events in Ukraine. During one of the first armed conflicts where both sides used low-level cyber actions extensively, events in the digital realm have unfolded independently of—and have had no discernible effect on—events on the ground. Conditions in Ukraine were in many ways optimal to observe the coercive impact of cyber actions, for reasons we already discussed (i.e. visibility of major attacks, regular claims of responsibility, less uncertainty over attribution). Yet we found no evidence that low-level cyber attacks affected physical violence. Nor did hackers on each side even affect each other's activities.\nWhile important, Ukraine is not the only contemporary conflict with a significant cyber dimension. In Syria, state and nonstate actors have employed low-level cyber actions extensively for propaganda and disruption, complementing traditional tools of warfare in the deadliest conflict ongoing today. Syria's war has also lasted three years longer than Ukraine's. Over this time, its digital front has expanded in scope and sophistication, offering a glimpse of cyber coercion in a more protracted setting.\nAn in-depth study of Syria's digital front lies beyond the scope of this article. A brief analysis of the data, however, suggests that our findings from Ukraine may be part of a broader pattern: cyber capabilities have not yet evolved to the point of having an impact on physical violence.\nTo evaluate the effectiveness of cyber compellence in this second case, we replicated the model in (equation 1), using an analogous daily time series of cyber attacks and violent events in Syria. Our data comprise 9,282 kinetic and 682 low-level cyber attacks ranging from March 2011 until July 2016. Table 2 provides a breakdown of cyber techniques used in the Syrian conflict, their brief description, and frequency. Our data on kinetic operations rely on human-assisted machine\nJournal of Conflict Resolution 63(2)\nFigure 3. Cyber and kinetic operations in Syria (March 2011-July 2016). G (blue) indicates operations by pro-Assad government forces; R (red) indicates operations by anti-Assad rebel groups.\ncoding of event reports from the International Institute for Strategic Studies Armed Conflict Database (see Online Appendix for details).\nGiven the complex nature of the Syrian conflict and the multiple parties involved, we restrict our analysis only to operations by progovernment forces (i.e., Syrian Army, Hezbollah and pro-Assad militias) and the main rebel opposition (i.e., Free Syrian Army, Jaish al-Fatah, including Al Nusra Front). Table 1 provides a list of cyber actors in the Syrian conflict, their targets, and frequency of their activities.\nThe dynamics of cyber and kinetic operations in Syria exhibit similar patterns to what we saw in Ukraine. Raw data (Figure 3a and b) suggest relatively little overlap in timing, especially at the beginning of the conflict. The IRF curves in Figure 4 show a rise in rebel operations following shocks to government operations (second row, first column), and mostly negligible (though negative) links between cyber and kinetic operations, and across cyber attacks by each actor. Links between kinetic\n|  Response: |   |\n| --- | --- |\n|  Kinetic (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380 385 390 395  |\n|  Kinetic (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295  |\n|  Cyber (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 260 270 275  |\n|  Cyber (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230  |\n|  Impulse: | Kinetic (G) Kinetic (R) Cyber (G) Cyber (R)  |\nFigure 4. Impulse response matrix, daily time series (Syria). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"G\" indicates reported kinetic and cyber operations by pro-Assad government forces, and \"R\" indicates operations by anti-Assad rebel forces.\noperations—and their disconnect from cyber attacks—are also evident in variance decomposition results, and Granger tests, provided in the Online Appendix.\nThere are several reasons for caution in interpreting these results. The Syrian conflict involves a larger constellation of actors than Ukraine, and our dyadic analysis may overlook significant interactions elsewhere, particularly between actors with more developed cyber capabilities (e.g. Russia, United States). We also lack interview evidence that might help contextualize the null effect. However tentative, these results do align with what we saw in Ukraine: low-level cyber attacks have had little or no impact on violence.\n## Conclusion\nThe evidence we presented in this article—based on analysis of new data and expert interviews—suggests that cyber attacks are ineffective as a tool of coercion in war. Although kinetic operations explain the timing of other kinetic operations, low-level cyber attacks have no discernible effect on violence in the physical world. In Ukraine and Syria, the “cyberwar” has unfolded in isolation from the rest of the conflict.\nThis finding has several implications for theory and policy. First, by providing the first statistical analysis of modern low-level cyber campaigns, our study complements the qualitative focus of previous empirical work. Second, our research sheds light on a theoretical question about the strength and direction of the cyber--kinetic relationship and—in so doing—begins to fill an empirical gap in political science literature on this topic. Third, to the extent that policymakers might overestimate the importance of cyber actions due to a lack of empirical evidence to the contrary, our findings can potentially help correct this misperception. Finally, and more worryingly, our results suggest that—due to their disconnect from physical violence—low-level cyber attacks are very difficult to predict.\nFurther research is needed to understand the dynamics of low-level cyber attacks. One such area of research is cyber coercion in the context of symmetric, conventional war. While our study helps illuminate dynamics of cyber compellence between parties with asymmetric capabilities, we may well observe different patterns when major powers use cyberspace against peer competitors. Thankfully, no armed conflict has yet provided researchers with the data needed to evaluate this possibility.\nSecond, our scope in this article has been exclusively on short-term military consequences rather than long-term political effects. The latter are no less theoretically significant, but—unlike simple counts of violent events—potentially more difficult to measure and analyze. A study of long-term political effects would also need to more systematically incorporate purely propagandistic cyber activities and their impact on public opinion, which we omitted here due to our focus on short-term military compellence.\nAlthough the secretive nature of many ongoing physical and digital operations is a challenge for this research, questions over the coercive potential of cyber attacks\nwill become only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” (Sabah 2016)—have yielded few tangible successes (Sanger and Schmitt 2017). Our data from Ukraine indicate that the US experience may be part of a broader pattern.\nAt best, coordination between low-level cyber and kinetic operations today is on roughly the same level as that between airpower and ground operations in World War I. Back then, armies were increasingly using aircraft for reconnaissance and surveillance on the front but were not yet able to fully exploit their potential for ground combat support and strategic bombing. That revolution appeared on the battlefield twenty-five years later, with devastating effect. As cyber capabilities develop and synchronization challenges become less severe, there will be a growing need for assessments of how far we have come. We hope that analyses of the sort we provided in these pages can serve as an early benchmark.\n## Authors' Note\nA previous version of this article was presented at the 2015 Peace Science Society International annual meeting, Oxford, MS, and at the Association for the Study of Nationalities Convention at New York, NY.\nWe are grateful to Maura Drabik, Paulina Knoblock, Neil Schwartz, and Alyssa Wallace for excellent research assistance. Robert Axelrod, Myriam Dunn-Cavelty, Eric Gartzke, Miguel Gomez, Todd Lehmann, Jon Lindsay, Tim Maurer, Brandon Valeriano, Christopher Whyte, and workshop participants of the Conflict & Peace, Research & Development workshop at the University of Michigan, of the Bridging the Gap Workshop on Cyber Conflict at Columbia University, of the Cross-Domain Deterrence lab at the University of California, San Diego, and of the Center for Security Studies at ETH Zurich provided helpful comments on the earlier drafts of this article.\n## Declaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n## Funding\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.\n## Supplemental Material\nSupplemental material for this article is available online."
    },
    "author_year": {
      "total": {
        "intext_total": 41,
        "success_occurrences": 39,
        "success_unique": 22,
        "bib_unique_total": 82,
        "occurrence_match_rate": 0.9512195121951219,
        "bib_coverage_rate": 0.2682926829268293,
        "success_percentage": 95.12,
        "style": "author_year"
      },
      "results": [
        {
          "index": "libicki|2009",
          "intext_citation": "(Libicki 2009; Sharma 2010; Andres 2012)",
          "preceding_text": "Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence",
          "footnote": "Libicki, Martin C. 2009. Cyberdeterrence and Cyberwar. Santa Monica, CA: Rand Corporation."
        },
        {
          "index": "valeriano|2014",
          "intext_citation": "(Valeriano and Maness 2014)",
          "preceding_text": "Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist",
          "footnote": "Valeriano, Brandon, and Ryan C. Maness. 2014. \"The Dynamics of Cyber Conflict between Rival Antagonists, 2001-11.\" *Journal of Peace Research* 51 (3): 347-60."
        },
        {
          "index": "geers|2015",
          "intext_citation": "(Geers 2015)",
          "preceding_text": "We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides",
          "footnote": "Geers, Kenneth. 2015. Cyber War in Perspective: Russian Aggression against Ukraine. Tallinn, Estonia: CCDCOE."
        },
        {
          "index": "zetter|2017",
          "intext_citation": "(Zetter 2017)",
          "preceding_text": "Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques”",
          "footnote": "Zetter, Kim. 2017. \"The Ukrainian Power Grid Was Hacked Again.\" *Motherboard*. Accessed June 15, 2017. http://bit.ly/2jEUqW3."
        },
        {
          "index": "ilchenko|2016",
          "intext_citation": "(Il'chenko 2016)",
          "preceding_text": "Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations",
          "footnote": "Il'chenko, Oleksandr. 2016. \"Rozstily Oleha Kalashnikova i Olesya Buzyny - rik potomu [Shootings of Oleg Kalashnikov of Oles Buzina—a year later].\" Segodnya."
        },
        {
          "index": "pape|2003",
          "intext_citation": "(Pape 2003, 2014)",
          "preceding_text": "The role of cyber compellence in wartime is not unlike that of airpower or terrorism",
          "footnote": "Pape, Robert A. 2003. \"The Strategic Logic of Suicide Terrorism.\" American Political Science Review 97 (03): 343-61."
        },
        {
          "index": "ottis|2010",
          "intext_citation": "(Ottis 2010)",
          "preceding_text": "Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties",
          "footnote": "Ottis, Rain. 2010. \"From Pitch Forks to Laptops: Volunteers in Cyber Conflicts.\" In Conference on Cyber Conflict Proceedings 2010, edited by C. Czosseck and K. Podins, 97-109. Tallinn, Estonia: CCD COE."
        },
        {
          "index": "schmitt|1999",
          "intext_citation": "(Schmitt 1999; Rios 2009; Clarke and Knake 2010; McGraw 2013; Eun and Aßmann 2014)",
          "preceding_text": "Despite the apparent promise of these “weapons of the future”",
          "footnote": "Schmitt, Michael N. 1999. \"Computer Network Attack and the Use of Force in International Law: Thoughts on a Normative Framework.\" *Columbia Journal of Transnational Law* 37: 1998-99."
        },
        {
          "index": "liff|2012",
          "intext_citation": "(Liff 2012; Rid 2012; Gartzke 2013; Junio 2013)",
          "preceding_text": "Despite the apparent promise of these “weapons of the future” (Schmitt 1999; Rios 2009; Clarke and Knake 2010; McGraw 2013; Eun and Aßmann 2014), some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion",
          "footnote": "Liff, Adam P. 2012. \"Cyberwar: A New 'Absolute Weapon'? The Proliferation of Cyberwarfare Capabilities and Interstate War.\" Journal of Strategic Studies 35 (3): 401-28."
        },
        {
          "index": "schelling|1966",
          "intext_citation": "(Schelling 1966)",
          "preceding_text": "Yet successful coercion also requires punishment to be both anticipated and avoidable",
          "footnote": "Schelling, Thomas C. 1966. Arms and Influence. New Haven, CT: Yale."
        },
        {
          "index": "axelrod|2014",
          "intext_citation": "(Axelrod and Iliev 2014)",
          "preceding_text": "Cyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities",
          "footnote": "Axelrod, Robert. 2014. “A Repertory of Cyber Analogies.” In Cyber Analogies, edited by Emily O. Goldman and John Arquilla. Monterey, CA: Department of Defense Information Operations Center for Research."
        },
        {
          "index": "axelrod|2014",
          "intext_citation": "(Axelrod and Iliev 2014)",
          "preceding_text": "exploited vulnerabilities, even successful attacks cause only temporary disruption",
          "footnote": "Axelrod, Robert. 2014. “A Repertory of Cyber Analogies.” In Cyber Analogies, edited by Emily O. Goldman and John Arquilla. Monterey, CA: Department of Defense Information Operations Center for Research."
        },
        {
          "index": "hare|2012",
          "intext_citation": "(Hare 2012; Lynn 2010; Nye 2010)",
          "preceding_text": "As a result, targets may see compliance as insufficient and unnecessary to stop the damage",
          "footnote": "Hare, Forrest. 2012. \"The Significance of Attribution to Cyberspace Coercion: A Political Perspective.\" In 2012 4th International Conference on Cyber Conflict (CYCON 2012, edited by C. Czosseck, R. Ottis, and K. Ziolkowski, 1-15. Tallinn, Estonia: NATO CCD COE"
        },
        {
          "index": "atran|2003",
          "intext_citation": "(Atran 2003; Pape 2003, 2014)",
          "preceding_text": "Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower",
          "footnote": "Atran, Scott. 2003. “Genesis of Suicide Terrorism.” Science 299 (5612): 1534-39."
        },
        {
          "index": "cha|2000",
          "intext_citation": "(Cha 2000; Griniaiev 2004; Libicki 2007, 2011; Czosseck and Geers 2009; Clarke and Knake 2010; Axelrod and Iliev 2014)",
          "preceding_text": "Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare",
          "footnote": "Cha, Victor D. 2000. “Globalization and the Study of International Security.” Journal of Peace Research 37 (3): 391-403."
        },
        {
          "index": "healey|2013",
          "intext_citation": "(Healey 2013; Kello 2013; Libicki 2015; Andress and Winterfeld 2013; Axelrod 2014)",
          "preceding_text": "ybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare (Cha 2000; Griniaiev 2004; Libicki 2007, 2011; Czosseck and Geers 2009; Clarke and Knake 2010; Axelrod and Iliev 2014), the overlap between cyber and kinetic capabilities",
          "footnote": "Healey, Jason. 2013. A Fierce Domain: Conflict in Cyberspace, 1986 to 2012. Arlington, VA: Cyber Conflict Studies Association."
        },
        {
          "index": "martin-shields|2013",
          "intext_citation": "(Martin-Shields 2013; Pierskalla and Hollenbach 2013; Crabtree, Darmofal, and Kern 2014; Gohdes 2014; Bailard 2015)",
          "preceding_text": "2009; Clarke and Knake 2010; Axelrod and Iliev 2014), the overlap between cyber and kinetic capabilities (Healey 2013; Kello 2013; Libicki 2015; Andress and Winterfeld 2013; Axelrod 2014), and the effect of information and communication technology on conflict",
          "footnote": "Martin-Shields, Charles Patrick. 2013. \"Inter-ethnic Cooperation Revisited: Why Mobile Phones can Help Prevent Discrete Events of Violence, Using the Kenyan Case Study.\" Stability: International Journal of Security and Development 2 (3): Art. 58."
        },
        {
          "index": "valeriano|2014",
          "intext_citation": "(Valeriano and Maness 2014)",
          "preceding_text": "Some large-n analyses do exist",
          "footnote": "Valeriano, Brandon, and Ryan C. Maness. 2014. \"The Dynamics of Cyber Conflict between Rival Antagonists, 2001-11.\" *Journal of Peace Research* 51 (3): 347-60."
        },
        {
          "index": "weidmann|2015",
          "intext_citation": "(Weidmann 2015)",
          "preceding_text": "ity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action",
          "footnote": "Weidmann, Nils B. 2015. \"Communication, Technology, and Political Conflict Introduction to the Special Issue.\" *Journal of Peace Research* 52 (3): 263-68."
        },
        {
          "index": "baum|2015",
          "intext_citation": "(Baum and Zhukov 2015; Davenport and Stam 2006; Woolley 2000)",
          "preceding_text": "In assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets",
          "footnote": "Baum, Matthew A. and Yuri M. Zhukov. 2015. “Filtering Revolution: Reporting Bias in International Newspaper Coverage of the Libyan Civil War.” Journal of Peace Research 9:10-11."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017)",
          "preceding_text": "We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, # 1)",
          "preceding_text": "p in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, # 12)",
          "preceding_text": "One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #7 & #8)",
          "preceding_text": "Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "2014february|2016",
          "intext_citation": "(March 2014–February 2016)",
          "preceding_text": "Cyber and kinetic operations in Ukraine",
          "footnote": null
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #3)",
          "preceding_text": "Ten years ago, the SBU briefly had a cyber department but shut it down after a year",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #3, #9)",
          "preceding_text": "Ten years ago, the SBU briefly had a cyber department but shut it down after a year (Kostyuk and Zhukov 2017, #3). This unit has recently reopened but continues to lack funding and personnel",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "maurer|2015",
          "intext_citation": "(Maurer and Geers 2015)",
          "preceding_text": "A second explanation is lack of government coordination with hackers, especially in Kyiv",
          "footnote": "Maurer, Tim, and Kenneth Geers. 2015. \"Cyber Proxies and the Crisis in Ukraine.\" In Cyber War in Perspective: Russian Aggression against Ukraine, edited by Kenneth Geers, 79-86. Tallinn, Estonia: NATO Cyber Center of Excellence, NATO CCD COE."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #1)",
          "preceding_text": "UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #1, #3, #9)",
          "preceding_text": "The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "geers|2015",
          "intext_citation": "(Geers 2015; Kostyuk and Zhukov 2017, #3, #13)",
          "preceding_text": "Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult",
          "footnote": "Geers, Kenneth. 2015. Cyber War in Perspective: Russian Aggression against Ukraine. Tallinn, Estonia: CCDCOE."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #11)",
          "preceding_text": "Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack”",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #3)",
          "preceding_text": "nt in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #7, #11)",
          "preceding_text": "Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #1)",
          "preceding_text": "Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #5, #12)",
          "preceding_text": "Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #11)",
          "preceding_text": "Consistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "kostyuk|2017",
          "intext_citation": "(Kostyuk and Zhukov 2017, #2, #14)",
          "preceding_text": "If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising",
          "footnote": "Kostyuk, Nadiya, and Yuri Zhukov. 2017. \"Online Appendix B: Interviews on Cyber and Information Warfare in Ukraine.\" *Journal of Conflict Resolution*."
        },
        {
          "index": "2011-july|2016",
          "intext_citation": "(March 2011-July 2016)",
          "preceding_text": "Cyber and kinetic operations in Syria",
          "footnote": null
        },
        {
          "index": "sabah|2016",
          "intext_citation": "(Sabah 2016)",
          "preceding_text": "In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection”",
          "footnote": "Sabah, Daily. 2016. \"Cyber Bombs Being Used to Destroy Daesh: US Defense Chief.\" February 29, 2016. Accessed March 15, 2017. https://www.dailysabah.com/mideast/2016/02/29/cyber-bombs-being-used-to-destroy-daesh-us-defense-chief."
        },
        {
          "index": "sanger|2017",
          "intext_citation": "(Sanger and Schmitt 2017)",
          "preceding_text": "ome only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” (Sabah 2016)—have yielded few tangible successes",
          "footnote": "Sanger, David E. 2016. \"U.S. Cyberattacks Target ISIS in a New Line of Combat.\" The New York Times. Accessed March 15, 2017. https://www.nytimes.com/2016/04/25/us/politics/us-directs-cyberweapons-at-isis-for-first-time.html?_r=0."
        }
      ],
      "flat_text": "Check for updates\nArticle\n# Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?\nJournal of Conflict Resolution\n2019, Vol. 63(2) 317-347\n© The Author(s) 2017\nArticle reuse guidelines:\nsagepub.com/journals-permissions\nDOI: 10.1177/0022002717737138\njournals.sagepub.com/home/jcr\nSAGE\nNadiya Kostyuk¹, and Yuri M. Zhukov¹\n## Abstract\nRecent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.\n## Keywords\ncompellence, coercion, physical violence, conflict, cyber attacks\nOn December 23, 2015, hackers attacked Ukraine’s power grid, disabling control systems used to coordinate remote electrical substations, and leaving people in the capital and western part of the country without power for several hours. The Security\n¹Department of Political Science, University of Michigan, Ann Arbor, MI, USA\n## Corresponding Author:\nNadiya Kostyuk, Department of Political Science, University of Michigan, 505 S State Street, Ann Arbor, MI 48109, USA.\nEmail: nadiya@umich.edu\nService of Ukraine (SBU) blamed the Russian government for the cyber attack, an accusation that later found support in malware analysis by a private computer security firm. The Ukrainian hack was the first publicly acknowledged case of a cyber attack successfully causing a power outage. It is also just one of thousands of cyber activities, mostly diffuse and low level, that have occurred alongside physical fighting in Ukraine. Attacks launched through the digital realm are playing an increasingly visible role in civil and interstate conflict—in Ukraine, Syria, Israel, Estonia, Georgia, and beyond. Yet it remains unknown whether such activities have a real coercive impact on the battlefield.\nRecent years have seen growing concern over the coercive potential of cyber capabilities in war, but little evidence that these new tools are yet making a difference. Theoretically, most research has focused on the consequences of cyber attacks for peacetime deterrence rather than wartime compellence . Yet the logic of coercion entails distinct challenges in peace and war, with potentially different implications for the cyber domain. Empirically, the literature has relied more on qualitative case studies than quantitative data. The few data sets that do exist  privilege massive cyber catastrophes over less sophisticated low-intensity attacks, like distributed denial of service (DDoS). The latter category, however, is far more common.\nThis article asks whether cyber attacks can compel short-term changes in battlefield behavior, using new event data on cyber and kinetic operations from armed conflicts in Ukraine and Syria. We use the Ukrainian conflict as our primary test case due to the extensive and sophisticated use of cyber attacks by both sides , and—uniquely—overt claims of responsibility, public damage assessments, and other releases of information that reduce uncertainty over timing and attribution. Since 2014, Ukraine has turned into “a training playground for research and development of novel attack techniques” . If cyber attacks can yet make a difference on the battlefield, Ukraine is one a few cases where we are most likely to observe such an effect. Our data include 1,841 unique cyber attacks and 26,289 kinetic operations by government and prorebel forces between 2014 and 2016. We supplement this quantitative analysis with fourteen primary source interviews with participants in the cyber campaign as well as Ukrainian, Russian, and Western cyber security experts with direct knowledge of these operations.\nTo evaluate the generalizability of the Ukrainian experience to other conflicts, we replicate our results with data from Syria's civil war. Like Ukraine, Syria has seen the extensive use of low-level cyber attacks by factions fighting for and against the incumbent regime. Because this war has gone on significantly longer than the conflict in Ukraine—giving hackers more time to organize and develop their capabilities—Syria offers a glimpse at cyber activities in a more protracted, higher intensity context. If we uncover similar patterns in two conflicts of such different scale and complexity, we can have greater confidence that our results are not artifacts of a single idiosyncratic case. Our data include 682 cyber attacks and 9,282 acts of violence by pro- and anti-Assad forces between 2011 and 2016.\nEvidence from both conflicts suggests that cyber attacks have not created forms of harm and coercion that visibly affect their targets' actions. Short of mounting synchronized, coordinated cyber campaigns, each group of hackers has seemed to operate in its own “bubble,” disengaged from unfolding events in both cyberspace and the physical world. The lack of discernible reciprocity between cyber and kinetic operations—and between the cyber actors themselves—questions whether cyber attacks can (yet) be successfully deployed in support of military operations.\nThis disconnect may be temporary, as joint planning and execution concepts continue to evolve. Many countries, for instance, still struggle in coordinating air-power for ground combat support, a century after World War I. Our study highlights some of the difficulties that countries will need to overcome in integrating and synchronizing these new capabilities.\nOur contribution is fourfold. We offer the first disaggregated analysis of cyber activities in war and take stock of the empirical relationship between the cyber and kinetic dimensions of modern battle. To do so, we collect the first microlevel data on wartime cyber attacks, using both open media sources and anonymous attack traffic data. Theoretically, our analysis addresses an important question on the coercive impact of low-level cyber attacks, advancing a literature that has been heavy on deductive argumentation, but light on evidence. Finally, from a policy standpoint, our findings should temper the popular tendency to overhype the transformative potential of cyber attacks. At present, interaction between cyber and kinetic operations is similar to that between airpower and ground operations in World War I—when armies began to use aircraft for reconnaissance but had not realized their full potential to shape battlefield outcomes.\n## Varieties of Cyber Activity\nThe term “cyber activities” captures a diverse assortment of tactics and procedures, directed against different types of targets, in pursuit of disparate objectives. Not all of these activities seek to achieve battlefield effects in the same way. Before proceeding further, we differentiate between two broad goals these actions tend to pursue: propaganda and disruption.\nCyber activities in the propaganda category seek to influence public opinion and indirectly undermine an opponent's financing or recruitment. Operations in this group include leaks of compromising private information, online publication of partisan content (e.g. “trolling” on comments pages), and the establishment of dedicated websites and forums to promote an armed group's message. Unless it openly incites or discourages violence, propaganda affects kinetic operations only indirectly by undermining an opponent's support base or obfuscating perceptions of events.\nIn the Ukrainian conflict, the importance of both groups attach to online propaganda is evident from the time and resources pro-Kyiv fighters spend updating Wikipedia, and pro-Russia groups devote to creating and running dedicated\nYouTube channels and social media accounts. Russian military doctrine places a heavy emphasis on the strategic use of information in warfare, as does US cyberspace joint planning doctrine.\nThe second category of cyber attacks—disruption—seeks to directly sabotage opponents' ability to operate in the physical or electronic realm. These mostly low-intensity activities include denial of service attacks, which make targeted resources unavailable through a flood of requests from a single source, and DDoS attacks, where requests originate from multiple compromised systems. Related efforts include inundating communications systems with floods of text messages or phone calls and using fire walls and proxies to block access to websites. At the extreme end of the scale is the use of malicious code to inflict physical damage or otherwise compromise infrastructure and military objects. Examples include interception of drones, communications and surveillance systems, control of Wi-Fi access points, and collection of protected information via phishing.\nThe most sophisticated known attack of this type is the Stuxnet worm, which—before its discovery in 2010—targeted industrial control systems critical to uranium enrichment in Iran. In Ukraine, notable disruptive activities have included attacks on the Central Election Committee's website during the 2014 presidential elections and attacks on the country's power grid in 2015 and 2016. Other examples include the use of malware to collect operational intelligence, like X-Agent, which retrieved locational data from mobile devices used by Ukrainian artillery troops, and the hacking of closed-circuit television (CCTV) cameras behind enemy lines.\nPropaganda and disruption are not mutually exclusive, and many cyber activities serve both purposes—shaping public opinion through disruption or disrupting an opponent's operations by shaping public opinion. For example, altering the visual appearance of websites can have the dual effect of embarrassing the target and limiting its ability to communicate. Leaks of private information also have dual implications for targets' public image and physical security.\nRecent examples of hybrid activities include the defacement of US Central Command's Twitter and Facebook pages by the Islamic State's (IS) Cyber Caliphate and operations by US Cyber Command against IS beginning in April 2016. In Ukraine, the pro-rebel group CyberBerkut (CB) has leaked private communications from senior United States, European Union, and Ukrainian officials and disclosed identities of pro-Kyiv field commanders—simultaneously creating a media scandal and forcing targets to commit more resources to personal security. Similarly, the pro-Kyiv website Myrotvorets' published names and addresses of suspected “rebel sympathizers”—information that allegedly facilitated several assassinations .\nIn the following, we limit the scope of our inquiry to cyber actions that are either purely disruptive (e.g. DDoS-style attacks) or are hybrids of the two approaches (e.g. web defacements). We do so for two reasons. First, most purely propagandistic operations, like comment-board trolling, do not aspire to influence the course of\nmilitary operations in the short term. Second, it is hard to separate the disruptive and propaganda effects of hybrid cyber activities because they depend on each other.\n## Cyber Coercion in Wartime\nOver the last two decades, cyber attacks have become an increasingly common tool of coercion, used by state and nonstate actors, independently and jointly with physical, kinetic operations. Like other instruments of coercion, cyber actions inflict costs on a target to compel a change in its behavior—either by punishing past misdeeds or by putting pressure on decision makers in real time.\nThe role of cyber compellence in wartime is not unlike that of airpower or terrorism . Cyber attacks cannot take or hold territory on their own, but they can support operations on the ground by disrupting opponents' command and control, collecting operational intelligence, and creating opportunities for conventional forces to exploit. If combatants use the Internet for coordination, recruitment, or training, low-level cyber disruption may prevent them from running these vital functions smoothly. Alternatively, cyber attacks can indirectly pressure an opponent by targeting civilian economy and infrastructure, similarly to strategic bombing. Yet unlike airpower, an operational cyber capability is relatively inexpensive to develop. It does not require new massive infrastructure, and many activities can be delegated to third parties . Unlike terrorism, the individual attacker is rarely at risk of direct physical harm.\nDespite the apparent promise of these “weapons of the future” , some scholars are skeptical that low-level cyber attacks can be an effective tool of coercion . There is little doubt that large numbers of low-level attacks can cumulatively produce large-scale damage, bringing “death by a thousand cuts” (Lemay, Fernandeza, and Knight 2010). Yet successful coercion also requires punishment to be both anticipated and avoidable , and these criteria can be difficult to meet in cyberspace.\nCyber attacks can be challenging for targets to anticipate because attackers face strong incentives to mount surprise “zero-day” exploits, before targets recognize and patch their vulnerabilities . Since the destructiveness of malicious code depreciates quickly after first use, cyber attacks are often most damaging when they are least anticipated.\nTargets also have many reasons to doubt that cyber attacks are avoidable by accommodation. For the attacker, cyber actions present a trade-off between plausible deniability—which helps prevent retaliation—and the credibility of coercive promises and threats. Any uncertainty over the source of an attack will also create uncertainty over the nature of compliance—what sort of actions will prevent future attacks and by whom.\nBeyond attribution uncertainty, cyber attacks may not generate sufficient costs to elicit compliance from. Because administrators can quickly fix or contain many\nexploited vulnerabilities, even successful attacks cause only temporary disruption . Unless the attacker continues to develop new methods and identify new vulnerabilities, a protracted campaign may quickly lose its coercive impact. As a result, targets may see compliance as insufficient and unnecessary to stop the damage .\nForce synchronization challenges may also render the timing of cyber attacks suboptimal for compellence. Hackers—especially those not integrated with military forces—may not observe battlefield events on a tactically relevant time line. Even if they did, the lead time required to plan and implement a successful attack—studying the target system, collecting intelligence on its vulnerabilities, and writing code that exploits them—can make these efforts difficult to synchronize with conventional operations.\nThese challenges are not insurmountable. Lead time is a greater barrier for high-level attacks (e.g. targeting major infrastructure) than for more routine, DDoS-style attacks. Force synchronization difficulties are also not unique to the cyber domain and are well established in research on terrorism and airpower . The ability of contemporary hackers to overcome these difficulties, however, remains unknown.\n### Previous Research\nThe question of whether low-level cyber attacks compel has deep implications for the theory and practice of national security. Yet the public and academic debate on this topic has unfolded largely in the absence of rigorous empirical evidence in either direction. Existing political science and policy literature on cybersecurity could be grouped into three broad areas: the “big picture” of cyber warfare , the overlap between cyber and kinetic capabilities , and the effect of information and communication technology on conflict .\nMost research in the first category has focused on the implications of cyber activities for peacetime deterrence or the offense--defense balance rather than wartime compellence. While the second group focuses more directly on cyber attacks during conflict, its empirical approach has been mostly qualitative, relying on evidence from descriptive case studies, macrohistorical surveys, and stylized facts. Some large-n analyses do exist , but their scope has remained on large-scale cyber attacks rather than the far more numerous low-intensity operations we consider here. While the third group does employ the statistical analysis of disaggregated data, its theoretical scope is distinct from mainstream literature on cyber attacks—evaluating, for instance, how technology affects collective action  rather than military compellence.\nOur study bridges the gap between these areas of inquiry. Our goal is to assess the coercive potential of low-level cyber actions during an armed conflict. We pursue this goal by studying the magnitude and direction of the relationship between cyber attacks and physical violence, using microlevel data from ongoing conflicts in Ukraine and Syria.\n### Empirical Expectations\nCyber attacks by actor A can affect physical violence by B in one of the three ways: negatively, positively, or not at all. If cyber compellence is successful, we should expect a short-term decrease in violence after a spike in cyber attacks. A positive response would suggest failure, where cyber attacks actually escalate violence by the opponent. If no relationship exists, cyber actions are either ineffective or irrelevant to fighting in the physical world.\nIn addition to compellence across domains, cyber attacks by actor A may impact cyber attacks by actor B. As before, only a negative relationship would imply coercive success, while a null or positive response would suggest that these actions are either ineffective or counterproductive.\n## Data Analysis\nTo evaluate whether and how cyber actions affect physical violence in war, we analyze new micro-level data from Ukraine and Syria. We begin with an in-depth study of the Ukrainian case, as one of few conflicts where both sides have used cyber attacks as a means of coercion. Due to the sophistication of hackers on both sides, the public nature of many attacks, and an abundance of data, the Ukrainian conflict allows us to observe the short-term coercive impact of cyber attacks. We then use analogous event data on Syria to evaluate the generalizability of our results. While a more systematic analysis of cross-national patterns lies beyond the scope of our article, micro-level evidence from these two conflicts might be suggestive of general patterns of modern warfare—particularly where combatants with asymmetric capabilities use cyberspace along with traditional tools of war.\nIn assembling our data, we follow two general guidelines. To address systematic differences in event reporting cross countries and media outlets , we draw data from multiple open sources—including press reports and anonymous attack traffic data. To reduce potential false positives, we include only those events that have been reported by more than one source.\n### Ukraine Cyber Attacks Data\nOur cyber event data on Ukraine include 1,841 unique, mostly low-level, cyber attacks from August 27, 2013, to February 29, 2016, drawn from two sets of sources.\nFirst are media reports of cyber attacks from rebel, Russian, Ukrainian, and Western news outlets, press releases and blogs along with social media platforms used by the involved nonstate actors. Second is the private cyber security firm Arbor Networks' Digital Attack Map (DAM; see http://www.digitalattackmap.com/about/). Unlike media sources—which include only cyber attacks publicly reported by news organizations or claimed by governments and hacker groups directly—DAM draws on anonymous attack traffic data and network outage reports to enumerate the top 2 percent of reported attacks that generate unusually high Internet traffic for each country. Including these “higher-visibility” attacks should make it easier to find a coercive effect.\nWe supplemented these data with fourteen primary source interviews with participants in the cyber campaign, as well as Russian, Ukrainian, and Western cyber security experts with direct knowledge of these operations, from the private and public sectors, academia, and journalism. We conducted all interviews in person or via e-mail or Skype in the summer and fall 2015 and provide full transcripts in the Online Appendix .\nWe grouped cyber attacks in our data set according to the partisanship of alleged perpetrators (pro-Ukrainian vs. prorebel) and the type of operation they conducted (propaganda vs. disruption). Table 1 list all actors conducting cyber activitiess in the Ukrainian conflict, their targets, and the reported frequency of their activities.\nUkrainian cyber actions include specific attacks by pro-Kyiv hackers like Anonymous Ukraine and Ukrainian Cyber Forces (UCFs). The latter is the most active group on the pro-Ukrainian side. In an interview, UCF leader Eugene Dokukin claimed to have established the nonstate group in March 2014, in response to Russian cyber attacks. Due to the “secret nature” of the organization, Dokukin was reluctant to discuss its size but noted that the number of volunteers fluctuates depending on the state of kinetic operations in eastern Ukraine . Pro-Kyiv hackers' most common targets are the communications and finances of rebel units as well as media firms and private companies in rebel-held areas.\nProrebel cyber actions include specific attacks by proseparatist or pro-Russian cyber actors, like CB, Cyber Riot Novorossiya, Green Dragon, and the Russian government. The first of these takes its name from Ukraine's disbanded Berkut riot police and claims to fight “neofascism” in Ukraine. Ukrainian and Russian cyber experts we interviewed offered contradictory assessments on CB's organizational structure. One Russian expert said that CB consists of former SBU employees who lost their jobs after the Euromaidan revolution . Contrarily, Ukrainian interviewees viewed CB either as a virtual group controlled by the Federal Security Service (FSB) or as a unit within the FSB . These groups' most popular targets include Ukrainian government officials, media, and private citizens.\nWe further disaggregated these events into the two categories previously defined—propaganda or disruption—as well as a third, hybrid, category of incidents\nTable I. Actors and Targets (Ukraine and Syria).\n|  Ukraine  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Pro-Kyiv | Actor/target | Frequency (%) | Prorebel | Actor/target | Frequency (%)  |\n|  Anonymous Ukraine | A | 6 (<1) | CyberBerkut | A | 134 (7)  |\n|  Ukrainian Cyber Forces | A | 1,392 (76) | Cyber Riot Novorossiya | A | 41 (2)  |\n|  Ukrainian governmental units and officials | A/T | 3 (<1)/326 (18) | Green Dragon | A | 1 (<1)  |\n|  Ukrainian army units | T | 1 (<1) | Quedagh | A | 1 (<1)  |\n|  Western governments and organizations | T | 15 (1) | Crimean government officials | T | 6 (<1)  |\n|  Western non-state actors | T | 7 (<1) | Russian army units | A/T | 1 (<1)/14 (1)  |\n|  Non-state supporters | T | 91 (5) | Non-state supporters | T | 444 (24)  |\n|   |  |  | Rebel groups | A/T | 2 (<1)/926 (50)  |\n|   |  |  | Russian state units and government officials | A/T | 2 (<1)/14 (1)  |\n|   |  |  | Russian state-sponsored groups | A | 237 (13)  |\n|  Total |  | 1,841 (100) |  |  | 1,841 (100)  |\n|  Syria  |   |   |   |   |   |\n|  Anti-Assad | Actor/target | Frequency (%) | Pro-Assad | Frequency (%) | Actor/target  |\n|  Anonymous/anonymous-sponsored units | A | 93 (14) | ISIL/ISIL-sponsored units | A | 54 (8)  |\n|  Anti-Assad non-state actors | A/T | 297 (44)/18 (3) | Russian government units | A | 3 (<1)  |\n|  Jabhat al-Nusra-sponsored units | A | 1 (<1) | Syrian government units and officials | A/T | 2 (<1)/272 (40)  |\n|  Kurdish non-state opposition | A | 11 (<2) | Syrian state-sponsored units | A/T | 102 (15)/2 (<1)  |\n|  Free Syrian Army | T | 1 (<1) | Pro-Assad non-state actors | T | 179 (26)  |\n|  Pro-ISIL social media and websites | T | 140 (21) |  |  |   |\n|  Total |  | 682 (100) |  |  | 682 (100)  |\nNote: ISIL = The Islamic State of Iraq and the Levant.\nthat potentially serve both purposes. The most common cyber actions in Ukraine have been DDoS-style attacks, followed by hacks of CCTV cameras and other communications. Website blockages have also proven popular, as have spearphishing e-mails targeting specific individuals. Table 2 provides a full breakdown.\nTo reduce false positives due to unconfirmed reports or dubious claims of responsibility, we only include attacks reported by more than one source. To account for uncertainty of attribution, we marked as “disputed” all cases where no one claimed responsibility and labeled as “nondisputed” those operations for which actors directly claimed responsibility in press releases, on social media, or in interviews. To focus on daily dynamics, we excluded activities whose intensity did not vary over time.\nFigure 1a depicts the temporal dynamics of pro-Ukrainian (Cyber U) and pro-Russian rebel (Cyber R) cyber operations. In early March 2014, about a week after the revolution in Kyiv, Figure 1 shows a spike in attacks by CB. The same month saw the establishment of the pro-Kyiv Ukrainian Cyber Forces, partly in response to CB's attacks. However, UCF operations do not become visible until May 2014, following an influx of volunteers to the group. May 2014 is also notable for a rise in activities by another pro-Russian cyber group, Cyber Riot Novorossiya—named after the czarist-era term (“New Russia”) for territories in southeastern Ukraine. After the first Minsk cease-fire agreement in September 2014, operations by pro-Ukrainian hackers converge to a steady rate of two to four per day, with occasional flare-ups, as in December 2014. Activities by pro-Russian hackers, by contrast, declined after the summer 2014.\n### Ukraine Violent Events Data\nOur data on kinetic operations include 26,289 violent events from Ukraine's Donbas region, recorded between February 28, 2014, and February 29, 2016. To offset reporting biases in any one source, while guarding against potential disruptions in media coverage due to cyber attacks, these data draw on seventeen Ukrainian, Russian, rebel, and international sources. As before, we include only events that appeared in more than one source.\nTo extract information on dates, locations, participants, and other event details, we relied on a combination of supervised machine learning (Support Vector Machine) and dictionary-based coding. The Online Appendix describes our measurement strategy and provides summary statistics.\nFigure 1b shows the temporal distribution of pro-Ukrainian (Kinetic U) and pro-Russian rebel (Kinetic R) physical violence. The plot shows several notable flare-ups of fighting—during a government offensive in late June 2014 and a rebel offensive in January 2015—as well as lulls following cease-fire agreements in September 2014, February 2015, and September 2015. Compared to the cyber operations in Figure 1, this plot reveals a clear correlation between kinetic operations\nTable 2. Types of Cyber Operations (Ukraine and Syria).\n|  Propaganda | Ukraine (%) | Syria (%) | Disruption | Ukraine (%) | Syria (%) | Both | Ukraine (%) | Syria (%)  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  PPI—publishing online private information of the members of the conflicting parties | 47 (2) | 59 (9) | AVG— audio-, video-, and geo-intelligence collection | 423 (23) | 1 (<1) | WDT—website defacement | 51 (3) | 389 (57)  |\n|  PRM/PUM—posting pro-rebel and pro-Ukrainian messages online | 54 (3)/5 (<1) | — | CPI—collecting private information via open sources | 13 (<1) | 10 (<2) |  |  |   |\n|  UWP—updating online pages | 6 (<1) | — | DDoS—distributed denial-of-service attack | 499 (27) | 78 (11) |  |  |   |\n|   |   |   |  ODS—other attacks with a purpose of disruption or espionage | 9 (1) | 10 (<2) |  |  |   |\n|   |   |   |  SPE—spear-phishing e-mail | 234 (13) | 17 (2.5) |  |  |   |\n|   |   |   |  STM—sending massive text messages or calling phones non-stop | 40 (2) | 1 (<1) |  |  |   |\n|   |   |   |  WBG—website blockage | 257 (14) | 376 (55) |  |  |   |\n|  Total | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100) |  | 1,841 (100) | 682 (100)  |\n|   |   |   |  |   |   |   |   |   |\nJournal of Conflict Resolution 63(2)\n(a) cyber\n(b) kinetic\nFigure 1. Cyber and kinetic operations in Ukraine . U (blue) indicates operations by Ukrainian government forces; R (red) indicates operations by pro-Russian rebel groups.\nby the two sides, with government and rebel attacks rising and falling in tandem. $^{15}$  Although this interdependence is not surprising, the data suggest that—with few exceptions—physical violence in Ukraine has been a reciprocal affair.\nFrom a brief glance at the timing of cyber and physical operations (Figure 1a and b), there are relatively few signs of a compelling effect—changes in the former do not appear to drive changes in the latter. However, a visual comparison can be misleading. Some of the variation may be due to fighting on the ground or in cyberspace, but other changes may reflect secular trends or shocks due to elections and other events not directly related to conflict. To account for these potential confounding factors and to gauge whether there is a stronger cyber-kinetic relationship than we would expect by chance, we conduct a series of more rigorous tests.\nEmpirical Strategy\nTo evaluate the relationship between cyber and kinetic operations in Ukraine, we estimate a series of vector autoregressive models\n$Y_{t} = \\sum\\limits_{j}^{p}B_{j}Y_{t - j} + GX_{t} + \\mu_{0} + \\mu_{1}t + \\mathbf{\\epsilon_{t}},$ (1)\nwhere $Y_{t} = \\left[y_{t}^{\\text{Kinetic(U)}}, y_{t}^{\\text{Kinetic(R)}}, y_{t}^{\\text{Cyber(U)}}, y_{t}^{\\text{Cyber(R)}}\\right]^{\\prime}$ is a matrix of endogenous variables, and $X_{t} = \\left[x_{1t},\\ldots,x_{kt}\\right]^{\\prime}$ is a matrix of k exogenous variables, which includes indicators for key dates and events during the war, like presidential and parliamentary electoral campaigns in Ukraine and breakaway territories; cease-fire agreements; and Ukrainian, Russian, and Soviet holidays. Deterministic components include a constant term (μ_{0}) and trend (μ_{1}t). p is the lag order, selected via Bayesian information criterion, and $\\mathbf{\\epsilon_{t}}$ is a vector of serially uncorrelated errors.\nWe control for Ukrainian, Russian, and Soviet holidays because anecdotal accounts suggest significant increases in cyber activity during such times. The UCF, for instance, had an operation called “Happy New Year,” which sought to print pro-Ukrainian messages from hacked printers in Crimea, Russia, and Donbas. National election campaigns represent another time when such activities may spike. Before and during the presidential elections, for instance, hackers bombarded Ukraine's Central Electoral Committee website with DDoS attacks. Finally, we may expect cease-fire agreements aimed at reducing physical violence to also have an effect in the cyber domain. For example, the cyber espionage operation “Armageddon”—directed against Ukrainian government websites—intensified before the Minsk I agreement went into force but then rapidly declined.\nBecause we are interested in the relationship between cyber attacks and physical violence during war, we limit our primary analysis to the active phase of military operations between May 11, 2014, and February 15, 2015—the period following independence referendums organized by the self-proclaimed Donetsk and Luhansk People's Republics and the second Minsk cease-fire agreement. In the Online Appendix, we present additional analyses of the full data set, which produced similar results.\n## Results\nData from Ukraine support the skeptical view of cyber coercion. The impulse--response curves in Figure 2 show a strong, escalatory dynamic between kinetic operations by the two sides (Kinetic U, Kinetic R), but no tangible links in either direction between kinetic and cyber operations, and no reciprocity between cyber actions (Cyber U, Cyber R).\nFollowing a standard deviation increase in kinetic rebel attacks, government violence sees a delayed rise, peaking around two days after the shock and gradually\n|  Response: |   |\n| --- | --- |\n|  Kinetic (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  |\n|  Kinetic (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  |\n|  Cyber (U) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  |\n|  Cyber (R) | 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  |\nFigure 2. Impulse response matrix, daily time series (Ukraine). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"U\" indicates reported kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\ndeclining back to zero (top row, second column). Rebel operations also rise after shocks to government operations (second row, first column), but the response here is immediate, without the delay we observe in government operations. This pattern may reflect command and control inefficiencies in the Ukrainian army, particularly early in the conflict, when indecision and leadership turnover lengthened decision cycles.\nThe relationship between cyber and kinetic operations is far weaker than that between rebel and government violence on the ground. Cyber attacks by pro-Ukrainian forces see no increase after shocks in kinetic government operations, and a positive, but uncertain increase after shocks in kinetic rebel operations (third row, first and second columns).\nThere is even less evidence that cyber attacks drive kinetic operations. The impulse--response function (IRF) curve for pro-Ukrainian government violence is, in fact, negative after shocks to rebel cyber operations (top row, two rightmost columns). Although this negative response might otherwise suggest that cyber attacks compel a decline in violence—consistent with coercive success—the estimate is also highly uncertain. Following shocks to pro-Ukrainian cyber activities, meanwhile, the main change in rebel kinetic operations is a short-term increase in volatility (second row, third column). In sum, the data suggest that cyber attacks may make violence less predictable but do not systematically change its intensity.\nPerhaps most surprisingly, there is little or no apparent strategic interaction between “cyber-warriors” on each side of the conflict. A shock in pro-Ukrainian cyber attacks yields no discernible change in pro-rebel cyber attacks (bottom row, third column) and vice versa (third row, fourth column). The two cyber campaigns, the data suggest, have unfolded independently of each other and independently of events on the ground.\nAs the diagonal elements in Figure 2 suggest, there is strong autocorrelation in each series. For each of the four categories, past shocks in operations yield a significant spike in subsequent operations. To evaluate whether the other categories of events can help us predict future values of each series, after we take this autocorrelation into account, Table 3 reports the results of Granger causality tests. The tests confirm that past levels of prorebel and pro-Kyiv kinetic operations help predict each other's future values. Kinetic operations, however, do not appear to “Granger cause”—or be “Granger caused” by—cyber attacks on either side.\nTable 4 reports the forecasting error variance decomposition, representing the proportion of variation in each series (rows) due to shocks in each endogenous variable (columns). For most variables, their own time-series account for almost all variation at the outset, but this dependency gradually decreases. As before, there is far more dependence within kinetic operations than between kinetic and cyber or within cyber actions. By the thirty-day point in the daily time series, shocks in rebel attacks account for 7 percent of variation in Ukrainian government operations, while shocks in government operations explain 12 percent of variation in rebel violence.\nJournal of Conflict Resolution 63(2)\nTable 3. Granger Causality Test, Daily Time Series (Ukraine).\n|  Effects | F statistic | p value  |\n| --- | --- | --- |\n|  Kinetic (R) → Kinetic (U) | 40.26 | .00  |\n|  Cyber (U) → Kinetic (U) | 0.50 | .48  |\n|  Cyber (R) → Kinetic (U) | 0.09 | .76  |\n|  Kinetic (U) → Kinetic (R) | 12.29 | .00  |\n|  Cyber (U) → Kinetic (R) | 1.44 | .23  |\n|  Cyber (R) → Kinetic (R) | 2.70 | .10  |\n|  Kinetic (U) → Cyber (U) | 1.40 | .24  |\n|  Kinetic (R) → Cyber (U) | 1.88 | .17  |\n|  Cyber (R) → Cyber (U) | 0.00 | .95  |\n|  Kinetic (U) → Cyber (R) | 1.74 | .19  |\n|  Kinetic (R) → Cyber (R) | 0.14 | .71  |\n|  Cyber (U) → Cyber (R) | 0.89 | .35  |\nNote: \"U\" indicates reported kinetic and cyber operations by Pro-Ukrainian government forces, and \"R\" indicates operations by Pro-Russian rebel forces.\nTable 4. Variance Decomposition, Daily Time Series (Ukraine).\n|  Operation type | Kinetic (U) | Kinetic (R) | Cyber (U) | Cyber (R)  |\n| --- | --- | --- | --- | --- |\n|  Kinetic (U) |  |  |  |   |\n|  1 Day | 1.000 | .000 | .000 | .000  |\n|  2 Days | 0.920 | .060 | .002 | .018  |\n|  7 Days | 0.906 | .071 | .002 | .020  |\n|  30 Days | 0.906 | .071 | .002 | .020  |\n|  Kinetic (R) |  |  |  |   |\n|  1 Day | 0.108 | .892 | .000 | .000  |\n|  2 Days | 0.121 | .873 | .000 | .006  |\n|  7 Days | 0.122 | .870 | .000 | .008  |\n|  30 Days | 0.122 | .870 | .000 | .008  |\n|  Cyber (U) |  |  |  |   |\n|  1 Day | 0.000 | .002 | .998 | .000  |\n|  2 Days | 0.000 | .002 | .997 | .000  |\n|  7 Days | 0.000 | .003 | .997 | .000  |\n|  30 Days | 0.000 | .003 | .997 | .000  |\n|  Cyber (R) |  |  |  |   |\n|  1 Day | 0.012 | .023 | .000 | .964  |\n|  2 Days | 0.014 | .023 | .001 | .962  |\n|  7 Days | 0.015 | .023 | .001 | .961  |\n|  30 Days | 0.015 | .023 | .001 | .961  |\nNote: \"U\" indicates kinetic and cyber operations by pro-Ukrainian government forces, and \"R\" indicates operations by pro-Russian rebel forces.\nBy contrast, shocks to cyber activities account for very little variation in kinetic operations. The highest value is for pro-Russian rebel cyber activities, which account for 2 percent of short-term variation in government violence. Cyber attacks by each side also have a relatively small impact on each other. Indeed, rebel kinetic operations explain more of the variation in cyber attacks by each actor than do cyber attacks by the other side.\nIn sum, our analysis suggests that low-level cyber attacks in Ukraine have had no effect on the timing of physical violence. Not only is there no evidence that cyber attacks have compelled opponents to de-escalate fighting, there is no discernible reciprocity between the cyber actors themselves. Each group of hackers seems to operate in its own bubble, disengaged from unfolding events in both cyberspace and the physical world.\n### Robustness Checks\nTo gauge the sensitivity of our results to various modeling and measurement choices, we conducted extensive robustness checks. We summarize their results briefly here (Table 5) and more fully in the Online Appendix.\nThe first set of tests considers vector autoregression models with alternative orderings of the four endogenous variables, which affects estimation of impulse responses. We find no substantive differences across the twenty-four permutations.\nIn a second set of robustness checks, we account for systematic differences in the kinds of conflict events that Ukrainian and Russian media report, which may bias statistical estimates—for example, by underreporting violence by a given actor. Using kinetic data from exclusively Russian or exclusively Ukrainian sources does not change the results.\nA third set of robustness tests examines different subsets of cyber attacks. Because purely disruptive activities may impose greater immediate costs than quasi-propagandistic hybrid attacks, pooling these events may dilute their coercive effect. Our results are consistent for all three subsets.\nThe last set of robustness checks examines different time periods of the conflict, since some cyber attacks predated military activity. In particular, we compare the period of intense fighting previously analyzed (May 11, 2014--February 15, 2015) to the entire date range for which we have data (February 28, 2014--February 29, 2016). Our results remain unchanged.\n## Evidence from Interviews\nIn interviews, Russian and Ukrainian cyber security experts highlighted five potential explanations for the apparent failure of cyber coercion in Ukraine: (1) lack of resources, (2) lack of coordination, (3) lack of targets, (4) lack of audience, and (5) lack of effort.\nTable 5. Robustness Checks (Ukraine and Syria).\n|  Ukraine (main results; May 11, 2014–February 15, 2015)  |   |   |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n|  I | Disruption and both | Kin(R) ↔ Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) ↔ Kin(R) | Kin(U) ↔ Kin(R) | Kin(U) → Kin(G)  |\n|  ID | Cyber | GCT(w) | VD(d) (30 day) | VD(w) (12 week) |  |  |   |\n|  I | Disruption and both |  | Kin(R) → 7%Kin(U) | Kin(R) → 10%Cyb(R) |  |  |   |\n|   |   |   | Kin(R) → 2%Cyb(R) | Kin(U) → 21%Kin(R) |  |  |   |\n|   |   |   | Kin(U) → 12%Kin(R) | Kin(U) → 17%Cyb(R) |  |  |   |\n|   |   |   | Kin(U) → 2%Cyb(R) | Cyb(U) → 4%Cyb(R) |  |  |   |\n|  ID | Cyber | IRF(d) | IRF(w) | GCT(d) | GCT(w) | VD(d) (30 day) | VD(w) (12 week)  |\n|  Ukraine (March 22, 2014–February 29, 16)  |   |   |   |   |   |   |   |\n|  2 | All | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U/R) ↔ Kin(U) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Cyb(U) ↔ Kin(R) |  |  | Kin(U) → 3%Cyb(R)  |\n|  3 | Propaganda | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin(U)/Cyb(R) | Kin(R) → 3%Kin(U) | Kin(R) → 9%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) → Kin/Cyb(R) | Kin(U) → Cyb(R) | Kin(U) → 18%Kin(R) | Kin(R) → 3%Cyb(R)  |\n|   |   |   | Cyb(U) → Kin(U) | Kin(U) → Cyb(R) |  |  | Kin(U) → 46%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(R)  |\n|  4 | Disruption | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(U/R) |  | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|  5 | Disruption and both | Kin(R) → Kin(U) | Kin(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Kin/Cyb(U) | Kin(R) → 3%Kin(U) | Kin(R) → 8%Kin(U)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) | Cyb(U) ↔ Kin(R) | Kin(U) → Cyb(R) | Kin(U) → 17%Kin(R) | Kin(U) → 45%Kin(R)  |\n|   |   |   |  | Kin(U) → Cyb(U) |  |  |   |\n(continued)\nTable 5. (continued)\n|  ID | Cyber | IRF(d) | IRF(w) | IRF(o)(d) Ukraine (May 11, 2014-February 11, 2015) | IRF(o)(w) | IRF(d) sources (RU) | IRF(d) sources (U)  |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  6 | All | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) |  | Kin(R) → 7%Kin(U) | Kin(R) → 2%Cyb(U)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(U) → 13%Kin(R) | Kin(R) → 18%Cyb(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 30%Kin(R)  |\n|   |   |   |  |  |  |  | Kin(U) → 2%Cyb(U/R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 4%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(U)  |\n|  7 | Propaganda | Kin(R) → Kin(U) | Cyb(R) → Kin(U) | Kin(R) ↔ Kin(U) | Kin(R) → Cyb(R) | Kin(R) → 7%Kin(U) | Kin(U) → 27%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) | Kin(U) → Kin(R) |  |  | Kin(U) → 13%Kin(R) | Kin(U) → 4%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 5%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 3%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 9%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 20%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 5%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(R) → 2%Cyb(U)  |\n|  8 | Disruption | Kin(R) → Kin(U) | Kin(U) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → Cyb(U) | Kin(R) → 7%Kin(U) | Kin(U) → 29%Kin(R)  |\n|   |   |  Kin(U) → Kin(R) |  |  |  | Kin(R) → 2%Cyb(R) | Kin(U) → 34%Cyb(U)  |\n|   |   |   |  |  |  | Kin(U) → 12%Kin(R) | Kin(U) → 22%Cyb(R)  |\n|   |   |   |  |  |  | Cyb(R) → 2%Kin(U) | Kin(R) → 3%Kin(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 10%Cyb(U)  |\n|   |   |   |  |  |  |  | Kin(R) → 13%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(U) → 2%Kin(U)  |\n|   |   |   |  |  |  |  | Cyb(U) → 6%Cyb(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 3%Kin(R)  |\n|   |   |   |  |  |  |  | Cyb(R) → 7%Cyb(U)  |\nSyria (March 17, 2011-July 10, 2016)\n|  9 | Disruption and both | Kin(G) → Kin(R) | Kin(R) ↔ Kin(U) | Kin(U) → 2%Kin(R)  |\n| --- | --- | --- | --- | --- |\nNote: IRF = impulse response functions; GCT = Granger causality tests; VD = variance decomposition; d = daily; w = weekly; o = alternative orderings; RU = Russian; U = Ukrainian.\nThe first explanation for coercive failure emphasizes limited resources and capabilities, particularly for the Ukrainian government. Ten years ago, the SBU briefly had a cyber department but shut it down after a year . This unit has recently reopened but continues to lack funding and personnel . It is possible that, with adequate resources, capabilities, and human capital, the Ukrainian cyber campaign might have been more effective. Resource constraints, however, do not explain coercive failure on the pro-Russian side, where investment in cyber capabilities is more robust.\nA second explanation is lack of government coordination with hackers, especially in Kyiv . UCF founder Eugene Dokukin claims to regularly provide the SBU with intelligence from hacked CCTV cameras and has offered cooperation in the past, with no success . The SBU's lack of desire to cooperate with the UCF could be due to the illegality of the latter's activities or the low priority the SBU assigns to cyber actions in the first place . Yet again, this explanation is less plausible on the pro-Russian side, where the Kremlin has cultivated extensive ties with non-state hacktivists.\nA third explanation is that—even with requisite capabilities and coordination—there are few opportune targets for disruption in Ukraine. Most industrial control systems that run Ukraine's critical infrastructure—particularly its Soviet-era components—are off-line, making remote access difficult . Yet some experts disagreed, noting that “weakness of infrastructure [security] should have provoked a DDoS attack” . The 2015 and 2016 hacks of Ukraine's power grid also seem to challenge this explanation.\nThe peculiarities of Ukraine's online population represent a fourth explanation for the indecisiveness of cyber attacks. Since only 44.1 percent of Ukrainians have Internet access—compared to 88.5 percent in the United States and 71.3 percent in Russia (see http://www.internetlivestats.com/internet-users-by-country/)—and most use it only for social media, a low-level cyber attack that blocks or defaces government websites is unlikely to influence the masses . Some experts speculated that this online population pays more attention to purely propagandistic campaigns than disruptive ones . Our data suggest that, even if this were the case, propagandistic attacks still had no effect on violence.\nThe final explanation is that cyber compellence failed because it was never seriously attempted. At first, our interviews with individual hackers revealed no shortage of coercive intent. UCF leader Eugene Dokukin claimed to conduct low-level attacks daily and vowed to continue until pro-Russian rebels lay down their arms. Dokukin further insisted—contrary to our findings—that there is close coordination between Russia's cyber and kinetic campaigns .\nWhile UCF and other nonstate groups have explicitly sought to affect battlefield outcomes, some interviewees questioned whether this intent extended to the Russian\ngovernment. Since Ukraine's information and telecommunication networks generally use Russian hardware and software, Moscow can monitor its neighbor with assets already in place . This access, along with vigorous cyber espionage—some of it ongoing since 2010—may create incentives against more aggressive actions, which could compromise valuable sources of intelligence.\nConsistent with the “lack of effort” explanation, some experts noted a shift in Russia's broader cyber strategy, away from disruption and toward propaganda . When in 2011 Vyacheslav Volodin replaced Vladislav Surkov as head of the Presidential Administration, he toughened existing laws against Russia's opposition and promoted the use of mass media and online platforms—tools already mostly under state control—to conduct information campaigns. If Russia's cyber activities have shifted toward propaganda due to this strategy change, weak short-term battlefield effects should not be surprising .\n## Evidence beyond Ukraine: Syria's Digital Front\nAccording to evidence from microlevel data and interviews, cyber attacks did not affect battlefield events in Ukraine. During one of the first armed conflicts where both sides used low-level cyber actions extensively, events in the digital realm have unfolded independently of—and have had no discernible effect on—events on the ground. Conditions in Ukraine were in many ways optimal to observe the coercive impact of cyber actions, for reasons we already discussed (i.e. visibility of major attacks, regular claims of responsibility, less uncertainty over attribution). Yet we found no evidence that low-level cyber attacks affected physical violence. Nor did hackers on each side even affect each other's activities.\nWhile important, Ukraine is not the only contemporary conflict with a significant cyber dimension. In Syria, state and nonstate actors have employed low-level cyber actions extensively for propaganda and disruption, complementing traditional tools of warfare in the deadliest conflict ongoing today. Syria's war has also lasted three years longer than Ukraine's. Over this time, its digital front has expanded in scope and sophistication, offering a glimpse of cyber coercion in a more protracted setting.\nAn in-depth study of Syria's digital front lies beyond the scope of this article. A brief analysis of the data, however, suggests that our findings from Ukraine may be part of a broader pattern: cyber capabilities have not yet evolved to the point of having an impact on physical violence.\nTo evaluate the effectiveness of cyber compellence in this second case, we replicated the model in (equation 1), using an analogous daily time series of cyber attacks and violent events in Syria. Our data comprise 9,282 kinetic and 682 low-level cyber attacks ranging from March 2011 until July 2016. Table 2 provides a breakdown of cyber techniques used in the Syrian conflict, their brief description, and frequency. Our data on kinetic operations rely on human-assisted machine\nJournal of Conflict Resolution 63(2)\nFigure 3. Cyber and kinetic operations in Syria . G (blue) indicates operations by pro-Assad government forces; R (red) indicates operations by anti-Assad rebel groups.\ncoding of event reports from the International Institute for Strategic Studies Armed Conflict Database (see Online Appendix for details).\nGiven the complex nature of the Syrian conflict and the multiple parties involved, we restrict our analysis only to operations by progovernment forces (i.e., Syrian Army, Hezbollah and pro-Assad militias) and the main rebel opposition (i.e., Free Syrian Army, Jaish al-Fatah, including Al Nusra Front). Table 1 provides a list of cyber actors in the Syrian conflict, their targets, and frequency of their activities.\nThe dynamics of cyber and kinetic operations in Syria exhibit similar patterns to what we saw in Ukraine. Raw data (Figure 3a and b) suggest relatively little overlap in timing, especially at the beginning of the conflict. The IRF curves in Figure 4 show a rise in rebel operations following shocks to government operations (second row, first column), and mostly negligible (though negative) links between cyber and kinetic operations, and across cyber attacks by each actor. Links between kinetic\n|  Response: |   |\n| --- | --- |\n|  Kinetic (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380 385 390 395  |\n|  Kinetic (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295  |\n|  Cyber (G) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230 235 240 245 250 260 270 275  |\n|  Cyber (R) | 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190 195 200 205 210 215 220 225 230  |\n|  Impulse: | Kinetic (G) Kinetic (R) Cyber (G) Cyber (R)  |\nFigure 4. Impulse response matrix, daily time series (Syria). Light gray area represents 95 percent confidence intervals, medium gray 90 percent, dark gray 68 percent. \"G\" indicates reported kinetic and cyber operations by pro-Assad government forces, and \"R\" indicates operations by anti-Assad rebel forces.\noperations—and their disconnect from cyber attacks—are also evident in variance decomposition results, and Granger tests, provided in the Online Appendix.\nThere are several reasons for caution in interpreting these results. The Syrian conflict involves a larger constellation of actors than Ukraine, and our dyadic analysis may overlook significant interactions elsewhere, particularly between actors with more developed cyber capabilities (e.g. Russia, United States). We also lack interview evidence that might help contextualize the null effect. However tentative, these results do align with what we saw in Ukraine: low-level cyber attacks have had little or no impact on violence.\n## Conclusion\nThe evidence we presented in this article—based on analysis of new data and expert interviews—suggests that cyber attacks are ineffective as a tool of coercion in war. Although kinetic operations explain the timing of other kinetic operations, low-level cyber attacks have no discernible effect on violence in the physical world. In Ukraine and Syria, the “cyberwar” has unfolded in isolation from the rest of the conflict.\nThis finding has several implications for theory and policy. First, by providing the first statistical analysis of modern low-level cyber campaigns, our study complements the qualitative focus of previous empirical work. Second, our research sheds light on a theoretical question about the strength and direction of the cyber--kinetic relationship and—in so doing—begins to fill an empirical gap in political science literature on this topic. Third, to the extent that policymakers might overestimate the importance of cyber actions due to a lack of empirical evidence to the contrary, our findings can potentially help correct this misperception. Finally, and more worryingly, our results suggest that—due to their disconnect from physical violence—low-level cyber attacks are very difficult to predict.\nFurther research is needed to understand the dynamics of low-level cyber attacks. One such area of research is cyber coercion in the context of symmetric, conventional war. While our study helps illuminate dynamics of cyber compellence between parties with asymmetric capabilities, we may well observe different patterns when major powers use cyberspace against peer competitors. Thankfully, no armed conflict has yet provided researchers with the data needed to evaluate this possibility.\nSecond, our scope in this article has been exclusively on short-term military consequences rather than long-term political effects. The latter are no less theoretically significant, but—unlike simple counts of violent events—potentially more difficult to measure and analyze. A study of long-term political effects would also need to more systematically incorporate purely propagandistic cyber activities and their impact on public opinion, which we omitted here due to our focus on short-term military compellence.\nAlthough the secretive nature of many ongoing physical and digital operations is a challenge for this research, questions over the coercive potential of cyber attacks\nwill become only more salient in the future. In June 2017, the New York Times reported that US cyber efforts against the IS—previously lauded as “a [major] shift in America's war-fighting strategy and power projection” —have yielded few tangible successes . Our data from Ukraine indicate that the US experience may be part of a broader pattern.\nAt best, coordination between low-level cyber and kinetic operations today is on roughly the same level as that between airpower and ground operations in World War I. Back then, armies were increasingly using aircraft for reconnaissance and surveillance on the front but were not yet able to fully exploit their potential for ground combat support and strategic bombing. That revolution appeared on the battlefield twenty-five years later, with devastating effect. As cyber capabilities develop and synchronization challenges become less severe, there will be a growing need for assessments of how far we have come. We hope that analyses of the sort we provided in these pages can serve as an early benchmark.\n## Authors' Note\nA previous version of this article was presented at the 2015 Peace Science Society International annual meeting, Oxford, MS, and at the Association for the Study of Nationalities Convention at New York, NY.\nWe are grateful to Maura Drabik, Paulina Knoblock, Neil Schwartz, and Alyssa Wallace for excellent research assistance. Robert Axelrod, Myriam Dunn-Cavelty, Eric Gartzke, Miguel Gomez, Todd Lehmann, Jon Lindsay, Tim Maurer, Brandon Valeriano, Christopher Whyte, and workshop participants of the Conflict & Peace, Research & Development workshop at the University of Michigan, of the Bridging the Gap Workshop on Cyber Conflict at Columbia University, of the Cross-Domain Deterrence lab at the University of California, San Diego, and of the Center for Security Studies at ETH Zurich provided helpful comments on the earlier drafts of this article.\n## Declaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n## Funding\nThe author(s) received no financial support for the research, authorship, and/or publication of this article.\n## Supplemental Material\nSupplemental material for this article is available online."
    }
  },
  "citation_summary": {
    "style": "author_year",
    "dominant_bucket": "author_year",
    "dominant": {
      "intext_total": 41.0,
      "success_occurrences": 39.0,
      "success_unique": 22.0,
      "bib_unique_total": 82.0,
      "occurrence_match_rate": 0.9512195121951219,
      "bib_coverage_rate": 0.2682926829268293,
      "success_percentage": 95.12,
      "missing_intext_expected_total": 0,
      "highest_intext_index": 0,
      "missing_footnotes_for_seen_total": 0,
      "uncited_footnote_total": 0,
      "style": "author_year"
    },
    "buckets": {
      "footnotes": {
        "intext_total": 1.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 14.0,
        "highest_intext_index": 15.0,
        "missing_footnotes_for_seen_total": 1.0,
        "uncited_footnote_total": 0.0,
        "style": "footnotes"
      },
      "tex": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 6.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0.0,
        "highest_intext_index": 0.0,
        "missing_footnotes_for_seen_total": 0.0,
        "uncited_footnote_total": 3.0,
        "style": "tex_superscript"
      },
      "numeric": {
        "intext_total": 0.0,
        "success_occurrences": 0.0,
        "success_unique": 0.0,
        "bib_unique_total": 0.0,
        "occurrence_match_rate": 0.0,
        "bib_coverage_rate": 0.0,
        "success_percentage": 0.0,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "numeric"
      },
      "author_year": {
        "intext_total": 41.0,
        "success_occurrences": 39.0,
        "success_unique": 22.0,
        "bib_unique_total": 82.0,
        "occurrence_match_rate": 0.9512195121951219,
        "bib_coverage_rate": 0.2682926829268293,
        "success_percentage": 95.12,
        "missing_intext_expected_total": 0,
        "highest_intext_index": 0,
        "missing_footnotes_for_seen_total": 0,
        "uncited_footnote_total": 0,
        "style": "author_year"
      }
    }
  },
  "metadata": {
    "title": "Invisible Digital Front: Can Cyber Attacks Shape Battlefield Events?",
    "subtitle": "Journal of Conflict Resolution",
    "document_type": "journal_article",
    "venue": "Journal of Conflict Resolution",
    "publication_year": 2017,
    "authors": [
      "Nadiya Kostyuk",
      "Yuri M. Zhukov"
    ],
    "affiliations": [],
    "emails": [
      "nadiya@umich.edu"
    ],
    "orcids": [],
    "corresponding_author_line": "",
    "abstract": "Recent years have seen growing concern over the use of cyber attacks in wartime, but little evidence that these new tools of coercion can change battlefield events. We present the first quantitative analysis of the relationship between cyber activities and physical violence during war. Using new event data from the armed conflict in Ukraine—and additional data from Syria’s civil war—we analyze the dynamics of cyber attacks and find that such activities have had little or no impact on fighting. In Ukraine—one of the first armed conflicts where both sides deployed such tools extensively—cyber activities failed to compel discernible changes in battlefield behavior. Indeed, hackers on both sides have had difficulty responding to battlefield events, much less shaping them. An analysis of conflict dynamics in Syria produces similar results: the timing of cyber actions is independent of fighting on the ground. Our finding—that cyber attacks are not (yet) effective as tools of coercion in war—has potentially significant implications for other armed conflicts with a digital front.",
    "keywords": [
      "compellence",
      "coercion",
      "physical violence",
      "conflict",
      "cyber attacks On December 23",
      "hackers attacked Ukraine’s power grid",
      "University of Michigan",
      "Ann Arbor",
      "MI",
      "USA"
    ],
    "publication_dates": {},
    "identifiers": {
      "doi": [
        "10.1177/0022002717737138"
      ],
      "issn": [],
      "isbn": [],
      "arxiv": [],
      "pmid": [],
      "pmcid": [],
      "urls": [
        "http://www.digitalattackmap.com/about"
      ]
    },
    "references_block_count": 1,
    "references_entries_estimated": 59,
    "heading_count": 22,
    "max_heading_level": 3,
    "partial_document": {
      "is_partial_document": false,
      "reasons": [],
      "toc_dot_lines": 0
    }
  },
  "validation": {
    "dominant_quality": {
      "intext_total": 41,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 1.0,
      "footnote_coverage": 0.9512195121951219,
      "unique_index_count": 24
    },
    "footnotes_quality": {
      "intext_total": 1,
      "index_coverage": 1.0,
      "intext_citation_coverage": 1.0,
      "preceding_text_coverage": 0.0,
      "footnote_coverage": 0.0,
      "unique_index_count": 1,
      "items_total": 0
    },
    "style_validation": {
      "detected_style": "author_year",
      "recommended_style": "unknown",
      "aligned": true,
      "signals": {
        "superscript_hits": 3,
        "superscript_definition_lines": 0,
        "numeric_bracket_hits": 0,
        "numeric_endnote_lines": 0,
        "author_year_hits": 0
      }
    },
    "coverage_validation": {
      "dominant_bib_total": 82.0,
      "dominant_bib_coverage_rate": 0.2682926829268293,
      "dominant_link_target": "bibliography",
      "dominant_unresolved_flag": "unresolved_reference_links"
    },
    "heading_validation": {
      "heading_count": 22,
      "max_heading_level": 3,
      "level_jump_violations": 0,
      "numbering_parent_violations": 0,
      "has_reference_heading": true,
      "has_subheadings": true
    },
    "metadata_validation": {
      "field_presence": {
        "title": true,
        "authors": true,
        "affiliations": false,
        "emails": true,
        "orcids": false,
        "abstract": true,
        "keywords": true,
        "venue": true,
        "persistent_identifier": true,
        "headings": true,
        "partial_document": false
      },
      "counts": {
        "authors": 2,
        "affiliations": 0,
        "emails": 1,
        "orcids": 0,
        "keywords": 10,
        "doi": 1,
        "issn": 0,
        "isbn": 0,
        "arxiv": 0,
        "pmid": 0,
        "pmcid": 0,
        "urls": 1
      },
      "coverage": {
        "core_coverage": 1.0,
        "email_author_link_rate": 0.0
      },
      "partial_document": {
        "is_partial_document": false,
        "reasons": [],
        "toc_dot_lines": 0
      },
      "flags": [
        "meta_missing_affiliations",
        "meta_low_email_author_link_rate"
      ]
    },
    "flags": [
      "unresolved_reference_links",
      "low_bib_coverage",
      "footnotes_bucket_unresolved",
      "meta_missing_affiliations",
      "meta_low_email_author_link_rate"
    ]
  },
  "updated_at_utc": "2026-02-14T08:28:11.992986+00:00"
}